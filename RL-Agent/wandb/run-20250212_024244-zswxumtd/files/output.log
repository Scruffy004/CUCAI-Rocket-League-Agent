Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.01161
Policy Entropy: 3.10495
Value Function Loss: 0.00540

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02164
Policy Update Magnitude: 0.20810
Value Function Update Magnitude: 0.19684

Collected Steps per Second: 6,992.98245
Overall Steps per Second: 4,078.10859

Timestep Collection Time: 7.15203
Timestep Consumption Time: 5.11199
PPO Batch Consumption Time: 2.06415
Total Iteration Time: 12.26402

Cumulative Model Updates: 140,486
Cumulative Timesteps: 1,171,717,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.89847
Policy Entropy: 3.11603
Value Function Loss: 0.00509

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 0.23297
Value Function Update Magnitude: 0.19548

Collected Steps per Second: 20,990.74028
Overall Steps per Second: 13,594.59420

Timestep Collection Time: 2.38248
Timestep Consumption Time: 1.29619
PPO Batch Consumption Time: 0.30350
Total Iteration Time: 3.67867

Cumulative Model Updates: 140,488
Cumulative Timesteps: 1,171,767,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1171767454...
Checkpoint 1171767454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.63037
Policy Entropy: 3.13733
Value Function Loss: 0.00462

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.45479
Value Function Update Magnitude: 0.39508

Collected Steps per Second: 21,362.13487
Overall Steps per Second: 11,861.87769

Timestep Collection Time: 2.34125
Timestep Consumption Time: 1.87512
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.21636

Cumulative Model Updates: 140,492
Cumulative Timesteps: 1,171,817,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.00649
Policy Entropy: 3.12437
Value Function Loss: 0.00442

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.62523
Value Function Update Magnitude: 0.57310

Collected Steps per Second: 21,781.42983
Overall Steps per Second: 10,658.63742

Timestep Collection Time: 2.29590
Timestep Consumption Time: 2.39588
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.69178

Cumulative Model Updates: 140,498
Cumulative Timesteps: 1,171,867,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1171867476...
Checkpoint 1171867476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.71072
Policy Entropy: 3.11832
Value Function Loss: 0.00409

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.59924
Value Function Update Magnitude: 0.54866

Collected Steps per Second: 21,492.37692
Overall Steps per Second: 10,486.55928

Timestep Collection Time: 2.32715
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.76953

Cumulative Model Updates: 140,504
Cumulative Timesteps: 1,171,917,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.98208
Policy Entropy: 3.10147
Value Function Loss: 0.00446

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.59301
Value Function Update Magnitude: 0.53749

Collected Steps per Second: 21,686.47483
Overall Steps per Second: 10,704.45881

Timestep Collection Time: 2.30641
Timestep Consumption Time: 2.36622
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.67263

Cumulative Model Updates: 140,510
Cumulative Timesteps: 1,171,967,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1171967510...
Checkpoint 1171967510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.32644
Policy Entropy: 3.11091
Value Function Loss: 0.00452

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.59057
Value Function Update Magnitude: 0.56510

Collected Steps per Second: 21,610.42857
Overall Steps per Second: 10,526.97531

Timestep Collection Time: 2.31379
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.74989

Cumulative Model Updates: 140,516
Cumulative Timesteps: 1,172,017,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.96210
Policy Entropy: 3.11428
Value Function Loss: 0.00485

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.59806
Value Function Update Magnitude: 0.58633

Collected Steps per Second: 22,044.38677
Overall Steps per Second: 10,769.05776

Timestep Collection Time: 2.26851
Timestep Consumption Time: 2.37516
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.64367

Cumulative Model Updates: 140,522
Cumulative Timesteps: 1,172,067,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1172067520...
Checkpoint 1172067520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.09252
Policy Entropy: 3.11128
Value Function Loss: 0.00481

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.60687
Value Function Update Magnitude: 0.58526

Collected Steps per Second: 21,892.76109
Overall Steps per Second: 10,767.60743

Timestep Collection Time: 2.28514
Timestep Consumption Time: 2.36102
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.64616

Cumulative Model Updates: 140,528
Cumulative Timesteps: 1,172,117,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.49307
Policy Entropy: 3.13109
Value Function Loss: 0.00500

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.60456
Value Function Update Magnitude: 0.57735

Collected Steps per Second: 22,086.87554
Overall Steps per Second: 10,406.19759

Timestep Collection Time: 2.26515
Timestep Consumption Time: 2.54257
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.80771

Cumulative Model Updates: 140,534
Cumulative Timesteps: 1,172,167,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1172167578...
Checkpoint 1172167578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.73121
Policy Entropy: 3.15775
Value Function Loss: 0.00438

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.58757
Value Function Update Magnitude: 0.57519

Collected Steps per Second: 21,387.20120
Overall Steps per Second: 10,483.20826

Timestep Collection Time: 2.33916
Timestep Consumption Time: 2.43305
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.77220

Cumulative Model Updates: 140,540
Cumulative Timesteps: 1,172,217,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,777.87615
Policy Entropy: 3.16266
Value Function Loss: 0.00447

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.58211
Value Function Update Magnitude: 0.58309

Collected Steps per Second: 21,452.58836
Overall Steps per Second: 10,454.11778

Timestep Collection Time: 2.33109
Timestep Consumption Time: 2.45248
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.78357

Cumulative Model Updates: 140,546
Cumulative Timesteps: 1,172,267,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1172267614...
Checkpoint 1172267614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.36143
Policy Entropy: 3.14772
Value Function Loss: 0.00447

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.58559
Value Function Update Magnitude: 0.57734

Collected Steps per Second: 21,928.56013
Overall Steps per Second: 10,510.24230

Timestep Collection Time: 2.28068
Timestep Consumption Time: 2.47773
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.75841

Cumulative Model Updates: 140,552
Cumulative Timesteps: 1,172,317,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.78636
Policy Entropy: 3.13293
Value Function Loss: 0.00485

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.59315
Value Function Update Magnitude: 0.58841

Collected Steps per Second: 22,108.55358
Overall Steps per Second: 10,430.98343

Timestep Collection Time: 2.26283
Timestep Consumption Time: 2.53326
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.79610

Cumulative Model Updates: 140,558
Cumulative Timesteps: 1,172,367,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1172367654...
Checkpoint 1172367654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.18684
Policy Entropy: 3.14146
Value Function Loss: 0.00483

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.59339
Value Function Update Magnitude: 0.57957

Collected Steps per Second: 21,621.74222
Overall Steps per Second: 10,664.30590

Timestep Collection Time: 2.31276
Timestep Consumption Time: 2.37634
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.68910

Cumulative Model Updates: 140,564
Cumulative Timesteps: 1,172,417,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.03577
Policy Entropy: 3.13498
Value Function Loss: 0.00461

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.59230
Value Function Update Magnitude: 0.58605

Collected Steps per Second: 22,126.03664
Overall Steps per Second: 10,764.75297

Timestep Collection Time: 2.26005
Timestep Consumption Time: 2.38529
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.64535

Cumulative Model Updates: 140,570
Cumulative Timesteps: 1,172,467,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1172467666...
Checkpoint 1172467666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623.27004
Policy Entropy: 3.14308
Value Function Loss: 0.00445

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.59986
Value Function Update Magnitude: 0.60270

Collected Steps per Second: 21,701.25745
Overall Steps per Second: 10,662.69009

Timestep Collection Time: 2.30484
Timestep Consumption Time: 2.38609
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.69094

Cumulative Model Updates: 140,576
Cumulative Timesteps: 1,172,517,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.31952
Policy Entropy: 3.14780
Value Function Loss: 0.00424

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.59582
Value Function Update Magnitude: 0.58405

Collected Steps per Second: 22,012.75527
Overall Steps per Second: 10,550.51704

Timestep Collection Time: 2.27150
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.73929

Cumulative Model Updates: 140,582
Cumulative Timesteps: 1,172,567,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1172567686...
Checkpoint 1172567686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.88812
Policy Entropy: 3.15121
Value Function Loss: 0.00424

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.58096
Value Function Update Magnitude: 0.56889

Collected Steps per Second: 21,790.61763
Overall Steps per Second: 10,616.59528

Timestep Collection Time: 2.29576
Timestep Consumption Time: 2.41630
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.71206

Cumulative Model Updates: 140,588
Cumulative Timesteps: 1,172,617,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,346.62347
Policy Entropy: 3.15060
Value Function Loss: 0.00413

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.56743
Value Function Update Magnitude: 0.52919

Collected Steps per Second: 22,256.46674
Overall Steps per Second: 10,798.48751

Timestep Collection Time: 2.24672
Timestep Consumption Time: 2.38393
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.63065

Cumulative Model Updates: 140,594
Cumulative Timesteps: 1,172,667,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1172667716...
Checkpoint 1172667716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.03351
Policy Entropy: 3.14491
Value Function Loss: 0.00422

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.56259
Value Function Update Magnitude: 0.52593

Collected Steps per Second: 21,784.31800
Overall Steps per Second: 10,703.03458

Timestep Collection Time: 2.29550
Timestep Consumption Time: 2.37663
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.67213

Cumulative Model Updates: 140,600
Cumulative Timesteps: 1,172,717,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.05861
Policy Entropy: 3.15125
Value Function Loss: 0.00406

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.52606

Collected Steps per Second: 21,596.33554
Overall Steps per Second: 10,486.58030

Timestep Collection Time: 2.31530
Timestep Consumption Time: 2.45289
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.76819

Cumulative Model Updates: 140,606
Cumulative Timesteps: 1,172,767,724

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1172767724...
Checkpoint 1172767724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.03899
Policy Entropy: 3.14091
Value Function Loss: 0.00460

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.58320
Value Function Update Magnitude: 0.52504

Collected Steps per Second: 21,328.42603
Overall Steps per Second: 10,456.48023

Timestep Collection Time: 2.34448
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.78211

Cumulative Model Updates: 140,612
Cumulative Timesteps: 1,172,817,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.18778
Policy Entropy: 3.13605
Value Function Loss: 0.00437

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.58397
Value Function Update Magnitude: 0.54870

Collected Steps per Second: 21,941.74241
Overall Steps per Second: 10,717.89033

Timestep Collection Time: 2.27913
Timestep Consumption Time: 2.38672
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.66584

Cumulative Model Updates: 140,618
Cumulative Timesteps: 1,172,867,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1172867736...
Checkpoint 1172867736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,155.71051
Policy Entropy: 3.12898
Value Function Loss: 0.00419

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.57766
Value Function Update Magnitude: 0.54791

Collected Steps per Second: 21,398.52964
Overall Steps per Second: 10,461.49091

Timestep Collection Time: 2.33698
Timestep Consumption Time: 2.44322
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.78020

Cumulative Model Updates: 140,624
Cumulative Timesteps: 1,172,917,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.97492
Policy Entropy: 3.13626
Value Function Loss: 0.00373

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.57246
Value Function Update Magnitude: 0.52631

Collected Steps per Second: 21,610.45764
Overall Steps per Second: 10,631.63437

Timestep Collection Time: 2.31536
Timestep Consumption Time: 2.39097
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.70633

Cumulative Model Updates: 140,630
Cumulative Timesteps: 1,172,967,780

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1172967780...
Checkpoint 1172967780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,271.52313
Policy Entropy: 3.15101
Value Function Loss: 0.00402

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.57526
Value Function Update Magnitude: 0.51670

Collected Steps per Second: 19,079.57411
Overall Steps per Second: 9,753.46520

Timestep Collection Time: 2.62291
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 5.13089

Cumulative Model Updates: 140,636
Cumulative Timesteps: 1,173,017,824

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,747.75616
Policy Entropy: 3.14253
Value Function Loss: 0.00403

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.57775
Value Function Update Magnitude: 0.52589

Collected Steps per Second: 21,122.49782
Overall Steps per Second: 10,286.30623

Timestep Collection Time: 2.36838
Timestep Consumption Time: 2.49498
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.86336

Cumulative Model Updates: 140,642
Cumulative Timesteps: 1,173,067,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1173067850...
Checkpoint 1173067850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.22473
Policy Entropy: 3.12642
Value Function Loss: 0.00441

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.58957
Value Function Update Magnitude: 0.55703

Collected Steps per Second: 21,849.17431
Overall Steps per Second: 10,506.64561

Timestep Collection Time: 2.28942
Timestep Consumption Time: 2.47156
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.76099

Cumulative Model Updates: 140,648
Cumulative Timesteps: 1,173,117,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.84970
Policy Entropy: 3.11690
Value Function Loss: 0.00437

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.59413
Value Function Update Magnitude: 0.58384

Collected Steps per Second: 22,158.62974
Overall Steps per Second: 10,621.88820

Timestep Collection Time: 2.25736
Timestep Consumption Time: 2.45178
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.70914

Cumulative Model Updates: 140,654
Cumulative Timesteps: 1,173,167,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1173167892...
Checkpoint 1173167892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,195.55902
Policy Entropy: 3.12626
Value Function Loss: 0.00428

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.58734
Value Function Update Magnitude: 0.56980

Collected Steps per Second: 21,910.66291
Overall Steps per Second: 10,447.61809

Timestep Collection Time: 2.28218
Timestep Consumption Time: 2.50399
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.78616

Cumulative Model Updates: 140,660
Cumulative Timesteps: 1,173,217,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.41446
Policy Entropy: 3.12699
Value Function Loss: 0.00403

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.58455
Value Function Update Magnitude: 0.54487

Collected Steps per Second: 22,630.06848
Overall Steps per Second: 10,640.20533

Timestep Collection Time: 2.20980
Timestep Consumption Time: 2.49011
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.69991

Cumulative Model Updates: 140,666
Cumulative Timesteps: 1,173,267,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1173267904...
Checkpoint 1173267904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,275.10482
Policy Entropy: 3.12207
Value Function Loss: 0.00426

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.58450
Value Function Update Magnitude: 0.52815

Collected Steps per Second: 22,541.68596
Overall Steps per Second: 10,609.64902

Timestep Collection Time: 2.21882
Timestep Consumption Time: 2.49538
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.71420

Cumulative Model Updates: 140,672
Cumulative Timesteps: 1,173,317,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.59179
Policy Entropy: 3.11051
Value Function Loss: 0.00435

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.58327
Value Function Update Magnitude: 0.53962

Collected Steps per Second: 22,870.88763
Overall Steps per Second: 10,789.74515

Timestep Collection Time: 2.18697
Timestep Consumption Time: 2.44873
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.63570

Cumulative Model Updates: 140,678
Cumulative Timesteps: 1,173,367,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1173367938...
Checkpoint 1173367938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.43261
Policy Entropy: 3.09319
Value Function Loss: 0.00438

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.58859
Value Function Update Magnitude: 0.54671

Collected Steps per Second: 22,356.92234
Overall Steps per Second: 10,690.69492

Timestep Collection Time: 2.23662
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.67734

Cumulative Model Updates: 140,684
Cumulative Timesteps: 1,173,417,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.06090
Policy Entropy: 3.09706
Value Function Loss: 0.00414

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.58659
Value Function Update Magnitude: 0.53449

Collected Steps per Second: 22,347.23922
Overall Steps per Second: 10,522.79578

Timestep Collection Time: 2.23849
Timestep Consumption Time: 2.51538
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.75387

Cumulative Model Updates: 140,690
Cumulative Timesteps: 1,173,467,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1173467966...
Checkpoint 1173467966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.10145
Policy Entropy: 3.10362
Value Function Loss: 0.00406

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.58042
Value Function Update Magnitude: 0.53159

Collected Steps per Second: 21,870.00622
Overall Steps per Second: 10,589.44300

Timestep Collection Time: 2.28697
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.72319

Cumulative Model Updates: 140,696
Cumulative Timesteps: 1,173,517,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.79782
Policy Entropy: 3.11941
Value Function Loss: 0.00399

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.57971
Value Function Update Magnitude: 0.52638

Collected Steps per Second: 22,214.52488
Overall Steps per Second: 10,298.25093

Timestep Collection Time: 2.25186
Timestep Consumption Time: 2.60566
PPO Batch Consumption Time: 0.30683
Total Iteration Time: 4.85752

Cumulative Model Updates: 140,702
Cumulative Timesteps: 1,173,568,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1173568006...
Checkpoint 1173568006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.66036
Policy Entropy: 3.13235
Value Function Loss: 0.00389

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.56695
Value Function Update Magnitude: 0.52560

Collected Steps per Second: 22,287.61396
Overall Steps per Second: 10,544.51646

Timestep Collection Time: 2.24412
Timestep Consumption Time: 2.49920
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.74332

Cumulative Model Updates: 140,708
Cumulative Timesteps: 1,173,618,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,276.70582
Policy Entropy: 3.13613
Value Function Loss: 0.00393

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.55969
Value Function Update Magnitude: 0.52858

Collected Steps per Second: 22,835.89458
Overall Steps per Second: 10,659.88305

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.69067

Cumulative Model Updates: 140,714
Cumulative Timesteps: 1,173,668,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1173668024...
Checkpoint 1173668024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,067.36818
Policy Entropy: 3.14160
Value Function Loss: 0.00401

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.52191

Collected Steps per Second: 22,424.07837
Overall Steps per Second: 10,652.62851

Timestep Collection Time: 2.23099
Timestep Consumption Time: 2.46531
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.69631

Cumulative Model Updates: 140,720
Cumulative Timesteps: 1,173,718,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,898.49501
Policy Entropy: 3.13694
Value Function Loss: 0.00395

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.50189

Collected Steps per Second: 22,751.98729
Overall Steps per Second: 10,534.38418

Timestep Collection Time: 2.19902
Timestep Consumption Time: 2.55038
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.74940

Cumulative Model Updates: 140,726
Cumulative Timesteps: 1,173,768,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1173768084...
Checkpoint 1173768084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,981.46880
Policy Entropy: 3.12711
Value Function Loss: 0.00387

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.55987
Value Function Update Magnitude: 0.47498

Collected Steps per Second: 22,482.34851
Overall Steps per Second: 10,679.05436

Timestep Collection Time: 2.22450
Timestep Consumption Time: 2.45869
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.68319

Cumulative Model Updates: 140,732
Cumulative Timesteps: 1,173,818,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.21546
Policy Entropy: 3.12100
Value Function Loss: 0.00396

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.56340
Value Function Update Magnitude: 0.50451

Collected Steps per Second: 22,933.35739
Overall Steps per Second: 10,833.70947

Timestep Collection Time: 2.18145
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.61781

Cumulative Model Updates: 140,738
Cumulative Timesteps: 1,173,868,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1173868124...
Checkpoint 1173868124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.59630
Policy Entropy: 3.11543
Value Function Loss: 0.00389

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.55647
Value Function Update Magnitude: 0.46910

Collected Steps per Second: 22,354.17931
Overall Steps per Second: 10,655.84647

Timestep Collection Time: 2.23761
Timestep Consumption Time: 2.45652
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.69414

Cumulative Model Updates: 140,744
Cumulative Timesteps: 1,173,918,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,625.33674
Policy Entropy: 3.11110
Value Function Loss: 0.00419

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.56306
Value Function Update Magnitude: 0.46741

Collected Steps per Second: 22,689.33283
Overall Steps per Second: 10,536.48812

Timestep Collection Time: 2.20438
Timestep Consumption Time: 2.54255
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.74693

Cumulative Model Updates: 140,750
Cumulative Timesteps: 1,173,968,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1173968160...
Checkpoint 1173968160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,728.00289
Policy Entropy: 3.10455
Value Function Loss: 0.00441

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.58728
Value Function Update Magnitude: 0.49652

Collected Steps per Second: 22,356.98988
Overall Steps per Second: 10,666.85051

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.68798

Cumulative Model Updates: 140,756
Cumulative Timesteps: 1,174,018,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.03683
Policy Entropy: 3.09813
Value Function Loss: 0.00462

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.58912
Value Function Update Magnitude: 0.52761

Collected Steps per Second: 22,466.92110
Overall Steps per Second: 10,587.94029

Timestep Collection Time: 2.22692
Timestep Consumption Time: 2.49846
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.72538

Cumulative Model Updates: 140,762
Cumulative Timesteps: 1,174,068,198

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1174068198...
Checkpoint 1174068198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.79605
Policy Entropy: 3.09728
Value Function Loss: 0.00435

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10826
Policy Update Magnitude: 0.58450
Value Function Update Magnitude: 0.53791

Collected Steps per Second: 22,120.91846
Overall Steps per Second: 10,608.79510

Timestep Collection Time: 2.26121
Timestep Consumption Time: 2.45375
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.71496

Cumulative Model Updates: 140,768
Cumulative Timesteps: 1,174,118,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692.66704
Policy Entropy: 3.08596
Value Function Loss: 0.00406

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.58069
Value Function Update Magnitude: 0.51961

Collected Steps per Second: 22,105.40087
Overall Steps per Second: 10,477.86339

Timestep Collection Time: 2.26252
Timestep Consumption Time: 2.51078
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.77330

Cumulative Model Updates: 140,774
Cumulative Timesteps: 1,174,168,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1174168232...
Checkpoint 1174168232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.08101
Policy Entropy: 3.09507
Value Function Loss: 0.00397

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.58566
Value Function Update Magnitude: 0.51802

Collected Steps per Second: 22,119.27708
Overall Steps per Second: 10,479.44037

Timestep Collection Time: 2.26092
Timestep Consumption Time: 2.51128
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.77220

Cumulative Model Updates: 140,780
Cumulative Timesteps: 1,174,218,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.54627
Policy Entropy: 3.10014
Value Function Loss: 0.00406

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.54492

Collected Steps per Second: 22,979.04828
Overall Steps per Second: 10,450.70269

Timestep Collection Time: 2.17720
Timestep Consumption Time: 2.61004
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 4.78724

Cumulative Model Updates: 140,786
Cumulative Timesteps: 1,174,268,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1174268272...
Checkpoint 1174268272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,198.82830
Policy Entropy: 3.09735
Value Function Loss: 0.00441

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10410
Policy Update Magnitude: 0.59209
Value Function Update Magnitude: 0.55799

Collected Steps per Second: 22,723.01283
Overall Steps per Second: 10,768.24844

Timestep Collection Time: 2.20129
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.64514

Cumulative Model Updates: 140,792
Cumulative Timesteps: 1,174,318,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.73702
Policy Entropy: 3.09090
Value Function Loss: 0.00446

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.60652
Value Function Update Magnitude: 0.59022

Collected Steps per Second: 22,215.97115
Overall Steps per Second: 10,517.17462

Timestep Collection Time: 2.25099
Timestep Consumption Time: 2.50390
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.75489

Cumulative Model Updates: 140,798
Cumulative Timesteps: 1,174,368,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1174368300...
Checkpoint 1174368300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.70718
Policy Entropy: 3.09402
Value Function Loss: 0.00461

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.61589
Value Function Update Magnitude: 0.59894

Collected Steps per Second: 22,821.21666
Overall Steps per Second: 10,597.19817

Timestep Collection Time: 2.19103
Timestep Consumption Time: 2.52739
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.71842

Cumulative Model Updates: 140,804
Cumulative Timesteps: 1,174,418,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.86873
Policy Entropy: 3.07899
Value Function Loss: 0.00477

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.61287
Value Function Update Magnitude: 0.58388

Collected Steps per Second: 23,170.66631
Overall Steps per Second: 10,882.74851

Timestep Collection Time: 2.15937
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.59755

Cumulative Model Updates: 140,810
Cumulative Timesteps: 1,174,468,336

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1174468336...
Checkpoint 1174468336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.57344
Policy Entropy: 3.06725
Value Function Loss: 0.00471

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.61862
Value Function Update Magnitude: 0.57176

Collected Steps per Second: 22,497.05022
Overall Steps per Second: 10,645.40526

Timestep Collection Time: 2.22305
Timestep Consumption Time: 2.47494
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69799

Cumulative Model Updates: 140,816
Cumulative Timesteps: 1,174,518,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.16777
Policy Entropy: 3.06774
Value Function Loss: 0.00443

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.61075
Value Function Update Magnitude: 0.55597

Collected Steps per Second: 22,960.13149
Overall Steps per Second: 10,823.67692

Timestep Collection Time: 2.17795
Timestep Consumption Time: 2.44211
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.62006

Cumulative Model Updates: 140,822
Cumulative Timesteps: 1,174,568,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1174568354...
Checkpoint 1174568354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.80237
Policy Entropy: 3.07484
Value Function Loss: 0.00457

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.60224
Value Function Update Magnitude: 0.53916

Collected Steps per Second: 21,873.78582
Overall Steps per Second: 10,477.91095

Timestep Collection Time: 2.28703
Timestep Consumption Time: 2.48740
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.77442

Cumulative Model Updates: 140,828
Cumulative Timesteps: 1,174,618,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.85568
Policy Entropy: 3.07927
Value Function Loss: 0.00480

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.60974
Value Function Update Magnitude: 0.53006

Collected Steps per Second: 22,439.86760
Overall Steps per Second: 10,718.10695

Timestep Collection Time: 2.22969
Timestep Consumption Time: 2.43848
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.66818

Cumulative Model Updates: 140,834
Cumulative Timesteps: 1,174,668,414

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1174668414...
Checkpoint 1174668414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.56752
Policy Entropy: 3.07508
Value Function Loss: 0.00490

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.61209
Value Function Update Magnitude: 0.56874

Collected Steps per Second: 21,982.76836
Overall Steps per Second: 10,637.96257

Timestep Collection Time: 2.27542
Timestep Consumption Time: 2.42661
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.70203

Cumulative Model Updates: 140,840
Cumulative Timesteps: 1,174,718,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.72049
Policy Entropy: 3.08146
Value Function Loss: 0.00458

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.60472
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 22,238.52589
Overall Steps per Second: 10,489.58141

Timestep Collection Time: 2.24871
Timestep Consumption Time: 2.51869
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.76740

Cumulative Model Updates: 140,846
Cumulative Timesteps: 1,174,768,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1174768442...
Checkpoint 1174768442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.93667
Policy Entropy: 3.09248
Value Function Loss: 0.00438

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.59638
Value Function Update Magnitude: 0.55446

Collected Steps per Second: 22,110.22397
Overall Steps per Second: 10,639.80429

Timestep Collection Time: 2.26194
Timestep Consumption Time: 2.43852
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.70046

Cumulative Model Updates: 140,852
Cumulative Timesteps: 1,174,818,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869.79835
Policy Entropy: 3.09793
Value Function Loss: 0.00440

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.58506
Value Function Update Magnitude: 0.50426

Collected Steps per Second: 23,088.26311
Overall Steps per Second: 10,620.02354

Timestep Collection Time: 2.16673
Timestep Consumption Time: 2.54381
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.71054

Cumulative Model Updates: 140,858
Cumulative Timesteps: 1,174,868,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1174868480...
Checkpoint 1174868480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,217.83173
Policy Entropy: 3.09516
Value Function Loss: 0.00422

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.57587
Value Function Update Magnitude: 0.49756

Collected Steps per Second: 21,258.35246
Overall Steps per Second: 10,365.35105

Timestep Collection Time: 2.35202
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.82376

Cumulative Model Updates: 140,864
Cumulative Timesteps: 1,174,918,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,980.70161
Policy Entropy: 3.09192
Value Function Loss: 0.00410

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.57697
Value Function Update Magnitude: 0.51258

Collected Steps per Second: 22,898.06556
Overall Steps per Second: 10,434.26499

Timestep Collection Time: 2.18385
Timestep Consumption Time: 2.60863
PPO Batch Consumption Time: 0.30723
Total Iteration Time: 4.79248

Cumulative Model Updates: 140,870
Cumulative Timesteps: 1,174,968,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1174968486...
Checkpoint 1174968486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.43269
Policy Entropy: 3.09171
Value Function Loss: 0.00410

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.58324
Value Function Update Magnitude: 0.51774

Collected Steps per Second: 22,429.05600
Overall Steps per Second: 10,696.50095

Timestep Collection Time: 2.22925
Timestep Consumption Time: 2.44517
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.67443

Cumulative Model Updates: 140,876
Cumulative Timesteps: 1,175,018,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.93799
Policy Entropy: 3.08590
Value Function Loss: 0.00419

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.50454

Collected Steps per Second: 22,850.26257
Overall Steps per Second: 10,548.06940

Timestep Collection Time: 2.18895
Timestep Consumption Time: 2.55296
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.74191

Cumulative Model Updates: 140,882
Cumulative Timesteps: 1,175,068,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1175068504...
Checkpoint 1175068504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,558.68209
Policy Entropy: 3.09511
Value Function Loss: 0.00441

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.58667
Value Function Update Magnitude: 0.50623

Collected Steps per Second: 22,606.37066
Overall Steps per Second: 10,597.18735

Timestep Collection Time: 2.21300
Timestep Consumption Time: 2.50787
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.72088

Cumulative Model Updates: 140,888
Cumulative Timesteps: 1,175,118,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,681.44979
Policy Entropy: 3.08360
Value Function Loss: 0.00443

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.59896
Value Function Update Magnitude: 0.52707

Collected Steps per Second: 22,864.32497
Overall Steps per Second: 10,710.64298

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.48204
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.66937

Cumulative Model Updates: 140,894
Cumulative Timesteps: 1,175,168,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1175168544...
Checkpoint 1175168544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 873.98643
Policy Entropy: 3.08881
Value Function Loss: 0.00398

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.59179
Value Function Update Magnitude: 0.51537

Collected Steps per Second: 22,176.80480
Overall Steps per Second: 10,519.70507

Timestep Collection Time: 2.25479
Timestep Consumption Time: 2.49858
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.75337

Cumulative Model Updates: 140,900
Cumulative Timesteps: 1,175,218,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,234.99338
Policy Entropy: 3.07940
Value Function Loss: 0.00413

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.58491
Value Function Update Magnitude: 0.50039

Collected Steps per Second: 22,603.21837
Overall Steps per Second: 10,750.56730

Timestep Collection Time: 2.21243
Timestep Consumption Time: 2.43923
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.65166

Cumulative Model Updates: 140,906
Cumulative Timesteps: 1,175,268,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1175268556...
Checkpoint 1175268556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.68790
Policy Entropy: 3.08105
Value Function Loss: 0.00420

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.58971
Value Function Update Magnitude: 0.50769

Collected Steps per Second: 22,151.12237
Overall Steps per Second: 10,668.03139

Timestep Collection Time: 2.25776
Timestep Consumption Time: 2.43026
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.68803

Cumulative Model Updates: 140,912
Cumulative Timesteps: 1,175,318,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.29720
Policy Entropy: 3.07338
Value Function Loss: 0.00467

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.59982
Value Function Update Magnitude: 0.53617

Collected Steps per Second: 22,365.30965
Overall Steps per Second: 10,493.32426

Timestep Collection Time: 2.23677
Timestep Consumption Time: 2.53064
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.76741

Cumulative Model Updates: 140,918
Cumulative Timesteps: 1,175,368,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1175368594...
Checkpoint 1175368594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.19208
Policy Entropy: 3.09284
Value Function Loss: 0.00485

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.59826
Value Function Update Magnitude: 0.55115

Collected Steps per Second: 22,652.70227
Overall Steps per Second: 10,663.34827

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.48251
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.69046

Cumulative Model Updates: 140,924
Cumulative Timesteps: 1,175,418,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.71507
Policy Entropy: 3.10944
Value Function Loss: 0.00465

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.59647
Value Function Update Magnitude: 0.54448

Collected Steps per Second: 22,751.60326
Overall Steps per Second: 10,782.91889

Timestep Collection Time: 2.19879
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.63937

Cumulative Model Updates: 140,930
Cumulative Timesteps: 1,175,468,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1175468636...
Checkpoint 1175468636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.98084
Policy Entropy: 3.11217
Value Function Loss: 0.00450

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.59173
Value Function Update Magnitude: 0.51580

Collected Steps per Second: 22,659.19172
Overall Steps per Second: 10,759.15536

Timestep Collection Time: 2.20696
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.64795

Cumulative Model Updates: 140,936
Cumulative Timesteps: 1,175,518,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.21571
Policy Entropy: 3.09932
Value Function Loss: 0.00473

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.60366
Value Function Update Magnitude: 0.51797

Collected Steps per Second: 22,766.02521
Overall Steps per Second: 10,825.99209

Timestep Collection Time: 2.19828
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.62276

Cumulative Model Updates: 140,942
Cumulative Timesteps: 1,175,568,690

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1175568690...
Checkpoint 1175568690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.75477
Policy Entropy: 3.09334
Value Function Loss: 0.00481

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.60488
Value Function Update Magnitude: 0.53094

Collected Steps per Second: 22,578.12810
Overall Steps per Second: 10,449.75566

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.57119
PPO Batch Consumption Time: 0.30567
Total Iteration Time: 4.78652

Cumulative Model Updates: 140,948
Cumulative Timesteps: 1,175,618,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,502.67696
Policy Entropy: 3.08892
Value Function Loss: 0.00472

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.59239
Value Function Update Magnitude: 0.53110

Collected Steps per Second: 22,960.52490
Overall Steps per Second: 10,524.69538

Timestep Collection Time: 2.17817
Timestep Consumption Time: 2.57370
PPO Batch Consumption Time: 0.30606
Total Iteration Time: 4.75187

Cumulative Model Updates: 140,954
Cumulative Timesteps: 1,175,668,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1175668720...
Checkpoint 1175668720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.93219
Policy Entropy: 3.07782
Value Function Loss: 0.00474

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.59156
Value Function Update Magnitude: 0.50622

Collected Steps per Second: 22,679.96561
Overall Steps per Second: 10,722.85487

Timestep Collection Time: 2.20556
Timestep Consumption Time: 2.45943
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.66499

Cumulative Model Updates: 140,960
Cumulative Timesteps: 1,175,718,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.65168
Policy Entropy: 3.05915
Value Function Loss: 0.00480

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.60179
Value Function Update Magnitude: 0.50328

Collected Steps per Second: 22,261.07126
Overall Steps per Second: 10,544.76263

Timestep Collection Time: 2.24670
Timestep Consumption Time: 2.49632
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.74302

Cumulative Model Updates: 140,966
Cumulative Timesteps: 1,175,768,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1175768756...
Checkpoint 1175768756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.47411
Policy Entropy: 3.05979
Value Function Loss: 0.00443

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.60108
Value Function Update Magnitude: 0.52130

Collected Steps per Second: 22,456.22417
Overall Steps per Second: 10,574.57339

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.72927

Cumulative Model Updates: 140,972
Cumulative Timesteps: 1,175,818,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.38894
Policy Entropy: 3.06934
Value Function Loss: 0.00430

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.59586
Value Function Update Magnitude: 0.54891

Collected Steps per Second: 21,933.59145
Overall Steps per Second: 10,411.92528

Timestep Collection Time: 2.27979
Timestep Consumption Time: 2.52278
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.80257

Cumulative Model Updates: 140,978
Cumulative Timesteps: 1,175,868,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1175868770...
Checkpoint 1175868770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,045.41957
Policy Entropy: 3.07877
Value Function Loss: 0.00415

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.59373
Value Function Update Magnitude: 0.53400

Collected Steps per Second: 22,330.50015
Overall Steps per Second: 10,637.08938

Timestep Collection Time: 2.23963
Timestep Consumption Time: 2.46203
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.70166

Cumulative Model Updates: 140,984
Cumulative Timesteps: 1,175,918,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.53474
Policy Entropy: 3.07675
Value Function Loss: 0.00431

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.59090
Value Function Update Magnitude: 0.51334

Collected Steps per Second: 22,221.44811
Overall Steps per Second: 10,470.97377

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.52563
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.77625

Cumulative Model Updates: 140,990
Cumulative Timesteps: 1,175,968,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1175968794...
Checkpoint 1175968794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.28944
Policy Entropy: 3.08264
Value Function Loss: 0.00451

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.59653
Value Function Update Magnitude: 0.51519

Collected Steps per Second: 22,555.56307
Overall Steps per Second: 10,637.64787

Timestep Collection Time: 2.21684
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.70048

Cumulative Model Updates: 140,996
Cumulative Timesteps: 1,176,018,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.60182
Policy Entropy: 3.06807
Value Function Loss: 0.00432

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.59019
Value Function Update Magnitude: 0.53430

Collected Steps per Second: 22,672.45348
Overall Steps per Second: 10,501.78554

Timestep Collection Time: 2.20647
Timestep Consumption Time: 2.55710
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.76357

Cumulative Model Updates: 141,002
Cumulative Timesteps: 1,176,068,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1176068822...
Checkpoint 1176068822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.98544
Policy Entropy: 3.07393
Value Function Loss: 0.00445

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.58993
Value Function Update Magnitude: 0.52584

Collected Steps per Second: 22,547.70487
Overall Steps per Second: 10,578.08234

Timestep Collection Time: 2.21770
Timestep Consumption Time: 2.50943
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.72713

Cumulative Model Updates: 141,008
Cumulative Timesteps: 1,176,118,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,068.31162
Policy Entropy: 3.06780
Value Function Loss: 0.00467

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.59647
Value Function Update Magnitude: 0.50050

Collected Steps per Second: 22,838.32587
Overall Steps per Second: 10,610.84353

Timestep Collection Time: 2.18939
Timestep Consumption Time: 2.52296
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.71235

Cumulative Model Updates: 141,014
Cumulative Timesteps: 1,176,168,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1176168828...
Checkpoint 1176168828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.82678
Policy Entropy: 3.09128
Value Function Loss: 0.00420

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.58489
Value Function Update Magnitude: 0.47644

Collected Steps per Second: 22,878.85712
Overall Steps per Second: 10,636.60821

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.51562
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.70131

Cumulative Model Updates: 141,020
Cumulative Timesteps: 1,176,218,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.41309
Policy Entropy: 3.09511
Value Function Loss: 0.00418

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.56717
Value Function Update Magnitude: 0.45886

Collected Steps per Second: 22,838.70497
Overall Steps per Second: 10,730.77187

Timestep Collection Time: 2.18953
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.66006

Cumulative Model Updates: 141,026
Cumulative Timesteps: 1,176,268,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1176268840...
Checkpoint 1176268840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.02191
Policy Entropy: 3.09144
Value Function Loss: 0.00431

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.57090
Value Function Update Magnitude: 0.48209

Collected Steps per Second: 22,805.79090
Overall Steps per Second: 10,480.35535

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.57871
PPO Batch Consumption Time: 0.30747
Total Iteration Time: 4.77140

Cumulative Model Updates: 141,032
Cumulative Timesteps: 1,176,318,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.49706
Policy Entropy: 3.08302
Value Function Loss: 0.00442

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.58065
Value Function Update Magnitude: 0.54026

Collected Steps per Second: 22,614.92931
Overall Steps per Second: 10,648.26582

Timestep Collection Time: 2.21172
Timestep Consumption Time: 2.48557
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.69729

Cumulative Model Updates: 141,038
Cumulative Timesteps: 1,176,368,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1176368864...
Checkpoint 1176368864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.10769
Policy Entropy: 3.08136
Value Function Loss: 0.00437

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.58331
Value Function Update Magnitude: 0.55804

Collected Steps per Second: 21,940.83853
Overall Steps per Second: 10,606.75171

Timestep Collection Time: 2.27940
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.71511

Cumulative Model Updates: 141,044
Cumulative Timesteps: 1,176,418,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,947.53904
Policy Entropy: 3.09630
Value Function Loss: 0.00412

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.53703

Collected Steps per Second: 22,236.49619
Overall Steps per Second: 10,456.86374

Timestep Collection Time: 2.24901
Timestep Consumption Time: 2.53350
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.78250

Cumulative Model Updates: 141,050
Cumulative Timesteps: 1,176,468,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1176468886...
Checkpoint 1176468886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.05779
Policy Entropy: 3.10473
Value Function Loss: 0.00455

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.59298
Value Function Update Magnitude: 0.54464

Collected Steps per Second: 22,493.93408
Overall Steps per Second: 10,743.29867

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.43134
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.65425

Cumulative Model Updates: 141,056
Cumulative Timesteps: 1,176,518,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.20585
Policy Entropy: 3.10796
Value Function Loss: 0.00475

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.60327
Value Function Update Magnitude: 0.54976

Collected Steps per Second: 22,989.47281
Overall Steps per Second: 10,600.51952

Timestep Collection Time: 2.17508
Timestep Consumption Time: 2.54204
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.71713

Cumulative Model Updates: 141,062
Cumulative Timesteps: 1,176,568,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1176568892...
Checkpoint 1176568892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.36761
Policy Entropy: 3.10457
Value Function Loss: 0.00464

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.60152
Value Function Update Magnitude: 0.55976

Collected Steps per Second: 22,509.86376
Overall Steps per Second: 10,650.27292

Timestep Collection Time: 2.22258
Timestep Consumption Time: 2.47495
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.69753

Cumulative Model Updates: 141,068
Cumulative Timesteps: 1,176,618,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.88571
Policy Entropy: 3.11006
Value Function Loss: 0.00440

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.59365
Value Function Update Magnitude: 0.55019

Collected Steps per Second: 22,970.53592
Overall Steps per Second: 10,696.78379

Timestep Collection Time: 2.17670
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.67430

Cumulative Model Updates: 141,074
Cumulative Timesteps: 1,176,668,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1176668922...
Checkpoint 1176668922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.71462
Policy Entropy: 3.10872
Value Function Loss: 0.00447

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.58775
Value Function Update Magnitude: 0.55321

Collected Steps per Second: 22,332.84180
Overall Steps per Second: 10,627.80470

Timestep Collection Time: 2.24109
Timestep Consumption Time: 2.46825
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.70935

Cumulative Model Updates: 141,080
Cumulative Timesteps: 1,176,718,972

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.96399
Policy Entropy: 3.10746
Value Function Loss: 0.00457

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.58997
Value Function Update Magnitude: 0.57273

Collected Steps per Second: 22,701.47560
Overall Steps per Second: 10,679.22968

Timestep Collection Time: 2.20268
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68236

Cumulative Model Updates: 141,086
Cumulative Timesteps: 1,176,768,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1176768976...
Checkpoint 1176768976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.27375
Policy Entropy: 3.10250
Value Function Loss: 0.00466

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10538
Policy Update Magnitude: 0.59346
Value Function Update Magnitude: 0.55854

Collected Steps per Second: 21,584.19781
Overall Steps per Second: 10,508.88375

Timestep Collection Time: 2.31799
Timestep Consumption Time: 2.44293
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.76092

Cumulative Model Updates: 141,092
Cumulative Timesteps: 1,176,819,008

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.24795
Policy Entropy: 3.10537
Value Function Loss: 0.00453

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.58872
Value Function Update Magnitude: 0.54995

Collected Steps per Second: 22,052.32808
Overall Steps per Second: 10,472.23383

Timestep Collection Time: 2.26743
Timestep Consumption Time: 2.50730
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.77472

Cumulative Model Updates: 141,098
Cumulative Timesteps: 1,176,869,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1176869010...
Checkpoint 1176869010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.71239
Policy Entropy: 3.10908
Value Function Loss: 0.00471

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.58197
Value Function Update Magnitude: 0.53876

Collected Steps per Second: 22,419.38194
Overall Steps per Second: 10,577.40657

Timestep Collection Time: 2.23093
Timestep Consumption Time: 2.49764
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.72857

Cumulative Model Updates: 141,104
Cumulative Timesteps: 1,176,919,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.90507
Policy Entropy: 3.11529
Value Function Loss: 0.00484

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.57664
Value Function Update Magnitude: 0.54629

Collected Steps per Second: 22,146.40194
Overall Steps per Second: 10,494.50344

Timestep Collection Time: 2.25897
Timestep Consumption Time: 2.50810
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.76707

Cumulative Model Updates: 141,110
Cumulative Timesteps: 1,176,969,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1176969054...
Checkpoint 1176969054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.07498
Policy Entropy: 3.11197
Value Function Loss: 0.00490

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11051
Policy Update Magnitude: 0.57377
Value Function Update Magnitude: 0.54146

Collected Steps per Second: 22,058.40741
Overall Steps per Second: 10,630.19308

Timestep Collection Time: 2.26707
Timestep Consumption Time: 2.43726
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.70434

Cumulative Model Updates: 141,116
Cumulative Timesteps: 1,177,019,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.13094
Policy Entropy: 3.10454
Value Function Loss: 0.00480

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.59121
Value Function Update Magnitude: 0.54846

Collected Steps per Second: 22,424.51225
Overall Steps per Second: 10,549.99242

Timestep Collection Time: 2.22970
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.73934

Cumulative Model Updates: 141,122
Cumulative Timesteps: 1,177,069,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1177069062...
Checkpoint 1177069062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,868.30654
Policy Entropy: 3.10209
Value Function Loss: 0.00461

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.60279
Value Function Update Magnitude: 0.59333

Collected Steps per Second: 22,365.49770
Overall Steps per Second: 10,555.81033

Timestep Collection Time: 2.23639
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.73843

Cumulative Model Updates: 141,128
Cumulative Timesteps: 1,177,119,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,877.37864
Policy Entropy: 3.10046
Value Function Loss: 0.00435

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11590
Policy Update Magnitude: 0.60552
Value Function Update Magnitude: 0.61550

Collected Steps per Second: 22,750.81990
Overall Steps per Second: 10,570.69742

Timestep Collection Time: 2.19878
Timestep Consumption Time: 2.53355
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.73233

Cumulative Model Updates: 141,134
Cumulative Timesteps: 1,177,169,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1177169104...
Checkpoint 1177169104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.80637
Policy Entropy: 3.09743
Value Function Loss: 0.00417

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.59600
Value Function Update Magnitude: 0.59434

Collected Steps per Second: 22,851.60592
Overall Steps per Second: 10,587.27632

Timestep Collection Time: 2.18873
Timestep Consumption Time: 2.53543
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.72416

Cumulative Model Updates: 141,140
Cumulative Timesteps: 1,177,219,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.82181
Policy Entropy: 3.09473
Value Function Loss: 0.00429

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.59545
Value Function Update Magnitude: 0.55906

Collected Steps per Second: 22,734.17544
Overall Steps per Second: 10,593.04582

Timestep Collection Time: 2.20039
Timestep Consumption Time: 2.52196
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.72234

Cumulative Model Updates: 141,146
Cumulative Timesteps: 1,177,269,144

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1177269144...
Checkpoint 1177269144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.80436
Policy Entropy: 3.09275
Value Function Loss: 0.00471

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.60685
Value Function Update Magnitude: 0.57581

Collected Steps per Second: 22,652.10518
Overall Steps per Second: 10,585.02361

Timestep Collection Time: 2.20801
Timestep Consumption Time: 2.51716
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.72517

Cumulative Model Updates: 141,152
Cumulative Timesteps: 1,177,319,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.90877
Policy Entropy: 3.09674
Value Function Loss: 0.00473

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.61543
Value Function Update Magnitude: 0.59187

Collected Steps per Second: 22,905.64434
Overall Steps per Second: 10,645.91529

Timestep Collection Time: 2.18296
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.69682

Cumulative Model Updates: 141,158
Cumulative Timesteps: 1,177,369,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1177369162...
Checkpoint 1177369162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.53880
Policy Entropy: 3.11349
Value Function Loss: 0.00484

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.60679
Value Function Update Magnitude: 0.57547

Collected Steps per Second: 22,394.00892
Overall Steps per Second: 10,744.53325

Timestep Collection Time: 2.23345
Timestep Consumption Time: 2.42156
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.65502

Cumulative Model Updates: 141,164
Cumulative Timesteps: 1,177,419,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.82629
Policy Entropy: 3.11040
Value Function Loss: 0.00423

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.58188
Value Function Update Magnitude: 0.56490

Collected Steps per Second: 22,737.57761
Overall Steps per Second: 10,644.47381

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.69840

Cumulative Model Updates: 141,170
Cumulative Timesteps: 1,177,469,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1177469190...
Checkpoint 1177469190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903.29014
Policy Entropy: 3.11886
Value Function Loss: 0.00374

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.54850

Collected Steps per Second: 22,418.12497
Overall Steps per Second: 10,536.17277

Timestep Collection Time: 2.23114
Timestep Consumption Time: 2.51612
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.74726

Cumulative Model Updates: 141,176
Cumulative Timesteps: 1,177,519,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,308.27937
Policy Entropy: 3.10465
Value Function Loss: 0.00375

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.55621
Value Function Update Magnitude: 0.51902

Collected Steps per Second: 22,525.83443
Overall Steps per Second: 10,504.24626

Timestep Collection Time: 2.21967
Timestep Consumption Time: 2.54031
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.75998

Cumulative Model Updates: 141,182
Cumulative Timesteps: 1,177,569,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1177569208...
Checkpoint 1177569208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891.77879
Policy Entropy: 3.10948
Value Function Loss: 0.00426

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.57181
Value Function Update Magnitude: 0.52446

Collected Steps per Second: 21,941.49219
Overall Steps per Second: 10,630.04118

Timestep Collection Time: 2.27970
Timestep Consumption Time: 2.42583
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.70553

Cumulative Model Updates: 141,188
Cumulative Timesteps: 1,177,619,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.15374
Policy Entropy: 3.11129
Value Function Loss: 0.00441

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.57229
Value Function Update Magnitude: 0.55044

Collected Steps per Second: 21,872.53403
Overall Steps per Second: 10,429.10645

Timestep Collection Time: 2.28625
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.79485

Cumulative Model Updates: 141,194
Cumulative Timesteps: 1,177,669,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1177669234...
Checkpoint 1177669234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847.42384
Policy Entropy: 3.11626
Value Function Loss: 0.00441

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.57900
Value Function Update Magnitude: 0.55266

Collected Steps per Second: 22,383.55249
Overall Steps per Second: 10,614.18343

Timestep Collection Time: 2.23423
Timestep Consumption Time: 2.47739
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.71162

Cumulative Model Updates: 141,200
Cumulative Timesteps: 1,177,719,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,370.48873
Policy Entropy: 3.11516
Value Function Loss: 0.00437

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.57241
Value Function Update Magnitude: 0.54806

Collected Steps per Second: 22,803.76446
Overall Steps per Second: 10,495.65900

Timestep Collection Time: 2.19376
Timestep Consumption Time: 2.57259
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.76635

Cumulative Model Updates: 141,206
Cumulative Timesteps: 1,177,769,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1177769270...
Checkpoint 1177769270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.72816
Policy Entropy: 3.10617
Value Function Loss: 0.00446

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.57223
Value Function Update Magnitude: 0.54913

Collected Steps per Second: 22,692.61328
Overall Steps per Second: 10,582.80166

Timestep Collection Time: 2.20398
Timestep Consumption Time: 2.52199
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.72597

Cumulative Model Updates: 141,212
Cumulative Timesteps: 1,177,819,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.74523
Policy Entropy: 3.09334
Value Function Loss: 0.00446

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.57003

Collected Steps per Second: 22,854.65403
Overall Steps per Second: 10,812.79334

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.43729
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.62582

Cumulative Model Updates: 141,218
Cumulative Timesteps: 1,177,869,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1177869302...
Checkpoint 1177869302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.10665
Policy Entropy: 3.09174
Value Function Loss: 0.00451

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.58864
Value Function Update Magnitude: 0.56424

Collected Steps per Second: 22,677.09412
Overall Steps per Second: 10,725.90766

Timestep Collection Time: 2.20549
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.66292

Cumulative Model Updates: 141,224
Cumulative Timesteps: 1,177,919,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.48524
Policy Entropy: 3.10504
Value Function Loss: 0.00424

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.58176
Value Function Update Magnitude: 0.55276

Collected Steps per Second: 23,012.12257
Overall Steps per Second: 10,839.22875

Timestep Collection Time: 2.17320
Timestep Consumption Time: 2.44059
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.61380

Cumulative Model Updates: 141,230
Cumulative Timesteps: 1,177,969,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1177969326...
Checkpoint 1177969326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.96332
Policy Entropy: 3.12688
Value Function Loss: 0.00439

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.58034
Value Function Update Magnitude: 0.54947

Collected Steps per Second: 22,488.07816
Overall Steps per Second: 10,771.38340

Timestep Collection Time: 2.22411
Timestep Consumption Time: 2.41930
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.64341

Cumulative Model Updates: 141,236
Cumulative Timesteps: 1,178,019,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.81357
Policy Entropy: 3.13283
Value Function Loss: 0.00414

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.57631
Value Function Update Magnitude: 0.56368

Collected Steps per Second: 22,059.06647
Overall Steps per Second: 10,465.10404

Timestep Collection Time: 2.26691
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.77836

Cumulative Model Updates: 141,242
Cumulative Timesteps: 1,178,069,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1178069348...
Checkpoint 1178069348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.45863
Policy Entropy: 3.12395
Value Function Loss: 0.00440

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.58788
Value Function Update Magnitude: 0.57590

Collected Steps per Second: 22,453.61428
Overall Steps per Second: 10,590.66023

Timestep Collection Time: 2.22744
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.72246

Cumulative Model Updates: 141,248
Cumulative Timesteps: 1,178,119,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974.37672
Policy Entropy: 3.11358
Value Function Loss: 0.00465

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.60062
Value Function Update Magnitude: 0.58768

Collected Steps per Second: 22,440.22028
Overall Steps per Second: 10,636.18209

Timestep Collection Time: 2.22877
Timestep Consumption Time: 2.47349
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.70225

Cumulative Model Updates: 141,254
Cumulative Timesteps: 1,178,169,376

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1178169376...
Checkpoint 1178169376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,175.49811
Policy Entropy: 3.11739
Value Function Loss: 0.00447

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.60058
Value Function Update Magnitude: 0.60297

Collected Steps per Second: 22,408.27296
Overall Steps per Second: 10,531.12410

Timestep Collection Time: 2.23239
Timestep Consumption Time: 2.51772
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.75011

Cumulative Model Updates: 141,260
Cumulative Timesteps: 1,178,219,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,668.74894
Policy Entropy: 3.12551
Value Function Loss: 0.00465

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11276
Policy Update Magnitude: 0.59496
Value Function Update Magnitude: 0.59556

Collected Steps per Second: 22,453.44849
Overall Steps per Second: 10,394.48321

Timestep Collection Time: 2.22727
Timestep Consumption Time: 2.58393
PPO Batch Consumption Time: 0.30104
Total Iteration Time: 4.81121

Cumulative Model Updates: 141,266
Cumulative Timesteps: 1,178,269,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1178269410...
Checkpoint 1178269410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.74000
Policy Entropy: 3.13464
Value Function Loss: 0.00482

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.61922
Value Function Update Magnitude: 0.63949

Collected Steps per Second: 21,866.78255
Overall Steps per Second: 10,535.05472

Timestep Collection Time: 2.28694
Timestep Consumption Time: 2.45988
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.74682

Cumulative Model Updates: 141,272
Cumulative Timesteps: 1,178,319,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.21234
Policy Entropy: 3.11707
Value Function Loss: 0.00516

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.63347
Value Function Update Magnitude: 0.70113

Collected Steps per Second: 22,871.69325
Overall Steps per Second: 10,606.10754

Timestep Collection Time: 2.18716
Timestep Consumption Time: 2.52937
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.71653

Cumulative Model Updates: 141,278
Cumulative Timesteps: 1,178,369,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1178369442...
Checkpoint 1178369442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.07867
Policy Entropy: 3.11417
Value Function Loss: 0.00506

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.63615
Value Function Update Magnitude: 0.70981

Collected Steps per Second: 22,407.42563
Overall Steps per Second: 10,543.95723

Timestep Collection Time: 2.23149
Timestep Consumption Time: 2.51075
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.74224

Cumulative Model Updates: 141,284
Cumulative Timesteps: 1,178,419,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.81934
Policy Entropy: 3.12249
Value Function Loss: 0.00449

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.61457
Value Function Update Magnitude: 0.64407

Collected Steps per Second: 22,778.20081
Overall Steps per Second: 10,682.31886

Timestep Collection Time: 2.19552
Timestep Consumption Time: 2.48605
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.68157

Cumulative Model Updates: 141,290
Cumulative Timesteps: 1,178,469,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1178469454...
Checkpoint 1178469454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,711.14793
Policy Entropy: 3.13069
Value Function Loss: 0.00437

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.58689
Value Function Update Magnitude: 0.57207

Collected Steps per Second: 22,696.34400
Overall Steps per Second: 10,588.37201

Timestep Collection Time: 2.20397
Timestep Consumption Time: 2.52027
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.72424

Cumulative Model Updates: 141,296
Cumulative Timesteps: 1,178,519,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.64701
Policy Entropy: 3.13334
Value Function Loss: 0.00424

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.57105

Collected Steps per Second: 23,130.68127
Overall Steps per Second: 10,796.89577

Timestep Collection Time: 2.16163
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.63096

Cumulative Model Updates: 141,302
Cumulative Timesteps: 1,178,569,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1178569476...
Checkpoint 1178569476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.77997
Policy Entropy: 3.12980
Value Function Loss: 0.00428

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.58091
Value Function Update Magnitude: 0.56276

Collected Steps per Second: 22,674.98010
Overall Steps per Second: 10,625.73870

Timestep Collection Time: 2.20507
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.70556

Cumulative Model Updates: 141,308
Cumulative Timesteps: 1,178,619,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,713.80275
Policy Entropy: 3.15366
Value Function Loss: 0.00419

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.57995
Value Function Update Magnitude: 0.55550

Collected Steps per Second: 22,872.92956
Overall Steps per Second: 10,639.68518

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.51490
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.70221

Cumulative Model Updates: 141,314
Cumulative Timesteps: 1,178,669,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1178669506...
Checkpoint 1178669506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.79743
Policy Entropy: 3.13650
Value Function Loss: 0.00423

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.57634
Value Function Update Magnitude: 0.56579

Collected Steps per Second: 20,927.23181
Overall Steps per Second: 10,176.52761

Timestep Collection Time: 2.38933
Timestep Consumption Time: 2.52414
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.91346

Cumulative Model Updates: 141,320
Cumulative Timesteps: 1,178,719,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.35985
Policy Entropy: 3.12603
Value Function Loss: 0.00427

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.58144
Value Function Update Magnitude: 0.55088

Collected Steps per Second: 22,550.47769
Overall Steps per Second: 10,690.42457

Timestep Collection Time: 2.21840
Timestep Consumption Time: 2.46111
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.67951

Cumulative Model Updates: 141,326
Cumulative Timesteps: 1,178,769,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1178769534...
Checkpoint 1178769534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,901.09761
Policy Entropy: 3.10279
Value Function Loss: 0.00434

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.58601
Value Function Update Magnitude: 0.52318

Collected Steps per Second: 22,123.21580
Overall Steps per Second: 10,622.63983

Timestep Collection Time: 2.26133
Timestep Consumption Time: 2.44823
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.70956

Cumulative Model Updates: 141,332
Cumulative Timesteps: 1,178,819,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.42538
Policy Entropy: 3.10652
Value Function Loss: 0.00434

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.58054
Value Function Update Magnitude: 0.50856

Collected Steps per Second: 22,467.44994
Overall Steps per Second: 10,513.36929

Timestep Collection Time: 2.22544
Timestep Consumption Time: 2.53041
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.75585

Cumulative Model Updates: 141,338
Cumulative Timesteps: 1,178,869,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1178869562...
Checkpoint 1178869562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.78285
Policy Entropy: 3.11027
Value Function Loss: 0.00410

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.57673
Value Function Update Magnitude: 0.50267

Collected Steps per Second: 22,525.75143
Overall Steps per Second: 10,518.28211

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.53537
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.75629

Cumulative Model Updates: 141,344
Cumulative Timesteps: 1,178,919,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.58125
Policy Entropy: 3.11732
Value Function Loss: 0.00410

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.57591
Value Function Update Magnitude: 0.50825

Collected Steps per Second: 23,212.88336
Overall Steps per Second: 10,609.51098

Timestep Collection Time: 2.15518
Timestep Consumption Time: 2.56021
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.71539

Cumulative Model Updates: 141,350
Cumulative Timesteps: 1,178,969,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1178969618...
Checkpoint 1178969618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.92155
Policy Entropy: 3.11716
Value Function Loss: 0.00405

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.56565
Value Function Update Magnitude: 0.52829

Collected Steps per Second: 22,774.10062
Overall Steps per Second: 10,648.32570

Timestep Collection Time: 2.19556
Timestep Consumption Time: 2.50020
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.69576

Cumulative Model Updates: 141,356
Cumulative Timesteps: 1,179,019,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.64483
Policy Entropy: 3.10160
Value Function Loss: 0.00451

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.57888
Value Function Update Magnitude: 0.53136

Collected Steps per Second: 23,170.12192
Overall Steps per Second: 10,873.51782

Timestep Collection Time: 2.15830
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.59906

Cumulative Model Updates: 141,362
Cumulative Timesteps: 1,179,069,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1179069628...
Checkpoint 1179069628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.88115
Policy Entropy: 3.09183
Value Function Loss: 0.00501

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.59542
Value Function Update Magnitude: 0.58227

Collected Steps per Second: 22,745.95025
Overall Steps per Second: 10,647.89820

Timestep Collection Time: 2.19819
Timestep Consumption Time: 2.49757
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.69576

Cumulative Model Updates: 141,368
Cumulative Timesteps: 1,179,119,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.25652
Policy Entropy: 3.10165
Value Function Loss: 0.00475

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.59295
Value Function Update Magnitude: 0.62780

Collected Steps per Second: 23,270.26193
Overall Steps per Second: 10,930.76199

Timestep Collection Time: 2.14901
Timestep Consumption Time: 2.42597
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.57498

Cumulative Model Updates: 141,374
Cumulative Timesteps: 1,179,169,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1179169636...
Checkpoint 1179169636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,667.64773
Policy Entropy: 3.10417
Value Function Loss: 0.00459

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.58288
Value Function Update Magnitude: 0.58157

Collected Steps per Second: 22,550.81936
Overall Steps per Second: 10,641.47181

Timestep Collection Time: 2.21828
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.70085

Cumulative Model Updates: 141,380
Cumulative Timesteps: 1,179,219,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.12679
Policy Entropy: 3.12114
Value Function Loss: 0.00448

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.57849
Value Function Update Magnitude: 0.54553

Collected Steps per Second: 22,542.10773
Overall Steps per Second: 10,646.76512

Timestep Collection Time: 2.21922
Timestep Consumption Time: 2.47948
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.69870

Cumulative Model Updates: 141,386
Cumulative Timesteps: 1,179,269,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1179269686...
Checkpoint 1179269686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.87094
Policy Entropy: 3.11958
Value Function Loss: 0.00415

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.57975
Value Function Update Magnitude: 0.54168

Collected Steps per Second: 22,353.58576
Overall Steps per Second: 10,636.39525

Timestep Collection Time: 2.23803
Timestep Consumption Time: 2.46544
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.70347

Cumulative Model Updates: 141,392
Cumulative Timesteps: 1,179,319,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.01574
Policy Entropy: 3.12393
Value Function Loss: 0.00430

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.58365
Value Function Update Magnitude: 0.55693

Collected Steps per Second: 22,837.61107
Overall Steps per Second: 10,773.35293

Timestep Collection Time: 2.19025
Timestep Consumption Time: 2.45269
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.64294

Cumulative Model Updates: 141,398
Cumulative Timesteps: 1,179,369,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1179369734...
Checkpoint 1179369734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,226.62994
Policy Entropy: 3.12379
Value Function Loss: 0.00431

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.57686

Collected Steps per Second: 22,668.09035
Overall Steps per Second: 10,606.97990

Timestep Collection Time: 2.20601
Timestep Consumption Time: 2.50843
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.71444

Cumulative Model Updates: 141,404
Cumulative Timesteps: 1,179,419,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.63428
Policy Entropy: 3.12429
Value Function Loss: 0.00463

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.59227
Value Function Update Magnitude: 0.58961

Collected Steps per Second: 23,292.39059
Overall Steps per Second: 10,935.97081

Timestep Collection Time: 2.14662
Timestep Consumption Time: 2.42544
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.57207

Cumulative Model Updates: 141,410
Cumulative Timesteps: 1,179,469,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1179469740...
Checkpoint 1179469740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.33734
Policy Entropy: 3.13530
Value Function Loss: 0.00432

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.59989
Value Function Update Magnitude: 0.58011

Collected Steps per Second: 22,904.40892
Overall Steps per Second: 10,703.81946

Timestep Collection Time: 2.18377
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.67291

Cumulative Model Updates: 141,416
Cumulative Timesteps: 1,179,519,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,364.07438
Policy Entropy: 3.14119
Value Function Loss: 0.00429

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.58740
Value Function Update Magnitude: 0.56254

Collected Steps per Second: 23,330.91656
Overall Steps per Second: 10,781.18543

Timestep Collection Time: 2.14376
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.63919

Cumulative Model Updates: 141,422
Cumulative Timesteps: 1,179,569,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1179569774...
Checkpoint 1179569774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,225.00511
Policy Entropy: 3.13145
Value Function Loss: 0.00441

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.58334
Value Function Update Magnitude: 0.55457

Collected Steps per Second: 22,782.96386
Overall Steps per Second: 10,610.48658

Timestep Collection Time: 2.19506
Timestep Consumption Time: 2.51820
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.71326

Cumulative Model Updates: 141,428
Cumulative Timesteps: 1,179,619,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.90173
Policy Entropy: 3.11392
Value Function Loss: 0.00437

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.58086
Value Function Update Magnitude: 0.55082

Collected Steps per Second: 22,957.51455
Overall Steps per Second: 10,852.95455

Timestep Collection Time: 2.17837
Timestep Consumption Time: 2.42959
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.60796

Cumulative Model Updates: 141,434
Cumulative Timesteps: 1,179,669,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1179669794...
Checkpoint 1179669794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715.34070
Policy Entropy: 3.10940
Value Function Loss: 0.00477

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.57382
Value Function Update Magnitude: 0.54087

Collected Steps per Second: 22,706.39758
Overall Steps per Second: 10,767.28729

Timestep Collection Time: 2.20282
Timestep Consumption Time: 2.44255
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.64537

Cumulative Model Updates: 141,440
Cumulative Timesteps: 1,179,719,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.03504
Policy Entropy: 3.12104
Value Function Loss: 0.00428

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.56162
Value Function Update Magnitude: 0.51933

Collected Steps per Second: 22,677.02441
Overall Steps per Second: 10,803.76550

Timestep Collection Time: 2.20514
Timestep Consumption Time: 2.42343
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.62857

Cumulative Model Updates: 141,446
Cumulative Timesteps: 1,179,769,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1179769818...
Checkpoint 1179769818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.69841
Policy Entropy: 3.12050
Value Function Loss: 0.00441

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.55482
Value Function Update Magnitude: 0.50002

Collected Steps per Second: 22,238.94521
Overall Steps per Second: 10,706.55812

Timestep Collection Time: 2.24867
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.67078

Cumulative Model Updates: 141,452
Cumulative Timesteps: 1,179,819,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.26968
Policy Entropy: 3.13585
Value Function Loss: 0.00391

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.54757
Value Function Update Magnitude: 0.52100

Collected Steps per Second: 22,736.58509
Overall Steps per Second: 10,599.74279

Timestep Collection Time: 2.20015
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.71936

Cumulative Model Updates: 141,458
Cumulative Timesteps: 1,179,869,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1179869850...
Checkpoint 1179869850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.41305
Policy Entropy: 3.12216
Value Function Loss: 0.00431

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.55717
Value Function Update Magnitude: 0.53679

Collected Steps per Second: 22,476.79163
Overall Steps per Second: 10,596.00573

Timestep Collection Time: 2.22532
Timestep Consumption Time: 2.49514
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.72046

Cumulative Model Updates: 141,464
Cumulative Timesteps: 1,179,919,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.71414
Policy Entropy: 3.12060
Value Function Loss: 0.00434

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.57422
Value Function Update Magnitude: 0.56301

Collected Steps per Second: 23,270.18448
Overall Steps per Second: 10,765.11303

Timestep Collection Time: 2.14910
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.64556

Cumulative Model Updates: 141,470
Cumulative Timesteps: 1,179,969,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1179969878...
Checkpoint 1179969878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,971.69451
Policy Entropy: 3.12142
Value Function Loss: 0.00449

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.16352
Policy Update Magnitude: 0.58106
Value Function Update Magnitude: 0.58003

Collected Steps per Second: 22,482.75596
Overall Steps per Second: 10,694.12038

Timestep Collection Time: 2.22464
Timestep Consumption Time: 2.45232
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.67696

Cumulative Model Updates: 141,476
Cumulative Timesteps: 1,180,019,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.86338
Policy Entropy: 3.12774
Value Function Loss: 0.00447

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.58272
Value Function Update Magnitude: 0.59200

Collected Steps per Second: 23,211.49042
Overall Steps per Second: 10,909.28148

Timestep Collection Time: 2.15419
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.58344

Cumulative Model Updates: 141,482
Cumulative Timesteps: 1,180,069,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1180069896...
Checkpoint 1180069896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,048.18094
Policy Entropy: 3.13124
Value Function Loss: 0.00413

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.57763
Value Function Update Magnitude: 0.57242

Collected Steps per Second: 22,955.52341
Overall Steps per Second: 10,602.47546

Timestep Collection Time: 2.17908
Timestep Consumption Time: 2.53887
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.71795

Cumulative Model Updates: 141,488
Cumulative Timesteps: 1,180,119,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.88371
Policy Entropy: 3.11917
Value Function Loss: 0.00412

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.57502
Value Function Update Magnitude: 0.54203

Collected Steps per Second: 23,197.22643
Overall Steps per Second: 10,893.32235

Timestep Collection Time: 2.15595
Timestep Consumption Time: 2.43512
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.59107

Cumulative Model Updates: 141,494
Cumulative Timesteps: 1,180,169,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1180169930...
Checkpoint 1180169930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.50416
Policy Entropy: 3.11484
Value Function Loss: 0.00422

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.58114
Value Function Update Magnitude: 0.54634

Collected Steps per Second: 22,413.10284
Overall Steps per Second: 10,743.08578

Timestep Collection Time: 2.23102
Timestep Consumption Time: 2.42351
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.65453

Cumulative Model Updates: 141,500
Cumulative Timesteps: 1,180,219,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.79558
Policy Entropy: 3.10132
Value Function Loss: 0.00427

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.58788
Value Function Update Magnitude: 0.55609

Collected Steps per Second: 22,766.90703
Overall Steps per Second: 10,791.01869

Timestep Collection Time: 2.19696
Timestep Consumption Time: 2.43819
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.63515

Cumulative Model Updates: 141,506
Cumulative Timesteps: 1,180,269,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1180269952...
Checkpoint 1180269952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,704.82447
Policy Entropy: 3.09391
Value Function Loss: 0.00458

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.59224
Value Function Update Magnitude: 0.55790

Collected Steps per Second: 22,106.68222
Overall Steps per Second: 10,622.87833

Timestep Collection Time: 2.26257
Timestep Consumption Time: 2.44594
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.70852

Cumulative Model Updates: 141,512
Cumulative Timesteps: 1,180,319,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.45308
Policy Entropy: 3.10964
Value Function Loss: 0.00442

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.59737
Value Function Update Magnitude: 0.55520

Collected Steps per Second: 22,631.18294
Overall Steps per Second: 10,568.34668

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.52247
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.73243

Cumulative Model Updates: 141,518
Cumulative Timesteps: 1,180,369,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1180369984...
Checkpoint 1180369984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.79136
Policy Entropy: 3.09954
Value Function Loss: 0.00441

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.59031
Value Function Update Magnitude: 0.53872

Collected Steps per Second: 22,276.29356
Overall Steps per Second: 10,626.20283

Timestep Collection Time: 2.24535
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.70704

Cumulative Model Updates: 141,524
Cumulative Timesteps: 1,180,420,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,992.29407
Policy Entropy: 3.10600
Value Function Loss: 0.00403

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.57820
Value Function Update Magnitude: 0.52450

Collected Steps per Second: 23,107.49184
Overall Steps per Second: 10,782.16053

Timestep Collection Time: 2.16397
Timestep Consumption Time: 2.47369
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.63766

Cumulative Model Updates: 141,530
Cumulative Timesteps: 1,180,470,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1180470006...
Checkpoint 1180470006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,211.41035
Policy Entropy: 3.08829
Value Function Loss: 0.00414

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.57825
Value Function Update Magnitude: 0.52892

Collected Steps per Second: 22,687.52564
Overall Steps per Second: 10,701.52978

Timestep Collection Time: 2.20474
Timestep Consumption Time: 2.46936
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.67410

Cumulative Model Updates: 141,536
Cumulative Timesteps: 1,180,520,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.93778
Policy Entropy: 3.08360
Value Function Loss: 0.00423

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.59391
Value Function Update Magnitude: 0.54508

Collected Steps per Second: 22,838.75527
Overall Steps per Second: 10,704.35481

Timestep Collection Time: 2.19005
Timestep Consumption Time: 2.48263
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.67268

Cumulative Model Updates: 141,542
Cumulative Timesteps: 1,180,570,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1180570044...
Checkpoint 1180570044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.12128
Policy Entropy: 3.08283
Value Function Loss: 0.00428

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.60328
Value Function Update Magnitude: 0.54159

Collected Steps per Second: 22,600.55600
Overall Steps per Second: 10,569.30151

Timestep Collection Time: 2.21304
Timestep Consumption Time: 2.51915
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.73220

Cumulative Model Updates: 141,548
Cumulative Timesteps: 1,180,620,060

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,241.72652
Policy Entropy: 3.09836
Value Function Loss: 0.00441

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.60273
Value Function Update Magnitude: 0.53902

Collected Steps per Second: 23,211.30928
Overall Steps per Second: 10,749.52500

Timestep Collection Time: 2.15473
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.65267

Cumulative Model Updates: 141,554
Cumulative Timesteps: 1,180,670,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1180670074...
Checkpoint 1180670074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.77818
Policy Entropy: 3.09210
Value Function Loss: 0.00433

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.58770
Value Function Update Magnitude: 0.54219

Collected Steps per Second: 22,671.50923
Overall Steps per Second: 10,656.03402

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.48687
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.69236

Cumulative Model Updates: 141,560
Cumulative Timesteps: 1,180,720,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.34185
Policy Entropy: 3.08390
Value Function Loss: 0.00450

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.58606
Value Function Update Magnitude: 0.53034

Collected Steps per Second: 22,829.16955
Overall Steps per Second: 10,836.14938

Timestep Collection Time: 2.19123
Timestep Consumption Time: 2.42517
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.61640

Cumulative Model Updates: 141,566
Cumulative Timesteps: 1,180,770,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1180770100...
Checkpoint 1180770100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.38541
Policy Entropy: 3.07782
Value Function Loss: 0.00452

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.59152
Value Function Update Magnitude: 0.52404

Collected Steps per Second: 21,943.49279
Overall Steps per Second: 10,658.24828

Timestep Collection Time: 2.27894
Timestep Consumption Time: 2.41301
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.69195

Cumulative Model Updates: 141,572
Cumulative Timesteps: 1,180,820,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.55906
Policy Entropy: 3.09120
Value Function Loss: 0.00446

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.59387
Value Function Update Magnitude: 0.51531

Collected Steps per Second: 22,491.24627
Overall Steps per Second: 10,572.69043

Timestep Collection Time: 2.22451
Timestep Consumption Time: 2.50768
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.73219

Cumulative Model Updates: 141,578
Cumulative Timesteps: 1,180,870,140

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1180870140...
Checkpoint 1180870140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.71015
Policy Entropy: 3.09214
Value Function Loss: 0.00439

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.58961
Value Function Update Magnitude: 0.52607

Collected Steps per Second: 22,448.41966
Overall Steps per Second: 10,624.64249

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.47990
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.70830

Cumulative Model Updates: 141,584
Cumulative Timesteps: 1,180,920,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.49809
Policy Entropy: 3.09432
Value Function Loss: 0.00458

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.58915
Value Function Update Magnitude: 0.55692

Collected Steps per Second: 23,209.11029
Overall Steps per Second: 10,752.28551

Timestep Collection Time: 2.15510
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.65185

Cumulative Model Updates: 141,590
Cumulative Timesteps: 1,180,970,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1180970182...
Checkpoint 1180970182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,034.95750
Policy Entropy: 3.09257
Value Function Loss: 0.00458

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.59962
Value Function Update Magnitude: 0.56768

Collected Steps per Second: 22,292.10649
Overall Steps per Second: 10,708.51039

Timestep Collection Time: 2.24295
Timestep Consumption Time: 2.42624
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.66918

Cumulative Model Updates: 141,596
Cumulative Timesteps: 1,181,020,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.97549
Policy Entropy: 3.10299
Value Function Loss: 0.00460

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.60161
Value Function Update Magnitude: 0.55876

Collected Steps per Second: 22,971.34488
Overall Steps per Second: 10,733.74991

Timestep Collection Time: 2.17723
Timestep Consumption Time: 2.48227
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.65951

Cumulative Model Updates: 141,602
Cumulative Timesteps: 1,181,070,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1181070196...
Checkpoint 1181070196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,119.63460
Policy Entropy: 3.10759
Value Function Loss: 0.00472

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.60667
Value Function Update Magnitude: 0.56940

Collected Steps per Second: 22,799.85004
Overall Steps per Second: 10,814.39497

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.62365

Cumulative Model Updates: 141,608
Cumulative Timesteps: 1,181,120,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.51094
Policy Entropy: 3.13338
Value Function Loss: 0.00444

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.59664
Value Function Update Magnitude: 0.57097

Collected Steps per Second: 23,034.36049
Overall Steps per Second: 10,861.21213

Timestep Collection Time: 2.17163
Timestep Consumption Time: 2.43394
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.60556

Cumulative Model Updates: 141,614
Cumulative Timesteps: 1,181,170,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1181170220...
Checkpoint 1181170220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.59576
Policy Entropy: 3.12949
Value Function Loss: 0.00439

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.58940
Value Function Update Magnitude: 0.56019

Collected Steps per Second: 22,110.85029
Overall Steps per Second: 10,678.75500

Timestep Collection Time: 2.26251
Timestep Consumption Time: 2.42212
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.68463

Cumulative Model Updates: 141,620
Cumulative Timesteps: 1,181,220,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.42699
Policy Entropy: 3.12366
Value Function Loss: 0.00426

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.59525
Value Function Update Magnitude: 0.54198

Collected Steps per Second: 22,447.39246
Overall Steps per Second: 10,537.14644

Timestep Collection Time: 2.22761
Timestep Consumption Time: 2.51789
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.74550

Cumulative Model Updates: 141,626
Cumulative Timesteps: 1,181,270,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1181270250...
Checkpoint 1181270250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.54681
Policy Entropy: 3.11404
Value Function Loss: 0.00445

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.59761
Value Function Update Magnitude: 0.52515

Collected Steps per Second: 22,193.42782
Overall Steps per Second: 10,613.17631

Timestep Collection Time: 2.25337
Timestep Consumption Time: 2.45870
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.71207

Cumulative Model Updates: 141,632
Cumulative Timesteps: 1,181,320,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,186.96823
Policy Entropy: 3.10435
Value Function Loss: 0.00464

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.60174
Value Function Update Magnitude: 0.53963

Collected Steps per Second: 22,862.39217
Overall Steps per Second: 10,833.74395

Timestep Collection Time: 2.18717
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.61558

Cumulative Model Updates: 141,638
Cumulative Timesteps: 1,181,370,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1181370264...
Checkpoint 1181370264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.20394
Policy Entropy: 3.09454
Value Function Loss: 0.00446

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.60895
Value Function Update Magnitude: 0.55511

Collected Steps per Second: 22,008.87263
Overall Steps per Second: 10,466.36554

Timestep Collection Time: 2.27263
Timestep Consumption Time: 2.50630
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.77893

Cumulative Model Updates: 141,644
Cumulative Timesteps: 1,181,420,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.25373
Policy Entropy: 3.08629
Value Function Loss: 0.00440

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.60795
Value Function Update Magnitude: 0.54469

Collected Steps per Second: 22,860.60605
Overall Steps per Second: 10,707.21071

Timestep Collection Time: 2.18857
Timestep Consumption Time: 2.48417
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.67274

Cumulative Model Updates: 141,650
Cumulative Timesteps: 1,181,470,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1181470314...
Checkpoint 1181470314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.48867
Policy Entropy: 3.10667
Value Function Loss: 0.00459

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.60738
Value Function Update Magnitude: 0.53083

Collected Steps per Second: 22,690.60684
Overall Steps per Second: 10,649.30216

Timestep Collection Time: 2.20461
Timestep Consumption Time: 2.49278
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.69740

Cumulative Model Updates: 141,656
Cumulative Timesteps: 1,181,520,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.13445
Policy Entropy: 3.10906
Value Function Loss: 0.00463

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.59078
Value Function Update Magnitude: 0.53236

Collected Steps per Second: 22,860.65522
Overall Steps per Second: 10,625.58989

Timestep Collection Time: 2.18786
Timestep Consumption Time: 2.51926
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.70713

Cumulative Model Updates: 141,662
Cumulative Timesteps: 1,181,570,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1181570354...
Checkpoint 1181570354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.89563
Policy Entropy: 3.11887
Value Function Loss: 0.00416

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.57885
Value Function Update Magnitude: 0.52814

Collected Steps per Second: 22,406.18792
Overall Steps per Second: 10,344.70665

Timestep Collection Time: 2.23269
Timestep Consumption Time: 2.60322
PPO Batch Consumption Time: 0.30893
Total Iteration Time: 4.83590

Cumulative Model Updates: 141,668
Cumulative Timesteps: 1,181,620,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,513.88645
Policy Entropy: 3.11127
Value Function Loss: 0.00384

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.57334
Value Function Update Magnitude: 0.51618

Collected Steps per Second: 22,958.96727
Overall Steps per Second: 10,722.99268

Timestep Collection Time: 2.17850
Timestep Consumption Time: 2.48587
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.66437

Cumulative Model Updates: 141,674
Cumulative Timesteps: 1,181,670,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1181670396...
Checkpoint 1181670396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.62289
Policy Entropy: 3.11616
Value Function Loss: 0.00405

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.56919
Value Function Update Magnitude: 0.52340

Collected Steps per Second: 22,612.82705
Overall Steps per Second: 10,641.97242

Timestep Collection Time: 2.21228
Timestep Consumption Time: 2.48854
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.70082

Cumulative Model Updates: 141,680
Cumulative Timesteps: 1,181,720,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.41921
Policy Entropy: 3.11670
Value Function Loss: 0.00405

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.57083
Value Function Update Magnitude: 0.52268

Collected Steps per Second: 22,853.06401
Overall Steps per Second: 10,726.90466

Timestep Collection Time: 2.18885
Timestep Consumption Time: 2.47437
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.66323

Cumulative Model Updates: 141,686
Cumulative Timesteps: 1,181,770,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1181770444...
Checkpoint 1181770444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,114.75551
Policy Entropy: 3.12091
Value Function Loss: 0.00435

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.56964
Value Function Update Magnitude: 0.51798

Collected Steps per Second: 22,601.24888
Overall Steps per Second: 10,696.51874

Timestep Collection Time: 2.21351
Timestep Consumption Time: 2.46353
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.67704

Cumulative Model Updates: 141,692
Cumulative Timesteps: 1,181,820,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,628.74977
Policy Entropy: 3.12079
Value Function Loss: 0.00410

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.57757
Value Function Update Magnitude: 0.53265

Collected Steps per Second: 22,805.21473
Overall Steps per Second: 10,627.95936

Timestep Collection Time: 2.19248
Timestep Consumption Time: 2.51209
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.70457

Cumulative Model Updates: 141,698
Cumulative Timesteps: 1,181,870,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1181870472...
Checkpoint 1181870472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,207.50062
Policy Entropy: 3.11776
Value Function Loss: 0.00392

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.57233
Value Function Update Magnitude: 0.52626

Collected Steps per Second: 22,210.70517
Overall Steps per Second: 10,468.22707

Timestep Collection Time: 2.25135
Timestep Consumption Time: 2.52539
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.77674

Cumulative Model Updates: 141,704
Cumulative Timesteps: 1,181,920,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.72241
Policy Entropy: 3.10013
Value Function Loss: 0.00379

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.56338
Value Function Update Magnitude: 0.49824

Collected Steps per Second: 22,438.34034
Overall Steps per Second: 10,558.06132

Timestep Collection Time: 2.22833
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.73572

Cumulative Model Updates: 141,710
Cumulative Timesteps: 1,181,970,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1181970476...
Checkpoint 1181970476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.79915
Policy Entropy: 3.08881
Value Function Loss: 0.00408

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.50567

Collected Steps per Second: 22,457.62887
Overall Steps per Second: 10,582.93539

Timestep Collection Time: 2.22748
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.72685

Cumulative Model Updates: 141,716
Cumulative Timesteps: 1,182,020,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.80548
Policy Entropy: 3.08969
Value Function Loss: 0.00449

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.59281
Value Function Update Magnitude: 0.53244

Collected Steps per Second: 22,724.41920
Overall Steps per Second: 10,552.45741

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.53928
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.74070

Cumulative Model Updates: 141,722
Cumulative Timesteps: 1,182,070,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1182070526...
Checkpoint 1182070526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911.84334
Policy Entropy: 3.10380
Value Function Loss: 0.00466

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.59235
Value Function Update Magnitude: 0.55515

Collected Steps per Second: 22,826.48988
Overall Steps per Second: 10,655.14576

Timestep Collection Time: 2.19131
Timestep Consumption Time: 2.50313
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.69445

Cumulative Model Updates: 141,728
Cumulative Timesteps: 1,182,120,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.56396
Policy Entropy: 3.11363
Value Function Loss: 0.00453

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.58483
Value Function Update Magnitude: 0.54074

Collected Steps per Second: 22,837.42028
Overall Steps per Second: 10,750.43970

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.46296
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.65358

Cumulative Model Updates: 141,734
Cumulative Timesteps: 1,182,170,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1182170574...
Checkpoint 1182170574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.61567
Policy Entropy: 3.10683
Value Function Loss: 0.00481

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.59399
Value Function Update Magnitude: 0.53637

Collected Steps per Second: 22,761.98748
Overall Steps per Second: 10,657.44965

Timestep Collection Time: 2.19700
Timestep Consumption Time: 2.49531
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.69230

Cumulative Model Updates: 141,740
Cumulative Timesteps: 1,182,220,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,613.11151
Policy Entropy: 3.09703
Value Function Loss: 0.00460

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.59305
Value Function Update Magnitude: 0.56137

Collected Steps per Second: 22,296.46452
Overall Steps per Second: 10,578.02496

Timestep Collection Time: 2.24314
Timestep Consumption Time: 2.48497
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.72810

Cumulative Model Updates: 141,746
Cumulative Timesteps: 1,182,270,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1182270596...
Checkpoint 1182270596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.59060
Policy Entropy: 3.09562
Value Function Loss: 0.00433

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.57643
Value Function Update Magnitude: 0.54042

Collected Steps per Second: 22,595.38709
Overall Steps per Second: 10,679.29253

Timestep Collection Time: 2.21320
Timestep Consumption Time: 2.46951
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.68271

Cumulative Model Updates: 141,752
Cumulative Timesteps: 1,182,320,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.62834
Policy Entropy: 3.08666
Value Function Loss: 0.00426

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.57796
Value Function Update Magnitude: 0.51393

Collected Steps per Second: 22,783.00098
Overall Steps per Second: 10,771.24854

Timestep Collection Time: 2.19462
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.64199

Cumulative Model Updates: 141,758
Cumulative Timesteps: 1,182,370,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1182370604...
Checkpoint 1182370604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.54907
Policy Entropy: 3.10021
Value Function Loss: 0.00414

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.57710
Value Function Update Magnitude: 0.51888

Collected Steps per Second: 22,543.13280
Overall Steps per Second: 10,620.56704

Timestep Collection Time: 2.21824
Timestep Consumption Time: 2.49018
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.70841

Cumulative Model Updates: 141,764
Cumulative Timesteps: 1,182,420,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.41334
Policy Entropy: 3.09348
Value Function Loss: 0.00406

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.54222

Collected Steps per Second: 22,248.44977
Overall Steps per Second: 10,511.26428

Timestep Collection Time: 2.24870
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.75966

Cumulative Model Updates: 141,770
Cumulative Timesteps: 1,182,470,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1182470640...
Checkpoint 1182470640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,882.73858
Policy Entropy: 3.09497
Value Function Loss: 0.00390

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.57017
Value Function Update Magnitude: 0.54416

Collected Steps per Second: 22,530.71356
Overall Steps per Second: 10,454.55649

Timestep Collection Time: 2.22035
Timestep Consumption Time: 2.56474
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.78509

Cumulative Model Updates: 141,776
Cumulative Timesteps: 1,182,520,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,954.56891
Policy Entropy: 3.08924
Value Function Loss: 0.00377

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.56056
Value Function Update Magnitude: 0.52453

Collected Steps per Second: 22,053.54221
Overall Steps per Second: 10,563.48752

Timestep Collection Time: 2.26784
Timestep Consumption Time: 2.46677
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.73461

Cumulative Model Updates: 141,782
Cumulative Timesteps: 1,182,570,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1182570680...
Checkpoint 1182570680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,703.14496
Policy Entropy: 3.07844
Value Function Loss: 0.00408

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.56508
Value Function Update Magnitude: 0.50738

Collected Steps per Second: 23,131.88355
Overall Steps per Second: 10,703.06777

Timestep Collection Time: 2.16273
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.67417

Cumulative Model Updates: 141,788
Cumulative Timesteps: 1,182,620,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.14372
Policy Entropy: 3.07747
Value Function Loss: 0.00432

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.58020
Value Function Update Magnitude: 0.51204

Collected Steps per Second: 22,845.04277
Overall Steps per Second: 10,616.30882

Timestep Collection Time: 2.18936
Timestep Consumption Time: 2.52188
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.71124

Cumulative Model Updates: 141,794
Cumulative Timesteps: 1,182,670,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1182670724...
Checkpoint 1182670724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.43069
Policy Entropy: 3.07388
Value Function Loss: 0.00488

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.59958
Value Function Update Magnitude: 0.55661

Collected Steps per Second: 22,856.99556
Overall Steps per Second: 10,670.11920

Timestep Collection Time: 2.18804
Timestep Consumption Time: 2.49907
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.68711

Cumulative Model Updates: 141,800
Cumulative Timesteps: 1,182,720,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.36958
Policy Entropy: 3.08304
Value Function Loss: 0.00443

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.59190
Value Function Update Magnitude: 0.57016

Collected Steps per Second: 22,808.64718
Overall Steps per Second: 10,694.98611

Timestep Collection Time: 2.19250
Timestep Consumption Time: 2.48333
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.67584

Cumulative Model Updates: 141,806
Cumulative Timesteps: 1,182,770,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1182770744...
Checkpoint 1182770744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.21851
Policy Entropy: 3.09309
Value Function Loss: 0.00433

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.57911
Value Function Update Magnitude: 0.52220

Collected Steps per Second: 22,557.87689
Overall Steps per Second: 10,648.09648

Timestep Collection Time: 2.21732
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.69737

Cumulative Model Updates: 141,812
Cumulative Timesteps: 1,182,820,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.09793
Policy Entropy: 3.08440
Value Function Loss: 0.00397

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.56953
Value Function Update Magnitude: 0.48315

Collected Steps per Second: 22,929.21685
Overall Steps per Second: 10,821.35059

Timestep Collection Time: 2.18176
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.62290

Cumulative Model Updates: 141,818
Cumulative Timesteps: 1,182,870,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1182870788...
Checkpoint 1182870788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,362.13652
Policy Entropy: 3.08019
Value Function Loss: 0.00398

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.57287
Value Function Update Magnitude: 0.47744

Collected Steps per Second: 22,562.34718
Overall Steps per Second: 10,610.12997

Timestep Collection Time: 2.21794
Timestep Consumption Time: 2.49849
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.71644

Cumulative Model Updates: 141,824
Cumulative Timesteps: 1,182,920,830

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.35886
Policy Entropy: 3.08670
Value Function Loss: 0.00382

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.56099
Value Function Update Magnitude: 0.47909

Collected Steps per Second: 21,913.70905
Overall Steps per Second: 10,563.75210

Timestep Collection Time: 2.28259
Timestep Consumption Time: 2.45247
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.73506

Cumulative Model Updates: 141,830
Cumulative Timesteps: 1,182,970,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1182970850...
Checkpoint 1182970850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,601.95354
Policy Entropy: 3.09759
Value Function Loss: 0.00379

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.55464
Value Function Update Magnitude: 0.45741

Collected Steps per Second: 22,281.63378
Overall Steps per Second: 10,677.10533

Timestep Collection Time: 2.24517
Timestep Consumption Time: 2.44018
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.68535

Cumulative Model Updates: 141,836
Cumulative Timesteps: 1,183,020,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,424.19756
Policy Entropy: 3.09507
Value Function Loss: 0.00411

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.57750
Value Function Update Magnitude: 0.47289

Collected Steps per Second: 22,369.87116
Overall Steps per Second: 10,492.52206

Timestep Collection Time: 2.23640
Timestep Consumption Time: 2.53157
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.76797

Cumulative Model Updates: 141,842
Cumulative Timesteps: 1,183,070,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1183070904...
Checkpoint 1183070904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.69872
Policy Entropy: 3.07693
Value Function Loss: 0.00417

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.59215
Value Function Update Magnitude: 0.52111

Collected Steps per Second: 22,086.04726
Overall Steps per Second: 10,583.71372

Timestep Collection Time: 2.26433
Timestep Consumption Time: 2.46086
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.72518

Cumulative Model Updates: 141,848
Cumulative Timesteps: 1,183,120,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.13598
Policy Entropy: 3.07864
Value Function Loss: 0.00431

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.59153
Value Function Update Magnitude: 0.54089

Collected Steps per Second: 22,833.38039
Overall Steps per Second: 10,643.28349

Timestep Collection Time: 2.18986
Timestep Consumption Time: 2.50812
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.69799

Cumulative Model Updates: 141,854
Cumulative Timesteps: 1,183,170,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1183170916...
Checkpoint 1183170916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.77282
Policy Entropy: 3.07214
Value Function Loss: 0.00418

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.58697
Value Function Update Magnitude: 0.53081

Collected Steps per Second: 22,824.93709
Overall Steps per Second: 10,580.73720

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.53610
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.72765

Cumulative Model Updates: 141,860
Cumulative Timesteps: 1,183,220,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,908.49049
Policy Entropy: 3.08841
Value Function Loss: 0.00404

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.57604
Value Function Update Magnitude: 0.53312

Collected Steps per Second: 22,972.46158
Overall Steps per Second: 10,772.55985

Timestep Collection Time: 2.17661
Timestep Consumption Time: 2.46500
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.64161

Cumulative Model Updates: 141,866
Cumulative Timesteps: 1,183,270,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1183270940...
Checkpoint 1183270940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.21212
Policy Entropy: 3.09372
Value Function Loss: 0.00405

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.56941
Value Function Update Magnitude: 0.54254

Collected Steps per Second: 22,944.86223
Overall Steps per Second: 10,712.09816

Timestep Collection Time: 2.17983
Timestep Consumption Time: 2.48928
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.66911

Cumulative Model Updates: 141,872
Cumulative Timesteps: 1,183,320,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.69329
Policy Entropy: 3.09908
Value Function Loss: 0.00409

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.57775
Value Function Update Magnitude: 0.53164

Collected Steps per Second: 22,600.41832
Overall Steps per Second: 10,595.33449

Timestep Collection Time: 2.21279
Timestep Consumption Time: 2.50721
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.72000

Cumulative Model Updates: 141,878
Cumulative Timesteps: 1,183,370,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1183370966...
Checkpoint 1183370966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.19546
Policy Entropy: 3.10339
Value Function Loss: 0.00398

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.53077

Collected Steps per Second: 23,092.86319
Overall Steps per Second: 10,781.82251

Timestep Collection Time: 2.16517
Timestep Consumption Time: 2.47226
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.63743

Cumulative Model Updates: 141,884
Cumulative Timesteps: 1,183,420,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,925.07316
Policy Entropy: 3.10381
Value Function Loss: 0.00400

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.56478
Value Function Update Magnitude: 0.52883

Collected Steps per Second: 22,905.57676
Overall Steps per Second: 10,627.75996

Timestep Collection Time: 2.18331
Timestep Consumption Time: 2.52229
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.70560

Cumulative Model Updates: 141,890
Cumulative Timesteps: 1,183,470,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1183470976...
Checkpoint 1183470976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,750.32615
Policy Entropy: 3.10356
Value Function Loss: 0.00410

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.53027

Collected Steps per Second: 22,344.54656
Overall Steps per Second: 10,551.48059

Timestep Collection Time: 2.23813
Timestep Consumption Time: 2.50149
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.73962

Cumulative Model Updates: 141,896
Cumulative Timesteps: 1,183,520,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.09990
Policy Entropy: 3.09135
Value Function Loss: 0.00415

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.58049
Value Function Update Magnitude: 0.53536

Collected Steps per Second: 22,446.96010
Overall Steps per Second: 10,448.26233

Timestep Collection Time: 2.22819
Timestep Consumption Time: 2.55883
PPO Batch Consumption Time: 0.30537
Total Iteration Time: 4.78702

Cumulative Model Updates: 141,902
Cumulative Timesteps: 1,183,571,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1183571002...
Checkpoint 1183571002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.37994
Policy Entropy: 3.07643
Value Function Loss: 0.00402

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.57343
Value Function Update Magnitude: 0.52199

Collected Steps per Second: 22,361.44654
Overall Steps per Second: 10,689.91931

Timestep Collection Time: 2.23689
Timestep Consumption Time: 2.44229
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.67917

Cumulative Model Updates: 141,908
Cumulative Timesteps: 1,183,621,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.76486
Policy Entropy: 3.08135
Value Function Loss: 0.00405

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.57172
Value Function Update Magnitude: 0.52327

Collected Steps per Second: 22,446.84122
Overall Steps per Second: 10,582.29178

Timestep Collection Time: 2.22829
Timestep Consumption Time: 2.49829
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.72658

Cumulative Model Updates: 141,914
Cumulative Timesteps: 1,183,671,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1183671040...
Checkpoint 1183671040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.32246
Policy Entropy: 3.06852
Value Function Loss: 0.00425

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.58886
Value Function Update Magnitude: 0.51861

Collected Steps per Second: 23,005.75747
Overall Steps per Second: 10,667.10559

Timestep Collection Time: 2.17363
Timestep Consumption Time: 2.51424
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.68787

Cumulative Model Updates: 141,920
Cumulative Timesteps: 1,183,721,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.75802
Policy Entropy: 3.06937
Value Function Loss: 0.00454

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.60023
Value Function Update Magnitude: 0.53380

Collected Steps per Second: 22,925.68555
Overall Steps per Second: 10,687.65196

Timestep Collection Time: 2.18218
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.68092

Cumulative Model Updates: 141,926
Cumulative Timesteps: 1,183,771,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1183771074...
Checkpoint 1183771074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.15940
Policy Entropy: 3.06307
Value Function Loss: 0.00427

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.60083
Value Function Update Magnitude: 0.55927

Collected Steps per Second: 22,557.47809
Overall Steps per Second: 10,692.72815

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.46040
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.67776

Cumulative Model Updates: 141,932
Cumulative Timesteps: 1,183,821,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.69022
Policy Entropy: 3.08388
Value Function Loss: 0.00399

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.59302
Value Function Update Magnitude: 0.54841

Collected Steps per Second: 22,659.10856
Overall Steps per Second: 10,597.72612

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.51178
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.71875

Cumulative Model Updates: 141,938
Cumulative Timesteps: 1,183,871,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1183871100...
Checkpoint 1183871100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,048.30046
Policy Entropy: 3.09279
Value Function Loss: 0.00383

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.57603
Value Function Update Magnitude: 0.51314

Collected Steps per Second: 22,737.64191
Overall Steps per Second: 10,598.63105

Timestep Collection Time: 2.19926
Timestep Consumption Time: 2.51890
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.71816

Cumulative Model Updates: 141,944
Cumulative Timesteps: 1,183,921,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,984.97503
Policy Entropy: 3.09705
Value Function Loss: 0.00394

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.56512
Value Function Update Magnitude: 0.49389

Collected Steps per Second: 22,929.80669
Overall Steps per Second: 10,779.92666

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.45906
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.64085

Cumulative Model Updates: 141,950
Cumulative Timesteps: 1,183,971,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1183971134...
Checkpoint 1183971134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.21615
Policy Entropy: 3.08921
Value Function Loss: 0.00386

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.56491
Value Function Update Magnitude: 0.48910

Collected Steps per Second: 22,577.78783
Overall Steps per Second: 10,716.35404

Timestep Collection Time: 2.21581
Timestep Consumption Time: 2.45257
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.66838

Cumulative Model Updates: 141,956
Cumulative Timesteps: 1,184,021,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.95781
Policy Entropy: 3.07354
Value Function Loss: 0.00375

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.56141
Value Function Update Magnitude: 0.49184

Collected Steps per Second: 22,229.18223
Overall Steps per Second: 10,556.81682

Timestep Collection Time: 2.25127
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.74044

Cumulative Model Updates: 141,962
Cumulative Timesteps: 1,184,071,206

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1184071206...
Checkpoint 1184071206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.72397
Policy Entropy: 3.07832
Value Function Loss: 0.00385

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.49849

Collected Steps per Second: 22,256.90520
Overall Steps per Second: 10,513.24132

Timestep Collection Time: 2.24676
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.75648

Cumulative Model Updates: 141,968
Cumulative Timesteps: 1,184,121,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.68545
Policy Entropy: 3.07462
Value Function Loss: 0.00420

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.50167

Collected Steps per Second: 22,172.34548
Overall Steps per Second: 10,539.87083

Timestep Collection Time: 2.25578
Timestep Consumption Time: 2.48963
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74541

Cumulative Model Updates: 141,974
Cumulative Timesteps: 1,184,171,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1184171228...
Checkpoint 1184171228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.87139
Policy Entropy: 3.07032
Value Function Loss: 0.00426

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10984
Policy Update Magnitude: 0.57555
Value Function Update Magnitude: 0.51854

Collected Steps per Second: 22,422.36522
Overall Steps per Second: 10,495.32599

Timestep Collection Time: 2.23001
Timestep Consumption Time: 2.53421
PPO Batch Consumption Time: 0.30139
Total Iteration Time: 4.76422

Cumulative Model Updates: 141,980
Cumulative Timesteps: 1,184,221,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.42900
Policy Entropy: 3.05713
Value Function Loss: 0.00437

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11471
Policy Update Magnitude: 0.58320
Value Function Update Magnitude: 0.52830

Collected Steps per Second: 22,377.27249
Overall Steps per Second: 10,373.57048

Timestep Collection Time: 2.23530
Timestep Consumption Time: 2.58657
PPO Batch Consumption Time: 0.30800
Total Iteration Time: 4.82187

Cumulative Model Updates: 141,986
Cumulative Timesteps: 1,184,271,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1184271250...
Checkpoint 1184271250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.62566
Policy Entropy: 3.06898
Value Function Loss: 0.00386

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.51645

Collected Steps per Second: 22,522.85815
Overall Steps per Second: 10,687.39807

Timestep Collection Time: 2.22121
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.68103

Cumulative Model Updates: 141,992
Cumulative Timesteps: 1,184,321,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,349.13139
Policy Entropy: 3.06933
Value Function Loss: 0.00412

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.58978
Value Function Update Magnitude: 0.51273

Collected Steps per Second: 22,948.93756
Overall Steps per Second: 10,715.39003

Timestep Collection Time: 2.17962
Timestep Consumption Time: 2.48843
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.66805

Cumulative Model Updates: 141,998
Cumulative Timesteps: 1,184,371,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1184371298...
Checkpoint 1184371298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,167.78335
Policy Entropy: 3.06722
Value Function Loss: 0.00456

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10601
Policy Update Magnitude: 0.59733
Value Function Update Magnitude: 0.55443

Collected Steps per Second: 22,868.35040
Overall Steps per Second: 10,821.31336

Timestep Collection Time: 2.18669
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.62107

Cumulative Model Updates: 142,004
Cumulative Timesteps: 1,184,421,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.33886
Policy Entropy: 3.04756
Value Function Loss: 0.00480

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.60898
Value Function Update Magnitude: 0.60464

Collected Steps per Second: 22,685.69932
Overall Steps per Second: 10,620.64227

Timestep Collection Time: 2.20535
Timestep Consumption Time: 2.50528
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.71064

Cumulative Model Updates: 142,010
Cumulative Timesteps: 1,184,471,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1184471334...
Checkpoint 1184471334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.53787
Policy Entropy: 3.04136
Value Function Loss: 0.00464

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.61753
Value Function Update Magnitude: 0.61542

Collected Steps per Second: 22,731.31586
Overall Steps per Second: 10,687.83844

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.47920
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.67934

Cumulative Model Updates: 142,016
Cumulative Timesteps: 1,184,521,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.07592
Policy Entropy: 3.03717
Value Function Loss: 0.00441

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.61680
Value Function Update Magnitude: 0.60701

Collected Steps per Second: 22,422.43326
Overall Steps per Second: 10,749.75640

Timestep Collection Time: 2.23080
Timestep Consumption Time: 2.42233
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.65313

Cumulative Model Updates: 142,022
Cumulative Timesteps: 1,184,571,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1184571366...
Checkpoint 1184571366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.90766
Policy Entropy: 3.03190
Value Function Loss: 0.00431

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.60779
Value Function Update Magnitude: 0.61793

Collected Steps per Second: 22,168.65411
Overall Steps per Second: 10,518.89596

Timestep Collection Time: 2.25607
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.75468

Cumulative Model Updates: 142,028
Cumulative Timesteps: 1,184,621,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.95028
Policy Entropy: 3.03697
Value Function Loss: 0.00438

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.59930
Value Function Update Magnitude: 0.60241

Collected Steps per Second: 22,616.66881
Overall Steps per Second: 10,718.41843

Timestep Collection Time: 2.21129
Timestep Consumption Time: 2.45470
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.66599

Cumulative Model Updates: 142,034
Cumulative Timesteps: 1,184,671,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1184671392...
Checkpoint 1184671392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.18083
Policy Entropy: 3.04876
Value Function Loss: 0.00426

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.59976
Value Function Update Magnitude: 0.57288

Collected Steps per Second: 22,101.30279
Overall Steps per Second: 10,595.28335

Timestep Collection Time: 2.26321
Timestep Consumption Time: 2.45775
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.72097

Cumulative Model Updates: 142,040
Cumulative Timesteps: 1,184,721,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.52442
Policy Entropy: 3.05654
Value Function Loss: 0.00436

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.59331
Value Function Update Magnitude: 0.55559

Collected Steps per Second: 22,527.84071
Overall Steps per Second: 10,570.06856

Timestep Collection Time: 2.21956
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73053

Cumulative Model Updates: 142,046
Cumulative Timesteps: 1,184,771,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1184771414...
Checkpoint 1184771414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.55363
Policy Entropy: 3.04886
Value Function Loss: 0.00431

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.58678
Value Function Update Magnitude: 0.55019

Collected Steps per Second: 22,710.06194
Overall Steps per Second: 10,543.08344

Timestep Collection Time: 2.20290
Timestep Consumption Time: 2.54220
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.74510

Cumulative Model Updates: 142,052
Cumulative Timesteps: 1,184,821,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.03581
Policy Entropy: 3.03796
Value Function Loss: 0.00446

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.59595
Value Function Update Magnitude: 0.55923

Collected Steps per Second: 22,868.39939
Overall Steps per Second: 10,822.95250

Timestep Collection Time: 2.18712
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.62129

Cumulative Model Updates: 142,058
Cumulative Timesteps: 1,184,871,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1184871458...
Checkpoint 1184871458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.01727
Policy Entropy: 3.01817
Value Function Loss: 0.00438

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.59219
Value Function Update Magnitude: 0.55392

Collected Steps per Second: 22,156.02961
Overall Steps per Second: 10,595.98518

Timestep Collection Time: 2.25708
Timestep Consumption Time: 2.46244
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.71952

Cumulative Model Updates: 142,064
Cumulative Timesteps: 1,184,921,466

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.90006
Policy Entropy: 3.02667
Value Function Loss: 0.00493

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.60933
Value Function Update Magnitude: 0.55049

Collected Steps per Second: 22,593.22778
Overall Steps per Second: 10,597.28083

Timestep Collection Time: 2.21411
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.72046

Cumulative Model Updates: 142,070
Cumulative Timesteps: 1,184,971,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1184971490...
Checkpoint 1184971490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.81086
Policy Entropy: 3.01936
Value Function Loss: 0.00497

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.61186
Value Function Update Magnitude: 0.55920

Collected Steps per Second: 22,645.31085
Overall Steps per Second: 10,640.10934

Timestep Collection Time: 2.20832
Timestep Consumption Time: 2.49164
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.69995

Cumulative Model Updates: 142,076
Cumulative Timesteps: 1,185,021,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.72425
Policy Entropy: 3.04041
Value Function Loss: 0.00494

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.59909
Value Function Update Magnitude: 0.55611

Collected Steps per Second: 22,891.82227
Overall Steps per Second: 10,805.83452

Timestep Collection Time: 2.18419
Timestep Consumption Time: 2.44294
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.62713

Cumulative Model Updates: 142,082
Cumulative Timesteps: 1,185,071,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1185071498...
Checkpoint 1185071498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.15020
Policy Entropy: 3.04200
Value Function Loss: 0.00465

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.58697
Value Function Update Magnitude: 0.53869

Collected Steps per Second: 22,485.83140
Overall Steps per Second: 10,731.94467

Timestep Collection Time: 2.22487
Timestep Consumption Time: 2.43673
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.66160

Cumulative Model Updates: 142,088
Cumulative Timesteps: 1,185,121,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.81929
Policy Entropy: 3.05375
Value Function Loss: 0.00458

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.58184
Value Function Update Magnitude: 0.52602

Collected Steps per Second: 22,470.96841
Overall Steps per Second: 10,627.95449

Timestep Collection Time: 2.22643
Timestep Consumption Time: 2.48097
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.70740

Cumulative Model Updates: 142,094
Cumulative Timesteps: 1,185,171,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1185171556...
Checkpoint 1185171556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.99835
Policy Entropy: 3.04574
Value Function Loss: 0.00467

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.54179

Collected Steps per Second: 22,532.40931
Overall Steps per Second: 10,670.98904

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.46786
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.68804

Cumulative Model Updates: 142,100
Cumulative Timesteps: 1,185,221,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.10584
Policy Entropy: 3.04765
Value Function Loss: 0.00478

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.61235
Value Function Update Magnitude: 0.57702

Collected Steps per Second: 22,541.81852
Overall Steps per Second: 10,779.78165

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.42118
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.64017

Cumulative Model Updates: 142,106
Cumulative Timesteps: 1,185,271,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1185271602...
Checkpoint 1185271602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,916.67405
Policy Entropy: 3.03875
Value Function Loss: 0.00463

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.60974
Value Function Update Magnitude: 0.59407

Collected Steps per Second: 22,224.68343
Overall Steps per Second: 10,596.52215

Timestep Collection Time: 2.25002
Timestep Consumption Time: 2.46907
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.71910

Cumulative Model Updates: 142,112
Cumulative Timesteps: 1,185,321,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.73718
Policy Entropy: 3.03978
Value Function Loss: 0.00465

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.60436
Value Function Update Magnitude: 0.56895

Collected Steps per Second: 22,994.03695
Overall Steps per Second: 10,602.30865

Timestep Collection Time: 2.17491
Timestep Consumption Time: 2.54199
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.71690

Cumulative Model Updates: 142,118
Cumulative Timesteps: 1,185,371,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1185371618...
Checkpoint 1185371618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.96938
Policy Entropy: 3.03164
Value Function Loss: 0.00469

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.60784
Value Function Update Magnitude: 0.58762

Collected Steps per Second: 22,743.75498
Overall Steps per Second: 10,816.56689

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.62420

Cumulative Model Updates: 142,124
Cumulative Timesteps: 1,185,421,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,215.87475
Policy Entropy: 3.04082
Value Function Loss: 0.00442

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.60668
Value Function Update Magnitude: 0.59652

Collected Steps per Second: 22,658.62327
Overall Steps per Second: 10,562.74638

Timestep Collection Time: 2.20825
Timestep Consumption Time: 2.52877
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.73703

Cumulative Model Updates: 142,130
Cumulative Timesteps: 1,185,471,672

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1185471672...
Checkpoint 1185471672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.76238
Policy Entropy: 3.03792
Value Function Loss: 0.00435

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.60377
Value Function Update Magnitude: 0.55683

Collected Steps per Second: 22,471.67888
Overall Steps per Second: 10,630.48580

Timestep Collection Time: 2.22547
Timestep Consumption Time: 2.47893
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.70439

Cumulative Model Updates: 142,136
Cumulative Timesteps: 1,185,521,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.42720
Policy Entropy: 3.04459
Value Function Loss: 0.00456

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11257
Policy Update Magnitude: 0.61123
Value Function Update Magnitude: 0.55662

Collected Steps per Second: 22,824.12614
Overall Steps per Second: 10,622.91019

Timestep Collection Time: 2.19075
Timestep Consumption Time: 2.51624
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.70700

Cumulative Model Updates: 142,142
Cumulative Timesteps: 1,185,571,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1185571684...
Checkpoint 1185571684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,857.29699
Policy Entropy: 3.04127
Value Function Loss: 0.00446

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.60998
Value Function Update Magnitude: 0.57703

Collected Steps per Second: 22,404.39266
Overall Steps per Second: 10,638.45060

Timestep Collection Time: 2.23260
Timestep Consumption Time: 2.46921
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.70181

Cumulative Model Updates: 142,148
Cumulative Timesteps: 1,185,621,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.18473
Policy Entropy: 3.05183
Value Function Loss: 0.00433

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.60862
Value Function Update Magnitude: 0.58814

Collected Steps per Second: 22,925.83326
Overall Steps per Second: 10,800.05401

Timestep Collection Time: 2.18138
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.63053

Cumulative Model Updates: 142,154
Cumulative Timesteps: 1,185,671,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1185671714...
Checkpoint 1185671714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677.72252
Policy Entropy: 3.04633
Value Function Loss: 0.00391

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.59384

Collected Steps per Second: 22,139.45048
Overall Steps per Second: 10,643.20058

Timestep Collection Time: 2.25923
Timestep Consumption Time: 2.44030
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.69953

Cumulative Model Updates: 142,160
Cumulative Timesteps: 1,185,721,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.01271
Policy Entropy: 3.05064
Value Function Loss: 0.00433

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.59755
Value Function Update Magnitude: 0.58743

Collected Steps per Second: 22,902.47759
Overall Steps per Second: 10,897.01897

Timestep Collection Time: 2.18378
Timestep Consumption Time: 2.40591
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.58970

Cumulative Model Updates: 142,166
Cumulative Timesteps: 1,185,771,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1185771746...
Checkpoint 1185771746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.33021
Policy Entropy: 3.04391
Value Function Loss: 0.00438

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.60456
Value Function Update Magnitude: 0.59556

Collected Steps per Second: 22,370.79917
Overall Steps per Second: 10,620.43302

Timestep Collection Time: 2.23524
Timestep Consumption Time: 2.47305
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.70828

Cumulative Model Updates: 142,172
Cumulative Timesteps: 1,185,821,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.94580
Policy Entropy: 3.02565
Value Function Loss: 0.00468

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.61737
Value Function Update Magnitude: 0.57924

Collected Steps per Second: 22,519.69381
Overall Steps per Second: 10,631.35987

Timestep Collection Time: 2.22063
Timestep Consumption Time: 2.48319
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.70382

Cumulative Model Updates: 142,178
Cumulative Timesteps: 1,185,871,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1185871758...
Checkpoint 1185871758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.60029
Policy Entropy: 3.03112
Value Function Loss: 0.00396

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.60687
Value Function Update Magnitude: 0.55053

Collected Steps per Second: 22,765.42380
Overall Steps per Second: 10,514.57946

Timestep Collection Time: 2.19754
Timestep Consumption Time: 2.56042
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.75796

Cumulative Model Updates: 142,184
Cumulative Timesteps: 1,185,921,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.37616
Policy Entropy: 3.02719
Value Function Loss: 0.00420

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.58698
Value Function Update Magnitude: 0.52012

Collected Steps per Second: 23,039.61472
Overall Steps per Second: 10,794.14478

Timestep Collection Time: 2.17044
Timestep Consumption Time: 2.46226
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.63270

Cumulative Model Updates: 142,190
Cumulative Timesteps: 1,185,971,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1185971792...
Checkpoint 1185971792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.79566
Policy Entropy: 3.03068
Value Function Loss: 0.00426

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.59197
Value Function Update Magnitude: 0.54067

Collected Steps per Second: 22,675.80174
Overall Steps per Second: 10,691.46287

Timestep Collection Time: 2.20526
Timestep Consumption Time: 2.47193
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.67719

Cumulative Model Updates: 142,196
Cumulative Timesteps: 1,186,021,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,490.23491
Policy Entropy: 3.03216
Value Function Loss: 0.00431

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.59799
Value Function Update Magnitude: 0.58336

Collected Steps per Second: 22,795.49418
Overall Steps per Second: 10,624.31874

Timestep Collection Time: 2.19359
Timestep Consumption Time: 2.51297
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.70656

Cumulative Model Updates: 142,202
Cumulative Timesteps: 1,186,071,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1186071802...
Checkpoint 1186071802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,883.16469
Policy Entropy: 3.02605
Value Function Loss: 0.00433

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.59431
Value Function Update Magnitude: 0.58913

Collected Steps per Second: 22,502.92554
Overall Steps per Second: 10,617.81853

Timestep Collection Time: 2.22318
Timestep Consumption Time: 2.48852
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.71170

Cumulative Model Updates: 142,208
Cumulative Timesteps: 1,186,121,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.95870
Policy Entropy: 3.04041
Value Function Loss: 0.00411

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.58762
Value Function Update Magnitude: 0.57006

Collected Steps per Second: 23,125.82459
Overall Steps per Second: 10,763.39592

Timestep Collection Time: 2.16243
Timestep Consumption Time: 2.48369
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.64612

Cumulative Model Updates: 142,214
Cumulative Timesteps: 1,186,171,838

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1186171838...
Checkpoint 1186171838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,331.19346
Policy Entropy: 3.02920
Value Function Loss: 0.00441

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.58500
Value Function Update Magnitude: 0.54521

Collected Steps per Second: 22,483.11047
Overall Steps per Second: 10,445.85992

Timestep Collection Time: 2.22425
Timestep Consumption Time: 2.56310
PPO Batch Consumption Time: 0.30563
Total Iteration Time: 4.78735

Cumulative Model Updates: 142,220
Cumulative Timesteps: 1,186,221,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.67497
Policy Entropy: 3.01720
Value Function Loss: 0.00429

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.59934
Value Function Update Magnitude: 0.55518

Collected Steps per Second: 22,406.04988
Overall Steps per Second: 10,629.66299

Timestep Collection Time: 2.23190
Timestep Consumption Time: 2.47267
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.70457

Cumulative Model Updates: 142,226
Cumulative Timesteps: 1,186,271,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1186271854...
Checkpoint 1186271854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.04723
Policy Entropy: 3.01872
Value Function Loss: 0.00426

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.59925
Value Function Update Magnitude: 0.56709

Collected Steps per Second: 21,968.12610
Overall Steps per Second: 10,627.10476

Timestep Collection Time: 2.27712
Timestep Consumption Time: 2.43009
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.70721

Cumulative Model Updates: 142,232
Cumulative Timesteps: 1,186,321,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,218.24580
Policy Entropy: 3.03598
Value Function Loss: 0.00377

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.54574

Collected Steps per Second: 22,131.08635
Overall Steps per Second: 10,475.53754

Timestep Collection Time: 2.25990
Timestep Consumption Time: 2.51446
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.77436

Cumulative Model Updates: 142,238
Cumulative Timesteps: 1,186,371,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1186371892...
Checkpoint 1186371892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.14415
Policy Entropy: 3.05626
Value Function Loss: 0.00401

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.53845

Collected Steps per Second: 22,101.68915
Overall Steps per Second: 10,689.06433

Timestep Collection Time: 2.26354
Timestep Consumption Time: 2.41676
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.68030

Cumulative Model Updates: 142,244
Cumulative Timesteps: 1,186,421,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.64370
Policy Entropy: 3.05917
Value Function Loss: 0.00396

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.57848
Value Function Update Magnitude: 0.55817

Collected Steps per Second: 22,504.92191
Overall Steps per Second: 10,611.66914

Timestep Collection Time: 2.22236
Timestep Consumption Time: 2.49076
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.71311

Cumulative Model Updates: 142,250
Cumulative Timesteps: 1,186,471,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1186471934...
Checkpoint 1186471934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.99901
Policy Entropy: 3.05314
Value Function Loss: 0.00414

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.58235
Value Function Update Magnitude: 0.55061

Collected Steps per Second: 22,795.59082
Overall Steps per Second: 10,614.14721

Timestep Collection Time: 2.19455
Timestep Consumption Time: 2.51860
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.71314

Cumulative Model Updates: 142,256
Cumulative Timesteps: 1,186,521,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.64472
Policy Entropy: 3.04832
Value Function Loss: 0.00421

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.58203
Value Function Update Magnitude: 0.55165

Collected Steps per Second: 23,175.09885
Overall Steps per Second: 10,692.98553

Timestep Collection Time: 2.15757
Timestep Consumption Time: 2.51858
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.67615

Cumulative Model Updates: 142,262
Cumulative Timesteps: 1,186,571,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1186571962...
Checkpoint 1186571962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.36024
Policy Entropy: 3.03373
Value Function Loss: 0.00414

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.58174
Value Function Update Magnitude: 0.56020

Collected Steps per Second: 22,658.48332
Overall Steps per Second: 10,691.91693

Timestep Collection Time: 2.20730
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.67774

Cumulative Model Updates: 142,268
Cumulative Timesteps: 1,186,621,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,947.88958
Policy Entropy: 3.04141
Value Function Loss: 0.00394

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.53684

Collected Steps per Second: 22,979.44676
Overall Steps per Second: 10,780.60702

Timestep Collection Time: 2.17603
Timestep Consumption Time: 2.46230
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.63833

Cumulative Model Updates: 142,274
Cumulative Timesteps: 1,186,671,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1186671980...
Checkpoint 1186671980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,795.36748
Policy Entropy: 3.03680
Value Function Loss: 0.00381

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.58457
Value Function Update Magnitude: 0.52924

Collected Steps per Second: 22,452.80986
Overall Steps per Second: 10,664.49990

Timestep Collection Time: 2.22716
Timestep Consumption Time: 2.46186
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.68901

Cumulative Model Updates: 142,280
Cumulative Timesteps: 1,186,721,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.31112
Policy Entropy: 3.05527
Value Function Loss: 0.00361

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.53203

Collected Steps per Second: 22,573.51324
Overall Steps per Second: 10,523.38819

Timestep Collection Time: 2.21507
Timestep Consumption Time: 2.53644
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.75151

Cumulative Model Updates: 142,286
Cumulative Timesteps: 1,186,771,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1186771988...
Checkpoint 1186771988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,348.52639
Policy Entropy: 3.06609
Value Function Loss: 0.00392

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.57382
Value Function Update Magnitude: 0.52770

Collected Steps per Second: 22,727.89754
Overall Steps per Second: 10,677.99345

Timestep Collection Time: 2.20064
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.68403

Cumulative Model Updates: 142,292
Cumulative Timesteps: 1,186,822,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,622.80264
Policy Entropy: 3.07803
Value Function Loss: 0.00416

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.57958
Value Function Update Magnitude: 0.52764

Collected Steps per Second: 22,588.78411
Overall Steps per Second: 10,353.96181

Timestep Collection Time: 2.21464
Timestep Consumption Time: 2.61694
PPO Batch Consumption Time: 0.30908
Total Iteration Time: 4.83158

Cumulative Model Updates: 142,298
Cumulative Timesteps: 1,186,872,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1186872030...
Checkpoint 1186872030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.71999
Policy Entropy: 3.06007
Value Function Loss: 0.00454

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.59570
Value Function Update Magnitude: 0.53291

Collected Steps per Second: 21,065.69251
Overall Steps per Second: 10,266.14919

Timestep Collection Time: 2.37381
Timestep Consumption Time: 2.49715
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.87096

Cumulative Model Updates: 142,304
Cumulative Timesteps: 1,186,922,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 872.08457
Policy Entropy: 3.05071
Value Function Loss: 0.00430

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.59467
Value Function Update Magnitude: 0.52056

Collected Steps per Second: 22,497.72104
Overall Steps per Second: 10,641.36167

Timestep Collection Time: 2.22360
Timestep Consumption Time: 2.47749
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70109

Cumulative Model Updates: 142,310
Cumulative Timesteps: 1,186,972,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1186972062...
Checkpoint 1186972062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,137.99405
Policy Entropy: 3.04132
Value Function Loss: 0.00440

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.59126
Value Function Update Magnitude: 0.51437

Collected Steps per Second: 22,795.83327
Overall Steps per Second: 10,731.76239

Timestep Collection Time: 2.19338
Timestep Consumption Time: 2.46568
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.65907

Cumulative Model Updates: 142,316
Cumulative Timesteps: 1,187,022,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.87886
Policy Entropy: 3.04100
Value Function Loss: 0.00428

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.59519
Value Function Update Magnitude: 0.51517

Collected Steps per Second: 22,629.67647
Overall Steps per Second: 10,704.46608

Timestep Collection Time: 2.20975
Timestep Consumption Time: 2.46175
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.67151

Cumulative Model Updates: 142,322
Cumulative Timesteps: 1,187,072,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1187072068...
Checkpoint 1187072068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,072.57170
Policy Entropy: 3.03665
Value Function Loss: 0.00421

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.59027
Value Function Update Magnitude: 0.50213

Collected Steps per Second: 23,058.12857
Overall Steps per Second: 10,743.03261

Timestep Collection Time: 2.16843
Timestep Consumption Time: 2.48575
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.65418

Cumulative Model Updates: 142,328
Cumulative Timesteps: 1,187,122,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,326.53492
Policy Entropy: 3.03783
Value Function Loss: 0.00422

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.58235
Value Function Update Magnitude: 0.50692

Collected Steps per Second: 23,425.04239
Overall Steps per Second: 10,778.90193

Timestep Collection Time: 2.13549
Timestep Consumption Time: 2.50543
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.64092

Cumulative Model Updates: 142,334
Cumulative Timesteps: 1,187,172,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1187172092...
Checkpoint 1187172092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.27358
Policy Entropy: 3.04865
Value Function Loss: 0.00412

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.58505
Value Function Update Magnitude: 0.52291

Collected Steps per Second: 22,906.13633
Overall Steps per Second: 10,675.91776

Timestep Collection Time: 2.18282
Timestep Consumption Time: 2.50062
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.68344

Cumulative Model Updates: 142,340
Cumulative Timesteps: 1,187,222,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.52015
Policy Entropy: 3.07296
Value Function Loss: 0.00410

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.53724

Collected Steps per Second: 23,010.73463
Overall Steps per Second: 10,817.87735

Timestep Collection Time: 2.17507
Timestep Consumption Time: 2.45153
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.62660

Cumulative Model Updates: 142,346
Cumulative Timesteps: 1,187,272,142

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1187272142...
Checkpoint 1187272142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.15670
Policy Entropy: 3.07624
Value Function Loss: 0.00391

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.56981
Value Function Update Magnitude: 0.51951

Collected Steps per Second: 22,807.83923
Overall Steps per Second: 10,658.67622

Timestep Collection Time: 2.19232
Timestep Consumption Time: 2.49889
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.69120

Cumulative Model Updates: 142,352
Cumulative Timesteps: 1,187,322,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,108.12556
Policy Entropy: 3.06785
Value Function Loss: 0.00383

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.56630
Value Function Update Magnitude: 0.49470

Collected Steps per Second: 23,250.69112
Overall Steps per Second: 10,884.31135

Timestep Collection Time: 2.15133
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.59561

Cumulative Model Updates: 142,358
Cumulative Timesteps: 1,187,372,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1187372164...
Checkpoint 1187372164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,477.59611
Policy Entropy: 3.06073
Value Function Loss: 0.00394

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.50214

Collected Steps per Second: 22,331.24356
Overall Steps per Second: 10,692.04819

Timestep Collection Time: 2.23919
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.67675

Cumulative Model Updates: 142,364
Cumulative Timesteps: 1,187,422,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.78217
Policy Entropy: 3.05871
Value Function Loss: 0.00417

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.57797
Value Function Update Magnitude: 0.52480

Collected Steps per Second: 22,911.00539
Overall Steps per Second: 10,796.66506

Timestep Collection Time: 2.18244
Timestep Consumption Time: 2.44880
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.63124

Cumulative Model Updates: 142,370
Cumulative Timesteps: 1,187,472,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1187472170...
Checkpoint 1187472170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.57302
Policy Entropy: 3.08172
Value Function Loss: 0.00414

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12064
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.53355

Collected Steps per Second: 22,582.02806
Overall Steps per Second: 10,694.53095

Timestep Collection Time: 2.21601
Timestep Consumption Time: 2.46320
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.67921

Cumulative Model Updates: 142,376
Cumulative Timesteps: 1,187,522,212

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,093.19039
Policy Entropy: 3.08142
Value Function Loss: 0.00426

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.57195
Value Function Update Magnitude: 0.53446

Collected Steps per Second: 22,872.49812
Overall Steps per Second: 10,634.57114

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.51723
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.70466

Cumulative Model Updates: 142,382
Cumulative Timesteps: 1,187,572,244

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1187572244...
Checkpoint 1187572244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,945.63016
Policy Entropy: 3.08405
Value Function Loss: 0.00424

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.58627
Value Function Update Magnitude: 0.56685

Collected Steps per Second: 23,033.69700
Overall Steps per Second: 10,645.64206

Timestep Collection Time: 2.17212
Timestep Consumption Time: 2.52764
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.69976

Cumulative Model Updates: 142,388
Cumulative Timesteps: 1,187,622,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.82659
Policy Entropy: 3.08581
Value Function Loss: 0.00422

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.59138
Value Function Update Magnitude: 0.58458

Collected Steps per Second: 23,430.11046
Overall Steps per Second: 10,707.10475

Timestep Collection Time: 2.13477
Timestep Consumption Time: 2.53670
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.67148

Cumulative Model Updates: 142,394
Cumulative Timesteps: 1,187,672,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1187672294...
Checkpoint 1187672294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,180.39327
Policy Entropy: 3.09203
Value Function Loss: 0.00468

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.59529
Value Function Update Magnitude: 0.59998

Collected Steps per Second: 22,629.00451
Overall Steps per Second: 10,660.94922

Timestep Collection Time: 2.20991
Timestep Consumption Time: 2.48086
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.69076

Cumulative Model Updates: 142,400
Cumulative Timesteps: 1,187,722,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.51023
Policy Entropy: 3.09022
Value Function Loss: 0.00503

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.59246
Value Function Update Magnitude: 0.60311

Collected Steps per Second: 23,356.46678
Overall Steps per Second: 10,920.64171

Timestep Collection Time: 2.14176
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.58068

Cumulative Model Updates: 142,406
Cumulative Timesteps: 1,187,772,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1187772326...
Checkpoint 1187772326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 861.92186
Policy Entropy: 3.08696
Value Function Loss: 0.00518

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.59198
Value Function Update Magnitude: 0.59309

Collected Steps per Second: 23,224.83346
Overall Steps per Second: 10,840.39878

Timestep Collection Time: 2.15364
Timestep Consumption Time: 2.46039
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.61404

Cumulative Model Updates: 142,412
Cumulative Timesteps: 1,187,822,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,736.34586
Policy Entropy: 3.09454
Value Function Loss: 0.00488

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.58999
Value Function Update Magnitude: 0.59397

Collected Steps per Second: 23,649.38804
Overall Steps per Second: 10,940.44570

Timestep Collection Time: 2.11507
Timestep Consumption Time: 2.45696
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.57203

Cumulative Model Updates: 142,418
Cumulative Timesteps: 1,187,872,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1187872364...
Checkpoint 1187872364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,594.93045
Policy Entropy: 3.09530
Value Function Loss: 0.00430

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.58623
Value Function Update Magnitude: 0.57922

Collected Steps per Second: 22,271.23583
Overall Steps per Second: 10,515.21195

Timestep Collection Time: 2.24532
Timestep Consumption Time: 2.51027
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.75559

Cumulative Model Updates: 142,424
Cumulative Timesteps: 1,187,922,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,345.32655
Policy Entropy: 3.10093
Value Function Loss: 0.00431

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.58750
Value Function Update Magnitude: 0.55725

Collected Steps per Second: 22,654.48419
Overall Steps per Second: 10,748.02728

Timestep Collection Time: 2.20742
Timestep Consumption Time: 2.44534
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.65276

Cumulative Model Updates: 142,430
Cumulative Timesteps: 1,187,972,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1187972378...
Checkpoint 1187972378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.48102
Policy Entropy: 3.11145
Value Function Loss: 0.00406

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.57468
Value Function Update Magnitude: 0.54553

Collected Steps per Second: 22,542.79013
Overall Steps per Second: 10,767.19482

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.64504

Cumulative Model Updates: 142,436
Cumulative Timesteps: 1,188,022,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.70006
Policy Entropy: 3.11277
Value Function Loss: 0.00430

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.57472
Value Function Update Magnitude: 0.54600

Collected Steps per Second: 22,902.13315
Overall Steps per Second: 10,804.10837

Timestep Collection Time: 2.18399
Timestep Consumption Time: 2.44555
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.62954

Cumulative Model Updates: 142,442
Cumulative Timesteps: 1,188,072,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1188072410...
Checkpoint 1188072410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.70577
Policy Entropy: 3.10687
Value Function Loss: 0.00395

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.56950
Value Function Update Magnitude: 0.55622

Collected Steps per Second: 22,596.43123
Overall Steps per Second: 10,701.54486

Timestep Collection Time: 2.21371
Timestep Consumption Time: 2.46057
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.67428

Cumulative Model Updates: 142,448
Cumulative Timesteps: 1,188,122,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.17236
Policy Entropy: 3.08654
Value Function Loss: 0.00405

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.56161
Value Function Update Magnitude: 0.55383

Collected Steps per Second: 23,299.89979
Overall Steps per Second: 10,915.28216

Timestep Collection Time: 2.14645
Timestep Consumption Time: 2.43539
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.58183

Cumulative Model Updates: 142,454
Cumulative Timesteps: 1,188,172,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1188172444...
Checkpoint 1188172444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.46436
Policy Entropy: 3.07507
Value Function Loss: 0.00421

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.57941
Value Function Update Magnitude: 0.53784

Collected Steps per Second: 22,854.37603
Overall Steps per Second: 10,702.55281

Timestep Collection Time: 2.18838
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.67309

Cumulative Model Updates: 142,460
Cumulative Timesteps: 1,188,222,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.58300
Policy Entropy: 3.06622
Value Function Loss: 0.00438

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.58495
Value Function Update Magnitude: 0.53581

Collected Steps per Second: 21,666.22373
Overall Steps per Second: 10,381.94965

Timestep Collection Time: 2.30885
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.81836

Cumulative Model Updates: 142,466
Cumulative Timesteps: 1,188,272,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1188272482...
Checkpoint 1188272482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.98263
Policy Entropy: 3.07414
Value Function Loss: 0.00428

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.58118
Value Function Update Magnitude: 0.53502

Collected Steps per Second: 22,922.27270
Overall Steps per Second: 10,615.20669

Timestep Collection Time: 2.18251
Timestep Consumption Time: 2.53036
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.71286

Cumulative Model Updates: 142,472
Cumulative Timesteps: 1,188,322,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.26296
Policy Entropy: 3.07983
Value Function Loss: 0.00421

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.57961
Value Function Update Magnitude: 0.54405

Collected Steps per Second: 23,508.66882
Overall Steps per Second: 10,939.00442

Timestep Collection Time: 2.12722
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.57153

Cumulative Model Updates: 142,478
Cumulative Timesteps: 1,188,372,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1188372518...
Checkpoint 1188372518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.24503
Policy Entropy: 3.08513
Value Function Loss: 0.00412

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.58035
Value Function Update Magnitude: 0.56767

Collected Steps per Second: 23,080.69610
Overall Steps per Second: 10,704.83698

Timestep Collection Time: 2.16701
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.67228

Cumulative Model Updates: 142,484
Cumulative Timesteps: 1,188,422,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,207.05772
Policy Entropy: 3.09032
Value Function Loss: 0.00392

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.57164
Value Function Update Magnitude: 0.54791

Collected Steps per Second: 22,845.98715
Overall Steps per Second: 10,771.20557

Timestep Collection Time: 2.18866
Timestep Consumption Time: 2.45354
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.64219

Cumulative Model Updates: 142,490
Cumulative Timesteps: 1,188,472,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1188472536...
Checkpoint 1188472536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,933.66668
Policy Entropy: 3.08766
Value Function Loss: 0.00386

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.56288
Value Function Update Magnitude: 0.50196

Collected Steps per Second: 22,530.21127
Overall Steps per Second: 10,717.34829

Timestep Collection Time: 2.22040
Timestep Consumption Time: 2.44736
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.66776

Cumulative Model Updates: 142,496
Cumulative Timesteps: 1,188,522,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,375.82517
Policy Entropy: 3.09314
Value Function Loss: 0.00365

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.49280

Collected Steps per Second: 22,710.73008
Overall Steps per Second: 10,630.62932

Timestep Collection Time: 2.20257
Timestep Consumption Time: 2.50289
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.70546

Cumulative Model Updates: 142,502
Cumulative Timesteps: 1,188,572,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1188572584...
Checkpoint 1188572584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.19368
Policy Entropy: 3.08093
Value Function Loss: 0.00374

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.55799
Value Function Update Magnitude: 0.49374

Collected Steps per Second: 23,322.98269
Overall Steps per Second: 10,925.84869

Timestep Collection Time: 2.14441
Timestep Consumption Time: 2.43318
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.57758

Cumulative Model Updates: 142,508
Cumulative Timesteps: 1,188,622,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,298.98298
Policy Entropy: 3.08284
Value Function Loss: 0.00368

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09551
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.49887

Collected Steps per Second: 23,263.62945
Overall Steps per Second: 10,851.27398

Timestep Collection Time: 2.14928
Timestep Consumption Time: 2.45848
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.60775

Cumulative Model Updates: 142,514
Cumulative Timesteps: 1,188,672,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1188672598...
Checkpoint 1188672598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,459.07576
Policy Entropy: 3.08284
Value Function Loss: 0.00364

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.55289
Value Function Update Magnitude: 0.51536

Collected Steps per Second: 23,050.66657
Overall Steps per Second: 10,671.17518

Timestep Collection Time: 2.16931
Timestep Consumption Time: 2.51659
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.68589

Cumulative Model Updates: 142,520
Cumulative Timesteps: 1,188,722,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,135.51204
Policy Entropy: 3.08667
Value Function Loss: 0.00362

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11843
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.50263

Collected Steps per Second: 23,149.14139
Overall Steps per Second: 10,917.20835

Timestep Collection Time: 2.16043
Timestep Consumption Time: 2.42060
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.58102

Cumulative Model Updates: 142,526
Cumulative Timesteps: 1,188,772,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1188772614...
Checkpoint 1188772614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.30935
Policy Entropy: 3.08096
Value Function Loss: 0.00370

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.54734
Value Function Update Magnitude: 0.49235

Collected Steps per Second: 23,075.55037
Overall Steps per Second: 10,810.46420

Timestep Collection Time: 2.16697
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.62552

Cumulative Model Updates: 142,532
Cumulative Timesteps: 1,188,822,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,394.45916
Policy Entropy: 3.06697
Value Function Loss: 0.00392

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.56077
Value Function Update Magnitude: 0.50831

Collected Steps per Second: 23,069.87319
Overall Steps per Second: 10,749.53983

Timestep Collection Time: 2.16828
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.65341

Cumulative Model Updates: 142,538
Cumulative Timesteps: 1,188,872,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1188872640...
Checkpoint 1188872640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.78590
Policy Entropy: 3.06564
Value Function Loss: 0.00379

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.57037
Value Function Update Magnitude: 0.52748

Collected Steps per Second: 22,617.78134
Overall Steps per Second: 10,646.94262

Timestep Collection Time: 2.21074
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.69637

Cumulative Model Updates: 142,544
Cumulative Timesteps: 1,188,922,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.87245
Policy Entropy: 3.05837
Value Function Loss: 0.00418

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.57953
Value Function Update Magnitude: 0.52291

Collected Steps per Second: 22,771.39689
Overall Steps per Second: 10,658.81626

Timestep Collection Time: 2.19705
Timestep Consumption Time: 2.49671
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.69377

Cumulative Model Updates: 142,550
Cumulative Timesteps: 1,188,972,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1188972672...
Checkpoint 1188972672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.93647
Policy Entropy: 3.05119
Value Function Loss: 0.00430

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.58834
Value Function Update Magnitude: 0.53840

Collected Steps per Second: 22,799.93486
Overall Steps per Second: 10,890.68100

Timestep Collection Time: 2.19334
Timestep Consumption Time: 2.39848
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.59182

Cumulative Model Updates: 142,556
Cumulative Timesteps: 1,189,022,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.67046
Policy Entropy: 3.05717
Value Function Loss: 0.00417

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.57719
Value Function Update Magnitude: 0.52825

Collected Steps per Second: 22,648.58414
Overall Steps per Second: 10,599.91744

Timestep Collection Time: 2.20888
Timestep Consumption Time: 2.51078
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.71966

Cumulative Model Updates: 142,562
Cumulative Timesteps: 1,189,072,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1189072708...
Checkpoint 1189072708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.81081
Policy Entropy: 3.07003
Value Function Loss: 0.00403

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.56186
Value Function Update Magnitude: 0.49627

Collected Steps per Second: 22,708.80192
Overall Steps per Second: 10,588.64161

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.52035
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.72223

Cumulative Model Updates: 142,568
Cumulative Timesteps: 1,189,122,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.75494
Policy Entropy: 3.07984
Value Function Loss: 0.00398

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.49765

Collected Steps per Second: 23,243.54303
Overall Steps per Second: 10,881.49910

Timestep Collection Time: 2.15200
Timestep Consumption Time: 2.44480
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.59679

Cumulative Model Updates: 142,574
Cumulative Timesteps: 1,189,172,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1189172730...
Checkpoint 1189172730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.98561
Policy Entropy: 3.07229
Value Function Loss: 0.00409

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11652
Policy Update Magnitude: 0.56599
Value Function Update Magnitude: 0.51298

Collected Steps per Second: 23,101.42923
Overall Steps per Second: 10,709.29646

Timestep Collection Time: 2.16489
Timestep Consumption Time: 2.50507
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.66996

Cumulative Model Updates: 142,580
Cumulative Timesteps: 1,189,222,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,857.81484
Policy Entropy: 3.08101
Value Function Loss: 0.00392

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10708
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.52188

Collected Steps per Second: 23,264.38372
Overall Steps per Second: 10,741.30348

Timestep Collection Time: 2.15007
Timestep Consumption Time: 2.50672
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.65679

Cumulative Model Updates: 142,586
Cumulative Timesteps: 1,189,272,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1189272762...
Checkpoint 1189272762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.26042
Policy Entropy: 3.09563
Value Function Loss: 0.00373

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.51277

Collected Steps per Second: 22,968.13437
Overall Steps per Second: 10,733.57734

Timestep Collection Time: 2.17806
Timestep Consumption Time: 2.48264
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.66070

Cumulative Model Updates: 142,592
Cumulative Timesteps: 1,189,322,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.65349
Policy Entropy: 3.09343
Value Function Loss: 0.00388

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.55039
Value Function Update Magnitude: 0.51027

Collected Steps per Second: 22,930.23371
Overall Steps per Second: 10,809.73734

Timestep Collection Time: 2.18105
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.62657

Cumulative Model Updates: 142,598
Cumulative Timesteps: 1,189,372,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1189372800...
Checkpoint 1189372800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.59732
Policy Entropy: 3.07680
Value Function Loss: 0.00416

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.55729
Value Function Update Magnitude: 0.53791

Collected Steps per Second: 22,358.58332
Overall Steps per Second: 10,586.08772

Timestep Collection Time: 2.23690
Timestep Consumption Time: 2.48760
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.72450

Cumulative Model Updates: 142,604
Cumulative Timesteps: 1,189,422,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,357.78639
Policy Entropy: 3.08308
Value Function Loss: 0.00424

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.56367
Value Function Update Magnitude: 0.52634

Collected Steps per Second: 22,716.31164
Overall Steps per Second: 10,738.62164

Timestep Collection Time: 2.20159
Timestep Consumption Time: 2.45562
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.65721

Cumulative Model Updates: 142,610
Cumulative Timesteps: 1,189,472,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1189472826...
Checkpoint 1189472826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.90006
Policy Entropy: 3.09396
Value Function Loss: 0.00400

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.51138

Collected Steps per Second: 22,623.76928
Overall Steps per Second: 10,640.94721

Timestep Collection Time: 2.21104
Timestep Consumption Time: 2.48986
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.70090

Cumulative Model Updates: 142,616
Cumulative Timesteps: 1,189,522,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.67610
Policy Entropy: 3.09470
Value Function Loss: 0.00432

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.56631
Value Function Update Magnitude: 0.51102

Collected Steps per Second: 22,864.84370
Overall Steps per Second: 10,799.36804

Timestep Collection Time: 2.18781
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.63212

Cumulative Model Updates: 142,622
Cumulative Timesteps: 1,189,572,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1189572872...
Checkpoint 1189572872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,564.00687
Policy Entropy: 3.07128
Value Function Loss: 0.00443

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.57459
Value Function Update Magnitude: 0.49977

Collected Steps per Second: 23,176.11979
Overall Steps per Second: 10,817.44351

Timestep Collection Time: 2.15860
Timestep Consumption Time: 2.46615
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.62475

Cumulative Model Updates: 142,628
Cumulative Timesteps: 1,189,622,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.88516
Policy Entropy: 3.05190
Value Function Loss: 0.00474

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.58382
Value Function Update Magnitude: 0.51400

Collected Steps per Second: 23,063.25332
Overall Steps per Second: 10,755.05698

Timestep Collection Time: 2.16908
Timestep Consumption Time: 2.48232
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.65139

Cumulative Model Updates: 142,634
Cumulative Timesteps: 1,189,672,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1189672926...
Checkpoint 1189672926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252.19842
Policy Entropy: 3.05027
Value Function Loss: 0.00459

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.58893
Value Function Update Magnitude: 0.52380

Collected Steps per Second: 22,896.30994
Overall Steps per Second: 10,679.31895

Timestep Collection Time: 2.18376
Timestep Consumption Time: 2.49819
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.68195

Cumulative Model Updates: 142,640
Cumulative Timesteps: 1,189,722,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.34921
Policy Entropy: 3.05127
Value Function Loss: 0.00432

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.53448

Collected Steps per Second: 23,186.00872
Overall Steps per Second: 10,972.35141

Timestep Collection Time: 2.15673
Timestep Consumption Time: 2.40072
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.55746

Cumulative Model Updates: 142,646
Cumulative Timesteps: 1,189,772,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1189772932...
Checkpoint 1189772932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.83885
Policy Entropy: 3.04630
Value Function Loss: 0.00453

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.58371
Value Function Update Magnitude: 0.52060

Collected Steps per Second: 23,142.04590
Overall Steps per Second: 10,708.26208

Timestep Collection Time: 2.16109
Timestep Consumption Time: 2.50932
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.67041

Cumulative Model Updates: 142,652
Cumulative Timesteps: 1,189,822,944

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.57840
Policy Entropy: 3.04339
Value Function Loss: 0.00442

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.58796
Value Function Update Magnitude: 0.51196

Collected Steps per Second: 23,192.45841
Overall Steps per Second: 10,851.59554

Timestep Collection Time: 2.15656
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.60909

Cumulative Model Updates: 142,658
Cumulative Timesteps: 1,189,872,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1189872960...
Checkpoint 1189872960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,419.35742
Policy Entropy: 3.03476
Value Function Loss: 0.00438

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.59101
Value Function Update Magnitude: 0.52161

Collected Steps per Second: 22,859.35999
Overall Steps per Second: 10,626.97066

Timestep Collection Time: 2.18764
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.70576

Cumulative Model Updates: 142,664
Cumulative Timesteps: 1,189,922,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.34271
Policy Entropy: 3.04178
Value Function Loss: 0.00437

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.59754
Value Function Update Magnitude: 0.55731

Collected Steps per Second: 22,788.28497
Overall Steps per Second: 10,870.47743

Timestep Collection Time: 2.19516
Timestep Consumption Time: 2.40666
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60182

Cumulative Model Updates: 142,670
Cumulative Timesteps: 1,189,972,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1189972992...
Checkpoint 1189972992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.96937
Policy Entropy: 3.03418
Value Function Loss: 0.00463

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.60343
Value Function Update Magnitude: 0.59601

Collected Steps per Second: 22,619.11676
Overall Steps per Second: 10,664.96041

Timestep Collection Time: 2.21070
Timestep Consumption Time: 2.47793
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.68863

Cumulative Model Updates: 142,676
Cumulative Timesteps: 1,190,022,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.04590
Policy Entropy: 3.03705
Value Function Loss: 0.00470

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.60312
Value Function Update Magnitude: 0.58059

Collected Steps per Second: 22,726.28056
Overall Steps per Second: 10,812.60061

Timestep Collection Time: 2.20133
Timestep Consumption Time: 2.42550
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.62682

Cumulative Model Updates: 142,682
Cumulative Timesteps: 1,190,073,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1190073024...
Checkpoint 1190073024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.78170
Policy Entropy: 3.04428
Value Function Loss: 0.00460

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.58827
Value Function Update Magnitude: 0.54623

Collected Steps per Second: 22,846.89543
Overall Steps per Second: 10,755.76399

Timestep Collection Time: 2.18971
Timestep Consumption Time: 2.46157
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.65127

Cumulative Model Updates: 142,688
Cumulative Timesteps: 1,190,123,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.89418
Policy Entropy: 3.05204
Value Function Loss: 0.00425

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.57515
Value Function Update Magnitude: 0.51634

Collected Steps per Second: 23,105.94443
Overall Steps per Second: 10,782.26701

Timestep Collection Time: 2.16498
Timestep Consumption Time: 2.47449
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.63947

Cumulative Model Updates: 142,694
Cumulative Timesteps: 1,190,173,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1190173076...
Checkpoint 1190173076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,271.02257
Policy Entropy: 3.05882
Value Function Loss: 0.00416

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.49330

Collected Steps per Second: 22,890.68025
Overall Steps per Second: 10,778.24711

Timestep Collection Time: 2.18482
Timestep Consumption Time: 2.45527
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.64009

Cumulative Model Updates: 142,700
Cumulative Timesteps: 1,190,223,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,452.70837
Policy Entropy: 3.06391
Value Function Loss: 0.00424

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.57534
Value Function Update Magnitude: 0.52319

Collected Steps per Second: 23,433.72252
Overall Steps per Second: 10,865.67513

Timestep Collection Time: 2.13436
Timestep Consumption Time: 2.46876
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.60312

Cumulative Model Updates: 142,706
Cumulative Timesteps: 1,190,273,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1190273104...
Checkpoint 1190273104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847.93630
Policy Entropy: 3.06657
Value Function Loss: 0.00402

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.57978
Value Function Update Magnitude: 0.55101

Collected Steps per Second: 23,087.36425
Overall Steps per Second: 10,665.32926

Timestep Collection Time: 2.16569
Timestep Consumption Time: 2.52240
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.68809

Cumulative Model Updates: 142,712
Cumulative Timesteps: 1,190,323,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.33036
Policy Entropy: 3.06272
Value Function Loss: 0.00453

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.58656
Value Function Update Magnitude: 0.55472

Collected Steps per Second: 23,237.67205
Overall Steps per Second: 10,858.79123

Timestep Collection Time: 2.15254
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.60641

Cumulative Model Updates: 142,718
Cumulative Timesteps: 1,190,373,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1190373124...
Checkpoint 1190373124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,122.76881
Policy Entropy: 3.06718
Value Function Loss: 0.00424

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.58457
Value Function Update Magnitude: 0.54954

Collected Steps per Second: 23,015.85563
Overall Steps per Second: 10,692.10084

Timestep Collection Time: 2.17328
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.67822

Cumulative Model Updates: 142,724
Cumulative Timesteps: 1,190,423,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,806.45292
Policy Entropy: 3.07702
Value Function Loss: 0.00411

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.57199
Value Function Update Magnitude: 0.52228

Collected Steps per Second: 22,424.35525
Overall Steps per Second: 10,555.38661

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.50730
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.73711

Cumulative Model Updates: 142,730
Cumulative Timesteps: 1,190,473,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1190473146...
Checkpoint 1190473146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,535.36584
Policy Entropy: 3.06973
Value Function Loss: 0.00372

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.49718

Collected Steps per Second: 22,926.78274
Overall Steps per Second: 10,900.45911

Timestep Collection Time: 2.18190
Timestep Consumption Time: 2.40726
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.58916

Cumulative Model Updates: 142,736
Cumulative Timesteps: 1,190,523,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,666.70785
Policy Entropy: 3.06321
Value Function Loss: 0.00372

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.49775

Collected Steps per Second: 22,535.12192
Overall Steps per Second: 10,544.14834

Timestep Collection Time: 2.21947
Timestep Consumption Time: 2.52402
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.74348

Cumulative Model Updates: 142,742
Cumulative Timesteps: 1,190,573,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1190573186...
Checkpoint 1190573186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.79446
Policy Entropy: 3.04881
Value Function Loss: 0.00371

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.49338

Collected Steps per Second: 22,100.58496
Overall Steps per Second: 10,614.84355

Timestep Collection Time: 2.26347
Timestep Consumption Time: 2.44918
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.71265

Cumulative Model Updates: 142,748
Cumulative Timesteps: 1,190,623,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.33854
Policy Entropy: 3.05070
Value Function Loss: 0.00385

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.56732
Value Function Update Magnitude: 0.51185

Collected Steps per Second: 22,981.11798
Overall Steps per Second: 10,583.13788

Timestep Collection Time: 2.17570
Timestep Consumption Time: 2.54880
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.72450

Cumulative Model Updates: 142,754
Cumulative Timesteps: 1,190,673,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1190673210...
Checkpoint 1190673210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 952.97361
Policy Entropy: 3.04429
Value Function Loss: 0.00406

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.57607
Value Function Update Magnitude: 0.53853

Collected Steps per Second: 23,157.23444
Overall Steps per Second: 10,957.27798

Timestep Collection Time: 2.16010
Timestep Consumption Time: 2.40508
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.56518

Cumulative Model Updates: 142,760
Cumulative Timesteps: 1,190,723,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800.09383
Policy Entropy: 3.05138
Value Function Loss: 0.00398

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.52582

Collected Steps per Second: 23,320.23787
Overall Steps per Second: 10,964.68103

Timestep Collection Time: 2.14466
Timestep Consumption Time: 2.41671
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.56137

Cumulative Model Updates: 142,766
Cumulative Timesteps: 1,190,773,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1190773246...
Checkpoint 1190773246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,497.80849
Policy Entropy: 3.05336
Value Function Loss: 0.00400

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.57404
Value Function Update Magnitude: 0.50507

Collected Steps per Second: 23,150.66370
Overall Steps per Second: 10,808.17887

Timestep Collection Time: 2.16063
Timestep Consumption Time: 2.46735
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.62798

Cumulative Model Updates: 142,772
Cumulative Timesteps: 1,190,823,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.93934
Policy Entropy: 3.05432
Value Function Loss: 0.00395

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.56585
Value Function Update Magnitude: 0.49160

Collected Steps per Second: 23,014.07525
Overall Steps per Second: 10,713.48892

Timestep Collection Time: 2.17276
Timestep Consumption Time: 2.49463
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.66739

Cumulative Model Updates: 142,778
Cumulative Timesteps: 1,190,873,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1190873270...
Checkpoint 1190873270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.60326
Policy Entropy: 3.06101
Value Function Loss: 0.00399

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.56268
Value Function Update Magnitude: 0.47033

Collected Steps per Second: 22,915.24581
Overall Steps per Second: 10,637.43612

Timestep Collection Time: 2.18222
Timestep Consumption Time: 2.51873
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.70094

Cumulative Model Updates: 142,784
Cumulative Timesteps: 1,190,923,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,555.74635
Policy Entropy: 3.07154
Value Function Loss: 0.00392

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.55553
Value Function Update Magnitude: 0.45152

Collected Steps per Second: 22,629.91611
Overall Steps per Second: 10,831.09848

Timestep Collection Time: 2.20973
Timestep Consumption Time: 2.40716
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.61689

Cumulative Model Updates: 142,790
Cumulative Timesteps: 1,190,973,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1190973282...
Checkpoint 1190973282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.99006
Policy Entropy: 3.07319
Value Function Loss: 0.00376

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.55351
Value Function Update Magnitude: 0.43969

Collected Steps per Second: 22,658.32246
Overall Steps per Second: 10,787.05229

Timestep Collection Time: 2.20696
Timestep Consumption Time: 2.42878
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.63574

Cumulative Model Updates: 142,796
Cumulative Timesteps: 1,191,023,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.46556
Policy Entropy: 3.06462
Value Function Loss: 0.00403

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.56176
Value Function Update Magnitude: 0.46225

Collected Steps per Second: 22,629.06884
Overall Steps per Second: 10,741.59006

Timestep Collection Time: 2.20999
Timestep Consumption Time: 2.44575
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.65574

Cumulative Model Updates: 142,802
Cumulative Timesteps: 1,191,073,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1191073298...
Checkpoint 1191073298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,113.94513
Policy Entropy: 3.04229
Value Function Loss: 0.00420

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.57236
Value Function Update Magnitude: 0.48144

Collected Steps per Second: 23,087.12332
Overall Steps per Second: 10,722.31382

Timestep Collection Time: 2.16571
Timestep Consumption Time: 2.49746
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.66317

Cumulative Model Updates: 142,808
Cumulative Timesteps: 1,191,123,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.83184
Policy Entropy: 3.03127
Value Function Loss: 0.00419

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.57835
Value Function Update Magnitude: 0.49642

Collected Steps per Second: 23,179.33032
Overall Steps per Second: 10,888.76930

Timestep Collection Time: 2.15839
Timestep Consumption Time: 2.43625
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.59464

Cumulative Model Updates: 142,814
Cumulative Timesteps: 1,191,173,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1191173328...
Checkpoint 1191173328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,763.50670
Policy Entropy: 3.04793
Value Function Loss: 0.00414

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.49974

Collected Steps per Second: 22,985.42640
Overall Steps per Second: 10,751.49650

Timestep Collection Time: 2.17616
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.65238

Cumulative Model Updates: 142,820
Cumulative Timesteps: 1,191,223,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.61295
Policy Entropy: 3.05592
Value Function Loss: 0.00397

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10700
Policy Update Magnitude: 0.56686
Value Function Update Magnitude: 0.49047

Collected Steps per Second: 23,231.07618
Overall Steps per Second: 10,864.01387

Timestep Collection Time: 2.15272
Timestep Consumption Time: 2.45055
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.60327

Cumulative Model Updates: 142,826
Cumulative Timesteps: 1,191,273,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1191273358...
Checkpoint 1191273358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.73896
Policy Entropy: 3.06103
Value Function Loss: 0.00370

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.55436
Value Function Update Magnitude: 0.47979

Collected Steps per Second: 23,059.56661
Overall Steps per Second: 10,802.79513

Timestep Collection Time: 2.16864
Timestep Consumption Time: 2.46053
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.62917

Cumulative Model Updates: 142,832
Cumulative Timesteps: 1,191,323,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.84546
Policy Entropy: 3.05098
Value Function Loss: 0.00369

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.55236
Value Function Update Magnitude: 0.46535

Collected Steps per Second: 23,249.66661
Overall Steps per Second: 10,704.43645

Timestep Collection Time: 2.15143
Timestep Consumption Time: 2.52140
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.67283

Cumulative Model Updates: 142,838
Cumulative Timesteps: 1,191,373,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1191373386...
Checkpoint 1191373386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843.72140
Policy Entropy: 3.05736
Value Function Loss: 0.00380

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.55727
Value Function Update Magnitude: 0.45840

Collected Steps per Second: 22,930.44924
Overall Steps per Second: 10,660.18728

Timestep Collection Time: 2.18103
Timestep Consumption Time: 2.51044
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.69147

Cumulative Model Updates: 142,844
Cumulative Timesteps: 1,191,423,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,461.59556
Policy Entropy: 3.05039
Value Function Loss: 0.00411

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.57435
Value Function Update Magnitude: 0.51904

Collected Steps per Second: 22,444.46861
Overall Steps per Second: 10,546.13059

Timestep Collection Time: 2.22799
Timestep Consumption Time: 2.51366
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.74164

Cumulative Model Updates: 142,850
Cumulative Timesteps: 1,191,473,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1191473404...
Checkpoint 1191473404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.08700
Policy Entropy: 3.03844
Value Function Loss: 0.00405

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.57953
Value Function Update Magnitude: 0.56298

Collected Steps per Second: 22,630.51908
Overall Steps per Second: 10,597.40048

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.50913
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.71889

Cumulative Model Updates: 142,856
Cumulative Timesteps: 1,191,523,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.68542
Policy Entropy: 3.03913
Value Function Loss: 0.00407

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.58487
Value Function Update Magnitude: 0.54090

Collected Steps per Second: 22,878.31387
Overall Steps per Second: 10,786.29051

Timestep Collection Time: 2.18574
Timestep Consumption Time: 2.45033
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.63607

Cumulative Model Updates: 142,862
Cumulative Timesteps: 1,191,573,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1191573418...
Checkpoint 1191573418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,893.29166
Policy Entropy: 3.06116
Value Function Loss: 0.00395

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.59191
Value Function Update Magnitude: 0.52240

Collected Steps per Second: 22,668.02685
Overall Steps per Second: 10,672.77855

Timestep Collection Time: 2.20637
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.68613

Cumulative Model Updates: 142,868
Cumulative Timesteps: 1,191,623,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.04179
Policy Entropy: 3.08044
Value Function Loss: 0.00385

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.58834
Value Function Update Magnitude: 0.50567

Collected Steps per Second: 23,038.70134
Overall Steps per Second: 10,640.95771

Timestep Collection Time: 2.17096
Timestep Consumption Time: 2.52937
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.70033

Cumulative Model Updates: 142,874
Cumulative Timesteps: 1,191,673,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1191673448...
Checkpoint 1191673448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.06376
Policy Entropy: 3.08137
Value Function Loss: 0.00368

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.57581
Value Function Update Magnitude: 0.49578

Collected Steps per Second: 23,142.86833
Overall Steps per Second: 10,841.35593

Timestep Collection Time: 2.16144
Timestep Consumption Time: 2.45256
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61400

Cumulative Model Updates: 142,880
Cumulative Timesteps: 1,191,723,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.35443
Policy Entropy: 3.08576
Value Function Loss: 0.00392

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.56930
Value Function Update Magnitude: 0.51690

Collected Steps per Second: 23,169.51477
Overall Steps per Second: 10,742.53574

Timestep Collection Time: 2.15896
Timestep Consumption Time: 2.49748
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.65644

Cumulative Model Updates: 142,886
Cumulative Timesteps: 1,191,773,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1191773492...
Checkpoint 1191773492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,092.84716
Policy Entropy: 3.08760
Value Function Loss: 0.00401

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.57002
Value Function Update Magnitude: 0.54007

Collected Steps per Second: 23,355.06869
Overall Steps per Second: 10,900.06064

Timestep Collection Time: 2.14112
Timestep Consumption Time: 2.44656
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.58768

Cumulative Model Updates: 142,892
Cumulative Timesteps: 1,191,823,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,271.33668
Policy Entropy: 3.08323
Value Function Loss: 0.00442

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.57255
Value Function Update Magnitude: 0.53890

Collected Steps per Second: 23,240.48259
Overall Steps per Second: 10,983.48207

Timestep Collection Time: 2.15245
Timestep Consumption Time: 2.40202
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.55448

Cumulative Model Updates: 142,898
Cumulative Timesteps: 1,191,873,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1191873522...
Checkpoint 1191873522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.83201
Policy Entropy: 3.06646
Value Function Loss: 0.00472

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.58375
Value Function Update Magnitude: 0.52799

Collected Steps per Second: 22,895.21232
Overall Steps per Second: 10,771.33512

Timestep Collection Time: 2.18500
Timestep Consumption Time: 2.45937
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.64436

Cumulative Model Updates: 142,904
Cumulative Timesteps: 1,191,923,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,062.85954
Policy Entropy: 3.05819
Value Function Loss: 0.00457

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.57973
Value Function Update Magnitude: 0.52213

Collected Steps per Second: 22,770.92621
Overall Steps per Second: 10,793.20146

Timestep Collection Time: 2.19622
Timestep Consumption Time: 2.43725
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.63347

Cumulative Model Updates: 142,910
Cumulative Timesteps: 1,191,973,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1191973558...
Checkpoint 1191973558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,255.70396
Policy Entropy: 3.06526
Value Function Loss: 0.00405

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.57242
Value Function Update Magnitude: 0.51208

Collected Steps per Second: 22,662.82791
Overall Steps per Second: 10,583.81303

Timestep Collection Time: 2.20714
Timestep Consumption Time: 2.51895
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.72609

Cumulative Model Updates: 142,916
Cumulative Timesteps: 1,192,023,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.75989
Policy Entropy: 3.07634
Value Function Loss: 0.00376

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.56134
Value Function Update Magnitude: 0.49745

Collected Steps per Second: 22,575.27830
Overall Steps per Second: 10,677.73436

Timestep Collection Time: 2.21623
Timestep Consumption Time: 2.46941
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.68564

Cumulative Model Updates: 142,922
Cumulative Timesteps: 1,192,073,610

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1192073610...
Checkpoint 1192073610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.10920
Policy Entropy: 3.08536
Value Function Loss: 0.00426

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.51099

Collected Steps per Second: 21,684.58600
Overall Steps per Second: 10,422.23535

Timestep Collection Time: 2.30662
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.79916

Cumulative Model Updates: 142,928
Cumulative Timesteps: 1,192,123,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.61074
Policy Entropy: 3.09345
Value Function Loss: 0.00478

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.58725
Value Function Update Magnitude: 0.53174

Collected Steps per Second: 23,293.71967
Overall Steps per Second: 10,689.01064

Timestep Collection Time: 2.14762
Timestep Consumption Time: 2.53252
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.68013

Cumulative Model Updates: 142,934
Cumulative Timesteps: 1,192,173,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1192173654...
Checkpoint 1192173654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,205.71343
Policy Entropy: 3.09207
Value Function Loss: 0.00434

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11156
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.52198

Collected Steps per Second: 23,334.13961
Overall Steps per Second: 10,908.79133

Timestep Collection Time: 2.14278
Timestep Consumption Time: 2.44068
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.58346

Cumulative Model Updates: 142,940
Cumulative Timesteps: 1,192,223,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.79190
Policy Entropy: 3.08612
Value Function Loss: 0.00413

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.57567
Value Function Update Magnitude: 0.52795

Collected Steps per Second: 23,355.48535
Overall Steps per Second: 10,906.08199

Timestep Collection Time: 2.14160
Timestep Consumption Time: 2.44465
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.58625

Cumulative Model Updates: 142,946
Cumulative Timesteps: 1,192,273,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1192273672...
Checkpoint 1192273672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.89609
Policy Entropy: 3.07794
Value Function Loss: 0.00387

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.57164
Value Function Update Magnitude: 0.51085

Collected Steps per Second: 23,296.80004
Overall Steps per Second: 10,797.36409

Timestep Collection Time: 2.14639
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.63113

Cumulative Model Updates: 142,952
Cumulative Timesteps: 1,192,323,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.07910
Policy Entropy: 3.08046
Value Function Loss: 0.00387

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.56425
Value Function Update Magnitude: 0.48857

Collected Steps per Second: 23,490.74103
Overall Steps per Second: 10,845.94606

Timestep Collection Time: 2.12892
Timestep Consumption Time: 2.48202
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.61094

Cumulative Model Updates: 142,958
Cumulative Timesteps: 1,192,373,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1192373686...
Checkpoint 1192373686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.63118
Policy Entropy: 3.07867
Value Function Loss: 0.00376

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.46901

Collected Steps per Second: 23,362.48047
Overall Steps per Second: 10,888.36959

Timestep Collection Time: 2.14130
Timestep Consumption Time: 2.45315
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.59444

Cumulative Model Updates: 142,964
Cumulative Timesteps: 1,192,423,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.31044
Policy Entropy: 3.06980
Value Function Loss: 0.00386

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.57038
Value Function Update Magnitude: 0.46108

Collected Steps per Second: 22,591.78477
Overall Steps per Second: 10,570.95502

Timestep Collection Time: 2.21355
Timestep Consumption Time: 2.51715
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.73070

Cumulative Model Updates: 142,970
Cumulative Timesteps: 1,192,473,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1192473720...
Checkpoint 1192473720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,398.49284
Policy Entropy: 3.07075
Value Function Loss: 0.00371

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.56850
Value Function Update Magnitude: 0.46155

Collected Steps per Second: 22,711.85052
Overall Steps per Second: 10,594.66698

Timestep Collection Time: 2.20255
Timestep Consumption Time: 2.51907
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.72162

Cumulative Model Updates: 142,976
Cumulative Timesteps: 1,192,523,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,518.65837
Policy Entropy: 3.07604
Value Function Loss: 0.00400

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.57637
Value Function Update Magnitude: 0.50622

Collected Steps per Second: 22,757.19529
Overall Steps per Second: 10,830.93887

Timestep Collection Time: 2.19825
Timestep Consumption Time: 2.42056
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.61881

Cumulative Model Updates: 142,982
Cumulative Timesteps: 1,192,573,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1192573770...
Checkpoint 1192573770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,926.65511
Policy Entropy: 3.06803
Value Function Loss: 0.00405

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.57696
Value Function Update Magnitude: 0.54353

Collected Steps per Second: 22,800.94492
Overall Steps per Second: 10,686.84450

Timestep Collection Time: 2.19359
Timestep Consumption Time: 2.48655
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.68015

Cumulative Model Updates: 142,988
Cumulative Timesteps: 1,192,623,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.07914
Policy Entropy: 3.06329
Value Function Loss: 0.00448

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.58636
Value Function Update Magnitude: 0.55019

Collected Steps per Second: 22,924.89644
Overall Steps per Second: 10,715.34828

Timestep Collection Time: 2.18138
Timestep Consumption Time: 2.48557
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.66695

Cumulative Model Updates: 142,994
Cumulative Timesteps: 1,192,673,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1192673794...
Checkpoint 1192673794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,772.40412
Policy Entropy: 3.06319
Value Function Loss: 0.00470

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.60140
Value Function Update Magnitude: 0.56438

Collected Steps per Second: 23,199.17817
Overall Steps per Second: 10,870.29619

Timestep Collection Time: 2.15646
Timestep Consumption Time: 2.44581
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.60227

Cumulative Model Updates: 143,000
Cumulative Timesteps: 1,192,723,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,373.69384
Policy Entropy: 3.06054
Value Function Loss: 0.00460

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.60166
Value Function Update Magnitude: 0.57816

Collected Steps per Second: 23,281.69337
Overall Steps per Second: 10,883.29124

Timestep Collection Time: 2.14941
Timestep Consumption Time: 2.44864
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.59806

Cumulative Model Updates: 143,006
Cumulative Timesteps: 1,192,773,864

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1192773864...
Checkpoint 1192773864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.86149
Policy Entropy: 3.07524
Value Function Loss: 0.00427

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.60085
Value Function Update Magnitude: 0.57207

Collected Steps per Second: 23,098.91773
Overall Steps per Second: 10,762.81801

Timestep Collection Time: 2.16504
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.64655

Cumulative Model Updates: 143,012
Cumulative Timesteps: 1,192,823,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.58415
Policy Entropy: 3.06727
Value Function Loss: 0.00428

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.59619
Value Function Update Magnitude: 0.56742

Collected Steps per Second: 23,175.82824
Overall Steps per Second: 10,829.86904

Timestep Collection Time: 2.15742
Timestep Consumption Time: 2.45944
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.61686

Cumulative Model Updates: 143,018
Cumulative Timesteps: 1,192,873,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1192873874...
Checkpoint 1192873874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.75392
Policy Entropy: 3.06756
Value Function Loss: 0.00452

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.59968
Value Function Update Magnitude: 0.55816

Collected Steps per Second: 23,347.99560
Overall Steps per Second: 11,010.26899

Timestep Collection Time: 2.14271
Timestep Consumption Time: 2.40105
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.54376

Cumulative Model Updates: 143,024
Cumulative Timesteps: 1,192,923,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.66281
Policy Entropy: 3.06063
Value Function Loss: 0.00439

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.58643
Value Function Update Magnitude: 0.56067

Collected Steps per Second: 22,616.64066
Overall Steps per Second: 10,543.11329

Timestep Collection Time: 2.21085
Timestep Consumption Time: 2.53177
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.74262

Cumulative Model Updates: 143,030
Cumulative Timesteps: 1,192,973,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1192973904...
Checkpoint 1192973904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.76485
Policy Entropy: 3.07106
Value Function Loss: 0.00436

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.58452
Value Function Update Magnitude: 0.55414

Collected Steps per Second: 22,809.98549
Overall Steps per Second: 10,701.25790

Timestep Collection Time: 2.19220
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.67272

Cumulative Model Updates: 143,036
Cumulative Timesteps: 1,193,023,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.82688
Policy Entropy: 3.07422
Value Function Loss: 0.00445

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.59839
Value Function Update Magnitude: 0.52729

Collected Steps per Second: 22,594.00604
Overall Steps per Second: 10,769.18929

Timestep Collection Time: 2.21342
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.64380

Cumulative Model Updates: 143,042
Cumulative Timesteps: 1,193,073,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1193073918...
Checkpoint 1193073918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.32457
Policy Entropy: 3.07661
Value Function Loss: 0.00456

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.60637
Value Function Update Magnitude: 0.52840

Collected Steps per Second: 23,226.89830
Overall Steps per Second: 10,729.80126

Timestep Collection Time: 2.15414
Timestep Consumption Time: 2.50895
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.66309

Cumulative Model Updates: 143,048
Cumulative Timesteps: 1,193,123,952

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,994.86236
Policy Entropy: 3.06301
Value Function Loss: 0.00440

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.59787
Value Function Update Magnitude: 0.53993

Collected Steps per Second: 23,210.98827
Overall Steps per Second: 10,825.97252

Timestep Collection Time: 2.15476
Timestep Consumption Time: 2.46506
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.61982

Cumulative Model Updates: 143,054
Cumulative Timesteps: 1,193,173,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1193173966...
Checkpoint 1193173966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.37730
Policy Entropy: 3.08482
Value Function Loss: 0.00406

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.58543
Value Function Update Magnitude: 0.53946

Collected Steps per Second: 23,120.25021
Overall Steps per Second: 10,662.85087

Timestep Collection Time: 2.16356
Timestep Consumption Time: 2.52768
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.69124

Cumulative Model Updates: 143,060
Cumulative Timesteps: 1,193,223,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.55534
Policy Entropy: 3.09521
Value Function Loss: 0.00395

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.57195
Value Function Update Magnitude: 0.51824

Collected Steps per Second: 22,880.66031
Overall Steps per Second: 10,693.92031

Timestep Collection Time: 2.18595
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.67705

Cumulative Model Updates: 143,066
Cumulative Timesteps: 1,193,274,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1193274004...
Checkpoint 1193274004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.97803
Policy Entropy: 3.10019
Value Function Loss: 0.00409

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.51152

Collected Steps per Second: 23,248.17168
Overall Steps per Second: 10,925.37517

Timestep Collection Time: 2.15174
Timestep Consumption Time: 2.42696
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.57870

Cumulative Model Updates: 143,072
Cumulative Timesteps: 1,193,324,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.03130
Policy Entropy: 3.08758
Value Function Loss: 0.00457

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.57543
Value Function Update Magnitude: 0.52660

Collected Steps per Second: 23,240.13424
Overall Steps per Second: 10,877.28354

Timestep Collection Time: 2.15179
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.59747

Cumulative Model Updates: 143,078
Cumulative Timesteps: 1,193,374,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1193374036...
Checkpoint 1193374036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.69572
Policy Entropy: 3.08663
Value Function Loss: 0.00483

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.58791
Value Function Update Magnitude: 0.54522

Collected Steps per Second: 22,588.47340
Overall Steps per Second: 10,684.00327

Timestep Collection Time: 2.21432
Timestep Consumption Time: 2.46726
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.68158

Cumulative Model Updates: 143,084
Cumulative Timesteps: 1,193,424,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.57233
Policy Entropy: 3.07975
Value Function Loss: 0.00444

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.58864
Value Function Update Magnitude: 0.55805

Collected Steps per Second: 22,484.00753
Overall Steps per Second: 10,582.52633

Timestep Collection Time: 2.22594
Timestep Consumption Time: 2.50337
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.72931

Cumulative Model Updates: 143,090
Cumulative Timesteps: 1,193,474,102

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1193474102...
Checkpoint 1193474102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.45329
Policy Entropy: 3.08685
Value Function Loss: 0.00417

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.53352

Collected Steps per Second: 22,773.25735
Overall Steps per Second: 10,883.58832

Timestep Collection Time: 2.19644
Timestep Consumption Time: 2.39947
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.59591

Cumulative Model Updates: 143,096
Cumulative Timesteps: 1,193,524,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.35379
Policy Entropy: 3.08012
Value Function Loss: 0.00400

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.57668
Value Function Update Magnitude: 0.52149

Collected Steps per Second: 23,032.48209
Overall Steps per Second: 10,572.86338

Timestep Collection Time: 2.17102
Timestep Consumption Time: 2.55845
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.72947

Cumulative Model Updates: 143,102
Cumulative Timesteps: 1,193,574,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1193574126...
Checkpoint 1193574126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,342.91397
Policy Entropy: 3.08044
Value Function Loss: 0.00403

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.57827
Value Function Update Magnitude: 0.52023

Collected Steps per Second: 23,083.90502
Overall Steps per Second: 10,651.75705

Timestep Collection Time: 2.16636
Timestep Consumption Time: 2.52845
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.69481

Cumulative Model Updates: 143,108
Cumulative Timesteps: 1,193,624,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.60567
Policy Entropy: 3.10585
Value Function Loss: 0.00403

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.57197
Value Function Update Magnitude: 0.52319

Collected Steps per Second: 23,226.32841
Overall Steps per Second: 10,839.84155

Timestep Collection Time: 2.15368
Timestep Consumption Time: 2.46097
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.61464

Cumulative Model Updates: 143,114
Cumulative Timesteps: 1,193,674,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1193674156...
Checkpoint 1193674156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.06906
Policy Entropy: 3.11553
Value Function Loss: 0.00388

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.56016
Value Function Update Magnitude: 0.51057

Collected Steps per Second: 23,155.10107
Overall Steps per Second: 10,698.60354

Timestep Collection Time: 2.15970
Timestep Consumption Time: 2.51456
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.67425

Cumulative Model Updates: 143,120
Cumulative Timesteps: 1,193,724,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974.50554
Policy Entropy: 3.12210
Value Function Loss: 0.00378

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.49555

Collected Steps per Second: 23,291.88678
Overall Steps per Second: 10,810.11200

Timestep Collection Time: 2.14753
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.62715

Cumulative Model Updates: 143,126
Cumulative Timesteps: 1,193,774,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1193774184...
Checkpoint 1193774184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,346.96972
Policy Entropy: 3.10565
Value Function Loss: 0.00401

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.56334
Value Function Update Magnitude: 0.50088

Collected Steps per Second: 23,224.04048
Overall Steps per Second: 10,818.21448

Timestep Collection Time: 2.15354
Timestep Consumption Time: 2.46958
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.62313

Cumulative Model Updates: 143,132
Cumulative Timesteps: 1,193,824,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.86596
Policy Entropy: 3.09355
Value Function Loss: 0.00406

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.57386
Value Function Update Magnitude: 0.51660

Collected Steps per Second: 23,105.27354
Overall Steps per Second: 10,788.07326

Timestep Collection Time: 2.16409
Timestep Consumption Time: 2.47084
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.63493

Cumulative Model Updates: 143,138
Cumulative Timesteps: 1,193,874,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1193874200...
Checkpoint 1193874200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,096.20479
Policy Entropy: 3.08927
Value Function Loss: 0.00432

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.58357
Value Function Update Magnitude: 0.54721

Collected Steps per Second: 22,852.16391
Overall Steps per Second: 10,639.20157

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.51213
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.70054

Cumulative Model Updates: 143,144
Cumulative Timesteps: 1,193,924,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.56554
Policy Entropy: 3.09303
Value Function Loss: 0.00405

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.58129
Value Function Update Magnitude: 0.55869

Collected Steps per Second: 22,612.08651
Overall Steps per Second: 10,659.27764

Timestep Collection Time: 2.21245
Timestep Consumption Time: 2.48093
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.69338

Cumulative Model Updates: 143,150
Cumulative Timesteps: 1,193,974,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1193974238...
Checkpoint 1193974238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.77148
Policy Entropy: 3.10298
Value Function Loss: 0.00390

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.56362
Value Function Update Magnitude: 0.52766

Collected Steps per Second: 22,651.08477
Overall Steps per Second: 10,769.82029

Timestep Collection Time: 2.20740
Timestep Consumption Time: 2.43520
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.64260

Cumulative Model Updates: 143,156
Cumulative Timesteps: 1,194,024,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.10038
Policy Entropy: 3.10300
Value Function Loss: 0.00378

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.50803

Collected Steps per Second: 22,635.73930
Overall Steps per Second: 10,540.96688

Timestep Collection Time: 2.20943
Timestep Consumption Time: 2.53511
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.74454

Cumulative Model Updates: 143,162
Cumulative Timesteps: 1,194,074,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1194074250...
Checkpoint 1194074250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.45618
Policy Entropy: 3.11643
Value Function Loss: 0.00346

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.54098
Value Function Update Magnitude: 0.48380

Collected Steps per Second: 22,759.47409
Overall Steps per Second: 10,621.60374

Timestep Collection Time: 2.19803
Timestep Consumption Time: 2.51181
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.70983

Cumulative Model Updates: 143,168
Cumulative Timesteps: 1,194,124,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,723.68254
Policy Entropy: 3.11178
Value Function Loss: 0.00386

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.53893
Value Function Update Magnitude: 0.48374

Collected Steps per Second: 23,201.01989
Overall Steps per Second: 10,837.24053

Timestep Collection Time: 2.15577
Timestep Consumption Time: 2.45943
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.61520

Cumulative Model Updates: 143,174
Cumulative Timesteps: 1,194,174,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1194174292...
Checkpoint 1194174292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,585.88706
Policy Entropy: 3.12181
Value Function Loss: 0.00380

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.50413

Collected Steps per Second: 22,929.92253
Overall Steps per Second: 10,749.73250

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.47220
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.65407

Cumulative Model Updates: 143,180
Cumulative Timesteps: 1,194,224,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.77095
Policy Entropy: 3.11252
Value Function Loss: 0.00396

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.55979
Value Function Update Magnitude: 0.51815

Collected Steps per Second: 23,203.92947
Overall Steps per Second: 10,875.32870

Timestep Collection Time: 2.15532
Timestep Consumption Time: 2.44334
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.59867

Cumulative Model Updates: 143,186
Cumulative Timesteps: 1,194,274,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1194274334...
Checkpoint 1194274334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.11283
Policy Entropy: 3.12021
Value Function Loss: 0.00380

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.55650
Value Function Update Magnitude: 0.53834

Collected Steps per Second: 23,114.61190
Overall Steps per Second: 10,692.53141

Timestep Collection Time: 2.16322
Timestep Consumption Time: 2.51313
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.67635

Cumulative Model Updates: 143,192
Cumulative Timesteps: 1,194,324,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.52480
Policy Entropy: 3.11459
Value Function Loss: 0.00422

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.55134

Collected Steps per Second: 22,927.85877
Overall Steps per Second: 10,810.86761

Timestep Collection Time: 2.18093
Timestep Consumption Time: 2.44442
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.62535

Cumulative Model Updates: 143,198
Cumulative Timesteps: 1,194,374,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1194374340...
Checkpoint 1194374340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.78381
Policy Entropy: 3.09879
Value Function Loss: 0.00414

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.57917
Value Function Update Magnitude: 0.57343

Collected Steps per Second: 22,804.55971
Overall Steps per Second: 10,735.22101

Timestep Collection Time: 2.19377
Timestep Consumption Time: 2.46640
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.66017

Cumulative Model Updates: 143,204
Cumulative Timesteps: 1,194,424,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.55981
Policy Entropy: 3.09401
Value Function Loss: 0.00436

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.57897
Value Function Update Magnitude: 0.54944

Collected Steps per Second: 22,779.08579
Overall Steps per Second: 10,843.93385

Timestep Collection Time: 2.19693
Timestep Consumption Time: 2.41800
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.61493

Cumulative Model Updates: 143,210
Cumulative Timesteps: 1,194,474,412

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1194474412...
Checkpoint 1194474412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,215.85862
Policy Entropy: 3.08753
Value Function Loss: 0.00442

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.57490
Value Function Update Magnitude: 0.52153

Collected Steps per Second: 22,690.07063
Overall Steps per Second: 10,686.08189

Timestep Collection Time: 2.20387
Timestep Consumption Time: 2.47567
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.67954

Cumulative Model Updates: 143,216
Cumulative Timesteps: 1,194,524,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.61807
Policy Entropy: 3.07626
Value Function Loss: 0.00486

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.52174

Collected Steps per Second: 22,902.35660
Overall Steps per Second: 10,874.06592

Timestep Collection Time: 2.18432
Timestep Consumption Time: 2.41617
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.60049

Cumulative Model Updates: 143,222
Cumulative Timesteps: 1,194,574,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1194574444...
Checkpoint 1194574444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.62908
Policy Entropy: 3.08023
Value Function Loss: 0.00438

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.52469

Collected Steps per Second: 22,641.89105
Overall Steps per Second: 10,678.72228

Timestep Collection Time: 2.20909
Timestep Consumption Time: 2.47480
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.68389

Cumulative Model Updates: 143,228
Cumulative Timesteps: 1,194,624,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.48573
Policy Entropy: 3.09400
Value Function Loss: 0.00430

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.56732
Value Function Update Magnitude: 0.53203

Collected Steps per Second: 23,387.41763
Overall Steps per Second: 10,915.45988

Timestep Collection Time: 2.13841
Timestep Consumption Time: 2.44334
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.58176

Cumulative Model Updates: 143,234
Cumulative Timesteps: 1,194,674,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1194674474...
Checkpoint 1194674474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.91169
Policy Entropy: 3.10871
Value Function Loss: 0.00371

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.51858

Collected Steps per Second: 23,175.76894
Overall Steps per Second: 10,709.35322

Timestep Collection Time: 2.15803
Timestep Consumption Time: 2.51209
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.67012

Cumulative Model Updates: 143,240
Cumulative Timesteps: 1,194,724,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,265.84667
Policy Entropy: 3.10825
Value Function Loss: 0.00363

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.55317
Value Function Update Magnitude: 0.50873

Collected Steps per Second: 23,189.07671
Overall Steps per Second: 10,814.10172

Timestep Collection Time: 2.15671
Timestep Consumption Time: 2.46800
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.62470

Cumulative Model Updates: 143,246
Cumulative Timesteps: 1,194,774,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1194774500...
Checkpoint 1194774500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.08135
Policy Entropy: 3.09217
Value Function Loss: 0.00385

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.55419
Value Function Update Magnitude: 0.51053

Collected Steps per Second: 23,079.74228
Overall Steps per Second: 10,773.46263

Timestep Collection Time: 2.16701
Timestep Consumption Time: 2.47532
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.64233

Cumulative Model Updates: 143,252
Cumulative Timesteps: 1,194,824,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,855.62136
Policy Entropy: 3.08372
Value Function Loss: 0.00409

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.56318
Value Function Update Magnitude: 0.52240

Collected Steps per Second: 23,384.53978
Overall Steps per Second: 10,789.49176

Timestep Collection Time: 2.13911
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.63618

Cumulative Model Updates: 143,258
Cumulative Timesteps: 1,194,874,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1194874536...
Checkpoint 1194874536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,492.11714
Policy Entropy: 3.07441
Value Function Loss: 0.00435

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11102
Policy Update Magnitude: 0.57962
Value Function Update Magnitude: 0.54133

Collected Steps per Second: 23,048.43878
Overall Steps per Second: 10,770.90821

Timestep Collection Time: 2.16978
Timestep Consumption Time: 2.47328
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.64306

Cumulative Model Updates: 143,264
Cumulative Timesteps: 1,194,924,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,434.04497
Policy Entropy: 3.08003
Value Function Loss: 0.00425

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.58630
Value Function Update Magnitude: 0.55814

Collected Steps per Second: 23,065.50961
Overall Steps per Second: 10,803.70755

Timestep Collection Time: 2.16869
Timestep Consumption Time: 2.46138
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.63008

Cumulative Model Updates: 143,270
Cumulative Timesteps: 1,194,974,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1194974568...
Checkpoint 1194974568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.90752
Policy Entropy: 3.07754
Value Function Loss: 0.00428

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.57595
Value Function Update Magnitude: 0.56452

Collected Steps per Second: 22,462.09611
Overall Steps per Second: 10,616.87539

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.48470
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.71174

Cumulative Model Updates: 143,276
Cumulative Timesteps: 1,195,024,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,683.44379
Policy Entropy: 3.07877
Value Function Loss: 0.00436

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.56624
Value Function Update Magnitude: 0.53964

Collected Steps per Second: 22,687.60290
Overall Steps per Second: 10,620.08729

Timestep Collection Time: 2.20490
Timestep Consumption Time: 2.50541
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.71032

Cumulative Model Updates: 143,282
Cumulative Timesteps: 1,195,074,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1195074616...
Checkpoint 1195074616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,488.34122
Policy Entropy: 3.07227
Value Function Loss: 0.00447

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.55838
Value Function Update Magnitude: 0.50969

Collected Steps per Second: 22,664.66675
Overall Steps per Second: 10,630.48191

Timestep Collection Time: 2.20669
Timestep Consumption Time: 2.49808
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.70477

Cumulative Model Updates: 143,288
Cumulative Timesteps: 1,195,124,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154.93288
Policy Entropy: 3.07419
Value Function Loss: 0.00436

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.55497
Value Function Update Magnitude: 0.49948

Collected Steps per Second: 23,284.27420
Overall Steps per Second: 10,774.91534

Timestep Collection Time: 2.14849
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.64282

Cumulative Model Updates: 143,294
Cumulative Timesteps: 1,195,174,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1195174656...
Checkpoint 1195174656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.29866
Policy Entropy: 3.07468
Value Function Loss: 0.00444

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.56721
Value Function Update Magnitude: 0.50990

Collected Steps per Second: 23,079.30455
Overall Steps per Second: 10,808.52682

Timestep Collection Time: 2.16705
Timestep Consumption Time: 2.46022
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.62727

Cumulative Model Updates: 143,300
Cumulative Timesteps: 1,195,224,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,150.96442
Policy Entropy: 3.06779
Value Function Loss: 0.00407

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.57117
Value Function Update Magnitude: 0.53984

Collected Steps per Second: 23,260.65139
Overall Steps per Second: 10,712.00542

Timestep Collection Time: 2.14990
Timestep Consumption Time: 2.51851
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.66841

Cumulative Model Updates: 143,306
Cumulative Timesteps: 1,195,274,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1195274678...
Checkpoint 1195274678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029.96949
Policy Entropy: 3.07024
Value Function Loss: 0.00367

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.56689
Value Function Update Magnitude: 0.53070

Collected Steps per Second: 23,282.41885
Overall Steps per Second: 10,667.14533

Timestep Collection Time: 2.14814
Timestep Consumption Time: 2.54046
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.68860

Cumulative Model Updates: 143,312
Cumulative Timesteps: 1,195,324,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.29608
Policy Entropy: 3.08705
Value Function Loss: 0.00367

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.55298
Value Function Update Magnitude: 0.51100

Collected Steps per Second: 23,244.17118
Overall Steps per Second: 10,919.37542

Timestep Collection Time: 2.15125
Timestep Consumption Time: 2.42813
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.57938

Cumulative Model Updates: 143,318
Cumulative Timesteps: 1,195,374,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1195374696...
Checkpoint 1195374696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.45615
Policy Entropy: 3.10216
Value Function Loss: 0.00382

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.54534
Value Function Update Magnitude: 0.48629

Collected Steps per Second: 23,025.72823
Overall Steps per Second: 10,661.79641

Timestep Collection Time: 2.17166
Timestep Consumption Time: 2.51836
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.69002

Cumulative Model Updates: 143,324
Cumulative Timesteps: 1,195,424,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,144.33483
Policy Entropy: 3.10438
Value Function Loss: 0.00397

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.54423
Value Function Update Magnitude: 0.47018

Collected Steps per Second: 22,912.60414
Overall Steps per Second: 10,782.94223

Timestep Collection Time: 2.18317
Timestep Consumption Time: 2.45583
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.63899

Cumulative Model Updates: 143,330
Cumulative Timesteps: 1,195,474,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1195474722...
Checkpoint 1195474722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,851.24195
Policy Entropy: 3.08516
Value Function Loss: 0.00406

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.55065
Value Function Update Magnitude: 0.48791

Collected Steps per Second: 22,616.07837
Overall Steps per Second: 10,673.45091

Timestep Collection Time: 2.21099
Timestep Consumption Time: 2.47390
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.68490

Cumulative Model Updates: 143,336
Cumulative Timesteps: 1,195,524,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.64614
Policy Entropy: 3.08958
Value Function Loss: 0.00421

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.55373
Value Function Update Magnitude: 0.51724

Collected Steps per Second: 22,771.82488
Overall Steps per Second: 10,646.99326

Timestep Collection Time: 2.19605
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.69691

Cumulative Model Updates: 143,342
Cumulative Timesteps: 1,195,574,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1195574734...
Checkpoint 1195574734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.57779
Policy Entropy: 3.08747
Value Function Loss: 0.00434

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.55694
Value Function Update Magnitude: 0.52239

Collected Steps per Second: 22,982.36225
Overall Steps per Second: 10,847.30116

Timestep Collection Time: 2.17593
Timestep Consumption Time: 2.43425
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61018

Cumulative Model Updates: 143,348
Cumulative Timesteps: 1,195,624,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,427.33691
Policy Entropy: 3.10130
Value Function Loss: 0.00431

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.55576
Value Function Update Magnitude: 0.52972

Collected Steps per Second: 22,854.37939
Overall Steps per Second: 10,618.63855

Timestep Collection Time: 2.18855
Timestep Consumption Time: 2.52184
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.71040

Cumulative Model Updates: 143,354
Cumulative Timesteps: 1,195,674,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1195674760...
Checkpoint 1195674760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,127.41587
Policy Entropy: 3.08880
Value Function Loss: 0.00421

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.54923
Value Function Update Magnitude: 0.52738

Collected Steps per Second: 22,926.31697
Overall Steps per Second: 10,674.61369

Timestep Collection Time: 2.18212
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.68663

Cumulative Model Updates: 143,360
Cumulative Timesteps: 1,195,724,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,428.28273
Policy Entropy: 3.09603
Value Function Loss: 0.00396

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.53925
Value Function Update Magnitude: 0.49680

Collected Steps per Second: 23,394.86602
Overall Steps per Second: 10,813.77213

Timestep Collection Time: 2.13833
Timestep Consumption Time: 2.48781
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.62614

Cumulative Model Updates: 143,366
Cumulative Timesteps: 1,195,774,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1195774814...
Checkpoint 1195774814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.05965
Policy Entropy: 3.08291
Value Function Loss: 0.00431

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.55297
Value Function Update Magnitude: 0.52812

Collected Steps per Second: 23,112.21828
Overall Steps per Second: 10,830.30911

Timestep Collection Time: 2.16336
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.61667

Cumulative Model Updates: 143,372
Cumulative Timesteps: 1,195,824,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.87982
Policy Entropy: 3.08551
Value Function Loss: 0.00397

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.56497
Value Function Update Magnitude: 0.56262

Collected Steps per Second: 23,306.16455
Overall Steps per Second: 10,699.85094

Timestep Collection Time: 2.14630
Timestep Consumption Time: 2.52872
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.67502

Cumulative Model Updates: 143,378
Cumulative Timesteps: 1,195,874,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1195874836...
Checkpoint 1195874836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,782.89472
Policy Entropy: 3.08453
Value Function Loss: 0.00373

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.56293
Value Function Update Magnitude: 0.56522

Collected Steps per Second: 22,828.15496
Overall Steps per Second: 10,627.51790

Timestep Collection Time: 2.19142
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.70721

Cumulative Model Updates: 143,384
Cumulative Timesteps: 1,195,924,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,434.66637
Policy Entropy: 3.08842
Value Function Loss: 0.00352

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.56187
Value Function Update Magnitude: 0.53689

Collected Steps per Second: 21,751.80454
Overall Steps per Second: 10,389.80769

Timestep Collection Time: 2.29894
Timestep Consumption Time: 2.51405
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.81299

Cumulative Model Updates: 143,390
Cumulative Timesteps: 1,195,974,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1195974868...
Checkpoint 1195974868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561.91452
Policy Entropy: 3.09321
Value Function Loss: 0.00376

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.55835
Value Function Update Magnitude: 0.52094

Collected Steps per Second: 22,363.14208
Overall Steps per Second: 10,687.99709

Timestep Collection Time: 2.23725
Timestep Consumption Time: 2.44389
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.68114

Cumulative Model Updates: 143,396
Cumulative Timesteps: 1,196,024,900

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.79125
Policy Entropy: 3.08842
Value Function Loss: 0.00375

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.55287
Value Function Update Magnitude: 0.53033

Collected Steps per Second: 22,649.29096
Overall Steps per Second: 10,620.64593

Timestep Collection Time: 2.20978
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.71252

Cumulative Model Updates: 143,402
Cumulative Timesteps: 1,196,074,950

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1196074950...
Checkpoint 1196074950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,669.55131
Policy Entropy: 3.09459
Value Function Loss: 0.00367

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.55295
Value Function Update Magnitude: 0.53105

Collected Steps per Second: 22,676.72421
Overall Steps per Second: 10,615.95174

Timestep Collection Time: 2.20499
Timestep Consumption Time: 2.50509
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.71008

Cumulative Model Updates: 143,408
Cumulative Timesteps: 1,196,124,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,016.74631
Policy Entropy: 3.09651
Value Function Loss: 0.00385

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.56513
Value Function Update Magnitude: 0.54426

Collected Steps per Second: 23,021.40583
Overall Steps per Second: 10,819.63258

Timestep Collection Time: 2.17328
Timestep Consumption Time: 2.45090
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.62419

Cumulative Model Updates: 143,414
Cumulative Timesteps: 1,196,174,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1196174984...
Checkpoint 1196174984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.43307
Policy Entropy: 3.09620
Value Function Loss: 0.00433

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.57799
Value Function Update Magnitude: 0.54842

Collected Steps per Second: 22,940.83987
Overall Steps per Second: 10,732.29787

Timestep Collection Time: 2.17978
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.65939

Cumulative Model Updates: 143,420
Cumulative Timesteps: 1,196,224,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.89498
Policy Entropy: 3.09713
Value Function Loss: 0.00451

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.57888
Value Function Update Magnitude: 0.54204

Collected Steps per Second: 23,154.62423
Overall Steps per Second: 10,772.79474

Timestep Collection Time: 2.15966
Timestep Consumption Time: 2.48222
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.64188

Cumulative Model Updates: 143,426
Cumulative Timesteps: 1,196,274,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1196274996...
Checkpoint 1196274996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212.94187
Policy Entropy: 3.09475
Value Function Loss: 0.00424

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.56069
Value Function Update Magnitude: 0.51560

Collected Steps per Second: 23,029.89204
Overall Steps per Second: 10,649.36767

Timestep Collection Time: 2.17213
Timestep Consumption Time: 2.52523
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.69737

Cumulative Model Updates: 143,432
Cumulative Timesteps: 1,196,325,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,792.54822
Policy Entropy: 3.09761
Value Function Loss: 0.00416

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.51067

Collected Steps per Second: 23,572.64837
Overall Steps per Second: 10,944.55526

Timestep Collection Time: 2.12119
Timestep Consumption Time: 2.44748
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.56866

Cumulative Model Updates: 143,438
Cumulative Timesteps: 1,196,375,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1196375022...
Checkpoint 1196375022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.17216
Policy Entropy: 3.08917
Value Function Loss: 0.00433

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.57418
Value Function Update Magnitude: 0.53649

Collected Steps per Second: 22,763.18430
Overall Steps per Second: 10,686.31917

Timestep Collection Time: 2.19776
Timestep Consumption Time: 2.48374
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.68150

Cumulative Model Updates: 143,444
Cumulative Timesteps: 1,196,425,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.05008
Policy Entropy: 3.09919
Value Function Loss: 0.00419

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.57678
Value Function Update Magnitude: 0.56116

Collected Steps per Second: 23,307.70052
Overall Steps per Second: 10,889.43715

Timestep Collection Time: 2.14556
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.59234

Cumulative Model Updates: 143,450
Cumulative Timesteps: 1,196,475,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1196475058...
Checkpoint 1196475058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.54246
Policy Entropy: 3.10210
Value Function Loss: 0.00406

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.56411
Value Function Update Magnitude: 0.53648

Collected Steps per Second: 22,614.64253
Overall Steps per Second: 10,594.97299

Timestep Collection Time: 2.21211
Timestep Consumption Time: 2.50957
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.72167

Cumulative Model Updates: 143,456
Cumulative Timesteps: 1,196,525,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.57962
Policy Entropy: 3.09772
Value Function Loss: 0.00385

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.55850
Value Function Update Magnitude: 0.51918

Collected Steps per Second: 23,025.41949
Overall Steps per Second: 10,846.10201

Timestep Collection Time: 2.17195
Timestep Consumption Time: 2.43893
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61087

Cumulative Model Updates: 143,462
Cumulative Timesteps: 1,196,575,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1196575094...
Checkpoint 1196575094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.57565
Policy Entropy: 3.08814
Value Function Loss: 0.00393

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.50532

Collected Steps per Second: 22,278.55032
Overall Steps per Second: 10,678.19684

Timestep Collection Time: 2.24431
Timestep Consumption Time: 2.43813
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.68244

Cumulative Model Updates: 143,468
Cumulative Timesteps: 1,196,625,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.86852
Policy Entropy: 3.07204
Value Function Loss: 0.00428

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.56951
Value Function Update Magnitude: 0.50158

Collected Steps per Second: 22,714.30546
Overall Steps per Second: 10,615.10161

Timestep Collection Time: 2.20205
Timestep Consumption Time: 2.50992
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.71197

Cumulative Model Updates: 143,474
Cumulative Timesteps: 1,196,675,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1196675112...
Checkpoint 1196675112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,375.45099
Policy Entropy: 3.09606
Value Function Loss: 0.00413

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.56087
Value Function Update Magnitude: 0.51569

Collected Steps per Second: 23,069.65607
Overall Steps per Second: 10,605.72595

Timestep Collection Time: 2.16839
Timestep Consumption Time: 2.54831
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.71670

Cumulative Model Updates: 143,480
Cumulative Timesteps: 1,196,725,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,962.18753
Policy Entropy: 3.09503
Value Function Loss: 0.00445

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.57360
Value Function Update Magnitude: 0.54271

Collected Steps per Second: 23,117.92174
Overall Steps per Second: 10,821.68544

Timestep Collection Time: 2.16300
Timestep Consumption Time: 2.45772
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.62072

Cumulative Model Updates: 143,486
Cumulative Timesteps: 1,196,775,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1196775140...
Checkpoint 1196775140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,202.18018
Policy Entropy: 3.08611
Value Function Loss: 0.00421

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10569
Policy Update Magnitude: 0.58363
Value Function Update Magnitude: 0.55452

Collected Steps per Second: 22,703.04151
Overall Steps per Second: 10,624.29250

Timestep Collection Time: 2.20358
Timestep Consumption Time: 2.50525
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.70883

Cumulative Model Updates: 143,492
Cumulative Timesteps: 1,196,825,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.72602
Policy Entropy: 3.06192
Value Function Loss: 0.00427

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.58290
Value Function Update Magnitude: 0.56364

Collected Steps per Second: 23,170.41073
Overall Steps per Second: 10,934.10888

Timestep Collection Time: 2.15879
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.57468

Cumulative Model Updates: 143,498
Cumulative Timesteps: 1,196,875,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1196875188...
Checkpoint 1196875188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.30581
Policy Entropy: 3.07855
Value Function Loss: 0.00397

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.57587
Value Function Update Magnitude: 0.54995

Collected Steps per Second: 22,992.59756
Overall Steps per Second: 10,775.41135

Timestep Collection Time: 2.17592
Timestep Consumption Time: 2.46706
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.64298

Cumulative Model Updates: 143,504
Cumulative Timesteps: 1,196,925,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,261.06695
Policy Entropy: 3.10097
Value Function Loss: 0.00374

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12086
Policy Update Magnitude: 0.56069
Value Function Update Magnitude: 0.50450

Collected Steps per Second: 23,580.12589
Overall Steps per Second: 10,734.62642

Timestep Collection Time: 2.12077
Timestep Consumption Time: 2.53780
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.65857

Cumulative Model Updates: 143,510
Cumulative Timesteps: 1,196,975,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1196975226...
Checkpoint 1196975226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,312.69866
Policy Entropy: 3.11375
Value Function Loss: 0.00359

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.47193

Collected Steps per Second: 22,442.64853
Overall Steps per Second: 10,638.53907

Timestep Collection Time: 2.22879
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.70177

Cumulative Model Updates: 143,516
Cumulative Timesteps: 1,197,025,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.29761
Policy Entropy: 3.09927
Value Function Loss: 0.00355

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.54438
Value Function Update Magnitude: 0.46684

Collected Steps per Second: 22,870.67386
Overall Steps per Second: 10,676.28939

Timestep Collection Time: 2.18656
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.68402

Cumulative Model Updates: 143,522
Cumulative Timesteps: 1,197,075,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1197075254...
Checkpoint 1197075254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,092.41651
Policy Entropy: 3.10149
Value Function Loss: 0.00335

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.47325

Collected Steps per Second: 22,754.26927
Overall Steps per Second: 10,667.60694

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.49049
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.68859

Cumulative Model Updates: 143,528
Cumulative Timesteps: 1,197,125,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.15451
Policy Entropy: 3.08299
Value Function Loss: 0.00390

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.48250

Collected Steps per Second: 23,328.04270
Overall Steps per Second: 10,768.10201

Timestep Collection Time: 2.14454
Timestep Consumption Time: 2.50140
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.64594

Cumulative Model Updates: 143,534
Cumulative Timesteps: 1,197,175,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1197175298...
Checkpoint 1197175298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.68773
Policy Entropy: 3.08301
Value Function Loss: 0.00412

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.56097
Value Function Update Magnitude: 0.49939

Collected Steps per Second: 22,939.06757
Overall Steps per Second: 10,628.41819

Timestep Collection Time: 2.18004
Timestep Consumption Time: 2.52509
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.70512

Cumulative Model Updates: 143,540
Cumulative Timesteps: 1,197,225,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.88425
Policy Entropy: 3.07090
Value Function Loss: 0.00424

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.50483

Collected Steps per Second: 23,140.29619
Overall Steps per Second: 10,854.97885

Timestep Collection Time: 2.16212
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.60913

Cumulative Model Updates: 143,546
Cumulative Timesteps: 1,197,275,338

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1197275338...
Checkpoint 1197275338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.42447
Policy Entropy: 3.07242
Value Function Loss: 0.00407

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.57472
Value Function Update Magnitude: 0.51662

Collected Steps per Second: 22,992.21082
Overall Steps per Second: 10,773.87775

Timestep Collection Time: 2.17595
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.64364

Cumulative Model Updates: 143,552
Cumulative Timesteps: 1,197,325,368

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.15505
Policy Entropy: 3.07127
Value Function Loss: 0.00417

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10410
Policy Update Magnitude: 0.59103
Value Function Update Magnitude: 0.53049

Collected Steps per Second: 23,520.51374
Overall Steps per Second: 10,758.18810

Timestep Collection Time: 2.12631
Timestep Consumption Time: 2.52242
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.64874

Cumulative Model Updates: 143,558
Cumulative Timesteps: 1,197,375,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1197375380...
Checkpoint 1197375380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.57093
Policy Entropy: 3.06279
Value Function Loss: 0.00443

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.59857
Value Function Update Magnitude: 0.52742

Collected Steps per Second: 22,995.36496
Overall Steps per Second: 10,688.23495

Timestep Collection Time: 2.17444
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.67823

Cumulative Model Updates: 143,564
Cumulative Timesteps: 1,197,425,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.62024
Policy Entropy: 3.06395
Value Function Loss: 0.00458

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.59253
Value Function Update Magnitude: 0.52416

Collected Steps per Second: 23,239.43957
Overall Steps per Second: 10,865.50421

Timestep Collection Time: 2.15169
Timestep Consumption Time: 2.45040
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.60209

Cumulative Model Updates: 143,570
Cumulative Timesteps: 1,197,475,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1197475386...
Checkpoint 1197475386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.48580
Policy Entropy: 3.05331
Value Function Loss: 0.00468

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.59414
Value Function Update Magnitude: 0.54051

Collected Steps per Second: 22,579.71481
Overall Steps per Second: 10,608.15867

Timestep Collection Time: 2.21455
Timestep Consumption Time: 2.49918
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.71373

Cumulative Model Updates: 143,576
Cumulative Timesteps: 1,197,525,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.89205
Policy Entropy: 3.06004
Value Function Loss: 0.00467

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.60046
Value Function Update Magnitude: 0.55393

Collected Steps per Second: 22,915.95912
Overall Steps per Second: 10,880.64781

Timestep Collection Time: 2.18241
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.59642

Cumulative Model Updates: 143,582
Cumulative Timesteps: 1,197,575,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1197575402...
Checkpoint 1197575402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.40461
Policy Entropy: 3.06290
Value Function Loss: 0.00443

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.54950

Collected Steps per Second: 22,505.18600
Overall Steps per Second: 10,703.48064

Timestep Collection Time: 2.22295
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.67399

Cumulative Model Updates: 143,588
Cumulative Timesteps: 1,197,625,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.99904
Policy Entropy: 3.05883
Value Function Loss: 0.00422

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.59974
Value Function Update Magnitude: 0.55796

Collected Steps per Second: 22,741.10756
Overall Steps per Second: 10,827.91474

Timestep Collection Time: 2.19998
Timestep Consumption Time: 2.42048
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.62046

Cumulative Model Updates: 143,594
Cumulative Timesteps: 1,197,675,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1197675460...
Checkpoint 1197675460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.49806
Policy Entropy: 3.06942
Value Function Loss: 0.00422

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.59343
Value Function Update Magnitude: 0.54512

Collected Steps per Second: 22,870.31928
Overall Steps per Second: 10,714.16573

Timestep Collection Time: 2.18659
Timestep Consumption Time: 2.48088
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.66747

Cumulative Model Updates: 143,600
Cumulative Timesteps: 1,197,725,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.94131
Policy Entropy: 3.07010
Value Function Loss: 0.00447

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.59088
Value Function Update Magnitude: 0.52766

Collected Steps per Second: 23,543.14218
Overall Steps per Second: 10,878.82906

Timestep Collection Time: 2.12478
Timestep Consumption Time: 2.47351
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.59829

Cumulative Model Updates: 143,606
Cumulative Timesteps: 1,197,775,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1197775492...
Checkpoint 1197775492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.09092
Policy Entropy: 3.07248
Value Function Loss: 0.00477

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.58386
Value Function Update Magnitude: 0.52120

Collected Steps per Second: 22,872.78650
Overall Steps per Second: 10,699.81098

Timestep Collection Time: 2.18670
Timestep Consumption Time: 2.48777
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.67448

Cumulative Model Updates: 143,612
Cumulative Timesteps: 1,197,825,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.69622
Policy Entropy: 3.05761
Value Function Loss: 0.00486

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.59098
Value Function Update Magnitude: 0.53195

Collected Steps per Second: 23,489.44461
Overall Steps per Second: 10,847.08825

Timestep Collection Time: 2.12981
Timestep Consumption Time: 2.48231
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.61211

Cumulative Model Updates: 143,618
Cumulative Timesteps: 1,197,875,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1197875536...
Checkpoint 1197875536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.64350
Policy Entropy: 3.05937
Value Function Loss: 0.00459

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.55927

Collected Steps per Second: 22,861.51188
Overall Steps per Second: 10,710.13588

Timestep Collection Time: 2.18787
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.67016

Cumulative Model Updates: 143,624
Cumulative Timesteps: 1,197,925,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.27036
Policy Entropy: 3.05864
Value Function Loss: 0.00434

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.58549
Value Function Update Magnitude: 0.56480

Collected Steps per Second: 23,323.56838
Overall Steps per Second: 10,927.78632

Timestep Collection Time: 2.14375
Timestep Consumption Time: 2.43174
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.57549

Cumulative Model Updates: 143,630
Cumulative Timesteps: 1,197,975,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1197975554...
Checkpoint 1197975554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,054.00763
Policy Entropy: 3.08067
Value Function Loss: 0.00404

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10541
Policy Update Magnitude: 0.57060
Value Function Update Magnitude: 0.53507

Collected Steps per Second: 22,347.01281
Overall Steps per Second: 10,582.38231

Timestep Collection Time: 2.23779
Timestep Consumption Time: 2.48780
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.72559

Cumulative Model Updates: 143,636
Cumulative Timesteps: 1,198,025,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.02377
Policy Entropy: 3.09152
Value Function Loss: 0.00426

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.53343

Collected Steps per Second: 22,669.72029
Overall Steps per Second: 10,643.50276

Timestep Collection Time: 2.20664
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.69996

Cumulative Model Updates: 143,642
Cumulative Timesteps: 1,198,075,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1198075586...
Checkpoint 1198075586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.50103
Policy Entropy: 3.10391
Value Function Loss: 0.00407

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.55325

Collected Steps per Second: 22,576.70901
Overall Steps per Second: 10,652.34868

Timestep Collection Time: 2.21511
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.69474

Cumulative Model Updates: 143,648
Cumulative Timesteps: 1,198,125,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060.41690
Policy Entropy: 3.08015
Value Function Loss: 0.00403

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.56881
Value Function Update Magnitude: 0.54401

Collected Steps per Second: 23,009.13543
Overall Steps per Second: 10,715.25873

Timestep Collection Time: 2.17375
Timestep Consumption Time: 2.49399
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.66774

Cumulative Model Updates: 143,654
Cumulative Timesteps: 1,198,175,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1198175612...
Checkpoint 1198175612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.39593
Policy Entropy: 3.06806
Value Function Loss: 0.00431

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.57763
Value Function Update Magnitude: 0.53978

Collected Steps per Second: 22,872.27931
Overall Steps per Second: 10,630.27460

Timestep Collection Time: 2.18719
Timestep Consumption Time: 2.51880
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.70599

Cumulative Model Updates: 143,660
Cumulative Timesteps: 1,198,225,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.91663
Policy Entropy: 3.06075
Value Function Loss: 0.00453

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.58973
Value Function Update Magnitude: 0.55730

Collected Steps per Second: 23,097.98877
Overall Steps per Second: 10,787.97205

Timestep Collection Time: 2.16564
Timestep Consumption Time: 2.47119
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.63683

Cumulative Model Updates: 143,666
Cumulative Timesteps: 1,198,275,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1198275660...
Checkpoint 1198275660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.71638
Policy Entropy: 3.05958
Value Function Loss: 0.00462

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.59603
Value Function Update Magnitude: 0.56305

Collected Steps per Second: 23,056.02221
Overall Steps per Second: 10,746.33078

Timestep Collection Time: 2.17054
Timestep Consumption Time: 2.48631
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.65685

Cumulative Model Updates: 143,672
Cumulative Timesteps: 1,198,325,704

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.97160
Policy Entropy: 3.07108
Value Function Loss: 0.00418

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.53058

Collected Steps per Second: 23,271.26917
Overall Steps per Second: 10,860.43209

Timestep Collection Time: 2.14874
Timestep Consumption Time: 2.45549
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.60424

Cumulative Model Updates: 143,678
Cumulative Timesteps: 1,198,375,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1198375708...
Checkpoint 1198375708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.82569
Policy Entropy: 3.04977
Value Function Loss: 0.00420

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.58357
Value Function Update Magnitude: 0.50400

Collected Steps per Second: 22,986.80869
Overall Steps per Second: 10,718.15152

Timestep Collection Time: 2.17551
Timestep Consumption Time: 2.49022
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.66573

Cumulative Model Updates: 143,684
Cumulative Timesteps: 1,198,425,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.52685
Policy Entropy: 3.04513
Value Function Loss: 0.00425

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.59257
Value Function Update Magnitude: 0.49846

Collected Steps per Second: 23,494.03406
Overall Steps per Second: 10,834.40471

Timestep Collection Time: 2.12863
Timestep Consumption Time: 2.48723
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.61585

Cumulative Model Updates: 143,690
Cumulative Timesteps: 1,198,475,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1198475726...
Checkpoint 1198475726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.76730
Policy Entropy: 3.03174
Value Function Loss: 0.00464

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.59287
Value Function Update Magnitude: 0.52963

Collected Steps per Second: 23,249.39752
Overall Steps per Second: 10,834.17212

Timestep Collection Time: 2.15145
Timestep Consumption Time: 2.46542
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.61687

Cumulative Model Updates: 143,696
Cumulative Timesteps: 1,198,525,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.47910
Policy Entropy: 3.04605
Value Function Loss: 0.00475

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.60694
Value Function Update Magnitude: 0.51997

Collected Steps per Second: 22,907.08389
Overall Steps per Second: 10,799.67700

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.44802
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.63162

Cumulative Model Updates: 143,702
Cumulative Timesteps: 1,198,575,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1198575766...
Checkpoint 1198575766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.30417
Policy Entropy: 3.04224
Value Function Loss: 0.00524

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.63080
Value Function Update Magnitude: 0.54746

Collected Steps per Second: 22,616.88492
Overall Steps per Second: 10,675.60548

Timestep Collection Time: 2.21136
Timestep Consumption Time: 2.47353
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.68489

Cumulative Model Updates: 143,708
Cumulative Timesteps: 1,198,625,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,795.55073
Policy Entropy: 3.04702
Value Function Loss: 0.00509

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.62220
Value Function Update Magnitude: 0.57687

Collected Steps per Second: 22,731.75048
Overall Steps per Second: 10,819.10507

Timestep Collection Time: 2.20027
Timestep Consumption Time: 2.42266
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.62293

Cumulative Model Updates: 143,714
Cumulative Timesteps: 1,198,675,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1198675796...
Checkpoint 1198675796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.41408
Policy Entropy: 3.04074
Value Function Loss: 0.00484

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.60633
Value Function Update Magnitude: 0.57086

Collected Steps per Second: 22,611.39409
Overall Steps per Second: 10,642.73676

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.70048

Cumulative Model Updates: 143,720
Cumulative Timesteps: 1,198,725,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.54989
Policy Entropy: 3.05440
Value Function Loss: 0.00456

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.59678
Value Function Update Magnitude: 0.55428

Collected Steps per Second: 23,557.05722
Overall Steps per Second: 10,914.03183

Timestep Collection Time: 2.12268
Timestep Consumption Time: 2.45895
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.58162

Cumulative Model Updates: 143,726
Cumulative Timesteps: 1,198,775,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1198775826...
Checkpoint 1198775826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.66827
Policy Entropy: 3.04805
Value Function Loss: 0.00435

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.59588
Value Function Update Magnitude: 0.56662

Collected Steps per Second: 22,863.65521
Overall Steps per Second: 10,723.08408

Timestep Collection Time: 2.18731
Timestep Consumption Time: 2.47646
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.66377

Cumulative Model Updates: 143,732
Cumulative Timesteps: 1,198,825,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.41796
Policy Entropy: 3.07276
Value Function Loss: 0.00421

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.58623
Value Function Update Magnitude: 0.53939

Collected Steps per Second: 23,325.04984
Overall Steps per Second: 10,814.83615

Timestep Collection Time: 2.14430
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.62476

Cumulative Model Updates: 143,738
Cumulative Timesteps: 1,198,875,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1198875852...
Checkpoint 1198875852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,147.31896
Policy Entropy: 3.06460
Value Function Loss: 0.00417

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.58205
Value Function Update Magnitude: 0.51547

Collected Steps per Second: 23,192.94523
Overall Steps per Second: 10,829.26339

Timestep Collection Time: 2.15643
Timestep Consumption Time: 2.46198
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.61841

Cumulative Model Updates: 143,744
Cumulative Timesteps: 1,198,925,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.69127
Policy Entropy: 3.08567
Value Function Loss: 0.00385

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.57668
Value Function Update Magnitude: 0.52730

Collected Steps per Second: 23,370.57531
Overall Steps per Second: 10,719.47367

Timestep Collection Time: 2.13987
Timestep Consumption Time: 2.52547
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.66534

Cumulative Model Updates: 143,750
Cumulative Timesteps: 1,198,975,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1198975876...
Checkpoint 1198975876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,167.51611
Policy Entropy: 3.08070
Value Function Loss: 0.00347

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.51695

Collected Steps per Second: 22,622.25926
Overall Steps per Second: 10,651.19369

Timestep Collection Time: 2.21030
Timestep Consumption Time: 2.48420
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.69450

Cumulative Model Updates: 143,756
Cumulative Timesteps: 1,199,025,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,648.51191
Policy Entropy: 3.08416
Value Function Loss: 0.00365

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.50613

Collected Steps per Second: 22,660.13681
Overall Steps per Second: 10,609.97584

Timestep Collection Time: 2.20767
Timestep Consumption Time: 2.50733
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.71500

Cumulative Model Updates: 143,762
Cumulative Timesteps: 1,199,075,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1199075904...
Checkpoint 1199075904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.08220
Policy Entropy: 3.06344
Value Function Loss: 0.00412

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.58937
Value Function Update Magnitude: 0.55583

Collected Steps per Second: 22,694.13781
Overall Steps per Second: 10,630.97733

Timestep Collection Time: 2.20339
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.70361

Cumulative Model Updates: 143,768
Cumulative Timesteps: 1,199,125,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.16508
Policy Entropy: 3.06701
Value Function Loss: 0.00423

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.59148
Value Function Update Magnitude: 0.56168

Collected Steps per Second: 22,950.13140
Overall Steps per Second: 10,745.41613

Timestep Collection Time: 2.17890
Timestep Consumption Time: 2.47481
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.65371

Cumulative Model Updates: 143,774
Cumulative Timesteps: 1,199,175,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1199175914...
Checkpoint 1199175914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.11845
Policy Entropy: 3.05993
Value Function Loss: 0.00418

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.58266
Value Function Update Magnitude: 0.58044

Collected Steps per Second: 22,802.02214
Overall Steps per Second: 10,699.57536

Timestep Collection Time: 2.19296
Timestep Consumption Time: 2.48049
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.67346

Cumulative Model Updates: 143,780
Cumulative Timesteps: 1,199,225,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.27444
Policy Entropy: 3.07215
Value Function Loss: 0.00406

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.57643
Value Function Update Magnitude: 0.56364

Collected Steps per Second: 23,306.94424
Overall Steps per Second: 10,817.87195

Timestep Collection Time: 2.14623
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.62401

Cumulative Model Updates: 143,786
Cumulative Timesteps: 1,199,275,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1199275940...
Checkpoint 1199275940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,622.85902
Policy Entropy: 3.07304
Value Function Loss: 0.00444

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.58570
Value Function Update Magnitude: 0.54599

Collected Steps per Second: 23,021.31749
Overall Steps per Second: 10,647.55816

Timestep Collection Time: 2.17199
Timestep Consumption Time: 2.52411
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.69610

Cumulative Model Updates: 143,792
Cumulative Timesteps: 1,199,325,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.16195
Policy Entropy: 3.09173
Value Function Loss: 0.00472

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.59547
Value Function Update Magnitude: 0.57251

Collected Steps per Second: 23,290.14427
Overall Steps per Second: 10,910.18629

Timestep Collection Time: 2.14760
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.58452

Cumulative Model Updates: 143,798
Cumulative Timesteps: 1,199,375,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1199375960...
Checkpoint 1199375960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.08428
Policy Entropy: 3.09665
Value Function Loss: 0.00448

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.59669
Value Function Update Magnitude: 0.55634

Collected Steps per Second: 22,795.57391
Overall Steps per Second: 10,672.73311

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.49292
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.68765

Cumulative Model Updates: 143,804
Cumulative Timesteps: 1,199,425,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.79596
Policy Entropy: 3.09046
Value Function Loss: 0.00461

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.59417
Value Function Update Magnitude: 0.55816

Collected Steps per Second: 23,065.52617
Overall Steps per Second: 10,895.42213

Timestep Collection Time: 2.16921
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.59220

Cumulative Model Updates: 143,810
Cumulative Timesteps: 1,199,476,024

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1199476024...
Checkpoint 1199476024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.80663
Policy Entropy: 3.08332
Value Function Loss: 0.00454

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.59504
Value Function Update Magnitude: 0.54554

Collected Steps per Second: 22,897.30665
Overall Steps per Second: 10,622.04761

Timestep Collection Time: 2.18471
Timestep Consumption Time: 2.52474
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.70945

Cumulative Model Updates: 143,816
Cumulative Timesteps: 1,199,526,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,206.14200
Policy Entropy: 3.08958
Value Function Loss: 0.00482

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.59649
Value Function Update Magnitude: 0.53982

Collected Steps per Second: 22,838.55445
Overall Steps per Second: 10,666.81861

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.49925
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.68950

Cumulative Model Updates: 143,822
Cumulative Timesteps: 1,199,576,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1199576070...
Checkpoint 1199576070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.80648
Policy Entropy: 3.08248
Value Function Loss: 0.00469

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.59278
Value Function Update Magnitude: 0.53250

Collected Steps per Second: 22,538.45045
Overall Steps per Second: 10,849.20595

Timestep Collection Time: 2.21861
Timestep Consumption Time: 2.39039
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.60900

Cumulative Model Updates: 143,828
Cumulative Timesteps: 1,199,626,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,349.63669
Policy Entropy: 3.08679
Value Function Loss: 0.00443

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.59151
Value Function Update Magnitude: 0.51647

Collected Steps per Second: 22,846.78654
Overall Steps per Second: 10,654.91505

Timestep Collection Time: 2.18875
Timestep Consumption Time: 2.50448
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.69323

Cumulative Model Updates: 143,834
Cumulative Timesteps: 1,199,676,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1199676080...
Checkpoint 1199676080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.68183
Policy Entropy: 3.07960
Value Function Loss: 0.00422

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.58837
Value Function Update Magnitude: 0.50551

Collected Steps per Second: 22,592.12203
Overall Steps per Second: 10,600.57016

Timestep Collection Time: 2.21467
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.71993

Cumulative Model Updates: 143,840
Cumulative Timesteps: 1,199,726,114

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.88002
Policy Entropy: 3.08728
Value Function Loss: 0.00438

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.58898
Value Function Update Magnitude: 0.52140

Collected Steps per Second: 22,919.77456
Overall Steps per Second: 10,846.09798

Timestep Collection Time: 2.18248
Timestep Consumption Time: 2.42950
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.61198

Cumulative Model Updates: 143,846
Cumulative Timesteps: 1,199,776,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1199776136...
Checkpoint 1199776136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.24716
Policy Entropy: 3.10364
Value Function Loss: 0.00431

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.58170
Value Function Update Magnitude: 0.54033

Collected Steps per Second: 21,867.66891
Overall Steps per Second: 10,278.63067

Timestep Collection Time: 2.28730
Timestep Consumption Time: 2.57891
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.86621

Cumulative Model Updates: 143,852
Cumulative Timesteps: 1,199,826,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.02133
Policy Entropy: 3.10732
Value Function Loss: 0.00452

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.58223
Value Function Update Magnitude: 0.53627

Collected Steps per Second: 23,116.55484
Overall Steps per Second: 10,790.44614

Timestep Collection Time: 2.16313
Timestep Consumption Time: 2.47097
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.63410

Cumulative Model Updates: 143,858
Cumulative Timesteps: 1,199,876,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1199876158...
Checkpoint 1199876158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.12344
Policy Entropy: 3.11096
Value Function Loss: 0.00439

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.57873
Value Function Update Magnitude: 0.53944

Collected Steps per Second: 22,887.94117
Overall Steps per Second: 10,633.86969

Timestep Collection Time: 2.18491
Timestep Consumption Time: 2.51780
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.70271

Cumulative Model Updates: 143,864
Cumulative Timesteps: 1,199,926,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.69812
Policy Entropy: 3.10409
Value Function Loss: 0.00434

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.53882

Collected Steps per Second: 23,350.26058
Overall Steps per Second: 10,901.00885

Timestep Collection Time: 2.14225
Timestep Consumption Time: 2.44650
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.58875

Cumulative Model Updates: 143,870
Cumulative Timesteps: 1,199,976,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1199976188...
Checkpoint 1199976188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.05028
Policy Entropy: 3.10615
Value Function Loss: 0.00422

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.57267
Value Function Update Magnitude: 0.52685

Collected Steps per Second: 23,084.48075
Overall Steps per Second: 10,685.70092

Timestep Collection Time: 2.16682
Timestep Consumption Time: 2.51420
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.68102

Cumulative Model Updates: 143,876
Cumulative Timesteps: 1,200,026,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885.98514
Policy Entropy: 3.10259
Value Function Loss: 0.00436

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.57414
Value Function Update Magnitude: 0.53419

Collected Steps per Second: 23,499.90149
Overall Steps per Second: 10,879.21588

Timestep Collection Time: 2.12775
Timestep Consumption Time: 2.46835
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.59610

Cumulative Model Updates: 143,882
Cumulative Timesteps: 1,200,076,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1200076210...
Checkpoint 1200076210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,131.58818
Policy Entropy: 3.10034
Value Function Loss: 0.00447

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.58181
Value Function Update Magnitude: 0.55252

Collected Steps per Second: 22,722.30699
Overall Steps per Second: 10,666.15856

Timestep Collection Time: 2.20145
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.68979

Cumulative Model Updates: 143,888
Cumulative Timesteps: 1,200,126,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,362.29109
Policy Entropy: 3.09702
Value Function Loss: 0.00427

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.58607
Value Function Update Magnitude: 0.56510

Collected Steps per Second: 22,688.14518
Overall Steps per Second: 10,831.02198

Timestep Collection Time: 2.20485
Timestep Consumption Time: 2.41373
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61859

Cumulative Model Updates: 143,894
Cumulative Timesteps: 1,200,176,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1200176256...
Checkpoint 1200176256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,058.77793
Policy Entropy: 3.09330
Value Function Loss: 0.00403

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.58143
Value Function Update Magnitude: 0.54800

Collected Steps per Second: 22,821.82612
Overall Steps per Second: 10,709.45251

Timestep Collection Time: 2.19150
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.67008

Cumulative Model Updates: 143,900
Cumulative Timesteps: 1,200,226,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.03800
Policy Entropy: 3.09246
Value Function Loss: 0.00371

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.51832

Collected Steps per Second: 23,292.91422
Overall Steps per Second: 10,800.93147

Timestep Collection Time: 2.14761
Timestep Consumption Time: 2.48385
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.63145

Cumulative Model Updates: 143,906
Cumulative Timesteps: 1,200,276,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1200276294...
Checkpoint 1200276294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.31364
Policy Entropy: 3.08517
Value Function Loss: 0.00418

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.56595
Value Function Update Magnitude: 0.49914

Collected Steps per Second: 23,302.01806
Overall Steps per Second: 10,718.50582

Timestep Collection Time: 2.14574
Timestep Consumption Time: 2.51909
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.66483

Cumulative Model Updates: 143,912
Cumulative Timesteps: 1,200,326,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.06578
Policy Entropy: 3.08220
Value Function Loss: 0.00443

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.57701
Value Function Update Magnitude: 0.51464

Collected Steps per Second: 23,217.28560
Overall Steps per Second: 10,897.97486

Timestep Collection Time: 2.15365
Timestep Consumption Time: 2.43454
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.58819

Cumulative Model Updates: 143,918
Cumulative Timesteps: 1,200,376,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1200376296...
Checkpoint 1200376296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.73759
Policy Entropy: 3.08366
Value Function Loss: 0.00457

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.57674
Value Function Update Magnitude: 0.53490

Collected Steps per Second: 23,097.53880
Overall Steps per Second: 10,827.73018

Timestep Collection Time: 2.16560
Timestep Consumption Time: 2.45402
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.61962

Cumulative Model Updates: 143,924
Cumulative Timesteps: 1,200,426,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,186.04614
Policy Entropy: 3.08860
Value Function Loss: 0.00440

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.56717
Value Function Update Magnitude: 0.52138

Collected Steps per Second: 23,297.54356
Overall Steps per Second: 10,747.67553

Timestep Collection Time: 2.14632
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.65254

Cumulative Model Updates: 143,930
Cumulative Timesteps: 1,200,476,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1200476320...
Checkpoint 1200476320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,304.96581
Policy Entropy: 3.08235
Value Function Loss: 0.00425

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.50176

Collected Steps per Second: 23,021.47941
Overall Steps per Second: 10,680.82530

Timestep Collection Time: 2.17241
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.68241

Cumulative Model Updates: 143,936
Cumulative Timesteps: 1,200,526,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.25901
Policy Entropy: 3.08937
Value Function Loss: 0.00445

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.50740

Collected Steps per Second: 22,665.48845
Overall Steps per Second: 10,780.63486

Timestep Collection Time: 2.20706
Timestep Consumption Time: 2.43312
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.64017

Cumulative Model Updates: 143,942
Cumulative Timesteps: 1,200,576,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1200576356...
Checkpoint 1200576356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.40367
Policy Entropy: 3.08933
Value Function Loss: 0.00409

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.58104
Value Function Update Magnitude: 0.51435

Collected Steps per Second: 22,749.08723
Overall Steps per Second: 10,722.77593

Timestep Collection Time: 2.19912
Timestep Consumption Time: 2.46646
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.66558

Cumulative Model Updates: 143,948
Cumulative Timesteps: 1,200,626,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.27154
Policy Entropy: 3.09670
Value Function Loss: 0.00405

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.57397
Value Function Update Magnitude: 0.51244

Collected Steps per Second: 23,089.92496
Overall Steps per Second: 10,908.88575

Timestep Collection Time: 2.16631
Timestep Consumption Time: 2.41894
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.58525

Cumulative Model Updates: 143,954
Cumulative Timesteps: 1,200,676,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1200676404...
Checkpoint 1200676404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.50856
Policy Entropy: 3.09117
Value Function Loss: 0.00386

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.57126
Value Function Update Magnitude: 0.53652

Collected Steps per Second: 22,881.92244
Overall Steps per Second: 10,708.80186

Timestep Collection Time: 2.18539
Timestep Consumption Time: 2.48422
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.66962

Cumulative Model Updates: 143,960
Cumulative Timesteps: 1,200,726,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.07619
Policy Entropy: 3.08334
Value Function Loss: 0.00410

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.53117

Collected Steps per Second: 22,988.72975
Overall Steps per Second: 10,818.15498

Timestep Collection Time: 2.17567
Timestep Consumption Time: 2.44766
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.62334

Cumulative Model Updates: 143,966
Cumulative Timesteps: 1,200,776,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1200776426...
Checkpoint 1200776426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.62791
Policy Entropy: 3.08561
Value Function Loss: 0.00415

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.57868
Value Function Update Magnitude: 0.53517

Collected Steps per Second: 23,060.66265
Overall Steps per Second: 10,694.86281

Timestep Collection Time: 2.16845
Timestep Consumption Time: 2.50725
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.67570

Cumulative Model Updates: 143,972
Cumulative Timesteps: 1,200,826,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.24096
Policy Entropy: 3.06398
Value Function Loss: 0.00453

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.58940
Value Function Update Magnitude: 0.54749

Collected Steps per Second: 23,147.69064
Overall Steps per Second: 10,906.11782

Timestep Collection Time: 2.16047
Timestep Consumption Time: 2.42503
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.58550

Cumulative Model Updates: 143,978
Cumulative Timesteps: 1,200,876,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1200876442...
Checkpoint 1200876442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.55797
Policy Entropy: 3.06708
Value Function Loss: 0.00464

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.60497
Value Function Update Magnitude: 0.58622

Collected Steps per Second: 23,270.59515
Overall Steps per Second: 10,874.41256

Timestep Collection Time: 2.14949
Timestep Consumption Time: 2.45029
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.59979

Cumulative Model Updates: 143,984
Cumulative Timesteps: 1,200,926,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,924.91979
Policy Entropy: 3.07074
Value Function Loss: 0.00460

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.60644
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 23,520.19701
Overall Steps per Second: 11,025.01265

Timestep Collection Time: 2.12600
Timestep Consumption Time: 2.40950
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.53550

Cumulative Model Updates: 143,990
Cumulative Timesteps: 1,200,976,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1200976466...
Checkpoint 1200976466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.61840
Policy Entropy: 3.09473
Value Function Loss: 0.00438

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.59362
Value Function Update Magnitude: 0.57894

Collected Steps per Second: 23,011.00479
Overall Steps per Second: 10,731.70271

Timestep Collection Time: 2.17409
Timestep Consumption Time: 2.48761
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.66170

Cumulative Model Updates: 143,996
Cumulative Timesteps: 1,201,026,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,038.82672
Policy Entropy: 3.09431
Value Function Loss: 0.00429

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.57854
Value Function Update Magnitude: 0.56931

Collected Steps per Second: 22,895.52954
Overall Steps per Second: 10,846.45298

Timestep Collection Time: 2.18427
Timestep Consumption Time: 2.42645
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.61072

Cumulative Model Updates: 144,002
Cumulative Timesteps: 1,201,076,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1201076504...
Checkpoint 1201076504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.22699
Policy Entropy: 3.07837
Value Function Loss: 0.00411

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.58141
Value Function Update Magnitude: 0.55319

Collected Steps per Second: 22,728.04445
Overall Steps per Second: 10,700.04647

Timestep Collection Time: 2.19993
Timestep Consumption Time: 2.47295
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.67288

Cumulative Model Updates: 144,008
Cumulative Timesteps: 1,201,126,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.33283
Policy Entropy: 3.07199
Value Function Loss: 0.00419

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.58215
Value Function Update Magnitude: 0.53291

Collected Steps per Second: 22,678.75765
Overall Steps per Second: 10,833.48738

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.41148
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.61698

Cumulative Model Updates: 144,014
Cumulative Timesteps: 1,201,176,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1201176522...
Checkpoint 1201176522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.29398
Policy Entropy: 3.07331
Value Function Loss: 0.00409

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.57666
Value Function Update Magnitude: 0.50657

Collected Steps per Second: 23,086.70385
Overall Steps per Second: 10,732.80161

Timestep Collection Time: 2.16618
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.65955

Cumulative Model Updates: 144,020
Cumulative Timesteps: 1,201,226,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.78842
Policy Entropy: 3.08601
Value Function Loss: 0.00403

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.57518
Value Function Update Magnitude: 0.51967

Collected Steps per Second: 23,358.67414
Overall Steps per Second: 10,848.82595

Timestep Collection Time: 2.14113
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.61008

Cumulative Model Updates: 144,026
Cumulative Timesteps: 1,201,276,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1201276546...
Checkpoint 1201276546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.48797
Policy Entropy: 3.07831
Value Function Loss: 0.00393

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.57791
Value Function Update Magnitude: 0.55063

Collected Steps per Second: 23,238.82679
Overall Steps per Second: 10,800.35569

Timestep Collection Time: 2.15183
Timestep Consumption Time: 2.47820
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.63003

Cumulative Model Updates: 144,032
Cumulative Timesteps: 1,201,326,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,689.31344
Policy Entropy: 3.06192
Value Function Loss: 0.00439

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.58712
Value Function Update Magnitude: 0.56358

Collected Steps per Second: 23,049.64866
Overall Steps per Second: 10,788.29951

Timestep Collection Time: 2.17053
Timestep Consumption Time: 2.46690
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.63743

Cumulative Model Updates: 144,038
Cumulative Timesteps: 1,201,376,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1201376582...
Checkpoint 1201376582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.11570
Policy Entropy: 3.05864
Value Function Loss: 0.00446

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.59723
Value Function Update Magnitude: 0.57702

Collected Steps per Second: 23,089.29399
Overall Steps per Second: 10,825.45782

Timestep Collection Time: 2.16637
Timestep Consumption Time: 2.45422
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.62059

Cumulative Model Updates: 144,044
Cumulative Timesteps: 1,201,426,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,639.73992
Policy Entropy: 3.06299
Value Function Loss: 0.00472

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.59706
Value Function Update Magnitude: 0.58337

Collected Steps per Second: 22,963.18335
Overall Steps per Second: 10,708.85844

Timestep Collection Time: 2.17862
Timestep Consumption Time: 2.49303
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.67165

Cumulative Model Updates: 144,050
Cumulative Timesteps: 1,201,476,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1201476630...
Checkpoint 1201476630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.33428
Policy Entropy: 3.07603
Value Function Loss: 0.00419

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.59118
Value Function Update Magnitude: 0.55321

Collected Steps per Second: 22,738.33818
Overall Steps per Second: 10,671.94348

Timestep Collection Time: 2.19972
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.68687

Cumulative Model Updates: 144,056
Cumulative Timesteps: 1,201,526,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.30420
Policy Entropy: 3.06932
Value Function Loss: 0.00416

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.58878
Value Function Update Magnitude: 0.53274

Collected Steps per Second: 22,710.49978
Overall Steps per Second: 10,839.37814

Timestep Collection Time: 2.20268
Timestep Consumption Time: 2.41234
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61502

Cumulative Model Updates: 144,062
Cumulative Timesteps: 1,201,576,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1201576672...
Checkpoint 1201576672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.63293
Policy Entropy: 3.06582
Value Function Loss: 0.00468

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.59883
Value Function Update Magnitude: 0.54567

Collected Steps per Second: 22,634.11660
Overall Steps per Second: 10,708.05780

Timestep Collection Time: 2.20958
Timestep Consumption Time: 2.46092
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.67050

Cumulative Model Updates: 144,068
Cumulative Timesteps: 1,201,626,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,796.80244
Policy Entropy: 3.06727
Value Function Loss: 0.00449

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.58909
Value Function Update Magnitude: 0.56137

Collected Steps per Second: 23,110.12737
Overall Steps per Second: 10,905.70022

Timestep Collection Time: 2.16390
Timestep Consumption Time: 2.42159
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.58549

Cumulative Model Updates: 144,074
Cumulative Timesteps: 1,201,676,692

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1201676692...
Checkpoint 1201676692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.32469
Policy Entropy: 3.05832
Value Function Loss: 0.00474

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.58303
Value Function Update Magnitude: 0.55281

Collected Steps per Second: 23,102.02906
Overall Steps per Second: 10,613.65539

Timestep Collection Time: 2.16449
Timestep Consumption Time: 2.54680
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.71129

Cumulative Model Updates: 144,080
Cumulative Timesteps: 1,201,726,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.07979
Policy Entropy: 3.05989
Value Function Loss: 0.00423

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.58421
Value Function Update Magnitude: 0.54568

Collected Steps per Second: 22,914.85413
Overall Steps per Second: 10,851.71016

Timestep Collection Time: 2.18225
Timestep Consumption Time: 2.42587
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.60812

Cumulative Model Updates: 144,086
Cumulative Timesteps: 1,201,776,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1201776702...
Checkpoint 1201776702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278.08467
Policy Entropy: 3.06116
Value Function Loss: 0.00421

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.57961
Value Function Update Magnitude: 0.56010

Collected Steps per Second: 23,175.70772
Overall Steps per Second: 10,779.02334

Timestep Collection Time: 2.15804
Timestep Consumption Time: 2.48190
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.63994

Cumulative Model Updates: 144,092
Cumulative Timesteps: 1,201,826,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,937.31258
Policy Entropy: 3.07581
Value Function Loss: 0.00411

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.57636
Value Function Update Magnitude: 0.55497

Collected Steps per Second: 23,087.80378
Overall Steps per Second: 10,856.79923

Timestep Collection Time: 2.16608
Timestep Consumption Time: 2.44025
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.60633

Cumulative Model Updates: 144,098
Cumulative Timesteps: 1,201,876,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1201876726...
Checkpoint 1201876726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.41219
Policy Entropy: 3.06401
Value Function Loss: 0.00430

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.58542
Value Function Update Magnitude: 0.56405

Collected Steps per Second: 23,172.42591
Overall Steps per Second: 10,710.66463

Timestep Collection Time: 2.15895
Timestep Consumption Time: 2.51191
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.67086

Cumulative Model Updates: 144,104
Cumulative Timesteps: 1,201,926,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.20211
Policy Entropy: 3.07148
Value Function Loss: 0.00392

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.57828
Value Function Update Magnitude: 0.55532

Collected Steps per Second: 23,007.93628
Overall Steps per Second: 10,828.53722

Timestep Collection Time: 2.17421
Timestep Consumption Time: 2.44544
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61965

Cumulative Model Updates: 144,110
Cumulative Timesteps: 1,201,976,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1201976778...
Checkpoint 1201976778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,882.29877
Policy Entropy: 3.05462
Value Function Loss: 0.00417

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.53455

Collected Steps per Second: 22,976.11050
Overall Steps per Second: 10,775.12387

Timestep Collection Time: 2.17696
Timestep Consumption Time: 2.46503
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.64199

Cumulative Model Updates: 144,116
Cumulative Timesteps: 1,202,026,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,950.41034
Policy Entropy: 3.05988
Value Function Loss: 0.00387

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.52851

Collected Steps per Second: 22,811.24757
Overall Steps per Second: 10,784.95991

Timestep Collection Time: 2.19322
Timestep Consumption Time: 2.44565
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.63887

Cumulative Model Updates: 144,122
Cumulative Timesteps: 1,202,076,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1202076826...
Checkpoint 1202076826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.47264
Policy Entropy: 3.04248
Value Function Loss: 0.00403

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.57265
Value Function Update Magnitude: 0.52269

Collected Steps per Second: 22,514.48783
Overall Steps per Second: 10,662.95726

Timestep Collection Time: 2.22150
Timestep Consumption Time: 2.46913
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.69063

Cumulative Model Updates: 144,128
Cumulative Timesteps: 1,202,126,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.54111
Policy Entropy: 3.04835
Value Function Loss: 0.00394

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.56909
Value Function Update Magnitude: 0.53082

Collected Steps per Second: 22,680.65337
Overall Steps per Second: 10,848.62351

Timestep Collection Time: 2.20558
Timestep Consumption Time: 2.40551
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.61109

Cumulative Model Updates: 144,134
Cumulative Timesteps: 1,202,176,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1202176866...
Checkpoint 1202176866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.14709
Policy Entropy: 3.03158
Value Function Loss: 0.00407

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.58334
Value Function Update Magnitude: 0.54912

Collected Steps per Second: 22,737.74170
Overall Steps per Second: 10,685.19342

Timestep Collection Time: 2.20066
Timestep Consumption Time: 2.48227
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.68293

Cumulative Model Updates: 144,140
Cumulative Timesteps: 1,202,226,904

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.73085
Policy Entropy: 3.03421
Value Function Loss: 0.00416

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.59253
Value Function Update Magnitude: 0.55222

Collected Steps per Second: 23,114.23244
Overall Steps per Second: 10,804.24393

Timestep Collection Time: 2.16386
Timestep Consumption Time: 2.46543
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62929

Cumulative Model Updates: 144,146
Cumulative Timesteps: 1,202,276,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1202276920...
Checkpoint 1202276920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.35530
Policy Entropy: 3.04493
Value Function Loss: 0.00427

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10776
Policy Update Magnitude: 0.59203
Value Function Update Magnitude: 0.55242

Collected Steps per Second: 23,214.25239
Overall Steps per Second: 10,774.64068

Timestep Collection Time: 2.15394
Timestep Consumption Time: 2.48678
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.64071

Cumulative Model Updates: 144,152
Cumulative Timesteps: 1,202,326,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.36252
Policy Entropy: 3.05983
Value Function Loss: 0.00443

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.58311
Value Function Update Magnitude: 0.55746

Collected Steps per Second: 23,277.21628
Overall Steps per Second: 10,876.22696

Timestep Collection Time: 2.14854
Timestep Consumption Time: 2.44975
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.59829

Cumulative Model Updates: 144,158
Cumulative Timesteps: 1,202,376,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1202376934...
Checkpoint 1202376934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,242.23696
Policy Entropy: 3.06513
Value Function Loss: 0.00453

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.58310
Value Function Update Magnitude: 0.55798

Collected Steps per Second: 23,018.57662
Overall Steps per Second: 10,749.04628

Timestep Collection Time: 2.17303
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.65344

Cumulative Model Updates: 144,164
Cumulative Timesteps: 1,202,426,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.40971
Policy Entropy: 3.06605
Value Function Loss: 0.00431

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.58263
Value Function Update Magnitude: 0.56099

Collected Steps per Second: 23,359.98226
Overall Steps per Second: 10,784.07147

Timestep Collection Time: 2.14101
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.63777

Cumulative Model Updates: 144,170
Cumulative Timesteps: 1,202,476,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1202476968...
Checkpoint 1202476968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.43643
Policy Entropy: 3.05713
Value Function Loss: 0.00440

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.58490
Value Function Update Magnitude: 0.55669

Collected Steps per Second: 23,158.41703
Overall Steps per Second: 10,720.93910

Timestep Collection Time: 2.15930
Timestep Consumption Time: 2.50503
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.66433

Cumulative Model Updates: 144,176
Cumulative Timesteps: 1,202,526,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.81624
Policy Entropy: 3.05546
Value Function Loss: 0.00440

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.58909
Value Function Update Magnitude: 0.54336

Collected Steps per Second: 22,622.16814
Overall Steps per Second: 10,814.10584

Timestep Collection Time: 2.21128
Timestep Consumption Time: 2.41453
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.62581

Cumulative Model Updates: 144,182
Cumulative Timesteps: 1,202,576,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1202576998...
Checkpoint 1202576998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.80232
Policy Entropy: 3.05323
Value Function Loss: 0.00425

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11168
Policy Update Magnitude: 0.58317
Value Function Update Magnitude: 0.52981

Collected Steps per Second: 22,608.29264
Overall Steps per Second: 10,632.08975

Timestep Collection Time: 2.21202
Timestep Consumption Time: 2.49166
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.70368

Cumulative Model Updates: 144,188
Cumulative Timesteps: 1,202,627,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.83052
Policy Entropy: 3.05799
Value Function Loss: 0.00425

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.57588
Value Function Update Magnitude: 0.52058

Collected Steps per Second: 22,917.93518
Overall Steps per Second: 10,868.84943

Timestep Collection Time: 2.18283
Timestep Consumption Time: 2.41986
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.60270

Cumulative Model Updates: 144,194
Cumulative Timesteps: 1,202,677,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1202677034...
Checkpoint 1202677034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.81778
Policy Entropy: 3.04918
Value Function Loss: 0.00436

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.58043
Value Function Update Magnitude: 0.49049

Collected Steps per Second: 22,609.80057
Overall Steps per Second: 10,699.88536

Timestep Collection Time: 2.21161
Timestep Consumption Time: 2.46171
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.67332

Cumulative Model Updates: 144,200
Cumulative Timesteps: 1,202,727,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.26137
Policy Entropy: 3.05132
Value Function Loss: 0.00429

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.58607
Value Function Update Magnitude: 0.50009

Collected Steps per Second: 22,739.92596
Overall Steps per Second: 10,504.53049

Timestep Collection Time: 2.19886
Timestep Consumption Time: 2.56118
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.76004

Cumulative Model Updates: 144,206
Cumulative Timesteps: 1,202,777,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1202777040...
Checkpoint 1202777040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,221.55599
Policy Entropy: 3.05352
Value Function Loss: 0.00422

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.58266
Value Function Update Magnitude: 0.51676

Collected Steps per Second: 23,172.17775
Overall Steps per Second: 10,751.75218

Timestep Collection Time: 2.15880
Timestep Consumption Time: 2.49384
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.65264

Cumulative Model Updates: 144,212
Cumulative Timesteps: 1,202,827,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.15383
Policy Entropy: 3.06449
Value Function Loss: 0.00398

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.57249
Value Function Update Magnitude: 0.53648

Collected Steps per Second: 22,922.25488
Overall Steps per Second: 10,699.21802

Timestep Collection Time: 2.18268
Timestep Consumption Time: 2.49355
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.67623

Cumulative Model Updates: 144,218
Cumulative Timesteps: 1,202,877,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1202877096...
Checkpoint 1202877096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.29652
Policy Entropy: 3.05075
Value Function Loss: 0.00408

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.57207
Value Function Update Magnitude: 0.53009

Collected Steps per Second: 23,177.64428
Overall Steps per Second: 10,673.41657

Timestep Collection Time: 2.15777
Timestep Consumption Time: 2.52789
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.68566

Cumulative Model Updates: 144,224
Cumulative Timesteps: 1,202,927,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.28954
Policy Entropy: 3.04525
Value Function Loss: 0.00403

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.52995

Collected Steps per Second: 23,130.77576
Overall Steps per Second: 10,949.18297

Timestep Collection Time: 2.16180
Timestep Consumption Time: 2.40512
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.56692

Cumulative Model Updates: 144,230
Cumulative Timesteps: 1,202,977,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1202977112...
Checkpoint 1202977112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.95865
Policy Entropy: 3.02717
Value Function Loss: 0.00430

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.58698
Value Function Update Magnitude: 0.52843

Collected Steps per Second: 23,049.94311
Overall Steps per Second: 10,727.14942

Timestep Collection Time: 2.17016
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.66312

Cumulative Model Updates: 144,236
Cumulative Timesteps: 1,203,027,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.41261
Policy Entropy: 3.04104
Value Function Loss: 0.00416

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.59865
Value Function Update Magnitude: 0.53948

Collected Steps per Second: 22,817.59226
Overall Steps per Second: 10,796.66238

Timestep Collection Time: 2.19252
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.63365

Cumulative Model Updates: 144,242
Cumulative Timesteps: 1,203,077,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1203077162...
Checkpoint 1203077162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.50617
Policy Entropy: 3.04154
Value Function Loss: 0.00433

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.59664
Value Function Update Magnitude: 0.54399

Collected Steps per Second: 22,604.00404
Overall Steps per Second: 10,619.17037

Timestep Collection Time: 2.21279
Timestep Consumption Time: 2.49737
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.71016

Cumulative Model Updates: 144,248
Cumulative Timesteps: 1,203,127,180

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,350.54455
Policy Entropy: 3.06572
Value Function Loss: 0.00414

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.59505
Value Function Update Magnitude: 0.54321

Collected Steps per Second: 22,806.46761
Overall Steps per Second: 10,639.90114

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.50793
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.70117

Cumulative Model Updates: 144,254
Cumulative Timesteps: 1,203,177,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1203177200...
Checkpoint 1203177200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,502.75754
Policy Entropy: 3.06874
Value Function Loss: 0.00394

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.58434
Value Function Update Magnitude: 0.53973

Collected Steps per Second: 22,577.72806
Overall Steps per Second: 10,549.03595

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.52641
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.74204

Cumulative Model Updates: 144,260
Cumulative Timesteps: 1,203,227,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,263.26721
Policy Entropy: 3.06969
Value Function Loss: 0.00372

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.51870

Collected Steps per Second: 23,347.46019
Overall Steps per Second: 10,760.01195

Timestep Collection Time: 2.14216
Timestep Consumption Time: 2.50598
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.64814

Cumulative Model Updates: 144,266
Cumulative Timesteps: 1,203,277,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1203277238...
Checkpoint 1203277238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.62304
Policy Entropy: 3.06377
Value Function Loss: 0.00406

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.56798
Value Function Update Magnitude: 0.49672

Collected Steps per Second: 22,788.69189
Overall Steps per Second: 10,639.40284

Timestep Collection Time: 2.19442
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.70026

Cumulative Model Updates: 144,272
Cumulative Timesteps: 1,203,327,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,949.50016
Policy Entropy: 3.07160
Value Function Loss: 0.00394

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.57357
Value Function Update Magnitude: 0.48937

Collected Steps per Second: 23,006.04785
Overall Steps per Second: 10,700.76833

Timestep Collection Time: 2.17421
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.67443

Cumulative Model Updates: 144,278
Cumulative Timesteps: 1,203,377,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1203377266...
Checkpoint 1203377266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.70885
Policy Entropy: 3.07296
Value Function Loss: 0.00406

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.57648
Value Function Update Magnitude: 0.50058

Collected Steps per Second: 23,230.65339
Overall Steps per Second: 10,923.54959

Timestep Collection Time: 2.15250
Timestep Consumption Time: 2.42513
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.57763

Cumulative Model Updates: 144,284
Cumulative Timesteps: 1,203,427,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,660.89397
Policy Entropy: 3.06553
Value Function Loss: 0.00444

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.58913
Value Function Update Magnitude: 0.53806

Collected Steps per Second: 23,219.90444
Overall Steps per Second: 10,879.23912

Timestep Collection Time: 2.15393
Timestep Consumption Time: 2.44327
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.59720

Cumulative Model Updates: 144,290
Cumulative Timesteps: 1,203,477,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1203477284...
Checkpoint 1203477284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.18213
Policy Entropy: 3.06998
Value Function Loss: 0.00459

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.60331
Value Function Update Magnitude: 0.57659

Collected Steps per Second: 23,177.32349
Overall Steps per Second: 10,699.02386

Timestep Collection Time: 2.15745
Timestep Consumption Time: 2.51624
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.67370

Cumulative Model Updates: 144,296
Cumulative Timesteps: 1,203,527,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.85428
Policy Entropy: 3.07177
Value Function Loss: 0.00460

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.59653
Value Function Update Magnitude: 0.57326

Collected Steps per Second: 22,924.45223
Overall Steps per Second: 10,902.20022

Timestep Collection Time: 2.18230
Timestep Consumption Time: 2.40650
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.58880

Cumulative Model Updates: 144,302
Cumulative Timesteps: 1,203,577,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1203577316...
Checkpoint 1203577316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,653.47231
Policy Entropy: 3.08568
Value Function Loss: 0.00417

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.58613
Value Function Update Magnitude: 0.56379

Collected Steps per Second: 22,780.41841
Overall Steps per Second: 10,744.47039

Timestep Collection Time: 2.19487
Timestep Consumption Time: 2.45869
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.65356

Cumulative Model Updates: 144,308
Cumulative Timesteps: 1,203,627,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.78849
Policy Entropy: 3.08549
Value Function Loss: 0.00398

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.57235
Value Function Update Magnitude: 0.55351

Collected Steps per Second: 21,947.49415
Overall Steps per Second: 10,485.18912

Timestep Collection Time: 2.27917
Timestep Consumption Time: 2.49156
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.77073

Cumulative Model Updates: 144,314
Cumulative Timesteps: 1,203,677,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1203677338...
Checkpoint 1203677338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.86257
Policy Entropy: 3.08691
Value Function Loss: 0.00411

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.57541
Value Function Update Magnitude: 0.56373

Collected Steps per Second: 22,971.43028
Overall Steps per Second: 10,842.93313

Timestep Collection Time: 2.17749
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61314

Cumulative Model Updates: 144,320
Cumulative Timesteps: 1,203,727,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.37529
Policy Entropy: 3.09105
Value Function Loss: 0.00438

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.58723
Value Function Update Magnitude: 0.59149

Collected Steps per Second: 23,074.51377
Overall Steps per Second: 10,911.44971

Timestep Collection Time: 2.16724
Timestep Consumption Time: 2.41584
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.58308

Cumulative Model Updates: 144,326
Cumulative Timesteps: 1,203,777,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1203777366...
Checkpoint 1203777366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.62045
Policy Entropy: 3.08804
Value Function Loss: 0.00474

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.60424
Value Function Update Magnitude: 0.59825

Collected Steps per Second: 23,170.59966
Overall Steps per Second: 10,781.27415

Timestep Collection Time: 2.15825
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.63841

Cumulative Model Updates: 144,332
Cumulative Timesteps: 1,203,827,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.25119
Policy Entropy: 3.10211
Value Function Loss: 0.00459

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.60665
Value Function Update Magnitude: 0.60792

Collected Steps per Second: 23,405.98921
Overall Steps per Second: 10,862.89161

Timestep Collection Time: 2.13749
Timestep Consumption Time: 2.46810
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.60559

Cumulative Model Updates: 144,338
Cumulative Timesteps: 1,203,877,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1203877404...
Checkpoint 1203877404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.25708
Policy Entropy: 3.09924
Value Function Loss: 0.00441

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.59422
Value Function Update Magnitude: 0.59697

Collected Steps per Second: 23,373.47354
Overall Steps per Second: 10,994.00571

Timestep Collection Time: 2.14029
Timestep Consumption Time: 2.41001
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.55030

Cumulative Model Updates: 144,344
Cumulative Timesteps: 1,203,927,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.39791
Policy Entropy: 3.09386
Value Function Loss: 0.00430

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.59500
Value Function Update Magnitude: 0.56489

Collected Steps per Second: 22,874.70813
Overall Steps per Second: 10,674.14473

Timestep Collection Time: 2.18678
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.68628

Cumulative Model Updates: 144,350
Cumulative Timesteps: 1,203,977,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1203977452...
Checkpoint 1203977452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.71241
Policy Entropy: 3.10094
Value Function Loss: 0.00428

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.58371
Value Function Update Magnitude: 0.54916

Collected Steps per Second: 22,803.92354
Overall Steps per Second: 10,675.79320

Timestep Collection Time: 2.19383
Timestep Consumption Time: 2.49228
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.68612

Cumulative Model Updates: 144,356
Cumulative Timesteps: 1,204,027,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,167.98362
Policy Entropy: 3.10344
Value Function Loss: 0.00448

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.58363
Value Function Update Magnitude: 0.56769

Collected Steps per Second: 22,721.25369
Overall Steps per Second: 10,730.97374

Timestep Collection Time: 2.20173
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.66183

Cumulative Model Updates: 144,362
Cumulative Timesteps: 1,204,077,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1204077506...
Checkpoint 1204077506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.68143
Policy Entropy: 3.09532
Value Function Loss: 0.00439

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.57652
Value Function Update Magnitude: 0.56572

Collected Steps per Second: 22,763.78054
Overall Steps per Second: 10,747.65912

Timestep Collection Time: 2.19735
Timestep Consumption Time: 2.45669
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.65404

Cumulative Model Updates: 144,368
Cumulative Timesteps: 1,204,127,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.64039
Policy Entropy: 3.09822
Value Function Loss: 0.00447

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.54181

Collected Steps per Second: 22,790.89303
Overall Steps per Second: 10,862.64292

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.40917
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.60312

Cumulative Model Updates: 144,374
Cumulative Timesteps: 1,204,177,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1204177528...
Checkpoint 1204177528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,361.09076
Policy Entropy: 3.09944
Value Function Loss: 0.00441

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.53329

Collected Steps per Second: 23,148.33240
Overall Steps per Second: 10,691.03447

Timestep Collection Time: 2.16093
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.67887

Cumulative Model Updates: 144,380
Cumulative Timesteps: 1,204,227,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.42470
Policy Entropy: 3.10996
Value Function Loss: 0.00426

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10342
Policy Update Magnitude: 0.57527
Value Function Update Magnitude: 0.52946

Collected Steps per Second: 23,377.92234
Overall Steps per Second: 10,854.23107

Timestep Collection Time: 2.13937
Timestep Consumption Time: 2.46842
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.60779

Cumulative Model Updates: 144,386
Cumulative Timesteps: 1,204,277,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1204277564...
Checkpoint 1204277564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.27639
Policy Entropy: 3.10924
Value Function Loss: 0.00373

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.57708
Value Function Update Magnitude: 0.52564

Collected Steps per Second: 23,098.01463
Overall Steps per Second: 10,678.71040

Timestep Collection Time: 2.16477
Timestep Consumption Time: 2.51763
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.68240

Cumulative Model Updates: 144,392
Cumulative Timesteps: 1,204,327,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.59076
Policy Entropy: 3.10253
Value Function Loss: 0.00387

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.57167
Value Function Update Magnitude: 0.50774

Collected Steps per Second: 22,625.96333
Overall Steps per Second: 10,610.53646

Timestep Collection Time: 2.21073
Timestep Consumption Time: 2.50345
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.71418

Cumulative Model Updates: 144,398
Cumulative Timesteps: 1,204,377,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1204377586...
Checkpoint 1204377586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.60985
Policy Entropy: 3.10371
Value Function Loss: 0.00404

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.58052
Value Function Update Magnitude: 0.51026

Collected Steps per Second: 23,012.59580
Overall Steps per Second: 10,846.27573

Timestep Collection Time: 2.17403
Timestep Consumption Time: 2.43862
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.61264

Cumulative Model Updates: 144,404
Cumulative Timesteps: 1,204,427,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.45823
Policy Entropy: 3.07354
Value Function Loss: 0.00469

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.59668
Value Function Update Magnitude: 0.54304

Collected Steps per Second: 23,287.39311
Overall Steps per Second: 11,017.07272

Timestep Collection Time: 2.14794
Timestep Consumption Time: 2.39228
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.54023

Cumulative Model Updates: 144,410
Cumulative Timesteps: 1,204,477,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1204477636...
Checkpoint 1204477636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.73936
Policy Entropy: 3.07386
Value Function Loss: 0.00439

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.60205
Value Function Update Magnitude: 0.56238

Collected Steps per Second: 22,546.87551
Overall Steps per Second: 10,613.60205

Timestep Collection Time: 2.21831
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.71244

Cumulative Model Updates: 144,416
Cumulative Timesteps: 1,204,527,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.78327
Policy Entropy: 3.07352
Value Function Loss: 0.00426

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.58890
Value Function Update Magnitude: 0.55425

Collected Steps per Second: 22,815.26757
Overall Steps per Second: 10,848.73387

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.41867
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.61141

Cumulative Model Updates: 144,422
Cumulative Timesteps: 1,204,577,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1204577680...
Checkpoint 1204577680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.54917
Policy Entropy: 3.08610
Value Function Loss: 0.00439

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.59483
Value Function Update Magnitude: 0.55863

Collected Steps per Second: 22,916.40992
Overall Steps per Second: 10,708.19407

Timestep Collection Time: 2.18193
Timestep Consumption Time: 2.48758
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.66951

Cumulative Model Updates: 144,428
Cumulative Timesteps: 1,204,627,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.38936
Policy Entropy: 3.07247
Value Function Loss: 0.00443

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.60300
Value Function Update Magnitude: 0.57986

Collected Steps per Second: 22,496.76074
Overall Steps per Second: 10,648.32286

Timestep Collection Time: 2.22281
Timestep Consumption Time: 2.47333
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.69614

Cumulative Model Updates: 144,434
Cumulative Timesteps: 1,204,677,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1204677688...
Checkpoint 1204677688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.46362
Policy Entropy: 3.07744
Value Function Loss: 0.00415

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.60273
Value Function Update Magnitude: 0.57470

Collected Steps per Second: 23,031.29606
Overall Steps per Second: 10,875.85285

Timestep Collection Time: 2.17113
Timestep Consumption Time: 2.42658
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.59771

Cumulative Model Updates: 144,440
Cumulative Timesteps: 1,204,727,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.12514
Policy Entropy: 3.07315
Value Function Loss: 0.00426

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.59816
Value Function Update Magnitude: 0.52547

Collected Steps per Second: 23,099.16134
Overall Steps per Second: 10,894.63636

Timestep Collection Time: 2.16536
Timestep Consumption Time: 2.42571
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.59107

Cumulative Model Updates: 144,446
Cumulative Timesteps: 1,204,777,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1204777710...
Checkpoint 1204777710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.95546
Policy Entropy: 3.08472
Value Function Loss: 0.00448

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.59799
Value Function Update Magnitude: 0.53611

Collected Steps per Second: 22,964.90044
Overall Steps per Second: 10,680.29279

Timestep Collection Time: 2.17767
Timestep Consumption Time: 2.50478
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.68246

Cumulative Model Updates: 144,452
Cumulative Timesteps: 1,204,827,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,893.56307
Policy Entropy: 3.07807
Value Function Loss: 0.00456

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.59801
Value Function Update Magnitude: 0.54716

Collected Steps per Second: 23,134.15850
Overall Steps per Second: 10,839.79213

Timestep Collection Time: 2.16165
Timestep Consumption Time: 2.45172
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.61337

Cumulative Model Updates: 144,458
Cumulative Timesteps: 1,204,877,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1204877728...
Checkpoint 1204877728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278.63911
Policy Entropy: 3.09496
Value Function Loss: 0.00422

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.59091
Value Function Update Magnitude: 0.53555

Collected Steps per Second: 23,055.12533
Overall Steps per Second: 10,679.34087

Timestep Collection Time: 2.16984
Timestep Consumption Time: 2.51453
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.68437

Cumulative Model Updates: 144,464
Cumulative Timesteps: 1,204,927,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,642.33911
Policy Entropy: 3.08657
Value Function Loss: 0.00432

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.51006

Collected Steps per Second: 23,108.31564
Overall Steps per Second: 10,933.03654

Timestep Collection Time: 2.16433
Timestep Consumption Time: 2.41025
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.57458

Cumulative Model Updates: 144,470
Cumulative Timesteps: 1,204,977,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1204977768...
Checkpoint 1204977768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.04625
Policy Entropy: 3.08448
Value Function Loss: 0.00434

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.58148
Value Function Update Magnitude: 0.49782

Collected Steps per Second: 22,719.65291
Overall Steps per Second: 10,674.05925

Timestep Collection Time: 2.20179
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.68650

Cumulative Model Updates: 144,476
Cumulative Timesteps: 1,205,027,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,395.53083
Policy Entropy: 3.09114
Value Function Loss: 0.00423

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.57640
Value Function Update Magnitude: 0.50164

Collected Steps per Second: 22,950.92427
Overall Steps per Second: 10,876.04332

Timestep Collection Time: 2.17856
Timestep Consumption Time: 2.41870
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.59726

Cumulative Model Updates: 144,482
Cumulative Timesteps: 1,205,077,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1205077792...
Checkpoint 1205077792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.33212
Policy Entropy: 3.09971
Value Function Loss: 0.00373

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.56822
Value Function Update Magnitude: 0.48939

Collected Steps per Second: 22,570.38783
Overall Steps per Second: 10,649.76990

Timestep Collection Time: 2.21591
Timestep Consumption Time: 2.48034
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.69625

Cumulative Model Updates: 144,488
Cumulative Timesteps: 1,205,127,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.23107
Policy Entropy: 3.10069
Value Function Loss: 0.00364

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.56478
Value Function Update Magnitude: 0.49297

Collected Steps per Second: 22,727.11578
Overall Steps per Second: 10,822.58879

Timestep Collection Time: 2.20107
Timestep Consumption Time: 2.42111
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.62218

Cumulative Model Updates: 144,494
Cumulative Timesteps: 1,205,177,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1205177830...
Checkpoint 1205177830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.40100
Policy Entropy: 3.10350
Value Function Loss: 0.00412

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.51855

Collected Steps per Second: 22,856.45861
Overall Steps per Second: 10,722.47643

Timestep Collection Time: 2.18800
Timestep Consumption Time: 2.47603
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.66403

Cumulative Model Updates: 144,500
Cumulative Timesteps: 1,205,227,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.90737
Policy Entropy: 3.10113
Value Function Loss: 0.00427

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.56456
Value Function Update Magnitude: 0.51742

Collected Steps per Second: 23,289.92970
Overall Steps per Second: 10,850.25306

Timestep Collection Time: 2.14857
Timestep Consumption Time: 2.46331
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.61187

Cumulative Model Updates: 144,506
Cumulative Timesteps: 1,205,277,880

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1205277880...
Checkpoint 1205277880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,740.74471
Policy Entropy: 3.09475
Value Function Loss: 0.00479

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.52271

Collected Steps per Second: 23,135.36352
Overall Steps per Second: 10,673.00127

Timestep Collection Time: 2.16189
Timestep Consumption Time: 2.52433
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.68622

Cumulative Model Updates: 144,512
Cumulative Timesteps: 1,205,327,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.54359
Policy Entropy: 3.07619
Value Function Loss: 0.00444

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.58720
Value Function Update Magnitude: 0.54210

Collected Steps per Second: 22,914.78272
Overall Steps per Second: 10,723.94957

Timestep Collection Time: 2.18270
Timestep Consumption Time: 2.48126
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.66395

Cumulative Model Updates: 144,518
Cumulative Timesteps: 1,205,377,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1205377912...
Checkpoint 1205377912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.19477
Policy Entropy: 3.07386
Value Function Loss: 0.00440

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.59450
Value Function Update Magnitude: 0.55509

Collected Steps per Second: 23,259.35299
Overall Steps per Second: 10,855.83180

Timestep Collection Time: 2.15010
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.60674

Cumulative Model Updates: 144,524
Cumulative Timesteps: 1,205,427,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,344.56811
Policy Entropy: 3.09111
Value Function Loss: 0.00399

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.59337
Value Function Update Magnitude: 0.54346

Collected Steps per Second: 23,249.76398
Overall Steps per Second: 10,876.84150

Timestep Collection Time: 2.15108
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.59803

Cumulative Model Updates: 144,530
Cumulative Timesteps: 1,205,477,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1205477934...
Checkpoint 1205477934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,536.67698
Policy Entropy: 3.09439
Value Function Loss: 0.00391

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.58623
Value Function Update Magnitude: 0.52017

Collected Steps per Second: 23,173.36478
Overall Steps per Second: 10,709.14205

Timestep Collection Time: 2.15843
Timestep Consumption Time: 2.51216
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.67059

Cumulative Model Updates: 144,536
Cumulative Timesteps: 1,205,527,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.62519
Policy Entropy: 3.09618
Value Function Loss: 0.00407

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.59093
Value Function Update Magnitude: 0.50567

Collected Steps per Second: 22,589.31541
Overall Steps per Second: 10,791.42550

Timestep Collection Time: 2.21432
Timestep Consumption Time: 2.42084
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.63516

Cumulative Model Updates: 144,542
Cumulative Timesteps: 1,205,577,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1205577972...
Checkpoint 1205577972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,176.74144
Policy Entropy: 3.09665
Value Function Loss: 0.00409

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.58818
Value Function Update Magnitude: 0.52228

Collected Steps per Second: 22,275.05288
Overall Steps per Second: 10,681.07464

Timestep Collection Time: 2.24655
Timestep Consumption Time: 2.43856
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.68511

Cumulative Model Updates: 144,548
Cumulative Timesteps: 1,205,628,014

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.53804
Policy Entropy: 3.10504
Value Function Loss: 0.00411

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.58011
Value Function Update Magnitude: 0.52804

Collected Steps per Second: 22,373.43649
Overall Steps per Second: 10,494.81870

Timestep Collection Time: 2.23515
Timestep Consumption Time: 2.52987
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.76502

Cumulative Model Updates: 144,554
Cumulative Timesteps: 1,205,678,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1205678022...
Checkpoint 1205678022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.60033
Policy Entropy: 3.09342
Value Function Loss: 0.00434

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.52558

Collected Steps per Second: 22,617.03790
Overall Steps per Second: 10,612.05760

Timestep Collection Time: 2.21152
Timestep Consumption Time: 2.50180
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.71332

Cumulative Model Updates: 144,560
Cumulative Timesteps: 1,205,728,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.24606
Policy Entropy: 3.10042
Value Function Loss: 0.00455

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.57929
Value Function Update Magnitude: 0.56790

Collected Steps per Second: 23,097.27299
Overall Steps per Second: 10,822.76708

Timestep Collection Time: 2.16493
Timestep Consumption Time: 2.45533
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62026

Cumulative Model Updates: 144,566
Cumulative Timesteps: 1,205,778,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1205778044...
Checkpoint 1205778044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.69090
Policy Entropy: 3.06981
Value Function Loss: 0.00478

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12106
Policy Update Magnitude: 0.59884
Value Function Update Magnitude: 0.59517

Collected Steps per Second: 23,158.71759
Overall Steps per Second: 10,770.86792

Timestep Collection Time: 2.15988
Timestep Consumption Time: 2.48413
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.64401

Cumulative Model Updates: 144,572
Cumulative Timesteps: 1,205,828,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,663.83551
Policy Entropy: 3.08961
Value Function Loss: 0.00427

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.59607
Value Function Update Magnitude: 0.58414

Collected Steps per Second: 23,080.16521
Overall Steps per Second: 10,846.96286

Timestep Collection Time: 2.16714
Timestep Consumption Time: 2.44410
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.61124

Cumulative Model Updates: 144,578
Cumulative Timesteps: 1,205,878,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1205878082...
Checkpoint 1205878082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.90869
Policy Entropy: 3.09870
Value Function Loss: 0.00450

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.60273
Value Function Update Magnitude: 0.55933

Collected Steps per Second: 23,237.61162
Overall Steps per Second: 10,823.69238

Timestep Collection Time: 2.15280
Timestep Consumption Time: 2.46909
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.62190

Cumulative Model Updates: 144,584
Cumulative Timesteps: 1,205,928,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,410.87245
Policy Entropy: 3.10843
Value Function Loss: 0.00464

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.60535
Value Function Update Magnitude: 0.55136

Collected Steps per Second: 23,074.47677
Overall Steps per Second: 10,760.40465

Timestep Collection Time: 2.16716
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.64722

Cumulative Model Updates: 144,590
Cumulative Timesteps: 1,205,978,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1205978114...
Checkpoint 1205978114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.41402
Policy Entropy: 3.10391
Value Function Loss: 0.00475

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.60848
Value Function Update Magnitude: 0.57689

Collected Steps per Second: 23,296.05387
Overall Steps per Second: 10,862.20436

Timestep Collection Time: 2.14654
Timestep Consumption Time: 2.45713
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.60367

Cumulative Model Updates: 144,596
Cumulative Timesteps: 1,206,028,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.06813
Policy Entropy: 3.09969
Value Function Loss: 0.00431

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.59413
Value Function Update Magnitude: 0.57813

Collected Steps per Second: 22,824.97097
Overall Steps per Second: 10,710.05814

Timestep Collection Time: 2.19137
Timestep Consumption Time: 2.47882
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.67019

Cumulative Model Updates: 144,602
Cumulative Timesteps: 1,206,078,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1206078138...
Checkpoint 1206078138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.73406
Policy Entropy: 3.11105
Value Function Loss: 0.00437

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.58123
Value Function Update Magnitude: 0.55767

Collected Steps per Second: 22,709.65318
Overall Steps per Second: 10,689.43728

Timestep Collection Time: 2.20197
Timestep Consumption Time: 2.47610
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.67808

Cumulative Model Updates: 144,608
Cumulative Timesteps: 1,206,128,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.27182
Policy Entropy: 3.10534
Value Function Loss: 0.00423

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.57122
Value Function Update Magnitude: 0.55316

Collected Steps per Second: 22,739.56480
Overall Steps per Second: 10,808.25872

Timestep Collection Time: 2.19987
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.62831

Cumulative Model Updates: 144,614
Cumulative Timesteps: 1,206,178,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1206178168...
Checkpoint 1206178168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007.26741
Policy Entropy: 3.09249
Value Function Loss: 0.00420

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.55355

Collected Steps per Second: 23,082.66302
Overall Steps per Second: 10,678.77044

Timestep Collection Time: 2.16673
Timestep Consumption Time: 2.51676
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.68350

Cumulative Model Updates: 144,620
Cumulative Timesteps: 1,206,228,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.89089
Policy Entropy: 3.08128
Value Function Loss: 0.00418

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.57819
Value Function Update Magnitude: 0.54142

Collected Steps per Second: 23,248.68353
Overall Steps per Second: 10,857.01036

Timestep Collection Time: 2.15161
Timestep Consumption Time: 2.45574
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.60735

Cumulative Model Updates: 144,626
Cumulative Timesteps: 1,206,278,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1206278204...
Checkpoint 1206278204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.85072
Policy Entropy: 3.09386
Value Function Loss: 0.00408

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.58247
Value Function Update Magnitude: 0.54397

Collected Steps per Second: 22,801.36560
Overall Steps per Second: 10,705.42688

Timestep Collection Time: 2.19338
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.67165

Cumulative Model Updates: 144,632
Cumulative Timesteps: 1,206,328,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.49223
Policy Entropy: 3.08811
Value Function Loss: 0.00418

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.58446
Value Function Update Magnitude: 0.52979

Collected Steps per Second: 23,104.34791
Overall Steps per Second: 10,920.95742

Timestep Collection Time: 2.16418
Timestep Consumption Time: 2.41435
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.57854

Cumulative Model Updates: 144,638
Cumulative Timesteps: 1,206,378,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1206378218...
Checkpoint 1206378218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.13271
Policy Entropy: 3.08825
Value Function Loss: 0.00426

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.58871
Value Function Update Magnitude: 0.51838

Collected Steps per Second: 23,072.18067
Overall Steps per Second: 10,815.56232

Timestep Collection Time: 2.16833
Timestep Consumption Time: 2.45723
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.62556

Cumulative Model Updates: 144,644
Cumulative Timesteps: 1,206,428,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.29515
Policy Entropy: 3.08450
Value Function Loss: 0.00445

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.58461
Value Function Update Magnitude: 0.50115

Collected Steps per Second: 23,207.26628
Overall Steps per Second: 10,800.55859

Timestep Collection Time: 2.15588
Timestep Consumption Time: 2.47648
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.63235

Cumulative Model Updates: 144,650
Cumulative Timesteps: 1,206,478,278

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1206478278...
Checkpoint 1206478278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.46478
Policy Entropy: 3.08595
Value Function Loss: 0.00450

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.58552
Value Function Update Magnitude: 0.52080

Collected Steps per Second: 22,759.79284
Overall Steps per Second: 10,602.18071

Timestep Collection Time: 2.19703
Timestep Consumption Time: 2.51936
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.71639

Cumulative Model Updates: 144,656
Cumulative Timesteps: 1,206,528,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.72100
Policy Entropy: 3.08572
Value Function Loss: 0.00460

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.59153
Value Function Update Magnitude: 0.57497

Collected Steps per Second: 22,757.89119
Overall Steps per Second: 10,840.19179

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.41658
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61468

Cumulative Model Updates: 144,662
Cumulative Timesteps: 1,206,578,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1206578306...
Checkpoint 1206578306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.37367
Policy Entropy: 3.07077
Value Function Loss: 0.00437

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.59014
Value Function Update Magnitude: 0.58757

Collected Steps per Second: 22,512.35770
Overall Steps per Second: 10,683.95623

Timestep Collection Time: 2.22216
Timestep Consumption Time: 2.46019
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.68235

Cumulative Model Updates: 144,668
Cumulative Timesteps: 1,206,628,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,721.73329
Policy Entropy: 3.07207
Value Function Loss: 0.00415

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.58193
Value Function Update Magnitude: 0.55582

Collected Steps per Second: 23,002.44726
Overall Steps per Second: 10,859.95531

Timestep Collection Time: 2.17394
Timestep Consumption Time: 2.43068
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.60462

Cumulative Model Updates: 144,674
Cumulative Timesteps: 1,206,678,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1206678338...
Checkpoint 1206678338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.63130
Policy Entropy: 3.07599
Value Function Loss: 0.00398

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.52775

Collected Steps per Second: 22,722.74827
Overall Steps per Second: 10,700.72784

Timestep Collection Time: 2.20167
Timestep Consumption Time: 2.47353
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.67520

Cumulative Model Updates: 144,680
Cumulative Timesteps: 1,206,728,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,340.20260
Policy Entropy: 3.08970
Value Function Loss: 0.00412

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.58048
Value Function Update Magnitude: 0.52799

Collected Steps per Second: 23,219.99209
Overall Steps per Second: 10,824.16863

Timestep Collection Time: 2.15426
Timestep Consumption Time: 2.46706
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.62132

Cumulative Model Updates: 144,686
Cumulative Timesteps: 1,206,778,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1206778388...
Checkpoint 1206778388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.70544
Policy Entropy: 3.09659
Value Function Loss: 0.00420

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.52895

Collected Steps per Second: 23,161.64566
Overall Steps per Second: 10,682.24541

Timestep Collection Time: 2.15986
Timestep Consumption Time: 2.52323
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.68310

Cumulative Model Updates: 144,692
Cumulative Timesteps: 1,206,828,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.96996
Policy Entropy: 3.08346
Value Function Loss: 0.00411

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.58057
Value Function Update Magnitude: 0.53260

Collected Steps per Second: 23,209.34488
Overall Steps per Second: 10,959.54219

Timestep Collection Time: 2.15482
Timestep Consumption Time: 2.40851
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.56333

Cumulative Model Updates: 144,698
Cumulative Timesteps: 1,206,878,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1206878426...
Checkpoint 1206878426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935.42379
Policy Entropy: 3.07823
Value Function Loss: 0.00405

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.57651
Value Function Update Magnitude: 0.52495

Collected Steps per Second: 23,176.04412
Overall Steps per Second: 10,758.98737

Timestep Collection Time: 2.15749
Timestep Consumption Time: 2.48998
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.64746

Cumulative Model Updates: 144,704
Cumulative Timesteps: 1,206,928,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,174.26511
Policy Entropy: 3.06370
Value Function Loss: 0.00451

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.58892
Value Function Update Magnitude: 0.56022

Collected Steps per Second: 22,797.10580
Overall Steps per Second: 10,811.17951

Timestep Collection Time: 2.19423
Timestep Consumption Time: 2.43265
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.62688

Cumulative Model Updates: 144,710
Cumulative Timesteps: 1,206,978,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1206978450...
Checkpoint 1206978450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.90658
Policy Entropy: 3.07745
Value Function Loss: 0.00439

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.59435
Value Function Update Magnitude: 0.57289

Collected Steps per Second: 23,117.71348
Overall Steps per Second: 10,728.68119

Timestep Collection Time: 2.16310
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.66096

Cumulative Model Updates: 144,716
Cumulative Timesteps: 1,207,028,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.42347
Policy Entropy: 3.09007
Value Function Loss: 0.00429

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10925
Policy Update Magnitude: 0.58442
Value Function Update Magnitude: 0.54531

Collected Steps per Second: 22,614.98521
Overall Steps per Second: 10,842.28791

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.40065
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.61157

Cumulative Model Updates: 144,722
Cumulative Timesteps: 1,207,078,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1207078456...
Checkpoint 1207078456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792.15906
Policy Entropy: 3.10521
Value Function Loss: 0.00420

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.57236
Value Function Update Magnitude: 0.51920

Collected Steps per Second: 22,523.30152
Overall Steps per Second: 10,587.29938

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.50332
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.72377

Cumulative Model Updates: 144,728
Cumulative Timesteps: 1,207,128,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,972.29985
Policy Entropy: 3.09748
Value Function Loss: 0.00416

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.55800
Value Function Update Magnitude: 0.49587

Collected Steps per Second: 22,704.40454
Overall Steps per Second: 10,837.05706

Timestep Collection Time: 2.20354
Timestep Consumption Time: 2.41303
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61657

Cumulative Model Updates: 144,734
Cumulative Timesteps: 1,207,178,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1207178498...
Checkpoint 1207178498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,009.67369
Policy Entropy: 3.10000
Value Function Loss: 0.00418

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.48324

Collected Steps per Second: 22,646.35246
Overall Steps per Second: 10,714.78230

Timestep Collection Time: 2.20804
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.66682

Cumulative Model Updates: 144,740
Cumulative Timesteps: 1,207,228,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.78507
Policy Entropy: 3.09043
Value Function Loss: 0.00411

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.56575
Value Function Update Magnitude: 0.49316

Collected Steps per Second: 23,256.58042
Overall Steps per Second: 10,848.99889

Timestep Collection Time: 2.15122
Timestep Consumption Time: 2.46027
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61149

Cumulative Model Updates: 144,746
Cumulative Timesteps: 1,207,278,532

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1207278532...
Checkpoint 1207278532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.13872
Policy Entropy: 3.07125
Value Function Loss: 0.00405

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.51708

Collected Steps per Second: 23,000.89513
Overall Steps per Second: 10,660.11038

Timestep Collection Time: 2.17409
Timestep Consumption Time: 2.51686
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69095

Cumulative Model Updates: 144,752
Cumulative Timesteps: 1,207,328,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,936.71023
Policy Entropy: 3.05466
Value Function Loss: 0.00377

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.56693
Value Function Update Magnitude: 0.50307

Collected Steps per Second: 22,882.10492
Overall Steps per Second: 10,825.47950

Timestep Collection Time: 2.18590
Timestep Consumption Time: 2.43450
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.62040

Cumulative Model Updates: 144,758
Cumulative Timesteps: 1,207,378,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1207378556...
Checkpoint 1207378556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,579.55421
Policy Entropy: 3.06354
Value Function Loss: 0.00424

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.49144

Collected Steps per Second: 22,958.81024
Overall Steps per Second: 10,742.19421

Timestep Collection Time: 2.17851
Timestep Consumption Time: 2.47752
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.65603

Cumulative Model Updates: 144,764
Cumulative Timesteps: 1,207,428,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.63971
Policy Entropy: 3.05307
Value Function Loss: 0.00431

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11594
Policy Update Magnitude: 0.58725
Value Function Update Magnitude: 0.50652

Collected Steps per Second: 23,409.48646
Overall Steps per Second: 10,947.15663

Timestep Collection Time: 2.13700
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.56977

Cumulative Model Updates: 144,770
Cumulative Timesteps: 1,207,478,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1207478598...
Checkpoint 1207478598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983.89556
Policy Entropy: 3.06820
Value Function Loss: 0.00456

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.58640
Value Function Update Magnitude: 0.52764

Collected Steps per Second: 22,505.06008
Overall Steps per Second: 10,611.36133

Timestep Collection Time: 2.22279
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.71419

Cumulative Model Updates: 144,776
Cumulative Timesteps: 1,207,528,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,864.61890
Policy Entropy: 3.07574
Value Function Loss: 0.00441

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.58306
Value Function Update Magnitude: 0.52901

Collected Steps per Second: 22,890.45233
Overall Steps per Second: 10,802.66669

Timestep Collection Time: 2.18502
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.62997

Cumulative Model Updates: 144,782
Cumulative Timesteps: 1,207,578,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1207578638...
Checkpoint 1207578638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,952.21579
Policy Entropy: 3.09009
Value Function Loss: 0.00435

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.57675
Value Function Update Magnitude: 0.54517

Collected Steps per Second: 22,464.22658
Overall Steps per Second: 10,744.09368

Timestep Collection Time: 2.22656
Timestep Consumption Time: 2.42883
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.65540

Cumulative Model Updates: 144,788
Cumulative Timesteps: 1,207,628,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.56906
Policy Entropy: 3.08684
Value Function Loss: 0.00438

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.57424
Value Function Update Magnitude: 0.52668

Collected Steps per Second: 22,940.51640
Overall Steps per Second: 10,891.42657

Timestep Collection Time: 2.17999
Timestep Consumption Time: 2.41170
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.59168

Cumulative Model Updates: 144,794
Cumulative Timesteps: 1,207,678,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1207678666...
Checkpoint 1207678666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.89532
Policy Entropy: 3.07841
Value Function Loss: 0.00458

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.50557

Collected Steps per Second: 22,570.28727
Overall Steps per Second: 10,650.19185

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.47955
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.69494

Cumulative Model Updates: 144,800
Cumulative Timesteps: 1,207,728,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.96084
Policy Entropy: 3.08362
Value Function Loss: 0.00452

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.57720
Value Function Update Magnitude: 0.50090

Collected Steps per Second: 23,185.53255
Overall Steps per Second: 10,851.40493

Timestep Collection Time: 2.15764
Timestep Consumption Time: 2.45246
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.61009

Cumulative Model Updates: 144,806
Cumulative Timesteps: 1,207,778,694

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1207778694...
Checkpoint 1207778694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853.07450
Policy Entropy: 3.08499
Value Function Loss: 0.00440

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.51469

Collected Steps per Second: 23,002.31288
Overall Steps per Second: 10,664.23062

Timestep Collection Time: 2.17396
Timestep Consumption Time: 2.51518
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.68913

Cumulative Model Updates: 144,812
Cumulative Timesteps: 1,207,828,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.74873
Policy Entropy: 3.08386
Value Function Loss: 0.00425

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.58386
Value Function Update Magnitude: 0.51956

Collected Steps per Second: 23,037.01571
Overall Steps per Second: 10,914.26443

Timestep Collection Time: 2.17085
Timestep Consumption Time: 2.41122
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.58208

Cumulative Model Updates: 144,818
Cumulative Timesteps: 1,207,878,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1207878710...
Checkpoint 1207878710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,705.79666
Policy Entropy: 3.06462
Value Function Loss: 0.00463

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.59990
Value Function Update Magnitude: 0.50774

Collected Steps per Second: 22,725.82252
Overall Steps per Second: 10,680.20683

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.68193

Cumulative Model Updates: 144,824
Cumulative Timesteps: 1,207,928,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.94211
Policy Entropy: 3.05714
Value Function Loss: 0.00455

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10489
Policy Update Magnitude: 0.60426
Value Function Update Magnitude: 0.53014

Collected Steps per Second: 23,041.29739
Overall Steps per Second: 10,885.92010

Timestep Collection Time: 2.17071
Timestep Consumption Time: 2.42385
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.59456

Cumulative Model Updates: 144,830
Cumulative Timesteps: 1,207,978,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1207978730...
Checkpoint 1207978730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.93198
Policy Entropy: 3.04318
Value Function Loss: 0.00422

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.59346
Value Function Update Magnitude: 0.52966

Collected Steps per Second: 23,019.44650
Overall Steps per Second: 10,761.75302

Timestep Collection Time: 2.17286
Timestep Consumption Time: 2.47490
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.64776

Cumulative Model Updates: 144,836
Cumulative Timesteps: 1,208,028,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.40800
Policy Entropy: 3.06781
Value Function Loss: 0.00398

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.57822
Value Function Update Magnitude: 0.51159

Collected Steps per Second: 23,033.07476
Overall Steps per Second: 10,888.51388

Timestep Collection Time: 2.17114
Timestep Consumption Time: 2.42159
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.59273

Cumulative Model Updates: 144,842
Cumulative Timesteps: 1,208,078,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1208078756...
Checkpoint 1208078756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.08075
Policy Entropy: 3.06550
Value Function Loss: 0.00426

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.57111
Value Function Update Magnitude: 0.49979

Collected Steps per Second: 22,674.92563
Overall Steps per Second: 10,605.07013

Timestep Collection Time: 2.20517
Timestep Consumption Time: 2.50975
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.71491

Cumulative Model Updates: 144,848
Cumulative Timesteps: 1,208,128,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.44480
Policy Entropy: 3.07385
Value Function Loss: 0.00401

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.57047
Value Function Update Magnitude: 0.50773

Collected Steps per Second: 22,860.93392
Overall Steps per Second: 10,778.40375

Timestep Collection Time: 2.18740
Timestep Consumption Time: 2.45206
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.63946

Cumulative Model Updates: 144,854
Cumulative Timesteps: 1,208,178,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1208178764...
Checkpoint 1208178764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,427.36352
Policy Entropy: 3.06838
Value Function Loss: 0.00401

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10570
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.49165

Collected Steps per Second: 23,045.42722
Overall Steps per Second: 10,734.96960

Timestep Collection Time: 2.17032
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.65917

Cumulative Model Updates: 144,860
Cumulative Timesteps: 1,208,228,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.41918
Policy Entropy: 3.08006
Value Function Loss: 0.00387

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.57592
Value Function Update Magnitude: 0.47793

Collected Steps per Second: 23,384.59593
Overall Steps per Second: 10,886.67697

Timestep Collection Time: 2.13825
Timestep Consumption Time: 2.45471
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.59295

Cumulative Model Updates: 144,866
Cumulative Timesteps: 1,208,278,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1208278782...
Checkpoint 1208278782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.19502
Policy Entropy: 3.06382
Value Function Loss: 0.00451

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.50711

Collected Steps per Second: 23,054.81350
Overall Steps per Second: 10,789.19213

Timestep Collection Time: 2.16926
Timestep Consumption Time: 2.46611
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.63538

Cumulative Model Updates: 144,872
Cumulative Timesteps: 1,208,328,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.83311
Policy Entropy: 3.06786
Value Function Loss: 0.00437

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.58854
Value Function Update Magnitude: 0.53097

Collected Steps per Second: 23,393.95705
Overall Steps per Second: 10,768.62475

Timestep Collection Time: 2.13824
Timestep Consumption Time: 2.50692
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.64516

Cumulative Model Updates: 144,878
Cumulative Timesteps: 1,208,378,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1208378816...
Checkpoint 1208378816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,332.56143
Policy Entropy: 3.08308
Value Function Loss: 0.00434

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.57542
Value Function Update Magnitude: 0.52535

Collected Steps per Second: 23,228.87383
Overall Steps per Second: 10,781.04891

Timestep Collection Time: 2.15361
Timestep Consumption Time: 2.48657
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.64018

Cumulative Model Updates: 144,884
Cumulative Timesteps: 1,208,428,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,065.99390
Policy Entropy: 3.09438
Value Function Loss: 0.00427

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.50536

Collected Steps per Second: 23,309.56715
Overall Steps per Second: 10,780.02283

Timestep Collection Time: 2.14624
Timestep Consumption Time: 2.49456
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.64081

Cumulative Model Updates: 144,890
Cumulative Timesteps: 1,208,478,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1208478870...
Checkpoint 1208478870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.09684
Policy Entropy: 3.11166
Value Function Loss: 0.00405

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.58552
Value Function Update Magnitude: 0.49459

Collected Steps per Second: 22,891.48636
Overall Steps per Second: 10,688.03293

Timestep Collection Time: 2.18492
Timestep Consumption Time: 2.49471
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.67963

Cumulative Model Updates: 144,896
Cumulative Timesteps: 1,208,528,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.32115
Policy Entropy: 3.10411
Value Function Loss: 0.00389

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10997
Policy Update Magnitude: 0.57397
Value Function Update Magnitude: 0.48650

Collected Steps per Second: 22,414.51090
Overall Steps per Second: 10,575.92913

Timestep Collection Time: 2.23168
Timestep Consumption Time: 2.49812
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.72980

Cumulative Model Updates: 144,902
Cumulative Timesteps: 1,208,578,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1208578908...
Checkpoint 1208578908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,244.74041
Policy Entropy: 3.10314
Value Function Loss: 0.00383

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.56928
Value Function Update Magnitude: 0.48311

Collected Steps per Second: 22,939.16424
Overall Steps per Second: 10,737.21767

Timestep Collection Time: 2.18011
Timestep Consumption Time: 2.47752
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.65763

Cumulative Model Updates: 144,908
Cumulative Timesteps: 1,208,628,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999.00588
Policy Entropy: 3.09645
Value Function Loss: 0.00400

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.56855
Value Function Update Magnitude: 0.50139

Collected Steps per Second: 23,216.77654
Overall Steps per Second: 10,821.18303

Timestep Collection Time: 2.15405
Timestep Consumption Time: 2.46745
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.62149

Cumulative Model Updates: 144,914
Cumulative Timesteps: 1,208,678,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1208678928...
Checkpoint 1208678928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,821.13925
Policy Entropy: 3.08794
Value Function Loss: 0.00397

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.56267
Value Function Update Magnitude: 0.51013

Collected Steps per Second: 22,396.35338
Overall Steps per Second: 10,641.17483

Timestep Collection Time: 2.23268
Timestep Consumption Time: 2.46642
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.69911

Cumulative Model Updates: 144,920
Cumulative Timesteps: 1,208,728,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,139.40493
Policy Entropy: 3.08140
Value Function Loss: 0.00424

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.52088

Collected Steps per Second: 23,320.78614
Overall Steps per Second: 10,735.07352

Timestep Collection Time: 2.14478
Timestep Consumption Time: 2.51452
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.65931

Cumulative Model Updates: 144,926
Cumulative Timesteps: 1,208,778,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1208778950...
Checkpoint 1208778950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.51786
Policy Entropy: 3.06756
Value Function Loss: 0.00455

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.59871
Value Function Update Magnitude: 0.52665

Collected Steps per Second: 23,082.95786
Overall Steps per Second: 10,803.96796

Timestep Collection Time: 2.16705
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.62997

Cumulative Model Updates: 144,932
Cumulative Timesteps: 1,208,828,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.87493
Policy Entropy: 3.07777
Value Function Loss: 0.00445

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.59396
Value Function Update Magnitude: 0.52031

Collected Steps per Second: 23,345.54539
Overall Steps per Second: 10,817.11010

Timestep Collection Time: 2.14234
Timestep Consumption Time: 2.48127
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.62360

Cumulative Model Updates: 144,938
Cumulative Timesteps: 1,208,878,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1208878986...
Checkpoint 1208878986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,587.31623
Policy Entropy: 3.07579
Value Function Loss: 0.00443

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.58398
Value Function Update Magnitude: 0.51504

Collected Steps per Second: 22,960.99316
Overall Steps per Second: 10,812.21216

Timestep Collection Time: 2.17856
Timestep Consumption Time: 2.44787
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.62644

Cumulative Model Updates: 144,944
Cumulative Timesteps: 1,208,929,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,153.94267
Policy Entropy: 3.07045
Value Function Loss: 0.00433

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10705
Policy Update Magnitude: 0.59615
Value Function Update Magnitude: 0.52551

Collected Steps per Second: 23,512.32337
Overall Steps per Second: 10,817.16474

Timestep Collection Time: 2.12859
Timestep Consumption Time: 2.49813
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.62672

Cumulative Model Updates: 144,950
Cumulative Timesteps: 1,208,979,056

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1208979056...
Checkpoint 1208979056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,271.33608
Policy Entropy: 3.05965
Value Function Loss: 0.00444

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.59213
Value Function Update Magnitude: 0.51813

Collected Steps per Second: 22,946.24121
Overall Steps per Second: 10,900.49331

Timestep Collection Time: 2.17927
Timestep Consumption Time: 2.40823
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.58750

Cumulative Model Updates: 144,956
Cumulative Timesteps: 1,209,029,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.02890
Policy Entropy: 3.05633
Value Function Loss: 0.00443

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.59018
Value Function Update Magnitude: 0.48769

Collected Steps per Second: 22,860.89062
Overall Steps per Second: 10,688.07980

Timestep Collection Time: 2.18828
Timestep Consumption Time: 2.49226
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.68054

Cumulative Model Updates: 144,962
Cumulative Timesteps: 1,209,079,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1209079088...
Checkpoint 1209079088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.00345
Policy Entropy: 3.05407
Value Function Loss: 0.00441

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11994
Policy Update Magnitude: 0.59452
Value Function Update Magnitude: 0.49210

Collected Steps per Second: 22,628.35297
Overall Steps per Second: 10,642.12427

Timestep Collection Time: 2.21015
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.69944

Cumulative Model Updates: 144,968
Cumulative Timesteps: 1,209,129,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.07569
Policy Entropy: 3.05291
Value Function Loss: 0.00441

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11344
Policy Update Magnitude: 0.59783
Value Function Update Magnitude: 0.49064

Collected Steps per Second: 23,118.15885
Overall Steps per Second: 10,721.17649

Timestep Collection Time: 2.16358
Timestep Consumption Time: 2.50177
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.66535

Cumulative Model Updates: 144,974
Cumulative Timesteps: 1,209,179,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1209179118...
Checkpoint 1209179118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.26493
Policy Entropy: 3.04612
Value Function Loss: 0.00442

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.60013
Value Function Update Magnitude: 0.50098

Collected Steps per Second: 22,646.78286
Overall Steps per Second: 10,639.44231

Timestep Collection Time: 2.20844
Timestep Consumption Time: 2.49237
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.70081

Cumulative Model Updates: 144,980
Cumulative Timesteps: 1,209,229,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.02747
Policy Entropy: 3.06805
Value Function Loss: 0.00411

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.58718
Value Function Update Magnitude: 0.49776

Collected Steps per Second: 23,562.56170
Overall Steps per Second: 10,937.01999

Timestep Collection Time: 2.12226
Timestep Consumption Time: 2.44991
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.57218

Cumulative Model Updates: 144,986
Cumulative Timesteps: 1,209,279,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1209279138...
Checkpoint 1209279138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.53871
Policy Entropy: 3.06631
Value Function Loss: 0.00412

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.56890
Value Function Update Magnitude: 0.47160

Collected Steps per Second: 23,189.14415
Overall Steps per Second: 10,718.98390

Timestep Collection Time: 2.15756
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.66761

Cumulative Model Updates: 144,992
Cumulative Timesteps: 1,209,329,170

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.18884
Policy Entropy: 3.06496
Value Function Loss: 0.00445

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.57565
Value Function Update Magnitude: 0.47022

Collected Steps per Second: 23,421.30277
Overall Steps per Second: 10,794.03699

Timestep Collection Time: 2.13549
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.63367

Cumulative Model Updates: 144,998
Cumulative Timesteps: 1,209,379,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1209379186...
Checkpoint 1209379186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.72135
Policy Entropy: 3.04999
Value Function Loss: 0.00477

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.59258
Value Function Update Magnitude: 0.50577

Collected Steps per Second: 23,041.22950
Overall Steps per Second: 10,628.02704

Timestep Collection Time: 2.17115
Timestep Consumption Time: 2.53584
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.70699

Cumulative Model Updates: 145,004
Cumulative Timesteps: 1,209,429,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.74162
Policy Entropy: 3.05271
Value Function Loss: 0.00483

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.60051
Value Function Update Magnitude: 0.52335

Collected Steps per Second: 22,704.33550
Overall Steps per Second: 10,712.91735

Timestep Collection Time: 2.20354
Timestep Consumption Time: 2.46652
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.67006

Cumulative Model Updates: 145,010
Cumulative Timesteps: 1,209,479,242

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1209479242...
Checkpoint 1209479242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.15833
Policy Entropy: 3.06196
Value Function Loss: 0.00449

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.58898
Value Function Update Magnitude: 0.51385

Collected Steps per Second: 22,642.86417
Overall Steps per Second: 10,826.43169

Timestep Collection Time: 2.20944
Timestep Consumption Time: 2.41148
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.62091

Cumulative Model Updates: 145,016
Cumulative Timesteps: 1,209,529,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.25312
Policy Entropy: 3.05978
Value Function Loss: 0.00428

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.58906
Value Function Update Magnitude: 0.50169

Collected Steps per Second: 22,988.04180
Overall Steps per Second: 10,688.43216

Timestep Collection Time: 2.17522
Timestep Consumption Time: 2.50311
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.67833

Cumulative Model Updates: 145,022
Cumulative Timesteps: 1,209,579,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1209579274...
Checkpoint 1209579274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.81807
Policy Entropy: 3.05922
Value Function Loss: 0.00433

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.59826
Value Function Update Magnitude: 0.50249

Collected Steps per Second: 22,832.70886
Overall Steps per Second: 10,839.46502

Timestep Collection Time: 2.19002
Timestep Consumption Time: 2.42313
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61314

Cumulative Model Updates: 145,028
Cumulative Timesteps: 1,209,629,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974.49540
Policy Entropy: 3.04974
Value Function Loss: 0.00466

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.60506
Value Function Update Magnitude: 0.52383

Collected Steps per Second: 23,249.80793
Overall Steps per Second: 10,931.19903

Timestep Collection Time: 2.15133
Timestep Consumption Time: 2.42438
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.57571

Cumulative Model Updates: 145,034
Cumulative Timesteps: 1,209,679,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1209679296...
Checkpoint 1209679296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.96798
Policy Entropy: 3.05123
Value Function Loss: 0.00500

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11110
Policy Update Magnitude: 0.61652
Value Function Update Magnitude: 0.53384

Collected Steps per Second: 22,969.05844
Overall Steps per Second: 10,725.50848

Timestep Collection Time: 2.17789
Timestep Consumption Time: 2.48613
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.66402

Cumulative Model Updates: 145,040
Cumulative Timesteps: 1,209,729,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.51917
Policy Entropy: 3.07082
Value Function Loss: 0.00461

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.60724
Value Function Update Magnitude: 0.53868

Collected Steps per Second: 23,652.65649
Overall Steps per Second: 10,873.70618

Timestep Collection Time: 2.11503
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.60064

Cumulative Model Updates: 145,046
Cumulative Timesteps: 1,209,779,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1209779346...
Checkpoint 1209779346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.22340
Policy Entropy: 3.08501
Value Function Loss: 0.00425

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.59139
Value Function Update Magnitude: 0.53586

Collected Steps per Second: 22,822.59883
Overall Steps per Second: 10,655.85033

Timestep Collection Time: 2.19169
Timestep Consumption Time: 2.50245
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.69414

Cumulative Model Updates: 145,052
Cumulative Timesteps: 1,209,829,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,665.17550
Policy Entropy: 3.10049
Value Function Loss: 0.00396

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11790
Policy Update Magnitude: 0.57665
Value Function Update Magnitude: 0.52729

Collected Steps per Second: 22,986.12623
Overall Steps per Second: 10,901.59267

Timestep Collection Time: 2.17566
Timestep Consumption Time: 2.41174
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.58740

Cumulative Model Updates: 145,058
Cumulative Timesteps: 1,209,879,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1209879376...
Checkpoint 1209879376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,915.77204
Policy Entropy: 3.08655
Value Function Loss: 0.00388

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.51827

Collected Steps per Second: 22,475.08642
Overall Steps per Second: 10,640.83723

Timestep Collection Time: 2.22504
Timestep Consumption Time: 2.47459
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.69963

Cumulative Model Updates: 145,064
Cumulative Timesteps: 1,209,929,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,373.99920
Policy Entropy: 3.08502
Value Function Loss: 0.00375

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.56580
Value Function Update Magnitude: 0.51986

Collected Steps per Second: 23,048.23670
Overall Steps per Second: 10,830.49756

Timestep Collection Time: 2.16954
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61696

Cumulative Model Updates: 145,070
Cumulative Timesteps: 1,209,979,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1209979388...
Checkpoint 1209979388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,929.57350
Policy Entropy: 3.07919
Value Function Loss: 0.00382

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.52074

Collected Steps per Second: 22,708.06703
Overall Steps per Second: 10,704.06083

Timestep Collection Time: 2.20318
Timestep Consumption Time: 2.47075
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.67393

Cumulative Model Updates: 145,076
Cumulative Timesteps: 1,210,029,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.96857
Policy Entropy: 3.08855
Value Function Loss: 0.00386

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.57243
Value Function Update Magnitude: 0.50108

Collected Steps per Second: 23,134.92428
Overall Steps per Second: 10,845.81689

Timestep Collection Time: 2.16132
Timestep Consumption Time: 2.44894
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61026

Cumulative Model Updates: 145,082
Cumulative Timesteps: 1,210,079,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1210079420...
Checkpoint 1210079420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.18596
Policy Entropy: 3.08290
Value Function Loss: 0.00400

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.56943
Value Function Update Magnitude: 0.51179

Collected Steps per Second: 22,994.98799
Overall Steps per Second: 10,713.86646

Timestep Collection Time: 2.17500
Timestep Consumption Time: 2.49316
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.66816

Cumulative Model Updates: 145,088
Cumulative Timesteps: 1,210,129,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.77449
Policy Entropy: 3.08583
Value Function Loss: 0.00401

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.56953
Value Function Update Magnitude: 0.52242

Collected Steps per Second: 23,556.85966
Overall Steps per Second: 10,860.52076

Timestep Collection Time: 2.12252
Timestep Consumption Time: 2.48131
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.60383

Cumulative Model Updates: 145,094
Cumulative Timesteps: 1,210,179,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1210179434...
Checkpoint 1210179434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,001.64062
Policy Entropy: 3.07481
Value Function Loss: 0.00401

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.57353
Value Function Update Magnitude: 0.49755

Collected Steps per Second: 22,483.44055
Overall Steps per Second: 10,668.06900

Timestep Collection Time: 2.22430
Timestep Consumption Time: 2.46352
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.68782

Cumulative Model Updates: 145,100
Cumulative Timesteps: 1,210,229,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.19401
Policy Entropy: 3.07181
Value Function Loss: 0.00449

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11359
Policy Update Magnitude: 0.59476
Value Function Update Magnitude: 0.53737

Collected Steps per Second: 23,382.07248
Overall Steps per Second: 10,930.97910

Timestep Collection Time: 2.13856
Timestep Consumption Time: 2.43596
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.57452

Cumulative Model Updates: 145,106
Cumulative Timesteps: 1,210,279,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1210279448...
Checkpoint 1210279448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,816.56908
Policy Entropy: 3.07796
Value Function Loss: 0.00440

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.59828
Value Function Update Magnitude: 0.56152

Collected Steps per Second: 22,927.58228
Overall Steps per Second: 10,728.68783

Timestep Collection Time: 2.18095
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.66077

Cumulative Model Updates: 145,112
Cumulative Timesteps: 1,210,329,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.10862
Policy Entropy: 3.08881
Value Function Loss: 0.00461

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.60048
Value Function Update Magnitude: 0.56801

Collected Steps per Second: 23,345.48209
Overall Steps per Second: 10,834.10193

Timestep Collection Time: 2.14208
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.61580

Cumulative Model Updates: 145,118
Cumulative Timesteps: 1,210,379,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1210379460...
Checkpoint 1210379460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.79398
Policy Entropy: 3.08499
Value Function Loss: 0.00442

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.59675
Value Function Update Magnitude: 0.57996

Collected Steps per Second: 22,731.84280
Overall Steps per Second: 10,612.74738

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.51236
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.71245

Cumulative Model Updates: 145,124
Cumulative Timesteps: 1,210,429,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.94791
Policy Entropy: 3.08507
Value Function Loss: 0.00444

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.59625
Value Function Update Magnitude: 0.58355

Collected Steps per Second: 23,107.08908
Overall Steps per Second: 10,959.07458

Timestep Collection Time: 2.16479
Timestep Consumption Time: 2.39965
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.56444

Cumulative Model Updates: 145,130
Cumulative Timesteps: 1,210,479,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1210479494...
Checkpoint 1210479494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.37413
Policy Entropy: 3.05382
Value Function Loss: 0.00438

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.60601
Value Function Update Magnitude: 0.54662

Collected Steps per Second: 22,399.44756
Overall Steps per Second: 10,597.32106

Timestep Collection Time: 2.23300
Timestep Consumption Time: 2.48687
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.71987

Cumulative Model Updates: 145,136
Cumulative Timesteps: 1,210,529,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.53649
Policy Entropy: 3.04239
Value Function Loss: 0.00431

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.61834
Value Function Update Magnitude: 0.54506

Collected Steps per Second: 22,973.53855
Overall Steps per Second: 10,865.82852

Timestep Collection Time: 2.17764
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.60416

Cumulative Model Updates: 145,142
Cumulative Timesteps: 1,210,579,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1210579540...
Checkpoint 1210579540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,002.75240
Policy Entropy: 3.04052
Value Function Loss: 0.00417

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.60216
Value Function Update Magnitude: 0.55148

Collected Steps per Second: 22,042.79350
Overall Steps per Second: 10,283.71507

Timestep Collection Time: 2.26904
Timestep Consumption Time: 2.59457
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.86361

Cumulative Model Updates: 145,148
Cumulative Timesteps: 1,210,629,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.93639
Policy Entropy: 3.04852
Value Function Loss: 0.00409

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.59196
Value Function Update Magnitude: 0.54322

Collected Steps per Second: 23,007.85781
Overall Steps per Second: 10,848.15415

Timestep Collection Time: 2.17352
Timestep Consumption Time: 2.43630
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.60982

Cumulative Model Updates: 145,154
Cumulative Timesteps: 1,210,679,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1210679564...
Checkpoint 1210679564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.01980
Policy Entropy: 3.04922
Value Function Loss: 0.00432

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.60076
Value Function Update Magnitude: 0.53431

Collected Steps per Second: 22,981.71958
Overall Steps per Second: 10,734.65136

Timestep Collection Time: 2.17616
Timestep Consumption Time: 2.48277
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.65893

Cumulative Model Updates: 145,160
Cumulative Timesteps: 1,210,729,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159.65138
Policy Entropy: 3.06100
Value Function Loss: 0.00404

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.60124
Value Function Update Magnitude: 0.53836

Collected Steps per Second: 23,412.98174
Overall Steps per Second: 10,885.58556

Timestep Collection Time: 2.13565
Timestep Consumption Time: 2.45776
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.59341

Cumulative Model Updates: 145,166
Cumulative Timesteps: 1,210,779,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1210779578...
Checkpoint 1210779578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,635.19310
Policy Entropy: 3.05714
Value Function Loss: 0.00432

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.59549
Value Function Update Magnitude: 0.51877

Collected Steps per Second: 23,319.65909
Overall Steps per Second: 10,786.74288

Timestep Collection Time: 2.14454
Timestep Consumption Time: 2.49170
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.63625

Cumulative Model Updates: 145,172
Cumulative Timesteps: 1,210,829,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.83026
Policy Entropy: 3.06832
Value Function Loss: 0.00412

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.60126
Value Function Update Magnitude: 0.51724

Collected Steps per Second: 23,492.98959
Overall Steps per Second: 10,888.09109

Timestep Collection Time: 2.12889
Timestep Consumption Time: 2.46457
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.59346

Cumulative Model Updates: 145,178
Cumulative Timesteps: 1,210,879,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1210879602...
Checkpoint 1210879602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.78887
Policy Entropy: 3.03537
Value Function Loss: 0.00469

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.60634
Value Function Update Magnitude: 0.52925

Collected Steps per Second: 22,415.90661
Overall Steps per Second: 10,663.02679

Timestep Collection Time: 2.23056
Timestep Consumption Time: 2.45854
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.68910

Cumulative Model Updates: 145,184
Cumulative Timesteps: 1,210,929,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.84908
Policy Entropy: 3.04994
Value Function Loss: 0.00436

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.61414
Value Function Update Magnitude: 0.54518

Collected Steps per Second: 22,738.75982
Overall Steps per Second: 10,740.91535

Timestep Collection Time: 2.20030
Timestep Consumption Time: 2.45778
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.65808

Cumulative Model Updates: 145,190
Cumulative Timesteps: 1,210,979,634

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1210979634...
Checkpoint 1210979634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.13660
Policy Entropy: 3.03282
Value Function Loss: 0.00429

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11873
Policy Update Magnitude: 0.60346
Value Function Update Magnitude: 0.51981

Collected Steps per Second: 22,212.31574
Overall Steps per Second: 10,613.17532

Timestep Collection Time: 2.25217
Timestep Consumption Time: 2.46140
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.71358

Cumulative Model Updates: 145,196
Cumulative Timesteps: 1,211,029,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.89932
Policy Entropy: 3.05492
Value Function Loss: 0.00403

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.59056
Value Function Update Magnitude: 0.50930

Collected Steps per Second: 23,110.43991
Overall Steps per Second: 10,904.38220

Timestep Collection Time: 2.16422
Timestep Consumption Time: 2.42256
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.58678

Cumulative Model Updates: 145,202
Cumulative Timesteps: 1,211,079,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1211079676...
Checkpoint 1211079676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,496.10595
Policy Entropy: 3.05881
Value Function Loss: 0.00401

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.59689
Value Function Update Magnitude: 0.50808

Collected Steps per Second: 22,812.25407
Overall Steps per Second: 10,684.17854

Timestep Collection Time: 2.19259
Timestep Consumption Time: 2.48891
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.68150

Cumulative Model Updates: 145,208
Cumulative Timesteps: 1,211,129,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.01076
Policy Entropy: 3.07239
Value Function Loss: 0.00416

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.59798
Value Function Update Magnitude: 0.51012

Collected Steps per Second: 22,846.28325
Overall Steps per Second: 10,776.12445

Timestep Collection Time: 2.18898
Timestep Consumption Time: 2.45184
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.64081

Cumulative Model Updates: 145,214
Cumulative Timesteps: 1,211,179,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1211179704...
Checkpoint 1211179704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.22537
Policy Entropy: 3.08401
Value Function Loss: 0.00393

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.58774
Value Function Update Magnitude: 0.49450

Collected Steps per Second: 22,958.00801
Overall Steps per Second: 10,720.26755

Timestep Collection Time: 2.17789
Timestep Consumption Time: 2.48617
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.66406

Cumulative Model Updates: 145,220
Cumulative Timesteps: 1,211,229,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.37446
Policy Entropy: 3.08569
Value Function Loss: 0.00392

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.57618
Value Function Update Magnitude: 0.48074

Collected Steps per Second: 23,260.88855
Overall Steps per Second: 10,880.20691

Timestep Collection Time: 2.14979
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.59605

Cumulative Model Updates: 145,226
Cumulative Timesteps: 1,211,279,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1211279710...
Checkpoint 1211279710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.12055
Policy Entropy: 3.08467
Value Function Loss: 0.00406

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.58525
Value Function Update Magnitude: 0.48403

Collected Steps per Second: 22,642.05952
Overall Steps per Second: 10,681.04485

Timestep Collection Time: 2.20890
Timestep Consumption Time: 2.47360
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.68250

Cumulative Model Updates: 145,232
Cumulative Timesteps: 1,211,329,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.23670
Policy Entropy: 3.07049
Value Function Loss: 0.00419

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.59791
Value Function Update Magnitude: 0.49931

Collected Steps per Second: 22,969.59751
Overall Steps per Second: 10,775.84697

Timestep Collection Time: 2.17688
Timestep Consumption Time: 2.46331
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.64019

Cumulative Model Updates: 145,238
Cumulative Timesteps: 1,211,379,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1211379726...
Checkpoint 1211379726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,621.90833
Policy Entropy: 3.07567
Value Function Loss: 0.00423

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.60134
Value Function Update Magnitude: 0.51650

Collected Steps per Second: 22,755.65296
Overall Steps per Second: 10,777.36149

Timestep Collection Time: 2.19743
Timestep Consumption Time: 2.44229
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.63973

Cumulative Model Updates: 145,244
Cumulative Timesteps: 1,211,429,730

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.21025
Policy Entropy: 3.07396
Value Function Loss: 0.00389

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.59481
Value Function Update Magnitude: 0.52189

Collected Steps per Second: 23,009.39610
Overall Steps per Second: 10,912.84481

Timestep Collection Time: 2.17424
Timestep Consumption Time: 2.41008
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.58432

Cumulative Model Updates: 145,250
Cumulative Timesteps: 1,211,479,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1211479758...
Checkpoint 1211479758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.57512
Policy Entropy: 3.06363
Value Function Loss: 0.00392

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.58644
Value Function Update Magnitude: 0.51618

Collected Steps per Second: 22,541.27774
Overall Steps per Second: 10,663.96660

Timestep Collection Time: 2.21824
Timestep Consumption Time: 2.47063
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.68887

Cumulative Model Updates: 145,256
Cumulative Timesteps: 1,211,529,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.07874
Policy Entropy: 3.05689
Value Function Loss: 0.00418

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.59453
Value Function Update Magnitude: 0.51686

Collected Steps per Second: 23,114.61595
Overall Steps per Second: 10,930.65943

Timestep Collection Time: 2.16417
Timestep Consumption Time: 2.41231
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.57649

Cumulative Model Updates: 145,262
Cumulative Timesteps: 1,211,579,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1211579784...
Checkpoint 1211579784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,632.40271
Policy Entropy: 3.05460
Value Function Loss: 0.00425

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.60255
Value Function Update Magnitude: 0.53038

Collected Steps per Second: 22,353.74945
Overall Steps per Second: 10,585.13233

Timestep Collection Time: 2.23775
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.72568

Cumulative Model Updates: 145,268
Cumulative Timesteps: 1,211,629,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,917.28356
Policy Entropy: 3.05260
Value Function Loss: 0.00429

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.59375
Value Function Update Magnitude: 0.52348

Collected Steps per Second: 23,363.03329
Overall Steps per Second: 10,921.76065

Timestep Collection Time: 2.14073
Timestep Consumption Time: 2.43857
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.57930

Cumulative Model Updates: 145,274
Cumulative Timesteps: 1,211,679,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1211679820...
Checkpoint 1211679820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532.78034
Policy Entropy: 3.05266
Value Function Loss: 0.00427

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.59564
Value Function Update Magnitude: 0.52124

Collected Steps per Second: 22,642.77664
Overall Steps per Second: 10,658.23466

Timestep Collection Time: 2.20839
Timestep Consumption Time: 2.48320
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69158

Cumulative Model Updates: 145,280
Cumulative Timesteps: 1,211,729,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.82765
Policy Entropy: 3.04815
Value Function Loss: 0.00440

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.60278
Value Function Update Magnitude: 0.53420

Collected Steps per Second: 23,326.12746
Overall Steps per Second: 10,888.31323

Timestep Collection Time: 2.14455
Timestep Consumption Time: 2.44974
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.59428

Cumulative Model Updates: 145,286
Cumulative Timesteps: 1,211,779,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1211779848...
Checkpoint 1211779848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.69144
Policy Entropy: 3.04613
Value Function Loss: 0.00422

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.60003
Value Function Update Magnitude: 0.55656

Collected Steps per Second: 23,054.75717
Overall Steps per Second: 10,767.92494

Timestep Collection Time: 2.16996
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.64602

Cumulative Model Updates: 145,292
Cumulative Timesteps: 1,211,829,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.14889
Policy Entropy: 3.05409
Value Function Loss: 0.00415

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.58941
Value Function Update Magnitude: 0.54270

Collected Steps per Second: 23,282.38106
Overall Steps per Second: 10,786.25011

Timestep Collection Time: 2.14875
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.63813

Cumulative Model Updates: 145,298
Cumulative Timesteps: 1,211,879,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1211879904...
Checkpoint 1211879904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,993.22854
Policy Entropy: 3.06238
Value Function Loss: 0.00459

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.59594
Value Function Update Magnitude: 0.54234

Collected Steps per Second: 22,720.05633
Overall Steps per Second: 10,657.73959

Timestep Collection Time: 2.20237
Timestep Consumption Time: 2.49262
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.69499

Cumulative Model Updates: 145,304
Cumulative Timesteps: 1,211,929,942

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.53639
Policy Entropy: 3.06491
Value Function Loss: 0.00441

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.60153
Value Function Update Magnitude: 0.55991

Collected Steps per Second: 22,872.17610
Overall Steps per Second: 10,805.85288

Timestep Collection Time: 2.18685
Timestep Consumption Time: 2.44194
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.62879

Cumulative Model Updates: 145,310
Cumulative Timesteps: 1,211,979,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1211979960...
Checkpoint 1211979960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.70840
Policy Entropy: 3.06555
Value Function Loss: 0.00430

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.60260
Value Function Update Magnitude: 0.56153

Collected Steps per Second: 22,631.18515
Overall Steps per Second: 10,764.06903

Timestep Collection Time: 2.21058
Timestep Consumption Time: 2.43711
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.64768

Cumulative Model Updates: 145,316
Cumulative Timesteps: 1,212,029,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,150.83526
Policy Entropy: 3.05822
Value Function Loss: 0.00435

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.60842
Value Function Update Magnitude: 0.56333

Collected Steps per Second: 22,881.48143
Overall Steps per Second: 10,866.53605

Timestep Collection Time: 2.18517
Timestep Consumption Time: 2.41611
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60128

Cumulative Model Updates: 145,322
Cumulative Timesteps: 1,212,079,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1212079988...
Checkpoint 1212079988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.89009
Policy Entropy: 3.04507
Value Function Loss: 0.00450

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.15718
Policy Update Magnitude: 0.61217
Value Function Update Magnitude: 0.58060

Collected Steps per Second: 22,254.19770
Overall Steps per Second: 10,680.94118

Timestep Collection Time: 2.24749
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.68273

Cumulative Model Updates: 145,328
Cumulative Timesteps: 1,212,130,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,042.34694
Policy Entropy: 3.03647
Value Function Loss: 0.00486

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.16584
Policy Update Magnitude: 0.62544
Value Function Update Magnitude: 0.61842

Collected Steps per Second: 23,349.04971
Overall Steps per Second: 10,860.06819

Timestep Collection Time: 2.14176
Timestep Consumption Time: 2.46300
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.60476

Cumulative Model Updates: 145,334
Cumulative Timesteps: 1,212,180,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1212180012...
Checkpoint 1212180012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.88599
Policy Entropy: 3.04166
Value Function Loss: 0.00467

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.64528
Value Function Update Magnitude: 0.62306

Collected Steps per Second: 23,152.07864
Overall Steps per Second: 10,764.10831

Timestep Collection Time: 2.15963
Timestep Consumption Time: 2.48543
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.64507

Cumulative Model Updates: 145,340
Cumulative Timesteps: 1,212,230,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.53345
Policy Entropy: 3.05866
Value Function Loss: 0.00459

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14845
Policy Update Magnitude: 0.63804
Value Function Update Magnitude: 0.59546

Collected Steps per Second: 23,514.39685
Overall Steps per Second: 10,818.37104

Timestep Collection Time: 2.12636
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.62177

Cumulative Model Updates: 145,346
Cumulative Timesteps: 1,212,280,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1212280012...
Checkpoint 1212280012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.71117
Policy Entropy: 3.07797
Value Function Loss: 0.00453

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.61052
Value Function Update Magnitude: 0.55870

Collected Steps per Second: 22,769.63902
Overall Steps per Second: 10,618.08290

Timestep Collection Time: 2.19670
Timestep Consumption Time: 2.51395
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.71064

Cumulative Model Updates: 145,352
Cumulative Timesteps: 1,212,330,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.77839
Policy Entropy: 3.08775
Value Function Loss: 0.00465

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.59639
Value Function Update Magnitude: 0.53417

Collected Steps per Second: 23,283.75981
Overall Steps per Second: 10,879.42118

Timestep Collection Time: 2.14759
Timestep Consumption Time: 2.44861
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.59620

Cumulative Model Updates: 145,358
Cumulative Timesteps: 1,212,380,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1212380034...
Checkpoint 1212380034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.14484
Policy Entropy: 3.09321
Value Function Loss: 0.00466

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.59387
Value Function Update Magnitude: 0.51965

Collected Steps per Second: 23,047.28676
Overall Steps per Second: 10,683.97616

Timestep Collection Time: 2.16971
Timestep Consumption Time: 2.51075
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.68047

Cumulative Model Updates: 145,364
Cumulative Timesteps: 1,212,430,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.44286
Policy Entropy: 3.09103
Value Function Loss: 0.00464

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.61121
Value Function Update Magnitude: 0.52913

Collected Steps per Second: 22,729.12227
Overall Steps per Second: 10,682.38148

Timestep Collection Time: 2.20079
Timestep Consumption Time: 2.48187
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.68266

Cumulative Model Updates: 145,370
Cumulative Timesteps: 1,212,480,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1212480062...
Checkpoint 1212480062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,715.48965
Policy Entropy: 3.07802
Value Function Loss: 0.00465

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11853
Policy Update Magnitude: 0.61793
Value Function Update Magnitude: 0.56312

Collected Steps per Second: 22,543.57352
Overall Steps per Second: 10,804.88040

Timestep Collection Time: 2.21802
Timestep Consumption Time: 2.40971
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.62772

Cumulative Model Updates: 145,376
Cumulative Timesteps: 1,212,530,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.70103
Policy Entropy: 3.07145
Value Function Loss: 0.00430

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.61429
Value Function Update Magnitude: 0.57618

Collected Steps per Second: 22,950.91163
Overall Steps per Second: 10,879.34054

Timestep Collection Time: 2.17856
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.59587

Cumulative Model Updates: 145,382
Cumulative Timesteps: 1,212,580,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1212580064...
Checkpoint 1212580064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.39559
Policy Entropy: 3.06464
Value Function Loss: 0.00422

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.60271
Value Function Update Magnitude: 0.54809

Collected Steps per Second: 22,598.35546
Overall Steps per Second: 10,741.58006

Timestep Collection Time: 2.21335
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.65648

Cumulative Model Updates: 145,388
Cumulative Timesteps: 1,212,630,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.33413
Policy Entropy: 3.05918
Value Function Loss: 0.00419

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.60551
Value Function Update Magnitude: 0.52998

Collected Steps per Second: 23,505.35801
Overall Steps per Second: 10,939.54510

Timestep Collection Time: 2.12769
Timestep Consumption Time: 2.44399
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57167

Cumulative Model Updates: 145,394
Cumulative Timesteps: 1,212,680,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1212680094...
Checkpoint 1212680094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.52053
Policy Entropy: 3.06356
Value Function Loss: 0.00432

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.61018
Value Function Update Magnitude: 0.52822

Collected Steps per Second: 22,995.33825
Overall Steps per Second: 10,782.73714

Timestep Collection Time: 2.17453
Timestep Consumption Time: 2.46288
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.63741

Cumulative Model Updates: 145,400
Cumulative Timesteps: 1,212,730,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.97854
Policy Entropy: 3.07051
Value Function Loss: 0.00414

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.59970
Value Function Update Magnitude: 0.52568

Collected Steps per Second: 23,561.02571
Overall Steps per Second: 10,888.05841

Timestep Collection Time: 2.12334
Timestep Consumption Time: 2.47142
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.59476

Cumulative Model Updates: 145,406
Cumulative Timesteps: 1,212,780,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1212780126...
Checkpoint 1212780126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.22359
Policy Entropy: 3.08045
Value Function Loss: 0.00427

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.60254
Value Function Update Magnitude: 0.54268

Collected Steps per Second: 23,280.55848
Overall Steps per Second: 10,920.42377

Timestep Collection Time: 2.14771
Timestep Consumption Time: 2.43086
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.57858

Cumulative Model Updates: 145,412
Cumulative Timesteps: 1,212,830,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.97180
Policy Entropy: 3.08527
Value Function Loss: 0.00388

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.60196
Value Function Update Magnitude: 0.55468

Collected Steps per Second: 23,527.50463
Overall Steps per Second: 10,961.54856

Timestep Collection Time: 2.12577
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.56268

Cumulative Model Updates: 145,418
Cumulative Timesteps: 1,212,880,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1212880140...
Checkpoint 1212880140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.09801
Policy Entropy: 3.08603
Value Function Loss: 0.00408

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.58475
Value Function Update Magnitude: 0.50842

Collected Steps per Second: 22,425.60321
Overall Steps per Second: 10,628.87240

Timestep Collection Time: 2.23031
Timestep Consumption Time: 2.47537
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.70567

Cumulative Model Updates: 145,424
Cumulative Timesteps: 1,212,930,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954.63463
Policy Entropy: 3.07985
Value Function Loss: 0.00436

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.51557

Collected Steps per Second: 22,766.75148
Overall Steps per Second: 10,784.94273

Timestep Collection Time: 2.19733
Timestep Consumption Time: 2.44118
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.63850

Cumulative Model Updates: 145,430
Cumulative Timesteps: 1,212,980,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1212980182...
Checkpoint 1212980182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,369.13973
Policy Entropy: 3.07764
Value Function Loss: 0.00486

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.61110
Value Function Update Magnitude: 0.55864

Collected Steps per Second: 22,456.06586
Overall Steps per Second: 10,730.83234

Timestep Collection Time: 2.22702
Timestep Consumption Time: 2.43339
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.66040

Cumulative Model Updates: 145,436
Cumulative Timesteps: 1,213,030,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,806.30965
Policy Entropy: 3.09092
Value Function Loss: 0.00442

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.60453
Value Function Update Magnitude: 0.57225

Collected Steps per Second: 22,737.73570
Overall Steps per Second: 10,686.27784

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.48199
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.68283

Cumulative Model Updates: 145,442
Cumulative Timesteps: 1,213,080,234

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1213080234...
Checkpoint 1213080234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.85051
Policy Entropy: 3.09931
Value Function Loss: 0.00413

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.58099
Value Function Update Magnitude: 0.57380

Collected Steps per Second: 22,527.05620
Overall Steps per Second: 10,629.26914

Timestep Collection Time: 2.22062
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.70625

Cumulative Model Updates: 145,448
Cumulative Timesteps: 1,213,130,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,009.31459
Policy Entropy: 3.09907
Value Function Loss: 0.00381

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.57154
Value Function Update Magnitude: 0.55044

Collected Steps per Second: 23,289.65193
Overall Steps per Second: 10,712.21222

Timestep Collection Time: 2.14799
Timestep Consumption Time: 2.52200
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.67000

Cumulative Model Updates: 145,454
Cumulative Timesteps: 1,213,180,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1213180284...
Checkpoint 1213180284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.71459
Policy Entropy: 3.09508
Value Function Loss: 0.00393

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.57697
Value Function Update Magnitude: 0.54980

Collected Steps per Second: 22,863.00076
Overall Steps per Second: 10,613.55132

Timestep Collection Time: 2.18781
Timestep Consumption Time: 2.52503
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.71284

Cumulative Model Updates: 145,460
Cumulative Timesteps: 1,213,230,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.03693
Policy Entropy: 3.09725
Value Function Loss: 0.00415

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.58586
Value Function Update Magnitude: 0.57285

Collected Steps per Second: 23,534.32175
Overall Steps per Second: 10,960.53733

Timestep Collection Time: 2.12532
Timestep Consumption Time: 2.43814
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.56346

Cumulative Model Updates: 145,466
Cumulative Timesteps: 1,213,280,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1213280322...
Checkpoint 1213280322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,741.71175
Policy Entropy: 3.08375
Value Function Loss: 0.00452

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.59259
Value Function Update Magnitude: 0.58015

Collected Steps per Second: 21,879.75281
Overall Steps per Second: 10,685.07493

Timestep Collection Time: 2.28549
Timestep Consumption Time: 2.39449
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.67999

Cumulative Model Updates: 145,472
Cumulative Timesteps: 1,213,330,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.05134
Policy Entropy: 3.08522
Value Function Loss: 0.00455

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.59951
Value Function Update Magnitude: 0.60650

Collected Steps per Second: 22,984.16462
Overall Steps per Second: 10,821.91941

Timestep Collection Time: 2.17646
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.62247

Cumulative Model Updates: 145,478
Cumulative Timesteps: 1,213,380,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1213380352...
Checkpoint 1213380352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,339.49197
Policy Entropy: 3.08802
Value Function Loss: 0.00432

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.59092
Value Function Update Magnitude: 0.60288

Collected Steps per Second: 22,455.37217
Overall Steps per Second: 10,654.98928

Timestep Collection Time: 2.22682
Timestep Consumption Time: 2.46620
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.69301

Cumulative Model Updates: 145,484
Cumulative Timesteps: 1,213,430,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,979.08000
Policy Entropy: 3.10221
Value Function Loss: 0.00406

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.58079
Value Function Update Magnitude: 0.57087

Collected Steps per Second: 23,385.00740
Overall Steps per Second: 10,873.83813

Timestep Collection Time: 2.13932
Timestep Consumption Time: 2.46145
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60077

Cumulative Model Updates: 145,490
Cumulative Timesteps: 1,213,480,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1213480384...
Checkpoint 1213480384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.46268
Policy Entropy: 3.10533
Value Function Loss: 0.00424

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.59009
Value Function Update Magnitude: 0.56758

Collected Steps per Second: 23,065.47537
Overall Steps per Second: 10,702.08530

Timestep Collection Time: 2.16852
Timestep Consumption Time: 2.50515
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.67367

Cumulative Model Updates: 145,496
Cumulative Timesteps: 1,213,530,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.70345
Policy Entropy: 3.11303
Value Function Loss: 0.00432

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.59615
Value Function Update Magnitude: 0.57432

Collected Steps per Second: 23,446.32576
Overall Steps per Second: 10,910.75812

Timestep Collection Time: 2.13287
Timestep Consumption Time: 2.45049
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.58337

Cumulative Model Updates: 145,502
Cumulative Timesteps: 1,213,580,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1213580410...
Checkpoint 1213580410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.36231
Policy Entropy: 3.11398
Value Function Loss: 0.00433

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10938
Policy Update Magnitude: 0.58974
Value Function Update Magnitude: 0.57110

Collected Steps per Second: 23,144.21965
Overall Steps per Second: 10,852.77487

Timestep Collection Time: 2.16132
Timestep Consumption Time: 2.44783
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.60914

Cumulative Model Updates: 145,508
Cumulative Timesteps: 1,213,630,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,448.45797
Policy Entropy: 3.10668
Value Function Loss: 0.00421

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.60042
Value Function Update Magnitude: 0.59743

Collected Steps per Second: 23,714.16886
Overall Steps per Second: 10,877.13581

Timestep Collection Time: 2.10861
Timestep Consumption Time: 2.48855
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.59717

Cumulative Model Updates: 145,514
Cumulative Timesteps: 1,213,680,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1213680436...
Checkpoint 1213680436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.17777
Policy Entropy: 3.08331
Value Function Loss: 0.00447

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.60832
Value Function Update Magnitude: 0.62970

Collected Steps per Second: 22,823.94733
Overall Steps per Second: 10,832.82790

Timestep Collection Time: 2.19121
Timestep Consumption Time: 2.42550
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.61671

Cumulative Model Updates: 145,520
Cumulative Timesteps: 1,213,730,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.06892
Policy Entropy: 3.08503
Value Function Loss: 0.00433

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.61056
Value Function Update Magnitude: 0.63320

Collected Steps per Second: 22,368.75146
Overall Steps per Second: 10,514.26489

Timestep Collection Time: 2.23526
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.75544

Cumulative Model Updates: 145,526
Cumulative Timesteps: 1,213,780,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1213780448...
Checkpoint 1213780448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.51114
Policy Entropy: 3.08412
Value Function Loss: 0.00436

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.60452
Value Function Update Magnitude: 0.60654

Collected Steps per Second: 22,620.70760
Overall Steps per Second: 10,647.77485

Timestep Collection Time: 2.21036
Timestep Consumption Time: 2.48545
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.69582

Cumulative Model Updates: 145,532
Cumulative Timesteps: 1,213,830,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,408.95516
Policy Entropy: 3.09277
Value Function Loss: 0.00404

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.56818

Collected Steps per Second: 23,095.56393
Overall Steps per Second: 10,843.65012

Timestep Collection Time: 2.16518
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61155

Cumulative Model Updates: 145,538
Cumulative Timesteps: 1,213,880,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1213880454...
Checkpoint 1213880454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.85517
Policy Entropy: 3.08859
Value Function Loss: 0.00392

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.54265

Collected Steps per Second: 22,690.12017
Overall Steps per Second: 10,731.76806

Timestep Collection Time: 2.20369
Timestep Consumption Time: 2.45556
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.65925

Cumulative Model Updates: 145,544
Cumulative Timesteps: 1,213,930,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,395.55416
Policy Entropy: 3.08521
Value Function Loss: 0.00389

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.58197
Value Function Update Magnitude: 0.55346

Collected Steps per Second: 23,207.24604
Overall Steps per Second: 10,824.78171

Timestep Collection Time: 2.15536
Timestep Consumption Time: 2.46552
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.62088

Cumulative Model Updates: 145,550
Cumulative Timesteps: 1,213,980,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1213980476...
Checkpoint 1213980476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,480.56424
Policy Entropy: 3.07902
Value Function Loss: 0.00400

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.59742
Value Function Update Magnitude: 0.55602

Collected Steps per Second: 23,045.61215
Overall Steps per Second: 10,760.71921

Timestep Collection Time: 2.17022
Timestep Consumption Time: 2.47761
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.64783

Cumulative Model Updates: 145,556
Cumulative Timesteps: 1,214,030,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.88881
Policy Entropy: 3.07607
Value Function Loss: 0.00452

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.60662
Value Function Update Magnitude: 0.56703

Collected Steps per Second: 23,248.72215
Overall Steps per Second: 10,858.99868

Timestep Collection Time: 2.15152
Timestep Consumption Time: 2.45480
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.60632

Cumulative Model Updates: 145,562
Cumulative Timesteps: 1,214,080,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1214080510...
Checkpoint 1214080510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,177.40334
Policy Entropy: 3.07427
Value Function Loss: 0.00440

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.59904
Value Function Update Magnitude: 0.56805

Collected Steps per Second: 22,924.20037
Overall Steps per Second: 10,623.32114

Timestep Collection Time: 2.18197
Timestep Consumption Time: 2.52654
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.70851

Cumulative Model Updates: 145,568
Cumulative Timesteps: 1,214,130,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.18175
Policy Entropy: 3.06699
Value Function Loss: 0.00446

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.58912
Value Function Update Magnitude: 0.53631

Collected Steps per Second: 23,120.37137
Overall Steps per Second: 10,848.80836

Timestep Collection Time: 2.16441
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.61267

Cumulative Model Updates: 145,574
Cumulative Timesteps: 1,214,180,572

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1214180572...
Checkpoint 1214180572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022.52891
Policy Entropy: 3.06942
Value Function Loss: 0.00426

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.58058
Value Function Update Magnitude: 0.52620

Collected Steps per Second: 22,895.20575
Overall Steps per Second: 10,716.62863

Timestep Collection Time: 2.18447
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.66695

Cumulative Model Updates: 145,580
Cumulative Timesteps: 1,214,230,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.99813
Policy Entropy: 3.07900
Value Function Loss: 0.00435

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.58150
Value Function Update Magnitude: 0.54083

Collected Steps per Second: 22,971.27075
Overall Steps per Second: 10,878.26288

Timestep Collection Time: 2.17681
Timestep Consumption Time: 2.41988
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.59669

Cumulative Model Updates: 145,586
Cumulative Timesteps: 1,214,280,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1214280590...
Checkpoint 1214280590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.05826
Policy Entropy: 3.08755
Value Function Loss: 0.00416

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.57557
Value Function Update Magnitude: 0.53033

Collected Steps per Second: 22,723.44237
Overall Steps per Second: 10,695.57992

Timestep Collection Time: 2.20072
Timestep Consumption Time: 2.47485
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.67558

Cumulative Model Updates: 145,592
Cumulative Timesteps: 1,214,330,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,697.99759
Policy Entropy: 3.09227
Value Function Loss: 0.00423

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.51805

Collected Steps per Second: 22,785.36407
Overall Steps per Second: 10,822.12702

Timestep Collection Time: 2.19509
Timestep Consumption Time: 2.42655
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.62164

Cumulative Model Updates: 145,598
Cumulative Timesteps: 1,214,380,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1214380614...
Checkpoint 1214380614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274.87388
Policy Entropy: 3.09824
Value Function Loss: 0.00420

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.57080
Value Function Update Magnitude: 0.50512

Collected Steps per Second: 22,888.54730
Overall Steps per Second: 10,717.38528

Timestep Collection Time: 2.18502
Timestep Consumption Time: 2.48141
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.66644

Cumulative Model Updates: 145,604
Cumulative Timesteps: 1,214,430,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,019.25674
Policy Entropy: 3.08931
Value Function Loss: 0.00430

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.58027
Value Function Update Magnitude: 0.50719

Collected Steps per Second: 23,379.49688
Overall Steps per Second: 10,900.34135

Timestep Collection Time: 2.13957
Timestep Consumption Time: 2.44946
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.58903

Cumulative Model Updates: 145,610
Cumulative Timesteps: 1,214,480,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1214480648...
Checkpoint 1214480648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.20799
Policy Entropy: 3.09360
Value Function Loss: 0.00432

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.59518
Value Function Update Magnitude: 0.53799

Collected Steps per Second: 23,023.14019
Overall Steps per Second: 10,803.30679

Timestep Collection Time: 2.17251
Timestep Consumption Time: 2.45737
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.62988

Cumulative Model Updates: 145,616
Cumulative Timesteps: 1,214,530,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.95046
Policy Entropy: 3.09059
Value Function Loss: 0.00440

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.59208
Value Function Update Magnitude: 0.54940

Collected Steps per Second: 23,336.00123
Overall Steps per Second: 10,795.07061

Timestep Collection Time: 2.14338
Timestep Consumption Time: 2.49003
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.63341

Cumulative Model Updates: 145,622
Cumulative Timesteps: 1,214,580,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1214580684...
Checkpoint 1214580684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.47009
Policy Entropy: 3.10930
Value Function Loss: 0.00433

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.58682
Value Function Update Magnitude: 0.53232

Collected Steps per Second: 23,106.02047
Overall Steps per Second: 10,934.34532

Timestep Collection Time: 2.16411
Timestep Consumption Time: 2.40900
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.57311

Cumulative Model Updates: 145,628
Cumulative Timesteps: 1,214,630,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.02154
Policy Entropy: 3.09364
Value Function Loss: 0.00444

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.58810
Value Function Update Magnitude: 0.53090

Collected Steps per Second: 23,253.61557
Overall Steps per Second: 10,783.40104

Timestep Collection Time: 2.15063
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.63768

Cumulative Model Updates: 145,634
Cumulative Timesteps: 1,214,680,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1214680698...
Checkpoint 1214680698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.95071
Policy Entropy: 3.09011
Value Function Loss: 0.00449

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.59693
Value Function Update Magnitude: 0.54694

Collected Steps per Second: 22,735.46793
Overall Steps per Second: 10,869.58766

Timestep Collection Time: 2.19973
Timestep Consumption Time: 2.40136
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60109

Cumulative Model Updates: 145,640
Cumulative Timesteps: 1,214,730,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.53231
Policy Entropy: 3.07152
Value Function Loss: 0.00453

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.60255
Value Function Update Magnitude: 0.55319

Collected Steps per Second: 22,931.54081
Overall Steps per Second: 10,879.43105

Timestep Collection Time: 2.18049
Timestep Consumption Time: 2.41552
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.59601

Cumulative Model Updates: 145,646
Cumulative Timesteps: 1,214,780,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1214780712...
Checkpoint 1214780712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,112.28390
Policy Entropy: 3.08318
Value Function Loss: 0.00452

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.60276
Value Function Update Magnitude: 0.56326

Collected Steps per Second: 22,442.37730
Overall Steps per Second: 10,654.80197

Timestep Collection Time: 2.22811
Timestep Consumption Time: 2.46499
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.69310

Cumulative Model Updates: 145,652
Cumulative Timesteps: 1,214,830,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.41486
Policy Entropy: 3.07437
Value Function Loss: 0.00413

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.52995

Collected Steps per Second: 22,937.87857
Overall Steps per Second: 10,865.49508

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.42357
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.60485

Cumulative Model Updates: 145,658
Cumulative Timesteps: 1,214,880,750

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1214880750...
Checkpoint 1214880750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.48448
Policy Entropy: 3.08615
Value Function Loss: 0.00406

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.56954
Value Function Update Magnitude: 0.48746

Collected Steps per Second: 22,491.78735
Overall Steps per Second: 10,681.95384

Timestep Collection Time: 2.22410
Timestep Consumption Time: 2.45894
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.68304

Cumulative Model Updates: 145,664
Cumulative Timesteps: 1,214,930,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.71178
Policy Entropy: 3.08606
Value Function Loss: 0.00392

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.56612
Value Function Update Magnitude: 0.48494

Collected Steps per Second: 23,208.43638
Overall Steps per Second: 10,804.94741

Timestep Collection Time: 2.15473
Timestep Consumption Time: 2.47352
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.62825

Cumulative Model Updates: 145,670
Cumulative Timesteps: 1,214,980,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1214980782...
Checkpoint 1214980782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.99672
Policy Entropy: 3.09914
Value Function Loss: 0.00377

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.50499

Collected Steps per Second: 23,199.15278
Overall Steps per Second: 10,738.76687

Timestep Collection Time: 2.15594
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.65752

Cumulative Model Updates: 145,676
Cumulative Timesteps: 1,215,030,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,041.15614
Policy Entropy: 3.09544
Value Function Loss: 0.00380

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.56449
Value Function Update Magnitude: 0.51134

Collected Steps per Second: 23,319.97560
Overall Steps per Second: 10,886.70215

Timestep Collection Time: 2.14520
Timestep Consumption Time: 2.44995
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.59515

Cumulative Model Updates: 145,682
Cumulative Timesteps: 1,215,080,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1215080824...
Checkpoint 1215080824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.43974
Policy Entropy: 3.09209
Value Function Loss: 0.00399

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.57420
Value Function Update Magnitude: 0.53274

Collected Steps per Second: 22,801.44905
Overall Steps per Second: 10,685.41594

Timestep Collection Time: 2.19354
Timestep Consumption Time: 2.48723
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.68077

Cumulative Model Updates: 145,688
Cumulative Timesteps: 1,215,130,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715.90184
Policy Entropy: 3.08716
Value Function Loss: 0.00420

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.53714

Collected Steps per Second: 23,253.65510
Overall Steps per Second: 10,854.22353

Timestep Collection Time: 2.15123
Timestep Consumption Time: 2.45748
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.60871

Cumulative Model Updates: 145,694
Cumulative Timesteps: 1,215,180,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1215180864...
Checkpoint 1215180864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.53590
Policy Entropy: 3.08440
Value Function Loss: 0.00443

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 0.58614
Value Function Update Magnitude: 0.53087

Collected Steps per Second: 22,870.40242
Overall Steps per Second: 10,717.04580

Timestep Collection Time: 2.18667
Timestep Consumption Time: 2.47973
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.66640

Cumulative Model Updates: 145,700
Cumulative Timesteps: 1,215,230,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,121.19762
Policy Entropy: 3.08502
Value Function Loss: 0.00438

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.58788
Value Function Update Magnitude: 0.53821

Collected Steps per Second: 22,507.05707
Overall Steps per Second: 10,672.69715

Timestep Collection Time: 2.22277
Timestep Consumption Time: 2.46471
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.68747

Cumulative Model Updates: 145,706
Cumulative Timesteps: 1,215,280,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1215280902...
Checkpoint 1215280902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.99324
Policy Entropy: 3.07166
Value Function Loss: 0.00439

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.59264
Value Function Update Magnitude: 0.53373

Collected Steps per Second: 22,783.22194
Overall Steps per Second: 10,824.50062

Timestep Collection Time: 2.19469
Timestep Consumption Time: 2.42465
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61934

Cumulative Model Updates: 145,712
Cumulative Timesteps: 1,215,330,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.70180
Policy Entropy: 3.08774
Value Function Loss: 0.00433

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.58916
Value Function Update Magnitude: 0.53789

Collected Steps per Second: 22,639.93525
Overall Steps per Second: 10,683.23069

Timestep Collection Time: 2.20875
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68079

Cumulative Model Updates: 145,718
Cumulative Timesteps: 1,215,380,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1215380910...
Checkpoint 1215380910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.59225
Policy Entropy: 3.09351
Value Function Loss: 0.00431

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.58237
Value Function Update Magnitude: 0.53207

Collected Steps per Second: 22,969.71431
Overall Steps per Second: 10,886.96105

Timestep Collection Time: 2.17756
Timestep Consumption Time: 2.41674
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.59430

Cumulative Model Updates: 145,724
Cumulative Timesteps: 1,215,430,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,030.18615
Policy Entropy: 3.10835
Value Function Loss: 0.00410

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.53457

Collected Steps per Second: 23,439.33647
Overall Steps per Second: 10,838.29261

Timestep Collection Time: 2.13385
Timestep Consumption Time: 2.48090
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61475

Cumulative Model Updates: 145,730
Cumulative Timesteps: 1,215,480,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1215480944...
Checkpoint 1215480944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,967.08938
Policy Entropy: 3.09719
Value Function Loss: 0.00385

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.56773
Value Function Update Magnitude: 0.51257

Collected Steps per Second: 22,871.04999
Overall Steps per Second: 10,766.38385

Timestep Collection Time: 2.18626
Timestep Consumption Time: 2.45801
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.64427

Cumulative Model Updates: 145,736
Cumulative Timesteps: 1,215,530,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.96827
Policy Entropy: 3.09197
Value Function Loss: 0.00407

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.56623
Value Function Update Magnitude: 0.49164

Collected Steps per Second: 23,278.36672
Overall Steps per Second: 10,888.48913

Timestep Collection Time: 2.14886
Timestep Consumption Time: 2.44516
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.59403

Cumulative Model Updates: 145,742
Cumulative Timesteps: 1,215,580,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1215580968...
Checkpoint 1215580968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.49052
Policy Entropy: 3.09712
Value Function Loss: 0.00404

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.57288
Value Function Update Magnitude: 0.49359

Collected Steps per Second: 23,276.21499
Overall Steps per Second: 10,707.08419

Timestep Collection Time: 2.14855
Timestep Consumption Time: 2.52219
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.67074

Cumulative Model Updates: 145,748
Cumulative Timesteps: 1,215,630,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.48405
Policy Entropy: 3.09887
Value Function Loss: 0.00431

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.57653
Value Function Update Magnitude: 0.51231

Collected Steps per Second: 23,339.89197
Overall Steps per Second: 10,860.05028

Timestep Collection Time: 2.14303
Timestep Consumption Time: 2.46266
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.60569

Cumulative Model Updates: 145,754
Cumulative Timesteps: 1,215,680,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1215680996...
Checkpoint 1215680996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,236.46369
Policy Entropy: 3.10352
Value Function Loss: 0.00400

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.53628

Collected Steps per Second: 22,990.12596
Overall Steps per Second: 10,680.61028

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.68194

Cumulative Model Updates: 145,760
Cumulative Timesteps: 1,215,731,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,830.23979
Policy Entropy: 3.09342
Value Function Loss: 0.00391

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.57440
Value Function Update Magnitude: 0.53397

Collected Steps per Second: 22,836.36993
Overall Steps per Second: 10,777.40601

Timestep Collection Time: 2.19010
Timestep Consumption Time: 2.45053
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.64063

Cumulative Model Updates: 145,766
Cumulative Timesteps: 1,215,781,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1215781016...
Checkpoint 1215781016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,647.60496
Policy Entropy: 3.09144
Value Function Loss: 0.00391

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.57117
Value Function Update Magnitude: 0.53175

Collected Steps per Second: 22,754.43190
Overall Steps per Second: 10,690.16297

Timestep Collection Time: 2.19790
Timestep Consumption Time: 2.48042
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.67832

Cumulative Model Updates: 145,772
Cumulative Timesteps: 1,215,831,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,186.35632
Policy Entropy: 3.08522
Value Function Loss: 0.00419

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.58611
Value Function Update Magnitude: 0.54103

Collected Steps per Second: 22,782.25292
Overall Steps per Second: 10,855.35257

Timestep Collection Time: 2.19583
Timestep Consumption Time: 2.41259
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.60842

Cumulative Model Updates: 145,778
Cumulative Timesteps: 1,215,881,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1215881054...
Checkpoint 1215881054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,249.52889
Policy Entropy: 3.09580
Value Function Loss: 0.00439

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.59269
Value Function Update Magnitude: 0.55787

Collected Steps per Second: 22,642.17859
Overall Steps per Second: 10,719.86503

Timestep Collection Time: 2.20836
Timestep Consumption Time: 2.45607
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.66442

Cumulative Model Updates: 145,784
Cumulative Timesteps: 1,215,931,056

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,411.00097
Policy Entropy: 3.09464
Value Function Loss: 0.00430

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.58574
Value Function Update Magnitude: 0.55147

Collected Steps per Second: 23,302.24845
Overall Steps per Second: 10,824.12694

Timestep Collection Time: 2.14666
Timestep Consumption Time: 2.47468
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.62134

Cumulative Model Updates: 145,790
Cumulative Timesteps: 1,215,981,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1215981078...
Checkpoint 1215981078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.15873
Policy Entropy: 3.07990
Value Function Loss: 0.00445

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.57479
Value Function Update Magnitude: 0.52388

Collected Steps per Second: 22,896.21619
Overall Steps per Second: 10,602.38349

Timestep Collection Time: 2.18490
Timestep Consumption Time: 2.53347
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.71837

Cumulative Model Updates: 145,796
Cumulative Timesteps: 1,216,031,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,467.33023
Policy Entropy: 3.07089
Value Function Loss: 0.00416

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.51042

Collected Steps per Second: 23,021.40918
Overall Steps per Second: 10,925.29105

Timestep Collection Time: 2.17215
Timestep Consumption Time: 2.40493
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.57709

Cumulative Model Updates: 145,802
Cumulative Timesteps: 1,216,081,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1216081110...
Checkpoint 1216081110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,584.47915
Policy Entropy: 3.06059
Value Function Loss: 0.00419

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.56288
Value Function Update Magnitude: 0.50483

Collected Steps per Second: 22,978.91079
Overall Steps per Second: 10,748.45892

Timestep Collection Time: 2.17643
Timestep Consumption Time: 2.47652
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.65295

Cumulative Model Updates: 145,808
Cumulative Timesteps: 1,216,131,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,708.43785
Policy Entropy: 3.06988
Value Function Loss: 0.00399

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.51072

Collected Steps per Second: 23,014.64103
Overall Steps per Second: 10,838.31160

Timestep Collection Time: 2.17375
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.61585

Cumulative Model Updates: 145,814
Cumulative Timesteps: 1,216,181,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1216181150...
Checkpoint 1216181150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,115.30964
Policy Entropy: 3.06733
Value Function Loss: 0.00400

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.52983

Collected Steps per Second: 22,885.24309
Overall Steps per Second: 10,687.46271

Timestep Collection Time: 2.18508
Timestep Consumption Time: 2.49386
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.67894

Cumulative Model Updates: 145,820
Cumulative Timesteps: 1,216,231,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,479.90468
Policy Entropy: 3.06859
Value Function Loss: 0.00406

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.58687
Value Function Update Magnitude: 0.54197

Collected Steps per Second: 22,642.29221
Overall Steps per Second: 10,626.93069

Timestep Collection Time: 2.20888
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70634

Cumulative Model Updates: 145,826
Cumulative Timesteps: 1,216,281,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1216281170...
Checkpoint 1216281170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,552.82664
Policy Entropy: 3.06240
Value Function Loss: 0.00375

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10573
Policy Update Magnitude: 0.58595
Value Function Update Magnitude: 0.53196

Collected Steps per Second: 22,079.28694
Overall Steps per Second: 10,494.68539

Timestep Collection Time: 2.26502
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.76527

Cumulative Model Updates: 145,832
Cumulative Timesteps: 1,216,331,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,195.39158
Policy Entropy: 3.06136
Value Function Loss: 0.00392

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.58922
Value Function Update Magnitude: 0.53146

Collected Steps per Second: 22,809.95888
Overall Steps per Second: 10,776.84758

Timestep Collection Time: 2.19246
Timestep Consumption Time: 2.44804
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.64050

Cumulative Model Updates: 145,838
Cumulative Timesteps: 1,216,381,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1216381190...
Checkpoint 1216381190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.86321
Policy Entropy: 3.05617
Value Function Loss: 0.00378

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.58123
Value Function Update Magnitude: 0.52637

Collected Steps per Second: 22,221.82524
Overall Steps per Second: 10,488.92868

Timestep Collection Time: 2.25031
Timestep Consumption Time: 2.51719
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.76750

Cumulative Model Updates: 145,844
Cumulative Timesteps: 1,216,431,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,359.76392
Policy Entropy: 3.06430
Value Function Loss: 0.00403

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.57810
Value Function Update Magnitude: 0.51145

Collected Steps per Second: 23,463.10736
Overall Steps per Second: 10,727.79182

Timestep Collection Time: 2.13177
Timestep Consumption Time: 2.53070
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.66247

Cumulative Model Updates: 145,850
Cumulative Timesteps: 1,216,481,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1216481214...
Checkpoint 1216481214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.47655
Policy Entropy: 3.06587
Value Function Loss: 0.00429

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.57785
Value Function Update Magnitude: 0.53467

Collected Steps per Second: 23,120.89441
Overall Steps per Second: 10,743.45772

Timestep Collection Time: 2.16263
Timestep Consumption Time: 2.49155
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.65418

Cumulative Model Updates: 145,856
Cumulative Timesteps: 1,216,531,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,961.82104
Policy Entropy: 3.05861
Value Function Loss: 0.00421

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.57517
Value Function Update Magnitude: 0.53951

Collected Steps per Second: 23,230.40205
Overall Steps per Second: 10,766.91161

Timestep Collection Time: 2.15235
Timestep Consumption Time: 2.49151
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.64386

Cumulative Model Updates: 145,862
Cumulative Timesteps: 1,216,581,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1216581216...
Checkpoint 1216581216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.29451
Policy Entropy: 3.05488
Value Function Loss: 0.00401

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.57954
Value Function Update Magnitude: 0.52799

Collected Steps per Second: 22,749.04040
Overall Steps per Second: 10,626.62450

Timestep Collection Time: 2.19842
Timestep Consumption Time: 2.50787
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.70629

Cumulative Model Updates: 145,868
Cumulative Timesteps: 1,216,631,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970.08278
Policy Entropy: 3.06853
Value Function Loss: 0.00381

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.58169
Value Function Update Magnitude: 0.51690

Collected Steps per Second: 22,911.74024
Overall Steps per Second: 10,826.72871

Timestep Collection Time: 2.18342
Timestep Consumption Time: 2.43718
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62060

Cumulative Model Updates: 145,874
Cumulative Timesteps: 1,216,681,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1216681254...
Checkpoint 1216681254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,247.43706
Policy Entropy: 3.05783
Value Function Loss: 0.00443

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.58778
Value Function Update Magnitude: 0.52178

Collected Steps per Second: 22,976.16462
Overall Steps per Second: 10,794.62200

Timestep Collection Time: 2.17756
Timestep Consumption Time: 2.45734
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.63490

Cumulative Model Updates: 145,880
Cumulative Timesteps: 1,216,731,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.31458
Policy Entropy: 3.04853
Value Function Loss: 0.00490

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.60454
Value Function Update Magnitude: 0.53622

Collected Steps per Second: 22,633.82698
Overall Steps per Second: 10,626.52677

Timestep Collection Time: 2.20979
Timestep Consumption Time: 2.49692
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.70671

Cumulative Model Updates: 145,886
Cumulative Timesteps: 1,216,781,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1216781302...
Checkpoint 1216781302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.88304
Policy Entropy: 3.04514
Value Function Loss: 0.00504

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.62140
Value Function Update Magnitude: 0.58281

Collected Steps per Second: 22,933.55915
Overall Steps per Second: 10,815.67522

Timestep Collection Time: 2.18134
Timestep Consumption Time: 2.44398
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.62532

Cumulative Model Updates: 145,892
Cumulative Timesteps: 1,216,831,328

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.11182
Policy Entropy: 3.07221
Value Function Loss: 0.00471

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.61092
Value Function Update Magnitude: 0.59270

Collected Steps per Second: 22,803.37479
Overall Steps per Second: 10,760.93698

Timestep Collection Time: 2.19397
Timestep Consumption Time: 2.45525
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.64922

Cumulative Model Updates: 145,898
Cumulative Timesteps: 1,216,881,358

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1216881358...
Checkpoint 1216881358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.51961
Policy Entropy: 3.07202
Value Function Loss: 0.00460

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.60178
Value Function Update Magnitude: 0.60398

Collected Steps per Second: 22,832.35021
Overall Steps per Second: 10,817.16074

Timestep Collection Time: 2.19005
Timestep Consumption Time: 2.43260
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.62265

Cumulative Model Updates: 145,904
Cumulative Timesteps: 1,216,931,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532.96501
Policy Entropy: 3.05815
Value Function Loss: 0.00450

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.60804
Value Function Update Magnitude: 0.60451

Collected Steps per Second: 22,875.92161
Overall Steps per Second: 10,675.05545

Timestep Collection Time: 2.18667
Timestep Consumption Time: 2.49921
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.68588

Cumulative Model Updates: 145,910
Cumulative Timesteps: 1,216,981,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1216981384...
Checkpoint 1216981384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,496.83031
Policy Entropy: 3.05830
Value Function Loss: 0.00417

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10570
Policy Update Magnitude: 0.60333
Value Function Update Magnitude: 0.61090

Collected Steps per Second: 23,287.72754
Overall Steps per Second: 10,884.91798

Timestep Collection Time: 2.14817
Timestep Consumption Time: 2.44773
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.59590

Cumulative Model Updates: 145,916
Cumulative Timesteps: 1,217,031,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.73236
Policy Entropy: 3.06393
Value Function Loss: 0.00415

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.59866
Value Function Update Magnitude: 0.58384

Collected Steps per Second: 22,916.52376
Overall Steps per Second: 10,719.34191

Timestep Collection Time: 2.18244
Timestep Consumption Time: 2.48333
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.66577

Cumulative Model Updates: 145,922
Cumulative Timesteps: 1,217,081,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1217081424...
Checkpoint 1217081424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.44136
Policy Entropy: 3.06386
Value Function Loss: 0.00459

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.61054
Value Function Update Magnitude: 0.58390

Collected Steps per Second: 23,072.34275
Overall Steps per Second: 10,854.80316

Timestep Collection Time: 2.16814
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.60847

Cumulative Model Updates: 145,928
Cumulative Timesteps: 1,217,131,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880.95705
Policy Entropy: 3.05797
Value Function Loss: 0.00506

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.61689
Value Function Update Magnitude: 0.59272

Collected Steps per Second: 21,965.93010
Overall Steps per Second: 10,425.77407

Timestep Collection Time: 2.27689
Timestep Consumption Time: 2.52026
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.79715

Cumulative Model Updates: 145,934
Cumulative Timesteps: 1,217,181,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1217181462...
Checkpoint 1217181462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.15186
Policy Entropy: 3.06695
Value Function Loss: 0.00471

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.60327
Value Function Update Magnitude: 0.59416

Collected Steps per Second: 22,936.18051
Overall Steps per Second: 10,661.41687

Timestep Collection Time: 2.18083
Timestep Consumption Time: 2.51085
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.69168

Cumulative Model Updates: 145,940
Cumulative Timesteps: 1,217,231,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.99995
Policy Entropy: 3.07064
Value Function Loss: 0.00427

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.58159
Value Function Update Magnitude: 0.56291

Collected Steps per Second: 22,935.44651
Overall Steps per Second: 10,704.61760

Timestep Collection Time: 2.18134
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.67368

Cumulative Model Updates: 145,946
Cumulative Timesteps: 1,217,281,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1217281512...
Checkpoint 1217281512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903.41183
Policy Entropy: 3.06196
Value Function Loss: 0.00424

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.56683
Value Function Update Magnitude: 0.57009

Collected Steps per Second: 22,755.01086
Overall Steps per Second: 10,809.52925

Timestep Collection Time: 2.19758
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.62610

Cumulative Model Updates: 145,952
Cumulative Timesteps: 1,217,331,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,202.64173
Policy Entropy: 3.06338
Value Function Loss: 0.00420

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.57883
Value Function Update Magnitude: 0.57172

Collected Steps per Second: 22,598.60354
Overall Steps per Second: 10,684.44836

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.46786
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.68101

Cumulative Model Updates: 145,958
Cumulative Timesteps: 1,217,381,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1217381532...
Checkpoint 1217381532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,602.89074
Policy Entropy: 3.07199
Value Function Loss: 0.00425

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.57918
Value Function Update Magnitude: 0.55213

Collected Steps per Second: 22,652.63291
Overall Steps per Second: 10,609.14087

Timestep Collection Time: 2.20849
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.71556

Cumulative Model Updates: 145,964
Cumulative Timesteps: 1,217,431,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388.83902
Policy Entropy: 3.07974
Value Function Loss: 0.00439

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.55646

Collected Steps per Second: 22,732.67897
Overall Steps per Second: 10,742.89204

Timestep Collection Time: 2.19948
Timestep Consumption Time: 2.45476
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.65424

Cumulative Model Updates: 145,970
Cumulative Timesteps: 1,217,481,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1217481560...
Checkpoint 1217481560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.28731
Policy Entropy: 3.08368
Value Function Loss: 0.00439

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.58431
Value Function Update Magnitude: 0.56850

Collected Steps per Second: 23,089.77468
Overall Steps per Second: 10,651.83956

Timestep Collection Time: 2.16633
Timestep Consumption Time: 2.52958
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.69590

Cumulative Model Updates: 145,976
Cumulative Timesteps: 1,217,531,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.07504
Policy Entropy: 3.06658
Value Function Loss: 0.00462

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.59958
Value Function Update Magnitude: 0.58404

Collected Steps per Second: 23,234.40301
Overall Steps per Second: 10,844.72060

Timestep Collection Time: 2.15267
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61201

Cumulative Model Updates: 145,982
Cumulative Timesteps: 1,217,581,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1217581596...
Checkpoint 1217581596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.73780
Policy Entropy: 3.05595
Value Function Loss: 0.00484

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.60895
Value Function Update Magnitude: 0.59481

Collected Steps per Second: 22,836.06859
Overall Steps per Second: 10,700.37683

Timestep Collection Time: 2.19013
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.67404

Cumulative Model Updates: 145,988
Cumulative Timesteps: 1,217,631,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.14652
Policy Entropy: 3.03946
Value Function Loss: 0.00512

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.61258
Value Function Update Magnitude: 0.57112

Collected Steps per Second: 23,055.76114
Overall Steps per Second: 10,939.50425

Timestep Collection Time: 2.16892
Timestep Consumption Time: 2.40222
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57114

Cumulative Model Updates: 145,994
Cumulative Timesteps: 1,217,681,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1217681616...
Checkpoint 1217681616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,955.13984
Policy Entropy: 3.05747
Value Function Loss: 0.00495

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.61072
Value Function Update Magnitude: 0.58591

Collected Steps per Second: 23,117.58706
Overall Steps per Second: 10,831.54800

Timestep Collection Time: 2.16294
Timestep Consumption Time: 2.45339
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.61633

Cumulative Model Updates: 146,000
Cumulative Timesteps: 1,217,731,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,249.31801
Policy Entropy: 3.06437
Value Function Loss: 0.00436

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.59605
Value Function Update Magnitude: 0.57244

Collected Steps per Second: 23,388.49125
Overall Steps per Second: 10,864.26980

Timestep Collection Time: 2.13874
Timestep Consumption Time: 2.46552
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.60427

Cumulative Model Updates: 146,006
Cumulative Timesteps: 1,217,781,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1217781640...
Checkpoint 1217781640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,892.21251
Policy Entropy: 3.05927
Value Function Loss: 0.00391

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.58469
Value Function Update Magnitude: 0.53797

Collected Steps per Second: 22,762.40983
Overall Steps per Second: 10,685.78281

Timestep Collection Time: 2.19704
Timestep Consumption Time: 2.48301
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.68005

Cumulative Model Updates: 146,012
Cumulative Timesteps: 1,217,831,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,918.79734
Policy Entropy: 3.05669
Value Function Loss: 0.00411

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.58916
Value Function Update Magnitude: 0.52070

Collected Steps per Second: 22,831.80884
Overall Steps per Second: 10,731.54379

Timestep Collection Time: 2.19098
Timestep Consumption Time: 2.47042
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.66140

Cumulative Model Updates: 146,018
Cumulative Timesteps: 1,217,881,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1217881674...
Checkpoint 1217881674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.38470
Policy Entropy: 3.05505
Value Function Loss: 0.00416

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.58832
Value Function Update Magnitude: 0.54812

Collected Steps per Second: 22,543.20495
Overall Steps per Second: 10,623.80038

Timestep Collection Time: 2.21823
Timestep Consumption Time: 2.48875
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.70698

Cumulative Model Updates: 146,024
Cumulative Timesteps: 1,217,931,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,002.81373
Policy Entropy: 3.07026
Value Function Loss: 0.00411

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.58296
Value Function Update Magnitude: 0.55755

Collected Steps per Second: 22,999.07010
Overall Steps per Second: 10,867.96629

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.42823
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.60362

Cumulative Model Updates: 146,030
Cumulative Timesteps: 1,217,981,712

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1217981712...
Checkpoint 1217981712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.98685
Policy Entropy: 3.06923
Value Function Loss: 0.00404

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.57817
Value Function Update Magnitude: 0.54659

Collected Steps per Second: 23,031.99401
Overall Steps per Second: 10,682.52644

Timestep Collection Time: 2.17202
Timestep Consumption Time: 2.51095
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.68297

Cumulative Model Updates: 146,036
Cumulative Timesteps: 1,218,031,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,498.75309
Policy Entropy: 3.08341
Value Function Loss: 0.00421

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.55659

Collected Steps per Second: 22,969.37139
Overall Steps per Second: 10,798.68593

Timestep Collection Time: 2.17794
Timestep Consumption Time: 2.45466
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.63260

Cumulative Model Updates: 146,042
Cumulative Timesteps: 1,218,081,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1218081764...
Checkpoint 1218081764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.77462
Policy Entropy: 3.08651
Value Function Loss: 0.00434

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.58756
Value Function Update Magnitude: 0.55196

Collected Steps per Second: 23,025.78953
Overall Steps per Second: 10,760.46579

Timestep Collection Time: 2.17148
Timestep Consumption Time: 2.47516
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.64664

Cumulative Model Updates: 146,048
Cumulative Timesteps: 1,218,131,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,583.03377
Policy Entropy: 3.09446
Value Function Loss: 0.00400

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.57757
Value Function Update Magnitude: 0.53174

Collected Steps per Second: 23,120.17235
Overall Steps per Second: 10,846.19673

Timestep Collection Time: 2.16382
Timestep Consumption Time: 2.44867
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.61249

Cumulative Model Updates: 146,054
Cumulative Timesteps: 1,218,181,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1218181792...
Checkpoint 1218181792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.26248
Policy Entropy: 3.07648
Value Function Loss: 0.00438

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.57636
Value Function Update Magnitude: 0.52651

Collected Steps per Second: 23,013.00883
Overall Steps per Second: 10,668.04743

Timestep Collection Time: 2.17303
Timestep Consumption Time: 2.51461
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.68764

Cumulative Model Updates: 146,060
Cumulative Timesteps: 1,218,231,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.44028
Policy Entropy: 3.06955
Value Function Loss: 0.00426

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.54173

Collected Steps per Second: 22,841.14316
Overall Steps per Second: 10,807.89758

Timestep Collection Time: 2.18947
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.62717

Cumulative Model Updates: 146,066
Cumulative Timesteps: 1,218,281,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1218281810...
Checkpoint 1218281810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.73273
Policy Entropy: 3.06013
Value Function Loss: 0.00454

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.56940

Collected Steps per Second: 22,833.05508
Overall Steps per Second: 10,750.17712

Timestep Collection Time: 2.18990
Timestep Consumption Time: 2.46138
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.65127

Cumulative Model Updates: 146,072
Cumulative Timesteps: 1,218,331,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.28296
Policy Entropy: 3.06177
Value Function Loss: 0.00424

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11185
Policy Update Magnitude: 0.58448
Value Function Update Magnitude: 0.56433

Collected Steps per Second: 22,800.19116
Overall Steps per Second: 10,813.04410

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.43176
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62534

Cumulative Model Updates: 146,078
Cumulative Timesteps: 1,218,381,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1218381826...
Checkpoint 1218381826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,272.91195
Policy Entropy: 3.06886
Value Function Loss: 0.00472

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.58792
Value Function Update Magnitude: 0.57822

Collected Steps per Second: 22,418.67138
Overall Steps per Second: 10,709.13333

Timestep Collection Time: 2.23171
Timestep Consumption Time: 2.44019
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.67190

Cumulative Model Updates: 146,084
Cumulative Timesteps: 1,218,431,858

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.65898
Policy Entropy: 3.08191
Value Function Loss: 0.00449

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.59180
Value Function Update Magnitude: 0.57824

Collected Steps per Second: 22,688.25628
Overall Steps per Second: 10,646.71130

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.49350
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.69816

Cumulative Model Updates: 146,090
Cumulative Timesteps: 1,218,481,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1218481878...
Checkpoint 1218481878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.63356
Policy Entropy: 3.09303
Value Function Loss: 0.00429

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.57384

Collected Steps per Second: 22,833.77881
Overall Steps per Second: 10,849.10310

Timestep Collection Time: 2.18974
Timestep Consumption Time: 2.41894
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.60868

Cumulative Model Updates: 146,096
Cumulative Timesteps: 1,218,531,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.90843
Policy Entropy: 3.09195
Value Function Loss: 0.00410

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.57715
Value Function Update Magnitude: 0.55616

Collected Steps per Second: 22,815.91349
Overall Steps per Second: 10,557.55858

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.54500
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.73689

Cumulative Model Updates: 146,102
Cumulative Timesteps: 1,218,581,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1218581888...
Checkpoint 1218581888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.94775
Policy Entropy: 3.09821
Value Function Loss: 0.00405

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.56824
Value Function Update Magnitude: 0.53190

Collected Steps per Second: 23,032.41776
Overall Steps per Second: 10,683.44916

Timestep Collection Time: 2.17137
Timestep Consumption Time: 2.50989
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.68126

Cumulative Model Updates: 146,108
Cumulative Timesteps: 1,218,631,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.74702
Policy Entropy: 3.09784
Value Function Loss: 0.00425

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.56129
Value Function Update Magnitude: 0.52566

Collected Steps per Second: 23,208.46065
Overall Steps per Second: 10,840.82144

Timestep Collection Time: 2.15525
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.61404

Cumulative Model Updates: 146,114
Cumulative Timesteps: 1,218,681,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1218681920...
Checkpoint 1218681920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,780.69659
Policy Entropy: 3.10030
Value Function Loss: 0.00432

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.57406
Value Function Update Magnitude: 0.54043

Collected Steps per Second: 22,994.31243
Overall Steps per Second: 10,679.82463

Timestep Collection Time: 2.17506
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.68304

Cumulative Model Updates: 146,120
Cumulative Timesteps: 1,218,731,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.51130
Policy Entropy: 3.07911
Value Function Loss: 0.00464

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.59057
Value Function Update Magnitude: 0.53919

Collected Steps per Second: 22,994.22312
Overall Steps per Second: 10,819.46990

Timestep Collection Time: 2.17446
Timestep Consumption Time: 2.44684
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.62130

Cumulative Model Updates: 146,126
Cumulative Timesteps: 1,218,781,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1218781934...
Checkpoint 1218781934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.17687
Policy Entropy: 3.06888
Value Function Loss: 0.00479

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.59857
Value Function Update Magnitude: 0.53487

Collected Steps per Second: 23,121.23119
Overall Steps per Second: 10,746.84998

Timestep Collection Time: 2.16269
Timestep Consumption Time: 2.49021
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.65290

Cumulative Model Updates: 146,132
Cumulative Timesteps: 1,218,831,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.46604
Policy Entropy: 3.07580
Value Function Loss: 0.00453

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.59092
Value Function Update Magnitude: 0.52059

Collected Steps per Second: 22,518.06419
Overall Steps per Second: 10,790.70992

Timestep Collection Time: 2.22177
Timestep Consumption Time: 2.41462
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.63640

Cumulative Model Updates: 146,138
Cumulative Timesteps: 1,218,881,968

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1218881968...
Checkpoint 1218881968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.69763
Policy Entropy: 3.09335
Value Function Loss: 0.00403

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.56683
Value Function Update Magnitude: 0.48322

Collected Steps per Second: 22,543.40229
Overall Steps per Second: 10,673.26197

Timestep Collection Time: 2.21830
Timestep Consumption Time: 2.46705
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.68535

Cumulative Model Updates: 146,144
Cumulative Timesteps: 1,218,931,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.41446
Policy Entropy: 3.09324
Value Function Loss: 0.00394

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.55495
Value Function Update Magnitude: 0.48517

Collected Steps per Second: 22,850.48462
Overall Steps per Second: 10,845.20477

Timestep Collection Time: 2.18814
Timestep Consumption Time: 2.42220
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.61033

Cumulative Model Updates: 146,150
Cumulative Timesteps: 1,218,981,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1218981976...
Checkpoint 1218981976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,768.53864
Policy Entropy: 3.09171
Value Function Loss: 0.00409

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.56753
Value Function Update Magnitude: 0.50019

Collected Steps per Second: 23,241.98506
Overall Steps per Second: 10,701.46001

Timestep Collection Time: 2.15188
Timestep Consumption Time: 2.52169
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.67357

Cumulative Model Updates: 146,156
Cumulative Timesteps: 1,219,031,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.80023
Policy Entropy: 3.07786
Value Function Loss: 0.00400

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.57575
Value Function Update Magnitude: 0.52126

Collected Steps per Second: 23,095.10405
Overall Steps per Second: 10,871.61282

Timestep Collection Time: 2.16600
Timestep Consumption Time: 2.43534
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60134

Cumulative Model Updates: 146,162
Cumulative Timesteps: 1,219,082,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1219082014...
Checkpoint 1219082014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.00520
Policy Entropy: 3.07415
Value Function Loss: 0.00407

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.57306
Value Function Update Magnitude: 0.51784

Collected Steps per Second: 22,736.48935
Overall Steps per Second: 10,716.59305

Timestep Collection Time: 2.20008
Timestep Consumption Time: 2.46764
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.66771

Cumulative Model Updates: 146,168
Cumulative Timesteps: 1,219,132,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.16619
Policy Entropy: 3.07181
Value Function Loss: 0.00407

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.57575
Value Function Update Magnitude: 0.51986

Collected Steps per Second: 23,041.46404
Overall Steps per Second: 10,930.47833

Timestep Collection Time: 2.17113
Timestep Consumption Time: 2.40561
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.57674

Cumulative Model Updates: 146,174
Cumulative Timesteps: 1,219,182,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1219182062...
Checkpoint 1219182062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841.75287
Policy Entropy: 3.07417
Value Function Loss: 0.00401

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.57815
Value Function Update Magnitude: 0.52696

Collected Steps per Second: 22,688.81404
Overall Steps per Second: 10,608.70240

Timestep Collection Time: 2.20496
Timestep Consumption Time: 2.51079
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71575

Cumulative Model Updates: 146,180
Cumulative Timesteps: 1,219,232,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,784.37609
Policy Entropy: 3.08713
Value Function Loss: 0.00382

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.56800
Value Function Update Magnitude: 0.53381

Collected Steps per Second: 22,537.34192
Overall Steps per Second: 10,601.93053

Timestep Collection Time: 2.21952
Timestep Consumption Time: 2.49868
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.71820

Cumulative Model Updates: 146,186
Cumulative Timesteps: 1,219,282,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1219282112...
Checkpoint 1219282112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.16160
Policy Entropy: 3.08973
Value Function Loss: 0.00416

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.54390

Collected Steps per Second: 22,866.62107
Overall Steps per Second: 10,883.19464

Timestep Collection Time: 2.18703
Timestep Consumption Time: 2.40813
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.59516

Cumulative Model Updates: 146,192
Cumulative Timesteps: 1,219,332,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.96319
Policy Entropy: 3.09204
Value Function Loss: 0.00429

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.57972
Value Function Update Magnitude: 0.55815

Collected Steps per Second: 22,680.60196
Overall Steps per Second: 10,602.20993

Timestep Collection Time: 2.20559
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.71826

Cumulative Model Updates: 146,198
Cumulative Timesteps: 1,219,382,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1219382146...
Checkpoint 1219382146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,876.68934
Policy Entropy: 3.08670
Value Function Loss: 0.00442

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.58595
Value Function Update Magnitude: 0.54676

Collected Steps per Second: 23,018.87381
Overall Steps per Second: 10,629.74831

Timestep Collection Time: 2.17326
Timestep Consumption Time: 2.53297
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.70623

Cumulative Model Updates: 146,204
Cumulative Timesteps: 1,219,432,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,357.75280
Policy Entropy: 3.07796
Value Function Loss: 0.00440

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11896
Policy Update Magnitude: 0.58912
Value Function Update Magnitude: 0.55442

Collected Steps per Second: 23,124.78221
Overall Steps per Second: 10,871.07712

Timestep Collection Time: 2.16236
Timestep Consumption Time: 2.43737
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.59973

Cumulative Model Updates: 146,210
Cumulative Timesteps: 1,219,482,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1219482176...
Checkpoint 1219482176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,599.94940
Policy Entropy: 3.07708
Value Function Loss: 0.00428

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.58730
Value Function Update Magnitude: 0.53961

Collected Steps per Second: 23,110.78419
Overall Steps per Second: 10,728.89543

Timestep Collection Time: 2.16427
Timestep Consumption Time: 2.49772
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.66199

Cumulative Model Updates: 146,216
Cumulative Timesteps: 1,219,532,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.71698
Policy Entropy: 3.06170
Value Function Loss: 0.00447

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.58411
Value Function Update Magnitude: 0.51501

Collected Steps per Second: 23,193.52262
Overall Steps per Second: 10,753.99068

Timestep Collection Time: 2.15577
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.64944

Cumulative Model Updates: 146,222
Cumulative Timesteps: 1,219,582,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1219582194...
Checkpoint 1219582194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.64134
Policy Entropy: 3.05457
Value Function Loss: 0.00422

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.58689
Value Function Update Magnitude: 0.51774

Collected Steps per Second: 23,049.30186
Overall Steps per Second: 10,688.33520

Timestep Collection Time: 2.16926
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.67800

Cumulative Model Updates: 146,228
Cumulative Timesteps: 1,219,632,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164.92419
Policy Entropy: 3.05419
Value Function Loss: 0.00411

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.59029
Value Function Update Magnitude: 0.53071

Collected Steps per Second: 22,960.83171
Overall Steps per Second: 10,833.56265

Timestep Collection Time: 2.17823
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.61658

Cumulative Model Updates: 146,234
Cumulative Timesteps: 1,219,682,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1219682208...
Checkpoint 1219682208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025.70775
Policy Entropy: 3.05581
Value Function Loss: 0.00430

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.59542
Value Function Update Magnitude: 0.54113

Collected Steps per Second: 22,961.57178
Overall Steps per Second: 10,768.11166

Timestep Collection Time: 2.17842
Timestep Consumption Time: 2.46677
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.64520

Cumulative Model Updates: 146,240
Cumulative Timesteps: 1,219,732,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.83522
Policy Entropy: 3.06092
Value Function Loss: 0.00424

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.59281
Value Function Update Magnitude: 0.53012

Collected Steps per Second: 22,809.63648
Overall Steps per Second: 10,790.82673

Timestep Collection Time: 2.19293
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.63542

Cumulative Model Updates: 146,246
Cumulative Timesteps: 1,219,782,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1219782248...
Checkpoint 1219782248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,326.71341
Policy Entropy: 3.06449
Value Function Loss: 0.00420

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.58346
Value Function Update Magnitude: 0.50583

Collected Steps per Second: 22,709.61296
Overall Steps per Second: 10,662.12304

Timestep Collection Time: 2.20197
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.69006

Cumulative Model Updates: 146,252
Cumulative Timesteps: 1,219,832,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.07881
Policy Entropy: 3.06795
Value Function Loss: 0.00392

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.57904
Value Function Update Magnitude: 0.50520

Collected Steps per Second: 22,781.15329
Overall Steps per Second: 10,633.15774

Timestep Collection Time: 2.19585
Timestep Consumption Time: 2.50868
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.70453

Cumulative Model Updates: 146,258
Cumulative Timesteps: 1,219,882,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1219882278...
Checkpoint 1219882278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.43486
Policy Entropy: 3.08798
Value Function Loss: 0.00423

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.58433
Value Function Update Magnitude: 0.50686

Collected Steps per Second: 22,826.85552
Overall Steps per Second: 10,822.79861

Timestep Collection Time: 2.19128
Timestep Consumption Time: 2.43045
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62173

Cumulative Model Updates: 146,264
Cumulative Timesteps: 1,219,932,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,031.62804
Policy Entropy: 3.08994
Value Function Loss: 0.00458

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.58970
Value Function Update Magnitude: 0.50937

Collected Steps per Second: 23,380.35251
Overall Steps per Second: 10,904.26367

Timestep Collection Time: 2.13949
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.58738

Cumulative Model Updates: 146,270
Cumulative Timesteps: 1,219,982,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1219982320...
Checkpoint 1219982320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.92679
Policy Entropy: 3.07820
Value Function Loss: 0.00505

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.58769
Value Function Update Magnitude: 0.55067

Collected Steps per Second: 22,974.81882
Overall Steps per Second: 10,665.76450

Timestep Collection Time: 2.17743
Timestep Consumption Time: 2.51291
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.69033

Cumulative Model Updates: 146,276
Cumulative Timesteps: 1,220,032,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.89344
Policy Entropy: 3.06330
Value Function Loss: 0.00484

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.59110
Value Function Update Magnitude: 0.56502

Collected Steps per Second: 23,089.12550
Overall Steps per Second: 10,918.28999

Timestep Collection Time: 2.16552
Timestep Consumption Time: 2.41395
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.57947

Cumulative Model Updates: 146,282
Cumulative Timesteps: 1,220,082,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1220082346...
Checkpoint 1220082346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,300.39502
Policy Entropy: 3.05239
Value Function Loss: 0.00440

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.58486
Value Function Update Magnitude: 0.53347

Collected Steps per Second: 22,852.44698
Overall Steps per Second: 10,691.97093

Timestep Collection Time: 2.18891
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.67846

Cumulative Model Updates: 146,288
Cumulative Timesteps: 1,220,132,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.12641
Policy Entropy: 3.06674
Value Function Loss: 0.00411

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.56936
Value Function Update Magnitude: 0.50350

Collected Steps per Second: 23,553.15588
Overall Steps per Second: 10,925.13026

Timestep Collection Time: 2.12303
Timestep Consumption Time: 2.45394
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.57697

Cumulative Model Updates: 146,294
Cumulative Timesteps: 1,220,182,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1220182372...
Checkpoint 1220182372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.83073
Policy Entropy: 3.05752
Value Function Loss: 0.00396

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.55781
Value Function Update Magnitude: 0.48151

Collected Steps per Second: 23,200.84414
Overall Steps per Second: 10,766.48038

Timestep Collection Time: 2.15509
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.64404

Cumulative Model Updates: 146,300
Cumulative Timesteps: 1,220,232,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.39473
Policy Entropy: 3.06378
Value Function Loss: 0.00417

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.57039
Value Function Update Magnitude: 0.48398

Collected Steps per Second: 22,572.42494
Overall Steps per Second: 10,829.64563

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.40206
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.61733

Cumulative Model Updates: 146,306
Cumulative Timesteps: 1,220,282,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1220282376...
Checkpoint 1220282376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.03490
Policy Entropy: 3.04737
Value Function Loss: 0.00417

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.57475
Value Function Update Magnitude: 0.49871

Collected Steps per Second: 22,966.80291
Overall Steps per Second: 10,806.21145

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.44991
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.62697

Cumulative Model Updates: 146,312
Cumulative Timesteps: 1,220,332,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,990.27828
Policy Entropy: 3.05291
Value Function Loss: 0.00442

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.51561

Collected Steps per Second: 23,108.93257
Overall Steps per Second: 10,747.37041

Timestep Collection Time: 2.16479
Timestep Consumption Time: 2.48993
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.65472

Cumulative Model Updates: 146,318
Cumulative Timesteps: 1,220,382,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1220382402...
Checkpoint 1220382402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,363.08515
Policy Entropy: 3.04339
Value Function Loss: 0.00455

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.58251
Value Function Update Magnitude: 0.53126

Collected Steps per Second: 22,852.78368
Overall Steps per Second: 10,638.77431

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.51328
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.70242

Cumulative Model Updates: 146,324
Cumulative Timesteps: 1,220,432,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,163.47500
Policy Entropy: 3.04843
Value Function Loss: 0.00422

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.58287
Value Function Update Magnitude: 0.53285

Collected Steps per Second: 23,194.57965
Overall Steps per Second: 10,877.39389

Timestep Collection Time: 2.15645
Timestep Consumption Time: 2.44189
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.59834

Cumulative Model Updates: 146,330
Cumulative Timesteps: 1,220,482,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1220482448...
Checkpoint 1220482448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.73068
Policy Entropy: 3.05434
Value Function Loss: 0.00411

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.58625
Value Function Update Magnitude: 0.52415

Collected Steps per Second: 22,881.91936
Overall Steps per Second: 10,672.47885

Timestep Collection Time: 2.18548
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.68570

Cumulative Model Updates: 146,336
Cumulative Timesteps: 1,220,532,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.13099
Policy Entropy: 3.04810
Value Function Loss: 0.00430

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.59806
Value Function Update Magnitude: 0.55543

Collected Steps per Second: 23,343.61713
Overall Steps per Second: 10,850.86196

Timestep Collection Time: 2.14311
Timestep Consumption Time: 2.46740
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.61051

Cumulative Model Updates: 146,342
Cumulative Timesteps: 1,220,582,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1220582484...
Checkpoint 1220582484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,890.44087
Policy Entropy: 3.05177
Value Function Loss: 0.00454

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11597
Policy Update Magnitude: 0.60737
Value Function Update Magnitude: 0.58079

Collected Steps per Second: 22,854.21277
Overall Steps per Second: 10,610.12188

Timestep Collection Time: 2.18892
Timestep Consumption Time: 2.52601
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.71493

Cumulative Model Updates: 146,348
Cumulative Timesteps: 1,220,632,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,502.02730
Policy Entropy: 3.05222
Value Function Loss: 0.00458

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.61013
Value Function Update Magnitude: 0.58068

Collected Steps per Second: 22,825.28530
Overall Steps per Second: 10,669.67211

Timestep Collection Time: 2.19125
Timestep Consumption Time: 2.49643
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.68768

Cumulative Model Updates: 146,354
Cumulative Timesteps: 1,220,682,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1220682526...
Checkpoint 1220682526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,881.96858
Policy Entropy: 3.06476
Value Function Loss: 0.00417

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.59671
Value Function Update Magnitude: 0.55330

Collected Steps per Second: 22,924.54617
Overall Steps per Second: 10,833.56568

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.43568
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61805

Cumulative Model Updates: 146,360
Cumulative Timesteps: 1,220,732,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.94792
Policy Entropy: 3.05970
Value Function Loss: 0.00398

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.53458

Collected Steps per Second: 22,563.29659
Overall Steps per Second: 10,648.75504

Timestep Collection Time: 2.21679
Timestep Consumption Time: 2.48029
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.69707

Cumulative Model Updates: 146,366
Cumulative Timesteps: 1,220,782,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1220782574...
Checkpoint 1220782574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.82265
Policy Entropy: 3.06700
Value Function Loss: 0.00370

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.56640
Value Function Update Magnitude: 0.52549

Collected Steps per Second: 22,872.01128
Overall Steps per Second: 10,708.80048

Timestep Collection Time: 2.18634
Timestep Consumption Time: 2.48328
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.66962

Cumulative Model Updates: 146,372
Cumulative Timesteps: 1,220,832,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,866.22497
Policy Entropy: 3.08084
Value Function Loss: 0.00396

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.52026

Collected Steps per Second: 22,983.19204
Overall Steps per Second: 10,727.71390

Timestep Collection Time: 2.17611
Timestep Consumption Time: 2.48602
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.66213

Cumulative Model Updates: 146,378
Cumulative Timesteps: 1,220,882,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1220882594...
Checkpoint 1220882594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,750.64806
Policy Entropy: 3.08267
Value Function Loss: 0.00391

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.57047
Value Function Update Magnitude: 0.53706

Collected Steps per Second: 22,966.08493
Overall Steps per Second: 10,630.08326

Timestep Collection Time: 2.17747
Timestep Consumption Time: 2.52691
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.70438

Cumulative Model Updates: 146,384
Cumulative Timesteps: 1,220,932,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.65756
Policy Entropy: 3.08727
Value Function Loss: 0.00390

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.56342
Value Function Update Magnitude: 0.54444

Collected Steps per Second: 22,849.92609
Overall Steps per Second: 10,821.23529

Timestep Collection Time: 2.18950
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.62332

Cumulative Model Updates: 146,390
Cumulative Timesteps: 1,220,982,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1220982632...
Checkpoint 1220982632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,474.45621
Policy Entropy: 3.07842
Value Function Loss: 0.00371

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.55796
Value Function Update Magnitude: 0.52799

Collected Steps per Second: 21,925.57561
Overall Steps per Second: 10,450.73184

Timestep Collection Time: 2.28126
Timestep Consumption Time: 2.50481
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.78608

Cumulative Model Updates: 146,396
Cumulative Timesteps: 1,221,032,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.32569
Policy Entropy: 3.06327
Value Function Loss: 0.00431

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.58161
Value Function Update Magnitude: 0.54782

Collected Steps per Second: 23,192.09609
Overall Steps per Second: 10,775.41406

Timestep Collection Time: 2.15686
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.64223

Cumulative Model Updates: 146,402
Cumulative Timesteps: 1,221,082,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1221082672...
Checkpoint 1221082672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,564.57033
Policy Entropy: 3.05144
Value Function Loss: 0.00473

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.60514
Value Function Update Magnitude: 0.59281

Collected Steps per Second: 23,177.46959
Overall Steps per Second: 10,962.80572

Timestep Collection Time: 2.15744
Timestep Consumption Time: 2.40380
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.56124

Cumulative Model Updates: 146,408
Cumulative Timesteps: 1,221,132,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539.79436
Policy Entropy: 3.04569
Value Function Loss: 0.00470

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.60164
Value Function Update Magnitude: 0.59944

Collected Steps per Second: 22,827.72915
Overall Steps per Second: 10,649.18758

Timestep Collection Time: 2.19093
Timestep Consumption Time: 2.50558
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.69651

Cumulative Model Updates: 146,414
Cumulative Timesteps: 1,221,182,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1221182690...
Checkpoint 1221182690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,781.47639
Policy Entropy: 3.04293
Value Function Loss: 0.00451

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11843
Policy Update Magnitude: 0.59286
Value Function Update Magnitude: 0.58021

Collected Steps per Second: 23,202.21883
Overall Steps per Second: 10,937.62173

Timestep Collection Time: 2.15591
Timestep Consumption Time: 2.41747
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.57339

Cumulative Model Updates: 146,420
Cumulative Timesteps: 1,221,232,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.34336
Policy Entropy: 3.03877
Value Function Loss: 0.00392

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.58417
Value Function Update Magnitude: 0.56775

Collected Steps per Second: 22,798.33264
Overall Steps per Second: 10,699.97624

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.48115
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.67552

Cumulative Model Updates: 146,426
Cumulative Timesteps: 1,221,282,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1221282740...
Checkpoint 1221282740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.84089
Policy Entropy: 3.04633
Value Function Loss: 0.00370

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.57816
Value Function Update Magnitude: 0.52870

Collected Steps per Second: 22,767.33663
Overall Steps per Second: 10,880.40999

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.40005
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.59689

Cumulative Model Updates: 146,432
Cumulative Timesteps: 1,221,332,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,374.23572
Policy Entropy: 3.04528
Value Function Loss: 0.00358

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.50120

Collected Steps per Second: 22,585.80006
Overall Steps per Second: 10,684.05069

Timestep Collection Time: 2.21493
Timestep Consumption Time: 2.46738
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.68231

Cumulative Model Updates: 146,438
Cumulative Timesteps: 1,221,382,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1221382782...
Checkpoint 1221382782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,990.10370
Policy Entropy: 3.04594
Value Function Loss: 0.00362

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.55894
Value Function Update Magnitude: 0.48768

Collected Steps per Second: 22,657.00681
Overall Steps per Second: 10,600.39483

Timestep Collection Time: 2.20726
Timestep Consumption Time: 2.51048
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.71775

Cumulative Model Updates: 146,444
Cumulative Timesteps: 1,221,432,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,902.06584
Policy Entropy: 3.03381
Value Function Loss: 0.00370

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.47770

Collected Steps per Second: 22,951.34643
Overall Steps per Second: 10,752.15248

Timestep Collection Time: 2.17974
Timestep Consumption Time: 2.47309
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.65284

Cumulative Model Updates: 146,450
Cumulative Timesteps: 1,221,482,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1221482820...
Checkpoint 1221482820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,779.94651
Policy Entropy: 3.03720
Value Function Loss: 0.00392

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.57906
Value Function Update Magnitude: 0.49959

Collected Steps per Second: 22,967.53330
Overall Steps per Second: 10,570.85044

Timestep Collection Time: 2.17812
Timestep Consumption Time: 2.55433
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.73245

Cumulative Model Updates: 146,456
Cumulative Timesteps: 1,221,532,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,105.03691
Policy Entropy: 3.04199
Value Function Loss: 0.00425

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.59670
Value Function Update Magnitude: 0.53410

Collected Steps per Second: 23,235.03834
Overall Steps per Second: 10,756.41576

Timestep Collection Time: 2.15201
Timestep Consumption Time: 2.49657
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.64857

Cumulative Model Updates: 146,462
Cumulative Timesteps: 1,221,582,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1221582848...
Checkpoint 1221582848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.77054
Policy Entropy: 3.04704
Value Function Loss: 0.00441

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.60149
Value Function Update Magnitude: 0.55704

Collected Steps per Second: 23,163.66346
Overall Steps per Second: 10,856.10435

Timestep Collection Time: 2.15916
Timestep Consumption Time: 2.44784
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.60699

Cumulative Model Updates: 146,468
Cumulative Timesteps: 1,221,632,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,103.83848
Policy Entropy: 3.05814
Value Function Loss: 0.00398

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.54840

Collected Steps per Second: 23,201.08649
Overall Steps per Second: 10,874.77789

Timestep Collection Time: 2.15542
Timestep Consumption Time: 2.44311
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59853

Cumulative Model Updates: 146,474
Cumulative Timesteps: 1,221,682,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1221682870...
Checkpoint 1221682870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.19768
Policy Entropy: 3.05883
Value Function Loss: 0.00398

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10665
Policy Update Magnitude: 0.56892
Value Function Update Magnitude: 0.51940

Collected Steps per Second: 22,884.58632
Overall Steps per Second: 10,711.26712

Timestep Collection Time: 2.18531
Timestep Consumption Time: 2.48360
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.66892

Cumulative Model Updates: 146,480
Cumulative Timesteps: 1,221,732,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.91371
Policy Entropy: 3.05806
Value Function Loss: 0.00410

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.57105
Value Function Update Magnitude: 0.51549

Collected Steps per Second: 22,520.52408
Overall Steps per Second: 10,594.13969

Timestep Collection Time: 2.22020
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.71959

Cumulative Model Updates: 146,486
Cumulative Timesteps: 1,221,782,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1221782880...
Checkpoint 1221782880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.56739
Policy Entropy: 3.03750
Value Function Loss: 0.00446

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.53443

Collected Steps per Second: 22,662.25708
Overall Steps per Second: 10,640.00398

Timestep Collection Time: 2.20737
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.70150

Cumulative Model Updates: 146,492
Cumulative Timesteps: 1,221,832,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.50666
Policy Entropy: 3.04535
Value Function Loss: 0.00452

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.58676
Value Function Update Magnitude: 0.55322

Collected Steps per Second: 22,710.79541
Overall Steps per Second: 10,789.93009

Timestep Collection Time: 2.20248
Timestep Consumption Time: 2.43333
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.63580

Cumulative Model Updates: 146,498
Cumulative Timesteps: 1,221,882,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1221882924...
Checkpoint 1221882924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,480.59125
Policy Entropy: 3.05896
Value Function Loss: 0.00439

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.58591
Value Function Update Magnitude: 0.56567

Collected Steps per Second: 23,170.17054
Overall Steps per Second: 10,746.61044

Timestep Collection Time: 2.15795
Timestep Consumption Time: 2.49468
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.65263

Cumulative Model Updates: 146,504
Cumulative Timesteps: 1,221,932,924

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,882.50197
Policy Entropy: 3.07034
Value Function Loss: 0.00450

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.59762
Value Function Update Magnitude: 0.60253

Collected Steps per Second: 23,190.60315
Overall Steps per Second: 10,694.50125

Timestep Collection Time: 2.15648
Timestep Consumption Time: 2.51976
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.67623

Cumulative Model Updates: 146,510
Cumulative Timesteps: 1,221,982,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1221982934...
Checkpoint 1221982934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,354.32480
Policy Entropy: 3.06972
Value Function Loss: 0.00443

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.60300
Value Function Update Magnitude: 0.60984

Collected Steps per Second: 23,031.80632
Overall Steps per Second: 10,770.56682

Timestep Collection Time: 2.17204
Timestep Consumption Time: 2.47266
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.64470

Cumulative Model Updates: 146,516
Cumulative Timesteps: 1,222,032,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.75789
Policy Entropy: 3.05964
Value Function Loss: 0.00466

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.59920
Value Function Update Magnitude: 0.59681

Collected Steps per Second: 23,317.08333
Overall Steps per Second: 10,854.42020

Timestep Collection Time: 2.14478
Timestep Consumption Time: 2.46256
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.60734

Cumulative Model Updates: 146,522
Cumulative Timesteps: 1,222,082,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1222082970...
Checkpoint 1222082970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.20201
Policy Entropy: 3.07694
Value Function Loss: 0.00453

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.58764
Value Function Update Magnitude: 0.58726

Collected Steps per Second: 22,881.81002
Overall Steps per Second: 10,709.05169

Timestep Collection Time: 2.18637
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.67156

Cumulative Model Updates: 146,528
Cumulative Timesteps: 1,222,132,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278.29699
Policy Entropy: 3.07272
Value Function Loss: 0.00433

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.58658

Collected Steps per Second: 23,505.76520
Overall Steps per Second: 10,843.99053

Timestep Collection Time: 2.12731
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.61122

Cumulative Model Updates: 146,534
Cumulative Timesteps: 1,222,183,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1222183002...
Checkpoint 1222183002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.08384
Policy Entropy: 3.07801
Value Function Loss: 0.00399

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.56392
Value Function Update Magnitude: 0.56057

Collected Steps per Second: 22,723.55346
Overall Steps per Second: 10,662.66627

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.49039
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.69207

Cumulative Model Updates: 146,540
Cumulative Timesteps: 1,222,233,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.46131
Policy Entropy: 3.07919
Value Function Loss: 0.00380

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.56052
Value Function Update Magnitude: 0.52437

Collected Steps per Second: 23,008.38338
Overall Steps per Second: 10,823.06713

Timestep Collection Time: 2.17434
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.62235

Cumulative Model Updates: 146,546
Cumulative Timesteps: 1,222,283,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1222283060...
Checkpoint 1222283060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,698.44993
Policy Entropy: 3.08766
Value Function Loss: 0.00368

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.55443
Value Function Update Magnitude: 0.53254

Collected Steps per Second: 22,537.53421
Overall Steps per Second: 10,682.22497

Timestep Collection Time: 2.21914
Timestep Consumption Time: 2.46284
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.68198

Cumulative Model Updates: 146,552
Cumulative Timesteps: 1,222,333,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.41316
Policy Entropy: 3.07764
Value Function Loss: 0.00367

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.52436

Collected Steps per Second: 22,825.84343
Overall Steps per Second: 10,695.71838

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.67701

Cumulative Model Updates: 146,558
Cumulative Timesteps: 1,222,383,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1222383098...
Checkpoint 1222383098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,443.04544
Policy Entropy: 3.06617
Value Function Loss: 0.00401

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.51989

Collected Steps per Second: 22,853.30805
Overall Steps per Second: 10,790.05935

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.63686

Cumulative Model Updates: 146,564
Cumulative Timesteps: 1,222,433,130

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.73742
Policy Entropy: 3.04893
Value Function Loss: 0.00430

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.57131
Value Function Update Magnitude: 0.52244

Collected Steps per Second: 22,806.18827
Overall Steps per Second: 10,520.74777

Timestep Collection Time: 2.19256
Timestep Consumption Time: 2.56033
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75289

Cumulative Model Updates: 146,570
Cumulative Timesteps: 1,222,483,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1222483134...
Checkpoint 1222483134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,520.37612
Policy Entropy: 3.04920
Value Function Loss: 0.00413

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.56637
Value Function Update Magnitude: 0.50913

Collected Steps per Second: 22,983.20176
Overall Steps per Second: 10,619.96357

Timestep Collection Time: 2.17663
Timestep Consumption Time: 2.53393
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.71056

Cumulative Model Updates: 146,576
Cumulative Timesteps: 1,222,533,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,388.86374
Policy Entropy: 3.03349
Value Function Loss: 0.00398

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.56538
Value Function Update Magnitude: 0.49256

Collected Steps per Second: 23,280.20629
Overall Steps per Second: 10,936.24794

Timestep Collection Time: 2.14869
Timestep Consumption Time: 2.42527
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.57396

Cumulative Model Updates: 146,582
Cumulative Timesteps: 1,222,583,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1222583182...
Checkpoint 1222583182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.28439
Policy Entropy: 3.04846
Value Function Loss: 0.00368

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.56400
Value Function Update Magnitude: 0.49396

Collected Steps per Second: 22,936.59815
Overall Steps per Second: 10,807.48748

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.44718
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.62772

Cumulative Model Updates: 146,588
Cumulative Timesteps: 1,222,633,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.58400
Policy Entropy: 3.02642
Value Function Loss: 0.00411

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.57299
Value Function Update Magnitude: 0.54468

Collected Steps per Second: 23,140.44755
Overall Steps per Second: 10,912.48704

Timestep Collection Time: 2.16193
Timestep Consumption Time: 2.42254
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.58447

Cumulative Model Updates: 146,594
Cumulative Timesteps: 1,222,683,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1222683224...
Checkpoint 1222683224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.19259
Policy Entropy: 3.03199
Value Function Loss: 0.00403

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.58411
Value Function Update Magnitude: 0.54292

Collected Steps per Second: 22,967.36058
Overall Steps per Second: 10,669.78496

Timestep Collection Time: 2.17805
Timestep Consumption Time: 2.51033
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.68838

Cumulative Model Updates: 146,600
Cumulative Timesteps: 1,222,733,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.58075
Policy Entropy: 3.02983
Value Function Loss: 0.00410

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.58681
Value Function Update Magnitude: 0.54075

Collected Steps per Second: 22,873.28529
Overall Steps per Second: 10,841.16751

Timestep Collection Time: 2.18639
Timestep Consumption Time: 2.42658
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61297

Cumulative Model Updates: 146,606
Cumulative Timesteps: 1,222,783,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1222783258...
Checkpoint 1222783258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,233.58305
Policy Entropy: 3.03470
Value Function Loss: 0.00410

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.58040
Value Function Update Magnitude: 0.51821

Collected Steps per Second: 22,608.19173
Overall Steps per Second: 10,674.61865

Timestep Collection Time: 2.21221
Timestep Consumption Time: 2.47311
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.68532

Cumulative Model Updates: 146,612
Cumulative Timesteps: 1,222,833,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,449.05606
Policy Entropy: 3.04857
Value Function Loss: 0.00390

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.56984
Value Function Update Magnitude: 0.49228

Collected Steps per Second: 22,817.34030
Overall Steps per Second: 10,681.04085

Timestep Collection Time: 2.19219
Timestep Consumption Time: 2.49087
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.68306

Cumulative Model Updates: 146,618
Cumulative Timesteps: 1,222,883,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1222883292...
Checkpoint 1222883292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,000.50544
Policy Entropy: 3.05742
Value Function Loss: 0.00398

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.55260
Value Function Update Magnitude: 0.48434

Collected Steps per Second: 22,985.83633
Overall Steps per Second: 10,790.62487

Timestep Collection Time: 2.17534
Timestep Consumption Time: 2.45850
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.63384

Cumulative Model Updates: 146,624
Cumulative Timesteps: 1,222,933,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,448.23942
Policy Entropy: 3.05555
Value Function Loss: 0.00378

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.54987
Value Function Update Magnitude: 0.47526

Collected Steps per Second: 23,313.12738
Overall Steps per Second: 10,892.81309

Timestep Collection Time: 2.14471
Timestep Consumption Time: 2.44547
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.59018

Cumulative Model Updates: 146,630
Cumulative Timesteps: 1,222,983,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1222983294...
Checkpoint 1222983294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,364.19715
Policy Entropy: 3.05097
Value Function Loss: 0.00400

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.55839
Value Function Update Magnitude: 0.49370

Collected Steps per Second: 22,951.75118
Overall Steps per Second: 10,747.31797

Timestep Collection Time: 2.17979
Timestep Consumption Time: 2.47532
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.65511

Cumulative Model Updates: 146,636
Cumulative Timesteps: 1,223,033,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.01577
Policy Entropy: 3.03971
Value Function Loss: 0.00411

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.57255
Value Function Update Magnitude: 0.52008

Collected Steps per Second: 23,377.52891
Overall Steps per Second: 10,901.55179

Timestep Collection Time: 2.13923
Timestep Consumption Time: 2.44819
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.58742

Cumulative Model Updates: 146,642
Cumulative Timesteps: 1,223,083,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1223083334...
Checkpoint 1223083334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,043.75091
Policy Entropy: 3.03138
Value Function Loss: 0.00459

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.59047
Value Function Update Magnitude: 0.55634

Collected Steps per Second: 22,964.90055
Overall Steps per Second: 10,680.99320

Timestep Collection Time: 2.17758
Timestep Consumption Time: 2.50438
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.68196

Cumulative Model Updates: 146,648
Cumulative Timesteps: 1,223,133,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.91764
Policy Entropy: 3.03657
Value Function Loss: 0.00467

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.60027
Value Function Update Magnitude: 0.58171

Collected Steps per Second: 23,279.32821
Overall Steps per Second: 10,891.83323

Timestep Collection Time: 2.14912
Timestep Consumption Time: 2.44423
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.59335

Cumulative Model Updates: 146,654
Cumulative Timesteps: 1,223,183,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1223183372...
Checkpoint 1223183372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,097.52107
Policy Entropy: 3.03939
Value Function Loss: 0.00454

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.59157
Value Function Update Magnitude: 0.56268

Collected Steps per Second: 22,322.01818
Overall Steps per Second: 10,626.38558

Timestep Collection Time: 2.24120
Timestep Consumption Time: 2.46671
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.70790

Cumulative Model Updates: 146,660
Cumulative Timesteps: 1,223,233,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,598.29342
Policy Entropy: 3.05356
Value Function Loss: 0.00444

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.55326

Collected Steps per Second: 22,803.13967
Overall Steps per Second: 10,875.94586

Timestep Collection Time: 2.19373
Timestep Consumption Time: 2.40578
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.59951

Cumulative Model Updates: 146,666
Cumulative Timesteps: 1,223,283,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1223283424...
Checkpoint 1223283424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.87273
Policy Entropy: 3.04330
Value Function Loss: 0.00421

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.58174
Value Function Update Magnitude: 0.54361

Collected Steps per Second: 22,680.52940
Overall Steps per Second: 10,729.63375

Timestep Collection Time: 2.20586
Timestep Consumption Time: 2.45693
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.66279

Cumulative Model Updates: 146,672
Cumulative Timesteps: 1,223,333,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.42938
Policy Entropy: 3.03750
Value Function Loss: 0.00437

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.57933
Value Function Update Magnitude: 0.54374

Collected Steps per Second: 23,248.70480
Overall Steps per Second: 10,814.96510

Timestep Collection Time: 2.15117
Timestep Consumption Time: 2.47316
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.62433

Cumulative Model Updates: 146,678
Cumulative Timesteps: 1,223,383,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1223383466...
Checkpoint 1223383466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,048.22947
Policy Entropy: 3.04685
Value Function Loss: 0.00395

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.57599
Value Function Update Magnitude: 0.54586

Collected Steps per Second: 22,753.27038
Overall Steps per Second: 10,655.14050

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.49548
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.69332

Cumulative Model Updates: 146,684
Cumulative Timesteps: 1,223,433,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,046.77197
Policy Entropy: 3.05320
Value Function Loss: 0.00429

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.54217

Collected Steps per Second: 23,265.70752
Overall Steps per Second: 10,890.05363

Timestep Collection Time: 2.14986
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.59300

Cumulative Model Updates: 146,690
Cumulative Timesteps: 1,223,483,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1223483492...
Checkpoint 1223483492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.38537
Policy Entropy: 3.05329
Value Function Loss: 0.00445

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.53028

Collected Steps per Second: 22,654.42259
Overall Steps per Second: 10,727.56366

Timestep Collection Time: 2.20796
Timestep Consumption Time: 2.45480
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.66275

Cumulative Model Updates: 146,696
Cumulative Timesteps: 1,223,533,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.40162
Policy Entropy: 3.02984
Value Function Loss: 0.00497

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.59439
Value Function Update Magnitude: 0.55203

Collected Steps per Second: 23,339.91375
Overall Steps per Second: 10,876.30090

Timestep Collection Time: 2.14302
Timestep Consumption Time: 2.45578
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.59881

Cumulative Model Updates: 146,702
Cumulative Timesteps: 1,223,583,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1223583530...
Checkpoint 1223583530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,850.93205
Policy Entropy: 3.04099
Value Function Loss: 0.00476

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.60136
Value Function Update Magnitude: 0.57358

Collected Steps per Second: 22,797.81422
Overall Steps per Second: 10,641.78710

Timestep Collection Time: 2.19442
Timestep Consumption Time: 2.50667
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.70109

Cumulative Model Updates: 146,708
Cumulative Timesteps: 1,223,633,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.81954
Policy Entropy: 3.04388
Value Function Loss: 0.00471

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.59741
Value Function Update Magnitude: 0.57108

Collected Steps per Second: 22,975.05519
Overall Steps per Second: 10,908.93185

Timestep Collection Time: 2.17758
Timestep Consumption Time: 2.40857
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.58615

Cumulative Model Updates: 146,714
Cumulative Timesteps: 1,223,683,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1223683588...
Checkpoint 1223683588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.14181
Policy Entropy: 3.05900
Value Function Loss: 0.00474

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.59946
Value Function Update Magnitude: 0.56912

Collected Steps per Second: 22,591.60690
Overall Steps per Second: 10,661.82524

Timestep Collection Time: 2.21348
Timestep Consumption Time: 2.47671
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.69019

Cumulative Model Updates: 146,720
Cumulative Timesteps: 1,223,733,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080.25709
Policy Entropy: 3.05436
Value Function Loss: 0.00485

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.61332
Value Function Update Magnitude: 0.57165

Collected Steps per Second: 23,085.05763
Overall Steps per Second: 10,950.91864

Timestep Collection Time: 2.16616
Timestep Consumption Time: 2.40021
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.56637

Cumulative Model Updates: 146,726
Cumulative Timesteps: 1,223,783,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1223783600...
Checkpoint 1223783600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.48415
Policy Entropy: 3.06166
Value Function Loss: 0.00465

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.61738
Value Function Update Magnitude: 0.57213

Collected Steps per Second: 22,595.51995
Overall Steps per Second: 10,586.48872

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.51068
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.72395

Cumulative Model Updates: 146,732
Cumulative Timesteps: 1,223,833,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,472.42585
Policy Entropy: 3.05154
Value Function Loss: 0.00456

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.61145
Value Function Update Magnitude: 0.57034

Collected Steps per Second: 23,113.45985
Overall Steps per Second: 10,902.80045

Timestep Collection Time: 2.16385
Timestep Consumption Time: 2.42341
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.58726

Cumulative Model Updates: 146,738
Cumulative Timesteps: 1,223,883,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1223883624...
Checkpoint 1223883624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.17649
Policy Entropy: 3.06072
Value Function Loss: 0.00431

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.60372
Value Function Update Magnitude: 0.57942

Collected Steps per Second: 23,020.10677
Overall Steps per Second: 10,672.75818

Timestep Collection Time: 2.17314
Timestep Consumption Time: 2.51412
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.68726

Cumulative Model Updates: 146,744
Cumulative Timesteps: 1,223,933,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.97495
Policy Entropy: 3.05536
Value Function Loss: 0.00423

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.60202
Value Function Update Magnitude: 0.56362

Collected Steps per Second: 23,266.44123
Overall Steps per Second: 10,915.58985

Timestep Collection Time: 2.14936
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.58134

Cumulative Model Updates: 146,750
Cumulative Timesteps: 1,223,983,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1223983658...
Checkpoint 1223983658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.15311
Policy Entropy: 3.07266
Value Function Loss: 0.00444

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.59903
Value Function Update Magnitude: 0.55741

Collected Steps per Second: 22,786.60837
Overall Steps per Second: 10,736.04894

Timestep Collection Time: 2.19568
Timestep Consumption Time: 2.46451
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.66019

Cumulative Model Updates: 146,756
Cumulative Timesteps: 1,224,033,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,953.18310
Policy Entropy: 3.07447
Value Function Loss: 0.00468

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.59664
Value Function Update Magnitude: 0.54949

Collected Steps per Second: 23,022.76748
Overall Steps per Second: 10,796.04654

Timestep Collection Time: 2.17246
Timestep Consumption Time: 2.46035
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.63281

Cumulative Model Updates: 146,762
Cumulative Timesteps: 1,224,083,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1224083706...
Checkpoint 1224083706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.16172
Policy Entropy: 3.07664
Value Function Loss: 0.00459

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.59128
Value Function Update Magnitude: 0.55151

Collected Steps per Second: 23,004.78874
Overall Steps per Second: 10,628.95717

Timestep Collection Time: 2.17433
Timestep Consumption Time: 2.53168
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.70601

Cumulative Model Updates: 146,768
Cumulative Timesteps: 1,224,133,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,742.50377
Policy Entropy: 3.05465
Value Function Loss: 0.00442

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.59501
Value Function Update Magnitude: 0.54472

Collected Steps per Second: 23,265.57143
Overall Steps per Second: 10,902.29581

Timestep Collection Time: 2.14910
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.58619

Cumulative Model Updates: 146,774
Cumulative Timesteps: 1,224,183,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1224183726...
Checkpoint 1224183726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,365.70888
Policy Entropy: 3.03713
Value Function Loss: 0.00440

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.59507
Value Function Update Magnitude: 0.52253

Collected Steps per Second: 22,452.84239
Overall Steps per Second: 10,648.56402

Timestep Collection Time: 2.22742
Timestep Consumption Time: 2.46917
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.69660

Cumulative Model Updates: 146,780
Cumulative Timesteps: 1,224,233,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.95682
Policy Entropy: 3.03947
Value Function Loss: 0.00429

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10569
Policy Update Magnitude: 0.58357
Value Function Update Magnitude: 0.51482

Collected Steps per Second: 22,923.82082
Overall Steps per Second: 10,921.05161

Timestep Collection Time: 2.18253
Timestep Consumption Time: 2.39871
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.58124

Cumulative Model Updates: 146,786
Cumulative Timesteps: 1,224,283,770

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1224283770...
Checkpoint 1224283770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,518.43007
Policy Entropy: 3.05368
Value Function Loss: 0.00416

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.50009

Collected Steps per Second: 22,490.18955
Overall Steps per Second: 10,622.57742

Timestep Collection Time: 2.22390
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.70846

Cumulative Model Updates: 146,792
Cumulative Timesteps: 1,224,333,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,190.56939
Policy Entropy: 3.06515
Value Function Loss: 0.00415

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.49934

Collected Steps per Second: 22,789.52892
Overall Steps per Second: 10,826.20985

Timestep Collection Time: 2.19478
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.62008

Cumulative Model Updates: 146,798
Cumulative Timesteps: 1,224,383,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1224383804...
Checkpoint 1224383804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.36967
Policy Entropy: 3.05840
Value Function Loss: 0.00423

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.58439
Value Function Update Magnitude: 0.51359

Collected Steps per Second: 22,831.47232
Overall Steps per Second: 10,720.39163

Timestep Collection Time: 2.19066
Timestep Consumption Time: 2.47484
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.66550

Cumulative Model Updates: 146,804
Cumulative Timesteps: 1,224,433,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.71998
Policy Entropy: 3.07578
Value Function Loss: 0.00444

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.59427
Value Function Update Magnitude: 0.54618

Collected Steps per Second: 23,201.68074
Overall Steps per Second: 10,866.93007

Timestep Collection Time: 2.15605
Timestep Consumption Time: 2.44727
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60332

Cumulative Model Updates: 146,810
Cumulative Timesteps: 1,224,483,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1224483844...
Checkpoint 1224483844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,103.68359
Policy Entropy: 3.06606
Value Function Loss: 0.00458

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.59261
Value Function Update Magnitude: 0.54131

Collected Steps per Second: 22,958.06809
Overall Steps per Second: 10,774.32869

Timestep Collection Time: 2.17902
Timestep Consumption Time: 2.46406
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.64307

Cumulative Model Updates: 146,816
Cumulative Timesteps: 1,224,533,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.71792
Policy Entropy: 3.07072
Value Function Loss: 0.00478

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.59315
Value Function Update Magnitude: 0.53791

Collected Steps per Second: 23,390.11920
Overall Steps per Second: 10,853.26834

Timestep Collection Time: 2.13800
Timestep Consumption Time: 2.46965
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.60764

Cumulative Model Updates: 146,822
Cumulative Timesteps: 1,224,583,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1224583878...
Checkpoint 1224583878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.83585
Policy Entropy: 3.07257
Value Function Loss: 0.00465

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.57927
Value Function Update Magnitude: 0.54787

Collected Steps per Second: 22,825.01695
Overall Steps per Second: 10,657.77792

Timestep Collection Time: 2.19067
Timestep Consumption Time: 2.50093
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.69160

Cumulative Model Updates: 146,828
Cumulative Timesteps: 1,224,633,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.83551
Policy Entropy: 3.08035
Value Function Loss: 0.00468

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.55510

Collected Steps per Second: 23,027.71427
Overall Steps per Second: 10,895.33363

Timestep Collection Time: 2.17130
Timestep Consumption Time: 2.41782
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.58912

Cumulative Model Updates: 146,834
Cumulative Timesteps: 1,224,683,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1224683880...
Checkpoint 1224683880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,550.10880
Policy Entropy: 3.08642
Value Function Loss: 0.00449

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.59003
Value Function Update Magnitude: 0.55207

Collected Steps per Second: 22,163.86759
Overall Steps per Second: 10,616.40907

Timestep Collection Time: 2.25601
Timestep Consumption Time: 2.45386
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.70988

Cumulative Model Updates: 146,840
Cumulative Timesteps: 1,224,733,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.26160
Policy Entropy: 3.07107
Value Function Loss: 0.00466

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.59458
Value Function Update Magnitude: 0.54603

Collected Steps per Second: 22,810.40044
Overall Steps per Second: 10,842.26108

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.41989
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.61214

Cumulative Model Updates: 146,846
Cumulative Timesteps: 1,224,783,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1224783888...
Checkpoint 1224783888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.24791
Policy Entropy: 3.06737
Value Function Loss: 0.00459

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.59424
Value Function Update Magnitude: 0.54402

Collected Steps per Second: 22,299.05983
Overall Steps per Second: 10,683.37261

Timestep Collection Time: 2.24225
Timestep Consumption Time: 2.43792
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.68017

Cumulative Model Updates: 146,852
Cumulative Timesteps: 1,224,833,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,198.33234
Policy Entropy: 3.04843
Value Function Loss: 0.00469

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.59235
Value Function Update Magnitude: 0.54180

Collected Steps per Second: 21,675.15010
Overall Steps per Second: 10,434.00058

Timestep Collection Time: 2.30679
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.79203

Cumulative Model Updates: 146,858
Cumulative Timesteps: 1,224,883,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1224883888...
Checkpoint 1224883888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,061.40104
Policy Entropy: 3.05019
Value Function Loss: 0.00460

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.58973
Value Function Update Magnitude: 0.52325

Collected Steps per Second: 22,910.88754
Overall Steps per Second: 10,669.47204

Timestep Collection Time: 2.18289
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.68739

Cumulative Model Updates: 146,864
Cumulative Timesteps: 1,224,933,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,853.37742
Policy Entropy: 3.04901
Value Function Loss: 0.00475

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.59562
Value Function Update Magnitude: 0.51204

Collected Steps per Second: 23,405.30316
Overall Steps per Second: 10,872.97111

Timestep Collection Time: 2.13712
Timestep Consumption Time: 2.46328
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.60040

Cumulative Model Updates: 146,870
Cumulative Timesteps: 1,224,983,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1224983920...
Checkpoint 1224983920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.42937
Policy Entropy: 3.06250
Value Function Loss: 0.00473

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.59415
Value Function Update Magnitude: 0.51370

Collected Steps per Second: 22,823.79080
Overall Steps per Second: 10,705.82972

Timestep Collection Time: 2.19113
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.67129

Cumulative Model Updates: 146,876
Cumulative Timesteps: 1,225,033,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,435.81882
Policy Entropy: 3.06776
Value Function Loss: 0.00452

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.58706
Value Function Update Magnitude: 0.51063

Collected Steps per Second: 23,432.16982
Overall Steps per Second: 10,875.93493

Timestep Collection Time: 2.13510
Timestep Consumption Time: 2.46497
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.60006

Cumulative Model Updates: 146,882
Cumulative Timesteps: 1,225,083,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1225083960...
Checkpoint 1225083960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.17729
Policy Entropy: 3.06920
Value Function Loss: 0.00442

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.57749
Value Function Update Magnitude: 0.49809

Collected Steps per Second: 22,840.06038
Overall Steps per Second: 10,642.23020

Timestep Collection Time: 2.18931
Timestep Consumption Time: 2.50933
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.69864

Cumulative Model Updates: 146,888
Cumulative Timesteps: 1,225,133,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.29319
Policy Entropy: 3.06259
Value Function Loss: 0.00449

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.58451
Value Function Update Magnitude: 0.50565

Collected Steps per Second: 23,269.19174
Overall Steps per Second: 10,922.52191

Timestep Collection Time: 2.15108
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.58264

Cumulative Model Updates: 146,894
Cumulative Timesteps: 1,225,184,018

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1225184018...
Checkpoint 1225184018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,681.82004
Policy Entropy: 3.06747
Value Function Loss: 0.00428

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.58020
Value Function Update Magnitude: 0.52750

Collected Steps per Second: 22,392.86423
Overall Steps per Second: 10,642.00651

Timestep Collection Time: 2.23312
Timestep Consumption Time: 2.46580
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.69893

Cumulative Model Updates: 146,900
Cumulative Timesteps: 1,225,234,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,100.52445
Policy Entropy: 3.08341
Value Function Loss: 0.00404

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.52011

Collected Steps per Second: 22,987.64591
Overall Steps per Second: 10,851.27667

Timestep Collection Time: 2.17630
Timestep Consumption Time: 2.43403
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.61033

Cumulative Model Updates: 146,906
Cumulative Timesteps: 1,225,284,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1225284052...
Checkpoint 1225284052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.85857
Policy Entropy: 3.09474
Value Function Loss: 0.00411

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.52179

Collected Steps per Second: 22,448.21577
Overall Steps per Second: 10,746.44164

Timestep Collection Time: 2.22753
Timestep Consumption Time: 2.42555
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.65308

Cumulative Model Updates: 146,912
Cumulative Timesteps: 1,225,334,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.47571
Policy Entropy: 3.10382
Value Function Loss: 0.00422

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.56653
Value Function Update Magnitude: 0.53632

Collected Steps per Second: 22,924.65723
Overall Steps per Second: 10,784.26302

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.45651
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.63861

Cumulative Model Updates: 146,918
Cumulative Timesteps: 1,225,384,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1225384080...
Checkpoint 1225384080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,713.01222
Policy Entropy: 3.10069
Value Function Loss: 0.00445

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.57122
Value Function Update Magnitude: 0.55378

Collected Steps per Second: 22,783.47071
Overall Steps per Second: 10,703.45183

Timestep Collection Time: 2.19536
Timestep Consumption Time: 2.47771
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.67307

Cumulative Model Updates: 146,924
Cumulative Timesteps: 1,225,434,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,143.28019
Policy Entropy: 3.10401
Value Function Loss: 0.00429

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.57998
Value Function Update Magnitude: 0.59719

Collected Steps per Second: 23,196.34867
Overall Steps per Second: 10,902.05430

Timestep Collection Time: 2.15568
Timestep Consumption Time: 2.43097
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.58666

Cumulative Model Updates: 146,930
Cumulative Timesteps: 1,225,484,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1225484102...
Checkpoint 1225484102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.25930
Policy Entropy: 3.08961
Value Function Loss: 0.00395

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.57866
Value Function Update Magnitude: 0.57563

Collected Steps per Second: 22,963.92563
Overall Steps per Second: 10,644.82707

Timestep Collection Time: 2.17829
Timestep Consumption Time: 2.52090
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.69918

Cumulative Model Updates: 146,936
Cumulative Timesteps: 1,225,534,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.41589
Policy Entropy: 3.08840
Value Function Loss: 0.00377

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.57099
Value Function Update Magnitude: 0.55025

Collected Steps per Second: 23,217.86694
Overall Steps per Second: 10,884.98558

Timestep Collection Time: 2.15429
Timestep Consumption Time: 2.44085
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.59514

Cumulative Model Updates: 146,942
Cumulative Timesteps: 1,225,584,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1225584142...
Checkpoint 1225584142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.59340
Policy Entropy: 3.07729
Value Function Loss: 0.00394

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.54458

Collected Steps per Second: 22,772.35949
Overall Steps per Second: 10,684.34900

Timestep Collection Time: 2.19652
Timestep Consumption Time: 2.48509
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.68161

Cumulative Model Updates: 146,948
Cumulative Timesteps: 1,225,634,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,276.75347
Policy Entropy: 3.07882
Value Function Loss: 0.00403

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.57153
Value Function Update Magnitude: 0.53543

Collected Steps per Second: 23,269.19810
Overall Steps per Second: 10,920.57142

Timestep Collection Time: 2.14919
Timestep Consumption Time: 2.43024
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.57943

Cumulative Model Updates: 146,954
Cumulative Timesteps: 1,225,684,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1225684172...
Checkpoint 1225684172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,908.44412
Policy Entropy: 3.07430
Value Function Loss: 0.00407

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.56345
Value Function Update Magnitude: 0.53381

Collected Steps per Second: 22,621.88016
Overall Steps per Second: 10,633.57947

Timestep Collection Time: 2.21087
Timestep Consumption Time: 2.49253
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.70340

Cumulative Model Updates: 146,960
Cumulative Timesteps: 1,225,734,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,529.14220
Policy Entropy: 3.08150
Value Function Loss: 0.00388

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.56968
Value Function Update Magnitude: 0.54556

Collected Steps per Second: 22,847.25407
Overall Steps per Second: 10,802.73528

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.62994

Cumulative Model Updates: 146,966
Cumulative Timesteps: 1,225,784,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1225784202...
Checkpoint 1225784202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.19641
Policy Entropy: 3.07318
Value Function Loss: 0.00392

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.57170
Value Function Update Magnitude: 0.54642

Collected Steps per Second: 22,576.80134
Overall Steps per Second: 10,775.32765

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.42634
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.64171

Cumulative Model Updates: 146,972
Cumulative Timesteps: 1,225,834,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,967.24048
Policy Entropy: 3.08084
Value Function Loss: 0.00392

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.57229
Value Function Update Magnitude: 0.54381

Collected Steps per Second: 22,974.95285
Overall Steps per Second: 10,814.95308

Timestep Collection Time: 2.17759
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.62600

Cumulative Model Updates: 146,978
Cumulative Timesteps: 1,225,884,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1225884248...
Checkpoint 1225884248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.26861
Policy Entropy: 3.08184
Value Function Loss: 0.00396

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.56436
Value Function Update Magnitude: 0.51992

Collected Steps per Second: 23,162.64625
Overall Steps per Second: 10,668.33468

Timestep Collection Time: 2.15865
Timestep Consumption Time: 2.52812
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.68677

Cumulative Model Updates: 146,984
Cumulative Timesteps: 1,225,934,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,275.00934
Policy Entropy: 3.07260
Value Function Loss: 0.00425

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.51659

Collected Steps per Second: 23,230.41315
Overall Steps per Second: 10,893.45280

Timestep Collection Time: 2.15338
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.59212

Cumulative Model Updates: 146,990
Cumulative Timesteps: 1,225,984,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1225984272...
Checkpoint 1225984272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.58481
Policy Entropy: 3.05112
Value Function Loss: 0.00434

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11068
Policy Update Magnitude: 0.58152
Value Function Update Magnitude: 0.52067

Collected Steps per Second: 22,781.64993
Overall Steps per Second: 10,690.93565

Timestep Collection Time: 2.19519
Timestep Consumption Time: 2.48261
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.67779

Cumulative Model Updates: 146,996
Cumulative Timesteps: 1,226,034,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.06060
Policy Entropy: 3.03735
Value Function Loss: 0.00419

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.57286
Value Function Update Magnitude: 0.52238

Collected Steps per Second: 23,354.48880
Overall Steps per Second: 10,924.03180

Timestep Collection Time: 2.14126
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.57780

Cumulative Model Updates: 147,002
Cumulative Timesteps: 1,226,084,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1226084290...
Checkpoint 1226084290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.70410
Policy Entropy: 3.03887
Value Function Loss: 0.00411

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.51570

Collected Steps per Second: 23,030.40414
Overall Steps per Second: 10,670.28466

Timestep Collection Time: 2.17104
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.68591

Cumulative Model Updates: 147,008
Cumulative Timesteps: 1,226,134,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.14250
Policy Entropy: 3.04408
Value Function Loss: 0.00420

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.59196
Value Function Update Magnitude: 0.52874

Collected Steps per Second: 23,203.56021
Overall Steps per Second: 10,905.14610

Timestep Collection Time: 2.15536
Timestep Consumption Time: 2.43073
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.58609

Cumulative Model Updates: 147,014
Cumulative Timesteps: 1,226,184,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1226184302...
Checkpoint 1226184302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,048.50971
Policy Entropy: 3.06128
Value Function Loss: 0.00426

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.59046
Value Function Update Magnitude: 0.52833

Collected Steps per Second: 22,372.32257
Overall Steps per Second: 10,595.54027

Timestep Collection Time: 2.23499
Timestep Consumption Time: 2.48416
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.71916

Cumulative Model Updates: 147,020
Cumulative Timesteps: 1,226,234,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,568.47161
Policy Entropy: 3.07174
Value Function Loss: 0.00438

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.57341
Value Function Update Magnitude: 0.49624

Collected Steps per Second: 22,859.92580
Overall Steps per Second: 10,834.87290

Timestep Collection Time: 2.18802
Timestep Consumption Time: 2.42837
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61639

Cumulative Model Updates: 147,026
Cumulative Timesteps: 1,226,284,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1226284322...
Checkpoint 1226284322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,738.46249
Policy Entropy: 3.07829
Value Function Loss: 0.00434

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.56109
Value Function Update Magnitude: 0.49005

Collected Steps per Second: 22,469.14996
Overall Steps per Second: 10,754.38805

Timestep Collection Time: 2.22590
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.65057

Cumulative Model Updates: 147,032
Cumulative Timesteps: 1,226,334,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759.17344
Policy Entropy: 3.07935
Value Function Loss: 0.00432

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.56753
Value Function Update Magnitude: 0.51060

Collected Steps per Second: 22,934.24855
Overall Steps per Second: 10,803.61219

Timestep Collection Time: 2.18084
Timestep Consumption Time: 2.44872
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.62956

Cumulative Model Updates: 147,038
Cumulative Timesteps: 1,226,384,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1226384352...
Checkpoint 1226384352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.58968
Policy Entropy: 3.08149
Value Function Loss: 0.00412

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.57086
Value Function Update Magnitude: 0.52043

Collected Steps per Second: 23,038.96897
Overall Steps per Second: 10,681.96190

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.51156
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.68266

Cumulative Model Updates: 147,044
Cumulative Timesteps: 1,226,434,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.55722
Policy Entropy: 3.07751
Value Function Loss: 0.00405

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.51516

Collected Steps per Second: 23,078.83017
Overall Steps per Second: 10,830.50952

Timestep Collection Time: 2.16761
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.61899

Cumulative Model Updates: 147,050
Cumulative Timesteps: 1,226,484,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1226484398...
Checkpoint 1226484398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.08010
Policy Entropy: 3.08650
Value Function Loss: 0.00398

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.56937
Value Function Update Magnitude: 0.51675

Collected Steps per Second: 23,182.99812
Overall Steps per Second: 10,761.48670

Timestep Collection Time: 2.15839
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.64973

Cumulative Model Updates: 147,056
Cumulative Timesteps: 1,226,534,436

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.96147
Policy Entropy: 3.09373
Value Function Loss: 0.00411

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.51381

Collected Steps per Second: 23,544.85544
Overall Steps per Second: 10,873.14743

Timestep Collection Time: 2.12446
Timestep Consumption Time: 2.47587
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.60032

Cumulative Model Updates: 147,062
Cumulative Timesteps: 1,226,584,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1226584456...
Checkpoint 1226584456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.66923
Policy Entropy: 3.09096
Value Function Loss: 0.00460

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.58078
Value Function Update Magnitude: 0.52950

Collected Steps per Second: 22,847.78822
Overall Steps per Second: 10,640.61768

Timestep Collection Time: 2.18953
Timestep Consumption Time: 2.51189
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.70142

Cumulative Model Updates: 147,068
Cumulative Timesteps: 1,226,634,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,703.98955
Policy Entropy: 3.07010
Value Function Loss: 0.00494

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.60014
Value Function Update Magnitude: 0.56527

Collected Steps per Second: 23,088.93321
Overall Steps per Second: 10,870.54865

Timestep Collection Time: 2.16580
Timestep Consumption Time: 2.43434
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.60014

Cumulative Model Updates: 147,074
Cumulative Timesteps: 1,226,684,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1226684488...
Checkpoint 1226684488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.88442
Policy Entropy: 3.05568
Value Function Loss: 0.00463

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.59904
Value Function Update Magnitude: 0.58128

Collected Steps per Second: 22,680.14266
Overall Steps per Second: 10,697.91399

Timestep Collection Time: 2.20545
Timestep Consumption Time: 2.47022
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.67568

Cumulative Model Updates: 147,080
Cumulative Timesteps: 1,226,734,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.61138
Policy Entropy: 3.05645
Value Function Loss: 0.00452

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.59811
Value Function Update Magnitude: 0.59445

Collected Steps per Second: 22,924.40643
Overall Steps per Second: 10,809.65589

Timestep Collection Time: 2.18178
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.62697

Cumulative Model Updates: 147,086
Cumulative Timesteps: 1,226,784,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1226784524...
Checkpoint 1226784524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,404.59466
Policy Entropy: 3.07133
Value Function Loss: 0.00388

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.58295
Value Function Update Magnitude: 0.58748

Collected Steps per Second: 22,227.33999
Overall Steps per Second: 10,661.47465

Timestep Collection Time: 2.25011
Timestep Consumption Time: 2.44098
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.69110

Cumulative Model Updates: 147,092
Cumulative Timesteps: 1,226,834,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.84334
Policy Entropy: 3.07382
Value Function Loss: 0.00439

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.57995
Value Function Update Magnitude: 0.58912

Collected Steps per Second: 22,714.07599
Overall Steps per Second: 10,637.26112

Timestep Collection Time: 2.20233
Timestep Consumption Time: 2.50038
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.70271

Cumulative Model Updates: 147,098
Cumulative Timesteps: 1,226,884,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1226884562...
Checkpoint 1226884562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.11479
Policy Entropy: 3.09050
Value Function Loss: 0.00403

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.57471
Value Function Update Magnitude: 0.57422

Collected Steps per Second: 22,619.22668
Overall Steps per Second: 10,586.49899

Timestep Collection Time: 2.21130
Timestep Consumption Time: 2.51339
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72470

Cumulative Model Updates: 147,104
Cumulative Timesteps: 1,226,934,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.53982
Policy Entropy: 3.09007
Value Function Loss: 0.00411

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.54878

Collected Steps per Second: 23,290.10595
Overall Steps per Second: 10,832.45939

Timestep Collection Time: 2.14804
Timestep Consumption Time: 2.47031
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.61834

Cumulative Model Updates: 147,110
Cumulative Timesteps: 1,226,984,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1226984608...
Checkpoint 1226984608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,292.81260
Policy Entropy: 3.10457
Value Function Loss: 0.00374

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.55157
Value Function Update Magnitude: 0.52339

Collected Steps per Second: 22,874.57110
Overall Steps per Second: 10,740.39660

Timestep Collection Time: 2.18601
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.65569

Cumulative Model Updates: 147,116
Cumulative Timesteps: 1,227,034,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.12432
Policy Entropy: 3.07295
Value Function Loss: 0.00430

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.54050

Collected Steps per Second: 23,187.64886
Overall Steps per Second: 10,816.47774

Timestep Collection Time: 2.15667
Timestep Consumption Time: 2.46665
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.62332

Cumulative Model Updates: 147,122
Cumulative Timesteps: 1,227,084,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1227084620...
Checkpoint 1227084620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.14087
Policy Entropy: 3.07449
Value Function Loss: 0.00437

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.58044
Value Function Update Magnitude: 0.57357

Collected Steps per Second: 23,018.12380
Overall Steps per Second: 10,774.59653

Timestep Collection Time: 2.17342
Timestep Consumption Time: 2.46973
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.64314

Cumulative Model Updates: 147,128
Cumulative Timesteps: 1,227,134,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.66685
Policy Entropy: 3.06340
Value Function Loss: 0.00458

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.57140
Value Function Update Magnitude: 0.57098

Collected Steps per Second: 23,647.60752
Overall Steps per Second: 10,919.35092

Timestep Collection Time: 2.11472
Timestep Consumption Time: 2.46504
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.57976

Cumulative Model Updates: 147,134
Cumulative Timesteps: 1,227,184,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1227184656...
Checkpoint 1227184656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,694.59078
Policy Entropy: 3.06626
Value Function Loss: 0.00427

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.56801
Value Function Update Magnitude: 0.55378

Collected Steps per Second: 22,767.67456
Overall Steps per Second: 10,683.87818

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.48534
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.68276

Cumulative Model Updates: 147,140
Cumulative Timesteps: 1,227,234,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,590.29659
Policy Entropy: 3.06704
Value Function Loss: 0.00422

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.57646
Value Function Update Magnitude: 0.53095

Collected Steps per Second: 23,008.23310
Overall Steps per Second: 10,776.04616

Timestep Collection Time: 2.17400
Timestep Consumption Time: 2.46777
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.64178

Cumulative Model Updates: 147,146
Cumulative Timesteps: 1,227,284,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1227284706...
Checkpoint 1227284706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,310.47087
Policy Entropy: 3.06442
Value Function Loss: 0.00439

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.58654
Value Function Update Magnitude: 0.54073

Collected Steps per Second: 22,528.01128
Overall Steps per Second: 10,633.51131

Timestep Collection Time: 2.22035
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.70400

Cumulative Model Updates: 147,152
Cumulative Timesteps: 1,227,334,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639.92369
Policy Entropy: 3.06691
Value Function Loss: 0.00446

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.59617
Value Function Update Magnitude: 0.57170

Collected Steps per Second: 22,879.30940
Overall Steps per Second: 10,820.09085

Timestep Collection Time: 2.18625
Timestep Consumption Time: 2.43663
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.62288

Cumulative Model Updates: 147,158
Cumulative Timesteps: 1,227,384,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1227384746...
Checkpoint 1227384746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.86714
Policy Entropy: 3.05152
Value Function Loss: 0.00450

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.59534
Value Function Update Magnitude: 0.56825

Collected Steps per Second: 22,479.78487
Overall Steps per Second: 10,713.80490

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.44383
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.66912

Cumulative Model Updates: 147,164
Cumulative Timesteps: 1,227,434,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958.03474
Policy Entropy: 3.04684
Value Function Loss: 0.00450

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.59181
Value Function Update Magnitude: 0.54736

Collected Steps per Second: 23,157.30804
Overall Steps per Second: 10,892.25402

Timestep Collection Time: 2.16018
Timestep Consumption Time: 2.43244
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.59262

Cumulative Model Updates: 147,170
Cumulative Timesteps: 1,227,484,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1227484794...
Checkpoint 1227484794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.99927
Policy Entropy: 3.04689
Value Function Loss: 0.00454

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.59221
Value Function Update Magnitude: 0.54989

Collected Steps per Second: 23,001.66219
Overall Steps per Second: 10,691.30988

Timestep Collection Time: 2.17436
Timestep Consumption Time: 2.50364
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.67800

Cumulative Model Updates: 147,176
Cumulative Timesteps: 1,227,534,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.11516
Policy Entropy: 3.04268
Value Function Loss: 0.00435

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.58275
Value Function Update Magnitude: 0.56255

Collected Steps per Second: 23,041.98640
Overall Steps per Second: 10,832.47175

Timestep Collection Time: 2.17021
Timestep Consumption Time: 2.44609
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61631

Cumulative Model Updates: 147,182
Cumulative Timesteps: 1,227,584,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1227584814...
Checkpoint 1227584814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,219.87159
Policy Entropy: 3.04973
Value Function Loss: 0.00426

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.57522
Value Function Update Magnitude: 0.55588

Collected Steps per Second: 22,758.45215
Overall Steps per Second: 10,675.70904

Timestep Collection Time: 2.19813
Timestep Consumption Time: 2.48784
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.68597

Cumulative Model Updates: 147,188
Cumulative Timesteps: 1,227,634,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,094.46490
Policy Entropy: 3.03352
Value Function Loss: 0.00429

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.57397
Value Function Update Magnitude: 0.55423

Collected Steps per Second: 23,374.88131
Overall Steps per Second: 10,954.50323

Timestep Collection Time: 2.14016
Timestep Consumption Time: 2.42655
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.56671

Cumulative Model Updates: 147,194
Cumulative Timesteps: 1,227,684,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1227684866...
Checkpoint 1227684866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.03300
Policy Entropy: 3.04794
Value Function Loss: 0.00422

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.57398
Value Function Update Magnitude: 0.56227

Collected Steps per Second: 23,014.52567
Overall Steps per Second: 10,808.83634

Timestep Collection Time: 2.17393
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.62881

Cumulative Model Updates: 147,200
Cumulative Timesteps: 1,227,734,898

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.35387
Policy Entropy: 3.03957
Value Function Loss: 0.00444

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.58311
Value Function Update Magnitude: 0.56642

Collected Steps per Second: 23,028.60286
Overall Steps per Second: 10,696.13872

Timestep Collection Time: 2.17226
Timestep Consumption Time: 2.50457
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.67683

Cumulative Model Updates: 147,206
Cumulative Timesteps: 1,227,784,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1227784922...
Checkpoint 1227784922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.53368
Policy Entropy: 3.05751
Value Function Loss: 0.00438

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.58833
Value Function Update Magnitude: 0.55477

Collected Steps per Second: 22,580.96074
Overall Steps per Second: 10,649.32366

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.69682

Cumulative Model Updates: 147,212
Cumulative Timesteps: 1,227,834,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.99892
Policy Entropy: 3.05429
Value Function Loss: 0.00428

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.58200
Value Function Update Magnitude: 0.53894

Collected Steps per Second: 22,946.47601
Overall Steps per Second: 10,891.59414

Timestep Collection Time: 2.17925
Timestep Consumption Time: 2.41200
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.59125

Cumulative Model Updates: 147,218
Cumulative Timesteps: 1,227,884,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1227884946...
Checkpoint 1227884946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,001.62522
Policy Entropy: 3.06365
Value Function Loss: 0.00440

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.58443
Value Function Update Magnitude: 0.54446

Collected Steps per Second: 22,642.36192
Overall Steps per Second: 10,674.67901

Timestep Collection Time: 2.20975
Timestep Consumption Time: 2.47741
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.68717

Cumulative Model Updates: 147,224
Cumulative Timesteps: 1,227,934,980

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.58367
Policy Entropy: 3.05225
Value Function Loss: 0.00419

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10676
Policy Update Magnitude: 0.58707
Value Function Update Magnitude: 0.54326

Collected Steps per Second: 23,318.37787
Overall Steps per Second: 10,919.12830

Timestep Collection Time: 2.14475
Timestep Consumption Time: 2.43547
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.58022

Cumulative Model Updates: 147,230
Cumulative Timesteps: 1,227,984,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1227984992...
Checkpoint 1227984992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.91795
Policy Entropy: 3.04888
Value Function Loss: 0.00456

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.58049
Value Function Update Magnitude: 0.52029

Collected Steps per Second: 22,976.81544
Overall Steps per Second: 10,776.15026

Timestep Collection Time: 2.17628
Timestep Consumption Time: 2.46397
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.64025

Cumulative Model Updates: 147,236
Cumulative Timesteps: 1,228,034,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164.36285
Policy Entropy: 3.05579
Value Function Loss: 0.00452

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.58109
Value Function Update Magnitude: 0.51194

Collected Steps per Second: 23,503.27680
Overall Steps per Second: 10,939.26090

Timestep Collection Time: 2.12796
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.57197

Cumulative Model Updates: 147,242
Cumulative Timesteps: 1,228,085,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1228085010...
Checkpoint 1228085010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.96314
Policy Entropy: 3.05208
Value Function Loss: 0.00454

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.58626
Value Function Update Magnitude: 0.51835

Collected Steps per Second: 23,108.70536
Overall Steps per Second: 10,882.69790

Timestep Collection Time: 2.16429
Timestep Consumption Time: 2.43144
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.59574

Cumulative Model Updates: 147,248
Cumulative Timesteps: 1,228,135,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.68302
Policy Entropy: 3.05291
Value Function Loss: 0.00432

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.59312
Value Function Update Magnitude: 0.54729

Collected Steps per Second: 23,425.79562
Overall Steps per Second: 10,916.25311

Timestep Collection Time: 2.13448
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.58051

Cumulative Model Updates: 147,254
Cumulative Timesteps: 1,228,185,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1228185026...
Checkpoint 1228185026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.06439
Policy Entropy: 3.05045
Value Function Loss: 0.00435

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.59668
Value Function Update Magnitude: 0.55458

Collected Steps per Second: 22,708.03306
Overall Steps per Second: 10,649.17307

Timestep Collection Time: 2.20248
Timestep Consumption Time: 2.49403
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.69651

Cumulative Model Updates: 147,260
Cumulative Timesteps: 1,228,235,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415.67514
Policy Entropy: 3.04810
Value Function Loss: 0.00426

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.58544
Value Function Update Magnitude: 0.53878

Collected Steps per Second: 22,793.30696
Overall Steps per Second: 10,884.92608

Timestep Collection Time: 2.19459
Timestep Consumption Time: 2.40094
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.59553

Cumulative Model Updates: 147,266
Cumulative Timesteps: 1,228,285,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1228285062...
Checkpoint 1228285062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.76189
Policy Entropy: 3.05290
Value Function Loss: 0.00418

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.58316
Value Function Update Magnitude: 0.52610

Collected Steps per Second: 22,537.98831
Overall Steps per Second: 10,707.74216

Timestep Collection Time: 2.21981
Timestep Consumption Time: 2.45251
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.67232

Cumulative Model Updates: 147,272
Cumulative Timesteps: 1,228,335,092

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,269.06226
Policy Entropy: 3.04943
Value Function Loss: 0.00411

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.59309
Value Function Update Magnitude: 0.51964

Collected Steps per Second: 22,800.33460
Overall Steps per Second: 10,858.30100

Timestep Collection Time: 2.19356
Timestep Consumption Time: 2.41250
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.60606

Cumulative Model Updates: 147,278
Cumulative Timesteps: 1,228,385,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1228385106...
Checkpoint 1228385106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.85241
Policy Entropy: 3.05671
Value Function Loss: 0.00404

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.59815
Value Function Update Magnitude: 0.52707

Collected Steps per Second: 22,463.99888
Overall Steps per Second: 10,703.93365

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.67305

Cumulative Model Updates: 147,284
Cumulative Timesteps: 1,228,435,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.56713
Policy Entropy: 3.04799
Value Function Loss: 0.00402

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.59070
Value Function Update Magnitude: 0.51009

Collected Steps per Second: 23,336.72293
Overall Steps per Second: 10,841.00691

Timestep Collection Time: 2.14263
Timestep Consumption Time: 2.46967
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.61230

Cumulative Model Updates: 147,290
Cumulative Timesteps: 1,228,485,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1228485128...
Checkpoint 1228485128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171.86559
Policy Entropy: 3.05077
Value Function Loss: 0.00400

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.58583
Value Function Update Magnitude: 0.51331

Collected Steps per Second: 23,076.91740
Overall Steps per Second: 10,822.66824

Timestep Collection Time: 2.16667
Timestep Consumption Time: 2.45327
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.61993

Cumulative Model Updates: 147,296
Cumulative Timesteps: 1,228,535,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.61138
Policy Entropy: 3.05315
Value Function Loss: 0.00457

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.60062
Value Function Update Magnitude: 0.53375

Collected Steps per Second: 23,479.97472
Overall Steps per Second: 10,836.95497

Timestep Collection Time: 2.12981
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.61458

Cumulative Model Updates: 147,302
Cumulative Timesteps: 1,228,585,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1228585136...
Checkpoint 1228585136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.62578
Policy Entropy: 3.06684
Value Function Loss: 0.00456

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.60469
Value Function Update Magnitude: 0.54652

Collected Steps per Second: 23,075.56528
Overall Steps per Second: 10,952.09287

Timestep Collection Time: 2.16697
Timestep Consumption Time: 2.39874
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.56570

Cumulative Model Updates: 147,308
Cumulative Timesteps: 1,228,635,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.43288
Policy Entropy: 3.08409
Value Function Loss: 0.00468

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.59886
Value Function Update Magnitude: 0.55765

Collected Steps per Second: 23,322.15638
Overall Steps per Second: 11,022.09255

Timestep Collection Time: 2.14406
Timestep Consumption Time: 2.39265
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.53671

Cumulative Model Updates: 147,314
Cumulative Timesteps: 1,228,685,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1228685144...
Checkpoint 1228685144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.67347
Policy Entropy: 3.10289
Value Function Loss: 0.00420

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.58472
Value Function Update Magnitude: 0.55904

Collected Steps per Second: 22,391.91903
Overall Steps per Second: 10,611.70912

Timestep Collection Time: 2.23340
Timestep Consumption Time: 2.47932
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.71272

Cumulative Model Updates: 147,320
Cumulative Timesteps: 1,228,735,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,811.57254
Policy Entropy: 3.10222
Value Function Loss: 0.00412

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.56749
Value Function Update Magnitude: 0.52258

Collected Steps per Second: 22,776.85562
Overall Steps per Second: 10,826.31952

Timestep Collection Time: 2.19600
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.62004

Cumulative Model Updates: 147,326
Cumulative Timesteps: 1,228,785,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1228785172...
Checkpoint 1228785172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.99266
Policy Entropy: 3.10629
Value Function Loss: 0.00404

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.56158
Value Function Update Magnitude: 0.50970

Collected Steps per Second: 22,490.61104
Overall Steps per Second: 10,718.55066

Timestep Collection Time: 2.22413
Timestep Consumption Time: 2.44273
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.66686

Cumulative Model Updates: 147,332
Cumulative Timesteps: 1,228,835,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,918.12776
Policy Entropy: 3.09897
Value Function Loss: 0.00405

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.56241
Value Function Update Magnitude: 0.50297

Collected Steps per Second: 22,920.66545
Overall Steps per Second: 10,810.36441

Timestep Collection Time: 2.18275
Timestep Consumption Time: 2.44522
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.62797

Cumulative Model Updates: 147,338
Cumulative Timesteps: 1,228,885,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1228885224...
Checkpoint 1228885224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,127.48801
Policy Entropy: 3.09243
Value Function Loss: 0.00387

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.56271
Value Function Update Magnitude: 0.49862

Collected Steps per Second: 22,381.19901
Overall Steps per Second: 10,705.37051

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.43712
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.67167

Cumulative Model Updates: 147,344
Cumulative Timesteps: 1,228,935,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,186.72778
Policy Entropy: 3.09247
Value Function Loss: 0.00425

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.57971
Value Function Update Magnitude: 0.50774

Collected Steps per Second: 23,407.57368
Overall Steps per Second: 10,865.32637

Timestep Collection Time: 2.13692
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.60364

Cumulative Model Updates: 147,350
Cumulative Timesteps: 1,228,985,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1228985256...
Checkpoint 1228985256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.54232
Policy Entropy: 3.07462
Value Function Loss: 0.00427

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.58419
Value Function Update Magnitude: 0.55197

Collected Steps per Second: 22,891.50325
Overall Steps per Second: 10,702.23067

Timestep Collection Time: 2.18544
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.67454

Cumulative Model Updates: 147,356
Cumulative Timesteps: 1,229,035,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,555.54145
Policy Entropy: 3.07230
Value Function Loss: 0.00424

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.57535
Value Function Update Magnitude: 0.57631

Collected Steps per Second: 23,420.68444
Overall Steps per Second: 10,945.59591

Timestep Collection Time: 2.13521
Timestep Consumption Time: 2.43357
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.56878

Cumulative Model Updates: 147,362
Cumulative Timesteps: 1,229,085,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1229085292...
Checkpoint 1229085292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.70305
Policy Entropy: 3.07861
Value Function Loss: 0.00403

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.55795

Collected Steps per Second: 23,202.20927
Overall Steps per Second: 10,790.01609

Timestep Collection Time: 2.15514
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.63428

Cumulative Model Updates: 147,368
Cumulative Timesteps: 1,229,135,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.97791
Policy Entropy: 3.09727
Value Function Loss: 0.00382

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.57640
Value Function Update Magnitude: 0.55189

Collected Steps per Second: 23,265.37083
Overall Steps per Second: 10,713.69919

Timestep Collection Time: 2.15041
Timestep Consumption Time: 2.51932
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.66972

Cumulative Model Updates: 147,374
Cumulative Timesteps: 1,229,185,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1229185326...
Checkpoint 1229185326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.00732
Policy Entropy: 3.10899
Value Function Loss: 0.00393

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.57214
Value Function Update Magnitude: 0.52588

Collected Steps per Second: 22,838.82086
Overall Steps per Second: 10,641.62949

Timestep Collection Time: 2.18978
Timestep Consumption Time: 2.50988
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.69966

Cumulative Model Updates: 147,380
Cumulative Timesteps: 1,229,235,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,959.46309
Policy Entropy: 3.09468
Value Function Loss: 0.00403

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.56619
Value Function Update Magnitude: 0.50350

Collected Steps per Second: 22,988.24692
Overall Steps per Second: 10,843.74921

Timestep Collection Time: 2.17607
Timestep Consumption Time: 2.43710
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61316

Cumulative Model Updates: 147,386
Cumulative Timesteps: 1,229,285,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1229285362...
Checkpoint 1229285362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.10588
Policy Entropy: 3.10180
Value Function Loss: 0.00383

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.55864
Value Function Update Magnitude: 0.49187

Collected Steps per Second: 22,626.40925
Overall Steps per Second: 10,756.26442

Timestep Collection Time: 2.21104
Timestep Consumption Time: 2.44001
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.65106

Cumulative Model Updates: 147,392
Cumulative Timesteps: 1,229,335,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,926.75262
Policy Entropy: 3.09011
Value Function Loss: 0.00443

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.50067

Collected Steps per Second: 22,700.24926
Overall Steps per Second: 10,787.81488

Timestep Collection Time: 2.20288
Timestep Consumption Time: 2.43253
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.63542

Cumulative Model Updates: 147,398
Cumulative Timesteps: 1,229,385,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1229385396...
Checkpoint 1229385396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.60794
Policy Entropy: 3.08883
Value Function Loss: 0.00455

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.58898
Value Function Update Magnitude: 0.53548

Collected Steps per Second: 22,498.73663
Overall Steps per Second: 10,749.88222

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.42896
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.65140

Cumulative Model Updates: 147,404
Cumulative Timesteps: 1,229,435,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.94563
Policy Entropy: 3.07279
Value Function Loss: 0.00432

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10839
Policy Update Magnitude: 0.58329
Value Function Update Magnitude: 0.55392

Collected Steps per Second: 23,483.34941
Overall Steps per Second: 10,922.49317

Timestep Collection Time: 2.12985
Timestep Consumption Time: 2.44932
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.57917

Cumulative Model Updates: 147,410
Cumulative Timesteps: 1,229,485,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1229485414...
Checkpoint 1229485414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.84782
Policy Entropy: 3.06745
Value Function Loss: 0.00431

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.53310

Collected Steps per Second: 23,332.29871
Overall Steps per Second: 10,970.02015

Timestep Collection Time: 2.14312
Timestep Consumption Time: 2.41512
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.55824

Cumulative Model Updates: 147,416
Cumulative Timesteps: 1,229,535,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.60385
Policy Entropy: 3.07191
Value Function Loss: 0.00401

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.57381
Value Function Update Magnitude: 0.53559

Collected Steps per Second: 23,162.07616
Overall Steps per Second: 10,884.27821

Timestep Collection Time: 2.16008
Timestep Consumption Time: 2.43664
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.59672

Cumulative Model Updates: 147,422
Cumulative Timesteps: 1,229,585,450

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1229585450...
Checkpoint 1229585450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,822.72819
Policy Entropy: 3.07109
Value Function Loss: 0.00431

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.57726
Value Function Update Magnitude: 0.52501

Collected Steps per Second: 23,126.63957
Overall Steps per Second: 10,729.45380

Timestep Collection Time: 2.16322
Timestep Consumption Time: 2.49946
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.66268

Cumulative Model Updates: 147,428
Cumulative Timesteps: 1,229,635,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,290.04852
Policy Entropy: 3.08271
Value Function Loss: 0.00419

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.58159
Value Function Update Magnitude: 0.53985

Collected Steps per Second: 23,459.89500
Overall Steps per Second: 10,968.80295

Timestep Collection Time: 2.13189
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.55966

Cumulative Model Updates: 147,434
Cumulative Timesteps: 1,229,685,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1229685492...
Checkpoint 1229685492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,115.92648
Policy Entropy: 3.06842
Value Function Loss: 0.00455

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.58749
Value Function Update Magnitude: 0.56814

Collected Steps per Second: 22,429.50844
Overall Steps per Second: 10,617.14733

Timestep Collection Time: 2.22930
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.70955

Cumulative Model Updates: 147,440
Cumulative Timesteps: 1,229,735,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.01526
Policy Entropy: 3.07281
Value Function Loss: 0.00421

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.60080
Value Function Update Magnitude: 0.58287

Collected Steps per Second: 22,819.82193
Overall Steps per Second: 10,819.01637

Timestep Collection Time: 2.19134
Timestep Consumption Time: 2.43071
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62205

Cumulative Model Updates: 147,446
Cumulative Timesteps: 1,229,785,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1229785500...
Checkpoint 1229785500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,011.76813
Policy Entropy: 3.06556
Value Function Loss: 0.00387

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.58616
Value Function Update Magnitude: 0.55675

Collected Steps per Second: 22,601.24871
Overall Steps per Second: 10,706.86092

Timestep Collection Time: 2.21271
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.67084

Cumulative Model Updates: 147,452
Cumulative Timesteps: 1,229,835,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.39897
Policy Entropy: 3.07401
Value Function Loss: 0.00387

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.57639
Value Function Update Magnitude: 0.53924

Collected Steps per Second: 22,696.16318
Overall Steps per Second: 10,694.75548

Timestep Collection Time: 2.20416
Timestep Consumption Time: 2.47346
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.67762

Cumulative Model Updates: 147,458
Cumulative Timesteps: 1,229,885,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1229885536...
Checkpoint 1229885536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,327.23368
Policy Entropy: 3.08402
Value Function Loss: 0.00374

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.57290
Value Function Update Magnitude: 0.52782

Collected Steps per Second: 23,123.01841
Overall Steps per Second: 10,856.95303

Timestep Collection Time: 2.16313
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60700

Cumulative Model Updates: 147,464
Cumulative Timesteps: 1,229,935,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736.53539
Policy Entropy: 3.08695
Value Function Loss: 0.00395

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.57039
Value Function Update Magnitude: 0.50531

Collected Steps per Second: 23,340.08606
Overall Steps per Second: 10,893.09031

Timestep Collection Time: 2.14284
Timestep Consumption Time: 2.44851
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.59135

Cumulative Model Updates: 147,470
Cumulative Timesteps: 1,229,985,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1229985568...
Checkpoint 1229985568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.16714
Policy Entropy: 3.09329
Value Function Loss: 0.00416

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.56915
Value Function Update Magnitude: 0.48125

Collected Steps per Second: 23,141.64966
Overall Steps per Second: 10,786.65929

Timestep Collection Time: 2.16147
Timestep Consumption Time: 2.47574
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.63721

Cumulative Model Updates: 147,476
Cumulative Timesteps: 1,230,035,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,639.79972
Policy Entropy: 3.09057
Value Function Loss: 0.00407

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10261
Policy Update Magnitude: 0.56783
Value Function Update Magnitude: 0.48703

Collected Steps per Second: 22,705.01726
Overall Steps per Second: 10,801.31077

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.42720
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.62962

Cumulative Model Updates: 147,482
Cumulative Timesteps: 1,230,085,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1230085594...
Checkpoint 1230085594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,127.82934
Policy Entropy: 3.09992
Value Function Loss: 0.00391

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.56418
Value Function Update Magnitude: 0.49023

Collected Steps per Second: 22,356.83528
Overall Steps per Second: 10,738.16431

Timestep Collection Time: 2.23708
Timestep Consumption Time: 2.42051
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.65759

Cumulative Model Updates: 147,488
Cumulative Timesteps: 1,230,135,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,337.65713
Policy Entropy: 3.10020
Value Function Loss: 0.00380

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.56073
Value Function Update Magnitude: 0.49605

Collected Steps per Second: 22,609.53418
Overall Steps per Second: 10,787.27264

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.63528

Cumulative Model Updates: 147,494
Cumulative Timesteps: 1,230,185,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1230185610...
Checkpoint 1230185610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.31878
Policy Entropy: 3.10232
Value Function Loss: 0.00380

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.55299
Value Function Update Magnitude: 0.48122

Collected Steps per Second: 21,872.71644
Overall Steps per Second: 10,624.71678

Timestep Collection Time: 2.28687
Timestep Consumption Time: 2.42102
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.70789

Cumulative Model Updates: 147,500
Cumulative Timesteps: 1,230,235,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.99456
Policy Entropy: 3.09906
Value Function Loss: 0.00379

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.55148
Value Function Update Magnitude: 0.48169

Collected Steps per Second: 22,020.25250
Overall Steps per Second: 10,679.05952

Timestep Collection Time: 2.27136
Timestep Consumption Time: 2.41219
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.68356

Cumulative Model Updates: 147,506
Cumulative Timesteps: 1,230,285,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1230285646...
Checkpoint 1230285646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,728.98562
Policy Entropy: 3.09922
Value Function Loss: 0.00365

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.55735
Value Function Update Magnitude: 0.48614

Collected Steps per Second: 22,191.80505
Overall Steps per Second: 10,854.99235

Timestep Collection Time: 2.25362
Timestep Consumption Time: 2.35366
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60728

Cumulative Model Updates: 147,512
Cumulative Timesteps: 1,230,335,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.53895
Policy Entropy: 3.08843
Value Function Loss: 0.00403

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.56559
Value Function Update Magnitude: 0.51663

Collected Steps per Second: 22,146.94577
Overall Steps per Second: 10,708.19494

Timestep Collection Time: 2.25846
Timestep Consumption Time: 2.41254
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.67100

Cumulative Model Updates: 147,518
Cumulative Timesteps: 1,230,385,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1230385676...
Checkpoint 1230385676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,884.36772
Policy Entropy: 3.09657
Value Function Loss: 0.00423

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11507
Policy Update Magnitude: 0.58593
Value Function Update Magnitude: 0.54305

Collected Steps per Second: 22,229.66766
Overall Steps per Second: 10,860.25886

Timestep Collection Time: 2.25015
Timestep Consumption Time: 2.35564
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60578

Cumulative Model Updates: 147,524
Cumulative Timesteps: 1,230,435,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,926.12180
Policy Entropy: 3.09265
Value Function Loss: 0.00426

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.58723
Value Function Update Magnitude: 0.54851

Collected Steps per Second: 22,624.02195
Overall Steps per Second: 10,874.80564

Timestep Collection Time: 2.21066
Timestep Consumption Time: 2.38841
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.59907

Cumulative Model Updates: 147,530
Cumulative Timesteps: 1,230,485,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1230485710...
Checkpoint 1230485710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.78746
Policy Entropy: 3.08311
Value Function Loss: 0.00436

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.58333
Value Function Update Magnitude: 0.54031

Collected Steps per Second: 22,544.25147
Overall Steps per Second: 10,761.54144

Timestep Collection Time: 2.21795
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.64636

Cumulative Model Updates: 147,536
Cumulative Timesteps: 1,230,535,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.75241
Policy Entropy: 3.06317
Value Function Loss: 0.00442

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.58742
Value Function Update Magnitude: 0.53382

Collected Steps per Second: 22,759.97440
Overall Steps per Second: 10,833.43668

Timestep Collection Time: 2.19693
Timestep Consumption Time: 2.41860
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.61553

Cumulative Model Updates: 147,542
Cumulative Timesteps: 1,230,585,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1230585714...
Checkpoint 1230585714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.02473
Policy Entropy: 3.05989
Value Function Loss: 0.00481

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.59224
Value Function Update Magnitude: 0.54733

Collected Steps per Second: 22,958.67443
Overall Steps per Second: 10,741.34155

Timestep Collection Time: 2.17861
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.65659

Cumulative Model Updates: 147,548
Cumulative Timesteps: 1,230,635,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 790.61118
Policy Entropy: 3.07691
Value Function Loss: 0.00455

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.58525
Value Function Update Magnitude: 0.56104

Collected Steps per Second: 22,101.76163
Overall Steps per Second: 10,595.93387

Timestep Collection Time: 2.26235
Timestep Consumption Time: 2.45663
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.71898

Cumulative Model Updates: 147,554
Cumulative Timesteps: 1,230,685,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1230685734...
Checkpoint 1230685734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.11717
Policy Entropy: 3.07798
Value Function Loss: 0.00448

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.58043
Value Function Update Magnitude: 0.55864

Collected Steps per Second: 22,324.50058
Overall Steps per Second: 10,785.95099

Timestep Collection Time: 2.24086
Timestep Consumption Time: 2.39721
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63807

Cumulative Model Updates: 147,560
Cumulative Timesteps: 1,230,735,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,442.00506
Policy Entropy: 3.09038
Value Function Loss: 0.00409

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.54657

Collected Steps per Second: 22,584.20242
Overall Steps per Second: 10,666.83637

Timestep Collection Time: 2.21465
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.68893

Cumulative Model Updates: 147,566
Cumulative Timesteps: 1,230,785,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1230785776...
Checkpoint 1230785776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.55210
Policy Entropy: 3.09508
Value Function Loss: 0.00428

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.56696
Value Function Update Magnitude: 0.56142

Collected Steps per Second: 22,937.88539
Overall Steps per Second: 10,870.20250

Timestep Collection Time: 2.18076
Timestep Consumption Time: 2.42100
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60175

Cumulative Model Updates: 147,572
Cumulative Timesteps: 1,230,835,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.01858
Policy Entropy: 3.09714
Value Function Loss: 0.00419

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.56924
Value Function Update Magnitude: 0.56039

Collected Steps per Second: 22,810.58595
Overall Steps per Second: 10,714.10970

Timestep Collection Time: 2.19293
Timestep Consumption Time: 2.47587
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.66880

Cumulative Model Updates: 147,578
Cumulative Timesteps: 1,230,885,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1230885820...
Checkpoint 1230885820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154.26605
Policy Entropy: 3.09142
Value Function Loss: 0.00396

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.56936
Value Function Update Magnitude: 0.53331

Collected Steps per Second: 22,963.35315
Overall Steps per Second: 10,840.03276

Timestep Collection Time: 2.17843
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.61475

Cumulative Model Updates: 147,584
Cumulative Timesteps: 1,230,935,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.07221
Policy Entropy: 3.07482
Value Function Loss: 0.00395

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.51662

Collected Steps per Second: 23,189.04404
Overall Steps per Second: 10,928.41284

Timestep Collection Time: 2.15628
Timestep Consumption Time: 2.41914
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.57541

Cumulative Model Updates: 147,590
Cumulative Timesteps: 1,230,985,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1230985846...
Checkpoint 1230985846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,448.01283
Policy Entropy: 3.06547
Value Function Loss: 0.00401

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.57399
Value Function Update Magnitude: 0.51818

Collected Steps per Second: 23,072.59216
Overall Steps per Second: 10,674.58497

Timestep Collection Time: 2.16742
Timestep Consumption Time: 2.51735
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.68477

Cumulative Model Updates: 147,596
Cumulative Timesteps: 1,231,035,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,843.53079
Policy Entropy: 3.05359
Value Function Loss: 0.00443

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.58393
Value Function Update Magnitude: 0.52666

Collected Steps per Second: 23,066.42944
Overall Steps per Second: 10,867.14899

Timestep Collection Time: 2.16835
Timestep Consumption Time: 2.43415
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.60250

Cumulative Model Updates: 147,602
Cumulative Timesteps: 1,231,085,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1231085870...
Checkpoint 1231085870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.41828
Policy Entropy: 3.05249
Value Function Loss: 0.00454

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.58692
Value Function Update Magnitude: 0.54087

Collected Steps per Second: 22,580.87103
Overall Steps per Second: 10,774.83372

Timestep Collection Time: 2.21506
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.64211

Cumulative Model Updates: 147,608
Cumulative Timesteps: 1,231,135,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.12558
Policy Entropy: 3.04578
Value Function Loss: 0.00483

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.58536
Value Function Update Magnitude: 0.54057

Collected Steps per Second: 22,937.84187
Overall Steps per Second: 10,899.19088

Timestep Collection Time: 2.18007
Timestep Consumption Time: 2.40798
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.58805

Cumulative Model Updates: 147,614
Cumulative Timesteps: 1,231,185,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1231185894...
Checkpoint 1231185894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.93237
Policy Entropy: 3.06316
Value Function Loss: 0.00495

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.58561
Value Function Update Magnitude: 0.55197

Collected Steps per Second: 22,871.53524
Overall Steps per Second: 10,791.36528

Timestep Collection Time: 2.18735
Timestep Consumption Time: 2.44858
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.63593

Cumulative Model Updates: 147,620
Cumulative Timesteps: 1,231,235,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.28449
Policy Entropy: 3.06704
Value Function Loss: 0.00493

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.58311
Value Function Update Magnitude: 0.55883

Collected Steps per Second: 23,356.75019
Overall Steps per Second: 10,743.92864

Timestep Collection Time: 2.14079
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.65398

Cumulative Model Updates: 147,626
Cumulative Timesteps: 1,231,285,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1231285924...
Checkpoint 1231285924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.15923
Policy Entropy: 3.07643
Value Function Loss: 0.00433

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.57570
Value Function Update Magnitude: 0.55102

Collected Steps per Second: 23,192.45206
Overall Steps per Second: 10,760.37626

Timestep Collection Time: 2.15708
Timestep Consumption Time: 2.49220
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.64928

Cumulative Model Updates: 147,632
Cumulative Timesteps: 1,231,335,952

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,112.50757
Policy Entropy: 3.07015
Value Function Loss: 0.00415

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.57902
Value Function Update Magnitude: 0.55241

Collected Steps per Second: 23,287.21873
Overall Steps per Second: 10,740.90283

Timestep Collection Time: 2.14787
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.65678

Cumulative Model Updates: 147,638
Cumulative Timesteps: 1,231,385,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1231385970...
Checkpoint 1231385970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.03651
Policy Entropy: 3.08113
Value Function Loss: 0.00381

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.57549
Value Function Update Magnitude: 0.56135

Collected Steps per Second: 23,048.59925
Overall Steps per Second: 10,692.49459

Timestep Collection Time: 2.16942
Timestep Consumption Time: 2.50695
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.67636

Cumulative Model Updates: 147,644
Cumulative Timesteps: 1,231,435,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.31596
Policy Entropy: 3.08110
Value Function Loss: 0.00400

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.57794
Value Function Update Magnitude: 0.53941

Collected Steps per Second: 23,140.58000
Overall Steps per Second: 10,850.03348

Timestep Collection Time: 2.16122
Timestep Consumption Time: 2.44816
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60939

Cumulative Model Updates: 147,650
Cumulative Timesteps: 1,231,485,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1231485984...
Checkpoint 1231485984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,740.03795
Policy Entropy: 3.06554
Value Function Loss: 0.00399

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.58311
Value Function Update Magnitude: 0.51772

Collected Steps per Second: 22,783.30742
Overall Steps per Second: 10,710.47546

Timestep Collection Time: 2.19503
Timestep Consumption Time: 2.47423
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.66926

Cumulative Model Updates: 147,656
Cumulative Timesteps: 1,231,535,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,766.35357
Policy Entropy: 3.04854
Value Function Loss: 0.00414

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.58475
Value Function Update Magnitude: 0.50409

Collected Steps per Second: 23,035.46482
Overall Steps per Second: 10,914.75174

Timestep Collection Time: 2.17117
Timestep Consumption Time: 2.41107
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.58224

Cumulative Model Updates: 147,662
Cumulative Timesteps: 1,231,586,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1231586008...
Checkpoint 1231586008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.39648
Policy Entropy: 3.03918
Value Function Loss: 0.00420

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.58637
Value Function Update Magnitude: 0.50746

Collected Steps per Second: 22,479.16910
Overall Steps per Second: 10,619.42836

Timestep Collection Time: 2.22490
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.70967

Cumulative Model Updates: 147,668
Cumulative Timesteps: 1,231,636,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,267.01451
Policy Entropy: 3.04681
Value Function Loss: 0.00400

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.58623
Value Function Update Magnitude: 0.52186

Collected Steps per Second: 22,811.91664
Overall Steps per Second: 10,779.21871

Timestep Collection Time: 2.19306
Timestep Consumption Time: 2.44809
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.64115

Cumulative Model Updates: 147,674
Cumulative Timesteps: 1,231,686,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1231686050...
Checkpoint 1231686050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,065.09244
Policy Entropy: 3.04503
Value Function Loss: 0.00415

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.58936
Value Function Update Magnitude: 0.51443

Collected Steps per Second: 22,989.32894
Overall Steps per Second: 10,787.78506

Timestep Collection Time: 2.17544
Timestep Consumption Time: 2.46054
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.63598

Cumulative Model Updates: 147,680
Cumulative Timesteps: 1,231,736,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.71421
Policy Entropy: 3.04161
Value Function Loss: 0.00403

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.58611
Value Function Update Magnitude: 0.50313

Collected Steps per Second: 23,316.80584
Overall Steps per Second: 10,794.49680

Timestep Collection Time: 2.14558
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.63458

Cumulative Model Updates: 147,686
Cumulative Timesteps: 1,231,786,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1231786090...
Checkpoint 1231786090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,875.80216
Policy Entropy: 3.03541
Value Function Loss: 0.00402

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.57790
Value Function Update Magnitude: 0.49635

Collected Steps per Second: 23,194.17938
Overall Steps per Second: 10,747.81239

Timestep Collection Time: 2.15675
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.65434

Cumulative Model Updates: 147,692
Cumulative Timesteps: 1,231,836,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.38220
Policy Entropy: 3.03736
Value Function Loss: 0.00435

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.58662
Value Function Update Magnitude: 0.49443

Collected Steps per Second: 23,350.56950
Overall Steps per Second: 10,888.35488

Timestep Collection Time: 2.14145
Timestep Consumption Time: 2.45098
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.59243

Cumulative Model Updates: 147,698
Cumulative Timesteps: 1,231,886,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1231886118...
Checkpoint 1231886118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.76150
Policy Entropy: 3.03495
Value Function Loss: 0.00435

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.58349
Value Function Update Magnitude: 0.51619

Collected Steps per Second: 23,122.45080
Overall Steps per Second: 10,995.77712

Timestep Collection Time: 2.16318
Timestep Consumption Time: 2.38566
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.54884

Cumulative Model Updates: 147,704
Cumulative Timesteps: 1,231,936,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.86206
Policy Entropy: 3.04112
Value Function Loss: 0.00433

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.58463
Value Function Update Magnitude: 0.53879

Collected Steps per Second: 22,901.99232
Overall Steps per Second: 10,884.04989

Timestep Collection Time: 2.18330
Timestep Consumption Time: 2.41076
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.59406

Cumulative Model Updates: 147,710
Cumulative Timesteps: 1,231,986,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1231986138...
Checkpoint 1231986138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.04099
Policy Entropy: 3.03749
Value Function Loss: 0.00414

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.58236
Value Function Update Magnitude: 0.52848

Collected Steps per Second: 22,587.37556
Overall Steps per Second: 10,758.80282

Timestep Collection Time: 2.21398
Timestep Consumption Time: 2.43412
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.64810

Cumulative Model Updates: 147,716
Cumulative Timesteps: 1,232,036,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.21516
Policy Entropy: 3.05136
Value Function Loss: 0.00430

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.51546

Collected Steps per Second: 22,419.98309
Overall Steps per Second: 10,588.47265

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.49306
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.72419

Cumulative Model Updates: 147,722
Cumulative Timesteps: 1,232,086,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1232086168...
Checkpoint 1232086168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,371.26143
Policy Entropy: 3.03306
Value Function Loss: 0.00450

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.58462
Value Function Update Magnitude: 0.50007

Collected Steps per Second: 22,670.94342
Overall Steps per Second: 10,692.31202

Timestep Collection Time: 2.20582
Timestep Consumption Time: 2.47119
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.67701

Cumulative Model Updates: 147,728
Cumulative Timesteps: 1,232,136,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,039.18190
Policy Entropy: 3.03595
Value Function Loss: 0.00434

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.59083
Value Function Update Magnitude: 0.49977

Collected Steps per Second: 22,420.61926
Overall Steps per Second: 10,676.95242

Timestep Collection Time: 2.23125
Timestep Consumption Time: 2.45417
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.68542

Cumulative Model Updates: 147,734
Cumulative Timesteps: 1,232,186,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1232186202...
Checkpoint 1232186202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,356.36950
Policy Entropy: 3.02932
Value Function Loss: 0.00413

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10808
Policy Update Magnitude: 0.58790
Value Function Update Magnitude: 0.51373

Collected Steps per Second: 23,054.03567
Overall Steps per Second: 10,643.49095

Timestep Collection Time: 2.16969
Timestep Consumption Time: 2.52990
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.69959

Cumulative Model Updates: 147,740
Cumulative Timesteps: 1,232,236,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532.06803
Policy Entropy: 3.06018
Value Function Loss: 0.00380

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.58644
Value Function Update Magnitude: 0.50190

Collected Steps per Second: 23,144.65483
Overall Steps per Second: 10,951.27190

Timestep Collection Time: 2.16154
Timestep Consumption Time: 2.40670
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.56824

Cumulative Model Updates: 147,746
Cumulative Timesteps: 1,232,286,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1232286250...
Checkpoint 1232286250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.33546
Policy Entropy: 3.04589
Value Function Loss: 0.00408

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.58741
Value Function Update Magnitude: 0.50737

Collected Steps per Second: 23,231.42802
Overall Steps per Second: 10,745.12745

Timestep Collection Time: 2.15355
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.65606

Cumulative Model Updates: 147,752
Cumulative Timesteps: 1,232,336,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843.47155
Policy Entropy: 3.02597
Value Function Loss: 0.00452

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.60111
Value Function Update Magnitude: 0.54691

Collected Steps per Second: 22,969.47908
Overall Steps per Second: 10,761.35570

Timestep Collection Time: 2.17759
Timestep Consumption Time: 2.47034
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.64793

Cumulative Model Updates: 147,758
Cumulative Timesteps: 1,232,386,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1232386298...
Checkpoint 1232386298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.94600
Policy Entropy: 3.01834
Value Function Loss: 0.00471

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10942
Policy Update Magnitude: 0.61072
Value Function Update Magnitude: 0.57613

Collected Steps per Second: 23,139.38726
Overall Steps per Second: 10,710.50397

Timestep Collection Time: 2.16160
Timestep Consumption Time: 2.50840
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.67000

Cumulative Model Updates: 147,764
Cumulative Timesteps: 1,232,436,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.04151
Policy Entropy: 3.02054
Value Function Loss: 0.00475

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.60747
Value Function Update Magnitude: 0.58974

Collected Steps per Second: 23,164.15589
Overall Steps per Second: 10,857.60089

Timestep Collection Time: 2.15911
Timestep Consumption Time: 2.44725
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.60636

Cumulative Model Updates: 147,770
Cumulative Timesteps: 1,232,486,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1232486330...
Checkpoint 1232486330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.07917
Policy Entropy: 3.04069
Value Function Loss: 0.00463

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.59913
Value Function Update Magnitude: 0.60139

Collected Steps per Second: 23,115.69253
Overall Steps per Second: 10,751.94754

Timestep Collection Time: 2.16364
Timestep Consumption Time: 2.48798
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.65162

Cumulative Model Updates: 147,776
Cumulative Timesteps: 1,232,536,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.86909
Policy Entropy: 3.04467
Value Function Loss: 0.00459

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.58728
Value Function Update Magnitude: 0.57226

Collected Steps per Second: 22,845.31805
Overall Steps per Second: 10,750.16945

Timestep Collection Time: 2.18968
Timestep Consumption Time: 2.46364
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.65332

Cumulative Model Updates: 147,782
Cumulative Timesteps: 1,232,586,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1232586368...
Checkpoint 1232586368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.43559
Policy Entropy: 3.03953
Value Function Loss: 0.00447

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.58682
Value Function Update Magnitude: 0.54303

Collected Steps per Second: 22,365.23546
Overall Steps per Second: 10,683.09310

Timestep Collection Time: 2.23597
Timestep Consumption Time: 2.44507
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.68104

Cumulative Model Updates: 147,788
Cumulative Timesteps: 1,232,636,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,035.48837
Policy Entropy: 3.01774
Value Function Loss: 0.00454

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.59576
Value Function Update Magnitude: 0.53696

Collected Steps per Second: 22,940.66439
Overall Steps per Second: 10,830.93995

Timestep Collection Time: 2.18015
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.61770

Cumulative Model Updates: 147,794
Cumulative Timesteps: 1,232,686,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1232686390...
Checkpoint 1232686390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.07773
Policy Entropy: 3.00866
Value Function Loss: 0.00429

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.59548
Value Function Update Magnitude: 0.55596

Collected Steps per Second: 22,628.28017
Overall Steps per Second: 10,752.79732

Timestep Collection Time: 2.20962
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.64995

Cumulative Model Updates: 147,800
Cumulative Timesteps: 1,232,736,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.94421
Policy Entropy: 3.02345
Value Function Loss: 0.00417

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.59517
Value Function Update Magnitude: 0.55799

Collected Steps per Second: 23,176.64771
Overall Steps per Second: 10,897.50852

Timestep Collection Time: 2.15760
Timestep Consumption Time: 2.43115
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.58876

Cumulative Model Updates: 147,806
Cumulative Timesteps: 1,232,786,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1232786396...
Checkpoint 1232786396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.12326
Policy Entropy: 3.02435
Value Function Loss: 0.00447

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.59544
Value Function Update Magnitude: 0.55134

Collected Steps per Second: 23,020.64907
Overall Steps per Second: 10,818.71247

Timestep Collection Time: 2.17231
Timestep Consumption Time: 2.45005
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.62236

Cumulative Model Updates: 147,812
Cumulative Timesteps: 1,232,836,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.57274
Policy Entropy: 3.04464
Value Function Loss: 0.00429

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10077
Policy Update Magnitude: 0.59913
Value Function Update Magnitude: 0.53433

Collected Steps per Second: 23,225.44398
Overall Steps per Second: 10,802.20962

Timestep Collection Time: 2.15367
Timestep Consumption Time: 2.47686
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.63053

Cumulative Model Updates: 147,818
Cumulative Timesteps: 1,232,886,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1232886424...
Checkpoint 1232886424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,075.95478
Policy Entropy: 3.05041
Value Function Loss: 0.00456

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.59910
Value Function Update Magnitude: 0.51568

Collected Steps per Second: 23,177.10035
Overall Steps per Second: 11,000.10654

Timestep Collection Time: 2.15825
Timestep Consumption Time: 2.38916
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.54741

Cumulative Model Updates: 147,824
Cumulative Timesteps: 1,232,936,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,021.23890
Policy Entropy: 3.04553
Value Function Loss: 0.00449

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.59006
Value Function Update Magnitude: 0.51664

Collected Steps per Second: 23,170.72696
Overall Steps per Second: 10,832.67636

Timestep Collection Time: 2.15910
Timestep Consumption Time: 2.45915
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.61825

Cumulative Model Updates: 147,830
Cumulative Timesteps: 1,232,986,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1232986474...
Checkpoint 1232986474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,772.81468
Policy Entropy: 3.03319
Value Function Loss: 0.00452

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.59786
Value Function Update Magnitude: 0.52404

Collected Steps per Second: 22,900.54109
Overall Steps per Second: 10,741.28525

Timestep Collection Time: 2.18432
Timestep Consumption Time: 2.47267
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.65698

Cumulative Model Updates: 147,836
Cumulative Timesteps: 1,233,036,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.39498
Policy Entropy: 3.00893
Value Function Loss: 0.00447

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.60517
Value Function Update Magnitude: 0.54602

Collected Steps per Second: 23,020.84206
Overall Steps per Second: 10,916.09799

Timestep Collection Time: 2.17264
Timestep Consumption Time: 2.40922
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.58186

Cumulative Model Updates: 147,842
Cumulative Timesteps: 1,233,086,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1233086512...
Checkpoint 1233086512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831.61389
Policy Entropy: 3.01861
Value Function Loss: 0.00429

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.60476
Value Function Update Magnitude: 0.55677

Collected Steps per Second: 22,555.92450
Overall Steps per Second: 10,612.17052

Timestep Collection Time: 2.21787
Timestep Consumption Time: 2.49616
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.71402

Cumulative Model Updates: 147,848
Cumulative Timesteps: 1,233,136,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.55240
Policy Entropy: 3.01177
Value Function Loss: 0.00424

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.59128
Value Function Update Magnitude: 0.55119

Collected Steps per Second: 22,830.21241
Overall Steps per Second: 10,866.47565

Timestep Collection Time: 2.19096
Timestep Consumption Time: 2.41219
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.60315

Cumulative Model Updates: 147,854
Cumulative Timesteps: 1,233,186,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1233186558...
Checkpoint 1233186558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.95986
Policy Entropy: 3.01162
Value Function Loss: 0.00425

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11767
Policy Update Magnitude: 0.58649
Value Function Update Magnitude: 0.53192

Collected Steps per Second: 22,801.48510
Overall Steps per Second: 10,717.74207

Timestep Collection Time: 2.19398
Timestep Consumption Time: 2.47361
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.66759

Cumulative Model Updates: 147,860
Cumulative Timesteps: 1,233,236,584

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.87402
Policy Entropy: 2.99830
Value Function Loss: 0.00445

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.59947
Value Function Update Magnitude: 0.53568

Collected Steps per Second: 23,267.53257
Overall Steps per Second: 10,897.58471

Timestep Collection Time: 2.14943
Timestep Consumption Time: 2.43984
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.58927

Cumulative Model Updates: 147,866
Cumulative Timesteps: 1,233,286,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1233286596...
Checkpoint 1233286596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.89628
Policy Entropy: 3.00323
Value Function Loss: 0.00444

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.59598
Value Function Update Magnitude: 0.54437

Collected Steps per Second: 23,241.03699
Overall Steps per Second: 10,770.86580

Timestep Collection Time: 2.15231
Timestep Consumption Time: 2.49188
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.64419

Cumulative Model Updates: 147,872
Cumulative Timesteps: 1,233,336,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.37211
Policy Entropy: 2.99822
Value Function Loss: 0.00472

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.61031
Value Function Update Magnitude: 0.54308

Collected Steps per Second: 23,168.57618
Overall Steps per Second: 10,795.44230

Timestep Collection Time: 2.15810
Timestep Consumption Time: 2.47349
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.63158

Cumulative Model Updates: 147,878
Cumulative Timesteps: 1,233,386,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1233386618...
Checkpoint 1233386618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.86170
Policy Entropy: 3.00909
Value Function Loss: 0.00463

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.60970
Value Function Update Magnitude: 0.55390

Collected Steps per Second: 22,922.79580
Overall Steps per Second: 10,612.95480

Timestep Collection Time: 2.18176
Timestep Consumption Time: 2.53060
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.71235

Cumulative Model Updates: 147,884
Cumulative Timesteps: 1,233,436,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.87629
Policy Entropy: 3.00940
Value Function Loss: 0.00497

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.61415
Value Function Update Magnitude: 0.56653

Collected Steps per Second: 23,093.11083
Overall Steps per Second: 10,861.80633

Timestep Collection Time: 2.16541
Timestep Consumption Time: 2.43843
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.60384

Cumulative Model Updates: 147,890
Cumulative Timesteps: 1,233,486,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1233486636...
Checkpoint 1233486636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,797.72392
Policy Entropy: 3.00166
Value Function Loss: 0.00478

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.61859
Value Function Update Magnitude: 0.57068

Collected Steps per Second: 22,985.26363
Overall Steps per Second: 10,763.10876

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.47029
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.64568

Cumulative Model Updates: 147,896
Cumulative Timesteps: 1,233,536,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,480.05187
Policy Entropy: 2.99485
Value Function Loss: 0.00460

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.61662
Value Function Update Magnitude: 0.56984

Collected Steps per Second: 22,908.93043
Overall Steps per Second: 10,822.95686

Timestep Collection Time: 2.18369
Timestep Consumption Time: 2.43852
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.62221

Cumulative Model Updates: 147,902
Cumulative Timesteps: 1,233,586,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1233586664...
Checkpoint 1233586664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.63305
Policy Entropy: 2.99279
Value Function Loss: 0.00432

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10839
Policy Update Magnitude: 0.61053
Value Function Update Magnitude: 0.53760

Collected Steps per Second: 22,861.49325
Overall Steps per Second: 10,722.18140

Timestep Collection Time: 2.18831
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.66584

Cumulative Model Updates: 147,908
Cumulative Timesteps: 1,233,636,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,973.00320
Policy Entropy: 3.01000
Value Function Loss: 0.00438

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.60274
Value Function Update Magnitude: 0.52608

Collected Steps per Second: 22,939.23643
Overall Steps per Second: 10,925.08775

Timestep Collection Time: 2.18037
Timestep Consumption Time: 2.39772
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.57809

Cumulative Model Updates: 147,914
Cumulative Timesteps: 1,233,686,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1233686708...
Checkpoint 1233686708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.37202
Policy Entropy: 3.01473
Value Function Loss: 0.00409

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.59469
Value Function Update Magnitude: 0.51617

Collected Steps per Second: 22,901.88699
Overall Steps per Second: 10,665.38151

Timestep Collection Time: 2.18349
Timestep Consumption Time: 2.50514
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.68863

Cumulative Model Updates: 147,920
Cumulative Timesteps: 1,233,736,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.81013
Policy Entropy: 3.02087
Value Function Loss: 0.00424

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.58556
Value Function Update Magnitude: 0.50920

Collected Steps per Second: 23,304.31191
Overall Steps per Second: 10,874.75167

Timestep Collection Time: 2.14595
Timestep Consumption Time: 2.45277
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.59873

Cumulative Model Updates: 147,926
Cumulative Timesteps: 1,233,786,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1233786724...
Checkpoint 1233786724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,977.39345
Policy Entropy: 3.00653
Value Function Loss: 0.00439

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.58987
Value Function Update Magnitude: 0.50576

Collected Steps per Second: 23,182.28964
Overall Steps per Second: 10,777.23981

Timestep Collection Time: 2.15803
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.64200

Cumulative Model Updates: 147,932
Cumulative Timesteps: 1,233,836,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.38337
Policy Entropy: 3.01606
Value Function Loss: 0.00465

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.59296
Value Function Update Magnitude: 0.51025

Collected Steps per Second: 23,561.87631
Overall Steps per Second: 10,919.79000

Timestep Collection Time: 2.12250
Timestep Consumption Time: 2.45726
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.57976

Cumulative Model Updates: 147,938
Cumulative Timesteps: 1,233,886,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1233886762...
Checkpoint 1233886762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.10277
Policy Entropy: 3.02618
Value Function Loss: 0.00433

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.59189
Value Function Update Magnitude: 0.52358

Collected Steps per Second: 23,462.41053
Overall Steps per Second: 10,891.15324

Timestep Collection Time: 2.13141
Timestep Consumption Time: 2.46021
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.59162

Cumulative Model Updates: 147,944
Cumulative Timesteps: 1,233,936,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.36218
Policy Entropy: 3.02988
Value Function Loss: 0.00444

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.59099
Value Function Update Magnitude: 0.52788

Collected Steps per Second: 23,028.04206
Overall Steps per Second: 10,840.21622

Timestep Collection Time: 2.17231
Timestep Consumption Time: 2.44236
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.61467

Cumulative Model Updates: 147,950
Cumulative Timesteps: 1,233,986,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1233986794...
Checkpoint 1233986794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,175.35875
Policy Entropy: 3.03587
Value Function Loss: 0.00441

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.60576
Value Function Update Magnitude: 0.54975

Collected Steps per Second: 23,010.47417
Overall Steps per Second: 10,685.18241

Timestep Collection Time: 2.17397
Timestep Consumption Time: 2.50766
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68162

Cumulative Model Updates: 147,956
Cumulative Timesteps: 1,234,036,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.38494
Policy Entropy: 3.04835
Value Function Loss: 0.00431

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.60898
Value Function Update Magnitude: 0.56862

Collected Steps per Second: 22,828.03708
Overall Steps per Second: 10,708.24897

Timestep Collection Time: 2.19055
Timestep Consumption Time: 2.47931
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.66986

Cumulative Model Updates: 147,962
Cumulative Timesteps: 1,234,086,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1234086824...
Checkpoint 1234086824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.30632
Policy Entropy: 3.04871
Value Function Loss: 0.00436

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.59612
Value Function Update Magnitude: 0.54225

Collected Steps per Second: 22,506.19215
Overall Steps per Second: 10,830.85860

Timestep Collection Time: 2.22241
Timestep Consumption Time: 2.39569
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61810

Cumulative Model Updates: 147,968
Cumulative Timesteps: 1,234,136,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.13231
Policy Entropy: 3.02902
Value Function Loss: 0.00447

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.59343
Value Function Update Magnitude: 0.52973

Collected Steps per Second: 22,667.47449
Overall Steps per Second: 10,689.68451

Timestep Collection Time: 2.20624
Timestep Consumption Time: 2.47210
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.67834

Cumulative Model Updates: 147,974
Cumulative Timesteps: 1,234,186,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1234186852...
Checkpoint 1234186852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.31592
Policy Entropy: 3.02083
Value Function Loss: 0.00449

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.59586
Value Function Update Magnitude: 0.52782

Collected Steps per Second: 23,033.86378
Overall Steps per Second: 10,878.13356

Timestep Collection Time: 2.17098
Timestep Consumption Time: 2.42595
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.59693

Cumulative Model Updates: 147,980
Cumulative Timesteps: 1,234,236,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,774.55936
Policy Entropy: 3.04524
Value Function Loss: 0.00453

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.59984
Value Function Update Magnitude: 0.51851

Collected Steps per Second: 23,278.57814
Overall Steps per Second: 10,779.37692

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.49179
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.64071

Cumulative Model Updates: 147,986
Cumulative Timesteps: 1,234,286,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1234286882...
Checkpoint 1234286882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,893.98696
Policy Entropy: 3.07214
Value Function Loss: 0.00445

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.58804
Value Function Update Magnitude: 0.51510

Collected Steps per Second: 23,063.73221
Overall Steps per Second: 10,745.74956

Timestep Collection Time: 2.16817
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.65356

Cumulative Model Updates: 147,992
Cumulative Timesteps: 1,234,336,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,235.76691
Policy Entropy: 3.06569
Value Function Loss: 0.00464

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.57998
Value Function Update Magnitude: 0.52365

Collected Steps per Second: 23,139.36980
Overall Steps per Second: 10,908.65021

Timestep Collection Time: 2.16125
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.58444

Cumulative Model Updates: 147,998
Cumulative Timesteps: 1,234,386,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1234386898...
Checkpoint 1234386898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,456.16824
Policy Entropy: 3.06354
Value Function Loss: 0.00440

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.57477
Value Function Update Magnitude: 0.50920

Collected Steps per Second: 23,417.63382
Overall Steps per Second: 10,762.14854

Timestep Collection Time: 2.13617
Timestep Consumption Time: 2.51197
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.64814

Cumulative Model Updates: 148,004
Cumulative Timesteps: 1,234,436,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,810.82478
Policy Entropy: 3.05043
Value Function Loss: 0.00449

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.57498
Value Function Update Magnitude: 0.51699

Collected Steps per Second: 23,374.12424
Overall Steps per Second: 10,806.23829

Timestep Collection Time: 2.13955
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.62788

Cumulative Model Updates: 148,010
Cumulative Timesteps: 1,234,486,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1234486932...
Checkpoint 1234486932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.52736
Policy Entropy: 3.06278
Value Function Loss: 0.00472

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.59449
Value Function Update Magnitude: 0.54569

Collected Steps per Second: 21,935.51742
Overall Steps per Second: 10,601.85757

Timestep Collection Time: 2.28087
Timestep Consumption Time: 2.43831
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.71917

Cumulative Model Updates: 148,016
Cumulative Timesteps: 1,234,536,964

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.21838
Policy Entropy: 3.06826
Value Function Loss: 0.00466

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12512
Policy Update Magnitude: 0.59453
Value Function Update Magnitude: 0.56625

Collected Steps per Second: 22,535.36003
Overall Steps per Second: 10,551.00643

Timestep Collection Time: 2.21918
Timestep Consumption Time: 2.52065
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.73983

Cumulative Model Updates: 148,022
Cumulative Timesteps: 1,234,586,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1234586974...
Checkpoint 1234586974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,059.74850
Policy Entropy: 3.07275
Value Function Loss: 0.00443

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.56590

Collected Steps per Second: 22,712.80962
Overall Steps per Second: 10,610.40418

Timestep Collection Time: 2.20184
Timestep Consumption Time: 2.51146
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.71330

Cumulative Model Updates: 148,028
Cumulative Timesteps: 1,234,636,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.29747
Policy Entropy: 3.07013
Value Function Loss: 0.00393

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.57501
Value Function Update Magnitude: 0.55600

Collected Steps per Second: 22,693.85537
Overall Steps per Second: 10,781.83246

Timestep Collection Time: 2.20394
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.63891

Cumulative Model Updates: 148,034
Cumulative Timesteps: 1,234,687,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1234687000...
Checkpoint 1234687000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,248.62821
Policy Entropy: 3.07321
Value Function Loss: 0.00378

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.55026

Collected Steps per Second: 22,534.75889
Overall Steps per Second: 10,755.65822

Timestep Collection Time: 2.21924
Timestep Consumption Time: 2.43041
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.64965

Cumulative Model Updates: 148,040
Cumulative Timesteps: 1,234,737,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,981.25796
Policy Entropy: 3.07796
Value Function Loss: 0.00410

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.56162
Value Function Update Magnitude: 0.53067

Collected Steps per Second: 22,924.11445
Overall Steps per Second: 10,643.38306

Timestep Collection Time: 2.18163
Timestep Consumption Time: 2.51725
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.69888

Cumulative Model Updates: 148,046
Cumulative Timesteps: 1,234,787,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1234787022...
Checkpoint 1234787022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,822.92466
Policy Entropy: 3.08361
Value Function Loss: 0.00404

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.51884

Collected Steps per Second: 23,129.77577
Overall Steps per Second: 10,838.88266

Timestep Collection Time: 2.16206
Timestep Consumption Time: 2.45170
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61376

Cumulative Model Updates: 148,052
Cumulative Timesteps: 1,234,837,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,486.84431
Policy Entropy: 3.08330
Value Function Loss: 0.00372

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11257
Policy Update Magnitude: 0.55675
Value Function Update Magnitude: 0.51867

Collected Steps per Second: 23,295.29931
Overall Steps per Second: 10,904.31397

Timestep Collection Time: 2.14704
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.58681

Cumulative Model Updates: 148,058
Cumulative Timesteps: 1,234,887,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1234887046...
Checkpoint 1234887046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.98076
Policy Entropy: 3.08566
Value Function Loss: 0.00364

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.48988

Collected Steps per Second: 23,217.50562
Overall Steps per Second: 10,746.18032

Timestep Collection Time: 2.15406
Timestep Consumption Time: 2.49987
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.65393

Cumulative Model Updates: 148,064
Cumulative Timesteps: 1,234,937,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,059.81309
Policy Entropy: 3.07742
Value Function Loss: 0.00383

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.48171

Collected Steps per Second: 23,241.66865
Overall Steps per Second: 10,857.51818

Timestep Collection Time: 2.15208
Timestep Consumption Time: 2.45468
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.60676

Cumulative Model Updates: 148,070
Cumulative Timesteps: 1,234,987,076

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1234987076...
Checkpoint 1234987076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,802.75951
Policy Entropy: 3.07264
Value Function Loss: 0.00427

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.57328
Value Function Update Magnitude: 0.50072

Collected Steps per Second: 23,389.74976
Overall Steps per Second: 10,847.31389

Timestep Collection Time: 2.13837
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.61091

Cumulative Model Updates: 148,076
Cumulative Timesteps: 1,235,037,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.57366
Policy Entropy: 3.07202
Value Function Loss: 0.00434

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.58805
Value Function Update Magnitude: 0.53940

Collected Steps per Second: 22,589.69221
Overall Steps per Second: 10,710.48601

Timestep Collection Time: 2.21437
Timestep Consumption Time: 2.45600
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.67038

Cumulative Model Updates: 148,082
Cumulative Timesteps: 1,235,087,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1235087114...
Checkpoint 1235087114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,677.27219
Policy Entropy: 3.07264
Value Function Loss: 0.00426

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.59670
Value Function Update Magnitude: 0.56202

Collected Steps per Second: 22,679.32040
Overall Steps per Second: 10,589.36868

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.51707
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.72172

Cumulative Model Updates: 148,088
Cumulative Timesteps: 1,235,137,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,861.97226
Policy Entropy: 3.07668
Value Function Loss: 0.00426

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.58843
Value Function Update Magnitude: 0.55308

Collected Steps per Second: 22,443.70569
Overall Steps per Second: 10,543.39587

Timestep Collection Time: 2.22780
Timestep Consumption Time: 2.51451
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.74231

Cumulative Model Updates: 148,094
Cumulative Timesteps: 1,235,187,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1235187114...
Checkpoint 1235187114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.61728
Policy Entropy: 3.09234
Value Function Loss: 0.00425

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.57528
Value Function Update Magnitude: 0.53764

Collected Steps per Second: 22,727.54328
Overall Steps per Second: 10,613.07774

Timestep Collection Time: 2.20085
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.71305

Cumulative Model Updates: 148,100
Cumulative Timesteps: 1,235,237,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.42160
Policy Entropy: 3.10608
Value Function Loss: 0.00398

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.50870

Collected Steps per Second: 23,011.97810
Overall Steps per Second: 10,784.25486

Timestep Collection Time: 2.17365
Timestep Consumption Time: 2.46459
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.63824

Cumulative Model Updates: 148,106
Cumulative Timesteps: 1,235,287,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1235287154...
Checkpoint 1235287154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.77790
Policy Entropy: 3.09685
Value Function Loss: 0.00397

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.48625

Collected Steps per Second: 23,108.37491
Overall Steps per Second: 10,700.50089

Timestep Collection Time: 2.16424
Timestep Consumption Time: 2.50956
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.67380

Cumulative Model Updates: 148,112
Cumulative Timesteps: 1,235,337,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,990.83847
Policy Entropy: 3.08578
Value Function Loss: 0.00405

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.50961

Collected Steps per Second: 23,122.35162
Overall Steps per Second: 10,953.87949

Timestep Collection Time: 2.16267
Timestep Consumption Time: 2.40247
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.56514

Cumulative Model Updates: 148,118
Cumulative Timesteps: 1,235,387,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1235387172...
Checkpoint 1235387172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.88082
Policy Entropy: 3.08343
Value Function Loss: 0.00390

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.53023

Collected Steps per Second: 23,113.05936
Overall Steps per Second: 10,968.86718

Timestep Collection Time: 2.16363
Timestep Consumption Time: 2.39546
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.55909

Cumulative Model Updates: 148,124
Cumulative Timesteps: 1,235,437,180

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.65589
Policy Entropy: 3.08050
Value Function Loss: 0.00383

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.52800

Collected Steps per Second: 23,106.72090
Overall Steps per Second: 10,744.70584

Timestep Collection Time: 2.16405
Timestep Consumption Time: 2.48978
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.65383

Cumulative Model Updates: 148,130
Cumulative Timesteps: 1,235,487,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1235487184...
Checkpoint 1235487184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,990.41431
Policy Entropy: 3.08192
Value Function Loss: 0.00411

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.57647
Value Function Update Magnitude: 0.52998

Collected Steps per Second: 23,223.36195
Overall Steps per Second: 10,932.85202

Timestep Collection Time: 2.15309
Timestep Consumption Time: 2.42046
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.57355

Cumulative Model Updates: 148,136
Cumulative Timesteps: 1,235,537,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.42731
Policy Entropy: 3.08854
Value Function Loss: 0.00435

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.57436
Value Function Update Magnitude: 0.53842

Collected Steps per Second: 22,942.90466
Overall Steps per Second: 10,926.60222

Timestep Collection Time: 2.17967
Timestep Consumption Time: 2.39705
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.57672

Cumulative Model Updates: 148,142
Cumulative Timesteps: 1,235,587,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1235587194...
Checkpoint 1235587194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956.88592
Policy Entropy: 3.10192
Value Function Loss: 0.00431

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.57529
Value Function Update Magnitude: 0.54330

Collected Steps per Second: 22,820.06184
Overall Steps per Second: 10,654.13156

Timestep Collection Time: 2.19202
Timestep Consumption Time: 2.50306
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69508

Cumulative Model Updates: 148,148
Cumulative Timesteps: 1,235,637,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,634.15236
Policy Entropy: 3.09528
Value Function Loss: 0.00389

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.50055

Collected Steps per Second: 22,842.45053
Overall Steps per Second: 10,814.57744

Timestep Collection Time: 2.18952
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.62468

Cumulative Model Updates: 148,154
Cumulative Timesteps: 1,235,687,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1235687230...
Checkpoint 1235687230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,855.75419
Policy Entropy: 3.08257
Value Function Loss: 0.00383

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.55966
Value Function Update Magnitude: 0.45567

Collected Steps per Second: 22,694.61504
Overall Steps per Second: 10,694.00578

Timestep Collection Time: 2.20378
Timestep Consumption Time: 2.47304
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.67683

Cumulative Model Updates: 148,160
Cumulative Timesteps: 1,235,737,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.80571
Policy Entropy: 3.06484
Value Function Loss: 0.00383

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.56836
Value Function Update Magnitude: 0.45230

Collected Steps per Second: 22,975.33005
Overall Steps per Second: 10,772.47903

Timestep Collection Time: 2.17660
Timestep Consumption Time: 2.46560
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.64220

Cumulative Model Updates: 148,166
Cumulative Timesteps: 1,235,787,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1235787252...
Checkpoint 1235787252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078.29326
Policy Entropy: 3.07625
Value Function Loss: 0.00393

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.57152
Value Function Update Magnitude: 0.47162

Collected Steps per Second: 23,294.88896
Overall Steps per Second: 10,757.38960

Timestep Collection Time: 2.14751
Timestep Consumption Time: 2.50288
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.65038

Cumulative Model Updates: 148,172
Cumulative Timesteps: 1,235,837,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.15924
Policy Entropy: 3.07861
Value Function Loss: 0.00402

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.56543
Value Function Update Magnitude: 0.46768

Collected Steps per Second: 23,206.88347
Overall Steps per Second: 10,917.18613

Timestep Collection Time: 2.15574
Timestep Consumption Time: 2.42676
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.58250

Cumulative Model Updates: 148,178
Cumulative Timesteps: 1,235,887,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1235887306...
Checkpoint 1235887306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,038.04233
Policy Entropy: 3.09388
Value Function Loss: 0.00408

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.56189
Value Function Update Magnitude: 0.47098

Collected Steps per Second: 23,301.86722
Overall Steps per Second: 10,800.77859

Timestep Collection Time: 2.14635
Timestep Consumption Time: 2.48424
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.63059

Cumulative Model Updates: 148,184
Cumulative Timesteps: 1,235,937,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.31299
Policy Entropy: 3.08498
Value Function Loss: 0.00420

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.55823
Value Function Update Magnitude: 0.47310

Collected Steps per Second: 23,092.13395
Overall Steps per Second: 10,707.45577

Timestep Collection Time: 2.16637
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.67207

Cumulative Model Updates: 148,190
Cumulative Timesteps: 1,235,987,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1235987346...
Checkpoint 1235987346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,909.30431
Policy Entropy: 3.08076
Value Function Loss: 0.00412

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.55844
Value Function Update Magnitude: 0.47899

Collected Steps per Second: 23,059.69011
Overall Steps per Second: 10,688.03944

Timestep Collection Time: 2.16950
Timestep Consumption Time: 2.51125
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.68075

Cumulative Model Updates: 148,196
Cumulative Timesteps: 1,236,037,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.87149
Policy Entropy: 3.05771
Value Function Loss: 0.00426

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.57217
Value Function Update Magnitude: 0.49261

Collected Steps per Second: 23,102.20780
Overall Steps per Second: 10,863.99161

Timestep Collection Time: 2.16525
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.60439

Cumulative Model Updates: 148,202
Cumulative Timesteps: 1,236,087,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1236087396...
Checkpoint 1236087396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,347.35612
Policy Entropy: 3.05525
Value Function Loss: 0.00437

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.58712
Value Function Update Magnitude: 0.54100

Collected Steps per Second: 22,610.94370
Overall Steps per Second: 10,682.67875

Timestep Collection Time: 2.21185
Timestep Consumption Time: 2.46975
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.68160

Cumulative Model Updates: 148,208
Cumulative Timesteps: 1,236,137,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.48284
Policy Entropy: 3.06118
Value Function Loss: 0.00452

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.58982
Value Function Update Magnitude: 0.56566

Collected Steps per Second: 22,796.55758
Overall Steps per Second: 10,792.64774

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.44064
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.63501

Cumulative Model Updates: 148,214
Cumulative Timesteps: 1,236,187,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1236187432...
Checkpoint 1236187432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.14834
Policy Entropy: 3.05038
Value Function Loss: 0.00458

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.59308
Value Function Update Magnitude: 0.57072

Collected Steps per Second: 22,774.76395
Overall Steps per Second: 10,754.65629

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.45531
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.65212

Cumulative Model Updates: 148,220
Cumulative Timesteps: 1,236,237,464

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.68796
Policy Entropy: 3.04231
Value Function Loss: 0.00485

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.60515
Value Function Update Magnitude: 0.58381

Collected Steps per Second: 23,158.45869
Overall Steps per Second: 10,799.40307

Timestep Collection Time: 2.15956
Timestep Consumption Time: 2.47144
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.63100

Cumulative Model Updates: 148,226
Cumulative Timesteps: 1,236,287,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1236287476...
Checkpoint 1236287476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,223.37993
Policy Entropy: 3.04900
Value Function Loss: 0.00460

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.60705
Value Function Update Magnitude: 0.57913

Collected Steps per Second: 23,186.80183
Overall Steps per Second: 10,704.14282

Timestep Collection Time: 2.15769
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.67389

Cumulative Model Updates: 148,232
Cumulative Timesteps: 1,236,337,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,727.35500
Policy Entropy: 3.04967
Value Function Loss: 0.00460

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.59943
Value Function Update Magnitude: 0.55917

Collected Steps per Second: 22,925.53076
Overall Steps per Second: 10,870.46434

Timestep Collection Time: 2.18167
Timestep Consumption Time: 2.41942
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60109

Cumulative Model Updates: 148,238
Cumulative Timesteps: 1,236,387,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1236387522...
Checkpoint 1236387522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.31319
Policy Entropy: 3.04705
Value Function Loss: 0.00431

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.59201
Value Function Update Magnitude: 0.54500

Collected Steps per Second: 23,011.55010
Overall Steps per Second: 10,700.46828

Timestep Collection Time: 2.17282
Timestep Consumption Time: 2.49987
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.67269

Cumulative Model Updates: 148,244
Cumulative Timesteps: 1,236,437,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.09784
Policy Entropy: 3.02652
Value Function Loss: 0.00463

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13024
Policy Update Magnitude: 0.60330
Value Function Update Magnitude: 0.56548

Collected Steps per Second: 21,993.37394
Overall Steps per Second: 10,516.56586

Timestep Collection Time: 2.27469
Timestep Consumption Time: 2.48238
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.75707

Cumulative Model Updates: 148,250
Cumulative Timesteps: 1,236,487,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1236487550...
Checkpoint 1236487550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.88722
Policy Entropy: 3.02678
Value Function Loss: 0.00454

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.60881
Value Function Update Magnitude: 0.58694

Collected Steps per Second: 22,835.58865
Overall Steps per Second: 10,799.47564

Timestep Collection Time: 2.18983
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.63041

Cumulative Model Updates: 148,256
Cumulative Timesteps: 1,236,537,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,460.14842
Policy Entropy: 3.02201
Value Function Loss: 0.00467

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.60833
Value Function Update Magnitude: 0.58071

Collected Steps per Second: 22,705.64067
Overall Steps per Second: 10,684.00508

Timestep Collection Time: 2.20306
Timestep Consumption Time: 2.47889
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.68195

Cumulative Model Updates: 148,262
Cumulative Timesteps: 1,236,587,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1236587578...
Checkpoint 1236587578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.18539
Policy Entropy: 3.02464
Value Function Loss: 0.00468

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.61765
Value Function Update Magnitude: 0.56599

Collected Steps per Second: 23,078.62531
Overall Steps per Second: 10,677.62098

Timestep Collection Time: 2.16729
Timestep Consumption Time: 2.51709
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.68438

Cumulative Model Updates: 148,268
Cumulative Timesteps: 1,236,637,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.87306
Policy Entropy: 3.02542
Value Function Loss: 0.00459

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.61417
Value Function Update Magnitude: 0.58063

Collected Steps per Second: 23,277.39570
Overall Steps per Second: 10,855.61605

Timestep Collection Time: 2.14878
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.60757

Cumulative Model Updates: 148,274
Cumulative Timesteps: 1,236,687,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1236687614...
Checkpoint 1236687614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.41587
Policy Entropy: 3.01726
Value Function Loss: 0.00482

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.62610
Value Function Update Magnitude: 0.58608

Collected Steps per Second: 23,013.77919
Overall Steps per Second: 10,696.83145

Timestep Collection Time: 2.17374
Timestep Consumption Time: 2.50297
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.67671

Cumulative Model Updates: 148,280
Cumulative Timesteps: 1,236,737,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.74852
Policy Entropy: 3.00886
Value Function Loss: 0.00461

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.62729
Value Function Update Magnitude: 0.58333

Collected Steps per Second: 23,096.30084
Overall Steps per Second: 10,874.76542

Timestep Collection Time: 2.16537
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.59890

Cumulative Model Updates: 148,286
Cumulative Timesteps: 1,236,787,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1236787652...
Checkpoint 1236787652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,535.23832
Policy Entropy: 3.00987
Value Function Loss: 0.00446

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11128
Policy Update Magnitude: 0.62973
Value Function Update Magnitude: 0.55420

Collected Steps per Second: 22,960.01278
Overall Steps per Second: 10,616.25992

Timestep Collection Time: 2.17840
Timestep Consumption Time: 2.53287
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.71126

Cumulative Model Updates: 148,292
Cumulative Timesteps: 1,236,837,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.39087
Policy Entropy: 3.02708
Value Function Loss: 0.00423

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10708
Policy Update Magnitude: 0.61824
Value Function Update Magnitude: 0.55162

Collected Steps per Second: 23,051.19370
Overall Steps per Second: 10,872.84680

Timestep Collection Time: 2.16995
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60045

Cumulative Model Updates: 148,298
Cumulative Timesteps: 1,236,887,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1236887688...
Checkpoint 1236887688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.49875
Policy Entropy: 3.03020
Value Function Loss: 0.00438

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.11768
Policy Update Magnitude: 0.61179
Value Function Update Magnitude: 0.54785

Collected Steps per Second: 22,982.26360
Overall Steps per Second: 10,758.63887

Timestep Collection Time: 2.17690
Timestep Consumption Time: 2.47332
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.65022

Cumulative Model Updates: 148,304
Cumulative Timesteps: 1,236,937,718

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,883.46962
Policy Entropy: 3.04983
Value Function Loss: 0.00442

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.60934
Value Function Update Magnitude: 0.54558

Collected Steps per Second: 22,798.13268
Overall Steps per Second: 10,850.39564

Timestep Collection Time: 2.19457
Timestep Consumption Time: 2.41651
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.61108

Cumulative Model Updates: 148,310
Cumulative Timesteps: 1,236,987,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1236987750...
Checkpoint 1236987750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.46070
Policy Entropy: 3.05417
Value Function Loss: 0.00428

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.60473
Value Function Update Magnitude: 0.53609

Collected Steps per Second: 22,512.02492
Overall Steps per Second: 10,647.75315

Timestep Collection Time: 2.22166
Timestep Consumption Time: 2.47548
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.69714

Cumulative Model Updates: 148,316
Cumulative Timesteps: 1,237,037,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,399.79007
Policy Entropy: 3.07051
Value Function Loss: 0.00424

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.59785
Value Function Update Magnitude: 0.53430

Collected Steps per Second: 23,023.90711
Overall Steps per Second: 10,910.96004

Timestep Collection Time: 2.17278
Timestep Consumption Time: 2.41215
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.58493

Cumulative Model Updates: 148,322
Cumulative Timesteps: 1,237,087,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1237087790...
Checkpoint 1237087790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159.58082
Policy Entropy: 3.06818
Value Function Loss: 0.00417

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.58477
Value Function Update Magnitude: 0.53541

Collected Steps per Second: 22,623.98089
Overall Steps per Second: 10,664.51056

Timestep Collection Time: 2.21004
Timestep Consumption Time: 2.47840
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.68845

Cumulative Model Updates: 148,328
Cumulative Timesteps: 1,237,137,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.77567
Policy Entropy: 3.06019
Value Function Loss: 0.00452

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.60017
Value Function Update Magnitude: 0.55027

Collected Steps per Second: 23,239.00076
Overall Steps per Second: 10,924.71040

Timestep Collection Time: 2.15293
Timestep Consumption Time: 2.42678
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.57971

Cumulative Model Updates: 148,334
Cumulative Timesteps: 1,237,187,822

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1237187822...
Checkpoint 1237187822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.84596
Policy Entropy: 3.05997
Value Function Loss: 0.00456

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.61755
Value Function Update Magnitude: 0.57300

Collected Steps per Second: 23,263.07282
Overall Steps per Second: 10,789.45787

Timestep Collection Time: 2.14942
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.63434

Cumulative Model Updates: 148,340
Cumulative Timesteps: 1,237,237,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.48976
Policy Entropy: 3.05752
Value Function Loss: 0.00432

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.61380
Value Function Update Magnitude: 0.58673

Collected Steps per Second: 23,301.90783
Overall Steps per Second: 10,823.50676

Timestep Collection Time: 2.14618
Timestep Consumption Time: 2.47432
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.62050

Cumulative Model Updates: 148,346
Cumulative Timesteps: 1,237,287,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1237287834...
Checkpoint 1237287834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007.31960
Policy Entropy: 3.06792
Value Function Loss: 0.00409

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.59891
Value Function Update Magnitude: 0.58798

Collected Steps per Second: 23,264.81186
Overall Steps per Second: 10,905.18793

Timestep Collection Time: 2.15037
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.58754

Cumulative Model Updates: 148,352
Cumulative Timesteps: 1,237,337,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,174.38653
Policy Entropy: 3.05029
Value Function Loss: 0.00403

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.60340
Value Function Update Magnitude: 0.58090

Collected Steps per Second: 22,997.04134
Overall Steps per Second: 10,894.20717

Timestep Collection Time: 2.17480
Timestep Consumption Time: 2.41608
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.59088

Cumulative Model Updates: 148,358
Cumulative Timesteps: 1,237,387,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1237387876...
Checkpoint 1237387876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,163.13837
Policy Entropy: 3.03325
Value Function Loss: 0.00439

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.62067
Value Function Update Magnitude: 0.58111

Collected Steps per Second: 22,648.22520
Overall Steps per Second: 10,771.13660

Timestep Collection Time: 2.20883
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.64445

Cumulative Model Updates: 148,364
Cumulative Timesteps: 1,237,437,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.17087
Policy Entropy: 3.02300
Value Function Loss: 0.00451

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.62422
Value Function Update Magnitude: 0.56678

Collected Steps per Second: 22,612.45778
Overall Steps per Second: 10,821.43737

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.40987
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.62157

Cumulative Model Updates: 148,370
Cumulative Timesteps: 1,237,487,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1237487914...
Checkpoint 1237487914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.33050
Policy Entropy: 3.02510
Value Function Loss: 0.00487

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.61739
Value Function Update Magnitude: 0.57161

Collected Steps per Second: 22,463.99138
Overall Steps per Second: 10,698.97519

Timestep Collection Time: 2.22712
Timestep Consumption Time: 2.44903
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.67615

Cumulative Model Updates: 148,376
Cumulative Timesteps: 1,237,537,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,639.15867
Policy Entropy: 3.05443
Value Function Loss: 0.00458

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.61435
Value Function Update Magnitude: 0.56390

Collected Steps per Second: 22,555.58789
Overall Steps per Second: 10,505.42533

Timestep Collection Time: 2.21701
Timestep Consumption Time: 2.54301
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.76002

Cumulative Model Updates: 148,382
Cumulative Timesteps: 1,237,587,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1237587950...
Checkpoint 1237587950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532.34814
Policy Entropy: 3.05641
Value Function Loss: 0.00458

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.61326
Value Function Update Magnitude: 0.55158

Collected Steps per Second: 22,982.88771
Overall Steps per Second: 10,709.47476

Timestep Collection Time: 2.17649
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.67082

Cumulative Model Updates: 148,388
Cumulative Timesteps: 1,237,637,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,130.97268
Policy Entropy: 3.06665
Value Function Loss: 0.00462

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.60917
Value Function Update Magnitude: 0.55940

Collected Steps per Second: 23,004.70475
Overall Steps per Second: 10,850.71935

Timestep Collection Time: 2.17425
Timestep Consumption Time: 2.43540
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.60965

Cumulative Model Updates: 148,394
Cumulative Timesteps: 1,237,687,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1237687990...
Checkpoint 1237687990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.62966
Policy Entropy: 3.04999
Value Function Loss: 0.00500

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.61122
Value Function Update Magnitude: 0.56511

Collected Steps per Second: 23,058.29729
Overall Steps per Second: 10,799.41073

Timestep Collection Time: 2.16928
Timestep Consumption Time: 2.46245
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.63173

Cumulative Model Updates: 148,400
Cumulative Timesteps: 1,237,738,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.08631
Policy Entropy: 3.05139
Value Function Loss: 0.00480

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.60451
Value Function Update Magnitude: 0.55677

Collected Steps per Second: 23,358.59529
Overall Steps per Second: 10,807.21096

Timestep Collection Time: 2.14182
Timestep Consumption Time: 2.48749
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.62932

Cumulative Model Updates: 148,406
Cumulative Timesteps: 1,237,788,040

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1237788040...
Checkpoint 1237788040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.09504
Policy Entropy: 3.05182
Value Function Loss: 0.00456

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.59451
Value Function Update Magnitude: 0.54484

Collected Steps per Second: 23,420.07788
Overall Steps per Second: 11,022.25971

Timestep Collection Time: 2.13526
Timestep Consumption Time: 2.40174
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.53700

Cumulative Model Updates: 148,412
Cumulative Timesteps: 1,237,838,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.40570
Policy Entropy: 3.05717
Value Function Loss: 0.00423

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.58615
Value Function Update Magnitude: 0.51528

Collected Steps per Second: 23,178.12860
Overall Steps per Second: 10,891.18171

Timestep Collection Time: 2.15781
Timestep Consumption Time: 2.43435
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.59216

Cumulative Model Updates: 148,418
Cumulative Timesteps: 1,237,888,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1237888062...
Checkpoint 1237888062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.57084
Policy Entropy: 3.04714
Value Function Loss: 0.00451

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.58892
Value Function Update Magnitude: 0.49944

Collected Steps per Second: 22,898.51250
Overall Steps per Second: 10,672.20191

Timestep Collection Time: 2.18407
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.68619

Cumulative Model Updates: 148,424
Cumulative Timesteps: 1,237,938,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,718.23258
Policy Entropy: 3.03615
Value Function Loss: 0.00429

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.59615
Value Function Update Magnitude: 0.51604

Collected Steps per Second: 22,814.54230
Overall Steps per Second: 10,755.12588

Timestep Collection Time: 2.19211
Timestep Consumption Time: 2.45795
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.65006

Cumulative Model Updates: 148,430
Cumulative Timesteps: 1,237,988,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1237988086...
Checkpoint 1237988086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,152.11263
Policy Entropy: 3.04403
Value Function Loss: 0.00417

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.58842
Value Function Update Magnitude: 0.53777

Collected Steps per Second: 22,789.14526
Overall Steps per Second: 10,788.35517

Timestep Collection Time: 2.19403
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.63463

Cumulative Model Updates: 148,436
Cumulative Timesteps: 1,238,038,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.97858
Policy Entropy: 3.03633
Value Function Loss: 0.00427

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.58547
Value Function Update Magnitude: 0.51423

Collected Steps per Second: 22,752.46628
Overall Steps per Second: 10,648.40299

Timestep Collection Time: 2.19879
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.69817

Cumulative Model Updates: 148,442
Cumulative Timesteps: 1,238,088,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1238088114...
Checkpoint 1238088114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,299.93350
Policy Entropy: 3.04083
Value Function Loss: 0.00445

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.58754
Value Function Update Magnitude: 0.51015

Collected Steps per Second: 23,399.60509
Overall Steps per Second: 10,916.29830

Timestep Collection Time: 2.13798
Timestep Consumption Time: 2.44489
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.58287

Cumulative Model Updates: 148,448
Cumulative Timesteps: 1,238,138,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,694.04042
Policy Entropy: 3.04147
Value Function Loss: 0.00457

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.58253
Value Function Update Magnitude: 0.51335

Collected Steps per Second: 22,924.81885
Overall Steps per Second: 10,806.61996

Timestep Collection Time: 2.18226
Timestep Consumption Time: 2.44712
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.62938

Cumulative Model Updates: 148,454
Cumulative Timesteps: 1,238,188,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1238188170...
Checkpoint 1238188170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.47364
Policy Entropy: 3.05819
Value Function Loss: 0.00454

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.58757
Value Function Update Magnitude: 0.53722

Collected Steps per Second: 23,061.31112
Overall Steps per Second: 10,711.80400

Timestep Collection Time: 2.16865
Timestep Consumption Time: 2.50021
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.66887

Cumulative Model Updates: 148,460
Cumulative Timesteps: 1,238,238,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.24119
Policy Entropy: 3.05668
Value Function Loss: 0.00439

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.58500
Value Function Update Magnitude: 0.54958

Collected Steps per Second: 23,219.99138
Overall Steps per Second: 10,902.90853

Timestep Collection Time: 2.15409
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.58758

Cumulative Model Updates: 148,466
Cumulative Timesteps: 1,238,288,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1238288200...
Checkpoint 1238288200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.62442
Policy Entropy: 3.05553
Value Function Loss: 0.00462

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.57648
Value Function Update Magnitude: 0.52394

Collected Steps per Second: 22,980.20733
Overall Steps per Second: 10,776.01297

Timestep Collection Time: 2.17657
Timestep Consumption Time: 2.46504
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.64161

Cumulative Model Updates: 148,472
Cumulative Timesteps: 1,238,338,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.95038
Policy Entropy: 3.05334
Value Function Loss: 0.00424

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11597
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.50878

Collected Steps per Second: 22,629.86236
Overall Steps per Second: 10,535.96753

Timestep Collection Time: 2.21035
Timestep Consumption Time: 2.53719
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.74755

Cumulative Model Updates: 148,478
Cumulative Timesteps: 1,238,388,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1238388238...
Checkpoint 1238388238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.52500
Policy Entropy: 3.06377
Value Function Loss: 0.00421

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.49094

Collected Steps per Second: 22,618.29646
Overall Steps per Second: 10,792.54455

Timestep Collection Time: 2.21087
Timestep Consumption Time: 2.42252
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63338

Cumulative Model Updates: 148,484
Cumulative Timesteps: 1,238,438,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,235.87974
Policy Entropy: 3.06134
Value Function Loss: 0.00407

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.57494
Value Function Update Magnitude: 0.51189

Collected Steps per Second: 22,704.55043
Overall Steps per Second: 10,617.66471

Timestep Collection Time: 2.20308
Timestep Consumption Time: 2.50793
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.71102

Cumulative Model Updates: 148,490
Cumulative Timesteps: 1,238,488,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1238488264...
Checkpoint 1238488264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.19974
Policy Entropy: 3.06397
Value Function Loss: 0.00411

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.57330
Value Function Update Magnitude: 0.51853

Collected Steps per Second: 22,720.18302
Overall Steps per Second: 10,628.14839

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.50490
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.70656

Cumulative Model Updates: 148,496
Cumulative Timesteps: 1,238,538,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,256.55246
Policy Entropy: 3.05516
Value Function Loss: 0.00397

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.56200
Value Function Update Magnitude: 0.50256

Collected Steps per Second: 22,787.51400
Overall Steps per Second: 10,786.84463

Timestep Collection Time: 2.19489
Timestep Consumption Time: 2.44187
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.63676

Cumulative Model Updates: 148,502
Cumulative Timesteps: 1,238,588,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1238588302...
Checkpoint 1238588302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.95046
Policy Entropy: 3.07315
Value Function Loss: 0.00391

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.49259

Collected Steps per Second: 22,989.36364
Overall Steps per Second: 10,752.47067

Timestep Collection Time: 2.17588
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.65214

Cumulative Model Updates: 148,508
Cumulative Timesteps: 1,238,638,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,167.77361
Policy Entropy: 3.05454
Value Function Loss: 0.00441

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.58145
Value Function Update Magnitude: 0.49843

Collected Steps per Second: 23,276.75811
Overall Steps per Second: 10,831.53028

Timestep Collection Time: 2.14824
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.61652

Cumulative Model Updates: 148,514
Cumulative Timesteps: 1,238,688,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1238688328...
Checkpoint 1238688328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.67292
Policy Entropy: 3.05943
Value Function Loss: 0.00452

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.53195

Collected Steps per Second: 23,158.92283
Overall Steps per Second: 10,807.66272

Timestep Collection Time: 2.15934
Timestep Consumption Time: 2.46775
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.62709

Cumulative Model Updates: 148,520
Cumulative Timesteps: 1,238,738,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,947.27154
Policy Entropy: 3.05784
Value Function Loss: 0.00459

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.58523
Value Function Update Magnitude: 0.56010

Collected Steps per Second: 23,060.14346
Overall Steps per Second: 10,782.17225

Timestep Collection Time: 2.16902
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.63895

Cumulative Model Updates: 148,526
Cumulative Timesteps: 1,238,788,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1238788354...
Checkpoint 1238788354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.97984
Policy Entropy: 3.07168
Value Function Loss: 0.00422

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.57856
Value Function Update Magnitude: 0.53563

Collected Steps per Second: 23,125.22282
Overall Steps per Second: 10,728.00305

Timestep Collection Time: 2.16231
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.66107

Cumulative Model Updates: 148,532
Cumulative Timesteps: 1,238,838,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,078.36082
Policy Entropy: 3.07994
Value Function Loss: 0.00395

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.56429
Value Function Update Magnitude: 0.49200

Collected Steps per Second: 23,028.40517
Overall Steps per Second: 10,773.20664

Timestep Collection Time: 2.17201
Timestep Consumption Time: 2.47080
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.64281

Cumulative Model Updates: 148,538
Cumulative Timesteps: 1,238,888,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1238888376...
Checkpoint 1238888376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532.58222
Policy Entropy: 3.07571
Value Function Loss: 0.00405

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.55149
Value Function Update Magnitude: 0.47076

Collected Steps per Second: 22,650.82072
Overall Steps per Second: 10,686.49344

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.47247
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.68086

Cumulative Model Updates: 148,544
Cumulative Timesteps: 1,238,938,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.39832
Policy Entropy: 3.07012
Value Function Loss: 0.00394

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.55484
Value Function Update Magnitude: 0.46352

Collected Steps per Second: 22,434.14964
Overall Steps per Second: 10,572.09575

Timestep Collection Time: 2.22973
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.73151

Cumulative Model Updates: 148,550
Cumulative Timesteps: 1,238,988,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1238988420...
Checkpoint 1238988420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.65087
Policy Entropy: 3.05826
Value Function Loss: 0.00444

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.49464

Collected Steps per Second: 22,571.45087
Overall Steps per Second: 10,627.71081

Timestep Collection Time: 2.21536
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.70506

Cumulative Model Updates: 148,556
Cumulative Timesteps: 1,239,038,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,709.06246
Policy Entropy: 3.05534
Value Function Loss: 0.00463

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.58961
Value Function Update Magnitude: 0.52631

Collected Steps per Second: 22,979.91599
Overall Steps per Second: 10,839.22609

Timestep Collection Time: 2.17607
Timestep Consumption Time: 2.43735
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.61343

Cumulative Model Updates: 148,562
Cumulative Timesteps: 1,239,088,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1239088430...
Checkpoint 1239088430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.54902
Policy Entropy: 3.04617
Value Function Loss: 0.00494

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.60363
Value Function Update Magnitude: 0.54900

Collected Steps per Second: 22,797.72105
Overall Steps per Second: 10,634.24458

Timestep Collection Time: 2.19390
Timestep Consumption Time: 2.50939
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.70330

Cumulative Model Updates: 148,568
Cumulative Timesteps: 1,239,138,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,447.66646
Policy Entropy: 3.04938
Value Function Loss: 0.00472

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.60149
Value Function Update Magnitude: 0.55528

Collected Steps per Second: 23,124.55260
Overall Steps per Second: 10,808.40802

Timestep Collection Time: 2.16290
Timestep Consumption Time: 2.46461
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.62751

Cumulative Model Updates: 148,574
Cumulative Timesteps: 1,239,188,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1239188462...
Checkpoint 1239188462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.16167
Policy Entropy: 3.04944
Value Function Loss: 0.00452

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.59693
Value Function Update Magnitude: 0.54291

Collected Steps per Second: 23,052.54457
Overall Steps per Second: 10,654.00244

Timestep Collection Time: 2.16991
Timestep Consumption Time: 2.52522
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.69514

Cumulative Model Updates: 148,580
Cumulative Timesteps: 1,239,238,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.24547
Policy Entropy: 3.05001
Value Function Loss: 0.00431

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.58419
Value Function Update Magnitude: 0.52996

Collected Steps per Second: 23,009.37482
Overall Steps per Second: 10,868.25344

Timestep Collection Time: 2.17338
Timestep Consumption Time: 2.42792
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.60129

Cumulative Model Updates: 148,586
Cumulative Timesteps: 1,239,288,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1239288492...
Checkpoint 1239288492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,883.40687
Policy Entropy: 3.05096
Value Function Loss: 0.00404

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.57173
Value Function Update Magnitude: 0.51285

Collected Steps per Second: 22,941.51263
Overall Steps per Second: 10,686.08906

Timestep Collection Time: 2.17963
Timestep Consumption Time: 2.49972
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.67935

Cumulative Model Updates: 148,592
Cumulative Timesteps: 1,239,338,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.65573
Policy Entropy: 3.04412
Value Function Loss: 0.00402

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.50751

Collected Steps per Second: 23,299.84103
Overall Steps per Second: 10,902.05917

Timestep Collection Time: 2.14619
Timestep Consumption Time: 2.44065
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.58684

Cumulative Model Updates: 148,598
Cumulative Timesteps: 1,239,388,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1239388502...
Checkpoint 1239388502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.89798
Policy Entropy: 3.05711
Value Function Loss: 0.00378

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.56144
Value Function Update Magnitude: 0.50702

Collected Steps per Second: 22,963.94188
Overall Steps per Second: 10,689.67880

Timestep Collection Time: 2.17776
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.67834

Cumulative Model Updates: 148,604
Cumulative Timesteps: 1,239,438,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.52239
Policy Entropy: 3.04760
Value Function Loss: 0.00397

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.56402
Value Function Update Magnitude: 0.51021

Collected Steps per Second: 22,688.72710
Overall Steps per Second: 10,771.82488

Timestep Collection Time: 2.20471
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.64378

Cumulative Model Updates: 148,610
Cumulative Timesteps: 1,239,488,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1239488534...
Checkpoint 1239488534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,424.73601
Policy Entropy: 3.06750
Value Function Loss: 0.00389

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.56168
Value Function Update Magnitude: 0.51449

Collected Steps per Second: 22,392.21112
Overall Steps per Second: 10,713.65471

Timestep Collection Time: 2.23301
Timestep Consumption Time: 2.43412
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.66713

Cumulative Model Updates: 148,616
Cumulative Timesteps: 1,239,538,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.84011
Policy Entropy: 3.07178
Value Function Loss: 0.00424

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.56476
Value Function Update Magnitude: 0.49789

Collected Steps per Second: 22,773.19695
Overall Steps per Second: 10,655.77856

Timestep Collection Time: 2.19556
Timestep Consumption Time: 2.49673
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.69229

Cumulative Model Updates: 148,622
Cumulative Timesteps: 1,239,588,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1239588536...
Checkpoint 1239588536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.90596
Policy Entropy: 3.07609
Value Function Loss: 0.00457

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10322
Policy Update Magnitude: 0.57378
Value Function Update Magnitude: 0.49291

Collected Steps per Second: 23,188.52893
Overall Steps per Second: 10,851.53964

Timestep Collection Time: 2.15632
Timestep Consumption Time: 2.45150
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.60783

Cumulative Model Updates: 148,628
Cumulative Timesteps: 1,239,638,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,224.79371
Policy Entropy: 3.06535
Value Function Loss: 0.00431

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.57159
Value Function Update Magnitude: 0.50440

Collected Steps per Second: 23,112.08674
Overall Steps per Second: 10,711.15193

Timestep Collection Time: 2.16458
Timestep Consumption Time: 2.50606
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.67065

Cumulative Model Updates: 148,634
Cumulative Timesteps: 1,239,688,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1239688566...
Checkpoint 1239688566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,186.01436
Policy Entropy: 3.07685
Value Function Loss: 0.00419

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.56296
Value Function Update Magnitude: 0.50941

Collected Steps per Second: 23,081.62062
Overall Steps per Second: 10,861.59010

Timestep Collection Time: 2.16709
Timestep Consumption Time: 2.43813
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60522

Cumulative Model Updates: 148,640
Cumulative Timesteps: 1,239,738,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.17367
Policy Entropy: 3.07088
Value Function Loss: 0.00393

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.56126
Value Function Update Magnitude: 0.51005

Collected Steps per Second: 23,226.67201
Overall Steps per Second: 10,909.34870

Timestep Collection Time: 2.15321
Timestep Consumption Time: 2.43111
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.58432

Cumulative Model Updates: 148,646
Cumulative Timesteps: 1,239,788,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1239788598...
Checkpoint 1239788598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.12455
Policy Entropy: 3.06348
Value Function Loss: 0.00415

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.56254
Value Function Update Magnitude: 0.51068

Collected Steps per Second: 22,796.72710
Overall Steps per Second: 10,675.01037

Timestep Collection Time: 2.19330
Timestep Consumption Time: 2.49054
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.68384

Cumulative Model Updates: 148,652
Cumulative Timesteps: 1,239,838,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.82357
Policy Entropy: 3.04613
Value Function Loss: 0.00448

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.57565
Value Function Update Magnitude: 0.53620

Collected Steps per Second: 23,420.65315
Overall Steps per Second: 10,919.03826

Timestep Collection Time: 2.13606
Timestep Consumption Time: 2.44566
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.58172

Cumulative Model Updates: 148,658
Cumulative Timesteps: 1,239,888,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1239888626...
Checkpoint 1239888626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.38854
Policy Entropy: 3.04623
Value Function Loss: 0.00434

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.59766
Value Function Update Magnitude: 0.58237

Collected Steps per Second: 22,170.23472
Overall Steps per Second: 10,651.33837

Timestep Collection Time: 2.25546
Timestep Consumption Time: 2.43916
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.69462

Cumulative Model Updates: 148,664
Cumulative Timesteps: 1,239,938,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.18749
Policy Entropy: 3.06849
Value Function Loss: 0.00421

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.59807
Value Function Update Magnitude: 0.58489

Collected Steps per Second: 22,910.42664
Overall Steps per Second: 10,844.43810

Timestep Collection Time: 2.18329
Timestep Consumption Time: 2.42922
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.61250

Cumulative Model Updates: 148,670
Cumulative Timesteps: 1,239,988,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1239988650...
Checkpoint 1239988650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.63437
Policy Entropy: 3.08136
Value Function Loss: 0.00403

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.58745
Value Function Update Magnitude: 0.57062

Collected Steps per Second: 22,221.36800
Overall Steps per Second: 10,699.85582

Timestep Collection Time: 2.25027
Timestep Consumption Time: 2.42307
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.67333

Cumulative Model Updates: 148,676
Cumulative Timesteps: 1,240,038,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.96117
Policy Entropy: 3.07551
Value Function Loss: 0.00418

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.58564
Value Function Update Magnitude: 0.56227

Collected Steps per Second: 22,933.93652
Overall Steps per Second: 10,785.21306

Timestep Collection Time: 2.18122
Timestep Consumption Time: 2.45698
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.63820

Cumulative Model Updates: 148,682
Cumulative Timesteps: 1,240,088,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1240088678...
Checkpoint 1240088678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.58315
Policy Entropy: 3.05255
Value Function Loss: 0.00462

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.59573
Value Function Update Magnitude: 0.55646

Collected Steps per Second: 22,811.78747
Overall Steps per Second: 10,783.91591

Timestep Collection Time: 2.19246
Timestep Consumption Time: 2.44537
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.63783

Cumulative Model Updates: 148,688
Cumulative Timesteps: 1,240,138,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.07873
Policy Entropy: 3.04119
Value Function Loss: 0.00466

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.58964
Value Function Update Magnitude: 0.56367

Collected Steps per Second: 23,216.44507
Overall Steps per Second: 10,830.96679

Timestep Collection Time: 2.15416
Timestep Consumption Time: 2.46334
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.61750

Cumulative Model Updates: 148,694
Cumulative Timesteps: 1,240,188,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1240188704...
Checkpoint 1240188704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,815.45473
Policy Entropy: 3.05660
Value Function Loss: 0.00424

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.58455
Value Function Update Magnitude: 0.56709

Collected Steps per Second: 23,019.52654
Overall Steps per Second: 10,691.54747

Timestep Collection Time: 2.17207
Timestep Consumption Time: 2.50452
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.67659

Cumulative Model Updates: 148,700
Cumulative Timesteps: 1,240,238,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,545.68261
Policy Entropy: 3.06307
Value Function Loss: 0.00389

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.57700
Value Function Update Magnitude: 0.55923

Collected Steps per Second: 22,843.61545
Overall Steps per Second: 10,775.54799

Timestep Collection Time: 2.18967
Timestep Consumption Time: 2.45232
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.64199

Cumulative Model Updates: 148,706
Cumulative Timesteps: 1,240,288,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1240288724...
Checkpoint 1240288724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,540.63114
Policy Entropy: 3.04574
Value Function Loss: 0.00394

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.57917
Value Function Update Magnitude: 0.53693

Collected Steps per Second: 21,868.93935
Overall Steps per Second: 10,475.04448

Timestep Collection Time: 2.28781
Timestep Consumption Time: 2.48849
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.77630

Cumulative Model Updates: 148,712
Cumulative Timesteps: 1,240,338,756

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.54018
Policy Entropy: 3.03402
Value Function Loss: 0.00431

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.58567
Value Function Update Magnitude: 0.56129

Collected Steps per Second: 22,834.65494
Overall Steps per Second: 10,748.20875

Timestep Collection Time: 2.19018
Timestep Consumption Time: 2.46287
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.65305

Cumulative Model Updates: 148,718
Cumulative Timesteps: 1,240,388,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1240388768...
Checkpoint 1240388768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.39322
Policy Entropy: 3.02817
Value Function Loss: 0.00428

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.59000
Value Function Update Magnitude: 0.59495

Collected Steps per Second: 22,668.63497
Overall Steps per Second: 10,636.09782

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70154

Cumulative Model Updates: 148,724
Cumulative Timesteps: 1,240,438,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.84254
Policy Entropy: 3.04061
Value Function Loss: 0.00450

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.59721
Value Function Update Magnitude: 0.61805

Collected Steps per Second: 23,433.79485
Overall Steps per Second: 10,859.57660

Timestep Collection Time: 2.13469
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.60644

Cumulative Model Updates: 148,730
Cumulative Timesteps: 1,240,488,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1240488798...
Checkpoint 1240488798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.45361
Policy Entropy: 3.04551
Value Function Loss: 0.00429

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.60104
Value Function Update Magnitude: 0.59106

Collected Steps per Second: 23,099.85920
Overall Steps per Second: 10,716.44007

Timestep Collection Time: 2.16478
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.66629

Cumulative Model Updates: 148,736
Cumulative Timesteps: 1,240,538,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,961.49399
Policy Entropy: 3.03519
Value Function Loss: 0.00448

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.59928
Value Function Update Magnitude: 0.56874

Collected Steps per Second: 23,266.14030
Overall Steps per Second: 10,830.25533

Timestep Collection Time: 2.14939
Timestep Consumption Time: 2.46805
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.61744

Cumulative Model Updates: 148,742
Cumulative Timesteps: 1,240,588,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1240588812...
Checkpoint 1240588812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.48809
Policy Entropy: 3.03294
Value Function Loss: 0.00450

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.59658
Value Function Update Magnitude: 0.55493

Collected Steps per Second: 23,042.42043
Overall Steps per Second: 10,727.53228

Timestep Collection Time: 2.17069
Timestep Consumption Time: 2.49189
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.66258

Cumulative Model Updates: 148,748
Cumulative Timesteps: 1,240,638,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.60003
Policy Entropy: 3.01086
Value Function Loss: 0.00458

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.58902
Value Function Update Magnitude: 0.55302

Collected Steps per Second: 23,502.08954
Overall Steps per Second: 10,845.88702

Timestep Collection Time: 2.12798
Timestep Consumption Time: 2.48317
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.61115

Cumulative Model Updates: 148,754
Cumulative Timesteps: 1,240,688,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1240688842...
Checkpoint 1240688842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,024.92269
Policy Entropy: 3.01218
Value Function Loss: 0.00429

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11471
Policy Update Magnitude: 0.58305
Value Function Update Magnitude: 0.53526

Collected Steps per Second: 22,352.84267
Overall Steps per Second: 10,746.90911

Timestep Collection Time: 2.23810
Timestep Consumption Time: 2.41700
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.65511

Cumulative Model Updates: 148,760
Cumulative Timesteps: 1,240,738,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.49084
Policy Entropy: 3.01167
Value Function Loss: 0.00427

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.57993
Value Function Update Magnitude: 0.50413

Collected Steps per Second: 22,246.20497
Overall Steps per Second: 10,832.80033

Timestep Collection Time: 2.24865
Timestep Consumption Time: 2.36917
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.61783

Cumulative Model Updates: 148,766
Cumulative Timesteps: 1,240,788,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1240788894...
Checkpoint 1240788894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.76545
Policy Entropy: 3.02476
Value Function Loss: 0.00448

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.59811
Value Function Update Magnitude: 0.52581

Collected Steps per Second: 22,028.77669
Overall Steps per Second: 10,642.53168

Timestep Collection Time: 2.27030
Timestep Consumption Time: 2.42895
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.69926

Cumulative Model Updates: 148,772
Cumulative Timesteps: 1,240,838,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,724.80936
Policy Entropy: 3.02501
Value Function Loss: 0.00443

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.60857
Value Function Update Magnitude: 0.55785

Collected Steps per Second: 22,356.66532
Overall Steps per Second: 10,859.83947

Timestep Collection Time: 2.23754
Timestep Consumption Time: 2.36879
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.60633

Cumulative Model Updates: 148,778
Cumulative Timesteps: 1,240,888,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1240888930...
Checkpoint 1240888930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.43340
Policy Entropy: 3.02562
Value Function Loss: 0.00432

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.60199
Value Function Update Magnitude: 0.52697

Collected Steps per Second: 22,095.13465
Overall Steps per Second: 10,636.75850

Timestep Collection Time: 2.26330
Timestep Consumption Time: 2.43813
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.70143

Cumulative Model Updates: 148,784
Cumulative Timesteps: 1,240,938,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,408.35496
Policy Entropy: 3.01430
Value Function Loss: 0.00470

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.60571
Value Function Update Magnitude: 0.54932

Collected Steps per Second: 22,464.66129
Overall Steps per Second: 10,840.44714

Timestep Collection Time: 2.22679
Timestep Consumption Time: 2.38778
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61457

Cumulative Model Updates: 148,790
Cumulative Timesteps: 1,240,988,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1240988962...
Checkpoint 1240988962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.93182
Policy Entropy: 3.01123
Value Function Loss: 0.00493

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.62076
Value Function Update Magnitude: 0.55877

Collected Steps per Second: 22,267.98204
Overall Steps per Second: 10,732.35166

Timestep Collection Time: 2.24574
Timestep Consumption Time: 2.41382
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.65956

Cumulative Model Updates: 148,796
Cumulative Timesteps: 1,241,038,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,253.07673
Policy Entropy: 3.01114
Value Function Loss: 0.00474

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.62125
Value Function Update Magnitude: 0.55602

Collected Steps per Second: 22,615.95527
Overall Steps per Second: 10,948.96367

Timestep Collection Time: 2.21145
Timestep Consumption Time: 2.35647
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.56792

Cumulative Model Updates: 148,802
Cumulative Timesteps: 1,241,088,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1241088984...
Checkpoint 1241088984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.25636
Policy Entropy: 3.01249
Value Function Loss: 0.00446

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.60686
Value Function Update Magnitude: 0.55532

Collected Steps per Second: 22,983.26915
Overall Steps per Second: 10,720.99461

Timestep Collection Time: 2.17567
Timestep Consumption Time: 2.48845
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.66412

Cumulative Model Updates: 148,808
Cumulative Timesteps: 1,241,138,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.11976
Policy Entropy: 3.02637
Value Function Loss: 0.00439

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.59869
Value Function Update Magnitude: 0.55035

Collected Steps per Second: 23,243.12727
Overall Steps per Second: 10,805.71962

Timestep Collection Time: 2.15186
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.62866

Cumulative Model Updates: 148,814
Cumulative Timesteps: 1,241,189,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1241189004...
Checkpoint 1241189004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.73603
Policy Entropy: 3.03759
Value Function Loss: 0.00432

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.59799
Value Function Update Magnitude: 0.56554

Collected Steps per Second: 20,945.07360
Overall Steps per Second: 10,346.77774

Timestep Collection Time: 2.38872
Timestep Consumption Time: 2.44679
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.83552

Cumulative Model Updates: 148,820
Cumulative Timesteps: 1,241,239,036

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.52889
Policy Entropy: 3.03304
Value Function Loss: 0.00456

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.60073
Value Function Update Magnitude: 0.55133

Collected Steps per Second: 22,480.18855
Overall Steps per Second: 10,718.27191

Timestep Collection Time: 2.22427
Timestep Consumption Time: 2.44085
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.66512

Cumulative Model Updates: 148,826
Cumulative Timesteps: 1,241,289,038

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1241289038...
Checkpoint 1241289038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,522.06380
Policy Entropy: 3.02371
Value Function Loss: 0.00448

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.60115
Value Function Update Magnitude: 0.55998

Collected Steps per Second: 21,942.99779
Overall Steps per Second: 10,648.44862

Timestep Collection Time: 2.27918
Timestep Consumption Time: 2.41747
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.69665

Cumulative Model Updates: 148,832
Cumulative Timesteps: 1,241,339,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,726.99627
Policy Entropy: 3.02164
Value Function Loss: 0.00422

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.58859
Value Function Update Magnitude: 0.56671

Collected Steps per Second: 22,154.30209
Overall Steps per Second: 10,821.46655

Timestep Collection Time: 2.25726
Timestep Consumption Time: 2.36393
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.62119

Cumulative Model Updates: 148,838
Cumulative Timesteps: 1,241,389,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1241389058...
Checkpoint 1241389058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.92295
Policy Entropy: 3.04157
Value Function Loss: 0.00420

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.57705
Value Function Update Magnitude: 0.53929

Collected Steps per Second: 22,302.89524
Overall Steps per Second: 10,733.45090

Timestep Collection Time: 2.24222
Timestep Consumption Time: 2.41686
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.65908

Cumulative Model Updates: 148,844
Cumulative Timesteps: 1,241,439,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.37285
Policy Entropy: 3.04133
Value Function Loss: 0.00442

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.57654
Value Function Update Magnitude: 0.54601

Collected Steps per Second: 22,788.04909
Overall Steps per Second: 10,913.41733

Timestep Collection Time: 2.19448
Timestep Consumption Time: 2.38777
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.58225

Cumulative Model Updates: 148,850
Cumulative Timesteps: 1,241,489,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1241489074...
Checkpoint 1241489074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.88534
Policy Entropy: 3.04252
Value Function Loss: 0.00454

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.59022
Value Function Update Magnitude: 0.56274

Collected Steps per Second: 22,100.03152
Overall Steps per Second: 10,632.13450

Timestep Collection Time: 2.26289
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.70367

Cumulative Model Updates: 148,856
Cumulative Timesteps: 1,241,539,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935.77383
Policy Entropy: 3.02826
Value Function Loss: 0.00434

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12073
Policy Update Magnitude: 0.58996
Value Function Update Magnitude: 0.54839

Collected Steps per Second: 22,290.75890
Overall Steps per Second: 10,852.34301

Timestep Collection Time: 2.24425
Timestep Consumption Time: 2.36545
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.60970

Cumulative Model Updates: 148,862
Cumulative Timesteps: 1,241,589,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1241589110...
Checkpoint 1241589110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,454.39484
Policy Entropy: 3.03666
Value Function Loss: 0.00424

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.58837
Value Function Update Magnitude: 0.53202

Collected Steps per Second: 22,284.55658
Overall Steps per Second: 10,701.56621

Timestep Collection Time: 2.24371
Timestep Consumption Time: 2.42851
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.67221

Cumulative Model Updates: 148,868
Cumulative Timesteps: 1,241,639,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,297.90594
Policy Entropy: 3.04554
Value Function Loss: 0.00429

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.57880
Value Function Update Magnitude: 0.53366

Collected Steps per Second: 22,373.67209
Overall Steps per Second: 10,856.46972

Timestep Collection Time: 2.23477
Timestep Consumption Time: 2.37078
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.60555

Cumulative Model Updates: 148,874
Cumulative Timesteps: 1,241,689,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1241689110...
Checkpoint 1241689110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.78008
Policy Entropy: 3.04798
Value Function Loss: 0.00428

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12064
Policy Update Magnitude: 0.57593
Value Function Update Magnitude: 0.56318

Collected Steps per Second: 21,750.99839
Overall Steps per Second: 10,685.05529

Timestep Collection Time: 2.30104
Timestep Consumption Time: 2.38307
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.68411

Cumulative Model Updates: 148,880
Cumulative Timesteps: 1,241,739,160

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.46615
Policy Entropy: 3.01930
Value Function Loss: 0.00457

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.58757
Value Function Update Magnitude: 0.57082

Collected Steps per Second: 22,374.01623
Overall Steps per Second: 10,655.35140

Timestep Collection Time: 2.23581
Timestep Consumption Time: 2.45892
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.69473

Cumulative Model Updates: 148,886
Cumulative Timesteps: 1,241,789,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1241789184...
Checkpoint 1241789184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.66383
Policy Entropy: 3.00043
Value Function Loss: 0.00440

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.59464
Value Function Update Magnitude: 0.55141

Collected Steps per Second: 22,665.85349
Overall Steps per Second: 10,811.94821

Timestep Collection Time: 2.20667
Timestep Consumption Time: 2.41933
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62599

Cumulative Model Updates: 148,892
Cumulative Timesteps: 1,241,839,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.56044
Policy Entropy: 3.01637
Value Function Loss: 0.00417

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.58592
Value Function Update Magnitude: 0.52706

Collected Steps per Second: 22,520.16677
Overall Steps per Second: 10,603.75625

Timestep Collection Time: 2.22094
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.71682

Cumulative Model Updates: 148,898
Cumulative Timesteps: 1,241,889,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1241889216...
Checkpoint 1241889216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.10444
Policy Entropy: 3.04199
Value Function Loss: 0.00401

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.58421
Value Function Update Magnitude: 0.51656

Collected Steps per Second: 22,657.64111
Overall Steps per Second: 10,627.16527

Timestep Collection Time: 2.20782
Timestep Consumption Time: 2.49936
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.70718

Cumulative Model Updates: 148,904
Cumulative Timesteps: 1,241,939,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.91949
Policy Entropy: 3.06391
Value Function Loss: 0.00434

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.59456
Value Function Update Magnitude: 0.54583

Collected Steps per Second: 23,502.02327
Overall Steps per Second: 10,816.18581

Timestep Collection Time: 2.12799
Timestep Consumption Time: 2.49582
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.62381

Cumulative Model Updates: 148,910
Cumulative Timesteps: 1,241,989,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1241989252...
Checkpoint 1241989252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.02915
Policy Entropy: 3.04133
Value Function Loss: 0.00435

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.59292
Value Function Update Magnitude: 0.57361

Collected Steps per Second: 23,209.08709
Overall Steps per Second: 10,872.16630

Timestep Collection Time: 2.15528
Timestep Consumption Time: 2.44565
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.60092

Cumulative Model Updates: 148,916
Cumulative Timesteps: 1,242,039,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.36463
Policy Entropy: 3.03889
Value Function Loss: 0.00436

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.55597

Collected Steps per Second: 23,557.37793
Overall Steps per Second: 10,953.26429

Timestep Collection Time: 2.12282
Timestep Consumption Time: 2.44276
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.56558

Cumulative Model Updates: 148,922
Cumulative Timesteps: 1,242,089,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1242089282...
Checkpoint 1242089282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,052.09516
Policy Entropy: 3.03499
Value Function Loss: 0.00422

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.56978
Value Function Update Magnitude: 0.51846

Collected Steps per Second: 22,901.69944
Overall Steps per Second: 10,819.06233

Timestep Collection Time: 2.18386
Timestep Consumption Time: 2.43891
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.62277

Cumulative Model Updates: 148,928
Cumulative Timesteps: 1,242,139,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.98899
Policy Entropy: 3.04582
Value Function Loss: 0.00400

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.56234
Value Function Update Magnitude: 0.50756

Collected Steps per Second: 23,325.56452
Overall Steps per Second: 10,912.55725

Timestep Collection Time: 2.14409
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.58298

Cumulative Model Updates: 148,934
Cumulative Timesteps: 1,242,189,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1242189308...
Checkpoint 1242189308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,832.11407
Policy Entropy: 3.05084
Value Function Loss: 0.00379

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.50688

Collected Steps per Second: 22,115.68395
Overall Steps per Second: 10,582.50088

Timestep Collection Time: 2.26174
Timestep Consumption Time: 2.46493
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.72667

Cumulative Model Updates: 148,940
Cumulative Timesteps: 1,242,239,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,220.38187
Policy Entropy: 3.03526
Value Function Loss: 0.00427

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.57352
Value Function Update Magnitude: 0.50833

Collected Steps per Second: 22,876.64819
Overall Steps per Second: 10,891.60618

Timestep Collection Time: 2.18677
Timestep Consumption Time: 2.40631
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.59308

Cumulative Model Updates: 148,946
Cumulative Timesteps: 1,242,289,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1242289354...
Checkpoint 1242289354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,042.78048
Policy Entropy: 3.01752
Value Function Loss: 0.00454

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.57946
Value Function Update Magnitude: 0.52863

Collected Steps per Second: 22,506.35631
Overall Steps per Second: 10,726.83470

Timestep Collection Time: 2.22311
Timestep Consumption Time: 2.44127
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.66438

Cumulative Model Updates: 148,952
Cumulative Timesteps: 1,242,339,388

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.33330
Policy Entropy: 3.00933
Value Function Loss: 0.00499

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.58799
Value Function Update Magnitude: 0.53723

Collected Steps per Second: 22,959.19480
Overall Steps per Second: 10,896.26425

Timestep Collection Time: 2.17839
Timestep Consumption Time: 2.41163
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.59001

Cumulative Model Updates: 148,958
Cumulative Timesteps: 1,242,389,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1242389402...
Checkpoint 1242389402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.99845
Policy Entropy: 3.01944
Value Function Loss: 0.00484

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.59690
Value Function Update Magnitude: 0.55794

Collected Steps per Second: 22,940.53220
Overall Steps per Second: 10,685.96611

Timestep Collection Time: 2.18094
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.68203

Cumulative Model Updates: 148,964
Cumulative Timesteps: 1,242,439,434

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.23983
Policy Entropy: 3.03413
Value Function Loss: 0.00444

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.58146
Value Function Update Magnitude: 0.54856

Collected Steps per Second: 23,480.95815
Overall Steps per Second: 10,879.73097

Timestep Collection Time: 2.13007
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.59717

Cumulative Model Updates: 148,970
Cumulative Timesteps: 1,242,489,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1242489450...
Checkpoint 1242489450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,002.81107
Policy Entropy: 3.03221
Value Function Loss: 0.00436

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.58546
Value Function Update Magnitude: 0.54744

Collected Steps per Second: 22,699.61620
Overall Steps per Second: 10,673.94992

Timestep Collection Time: 2.20374
Timestep Consumption Time: 2.48281
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.68655

Cumulative Model Updates: 148,976
Cumulative Timesteps: 1,242,539,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,074.62352
Policy Entropy: 3.01561
Value Function Loss: 0.00469

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.60257
Value Function Update Magnitude: 0.55860

Collected Steps per Second: 23,470.17982
Overall Steps per Second: 10,943.67448

Timestep Collection Time: 2.13045
Timestep Consumption Time: 2.43858
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.56903

Cumulative Model Updates: 148,982
Cumulative Timesteps: 1,242,589,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1242589476...
Checkpoint 1242589476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.86538
Policy Entropy: 3.00885
Value Function Loss: 0.00481

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.60250
Value Function Update Magnitude: 0.55162

Collected Steps per Second: 23,282.19130
Overall Steps per Second: 10,790.58266

Timestep Collection Time: 2.14834
Timestep Consumption Time: 2.48700
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.63534

Cumulative Model Updates: 148,988
Cumulative Timesteps: 1,242,639,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.79351
Policy Entropy: 3.01464
Value Function Loss: 0.00464

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.60364
Value Function Update Magnitude: 0.55079

Collected Steps per Second: 23,686.39845
Overall Steps per Second: 10,858.58056

Timestep Collection Time: 2.11159
Timestep Consumption Time: 2.49454
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.60613

Cumulative Model Updates: 148,994
Cumulative Timesteps: 1,242,689,510

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1242689510...
Checkpoint 1242689510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.64789
Policy Entropy: 3.01464
Value Function Loss: 0.00425

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.59583
Value Function Update Magnitude: 0.54500

Collected Steps per Second: 22,653.00253
Overall Steps per Second: 10,638.47073

Timestep Collection Time: 2.20818
Timestep Consumption Time: 2.49381
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.70199

Cumulative Model Updates: 149,000
Cumulative Timesteps: 1,242,739,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.56954
Policy Entropy: 3.01402
Value Function Loss: 0.00452

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.60075
Value Function Update Magnitude: 0.55429

Collected Steps per Second: 23,032.89856
Overall Steps per Second: 10,798.92300

Timestep Collection Time: 2.17194
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.63250

Cumulative Model Updates: 149,006
Cumulative Timesteps: 1,242,789,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1242789558...
Checkpoint 1242789558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.03551
Policy Entropy: 3.00677
Value Function Loss: 0.00444

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.59340
Value Function Update Magnitude: 0.56530

Collected Steps per Second: 22,529.93503
Overall Steps per Second: 10,649.79394

Timestep Collection Time: 2.21989
Timestep Consumption Time: 2.47635
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.69624

Cumulative Model Updates: 149,012
Cumulative Timesteps: 1,242,839,572

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439.36265
Policy Entropy: 3.00109
Value Function Loss: 0.00444

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.58672
Value Function Update Magnitude: 0.55387

Collected Steps per Second: 22,774.05115
Overall Steps per Second: 10,788.93197

Timestep Collection Time: 2.19662
Timestep Consumption Time: 2.44017
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.63679

Cumulative Model Updates: 149,018
Cumulative Timesteps: 1,242,889,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1242889598...
Checkpoint 1242889598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,881.35787
Policy Entropy: 3.00766
Value Function Loss: 0.00423

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.58420
Value Function Update Magnitude: 0.54618

Collected Steps per Second: 22,903.12568
Overall Steps per Second: 10,741.73102

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.47312
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.65754

Cumulative Model Updates: 149,024
Cumulative Timesteps: 1,242,939,628

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,702.55860
Policy Entropy: 3.00520
Value Function Loss: 0.00452

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.58715
Value Function Update Magnitude: 0.53840

Collected Steps per Second: 23,553.79337
Overall Steps per Second: 10,765.81161

Timestep Collection Time: 2.12339
Timestep Consumption Time: 2.52224
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.64563

Cumulative Model Updates: 149,030
Cumulative Timesteps: 1,242,989,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1242989642...
Checkpoint 1242989642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.57946
Policy Entropy: 3.01585
Value Function Loss: 0.00430

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.58412
Value Function Update Magnitude: 0.54424

Collected Steps per Second: 23,064.52386
Overall Steps per Second: 10,792.39441

Timestep Collection Time: 2.16887
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.63512

Cumulative Model Updates: 149,036
Cumulative Timesteps: 1,243,039,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.54907
Policy Entropy: 3.02483
Value Function Loss: 0.00424

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11102
Policy Update Magnitude: 0.57262
Value Function Update Magnitude: 0.52762

Collected Steps per Second: 23,309.11847
Overall Steps per Second: 10,890.55737

Timestep Collection Time: 2.14594
Timestep Consumption Time: 2.44703
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.59297

Cumulative Model Updates: 149,042
Cumulative Timesteps: 1,243,089,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1243089686...
Checkpoint 1243089686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,190.27604
Policy Entropy: 3.02337
Value Function Loss: 0.00406

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.48732

Collected Steps per Second: 22,909.64386
Overall Steps per Second: 10,623.28151

Timestep Collection Time: 2.18327
Timestep Consumption Time: 2.52507
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.70834

Cumulative Model Updates: 149,048
Cumulative Timesteps: 1,243,139,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,768.94639
Policy Entropy: 3.02395
Value Function Loss: 0.00427

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.49180

Collected Steps per Second: 23,313.09789
Overall Steps per Second: 11,008.44098

Timestep Collection Time: 2.14558
Timestep Consumption Time: 2.39821
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.54379

Cumulative Model Updates: 149,054
Cumulative Timesteps: 1,243,189,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1243189724...
Checkpoint 1243189724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.81724
Policy Entropy: 3.01370
Value Function Loss: 0.00432

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.58142
Value Function Update Magnitude: 0.50814

Collected Steps per Second: 22,622.35102
Overall Steps per Second: 10,603.98468

Timestep Collection Time: 2.21100
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.71691

Cumulative Model Updates: 149,060
Cumulative Timesteps: 1,243,239,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.06880
Policy Entropy: 3.01108
Value Function Loss: 0.00452

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.58823
Value Function Update Magnitude: 0.53701

Collected Steps per Second: 23,087.52837
Overall Steps per Second: 10,863.59735

Timestep Collection Time: 2.16662
Timestep Consumption Time: 2.43793
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.60455

Cumulative Model Updates: 149,066
Cumulative Timesteps: 1,243,289,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1243289764...
Checkpoint 1243289764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,656.28308
Policy Entropy: 3.03017
Value Function Loss: 0.00410

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.55002

Collected Steps per Second: 22,715.11505
Overall Steps per Second: 10,645.05094

Timestep Collection Time: 2.20250
Timestep Consumption Time: 2.49734
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.69984

Cumulative Model Updates: 149,072
Cumulative Timesteps: 1,243,339,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.56659
Policy Entropy: 3.02236
Value Function Loss: 0.00416

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.58197
Value Function Update Magnitude: 0.54106

Collected Steps per Second: 22,995.99694
Overall Steps per Second: 10,670.30542

Timestep Collection Time: 2.17481
Timestep Consumption Time: 2.51221
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.68703

Cumulative Model Updates: 149,078
Cumulative Timesteps: 1,243,389,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1243389806...
Checkpoint 1243389806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,979.93382
Policy Entropy: 3.03037
Value Function Loss: 0.00390

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.57831
Value Function Update Magnitude: 0.54782

Collected Steps per Second: 23,151.62327
Overall Steps per Second: 10,856.38707

Timestep Collection Time: 2.16019
Timestep Consumption Time: 2.44650
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.60669

Cumulative Model Updates: 149,084
Cumulative Timesteps: 1,243,439,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.53581
Policy Entropy: 2.99932
Value Function Loss: 0.00439

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.58432
Value Function Update Magnitude: 0.53454

Collected Steps per Second: 23,283.75320
Overall Steps per Second: 10,959.44062

Timestep Collection Time: 2.14785
Timestep Consumption Time: 2.41534
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.56319

Cumulative Model Updates: 149,090
Cumulative Timesteps: 1,243,489,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1243489828...
Checkpoint 1243489828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.42326
Policy Entropy: 3.00855
Value Function Loss: 0.00426

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.59025
Value Function Update Magnitude: 0.53898

Collected Steps per Second: 22,500.79275
Overall Steps per Second: 10,594.58922

Timestep Collection Time: 2.22232
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.71977

Cumulative Model Updates: 149,096
Cumulative Timesteps: 1,243,539,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.07008
Policy Entropy: 3.00923
Value Function Loss: 0.00467

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.59103
Value Function Update Magnitude: 0.52703

Collected Steps per Second: 23,454.88638
Overall Steps per Second: 10,903.11792

Timestep Collection Time: 2.13278
Timestep Consumption Time: 2.45527
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.58805

Cumulative Model Updates: 149,102
Cumulative Timesteps: 1,243,589,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1243589856...
Checkpoint 1243589856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.87774
Policy Entropy: 3.02709
Value Function Loss: 0.00439

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.57871
Value Function Update Magnitude: 0.49734

Collected Steps per Second: 23,141.93923
Overall Steps per Second: 10,825.22286

Timestep Collection Time: 2.16162
Timestep Consumption Time: 2.45944
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.62106

Cumulative Model Updates: 149,108
Cumulative Timesteps: 1,243,639,880

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.43251
Policy Entropy: 3.02910
Value Function Loss: 0.00445

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.57035
Value Function Update Magnitude: 0.46981

Collected Steps per Second: 22,905.25381
Overall Steps per Second: 10,788.28584

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.45234
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.63577

Cumulative Model Updates: 149,114
Cumulative Timesteps: 1,243,689,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1243689892...
Checkpoint 1243689892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.44260
Policy Entropy: 3.02984
Value Function Loss: 0.00405

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.56734
Value Function Update Magnitude: 0.47482

Collected Steps per Second: 22,691.85988
Overall Steps per Second: 10,592.50997

Timestep Collection Time: 2.20387
Timestep Consumption Time: 2.51739
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.72126

Cumulative Model Updates: 149,120
Cumulative Timesteps: 1,243,739,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.10415
Policy Entropy: 3.01047
Value Function Loss: 0.00414

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.14301
Policy Update Magnitude: 0.57344
Value Function Update Magnitude: 0.48696

Collected Steps per Second: 22,719.37264
Overall Steps per Second: 10,861.59764

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.40357
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60522

Cumulative Model Updates: 149,126
Cumulative Timesteps: 1,243,789,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1243789922...
Checkpoint 1243789922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,256.55233
Policy Entropy: 3.00281
Value Function Loss: 0.00419

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.59250
Value Function Update Magnitude: 0.49081

Collected Steps per Second: 22,904.24341
Overall Steps per Second: 10,721.53348

Timestep Collection Time: 2.18344
Timestep Consumption Time: 2.48101
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.66444

Cumulative Model Updates: 149,132
Cumulative Timesteps: 1,243,839,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.30441
Policy Entropy: 2.97684
Value Function Loss: 0.00441

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.59912
Value Function Update Magnitude: 0.49783

Collected Steps per Second: 23,399.75241
Overall Steps per Second: 10,802.06277

Timestep Collection Time: 2.13720
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.62967

Cumulative Model Updates: 149,138
Cumulative Timesteps: 1,243,889,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1243889942...
Checkpoint 1243889942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.55022
Policy Entropy: 2.99366
Value Function Loss: 0.00440

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.60175
Value Function Update Magnitude: 0.51549

Collected Steps per Second: 23,007.27924
Overall Steps per Second: 10,747.80605

Timestep Collection Time: 2.17340
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.65248

Cumulative Model Updates: 149,144
Cumulative Timesteps: 1,243,939,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040.96386
Policy Entropy: 3.00194
Value Function Loss: 0.00436

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.59542
Value Function Update Magnitude: 0.52197

Collected Steps per Second: 23,488.85369
Overall Steps per Second: 10,869.32381

Timestep Collection Time: 2.12935
Timestep Consumption Time: 2.47222
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.60157

Cumulative Model Updates: 149,150
Cumulative Timesteps: 1,243,989,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1243989962...
Checkpoint 1243989962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.92755
Policy Entropy: 3.01479
Value Function Loss: 0.00444

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.59784
Value Function Update Magnitude: 0.52104

Collected Steps per Second: 23,098.70798
Overall Steps per Second: 10,731.92994

Timestep Collection Time: 2.16540
Timestep Consumption Time: 2.49527
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.66067

Cumulative Model Updates: 149,156
Cumulative Timesteps: 1,244,039,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.62898
Policy Entropy: 3.02107
Value Function Loss: 0.00464

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.59771
Value Function Update Magnitude: 0.53675

Collected Steps per Second: 23,378.30649
Overall Steps per Second: 10,803.75462

Timestep Collection Time: 2.13873
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.62802

Cumulative Model Updates: 149,162
Cumulative Timesteps: 1,244,089,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1244089980...
Checkpoint 1244089980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.80903
Policy Entropy: 3.01501
Value Function Loss: 0.00472

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.60345
Value Function Update Magnitude: 0.54538

Collected Steps per Second: 22,568.72121
Overall Steps per Second: 10,671.09585

Timestep Collection Time: 2.21590
Timestep Consumption Time: 2.47059
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.68649

Cumulative Model Updates: 149,168
Cumulative Timesteps: 1,244,139,990

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,975.67588
Policy Entropy: 3.02640
Value Function Loss: 0.00439

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.59680
Value Function Update Magnitude: 0.56333

Collected Steps per Second: 21,240.89544
Overall Steps per Second: 10,401.51391

Timestep Collection Time: 2.35423
Timestep Consumption Time: 2.45334
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.80757

Cumulative Model Updates: 149,174
Cumulative Timesteps: 1,244,189,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1244189996...
Checkpoint 1244189996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.88174
Policy Entropy: 3.03781
Value Function Loss: 0.00452

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.59169
Value Function Update Magnitude: 0.56143

Collected Steps per Second: 22,564.01660
Overall Steps per Second: 10,762.79190

Timestep Collection Time: 2.21680
Timestep Consumption Time: 2.43069
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.64749

Cumulative Model Updates: 149,180
Cumulative Timesteps: 1,244,240,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.06979
Policy Entropy: 3.04809
Value Function Loss: 0.00432

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.59078
Value Function Update Magnitude: 0.54685

Collected Steps per Second: 22,828.55587
Overall Steps per Second: 10,794.97679

Timestep Collection Time: 2.19033
Timestep Consumption Time: 2.44164
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.63197

Cumulative Model Updates: 149,186
Cumulative Timesteps: 1,244,290,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1244290018...
Checkpoint 1244290018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,195.66407
Policy Entropy: 3.04610
Value Function Loss: 0.00418

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.58063
Value Function Update Magnitude: 0.54512

Collected Steps per Second: 23,034.00015
Overall Steps per Second: 10,700.08625

Timestep Collection Time: 2.17175
Timestep Consumption Time: 2.50336
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.67510

Cumulative Model Updates: 149,192
Cumulative Timesteps: 1,244,340,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.60993
Policy Entropy: 3.04837
Value Function Loss: 0.00403

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.57876
Value Function Update Magnitude: 0.53281

Collected Steps per Second: 23,206.23487
Overall Steps per Second: 10,885.59999

Timestep Collection Time: 2.15554
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.59525

Cumulative Model Updates: 149,198
Cumulative Timesteps: 1,244,390,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1244390064...
Checkpoint 1244390064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.18101
Policy Entropy: 3.05089
Value Function Loss: 0.00388

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.57942
Value Function Update Magnitude: 0.52520

Collected Steps per Second: 22,878.49478
Overall Steps per Second: 10,770.04463

Timestep Collection Time: 2.18659
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.64492

Cumulative Model Updates: 149,204
Cumulative Timesteps: 1,244,440,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,348.27017
Policy Entropy: 3.04813
Value Function Loss: 0.00422

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.51836

Collected Steps per Second: 23,618.60398
Overall Steps per Second: 10,758.49428

Timestep Collection Time: 2.11757
Timestep Consumption Time: 2.53122
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.64879

Cumulative Model Updates: 149,210
Cumulative Timesteps: 1,244,490,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1244490104...
Checkpoint 1244490104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,143.59903
Policy Entropy: 3.02441
Value Function Loss: 0.00442

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.60248
Value Function Update Magnitude: 0.53990

Collected Steps per Second: 22,835.51425
Overall Steps per Second: 10,654.34396

Timestep Collection Time: 2.19001
Timestep Consumption Time: 2.50385
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.69386

Cumulative Model Updates: 149,216
Cumulative Timesteps: 1,244,540,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.57976
Policy Entropy: 3.00601
Value Function Loss: 0.00455

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.60120
Value Function Update Magnitude: 0.54324

Collected Steps per Second: 23,405.11645
Overall Steps per Second: 10,943.37315

Timestep Collection Time: 2.13723
Timestep Consumption Time: 2.43376
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.57099

Cumulative Model Updates: 149,222
Cumulative Timesteps: 1,244,590,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1244590136...
Checkpoint 1244590136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.02404
Policy Entropy: 3.02045
Value Function Loss: 0.00461

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.60019
Value Function Update Magnitude: 0.53163

Collected Steps per Second: 22,721.24685
Overall Steps per Second: 10,632.35649

Timestep Collection Time: 2.20111
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.70375

Cumulative Model Updates: 149,228
Cumulative Timesteps: 1,244,640,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,232.62540
Policy Entropy: 3.02764
Value Function Loss: 0.00463

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.59211
Value Function Update Magnitude: 0.53743

Collected Steps per Second: 22,871.49801
Overall Steps per Second: 10,823.60721

Timestep Collection Time: 2.18665
Timestep Consumption Time: 2.43399
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62064

Cumulative Model Updates: 149,234
Cumulative Timesteps: 1,244,690,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1244690160...
Checkpoint 1244690160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078.81191
Policy Entropy: 3.03715
Value Function Loss: 0.00453

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.59471
Value Function Update Magnitude: 0.55430

Collected Steps per Second: 22,741.54558
Overall Steps per Second: 10,719.95098

Timestep Collection Time: 2.19871
Timestep Consumption Time: 2.46568
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.66439

Cumulative Model Updates: 149,240
Cumulative Timesteps: 1,244,740,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731.21417
Policy Entropy: 3.01968
Value Function Loss: 0.00459

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.60326
Value Function Update Magnitude: 0.56945

Collected Steps per Second: 22,608.56796
Overall Steps per Second: 10,799.45161

Timestep Collection Time: 2.21190
Timestep Consumption Time: 2.41870
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.63061

Cumulative Model Updates: 149,246
Cumulative Timesteps: 1,244,790,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1244790170...
Checkpoint 1244790170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.25460
Policy Entropy: 3.01735
Value Function Loss: 0.00462

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.59687
Value Function Update Magnitude: 0.55357

Collected Steps per Second: 22,634.27522
Overall Steps per Second: 10,691.04693

Timestep Collection Time: 2.20983
Timestep Consumption Time: 2.46866
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.67849

Cumulative Model Updates: 149,252
Cumulative Timesteps: 1,244,840,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.78294
Policy Entropy: 3.02355
Value Function Loss: 0.00437

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.58036
Value Function Update Magnitude: 0.50260

Collected Steps per Second: 23,203.98463
Overall Steps per Second: 10,853.92046

Timestep Collection Time: 2.15506
Timestep Consumption Time: 2.45212
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.60718

Cumulative Model Updates: 149,258
Cumulative Timesteps: 1,244,890,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1244890194...
Checkpoint 1244890194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.09261
Policy Entropy: 3.01809
Value Function Loss: 0.00441

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.57790
Value Function Update Magnitude: 0.49091

Collected Steps per Second: 22,586.45230
Overall Steps per Second: 10,728.44968

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.44718
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.66125

Cumulative Model Updates: 149,264
Cumulative Timesteps: 1,244,940,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.27362
Policy Entropy: 3.03702
Value Function Loss: 0.00417

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.51527

Collected Steps per Second: 23,347.01984
Overall Steps per Second: 10,933.94105

Timestep Collection Time: 2.14340
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.57676

Cumulative Model Updates: 149,270
Cumulative Timesteps: 1,244,990,244

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1244990244...
Checkpoint 1244990244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,242.12256
Policy Entropy: 3.01460
Value Function Loss: 0.00425

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.57792
Value Function Update Magnitude: 0.52473

Collected Steps per Second: 23,008.89972
Overall Steps per Second: 10,701.07925

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.49985
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.67336

Cumulative Model Updates: 149,276
Cumulative Timesteps: 1,245,040,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.24647
Policy Entropy: 3.02331
Value Function Loss: 0.00414

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.56925
Value Function Update Magnitude: 0.50290

Collected Steps per Second: 23,347.20189
Overall Steps per Second: 10,806.46608

Timestep Collection Time: 2.14218
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.62815

Cumulative Model Updates: 149,282
Cumulative Timesteps: 1,245,090,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1245090268...
Checkpoint 1245090268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278.44990
Policy Entropy: 3.01012
Value Function Loss: 0.00442

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.58256
Value Function Update Magnitude: 0.49863

Collected Steps per Second: 22,289.98205
Overall Steps per Second: 10,674.83979

Timestep Collection Time: 2.24325
Timestep Consumption Time: 2.44085
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.68410

Cumulative Model Updates: 149,288
Cumulative Timesteps: 1,245,140,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,467.91002
Policy Entropy: 3.02839
Value Function Loss: 0.00436

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.51441

Collected Steps per Second: 23,101.96755
Overall Steps per Second: 10,960.46990

Timestep Collection Time: 2.16501
Timestep Consumption Time: 2.39830
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.56331

Cumulative Model Updates: 149,294
Cumulative Timesteps: 1,245,190,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1245190286...
Checkpoint 1245190286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,551.67375
Policy Entropy: 3.03093
Value Function Loss: 0.00451

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.50826

Collected Steps per Second: 22,942.36733
Overall Steps per Second: 10,672.50209

Timestep Collection Time: 2.17955
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.68531

Cumulative Model Updates: 149,300
Cumulative Timesteps: 1,245,240,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.01683
Policy Entropy: 3.03266
Value Function Loss: 0.00461

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.58438
Value Function Update Magnitude: 0.49735

Collected Steps per Second: 23,171.92873
Overall Steps per Second: 10,800.68708

Timestep Collection Time: 2.15882
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.63156

Cumulative Model Updates: 149,306
Cumulative Timesteps: 1,245,290,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1245290314...
Checkpoint 1245290314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,468.61827
Policy Entropy: 3.03805
Value Function Loss: 0.00463

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.59068
Value Function Update Magnitude: 0.51387

Collected Steps per Second: 23,146.17453
Overall Steps per Second: 10,745.18916

Timestep Collection Time: 2.16044
Timestep Consumption Time: 2.49336
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.65380

Cumulative Model Updates: 149,312
Cumulative Timesteps: 1,245,340,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,311.77542
Policy Entropy: 3.03756
Value Function Loss: 0.00445

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.58176
Value Function Update Magnitude: 0.51609

Collected Steps per Second: 23,572.09265
Overall Steps per Second: 10,787.86818

Timestep Collection Time: 2.12141
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.63539

Cumulative Model Updates: 149,318
Cumulative Timesteps: 1,245,390,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1245390326...
Checkpoint 1245390326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,407.31093
Policy Entropy: 3.02023
Value Function Loss: 0.00445

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.57946
Value Function Update Magnitude: 0.49741

Collected Steps per Second: 22,746.75684
Overall Steps per Second: 10,659.58744

Timestep Collection Time: 2.19899
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.69249

Cumulative Model Updates: 149,324
Cumulative Timesteps: 1,245,440,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,863.05596
Policy Entropy: 3.02835
Value Function Loss: 0.00431

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.57907
Value Function Update Magnitude: 0.48754

Collected Steps per Second: 23,547.63606
Overall Steps per Second: 10,888.03865

Timestep Collection Time: 2.12412
Timestep Consumption Time: 2.46973
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.59385

Cumulative Model Updates: 149,330
Cumulative Timesteps: 1,245,490,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1245490364...
Checkpoint 1245490364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.67000
Policy Entropy: 3.03378
Value Function Loss: 0.00429

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.50634

Collected Steps per Second: 22,897.37565
Overall Steps per Second: 10,657.90334

Timestep Collection Time: 2.18392
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.69192

Cumulative Model Updates: 149,336
Cumulative Timesteps: 1,245,540,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,659.07495
Policy Entropy: 3.04874
Value Function Loss: 0.00440

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.58716
Value Function Update Magnitude: 0.51981

Collected Steps per Second: 23,022.81313
Overall Steps per Second: 10,844.15508

Timestep Collection Time: 2.17185
Timestep Consumption Time: 2.43912
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61096

Cumulative Model Updates: 149,342
Cumulative Timesteps: 1,245,590,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1245590372...
Checkpoint 1245590372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.69403
Policy Entropy: 3.04352
Value Function Loss: 0.00425

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.57676
Value Function Update Magnitude: 0.50910

Collected Steps per Second: 22,468.71565
Overall Steps per Second: 10,743.86564

Timestep Collection Time: 2.22576
Timestep Consumption Time: 2.42899
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.65475

Cumulative Model Updates: 149,348
Cumulative Timesteps: 1,245,640,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,786.91918
Policy Entropy: 3.03660
Value Function Loss: 0.00420

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.48134

Collected Steps per Second: 22,859.14064
Overall Steps per Second: 10,899.03536

Timestep Collection Time: 2.18871
Timestep Consumption Time: 2.40179
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.59050

Cumulative Model Updates: 149,354
Cumulative Timesteps: 1,245,690,414

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1245690414...
Checkpoint 1245690414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,360.94941
Policy Entropy: 3.01733
Value Function Loss: 0.00423

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.56325
Value Function Update Magnitude: 0.47650

Collected Steps per Second: 22,120.36561
Overall Steps per Second: 10,640.80207

Timestep Collection Time: 2.26181
Timestep Consumption Time: 2.44009
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.70190

Cumulative Model Updates: 149,360
Cumulative Timesteps: 1,245,740,446

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.38428
Policy Entropy: 3.01504
Value Function Loss: 0.00426

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.56966
Value Function Update Magnitude: 0.48405

Collected Steps per Second: 22,846.08207
Overall Steps per Second: 10,814.45023

Timestep Collection Time: 2.18987
Timestep Consumption Time: 2.43635
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.62622

Cumulative Model Updates: 149,366
Cumulative Timesteps: 1,245,790,476

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1245790476...
Checkpoint 1245790476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,003.22385
Policy Entropy: 3.01925
Value Function Loss: 0.00452

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.57927
Value Function Update Magnitude: 0.49983

Collected Steps per Second: 22,425.01685
Overall Steps per Second: 10,722.97844

Timestep Collection Time: 2.22983
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.66326

Cumulative Model Updates: 149,372
Cumulative Timesteps: 1,245,840,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,884.58740
Policy Entropy: 3.02241
Value Function Loss: 0.00431

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.58462
Value Function Update Magnitude: 0.50012

Collected Steps per Second: 23,378.73048
Overall Steps per Second: 10,898.64221

Timestep Collection Time: 2.13921
Timestep Consumption Time: 2.44962
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.58883

Cumulative Model Updates: 149,378
Cumulative Timesteps: 1,245,890,492

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1245890492...
Checkpoint 1245890492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.40709
Policy Entropy: 2.99680
Value Function Loss: 0.00460

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.58545
Value Function Update Magnitude: 0.50377

Collected Steps per Second: 22,937.56984
Overall Steps per Second: 10,650.21770

Timestep Collection Time: 2.18079
Timestep Consumption Time: 2.51602
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.69681

Cumulative Model Updates: 149,384
Cumulative Timesteps: 1,245,940,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,541.56531
Policy Entropy: 2.98406
Value Function Loss: 0.00443

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.59114
Value Function Update Magnitude: 0.51223

Collected Steps per Second: 23,187.45993
Overall Steps per Second: 10,872.52467

Timestep Collection Time: 2.15737
Timestep Consumption Time: 2.44358
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60096

Cumulative Model Updates: 149,390
Cumulative Timesteps: 1,245,990,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1245990538...
Checkpoint 1245990538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.76746
Policy Entropy: 2.98459
Value Function Loss: 0.00452

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.59182
Value Function Update Magnitude: 0.51876

Collected Steps per Second: 22,989.00017
Overall Steps per Second: 10,679.57393

Timestep Collection Time: 2.17600
Timestep Consumption Time: 2.50808
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.68408

Cumulative Model Updates: 149,396
Cumulative Timesteps: 1,246,040,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.86292
Policy Entropy: 3.00141
Value Function Loss: 0.00444

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.58524
Value Function Update Magnitude: 0.52533

Collected Steps per Second: 23,160.60945
Overall Steps per Second: 10,811.36302

Timestep Collection Time: 2.16039
Timestep Consumption Time: 2.46770
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.62809

Cumulative Model Updates: 149,402
Cumulative Timesteps: 1,246,090,598

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1246090598...
Checkpoint 1246090598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,346.42391
Policy Entropy: 3.01842
Value Function Loss: 0.00450

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.58726
Value Function Update Magnitude: 0.51292

Collected Steps per Second: 22,882.62736
Overall Steps per Second: 10,715.63034

Timestep Collection Time: 2.18611
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.66832

Cumulative Model Updates: 149,408
Cumulative Timesteps: 1,246,140,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,556.13946
Policy Entropy: 3.02383
Value Function Loss: 0.00430

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.58424
Value Function Update Magnitude: 0.49626

Collected Steps per Second: 22,703.27067
Overall Steps per Second: 10,654.66546

Timestep Collection Time: 2.20303
Timestep Consumption Time: 2.49125
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.69428

Cumulative Model Updates: 149,414
Cumulative Timesteps: 1,246,190,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1246190638...
Checkpoint 1246190638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.67498
Policy Entropy: 3.01577
Value Function Loss: 0.00422

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.57697
Value Function Update Magnitude: 0.50380

Collected Steps per Second: 22,694.39224
Overall Steps per Second: 10,669.68061

Timestep Collection Time: 2.20433
Timestep Consumption Time: 2.48428
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.68861

Cumulative Model Updates: 149,420
Cumulative Timesteps: 1,246,240,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.45830
Policy Entropy: 3.00961
Value Function Loss: 0.00411

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.58564
Value Function Update Magnitude: 0.51688

Collected Steps per Second: 22,949.73115
Overall Steps per Second: 10,679.78701

Timestep Collection Time: 2.18042
Timestep Consumption Time: 2.50507
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.68549

Cumulative Model Updates: 149,426
Cumulative Timesteps: 1,246,290,704

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1246290704...
Checkpoint 1246290704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.32754
Policy Entropy: 3.00744
Value Function Loss: 0.00411

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.58675
Value Function Update Magnitude: 0.51841

Collected Steps per Second: 22,751.37258
Overall Steps per Second: 10,656.13964

Timestep Collection Time: 2.19890
Timestep Consumption Time: 2.49586
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.69476

Cumulative Model Updates: 149,432
Cumulative Timesteps: 1,246,340,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,811.39166
Policy Entropy: 3.01777
Value Function Loss: 0.00411

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.57906
Value Function Update Magnitude: 0.50748

Collected Steps per Second: 23,078.82297
Overall Steps per Second: 10,839.21207

Timestep Collection Time: 2.16692
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61380

Cumulative Model Updates: 149,438
Cumulative Timesteps: 1,246,390,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1246390742...
Checkpoint 1246390742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060.99085
Policy Entropy: 3.03518
Value Function Loss: 0.00436

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.58109
Value Function Update Magnitude: 0.50130

Collected Steps per Second: 23,039.51046
Overall Steps per Second: 10,675.71945

Timestep Collection Time: 2.17018
Timestep Consumption Time: 2.51334
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.68353

Cumulative Model Updates: 149,444
Cumulative Timesteps: 1,246,440,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,220.79654
Policy Entropy: 3.03982
Value Function Loss: 0.00460

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11286
Policy Update Magnitude: 0.59120
Value Function Update Magnitude: 0.52185

Collected Steps per Second: 23,008.61123
Overall Steps per Second: 10,840.10253

Timestep Collection Time: 2.17371
Timestep Consumption Time: 2.44009
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.61379

Cumulative Model Updates: 149,450
Cumulative Timesteps: 1,246,490,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1246490756...
Checkpoint 1246490756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,707.74355
Policy Entropy: 3.03600
Value Function Loss: 0.00438

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.54187

Collected Steps per Second: 22,775.10352
Overall Steps per Second: 10,738.88468

Timestep Collection Time: 2.19652
Timestep Consumption Time: 2.46188
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.65840

Cumulative Model Updates: 149,456
Cumulative Timesteps: 1,246,540,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180.60011
Policy Entropy: 3.02254
Value Function Loss: 0.00437

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.58593
Value Function Update Magnitude: 0.55194

Collected Steps per Second: 23,352.60723
Overall Steps per Second: 10,930.90695

Timestep Collection Time: 2.14177
Timestep Consumption Time: 2.43388
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.57565

Cumulative Model Updates: 149,462
Cumulative Timesteps: 1,246,590,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1246590798...
Checkpoint 1246590798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,061.45987
Policy Entropy: 3.01044
Value Function Loss: 0.00484

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.59860
Value Function Update Magnitude: 0.55639

Collected Steps per Second: 23,065.75238
Overall Steps per Second: 10,716.67221

Timestep Collection Time: 2.16893
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.66824

Cumulative Model Updates: 149,468
Cumulative Timesteps: 1,246,640,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.99815
Policy Entropy: 3.01066
Value Function Loss: 0.00495

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.60491
Value Function Update Magnitude: 0.57224

Collected Steps per Second: 22,802.96280
Overall Steps per Second: 10,780.55043

Timestep Collection Time: 2.19357
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.63984

Cumulative Model Updates: 149,474
Cumulative Timesteps: 1,246,690,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1246690846...
Checkpoint 1246690846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.36261
Policy Entropy: 3.02354
Value Function Loss: 0.00477

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.59177
Value Function Update Magnitude: 0.55873

Collected Steps per Second: 22,011.73921
Overall Steps per Second: 10,681.50431

Timestep Collection Time: 2.27288
Timestep Consumption Time: 2.41092
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.68380

Cumulative Model Updates: 149,480
Cumulative Timesteps: 1,246,740,876

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.56234
Policy Entropy: 3.03507
Value Function Loss: 0.00450

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.58921
Value Function Update Magnitude: 0.53648

Collected Steps per Second: 22,985.44220
Overall Steps per Second: 10,876.09629

Timestep Collection Time: 2.17538
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.59742

Cumulative Model Updates: 149,486
Cumulative Timesteps: 1,246,790,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1246790878...
Checkpoint 1246790878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.54117
Policy Entropy: 3.04012
Value Function Loss: 0.00449

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.58984
Value Function Update Magnitude: 0.52729

Collected Steps per Second: 23,021.03988
Overall Steps per Second: 10,649.92572

Timestep Collection Time: 2.17236
Timestep Consumption Time: 2.52345
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.69581

Cumulative Model Updates: 149,492
Cumulative Timesteps: 1,246,840,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.50719
Policy Entropy: 3.03598
Value Function Loss: 0.00457

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.59514
Value Function Update Magnitude: 0.53142

Collected Steps per Second: 23,405.16559
Overall Steps per Second: 10,895.36298

Timestep Collection Time: 2.13637
Timestep Consumption Time: 2.45293
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.58929

Cumulative Model Updates: 149,498
Cumulative Timesteps: 1,246,890,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1246890890...
Checkpoint 1246890890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.14095
Policy Entropy: 3.03740
Value Function Loss: 0.00469

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.59850
Value Function Update Magnitude: 0.53164

Collected Steps per Second: 23,072.79590
Overall Steps per Second: 10,689.64629

Timestep Collection Time: 2.16818
Timestep Consumption Time: 2.51167
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.67986

Cumulative Model Updates: 149,504
Cumulative Timesteps: 1,246,940,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.69014
Policy Entropy: 3.03137
Value Function Loss: 0.00478

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.60049
Value Function Update Magnitude: 0.54843

Collected Steps per Second: 23,224.68471
Overall Steps per Second: 10,923.90894

Timestep Collection Time: 2.15426
Timestep Consumption Time: 2.42579
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.58005

Cumulative Model Updates: 149,510
Cumulative Timesteps: 1,246,990,948

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1246990948...
Checkpoint 1246990948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.05736
Policy Entropy: 3.03660
Value Function Loss: 0.00443

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.59613
Value Function Update Magnitude: 0.56725

Collected Steps per Second: 22,970.42596
Overall Steps per Second: 10,778.43679

Timestep Collection Time: 2.17732
Timestep Consumption Time: 2.46287
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.64019

Cumulative Model Updates: 149,516
Cumulative Timesteps: 1,247,040,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.69504
Policy Entropy: 3.03968
Value Function Loss: 0.00423

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.58621
Value Function Update Magnitude: 0.54657

Collected Steps per Second: 23,194.05540
Overall Steps per Second: 10,803.49965

Timestep Collection Time: 2.15667
Timestep Consumption Time: 2.47349
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.63017

Cumulative Model Updates: 149,522
Cumulative Timesteps: 1,247,090,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1247090984...
Checkpoint 1247090984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,572.04741
Policy Entropy: 3.03917
Value Function Loss: 0.00426

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.59612
Value Function Update Magnitude: 0.56112

Collected Steps per Second: 22,755.57565
Overall Steps per Second: 10,623.07822

Timestep Collection Time: 2.19805
Timestep Consumption Time: 2.51037
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.70843

Cumulative Model Updates: 149,528
Cumulative Timesteps: 1,247,141,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.64397
Policy Entropy: 3.03588
Value Function Loss: 0.00402

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.59624
Value Function Update Magnitude: 0.55694

Collected Steps per Second: 22,859.27840
Overall Steps per Second: 10,823.00619

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.43298
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62071

Cumulative Model Updates: 149,534
Cumulative Timesteps: 1,247,191,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1247191012...
Checkpoint 1247191012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.29206
Policy Entropy: 3.04661
Value Function Loss: 0.00383

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.58837
Value Function Update Magnitude: 0.52726

Collected Steps per Second: 22,722.04522
Overall Steps per Second: 10,719.31683

Timestep Collection Time: 2.20077
Timestep Consumption Time: 2.46427
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.66504

Cumulative Model Updates: 149,540
Cumulative Timesteps: 1,247,241,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,243.99954
Policy Entropy: 3.04666
Value Function Loss: 0.00397

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.58258
Value Function Update Magnitude: 0.50442

Collected Steps per Second: 23,101.86950
Overall Steps per Second: 10,782.81397

Timestep Collection Time: 2.16563
Timestep Consumption Time: 2.47417
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.63979

Cumulative Model Updates: 149,546
Cumulative Timesteps: 1,247,291,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1247291048...
Checkpoint 1247291048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.52170
Policy Entropy: 3.04417
Value Function Loss: 0.00413

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.50606

Collected Steps per Second: 22,901.68590
Overall Steps per Second: 10,720.88478

Timestep Collection Time: 2.18447
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.66641

Cumulative Model Updates: 149,552
Cumulative Timesteps: 1,247,341,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.13810
Policy Entropy: 3.02830
Value Function Loss: 0.00456

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.59438
Value Function Update Magnitude: 0.52415

Collected Steps per Second: 23,193.82473
Overall Steps per Second: 10,990.54761

Timestep Collection Time: 2.15626
Timestep Consumption Time: 2.39419
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.55046

Cumulative Model Updates: 149,558
Cumulative Timesteps: 1,247,391,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1247391088...
Checkpoint 1247391088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,261.41603
Policy Entropy: 3.03344
Value Function Loss: 0.00434

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.59447
Value Function Update Magnitude: 0.53554

Collected Steps per Second: 23,048.33858
Overall Steps per Second: 10,959.78232

Timestep Collection Time: 2.17057
Timestep Consumption Time: 2.39412
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.56469

Cumulative Model Updates: 149,564
Cumulative Timesteps: 1,247,441,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.67536
Policy Entropy: 3.02985
Value Function Loss: 0.00454

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.59067
Value Function Update Magnitude: 0.54677

Collected Steps per Second: 23,287.88693
Overall Steps per Second: 10,959.38496

Timestep Collection Time: 2.14721
Timestep Consumption Time: 2.41545
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.56266

Cumulative Model Updates: 149,570
Cumulative Timesteps: 1,247,491,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1247491120...
Checkpoint 1247491120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841.95845
Policy Entropy: 3.02988
Value Function Loss: 0.00462

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.60758
Value Function Update Magnitude: 0.55487

Collected Steps per Second: 22,977.52108
Overall Steps per Second: 10,684.02768

Timestep Collection Time: 2.17691
Timestep Consumption Time: 2.50484
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.68175

Cumulative Model Updates: 149,576
Cumulative Timesteps: 1,247,541,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,299.55671
Policy Entropy: 3.03483
Value Function Loss: 0.00487

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.61125
Value Function Update Magnitude: 0.57263

Collected Steps per Second: 22,770.29860
Overall Steps per Second: 10,798.21475

Timestep Collection Time: 2.19619
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.63114

Cumulative Model Updates: 149,582
Cumulative Timesteps: 1,247,591,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1247591148...
Checkpoint 1247591148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.50023
Policy Entropy: 3.04115
Value Function Loss: 0.00500

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.60937
Value Function Update Magnitude: 0.56482

Collected Steps per Second: 22,473.08637
Overall Steps per Second: 10,762.63436

Timestep Collection Time: 2.22568
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.64738

Cumulative Model Updates: 149,588
Cumulative Timesteps: 1,247,641,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.49649
Policy Entropy: 3.05201
Value Function Loss: 0.00492

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.60184
Value Function Update Magnitude: 0.55038

Collected Steps per Second: 22,958.70870
Overall Steps per Second: 10,853.48400

Timestep Collection Time: 2.17896
Timestep Consumption Time: 2.43026
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60921

Cumulative Model Updates: 149,594
Cumulative Timesteps: 1,247,691,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1247691192...
Checkpoint 1247691192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,161.53554
Policy Entropy: 3.03767
Value Function Loss: 0.00477

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.59175
Value Function Update Magnitude: 0.54835

Collected Steps per Second: 22,659.53103
Overall Steps per Second: 10,649.07655

Timestep Collection Time: 2.20658
Timestep Consumption Time: 2.48867
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69524

Cumulative Model Updates: 149,600
Cumulative Timesteps: 1,247,741,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,235.67561
Policy Entropy: 3.03399
Value Function Loss: 0.00475

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.59770
Value Function Update Magnitude: 0.54560

Collected Steps per Second: 23,361.74742
Overall Steps per Second: 10,888.41908

Timestep Collection Time: 2.14145
Timestep Consumption Time: 2.45316
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.59461

Cumulative Model Updates: 149,606
Cumulative Timesteps: 1,247,791,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1247791220...
Checkpoint 1247791220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.97966
Policy Entropy: 3.02797
Value Function Loss: 0.00473

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.60492
Value Function Update Magnitude: 0.56032

Collected Steps per Second: 23,088.82575
Overall Steps per Second: 10,805.06504

Timestep Collection Time: 2.16668
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.62987

Cumulative Model Updates: 149,612
Cumulative Timesteps: 1,247,841,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748.23748
Policy Entropy: 3.03431
Value Function Loss: 0.00442

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.59623
Value Function Update Magnitude: 0.55280

Collected Steps per Second: 23,388.98759
Overall Steps per Second: 10,826.31855

Timestep Collection Time: 2.13776
Timestep Consumption Time: 2.48062
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.61838

Cumulative Model Updates: 149,618
Cumulative Timesteps: 1,247,891,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1247891246...
Checkpoint 1247891246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,772.69736
Policy Entropy: 3.03336
Value Function Loss: 0.00426

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.58666
Value Function Update Magnitude: 0.54055

Collected Steps per Second: 22,821.53434
Overall Steps per Second: 10,662.95122

Timestep Collection Time: 2.19100
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.68932

Cumulative Model Updates: 149,624
Cumulative Timesteps: 1,247,941,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.39172
Policy Entropy: 3.03920
Value Function Loss: 0.00430

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.58123
Value Function Update Magnitude: 0.52396

Collected Steps per Second: 23,197.01877
Overall Steps per Second: 10,860.24582

Timestep Collection Time: 2.15597
Timestep Consumption Time: 2.44909
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.60505

Cumulative Model Updates: 149,630
Cumulative Timesteps: 1,247,991,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1247991260...
Checkpoint 1247991260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.53931
Policy Entropy: 3.04893
Value Function Loss: 0.00451

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11018
Policy Update Magnitude: 0.58456
Value Function Update Magnitude: 0.52182

Collected Steps per Second: 22,176.65594
Overall Steps per Second: 10,673.20069

Timestep Collection Time: 2.25562
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.68669

Cumulative Model Updates: 149,636
Cumulative Timesteps: 1,248,041,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.81861
Policy Entropy: 3.06860
Value Function Loss: 0.00441

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.57827
Value Function Update Magnitude: 0.52070

Collected Steps per Second: 22,546.72891
Overall Steps per Second: 10,746.39454

Timestep Collection Time: 2.21788
Timestep Consumption Time: 2.43540
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.65328

Cumulative Model Updates: 149,642
Cumulative Timesteps: 1,248,091,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1248091288...
Checkpoint 1248091288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.27425
Policy Entropy: 3.06798
Value Function Loss: 0.00469

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.58178
Value Function Update Magnitude: 0.52544

Collected Steps per Second: 22,481.63352
Overall Steps per Second: 10,715.23314

Timestep Collection Time: 2.22537
Timestep Consumption Time: 2.44368
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.66905

Cumulative Model Updates: 149,648
Cumulative Timesteps: 1,248,141,318

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.07309
Policy Entropy: 3.06829
Value Function Loss: 0.00451

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.58911
Value Function Update Magnitude: 0.50367

Collected Steps per Second: 22,838.83828
Overall Steps per Second: 10,677.27013

Timestep Collection Time: 2.18987
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.68416

Cumulative Model Updates: 149,654
Cumulative Timesteps: 1,248,191,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1248191332...
Checkpoint 1248191332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.64930
Policy Entropy: 3.06528
Value Function Loss: 0.00451

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.58515
Value Function Update Magnitude: 0.50551

Collected Steps per Second: 22,836.60609
Overall Steps per Second: 10,676.78176

Timestep Collection Time: 2.18947
Timestep Consumption Time: 2.49359
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.68306

Cumulative Model Updates: 149,660
Cumulative Timesteps: 1,248,241,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210.85488
Policy Entropy: 3.06075
Value Function Loss: 0.00422

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.57640
Value Function Update Magnitude: 0.50308

Collected Steps per Second: 23,200.20561
Overall Steps per Second: 10,732.00798

Timestep Collection Time: 2.15636
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.66157

Cumulative Model Updates: 149,666
Cumulative Timesteps: 1,248,291,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1248291360...
Checkpoint 1248291360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.61242
Policy Entropy: 3.05677
Value Function Loss: 0.00491

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.58715
Value Function Update Magnitude: 0.49987

Collected Steps per Second: 22,922.69966
Overall Steps per Second: 10,900.37052

Timestep Collection Time: 2.18185
Timestep Consumption Time: 2.40643
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.58828

Cumulative Model Updates: 149,672
Cumulative Timesteps: 1,248,341,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.07676
Policy Entropy: 3.05138
Value Function Loss: 0.00495

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.59535
Value Function Update Magnitude: 0.52195

Collected Steps per Second: 23,409.45314
Overall Steps per Second: 10,926.84187

Timestep Collection Time: 2.13666
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.57753

Cumulative Model Updates: 149,678
Cumulative Timesteps: 1,248,391,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1248391392...
Checkpoint 1248391392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.61959
Policy Entropy: 3.04053
Value Function Loss: 0.00549

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.59416
Value Function Update Magnitude: 0.54871

Collected Steps per Second: 23,163.34287
Overall Steps per Second: 10,718.85932

Timestep Collection Time: 2.15962
Timestep Consumption Time: 2.50730
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.66691

Cumulative Model Updates: 149,684
Cumulative Timesteps: 1,248,441,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.18860
Policy Entropy: 3.04299
Value Function Loss: 0.00467

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.58963
Value Function Update Magnitude: 0.54815

Collected Steps per Second: 23,155.58028
Overall Steps per Second: 10,962.27042

Timestep Collection Time: 2.16060
Timestep Consumption Time: 2.40323
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.56384

Cumulative Model Updates: 149,690
Cumulative Timesteps: 1,248,491,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1248491446...
Checkpoint 1248491446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.96800
Policy Entropy: 3.05899
Value Function Loss: 0.00435

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.58363
Value Function Update Magnitude: 0.53990

Collected Steps per Second: 22,754.72890
Overall Steps per Second: 10,710.49312

Timestep Collection Time: 2.19805
Timestep Consumption Time: 2.47176
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.66981

Cumulative Model Updates: 149,696
Cumulative Timesteps: 1,248,541,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.45214
Policy Entropy: 3.06937
Value Function Loss: 0.00405

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10902
Policy Update Magnitude: 0.57194
Value Function Update Magnitude: 0.52577

Collected Steps per Second: 22,912.71198
Overall Steps per Second: 10,840.79645

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.43128
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.61461

Cumulative Model Updates: 149,702
Cumulative Timesteps: 1,248,591,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1248591488...
Checkpoint 1248591488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,922.80855
Policy Entropy: 3.06512
Value Function Loss: 0.00416

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.52227

Collected Steps per Second: 22,723.42601
Overall Steps per Second: 10,606.34959

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.51429
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.71510

Cumulative Model Updates: 149,708
Cumulative Timesteps: 1,248,641,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.98387
Policy Entropy: 3.04718
Value Function Loss: 0.00447

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.51182

Collected Steps per Second: 23,044.44518
Overall Steps per Second: 10,947.35941

Timestep Collection Time: 2.17033
Timestep Consumption Time: 2.39826
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.56859

Cumulative Model Updates: 149,714
Cumulative Timesteps: 1,248,691,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1248691512...
Checkpoint 1248691512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,883.04389
Policy Entropy: 3.04829
Value Function Loss: 0.00447

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.58793
Value Function Update Magnitude: 0.50011

Collected Steps per Second: 22,594.11743
Overall Steps per Second: 10,656.43690

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.48013
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.69406

Cumulative Model Updates: 149,720
Cumulative Timesteps: 1,248,741,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,353.68122
Policy Entropy: 3.04203
Value Function Loss: 0.00442

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.58099
Value Function Update Magnitude: 0.50768

Collected Steps per Second: 23,384.39061
Overall Steps per Second: 10,898.68130

Timestep Collection Time: 2.13929
Timestep Consumption Time: 2.45081
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.59010

Cumulative Model Updates: 149,726
Cumulative Timesteps: 1,248,791,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1248791560...
Checkpoint 1248791560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.93215
Policy Entropy: 3.04538
Value Function Loss: 0.00422

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.51471

Collected Steps per Second: 23,127.30419
Overall Steps per Second: 10,974.43521

Timestep Collection Time: 2.16212
Timestep Consumption Time: 2.39429
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.55641

Cumulative Model Updates: 149,732
Cumulative Timesteps: 1,248,841,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,263.19396
Policy Entropy: 3.05339
Value Function Loss: 0.00417

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.58529
Value Function Update Magnitude: 0.52024

Collected Steps per Second: 23,075.79402
Overall Steps per Second: 10,757.04494

Timestep Collection Time: 2.16790
Timestep Consumption Time: 2.48263
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.65053

Cumulative Model Updates: 149,738
Cumulative Timesteps: 1,248,891,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1248891590...
Checkpoint 1248891590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,237.36739
Policy Entropy: 3.05587
Value Function Loss: 0.00425

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.51077

Collected Steps per Second: 23,039.07326
Overall Steps per Second: 10,841.07813

Timestep Collection Time: 2.17135
Timestep Consumption Time: 2.44313
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.61449

Cumulative Model Updates: 149,744
Cumulative Timesteps: 1,248,941,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.27557
Policy Entropy: 3.05194
Value Function Loss: 0.00429

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.57299
Value Function Update Magnitude: 0.49090

Collected Steps per Second: 23,114.97879
Overall Steps per Second: 10,855.73057

Timestep Collection Time: 2.16440
Timestep Consumption Time: 2.44423
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.60863

Cumulative Model Updates: 149,750
Cumulative Timesteps: 1,248,991,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1248991646...
Checkpoint 1248991646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532.13719
Policy Entropy: 3.03237
Value Function Loss: 0.00446

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.57392
Value Function Update Magnitude: 0.48020

Collected Steps per Second: 22,682.40502
Overall Steps per Second: 10,791.29241

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.63540

Cumulative Model Updates: 149,756
Cumulative Timesteps: 1,249,041,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.37690
Policy Entropy: 3.02832
Value Function Loss: 0.00469

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.58643
Value Function Update Magnitude: 0.48851

Collected Steps per Second: 22,836.79144
Overall Steps per Second: 10,862.46778

Timestep Collection Time: 2.19076
Timestep Consumption Time: 2.41500
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.60577

Cumulative Model Updates: 149,762
Cumulative Timesteps: 1,249,091,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1249091698...
Checkpoint 1249091698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.72624
Policy Entropy: 3.04876
Value Function Loss: 0.00480

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.60060
Value Function Update Magnitude: 0.51033

Collected Steps per Second: 22,543.49968
Overall Steps per Second: 10,647.29398

Timestep Collection Time: 2.21820
Timestep Consumption Time: 2.47839
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.69659

Cumulative Model Updates: 149,768
Cumulative Timesteps: 1,249,141,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.04453
Policy Entropy: 3.05672
Value Function Loss: 0.00487

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.60377
Value Function Update Magnitude: 0.55084

Collected Steps per Second: 22,827.06658
Overall Steps per Second: 10,857.43529

Timestep Collection Time: 2.19161
Timestep Consumption Time: 2.41611
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.60772

Cumulative Model Updates: 149,774
Cumulative Timesteps: 1,249,191,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1249191732...
Checkpoint 1249191732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.62606
Policy Entropy: 3.05594
Value Function Loss: 0.00476

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.59780
Value Function Update Magnitude: 0.57058

Collected Steps per Second: 22,607.17933
Overall Steps per Second: 10,765.24113

Timestep Collection Time: 2.21222
Timestep Consumption Time: 2.43347
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.64569

Cumulative Model Updates: 149,780
Cumulative Timesteps: 1,249,241,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,242.17388
Policy Entropy: 3.04612
Value Function Loss: 0.00464

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11873
Policy Update Magnitude: 0.59226
Value Function Update Magnitude: 0.56878

Collected Steps per Second: 22,894.34348
Overall Steps per Second: 10,790.97399

Timestep Collection Time: 2.18430
Timestep Consumption Time: 2.44995
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.63424

Cumulative Model Updates: 149,786
Cumulative Timesteps: 1,249,291,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1249291752...
Checkpoint 1249291752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.27901
Policy Entropy: 3.06601
Value Function Loss: 0.00432

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.58510
Value Function Update Magnitude: 0.56754

Collected Steps per Second: 23,087.57803
Overall Steps per Second: 10,736.16388

Timestep Collection Time: 2.16584
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.65753

Cumulative Model Updates: 149,792
Cumulative Timesteps: 1,249,341,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,406.52251
Policy Entropy: 3.06433
Value Function Loss: 0.00408

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.58411
Value Function Update Magnitude: 0.53717

Collected Steps per Second: 22,114.76900
Overall Steps per Second: 10,428.49140

Timestep Collection Time: 2.26166
Timestep Consumption Time: 2.53444
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.79609

Cumulative Model Updates: 149,798
Cumulative Timesteps: 1,249,391,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1249391772...
Checkpoint 1249391772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.49739
Policy Entropy: 3.07060
Value Function Loss: 0.00417

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.58329
Value Function Update Magnitude: 0.53844

Collected Steps per Second: 23,158.62394
Overall Steps per Second: 10,973.04927

Timestep Collection Time: 2.16040
Timestep Consumption Time: 2.39913
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.55953

Cumulative Model Updates: 149,804
Cumulative Timesteps: 1,249,441,804

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.54070
Policy Entropy: 3.04308
Value Function Loss: 0.00430

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.58639
Value Function Update Magnitude: 0.53136

Collected Steps per Second: 23,236.11484
Overall Steps per Second: 10,781.77206

Timestep Collection Time: 2.15191
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.63764

Cumulative Model Updates: 149,810
Cumulative Timesteps: 1,249,491,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1249491806...
Checkpoint 1249491806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.12434
Policy Entropy: 3.05452
Value Function Loss: 0.00435

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.11853
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.52785

Collected Steps per Second: 23,074.44218
Overall Steps per Second: 10,910.91715

Timestep Collection Time: 2.16733
Timestep Consumption Time: 2.41615
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.58348

Cumulative Model Updates: 149,816
Cumulative Timesteps: 1,249,541,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.19079
Policy Entropy: 3.04859
Value Function Loss: 0.00441

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.58585
Value Function Update Magnitude: 0.53757

Collected Steps per Second: 22,719.77107
Overall Steps per Second: 10,823.90973

Timestep Collection Time: 2.20073
Timestep Consumption Time: 2.41868
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.61940

Cumulative Model Updates: 149,822
Cumulative Timesteps: 1,249,591,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1249591816...
Checkpoint 1249591816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.47084
Policy Entropy: 3.05031
Value Function Loss: 0.00462

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.59114
Value Function Update Magnitude: 0.53680

Collected Steps per Second: 22,200.62571
Overall Steps per Second: 10,741.55645

Timestep Collection Time: 2.25345
Timestep Consumption Time: 2.40398
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.65743

Cumulative Model Updates: 149,828
Cumulative Timesteps: 1,249,641,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.13274
Policy Entropy: 3.05600
Value Function Loss: 0.00468

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.60051
Value Function Update Magnitude: 0.53116

Collected Steps per Second: 22,730.88477
Overall Steps per Second: 10,795.00287

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.63455

Cumulative Model Updates: 149,834
Cumulative Timesteps: 1,249,691,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1249691874...
Checkpoint 1249691874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.28760
Policy Entropy: 3.06900
Value Function Loss: 0.00478

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.60108
Value Function Update Magnitude: 0.53933

Collected Steps per Second: 22,771.07559
Overall Steps per Second: 10,777.70270

Timestep Collection Time: 2.19709
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.64199

Cumulative Model Updates: 149,840
Cumulative Timesteps: 1,249,741,904

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.92398
Policy Entropy: 3.09006
Value Function Loss: 0.00451

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.59134
Value Function Update Magnitude: 0.55681

Collected Steps per Second: 23,202.86656
Overall Steps per Second: 10,799.37967

Timestep Collection Time: 2.15620
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.63267

Cumulative Model Updates: 149,846
Cumulative Timesteps: 1,249,791,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1249791934...
Checkpoint 1249791934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.07560
Policy Entropy: 3.08807
Value Function Loss: 0.00442

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.58402
Value Function Update Magnitude: 0.54788

Collected Steps per Second: 23,076.91846
Overall Steps per Second: 10,753.20212

Timestep Collection Time: 2.16719
Timestep Consumption Time: 2.48371
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.65089

Cumulative Model Updates: 149,852
Cumulative Timesteps: 1,249,841,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.30150
Policy Entropy: 3.08506
Value Function Loss: 0.00479

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.59168
Value Function Update Magnitude: 0.54827

Collected Steps per Second: 22,921.80892
Overall Steps per Second: 10,889.81586

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.41118
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.59347

Cumulative Model Updates: 149,858
Cumulative Timesteps: 1,249,891,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1249891968...
Checkpoint 1249891968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.43043
Policy Entropy: 3.08108
Value Function Loss: 0.00488

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.60241
Value Function Update Magnitude: 0.56613

Collected Steps per Second: 23,133.71159
Overall Steps per Second: 10,801.41849

Timestep Collection Time: 2.16256
Timestep Consumption Time: 2.46906
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.63161

Cumulative Model Updates: 149,864
Cumulative Timesteps: 1,249,941,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.74747
Policy Entropy: 3.08592
Value Function Loss: 0.00488

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10429
Policy Update Magnitude: 0.60108
Value Function Update Magnitude: 0.56813

Collected Steps per Second: 22,444.01763
Overall Steps per Second: 10,797.61777

Timestep Collection Time: 2.22830
Timestep Consumption Time: 2.40346
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.63176

Cumulative Model Updates: 149,870
Cumulative Timesteps: 1,249,992,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1249992008...
Checkpoint 1249992008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 882.06345
Policy Entropy: 3.07913
Value Function Loss: 0.00477

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.58753
Value Function Update Magnitude: 0.54516

Collected Steps per Second: 22,640.65418
Overall Steps per Second: 10,683.82893

Timestep Collection Time: 2.20877
Timestep Consumption Time: 2.47195
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.68072

Cumulative Model Updates: 149,876
Cumulative Timesteps: 1,250,042,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.79662
Policy Entropy: 3.07375
Value Function Loss: 0.00465

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.58555
Value Function Update Magnitude: 0.51991

Collected Steps per Second: 22,904.58368
Overall Steps per Second: 10,820.04328

Timestep Collection Time: 2.18358
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.62235

Cumulative Model Updates: 149,882
Cumulative Timesteps: 1,250,092,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1250092030...
Checkpoint 1250092030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.38960
Policy Entropy: 3.07523
Value Function Loss: 0.00460

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.57937
Value Function Update Magnitude: 0.51791

Collected Steps per Second: 22,985.49355
Overall Steps per Second: 10,657.13133

Timestep Collection Time: 2.17659
Timestep Consumption Time: 2.51792
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.69451

Cumulative Model Updates: 149,888
Cumulative Timesteps: 1,250,142,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.56247
Policy Entropy: 3.07152
Value Function Loss: 0.00446

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.57077
Value Function Update Magnitude: 0.51389

Collected Steps per Second: 23,448.95280
Overall Steps per Second: 10,879.66129

Timestep Collection Time: 2.13314
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.59757

Cumulative Model Updates: 149,894
Cumulative Timesteps: 1,250,192,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1250192080...
Checkpoint 1250192080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,364.48014
Policy Entropy: 3.06746
Value Function Loss: 0.00463

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.57917
Value Function Update Magnitude: 0.54247

Collected Steps per Second: 23,202.47179
Overall Steps per Second: 10,849.89366

Timestep Collection Time: 2.15572
Timestep Consumption Time: 2.45428
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.61000

Cumulative Model Updates: 149,900
Cumulative Timesteps: 1,250,242,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.87381
Policy Entropy: 3.05245
Value Function Loss: 0.00436

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.58527
Value Function Update Magnitude: 0.55182

Collected Steps per Second: 22,982.92345
Overall Steps per Second: 10,743.06123

Timestep Collection Time: 2.17683
Timestep Consumption Time: 2.48013
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.65696

Cumulative Model Updates: 149,906
Cumulative Timesteps: 1,250,292,128

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1250292128...
Checkpoint 1250292128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,826.86930
Policy Entropy: 3.08649
Value Function Loss: 0.00406

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.57168
Value Function Update Magnitude: 0.54565

Collected Steps per Second: 22,903.63826
Overall Steps per Second: 10,666.69124

Timestep Collection Time: 2.18315
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.68768

Cumulative Model Updates: 149,912
Cumulative Timesteps: 1,250,342,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.23341
Policy Entropy: 3.09609
Value Function Loss: 0.00410

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.56062
Value Function Update Magnitude: 0.52295

Collected Steps per Second: 23,048.89071
Overall Steps per Second: 10,853.36921

Timestep Collection Time: 2.16991
Timestep Consumption Time: 2.43825
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.60815

Cumulative Model Updates: 149,918
Cumulative Timesteps: 1,250,392,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1250392144...
Checkpoint 1250392144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,549.20043
Policy Entropy: 3.09732
Value Function Loss: 0.00430

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.56528
Value Function Update Magnitude: 0.52237

Collected Steps per Second: 23,018.82418
Overall Steps per Second: 10,746.24260

Timestep Collection Time: 2.17318
Timestep Consumption Time: 2.48184
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.65502

Cumulative Model Updates: 149,924
Cumulative Timesteps: 1,250,442,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.33857
Policy Entropy: 3.07880
Value Function Loss: 0.00423

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.52088

Collected Steps per Second: 22,887.03822
Overall Steps per Second: 10,926.36014

Timestep Collection Time: 2.18499
Timestep Consumption Time: 2.39183
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.57682

Cumulative Model Updates: 149,930
Cumulative Timesteps: 1,250,492,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1250492176...
Checkpoint 1250492176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,530.22876
Policy Entropy: 3.07945
Value Function Loss: 0.00393

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.55199
Value Function Update Magnitude: 0.50667

Collected Steps per Second: 22,739.34449
Overall Steps per Second: 10,635.38742

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.50325
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.70279

Cumulative Model Updates: 149,936
Cumulative Timesteps: 1,250,542,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.34370
Policy Entropy: 3.09636
Value Function Loss: 0.00405

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.48014

Collected Steps per Second: 22,630.48022
Overall Steps per Second: 10,766.43541

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.43543
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.64555

Cumulative Model Updates: 149,942
Cumulative Timesteps: 1,250,592,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1250592208...
Checkpoint 1250592208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.52017
Policy Entropy: 3.09632
Value Function Loss: 0.00432

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.47327

Collected Steps per Second: 22,689.02352
Overall Steps per Second: 10,692.33774

Timestep Collection Time: 2.20450
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.67793

Cumulative Model Updates: 149,948
Cumulative Timesteps: 1,250,642,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.95269
Policy Entropy: 3.08179
Value Function Loss: 0.00469

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.48131

Collected Steps per Second: 23,122.17418
Overall Steps per Second: 10,890.30699

Timestep Collection Time: 2.16260
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.59161

Cumulative Model Updates: 149,954
Cumulative Timesteps: 1,250,692,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1250692230...
Checkpoint 1250692230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.27564
Policy Entropy: 3.07614
Value Function Loss: 0.00456

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.57036
Value Function Update Magnitude: 0.47954

Collected Steps per Second: 23,101.44201
Overall Steps per Second: 10,842.39454

Timestep Collection Time: 2.16558
Timestep Consumption Time: 2.44853
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.61411

Cumulative Model Updates: 149,960
Cumulative Timesteps: 1,250,742,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.87467
Policy Entropy: 3.06794
Value Function Loss: 0.00471

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.57199
Value Function Update Magnitude: 0.50035

Collected Steps per Second: 23,356.11556
Overall Steps per Second: 10,826.55616

Timestep Collection Time: 2.14094
Timestep Consumption Time: 2.47771
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.61864

Cumulative Model Updates: 149,966
Cumulative Timesteps: 1,250,792,262

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1250792262...
Checkpoint 1250792262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.42150
Policy Entropy: 3.06707
Value Function Loss: 0.00417

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.56987
Value Function Update Magnitude: 0.50881

Collected Steps per Second: 23,374.46111
Overall Steps per Second: 11,002.36856

Timestep Collection Time: 2.14037
Timestep Consumption Time: 2.40683
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.54720

Cumulative Model Updates: 149,972
Cumulative Timesteps: 1,250,842,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.48021
Policy Entropy: 3.06454
Value Function Loss: 0.00459

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.57532
Value Function Update Magnitude: 0.53258

Collected Steps per Second: 22,900.14278
Overall Steps per Second: 10,874.52761

Timestep Collection Time: 2.18462
Timestep Consumption Time: 2.41586
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.60048

Cumulative Model Updates: 149,978
Cumulative Timesteps: 1,250,892,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1250892320...
Checkpoint 1250892320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,677.97598
Policy Entropy: 3.05441
Value Function Loss: 0.00438

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.60172
Value Function Update Magnitude: 0.57036

Collected Steps per Second: 22,717.22890
Overall Steps per Second: 10,720.18550

Timestep Collection Time: 2.20194
Timestep Consumption Time: 2.46421
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.66615

Cumulative Model Updates: 149,984
Cumulative Timesteps: 1,250,942,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393.94800
Policy Entropy: 3.05890
Value Function Loss: 0.00456

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.60565
Value Function Update Magnitude: 0.56538

Collected Steps per Second: 22,773.78718
Overall Steps per Second: 10,847.49538

Timestep Collection Time: 2.19638
Timestep Consumption Time: 2.41482
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.61120

Cumulative Model Updates: 149,990
Cumulative Timesteps: 1,250,992,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1250992362...
Checkpoint 1250992362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,140.73510
Policy Entropy: 3.06209
Value Function Loss: 0.00409

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.58432
Value Function Update Magnitude: 0.53436

Collected Steps per Second: 22,601.57262
Overall Steps per Second: 10,664.37718

Timestep Collection Time: 2.21259
Timestep Consumption Time: 2.47667
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.68926

Cumulative Model Updates: 149,996
Cumulative Timesteps: 1,251,042,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.41456
Policy Entropy: 3.07212
Value Function Loss: 0.00426

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.57093
Value Function Update Magnitude: 0.51387

Collected Steps per Second: 22,665.81414
Overall Steps per Second: 10,619.55992

Timestep Collection Time: 2.20614
Timestep Consumption Time: 2.50253
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.70867

Cumulative Model Updates: 150,002
Cumulative Timesteps: 1,251,092,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1251092374...
Checkpoint 1251092374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,493.03058
Policy Entropy: 3.07782
Value Function Loss: 0.00430

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.58378
Value Function Update Magnitude: 0.52023

Collected Steps per Second: 22,714.47669
Overall Steps per Second: 10,636.94226

Timestep Collection Time: 2.20203
Timestep Consumption Time: 2.50026
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.70229

Cumulative Model Updates: 150,008
Cumulative Timesteps: 1,251,142,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.84888
Policy Entropy: 3.07247
Value Function Loss: 0.00465

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.59789
Value Function Update Magnitude: 0.53524

Collected Steps per Second: 23,039.12419
Overall Steps per Second: 10,682.08415

Timestep Collection Time: 2.17135
Timestep Consumption Time: 2.51182
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.68317

Cumulative Model Updates: 150,014
Cumulative Timesteps: 1,251,192,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1251192418...
Checkpoint 1251192418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,178.43335
Policy Entropy: 3.07950
Value Function Loss: 0.00460

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.59736
Value Function Update Magnitude: 0.55547

Collected Steps per Second: 22,497.57148
Overall Steps per Second: 10,515.58833

Timestep Collection Time: 2.22255
Timestep Consumption Time: 2.53248
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.75504

Cumulative Model Updates: 150,020
Cumulative Timesteps: 1,251,242,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.95500
Policy Entropy: 3.07676
Value Function Loss: 0.00436

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.58110
Value Function Update Magnitude: 0.53873

Collected Steps per Second: 22,673.34411
Overall Steps per Second: 10,652.56161

Timestep Collection Time: 2.20611
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.69558

Cumulative Model Updates: 150,026
Cumulative Timesteps: 1,251,292,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1251292440...
Checkpoint 1251292440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,306.09820
Policy Entropy: 3.08368
Value Function Loss: 0.00427

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.57572
Value Function Update Magnitude: 0.51886

Collected Steps per Second: 22,817.21300
Overall Steps per Second: 10,645.50103

Timestep Collection Time: 2.19133
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.69682

Cumulative Model Updates: 150,032
Cumulative Timesteps: 1,251,342,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.79419
Policy Entropy: 3.06948
Value Function Loss: 0.00445

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.52159

Collected Steps per Second: 22,641.81249
Overall Steps per Second: 10,585.60375

Timestep Collection Time: 2.20892
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.72472

Cumulative Model Updates: 150,038
Cumulative Timesteps: 1,251,392,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1251392454...
Checkpoint 1251392454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.87752
Policy Entropy: 3.05383
Value Function Loss: 0.00465

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.59292
Value Function Update Magnitude: 0.53374

Collected Steps per Second: 22,584.05251
Overall Steps per Second: 10,558.31859

Timestep Collection Time: 2.21466
Timestep Consumption Time: 2.52246
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.73712

Cumulative Model Updates: 150,044
Cumulative Timesteps: 1,251,442,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,058.21251
Policy Entropy: 3.05790
Value Function Loss: 0.00422

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.58814
Value Function Update Magnitude: 0.53263

Collected Steps per Second: 21,402.91691
Overall Steps per Second: 10,353.82140

Timestep Collection Time: 2.33660
Timestep Consumption Time: 2.49350
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.83010

Cumulative Model Updates: 150,050
Cumulative Timesteps: 1,251,492,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1251492480...
Checkpoint 1251492480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.81519
Policy Entropy: 3.05698
Value Function Loss: 0.00402

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.58011
Value Function Update Magnitude: 0.53066

Collected Steps per Second: 19,951.65426
Overall Steps per Second: 9,710.22409

Timestep Collection Time: 2.50686
Timestep Consumption Time: 2.64400
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 5.15086

Cumulative Model Updates: 150,056
Cumulative Timesteps: 1,251,542,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,299.70794
Policy Entropy: 3.05939
Value Function Loss: 0.00417

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.58384
Value Function Update Magnitude: 0.52688

Collected Steps per Second: 19,017.12613
Overall Steps per Second: 9,544.31541

Timestep Collection Time: 2.63068
Timestep Consumption Time: 2.61097
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 5.24165

Cumulative Model Updates: 150,062
Cumulative Timesteps: 1,251,592,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1251592524...
Checkpoint 1251592524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.72994
Policy Entropy: 3.04881
Value Function Loss: 0.00448

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.58014
Value Function Update Magnitude: 0.50579

Collected Steps per Second: 21,897.09320
Overall Steps per Second: 10,534.60875

Timestep Collection Time: 2.28441
Timestep Consumption Time: 2.46394
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.74835

Cumulative Model Updates: 150,068
Cumulative Timesteps: 1,251,642,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.58344
Policy Entropy: 3.04796
Value Function Loss: 0.00436

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.51942

Collected Steps per Second: 21,839.00699
Overall Steps per Second: 10,452.53316

Timestep Collection Time: 2.29031
Timestep Consumption Time: 2.49495
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.78525

Cumulative Model Updates: 150,074
Cumulative Timesteps: 1,251,692,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1251692564...
Checkpoint 1251692564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.86071
Policy Entropy: 3.06193
Value Function Loss: 0.00431

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.57043
Value Function Update Magnitude: 0.51680

Collected Steps per Second: 16,465.69804
Overall Steps per Second: 8,595.55623

Timestep Collection Time: 3.03892
Timestep Consumption Time: 2.78246
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 5.82138

Cumulative Model Updates: 150,080
Cumulative Timesteps: 1,251,742,602

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.57227
Policy Entropy: 3.05226
Value Function Loss: 0.00456

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.58370
Value Function Update Magnitude: 0.52177

Collected Steps per Second: 9,699.18496
Overall Steps per Second: 6,226.89804

Timestep Collection Time: 5.16023
Timestep Consumption Time: 2.87748
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 8.03771

Cumulative Model Updates: 150,086
Cumulative Timesteps: 1,251,792,652

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1251792652...
Checkpoint 1251792652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,422.82570
Policy Entropy: 3.04483
Value Function Loss: 0.00462

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.60361
Value Function Update Magnitude: 0.55551

Collected Steps per Second: 17,352.28777
Overall Steps per Second: 9,363.36372

Timestep Collection Time: 2.88239
Timestep Consumption Time: 2.45928
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 5.34167

Cumulative Model Updates: 150,092
Cumulative Timesteps: 1,251,842,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,014.45001
Policy Entropy: 3.02536
Value Function Loss: 0.00432

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.60343
Value Function Update Magnitude: 0.56746

Collected Steps per Second: 21,937.16908
Overall Steps per Second: 10,613.64390

Timestep Collection Time: 2.27942
Timestep Consumption Time: 2.43188
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.71129

Cumulative Model Updates: 150,098
Cumulative Timesteps: 1,251,892,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1251892672...
Checkpoint 1251892672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.80591
Policy Entropy: 3.03373
Value Function Loss: 0.00425

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.58862
Value Function Update Magnitude: 0.53625

Collected Steps per Second: 22,731.34914
Overall Steps per Second: 10,735.24496

Timestep Collection Time: 2.20057
Timestep Consumption Time: 2.45903
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.65960

Cumulative Model Updates: 150,104
Cumulative Timesteps: 1,251,942,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.88919
Policy Entropy: 3.03607
Value Function Loss: 0.00426

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11088
Policy Update Magnitude: 0.58218
Value Function Update Magnitude: 0.51670

Collected Steps per Second: 22,823.68321
Overall Steps per Second: 10,798.73404

Timestep Collection Time: 2.19106
Timestep Consumption Time: 2.43986
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.63091

Cumulative Model Updates: 150,110
Cumulative Timesteps: 1,251,992,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1251992702...
Checkpoint 1251992702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.59651
Policy Entropy: 3.03952
Value Function Loss: 0.00441

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.59034
Value Function Update Magnitude: 0.51694

Collected Steps per Second: 22,850.98761
Overall Steps per Second: 10,582.25486

Timestep Collection Time: 2.18870
Timestep Consumption Time: 2.53751
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.72621

Cumulative Model Updates: 150,116
Cumulative Timesteps: 1,252,042,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.05361
Policy Entropy: 3.03874
Value Function Loss: 0.00461

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.59725
Value Function Update Magnitude: 0.52187

Collected Steps per Second: 23,209.94376
Overall Steps per Second: 10,976.65352

Timestep Collection Time: 2.15477
Timestep Consumption Time: 2.40145
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.55622

Cumulative Model Updates: 150,122
Cumulative Timesteps: 1,252,092,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1252092728...
Checkpoint 1252092728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.20077
Policy Entropy: 3.03219
Value Function Loss: 0.00445

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.59778
Value Function Update Magnitude: 0.53793

Collected Steps per Second: 22,828.15797
Overall Steps per Second: 10,737.84244

Timestep Collection Time: 2.19133
Timestep Consumption Time: 2.46734
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.65866

Cumulative Model Updates: 150,128
Cumulative Timesteps: 1,252,142,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,855.20303
Policy Entropy: 3.02388
Value Function Loss: 0.00451

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.59356
Value Function Update Magnitude: 0.52956

Collected Steps per Second: 23,368.61818
Overall Steps per Second: 10,761.25809

Timestep Collection Time: 2.14014
Timestep Consumption Time: 2.50728
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.64741

Cumulative Model Updates: 150,134
Cumulative Timesteps: 1,252,192,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1252192764...
Checkpoint 1252192764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.07086
Policy Entropy: 3.01552
Value Function Loss: 0.00428

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10723
Policy Update Magnitude: 0.59176
Value Function Update Magnitude: 0.49862

Collected Steps per Second: 22,894.07529
Overall Steps per Second: 10,619.95692

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.52526
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.71019

Cumulative Model Updates: 150,140
Cumulative Timesteps: 1,252,242,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.89157
Policy Entropy: 3.01448
Value Function Loss: 0.00479

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.59208
Value Function Update Magnitude: 0.52167

Collected Steps per Second: 23,371.11591
Overall Steps per Second: 10,962.56528

Timestep Collection Time: 2.13948
Timestep Consumption Time: 2.42168
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.56116

Cumulative Model Updates: 150,146
Cumulative Timesteps: 1,252,292,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1252292788...
Checkpoint 1252292788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,493.19284
Policy Entropy: 3.00526
Value Function Loss: 0.00469

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.59296
Value Function Update Magnitude: 0.52700

Collected Steps per Second: 22,767.16485
Overall Steps per Second: 10,632.99741

Timestep Collection Time: 2.19632
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.70272

Cumulative Model Updates: 150,152
Cumulative Timesteps: 1,252,342,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.22329
Policy Entropy: 3.01572
Value Function Loss: 0.00497

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.59112
Value Function Update Magnitude: 0.53603

Collected Steps per Second: 23,039.42300
Overall Steps per Second: 10,845.51168

Timestep Collection Time: 2.17089
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.61168

Cumulative Model Updates: 150,158
Cumulative Timesteps: 1,252,392,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1252392808...
Checkpoint 1252392808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.04534
Policy Entropy: 3.02388
Value Function Loss: 0.00436

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.58328
Value Function Update Magnitude: 0.53576

Collected Steps per Second: 22,378.69977
Overall Steps per Second: 10,722.34607

Timestep Collection Time: 2.23436
Timestep Consumption Time: 2.42899
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.66335

Cumulative Model Updates: 150,164
Cumulative Timesteps: 1,252,442,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.52034
Policy Entropy: 3.03826
Value Function Loss: 0.00464

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.51955

Collected Steps per Second: 22,849.25932
Overall Steps per Second: 10,911.96763

Timestep Collection Time: 2.18843
Timestep Consumption Time: 2.39406
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.58249

Cumulative Model Updates: 150,170
Cumulative Timesteps: 1,252,492,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1252492814...
Checkpoint 1252492814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.13312
Policy Entropy: 3.04146
Value Function Loss: 0.00466

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.58869
Value Function Update Magnitude: 0.52161

Collected Steps per Second: 23,324.78691
Overall Steps per Second: 10,793.44834

Timestep Collection Time: 2.14476
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.63485

Cumulative Model Updates: 150,176
Cumulative Timesteps: 1,252,542,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.10893
Policy Entropy: 3.03100
Value Function Loss: 0.00456

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.58385
Value Function Update Magnitude: 0.52848

Collected Steps per Second: 23,209.38456
Overall Steps per Second: 10,816.17756

Timestep Collection Time: 2.15456
Timestep Consumption Time: 2.46870
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.62326

Cumulative Model Updates: 150,182
Cumulative Timesteps: 1,252,592,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1252592846...
Checkpoint 1252592846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.10745
Policy Entropy: 3.01600
Value Function Loss: 0.00493

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.59442
Value Function Update Magnitude: 0.53443

Collected Steps per Second: 23,040.41458
Overall Steps per Second: 10,931.81903

Timestep Collection Time: 2.17140
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.57655

Cumulative Model Updates: 150,188
Cumulative Timesteps: 1,252,642,876

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.21510
Policy Entropy: 3.00596
Value Function Loss: 0.00523

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.60688
Value Function Update Magnitude: 0.54640

Collected Steps per Second: 23,176.61113
Overall Steps per Second: 10,945.40546

Timestep Collection Time: 2.15769
Timestep Consumption Time: 2.41117
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.56886

Cumulative Model Updates: 150,194
Cumulative Timesteps: 1,252,692,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1252692884...
Checkpoint 1252692884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,175.93210
Policy Entropy: 3.01501
Value Function Loss: 0.00503

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.60419
Value Function Update Magnitude: 0.54338

Collected Steps per Second: 22,800.79181
Overall Steps per Second: 10,673.39540

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.49164
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.68454

Cumulative Model Updates: 150,200
Cumulative Timesteps: 1,252,742,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.08777
Policy Entropy: 3.02578
Value Function Loss: 0.00464

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.59403
Value Function Update Magnitude: 0.53545

Collected Steps per Second: 22,880.97766
Overall Steps per Second: 10,781.86242

Timestep Collection Time: 2.18610
Timestep Consumption Time: 2.45318
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.63927

Cumulative Model Updates: 150,206
Cumulative Timesteps: 1,252,792,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1252792904...
Checkpoint 1252792904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,978.08149
Policy Entropy: 3.03343
Value Function Loss: 0.00420

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.58863
Value Function Update Magnitude: 0.52792

Collected Steps per Second: 22,565.87909
Overall Steps per Second: 10,713.44761

Timestep Collection Time: 2.21591
Timestep Consumption Time: 2.45149
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.66741

Cumulative Model Updates: 150,212
Cumulative Timesteps: 1,252,842,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,354.13611
Policy Entropy: 3.02938
Value Function Loss: 0.00413

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.58036
Value Function Update Magnitude: 0.51257

Collected Steps per Second: 22,787.04490
Overall Steps per Second: 10,891.25666

Timestep Collection Time: 2.19432
Timestep Consumption Time: 2.39671
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.59102

Cumulative Model Updates: 150,218
Cumulative Timesteps: 1,252,892,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1252892910...
Checkpoint 1252892910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,317.73043
Policy Entropy: 3.04050
Value Function Loss: 0.00385

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.56479
Value Function Update Magnitude: 0.49492

Collected Steps per Second: 22,707.41169
Overall Steps per Second: 10,674.16735

Timestep Collection Time: 2.20280
Timestep Consumption Time: 2.48327
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.68608

Cumulative Model Updates: 150,224
Cumulative Timesteps: 1,252,942,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,602.22605
Policy Entropy: 3.04702
Value Function Loss: 0.00386

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.50043

Collected Steps per Second: 22,799.90241
Overall Steps per Second: 10,835.62876

Timestep Collection Time: 2.19369
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61588

Cumulative Model Updates: 150,230
Cumulative Timesteps: 1,252,992,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1252992946...
Checkpoint 1252992946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,047.19010
Policy Entropy: 3.05137
Value Function Loss: 0.00383

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.51324

Collected Steps per Second: 22,762.94458
Overall Steps per Second: 10,657.74693

Timestep Collection Time: 2.19673
Timestep Consumption Time: 2.49507
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.69180

Cumulative Model Updates: 150,236
Cumulative Timesteps: 1,253,042,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.19799
Policy Entropy: 3.04391
Value Function Loss: 0.00371

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.56603
Value Function Update Magnitude: 0.51921

Collected Steps per Second: 23,122.71391
Overall Steps per Second: 10,844.74731

Timestep Collection Time: 2.16289
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.61163

Cumulative Model Updates: 150,242
Cumulative Timesteps: 1,253,092,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1253092962...
Checkpoint 1253092962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.29300
Policy Entropy: 3.03307
Value Function Loss: 0.00424

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.52049

Collected Steps per Second: 22,943.55238
Overall Steps per Second: 10,745.01606

Timestep Collection Time: 2.18039
Timestep Consumption Time: 2.47535
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.65574

Cumulative Model Updates: 150,248
Cumulative Timesteps: 1,253,142,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,454.49216
Policy Entropy: 3.02790
Value Function Loss: 0.00451

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.58776
Value Function Update Magnitude: 0.52866

Collected Steps per Second: 23,618.31935
Overall Steps per Second: 10,929.12268

Timestep Collection Time: 2.11810
Timestep Consumption Time: 2.45921
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.57731

Cumulative Model Updates: 150,254
Cumulative Timesteps: 1,253,193,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1253193014...
Checkpoint 1253193014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.84274
Policy Entropy: 3.01574
Value Function Loss: 0.00471

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.59260
Value Function Update Magnitude: 0.52753

Collected Steps per Second: 22,801.48548
Overall Steps per Second: 10,740.22124

Timestep Collection Time: 2.19293
Timestep Consumption Time: 2.46266
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.65558

Cumulative Model Updates: 150,260
Cumulative Timesteps: 1,253,243,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.12367
Policy Entropy: 3.02543
Value Function Loss: 0.00427

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.58299
Value Function Update Magnitude: 0.51527

Collected Steps per Second: 23,296.43372
Overall Steps per Second: 10,813.33156

Timestep Collection Time: 2.14634
Timestep Consumption Time: 2.47777
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.62411

Cumulative Model Updates: 150,266
Cumulative Timesteps: 1,253,293,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1253293018...
Checkpoint 1253293018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,885.30403
Policy Entropy: 3.03457
Value Function Loss: 0.00414

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.57019
Value Function Update Magnitude: 0.49302

Collected Steps per Second: 22,540.56240
Overall Steps per Second: 10,636.57733

Timestep Collection Time: 2.21893
Timestep Consumption Time: 2.48333
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.70226

Cumulative Model Updates: 150,272
Cumulative Timesteps: 1,253,343,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.85394
Policy Entropy: 3.03003
Value Function Loss: 0.00388

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.56577
Value Function Update Magnitude: 0.48327

Collected Steps per Second: 22,873.42745
Overall Steps per Second: 10,818.10830

Timestep Collection Time: 2.18682
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.62373

Cumulative Model Updates: 150,278
Cumulative Timesteps: 1,253,393,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1253393054...
Checkpoint 1253393054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,689.51479
Policy Entropy: 3.03038
Value Function Loss: 0.00416

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.57205
Value Function Update Magnitude: 0.48263

Collected Steps per Second: 22,148.20296
Overall Steps per Second: 10,663.63265

Timestep Collection Time: 2.25788
Timestep Consumption Time: 2.43170
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.68958

Cumulative Model Updates: 150,284
Cumulative Timesteps: 1,253,443,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.49797
Policy Entropy: 3.02610
Value Function Loss: 0.00423

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.57012
Value Function Update Magnitude: 0.50794

Collected Steps per Second: 22,780.30300
Overall Steps per Second: 10,680.28307

Timestep Collection Time: 2.19523
Timestep Consumption Time: 2.48704
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.68227

Cumulative Model Updates: 150,290
Cumulative Timesteps: 1,253,493,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1253493070...
Checkpoint 1253493070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.45207
Policy Entropy: 3.03470
Value Function Loss: 0.00437

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.56764
Value Function Update Magnitude: 0.51141

Collected Steps per Second: 22,982.89965
Overall Steps per Second: 10,827.53307

Timestep Collection Time: 2.17579
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.61841

Cumulative Model Updates: 150,296
Cumulative Timesteps: 1,253,543,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,005.46670
Policy Entropy: 3.02995
Value Function Loss: 0.00447

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.56807
Value Function Update Magnitude: 0.50310

Collected Steps per Second: 23,277.55256
Overall Steps per Second: 10,920.97349

Timestep Collection Time: 2.14868
Timestep Consumption Time: 2.43113
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.57981

Cumulative Model Updates: 150,302
Cumulative Timesteps: 1,253,593,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1253593092...
Checkpoint 1253593092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.95628
Policy Entropy: 3.04034
Value Function Loss: 0.00417

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.55332
Value Function Update Magnitude: 0.50247

Collected Steps per Second: 22,878.35673
Overall Steps per Second: 10,720.96358

Timestep Collection Time: 2.18617
Timestep Consumption Time: 2.47908
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.66525

Cumulative Model Updates: 150,308
Cumulative Timesteps: 1,253,643,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,769.21918
Policy Entropy: 3.02373
Value Function Loss: 0.00461

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10938
Policy Update Magnitude: 0.56995
Value Function Update Magnitude: 0.54063

Collected Steps per Second: 23,480.90277
Overall Steps per Second: 10,941.56644

Timestep Collection Time: 2.13016
Timestep Consumption Time: 2.44122
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.57137

Cumulative Model Updates: 150,314
Cumulative Timesteps: 1,253,693,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1253693126...
Checkpoint 1253693126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,361.38810
Policy Entropy: 3.03318
Value Function Loss: 0.00418

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.54331

Collected Steps per Second: 23,002.24551
Overall Steps per Second: 10,580.04599

Timestep Collection Time: 2.17474
Timestep Consumption Time: 2.55340
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.72815

Cumulative Model Updates: 150,320
Cumulative Timesteps: 1,253,743,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867.50066
Policy Entropy: 3.01507
Value Function Loss: 0.00456

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.58712
Value Function Update Magnitude: 0.53757

Collected Steps per Second: 23,130.91219
Overall Steps per Second: 10,862.82985

Timestep Collection Time: 2.16239
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.60451

Cumulative Model Updates: 150,326
Cumulative Timesteps: 1,253,793,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1253793168...
Checkpoint 1253793168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,226.33855
Policy Entropy: 3.01432
Value Function Loss: 0.00407

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.58592
Value Function Update Magnitude: 0.53446

Collected Steps per Second: 22,265.66793
Overall Steps per Second: 10,682.46437

Timestep Collection Time: 2.24633
Timestep Consumption Time: 2.43574
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.68207

Cumulative Model Updates: 150,332
Cumulative Timesteps: 1,253,843,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.69539
Policy Entropy: 3.00047
Value Function Loss: 0.00389

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.57341
Value Function Update Magnitude: 0.51841

Collected Steps per Second: 22,937.58417
Overall Steps per Second: 10,752.32401

Timestep Collection Time: 2.18000
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.65053

Cumulative Model Updates: 150,338
Cumulative Timesteps: 1,253,893,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1253893188...
Checkpoint 1253893188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.55911
Policy Entropy: 3.00904
Value Function Loss: 0.00396

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.57108
Value Function Update Magnitude: 0.49418

Collected Steps per Second: 22,457.99152
Overall Steps per Second: 10,810.30606

Timestep Collection Time: 2.22691
Timestep Consumption Time: 2.39941
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.62633

Cumulative Model Updates: 150,344
Cumulative Timesteps: 1,253,943,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.34848
Policy Entropy: 2.99808
Value Function Loss: 0.00405

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.49836

Collected Steps per Second: 23,268.46758
Overall Steps per Second: 10,901.88506

Timestep Collection Time: 2.14995
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.58875

Cumulative Model Updates: 150,350
Cumulative Timesteps: 1,253,993,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1253993226...
Checkpoint 1253993226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.46968
Policy Entropy: 2.99791
Value Function Loss: 0.00396

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.57211
Value Function Update Magnitude: 0.49850

Collected Steps per Second: 23,074.19322
Overall Steps per Second: 10,652.19130

Timestep Collection Time: 2.16805
Timestep Consumption Time: 2.52826
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.69631

Cumulative Model Updates: 150,356
Cumulative Timesteps: 1,254,043,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,423.13552
Policy Entropy: 3.00529
Value Function Loss: 0.00395

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.56750
Value Function Update Magnitude: 0.47916

Collected Steps per Second: 23,056.12788
Overall Steps per Second: 10,842.86645

Timestep Collection Time: 2.16888
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.61188

Cumulative Model Updates: 150,362
Cumulative Timesteps: 1,254,093,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1254093258...
Checkpoint 1254093258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.10403
Policy Entropy: 3.01879
Value Function Loss: 0.00380

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.47553

Collected Steps per Second: 23,040.39089
Overall Steps per Second: 10,720.64725

Timestep Collection Time: 2.17071
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.66520

Cumulative Model Updates: 150,368
Cumulative Timesteps: 1,254,143,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928.42357
Policy Entropy: 3.02999
Value Function Loss: 0.00362

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.56061
Value Function Update Magnitude: 0.47407

Collected Steps per Second: 23,150.67034
Overall Steps per Second: 10,856.77602

Timestep Collection Time: 2.16046
Timestep Consumption Time: 2.44644
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60689

Cumulative Model Updates: 150,374
Cumulative Timesteps: 1,254,193,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1254193288...
Checkpoint 1254193288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.14841
Policy Entropy: 3.04091
Value Function Loss: 0.00371

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.45975

Collected Steps per Second: 22,775.66196
Overall Steps per Second: 10,674.36184

Timestep Collection Time: 2.19550
Timestep Consumption Time: 2.48899
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.68450

Cumulative Model Updates: 150,380
Cumulative Timesteps: 1,254,243,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,306.91268
Policy Entropy: 3.02309
Value Function Loss: 0.00418

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.57799
Value Function Update Magnitude: 0.49252

Collected Steps per Second: 22,953.69912
Overall Steps per Second: 10,849.23844

Timestep Collection Time: 2.17847
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.60899

Cumulative Model Updates: 150,386
Cumulative Timesteps: 1,254,293,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1254293296...
Checkpoint 1254293296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.53693
Policy Entropy: 3.01120
Value Function Loss: 0.00458

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.59204
Value Function Update Magnitude: 0.54392

Collected Steps per Second: 22,277.38051
Overall Steps per Second: 10,750.43504

Timestep Collection Time: 2.24542
Timestep Consumption Time: 2.40760
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.65302

Cumulative Model Updates: 150,392
Cumulative Timesteps: 1,254,343,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.23977
Policy Entropy: 3.01068
Value Function Loss: 0.00428

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.58840
Value Function Update Magnitude: 0.56087

Collected Steps per Second: 22,819.39232
Overall Steps per Second: 10,878.16776

Timestep Collection Time: 2.19147
Timestep Consumption Time: 2.40563
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.59710

Cumulative Model Updates: 150,398
Cumulative Timesteps: 1,254,393,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1254393326...
Checkpoint 1254393326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.90871
Policy Entropy: 3.02757
Value Function Loss: 0.00409

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.57638
Value Function Update Magnitude: 0.53941

Collected Steps per Second: 22,227.44278
Overall Steps per Second: 10,664.16548

Timestep Collection Time: 2.24965
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.68897

Cumulative Model Updates: 150,404
Cumulative Timesteps: 1,254,443,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,066.37251
Policy Entropy: 3.03618
Value Function Loss: 0.00383

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.57500
Value Function Update Magnitude: 0.51708

Collected Steps per Second: 22,794.77418
Overall Steps per Second: 10,644.18963

Timestep Collection Time: 2.19480
Timestep Consumption Time: 2.50542
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.70022

Cumulative Model Updates: 150,410
Cumulative Timesteps: 1,254,493,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1254493360...
Checkpoint 1254493360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,350.85610
Policy Entropy: 3.03983
Value Function Loss: 0.00410

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.57608
Value Function Update Magnitude: 0.50232

Collected Steps per Second: 23,223.83794
Overall Steps per Second: 10,893.03860

Timestep Collection Time: 2.15365
Timestep Consumption Time: 2.43791
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.59156

Cumulative Model Updates: 150,416
Cumulative Timesteps: 1,254,543,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.73887
Policy Entropy: 3.03192
Value Function Loss: 0.00452

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.59539
Value Function Update Magnitude: 0.52122

Collected Steps per Second: 23,340.81262
Overall Steps per Second: 10,996.08528

Timestep Collection Time: 2.14406
Timestep Consumption Time: 2.40702
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.55107

Cumulative Model Updates: 150,422
Cumulative Timesteps: 1,254,593,420

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1254593420...
Checkpoint 1254593420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,968.75885
Policy Entropy: 3.02222
Value Function Loss: 0.00469

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.60247
Value Function Update Magnitude: 0.56530

Collected Steps per Second: 22,726.28981
Overall Steps per Second: 10,694.15649

Timestep Collection Time: 2.20124
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.67788

Cumulative Model Updates: 150,428
Cumulative Timesteps: 1,254,643,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,221.74249
Policy Entropy: 3.00892
Value Function Loss: 0.00450

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.60585
Value Function Update Magnitude: 0.59276

Collected Steps per Second: 23,340.09248
Overall Steps per Second: 10,866.41024

Timestep Collection Time: 2.14292
Timestep Consumption Time: 2.45989
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.60281

Cumulative Model Updates: 150,434
Cumulative Timesteps: 1,254,693,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1254693462...
Checkpoint 1254693462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,866.52138
Policy Entropy: 3.01732
Value Function Loss: 0.00407

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.59649
Value Function Update Magnitude: 0.58245

Collected Steps per Second: 22,738.75523
Overall Steps per Second: 10,619.61604

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.51018
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.70977

Cumulative Model Updates: 150,440
Cumulative Timesteps: 1,254,743,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,477.90715
Policy Entropy: 3.01371
Value Function Loss: 0.00413

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.58572
Value Function Update Magnitude: 0.56629

Collected Steps per Second: 23,440.36316
Overall Steps per Second: 10,890.18247

Timestep Collection Time: 2.13324
Timestep Consumption Time: 2.45842
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.59166

Cumulative Model Updates: 150,446
Cumulative Timesteps: 1,254,793,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1254793482...
Checkpoint 1254793482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.85024
Policy Entropy: 3.01292
Value Function Loss: 0.00402

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.58244
Value Function Update Magnitude: 0.56340

Collected Steps per Second: 22,511.85319
Overall Steps per Second: 10,675.23155

Timestep Collection Time: 2.22221
Timestep Consumption Time: 2.46397
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.68617

Cumulative Model Updates: 150,452
Cumulative Timesteps: 1,254,843,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,536.33887
Policy Entropy: 3.02429
Value Function Loss: 0.00430

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.57132
Value Function Update Magnitude: 0.54787

Collected Steps per Second: 22,869.04568
Overall Steps per Second: 10,884.96057

Timestep Collection Time: 2.18724
Timestep Consumption Time: 2.40810
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.59533

Cumulative Model Updates: 150,458
Cumulative Timesteps: 1,254,893,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1254893528...
Checkpoint 1254893528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.49015
Policy Entropy: 3.02936
Value Function Loss: 0.00430

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.57260
Value Function Update Magnitude: 0.55354

Collected Steps per Second: 22,409.28938
Overall Steps per Second: 10,677.88836

Timestep Collection Time: 2.23202
Timestep Consumption Time: 2.45224
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.68426

Cumulative Model Updates: 150,464
Cumulative Timesteps: 1,254,943,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.64254
Policy Entropy: 3.02574
Value Function Loss: 0.00449

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.59008
Value Function Update Magnitude: 0.55930

Collected Steps per Second: 22,904.87406
Overall Steps per Second: 10,814.23570

Timestep Collection Time: 2.18347
Timestep Consumption Time: 2.44118
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.62464

Cumulative Model Updates: 150,470
Cumulative Timesteps: 1,254,993,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1254993558...
Checkpoint 1254993558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.09700
Policy Entropy: 3.01785
Value Function Loss: 0.00465

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.60999
Value Function Update Magnitude: 0.58690

Collected Steps per Second: 22,727.12815
Overall Steps per Second: 10,689.03273

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.67938

Cumulative Model Updates: 150,476
Cumulative Timesteps: 1,255,043,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,904.43487
Policy Entropy: 3.02033
Value Function Loss: 0.00452

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.60889
Value Function Update Magnitude: 0.58180

Collected Steps per Second: 23,157.40427
Overall Steps per Second: 10,934.18016

Timestep Collection Time: 2.15948
Timestep Consumption Time: 2.41407
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.57355

Cumulative Model Updates: 150,482
Cumulative Timesteps: 1,255,093,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1255093584...
Checkpoint 1255093584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.03835
Policy Entropy: 3.02103
Value Function Loss: 0.00461

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.59818
Value Function Update Magnitude: 0.58395

Collected Steps per Second: 23,088.21499
Overall Steps per Second: 10,729.81820

Timestep Collection Time: 2.16561
Timestep Consumption Time: 2.49430
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.65991

Cumulative Model Updates: 150,488
Cumulative Timesteps: 1,255,143,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,872.61084
Policy Entropy: 3.01282
Value Function Loss: 0.00438

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.59013
Value Function Update Magnitude: 0.58387

Collected Steps per Second: 23,421.79235
Overall Steps per Second: 10,795.45408

Timestep Collection Time: 2.13511
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.63232

Cumulative Model Updates: 150,494
Cumulative Timesteps: 1,255,193,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1255193592...
Checkpoint 1255193592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.23778
Policy Entropy: 3.00037
Value Function Loss: 0.00452

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.59130
Value Function Update Magnitude: 0.56307

Collected Steps per Second: 22,886.13316
Overall Steps per Second: 10,647.37727

Timestep Collection Time: 2.18595
Timestep Consumption Time: 2.51267
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.69862

Cumulative Model Updates: 150,500
Cumulative Timesteps: 1,255,243,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.89145
Policy Entropy: 2.99282
Value Function Loss: 0.00430

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.58584
Value Function Update Magnitude: 0.52525

Collected Steps per Second: 23,247.06937
Overall Steps per Second: 10,946.48391

Timestep Collection Time: 2.15150
Timestep Consumption Time: 2.41764
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.56914

Cumulative Model Updates: 150,506
Cumulative Timesteps: 1,255,293,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1255293636...
Checkpoint 1255293636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.36404
Policy Entropy: 2.99298
Value Function Loss: 0.00418

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.57065
Value Function Update Magnitude: 0.49890

Collected Steps per Second: 22,836.36720
Overall Steps per Second: 10,645.15854

Timestep Collection Time: 2.19037
Timestep Consumption Time: 2.50848
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.69885

Cumulative Model Updates: 150,512
Cumulative Timesteps: 1,255,343,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,634.34623
Policy Entropy: 3.00648
Value Function Loss: 0.00399

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.56310
Value Function Update Magnitude: 0.48994

Collected Steps per Second: 22,896.93027
Overall Steps per Second: 10,806.44418

Timestep Collection Time: 2.18527
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.63020

Cumulative Model Updates: 150,518
Cumulative Timesteps: 1,255,393,692

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1255393692...
Checkpoint 1255393692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,472.88565
Policy Entropy: 2.99597
Value Function Loss: 0.00426

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.57294
Value Function Update Magnitude: 0.51964

Collected Steps per Second: 22,631.37696
Overall Steps per Second: 10,708.81693

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.46061
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.67073

Cumulative Model Updates: 150,524
Cumulative Timesteps: 1,255,443,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.28742
Policy Entropy: 3.00926
Value Function Loss: 0.00392

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.50629

Collected Steps per Second: 22,918.54172
Overall Steps per Second: 10,847.01947

Timestep Collection Time: 2.18260
Timestep Consumption Time: 2.42899
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.61159

Cumulative Model Updates: 150,530
Cumulative Timesteps: 1,255,493,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1255493732...
Checkpoint 1255493732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,350.79180
Policy Entropy: 3.00755
Value Function Loss: 0.00454

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.58388
Value Function Update Magnitude: 0.50938

Collected Steps per Second: 22,709.43351
Overall Steps per Second: 10,743.65696

Timestep Collection Time: 2.20199
Timestep Consumption Time: 2.45247
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.65447

Cumulative Model Updates: 150,536
Cumulative Timesteps: 1,255,543,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,211.51860
Policy Entropy: 3.01989
Value Function Loss: 0.00445

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.60138
Value Function Update Magnitude: 0.52965

Collected Steps per Second: 23,365.78186
Overall Steps per Second: 10,801.23098

Timestep Collection Time: 2.14014
Timestep Consumption Time: 2.48952
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.62966

Cumulative Model Updates: 150,542
Cumulative Timesteps: 1,255,593,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1255593744...
Checkpoint 1255593744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,993.18843
Policy Entropy: 3.01222
Value Function Loss: 0.00451

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.59809
Value Function Update Magnitude: 0.53598

Collected Steps per Second: 22,894.48678
Overall Steps per Second: 10,668.28939

Timestep Collection Time: 2.18454
Timestep Consumption Time: 2.50356
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.68810

Cumulative Model Updates: 150,548
Cumulative Timesteps: 1,255,643,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.60668
Policy Entropy: 3.00569
Value Function Loss: 0.00423

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.59327
Value Function Update Magnitude: 0.52086

Collected Steps per Second: 21,842.50861
Overall Steps per Second: 10,472.64631

Timestep Collection Time: 2.29003
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.77625

Cumulative Model Updates: 150,554
Cumulative Timesteps: 1,255,693,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1255693778...
Checkpoint 1255693778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.52868
Policy Entropy: 3.00763
Value Function Loss: 0.00443

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.59615
Value Function Update Magnitude: 0.51878

Collected Steps per Second: 22,681.74109
Overall Steps per Second: 10,664.90017

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68996

Cumulative Model Updates: 150,560
Cumulative Timesteps: 1,255,743,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.49222
Policy Entropy: 3.00271
Value Function Loss: 0.00449

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.59130
Value Function Update Magnitude: 0.52057

Collected Steps per Second: 22,842.79205
Overall Steps per Second: 10,798.49596

Timestep Collection Time: 2.18922
Timestep Consumption Time: 2.44179
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.63102

Cumulative Model Updates: 150,566
Cumulative Timesteps: 1,255,793,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1255793804...
Checkpoint 1255793804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.54398
Policy Entropy: 3.01077
Value Function Loss: 0.00443

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.58095
Value Function Update Magnitude: 0.53218

Collected Steps per Second: 22,670.08834
Overall Steps per Second: 10,740.05781

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.45031
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.65621

Cumulative Model Updates: 150,572
Cumulative Timesteps: 1,255,843,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.91894
Policy Entropy: 3.00649
Value Function Loss: 0.00457

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.53763

Collected Steps per Second: 23,105.66726
Overall Steps per Second: 10,846.36690

Timestep Collection Time: 2.16432
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61058

Cumulative Model Updates: 150,578
Cumulative Timesteps: 1,255,893,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1255893820...
Checkpoint 1255893820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.05602
Policy Entropy: 2.99956
Value Function Loss: 0.00453

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.58043
Value Function Update Magnitude: 0.54518

Collected Steps per Second: 22,867.70636
Overall Steps per Second: 10,685.70144

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.68196

Cumulative Model Updates: 150,584
Cumulative Timesteps: 1,255,943,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.45609
Policy Entropy: 3.00846
Value Function Loss: 0.00445

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.58032
Value Function Update Magnitude: 0.54708

Collected Steps per Second: 23,396.02310
Overall Steps per Second: 10,864.68166

Timestep Collection Time: 2.13737
Timestep Consumption Time: 2.46525
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.60262

Cumulative Model Updates: 150,590
Cumulative Timesteps: 1,255,993,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1255993856...
Checkpoint 1255993856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,636.05451
Policy Entropy: 3.01872
Value Function Loss: 0.00409

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.56809
Value Function Update Magnitude: 0.52825

Collected Steps per Second: 21,918.85266
Overall Steps per Second: 10,586.60169

Timestep Collection Time: 2.28215
Timestep Consumption Time: 2.44288
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.72503

Cumulative Model Updates: 150,596
Cumulative Timesteps: 1,256,043,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,075.50649
Policy Entropy: 3.02568
Value Function Loss: 0.00386

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.56079
Value Function Update Magnitude: 0.49650

Collected Steps per Second: 20,839.57985
Overall Steps per Second: 10,100.27117

Timestep Collection Time: 2.40034
Timestep Consumption Time: 2.55220
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.95254

Cumulative Model Updates: 150,602
Cumulative Timesteps: 1,256,093,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1256093900...
Checkpoint 1256093900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.97440
Policy Entropy: 3.02526
Value Function Loss: 0.00419

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.49070

Collected Steps per Second: 22,795.17308
Overall Steps per Second: 10,665.71951

Timestep Collection Time: 2.19362
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.68829

Cumulative Model Updates: 150,608
Cumulative Timesteps: 1,256,143,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.95908
Policy Entropy: 3.01622
Value Function Loss: 0.00424

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.57117
Value Function Update Magnitude: 0.51291

Collected Steps per Second: 22,666.72291
Overall Steps per Second: 10,635.89283

Timestep Collection Time: 2.20694
Timestep Consumption Time: 2.49638
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.70332

Cumulative Model Updates: 150,614
Cumulative Timesteps: 1,256,193,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1256193928...
Checkpoint 1256193928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.95072
Policy Entropy: 3.01071
Value Function Loss: 0.00416

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.56636
Value Function Update Magnitude: 0.50315

Collected Steps per Second: 22,419.96098
Overall Steps per Second: 10,693.94653

Timestep Collection Time: 2.23114
Timestep Consumption Time: 2.44646
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.67760

Cumulative Model Updates: 150,620
Cumulative Timesteps: 1,256,243,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.57175
Policy Entropy: 3.00813
Value Function Loss: 0.00453

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.56961
Value Function Update Magnitude: 0.49880

Collected Steps per Second: 23,080.82970
Overall Steps per Second: 10,746.33847

Timestep Collection Time: 2.16673
Timestep Consumption Time: 2.48694
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.65368

Cumulative Model Updates: 150,626
Cumulative Timesteps: 1,256,293,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1256293960...
Checkpoint 1256293960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.60592
Policy Entropy: 2.98908
Value Function Loss: 0.00466

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11710
Policy Update Magnitude: 0.58415
Value Function Update Magnitude: 0.52779

Collected Steps per Second: 22,969.56269
Overall Steps per Second: 10,672.79186

Timestep Collection Time: 2.17688
Timestep Consumption Time: 2.50812
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.68500

Cumulative Model Updates: 150,632
Cumulative Timesteps: 1,256,343,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,756.31611
Policy Entropy: 2.99231
Value Function Loss: 0.00462

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.59602
Value Function Update Magnitude: 0.56341

Collected Steps per Second: 23,457.05981
Overall Steps per Second: 10,752.10199

Timestep Collection Time: 2.13232
Timestep Consumption Time: 2.51961
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.65193

Cumulative Model Updates: 150,638
Cumulative Timesteps: 1,256,393,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1256393980...
Checkpoint 1256393980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,432.14705
Policy Entropy: 2.98657
Value Function Loss: 0.00441

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.60318
Value Function Update Magnitude: 0.59518

Collected Steps per Second: 22,906.66101
Overall Steps per Second: 10,750.85980

Timestep Collection Time: 2.18356
Timestep Consumption Time: 2.46891
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.65247

Cumulative Model Updates: 150,644
Cumulative Timesteps: 1,256,443,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.91011
Policy Entropy: 2.98416
Value Function Loss: 0.00428

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.60107
Value Function Update Magnitude: 0.57993

Collected Steps per Second: 23,402.17311
Overall Steps per Second: 10,814.49546

Timestep Collection Time: 2.13818
Timestep Consumption Time: 2.48876
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.62694

Cumulative Model Updates: 150,650
Cumulative Timesteps: 1,256,494,036

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1256494036...
Checkpoint 1256494036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.01991
Policy Entropy: 2.97719
Value Function Loss: 0.00482

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.59876
Value Function Update Magnitude: 0.54468

Collected Steps per Second: 22,837.27573
Overall Steps per Second: 10,734.09579

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.46865
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.65805

Cumulative Model Updates: 150,656
Cumulative Timesteps: 1,256,544,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.37077
Policy Entropy: 2.98243
Value Function Loss: 0.00497

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.60120
Value Function Update Magnitude: 0.51977

Collected Steps per Second: 23,536.72047
Overall Steps per Second: 10,845.48512

Timestep Collection Time: 2.12510
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.61187

Cumulative Model Updates: 150,662
Cumulative Timesteps: 1,256,594,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1256594054...
Checkpoint 1256594054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736.21390
Policy Entropy: 2.98996
Value Function Loss: 0.00482

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.59512
Value Function Update Magnitude: 0.50535

Collected Steps per Second: 22,848.74810
Overall Steps per Second: 10,750.78262

Timestep Collection Time: 2.18830
Timestep Consumption Time: 2.46252
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.65082

Cumulative Model Updates: 150,668
Cumulative Timesteps: 1,256,644,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.39555
Policy Entropy: 3.00107
Value Function Loss: 0.00455

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.58657
Value Function Update Magnitude: 0.51020

Collected Steps per Second: 22,917.39355
Overall Steps per Second: 10,819.18531

Timestep Collection Time: 2.18227
Timestep Consumption Time: 2.44026
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.62253

Cumulative Model Updates: 150,674
Cumulative Timesteps: 1,256,694,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1256694066...
Checkpoint 1256694066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,671.79240
Policy Entropy: 3.01273
Value Function Loss: 0.00426

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.58105
Value Function Update Magnitude: 0.51751

Collected Steps per Second: 22,700.20917
Overall Steps per Second: 10,613.94982

Timestep Collection Time: 2.20306
Timestep Consumption Time: 2.50866
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.71172

Cumulative Model Updates: 150,680
Cumulative Timesteps: 1,256,744,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,148.86890
Policy Entropy: 3.01663
Value Function Loss: 0.00437

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.58115
Value Function Update Magnitude: 0.52118

Collected Steps per Second: 23,053.53899
Overall Steps per Second: 10,855.17782

Timestep Collection Time: 2.16982
Timestep Consumption Time: 2.43830
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60812

Cumulative Model Updates: 150,686
Cumulative Timesteps: 1,256,794,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1256794098...
Checkpoint 1256794098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,188.37759
Policy Entropy: 3.02204
Value Function Loss: 0.00453

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.59432
Value Function Update Magnitude: 0.55591

Collected Steps per Second: 22,583.15917
Overall Steps per Second: 10,678.76508

Timestep Collection Time: 2.21430
Timestep Consumption Time: 2.46845
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.68275

Cumulative Model Updates: 150,692
Cumulative Timesteps: 1,256,844,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.67376
Policy Entropy: 3.01752
Value Function Loss: 0.00446

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.59593
Value Function Update Magnitude: 0.56603

Collected Steps per Second: 23,104.30542
Overall Steps per Second: 10,830.72778

Timestep Collection Time: 2.16462
Timestep Consumption Time: 2.45298
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.61760

Cumulative Model Updates: 150,698
Cumulative Timesteps: 1,256,894,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1256894116...
Checkpoint 1256894116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.53201
Policy Entropy: 3.01844
Value Function Loss: 0.00449

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.59832
Value Function Update Magnitude: 0.57273

Collected Steps per Second: 22,899.92779
Overall Steps per Second: 10,679.72835

Timestep Collection Time: 2.18437
Timestep Consumption Time: 2.49945
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.68383

Cumulative Model Updates: 150,704
Cumulative Timesteps: 1,256,944,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.50013
Policy Entropy: 3.01692
Value Function Loss: 0.00435

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.59793
Value Function Update Magnitude: 0.57127

Collected Steps per Second: 23,149.00404
Overall Steps per Second: 10,924.34446

Timestep Collection Time: 2.16096
Timestep Consumption Time: 2.41817
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.57913

Cumulative Model Updates: 150,710
Cumulative Timesteps: 1,256,994,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1256994162...
Checkpoint 1256994162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,651.05780
Policy Entropy: 3.02218
Value Function Loss: 0.00443

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.59763
Value Function Update Magnitude: 0.57079

Collected Steps per Second: 23,166.84819
Overall Steps per Second: 10,703.31014

Timestep Collection Time: 2.15834
Timestep Consumption Time: 2.51330
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.67164

Cumulative Model Updates: 150,716
Cumulative Timesteps: 1,257,044,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.99422
Policy Entropy: 3.02210
Value Function Loss: 0.00437

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.59031
Value Function Update Magnitude: 0.56819

Collected Steps per Second: 23,434.77065
Overall Steps per Second: 10,905.53452

Timestep Collection Time: 2.13478
Timestep Consumption Time: 2.45262
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.58740

Cumulative Model Updates: 150,722
Cumulative Timesteps: 1,257,094,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1257094192...
Checkpoint 1257094192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.29551
Policy Entropy: 3.03958
Value Function Loss: 0.00438

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.58388
Value Function Update Magnitude: 0.56681

Collected Steps per Second: 23,049.84014
Overall Steps per Second: 10,729.43332

Timestep Collection Time: 2.17043
Timestep Consumption Time: 2.49226
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.66269

Cumulative Model Updates: 150,728
Cumulative Timesteps: 1,257,144,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.48721
Policy Entropy: 3.04412
Value Function Loss: 0.00414

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.57639
Value Function Update Magnitude: 0.57418

Collected Steps per Second: 23,249.32914
Overall Steps per Second: 10,804.78522

Timestep Collection Time: 2.15172
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.62999

Cumulative Model Updates: 150,734
Cumulative Timesteps: 1,257,194,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1257194246...
Checkpoint 1257194246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,729.60932
Policy Entropy: 3.03853
Value Function Loss: 0.00448

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.57933
Value Function Update Magnitude: 0.56074

Collected Steps per Second: 22,388.18801
Overall Steps per Second: 10,650.69384

Timestep Collection Time: 2.23350
Timestep Consumption Time: 2.46141
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.69491

Cumulative Model Updates: 150,740
Cumulative Timesteps: 1,257,244,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.76988
Policy Entropy: 3.02433
Value Function Loss: 0.00472

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.59007
Value Function Update Magnitude: 0.55437

Collected Steps per Second: 22,858.03160
Overall Steps per Second: 10,863.37939

Timestep Collection Time: 2.18864
Timestep Consumption Time: 2.41656
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.60520

Cumulative Model Updates: 150,746
Cumulative Timesteps: 1,257,294,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1257294278...
Checkpoint 1257294278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,872.04240
Policy Entropy: 2.99995
Value Function Loss: 0.00473

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.59396
Value Function Update Magnitude: 0.54936

Collected Steps per Second: 22,578.90053
Overall Steps per Second: 10,748.68168

Timestep Collection Time: 2.21490
Timestep Consumption Time: 2.43776
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.65266

Cumulative Model Updates: 150,752
Cumulative Timesteps: 1,257,344,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.39544
Policy Entropy: 2.99715
Value Function Loss: 0.00449

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.58915
Value Function Update Magnitude: 0.53576

Collected Steps per Second: 23,335.17207
Overall Steps per Second: 10,969.65839

Timestep Collection Time: 2.14277
Timestep Consumption Time: 2.41544
PPO Batch Consumption Time: 0.27677
Total Iteration Time: 4.55821

Cumulative Model Updates: 150,758
Cumulative Timesteps: 1,257,394,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1257394290...
Checkpoint 1257394290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.88967
Policy Entropy: 3.00150
Value Function Loss: 0.00433

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.52716

Collected Steps per Second: 22,839.41024
Overall Steps per Second: 10,865.99273

Timestep Collection Time: 2.19025
Timestep Consumption Time: 2.41347
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.60372

Cumulative Model Updates: 150,764
Cumulative Timesteps: 1,257,444,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.98171
Policy Entropy: 3.02748
Value Function Loss: 0.00437

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.57693
Value Function Update Magnitude: 0.53185

Collected Steps per Second: 23,184.10999
Overall Steps per Second: 10,988.45772

Timestep Collection Time: 2.15674
Timestep Consumption Time: 2.39368
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.55041

Cumulative Model Updates: 150,770
Cumulative Timesteps: 1,257,494,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1257494316...
Checkpoint 1257494316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.21121
Policy Entropy: 3.02738
Value Function Loss: 0.00447

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.57759
Value Function Update Magnitude: 0.53436

Collected Steps per Second: 23,187.54880
Overall Steps per Second: 10,836.08580

Timestep Collection Time: 2.15650
Timestep Consumption Time: 2.45808
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.61458

Cumulative Model Updates: 150,776
Cumulative Timesteps: 1,257,544,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.92179
Policy Entropy: 3.03491
Value Function Loss: 0.00430

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.57849
Value Function Update Magnitude: 0.54416

Collected Steps per Second: 23,299.73265
Overall Steps per Second: 10,734.40030

Timestep Collection Time: 2.14715
Timestep Consumption Time: 2.51338
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.66053

Cumulative Model Updates: 150,782
Cumulative Timesteps: 1,257,594,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1257594348...
Checkpoint 1257594348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,099.05782
Policy Entropy: 3.03734
Value Function Loss: 0.00389

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.52079

Collected Steps per Second: 22,490.54334
Overall Steps per Second: 10,695.48875

Timestep Collection Time: 2.22449
Timestep Consumption Time: 2.45318
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.67767

Cumulative Model Updates: 150,788
Cumulative Timesteps: 1,257,644,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.13168
Policy Entropy: 3.02668
Value Function Loss: 0.00397

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.49400

Collected Steps per Second: 22,964.60206
Overall Steps per Second: 10,937.07781

Timestep Collection Time: 2.17857
Timestep Consumption Time: 2.39578
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.57435

Cumulative Model Updates: 150,794
Cumulative Timesteps: 1,257,694,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1257694408...
Checkpoint 1257694408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.51375
Policy Entropy: 3.01142
Value Function Loss: 0.00421

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.57694
Value Function Update Magnitude: 0.49173

Collected Steps per Second: 22,556.39064
Overall Steps per Second: 10,607.96927

Timestep Collection Time: 2.21693
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.71400

Cumulative Model Updates: 150,800
Cumulative Timesteps: 1,257,744,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.86665
Policy Entropy: 2.99263
Value Function Loss: 0.00464

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.58492
Value Function Update Magnitude: 0.51509

Collected Steps per Second: 22,926.32370
Overall Steps per Second: 10,881.80103

Timestep Collection Time: 2.18125
Timestep Consumption Time: 2.41431
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.59556

Cumulative Model Updates: 150,806
Cumulative Timesteps: 1,257,794,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1257794422...
Checkpoint 1257794422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.65690
Policy Entropy: 3.02126
Value Function Loss: 0.00460

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.59154
Value Function Update Magnitude: 0.53236

Collected Steps per Second: 22,738.29845
Overall Steps per Second: 10,669.42912

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.68685

Cumulative Model Updates: 150,812
Cumulative Timesteps: 1,257,844,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.46633
Policy Entropy: 3.04941
Value Function Loss: 0.00448

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.57976
Value Function Update Magnitude: 0.52826

Collected Steps per Second: 23,231.04138
Overall Steps per Second: 10,857.79677

Timestep Collection Time: 2.15298
Timestep Consumption Time: 2.45348
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60646

Cumulative Model Updates: 150,818
Cumulative Timesteps: 1,257,894,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1257894444...
Checkpoint 1257894444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.74645
Policy Entropy: 3.05157
Value Function Loss: 0.00429

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.57581
Value Function Update Magnitude: 0.50941

Collected Steps per Second: 23,106.77652
Overall Steps per Second: 10,711.22761

Timestep Collection Time: 2.16421
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.66875

Cumulative Model Updates: 150,824
Cumulative Timesteps: 1,257,944,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.15700
Policy Entropy: 3.03311
Value Function Loss: 0.00446

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.58521
Value Function Update Magnitude: 0.51493

Collected Steps per Second: 23,197.14624
Overall Steps per Second: 10,888.24650

Timestep Collection Time: 2.15570
Timestep Consumption Time: 2.43696
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.59266

Cumulative Model Updates: 150,830
Cumulative Timesteps: 1,257,994,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1257994458...
Checkpoint 1257994458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.44270
Policy Entropy: 3.03340
Value Function Loss: 0.00446

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.58949
Value Function Update Magnitude: 0.53412

Collected Steps per Second: 22,850.65169
Overall Steps per Second: 10,736.93922

Timestep Collection Time: 2.18917
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.65906

Cumulative Model Updates: 150,836
Cumulative Timesteps: 1,258,044,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.33758
Policy Entropy: 3.03679
Value Function Loss: 0.00434

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.53178

Collected Steps per Second: 23,344.08554
Overall Steps per Second: 10,810.33216

Timestep Collection Time: 2.14204
Timestep Consumption Time: 2.48353
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.62557

Cumulative Model Updates: 150,842
Cumulative Timesteps: 1,258,094,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1258094486...
Checkpoint 1258094486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.84807
Policy Entropy: 3.03367
Value Function Loss: 0.00432

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.58781
Value Function Update Magnitude: 0.51688

Collected Steps per Second: 22,957.67527
Overall Steps per Second: 10,775.10782

Timestep Collection Time: 2.17862
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.64181

Cumulative Model Updates: 150,848
Cumulative Timesteps: 1,258,144,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,795.91800
Policy Entropy: 3.01781
Value Function Loss: 0.00460

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.59604
Value Function Update Magnitude: 0.51668

Collected Steps per Second: 22,972.36764
Overall Steps per Second: 10,779.53533

Timestep Collection Time: 2.17661
Timestep Consumption Time: 2.46199
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.63860

Cumulative Model Updates: 150,854
Cumulative Timesteps: 1,258,194,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1258194504...
Checkpoint 1258194504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.86778
Policy Entropy: 3.02033
Value Function Loss: 0.00479

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.59796
Value Function Update Magnitude: 0.52828

Collected Steps per Second: 22,362.58827
Overall Steps per Second: 10,625.04381

Timestep Collection Time: 2.23704
Timestep Consumption Time: 2.47127
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.70831

Cumulative Model Updates: 150,860
Cumulative Timesteps: 1,258,244,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.42421
Policy Entropy: 3.01845
Value Function Loss: 0.00459

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.58970
Value Function Update Magnitude: 0.55499

Collected Steps per Second: 22,801.87578
Overall Steps per Second: 10,669.20593

Timestep Collection Time: 2.19315
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.68713

Cumulative Model Updates: 150,866
Cumulative Timesteps: 1,258,294,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1258294538...
Checkpoint 1258294538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.78723
Policy Entropy: 3.02459
Value Function Loss: 0.00430

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.57818
Value Function Update Magnitude: 0.53674

Collected Steps per Second: 22,602.63031
Overall Steps per Second: 10,777.05821

Timestep Collection Time: 2.21346
Timestep Consumption Time: 2.42881
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.64227

Cumulative Model Updates: 150,872
Cumulative Timesteps: 1,258,344,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.51622
Policy Entropy: 3.02667
Value Function Loss: 0.00422

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.57757
Value Function Update Magnitude: 0.52741

Collected Steps per Second: 23,454.63692
Overall Steps per Second: 10,927.45818

Timestep Collection Time: 2.13246
Timestep Consumption Time: 2.44464
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.57709

Cumulative Model Updates: 150,878
Cumulative Timesteps: 1,258,394,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1258394584...
Checkpoint 1258394584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.53696
Policy Entropy: 3.03771
Value Function Loss: 0.00422

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.53520

Collected Steps per Second: 22,713.70612
Overall Steps per Second: 10,676.36413

Timestep Collection Time: 2.20193
Timestep Consumption Time: 2.48262
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.68455

Cumulative Model Updates: 150,884
Cumulative Timesteps: 1,258,444,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,314.52458
Policy Entropy: 3.03572
Value Function Loss: 0.00415

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.57796
Value Function Update Magnitude: 0.54279

Collected Steps per Second: 23,036.10885
Overall Steps per Second: 10,870.09629

Timestep Collection Time: 2.17111
Timestep Consumption Time: 2.42995
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.60106

Cumulative Model Updates: 150,890
Cumulative Timesteps: 1,258,494,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1258494612...
Checkpoint 1258494612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.52977
Policy Entropy: 3.04473
Value Function Loss: 0.00427

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.59310
Value Function Update Magnitude: 0.56625

Collected Steps per Second: 23,134.52341
Overall Steps per Second: 10,753.66502

Timestep Collection Time: 2.16127
Timestep Consumption Time: 2.48831
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.64958

Cumulative Model Updates: 150,896
Cumulative Timesteps: 1,258,544,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,370.76803
Policy Entropy: 3.05129
Value Function Loss: 0.00402

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.59596
Value Function Update Magnitude: 0.57031

Collected Steps per Second: 23,207.10281
Overall Steps per Second: 10,855.87563

Timestep Collection Time: 2.15494
Timestep Consumption Time: 2.45178
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.60672

Cumulative Model Updates: 150,902
Cumulative Timesteps: 1,258,594,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1258594622...
Checkpoint 1258594622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.93532
Policy Entropy: 3.04218
Value Function Loss: 0.00440

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.59077
Value Function Update Magnitude: 0.55961

Collected Steps per Second: 22,843.81307
Overall Steps per Second: 10,675.43940

Timestep Collection Time: 2.18904
Timestep Consumption Time: 2.49517
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68421

Cumulative Model Updates: 150,908
Cumulative Timesteps: 1,258,644,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.74366
Policy Entropy: 3.03460
Value Function Loss: 0.00459

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.58754
Value Function Update Magnitude: 0.55583

Collected Steps per Second: 22,607.90413
Overall Steps per Second: 10,661.48684

Timestep Collection Time: 2.21259
Timestep Consumption Time: 2.47925
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.69184

Cumulative Model Updates: 150,914
Cumulative Timesteps: 1,258,694,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1258694650...
Checkpoint 1258694650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,324.57752
Policy Entropy: 3.03991
Value Function Loss: 0.00523

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.59376
Value Function Update Magnitude: 0.56547

Collected Steps per Second: 22,750.11048
Overall Steps per Second: 10,881.88298

Timestep Collection Time: 2.19911
Timestep Consumption Time: 2.39844
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.59755

Cumulative Model Updates: 150,920
Cumulative Timesteps: 1,258,744,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,320.20480
Policy Entropy: 3.05043
Value Function Loss: 0.00507

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.59541
Value Function Update Magnitude: 0.59944

Collected Steps per Second: 22,897.32784
Overall Steps per Second: 10,690.18650

Timestep Collection Time: 2.18419
Timestep Consumption Time: 2.49412
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.67831

Cumulative Model Updates: 150,926
Cumulative Timesteps: 1,258,794,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1258794692...
Checkpoint 1258794692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.09520
Policy Entropy: 3.05377
Value Function Loss: 0.00481

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.59611
Value Function Update Magnitude: 0.60560

Collected Steps per Second: 22,918.24737
Overall Steps per Second: 10,848.86282

Timestep Collection Time: 2.18376
Timestep Consumption Time: 2.42944
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.61320

Cumulative Model Updates: 150,932
Cumulative Timesteps: 1,258,844,740

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.83714
Policy Entropy: 3.04172
Value Function Loss: 0.00450

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.57573

Collected Steps per Second: 23,130.44871
Overall Steps per Second: 10,661.00468

Timestep Collection Time: 2.16174
Timestep Consumption Time: 2.52844
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.69018

Cumulative Model Updates: 150,938
Cumulative Timesteps: 1,258,894,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1258894742...
Checkpoint 1258894742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.50359
Policy Entropy: 3.05275
Value Function Loss: 0.00441

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.57940
Value Function Update Magnitude: 0.55169

Collected Steps per Second: 23,052.18911
Overall Steps per Second: 10,942.24977

Timestep Collection Time: 2.16986
Timestep Consumption Time: 2.40141
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.57127

Cumulative Model Updates: 150,944
Cumulative Timesteps: 1,258,944,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,957.84444
Policy Entropy: 3.05540
Value Function Loss: 0.00433

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.56945
Value Function Update Magnitude: 0.53573

Collected Steps per Second: 23,430.95497
Overall Steps per Second: 10,889.49219

Timestep Collection Time: 2.13401
Timestep Consumption Time: 2.45775
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.59177

Cumulative Model Updates: 150,950
Cumulative Timesteps: 1,258,994,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1258994764...
Checkpoint 1258994764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,808.24797
Policy Entropy: 3.04038
Value Function Loss: 0.00451

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.57585
Value Function Update Magnitude: 0.52635

Collected Steps per Second: 23,293.36927
Overall Steps per Second: 10,752.79705

Timestep Collection Time: 2.14722
Timestep Consumption Time: 2.50422
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.65144

Cumulative Model Updates: 150,956
Cumulative Timesteps: 1,259,044,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,533.16561
Policy Entropy: 3.04709
Value Function Loss: 0.00468

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.58156
Value Function Update Magnitude: 0.52858

Collected Steps per Second: 23,304.85899
Overall Steps per Second: 10,804.41783

Timestep Collection Time: 2.14625
Timestep Consumption Time: 2.48315
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.62940

Cumulative Model Updates: 150,962
Cumulative Timesteps: 1,259,094,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1259094798...
Checkpoint 1259094798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,183.34228
Policy Entropy: 3.04249
Value Function Loss: 0.00458

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.57979
Value Function Update Magnitude: 0.51862

Collected Steps per Second: 22,553.74782
Overall Steps per Second: 10,623.87203

Timestep Collection Time: 2.21710
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70676

Cumulative Model Updates: 150,968
Cumulative Timesteps: 1,259,144,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.86259
Policy Entropy: 3.03663
Value Function Loss: 0.00459

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.58154
Value Function Update Magnitude: 0.55808

Collected Steps per Second: 22,800.31117
Overall Steps per Second: 10,676.13645

Timestep Collection Time: 2.19330
Timestep Consumption Time: 2.49079
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.68409

Cumulative Model Updates: 150,974
Cumulative Timesteps: 1,259,194,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1259194810...
Checkpoint 1259194810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.38918
Policy Entropy: 3.04658
Value Function Loss: 0.00419

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.57778
Value Function Update Magnitude: 0.55608

Collected Steps per Second: 22,466.65691
Overall Steps per Second: 10,643.66259

Timestep Collection Time: 2.22614
Timestep Consumption Time: 2.47280
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.69895

Cumulative Model Updates: 150,980
Cumulative Timesteps: 1,259,244,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,548.46287
Policy Entropy: 3.02747
Value Function Loss: 0.00413

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.56957
Value Function Update Magnitude: 0.51883

Collected Steps per Second: 23,288.73097
Overall Steps per Second: 10,677.98412

Timestep Collection Time: 2.14825
Timestep Consumption Time: 2.53709
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.68534

Cumulative Model Updates: 150,986
Cumulative Timesteps: 1,259,294,854

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1259294854...
Checkpoint 1259294854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.76049
Policy Entropy: 3.03123
Value Function Loss: 0.00415

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.56729
Value Function Update Magnitude: 0.50310

Collected Steps per Second: 23,076.48571
Overall Steps per Second: 10,602.16061

Timestep Collection Time: 2.16679
Timestep Consumption Time: 2.54941
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.71621

Cumulative Model Updates: 150,992
Cumulative Timesteps: 1,259,344,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.47206
Policy Entropy: 3.03337
Value Function Loss: 0.00437

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.57644
Value Function Update Magnitude: 0.52211

Collected Steps per Second: 23,261.98418
Overall Steps per Second: 10,984.23923

Timestep Collection Time: 2.14986
Timestep Consumption Time: 2.40303
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.55289

Cumulative Model Updates: 150,998
Cumulative Timesteps: 1,259,394,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1259394866...
Checkpoint 1259394866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.57198
Policy Entropy: 3.05033
Value Function Loss: 0.00417

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.58475
Value Function Update Magnitude: 0.54357

Collected Steps per Second: 22,837.38171
Overall Steps per Second: 10,662.21730

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.69208

Cumulative Model Updates: 151,004
Cumulative Timesteps: 1,259,444,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.88097
Policy Entropy: 3.04770
Value Function Loss: 0.00400

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.58463
Value Function Update Magnitude: 0.54386

Collected Steps per Second: 23,280.99477
Overall Steps per Second: 10,820.52832

Timestep Collection Time: 2.14828
Timestep Consumption Time: 2.47386
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.62214

Cumulative Model Updates: 151,010
Cumulative Timesteps: 1,259,494,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1259494908...
Checkpoint 1259494908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.50458
Policy Entropy: 3.05109
Value Function Loss: 0.00393

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.57671
Value Function Update Magnitude: 0.53017

Collected Steps per Second: 21,200.59124
Overall Steps per Second: 10,267.49807

Timestep Collection Time: 2.35946
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.87188

Cumulative Model Updates: 151,016
Cumulative Timesteps: 1,259,544,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164.52777
Policy Entropy: 3.02328
Value Function Loss: 0.00462

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.53008

Collected Steps per Second: 22,685.41130
Overall Steps per Second: 10,844.96370

Timestep Collection Time: 2.20468
Timestep Consumption Time: 2.40705
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61173

Cumulative Model Updates: 151,022
Cumulative Timesteps: 1,259,594,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1259594944...
Checkpoint 1259594944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.74453
Policy Entropy: 3.03034
Value Function Loss: 0.00469

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.59058
Value Function Update Magnitude: 0.53990

Collected Steps per Second: 22,449.20403
Overall Steps per Second: 10,678.09991

Timestep Collection Time: 2.22779
Timestep Consumption Time: 2.45582
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.68360

Cumulative Model Updates: 151,028
Cumulative Timesteps: 1,259,644,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.54188
Policy Entropy: 3.01350
Value Function Loss: 0.00477

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.59327
Value Function Update Magnitude: 0.55868

Collected Steps per Second: 23,026.82293
Overall Steps per Second: 10,830.08651

Timestep Collection Time: 2.17225
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61862

Cumulative Model Updates: 151,034
Cumulative Timesteps: 1,259,694,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1259694976...
Checkpoint 1259694976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,368.61869
Policy Entropy: 3.03926
Value Function Loss: 0.00434

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.58863
Value Function Update Magnitude: 0.55760

Collected Steps per Second: 22,854.87270
Overall Steps per Second: 10,702.10716

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.48446
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.67235

Cumulative Model Updates: 151,040
Cumulative Timesteps: 1,259,744,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759.24813
Policy Entropy: 3.03214
Value Function Loss: 0.00433

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.58275
Value Function Update Magnitude: 0.55239

Collected Steps per Second: 23,279.54500
Overall Steps per Second: 10,978.00562

Timestep Collection Time: 2.14850
Timestep Consumption Time: 2.40752
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.55602

Cumulative Model Updates: 151,046
Cumulative Timesteps: 1,259,794,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1259794996...
Checkpoint 1259794996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.13085
Policy Entropy: 3.03425
Value Function Loss: 0.00430

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.58696
Value Function Update Magnitude: 0.55187

Collected Steps per Second: 23,302.63135
Overall Steps per Second: 10,808.30125

Timestep Collection Time: 2.14654
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.62792

Cumulative Model Updates: 151,052
Cumulative Timesteps: 1,259,845,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,550.05353
Policy Entropy: 3.02709
Value Function Loss: 0.00425

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.59496
Value Function Update Magnitude: 0.55806

Collected Steps per Second: 23,558.50974
Overall Steps per Second: 10,836.22654

Timestep Collection Time: 2.12297
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.61544

Cumulative Model Updates: 151,058
Cumulative Timesteps: 1,259,895,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1259895030...
Checkpoint 1259895030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,980.16637
Policy Entropy: 3.00625
Value Function Loss: 0.00432

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.60043
Value Function Update Magnitude: 0.55567

Collected Steps per Second: 23,177.60260
Overall Steps per Second: 10,986.55522

Timestep Collection Time: 2.15760
Timestep Consumption Time: 2.39415
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.55175

Cumulative Model Updates: 151,064
Cumulative Timesteps: 1,259,945,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,620.70242
Policy Entropy: 3.01719
Value Function Loss: 0.00432

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.59532
Value Function Update Magnitude: 0.55024

Collected Steps per Second: 22,793.19253
Overall Steps per Second: 10,904.68311

Timestep Collection Time: 2.19399
Timestep Consumption Time: 2.39193
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.58592

Cumulative Model Updates: 151,070
Cumulative Timesteps: 1,259,995,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1259995046...
Checkpoint 1259995046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.46372
Policy Entropy: 3.02201
Value Function Loss: 0.00445

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.59144
Value Function Update Magnitude: 0.54486

Collected Steps per Second: 22,588.53422
Overall Steps per Second: 10,606.47109

Timestep Collection Time: 2.21466
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.71655

Cumulative Model Updates: 151,076
Cumulative Timesteps: 1,260,045,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.84577
Policy Entropy: 3.04268
Value Function Loss: 0.00410

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.58155
Value Function Update Magnitude: 0.53228

Collected Steps per Second: 22,992.22167
Overall Steps per Second: 10,843.63794

Timestep Collection Time: 2.17517
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61211

Cumulative Model Updates: 151,082
Cumulative Timesteps: 1,260,095,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1260095084...
Checkpoint 1260095084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.67944
Policy Entropy: 3.03920
Value Function Loss: 0.00433

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.53109

Collected Steps per Second: 22,846.97838
Overall Steps per Second: 10,757.13009

Timestep Collection Time: 2.18891
Timestep Consumption Time: 2.46010
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.64901

Cumulative Model Updates: 151,088
Cumulative Timesteps: 1,260,145,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657.93999
Policy Entropy: 3.03240
Value Function Loss: 0.00432

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.58876
Value Function Update Magnitude: 0.54911

Collected Steps per Second: 23,121.16704
Overall Steps per Second: 10,848.41378

Timestep Collection Time: 2.16261
Timestep Consumption Time: 2.44655
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.60915

Cumulative Model Updates: 151,094
Cumulative Timesteps: 1,260,195,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1260195096...
Checkpoint 1260195096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,758.60947
Policy Entropy: 3.04340
Value Function Loss: 0.00453

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.58943
Value Function Update Magnitude: 0.54402

Collected Steps per Second: 22,787.60397
Overall Steps per Second: 10,699.60853

Timestep Collection Time: 2.19470
Timestep Consumption Time: 2.47949
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.67419

Cumulative Model Updates: 151,100
Cumulative Timesteps: 1,260,245,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,492.65778
Policy Entropy: 3.03057
Value Function Loss: 0.00475

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.59144
Value Function Update Magnitude: 0.56666

Collected Steps per Second: 23,285.06433
Overall Steps per Second: 10,873.10016

Timestep Collection Time: 2.14730
Timestep Consumption Time: 2.45121
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.59850

Cumulative Model Updates: 151,106
Cumulative Timesteps: 1,260,295,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1260295108...
Checkpoint 1260295108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.37625
Policy Entropy: 3.03013
Value Function Loss: 0.00444

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.59381
Value Function Update Magnitude: 0.59099

Collected Steps per Second: 23,215.21001
Overall Steps per Second: 10,830.92894

Timestep Collection Time: 2.15376
Timestep Consumption Time: 2.46265
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.61641

Cumulative Model Updates: 151,112
Cumulative Timesteps: 1,260,345,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.58850
Policy Entropy: 3.02223
Value Function Loss: 0.00422

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.57959
Value Function Update Magnitude: 0.56068

Collected Steps per Second: 23,275.32212
Overall Steps per Second: 10,691.37623

Timestep Collection Time: 2.14949
Timestep Consumption Time: 2.52999
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.67947

Cumulative Model Updates: 151,118
Cumulative Timesteps: 1,260,395,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1260395138...
Checkpoint 1260395138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.28282
Policy Entropy: 3.01643
Value Function Loss: 0.00433

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.56820
Value Function Update Magnitude: 0.52048

Collected Steps per Second: 22,905.95344
Overall Steps per Second: 10,665.01346

Timestep Collection Time: 2.18458
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.69198

Cumulative Model Updates: 151,124
Cumulative Timesteps: 1,260,445,178

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.67403
Policy Entropy: 3.00799
Value Function Loss: 0.00436

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.51232

Collected Steps per Second: 22,649.62180
Overall Steps per Second: 10,833.42295

Timestep Collection Time: 2.20860
Timestep Consumption Time: 2.40896
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.61756

Cumulative Model Updates: 151,130
Cumulative Timesteps: 1,260,495,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1260495202...
Checkpoint 1260495202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,392.22820
Policy Entropy: 3.00068
Value Function Loss: 0.00440

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.58527
Value Function Update Magnitude: 0.52932

Collected Steps per Second: 22,771.64268
Overall Steps per Second: 10,674.16675

Timestep Collection Time: 2.19677
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.68645

Cumulative Model Updates: 151,136
Cumulative Timesteps: 1,260,545,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.07204
Policy Entropy: 3.01333
Value Function Loss: 0.00416

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.58530
Value Function Update Magnitude: 0.52252

Collected Steps per Second: 22,618.03712
Overall Steps per Second: 10,726.70314

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.45074
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.66145

Cumulative Model Updates: 151,142
Cumulative Timesteps: 1,260,595,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1260595228...
Checkpoint 1260595228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.09576
Policy Entropy: 3.01302
Value Function Loss: 0.00434

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.58117
Value Function Update Magnitude: 0.50975

Collected Steps per Second: 22,583.77658
Overall Steps per Second: 10,802.64606

Timestep Collection Time: 2.21460
Timestep Consumption Time: 2.41519
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.62979

Cumulative Model Updates: 151,148
Cumulative Timesteps: 1,260,645,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.33767
Policy Entropy: 3.03907
Value Function Loss: 0.00442

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.49148

Collected Steps per Second: 23,125.95504
Overall Steps per Second: 10,906.71071

Timestep Collection Time: 2.16294
Timestep Consumption Time: 2.42323
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.58617

Cumulative Model Updates: 151,154
Cumulative Timesteps: 1,260,695,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1260695262...
Checkpoint 1260695262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894.08588
Policy Entropy: 3.03373
Value Function Loss: 0.00449

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.56614
Value Function Update Magnitude: 0.47682

Collected Steps per Second: 22,912.58420
Overall Steps per Second: 10,727.87088

Timestep Collection Time: 2.18317
Timestep Consumption Time: 2.47964
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.66281

Cumulative Model Updates: 151,160
Cumulative Timesteps: 1,260,745,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.80742
Policy Entropy: 3.04702
Value Function Loss: 0.00455

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.47708

Collected Steps per Second: 23,381.69228
Overall Steps per Second: 10,908.25062

Timestep Collection Time: 2.13843
Timestep Consumption Time: 2.44526
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.58369

Cumulative Model Updates: 151,166
Cumulative Timesteps: 1,260,795,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1260795284...
Checkpoint 1260795284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.88327
Policy Entropy: 3.03365
Value Function Loss: 0.00465

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.57279
Value Function Update Magnitude: 0.48750

Collected Steps per Second: 22,858.61417
Overall Steps per Second: 10,772.31394

Timestep Collection Time: 2.18736
Timestep Consumption Time: 2.45417
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.64153

Cumulative Model Updates: 151,172
Cumulative Timesteps: 1,260,845,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.78138
Policy Entropy: 3.03915
Value Function Loss: 0.00452

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.58546
Value Function Update Magnitude: 0.51365

Collected Steps per Second: 23,082.42709
Overall Steps per Second: 10,752.84399

Timestep Collection Time: 2.16667
Timestep Consumption Time: 2.48438
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.65105

Cumulative Model Updates: 151,178
Cumulative Timesteps: 1,260,895,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1260895296...
Checkpoint 1260895296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.48814
Policy Entropy: 3.02313
Value Function Loss: 0.00459

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.59056
Value Function Update Magnitude: 0.53757

Collected Steps per Second: 22,970.79452
Overall Steps per Second: 10,689.59125

Timestep Collection Time: 2.17772
Timestep Consumption Time: 2.50197
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.67969

Cumulative Model Updates: 151,184
Cumulative Timesteps: 1,260,945,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,231.59549
Policy Entropy: 3.02041
Value Function Loss: 0.00418

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.53149

Collected Steps per Second: 22,685.77283
Overall Steps per Second: 10,780.63208

Timestep Collection Time: 2.20411
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.63813

Cumulative Model Updates: 151,190
Cumulative Timesteps: 1,260,995,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1260995322...
Checkpoint 1260995322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,078.52417
Policy Entropy: 3.00177
Value Function Loss: 0.00444

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.57415
Value Function Update Magnitude: 0.52370

Collected Steps per Second: 22,515.89250
Overall Steps per Second: 10,775.14636

Timestep Collection Time: 2.22065
Timestep Consumption Time: 2.41965
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.64031

Cumulative Model Updates: 151,196
Cumulative Timesteps: 1,261,045,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.76326
Policy Entropy: 3.00131
Value Function Loss: 0.00413

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.57439
Value Function Update Magnitude: 0.50648

Collected Steps per Second: 22,886.04902
Overall Steps per Second: 10,844.98797

Timestep Collection Time: 2.18544
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.61190

Cumulative Model Updates: 151,202
Cumulative Timesteps: 1,261,095,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1261095338...
Checkpoint 1261095338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,568.83976
Policy Entropy: 2.99655
Value Function Loss: 0.00429

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.58367
Value Function Update Magnitude: 0.51523

Collected Steps per Second: 22,722.15733
Overall Steps per Second: 10,674.39210

Timestep Collection Time: 2.20146
Timestep Consumption Time: 2.48470
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.68617

Cumulative Model Updates: 151,208
Cumulative Timesteps: 1,261,145,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,354.27058
Policy Entropy: 3.01092
Value Function Loss: 0.00415

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.58653
Value Function Update Magnitude: 0.51551

Collected Steps per Second: 23,223.63260
Overall Steps per Second: 10,876.02959

Timestep Collection Time: 2.15393
Timestep Consumption Time: 2.44536
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.59929

Cumulative Model Updates: 151,214
Cumulative Timesteps: 1,261,195,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1261195382...
Checkpoint 1261195382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.34178
Policy Entropy: 3.00815
Value Function Loss: 0.00401

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.58224
Value Function Update Magnitude: 0.51950

Collected Steps per Second: 23,154.10283
Overall Steps per Second: 11,001.58036

Timestep Collection Time: 2.15944
Timestep Consumption Time: 2.38536
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.54480

Cumulative Model Updates: 151,220
Cumulative Timesteps: 1,261,245,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.03100
Policy Entropy: 3.01469
Value Function Loss: 0.00384

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.56689
Value Function Update Magnitude: 0.49951

Collected Steps per Second: 23,289.33636
Overall Steps per Second: 10,926.08570

Timestep Collection Time: 2.14768
Timestep Consumption Time: 2.43017
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.57785

Cumulative Model Updates: 151,226
Cumulative Timesteps: 1,261,295,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1261295400...
Checkpoint 1261295400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537.79437
Policy Entropy: 3.01889
Value Function Loss: 0.00395

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.48272

Collected Steps per Second: 23,116.63594
Overall Steps per Second: 10,683.98389

Timestep Collection Time: 2.16355
Timestep Consumption Time: 2.51766
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.68121

Cumulative Model Updates: 151,232
Cumulative Timesteps: 1,261,345,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,225.47255
Policy Entropy: 3.02859
Value Function Loss: 0.00430

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.56586
Value Function Update Magnitude: 0.48487

Collected Steps per Second: 23,318.59979
Overall Steps per Second: 10,922.81951

Timestep Collection Time: 2.14524
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.57977

Cumulative Model Updates: 151,238
Cumulative Timesteps: 1,261,395,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1261395438...
Checkpoint 1261395438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.95851
Policy Entropy: 3.01326
Value Function Loss: 0.00455

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.57339
Value Function Update Magnitude: 0.49326

Collected Steps per Second: 23,016.15202
Overall Steps per Second: 10,658.30535

Timestep Collection Time: 2.17352
Timestep Consumption Time: 2.52010
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.69362

Cumulative Model Updates: 151,244
Cumulative Timesteps: 1,261,445,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.30997
Policy Entropy: 3.01454
Value Function Loss: 0.00427

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.50729

Collected Steps per Second: 22,657.44218
Overall Steps per Second: 10,835.24496

Timestep Collection Time: 2.20749
Timestep Consumption Time: 2.40856
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61605

Cumulative Model Updates: 151,250
Cumulative Timesteps: 1,261,495,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1261495480...
Checkpoint 1261495480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.51085
Policy Entropy: 3.01146
Value Function Loss: 0.00405

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.56683
Value Function Update Magnitude: 0.50833

Collected Steps per Second: 22,425.03470
Overall Steps per Second: 10,733.42334

Timestep Collection Time: 2.23063
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.66040

Cumulative Model Updates: 151,256
Cumulative Timesteps: 1,261,545,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,491.86669
Policy Entropy: 3.02755
Value Function Loss: 0.00412

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.56807
Value Function Update Magnitude: 0.50917

Collected Steps per Second: 22,616.13114
Overall Steps per Second: 10,822.26028

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.41026
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.62196

Cumulative Model Updates: 151,262
Cumulative Timesteps: 1,261,595,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1261595522...
Checkpoint 1261595522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.15710
Policy Entropy: 3.01315
Value Function Loss: 0.00433

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.57453
Value Function Update Magnitude: 0.51388

Collected Steps per Second: 22,705.02010
Overall Steps per Second: 10,731.60250

Timestep Collection Time: 2.20321
Timestep Consumption Time: 2.45816
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.66137

Cumulative Model Updates: 151,268
Cumulative Timesteps: 1,261,645,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.36712
Policy Entropy: 3.00377
Value Function Loss: 0.00428

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.57761
Value Function Update Magnitude: 0.50664

Collected Steps per Second: 23,216.93089
Overall Steps per Second: 10,867.27668

Timestep Collection Time: 2.15446
Timestep Consumption Time: 2.44835
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60281

Cumulative Model Updates: 151,274
Cumulative Timesteps: 1,261,695,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1261695566...
Checkpoint 1261695566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.69909
Policy Entropy: 3.00692
Value Function Loss: 0.00467

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.59309
Value Function Update Magnitude: 0.52509

Collected Steps per Second: 23,160.48475
Overall Steps per Second: 10,714.07236

Timestep Collection Time: 2.15971
Timestep Consumption Time: 2.50891
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.66863

Cumulative Model Updates: 151,280
Cumulative Timesteps: 1,261,745,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,706.36134
Policy Entropy: 3.00439
Value Function Loss: 0.00484

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.60488
Value Function Update Magnitude: 0.53687

Collected Steps per Second: 22,986.87632
Overall Steps per Second: 10,886.04358

Timestep Collection Time: 2.17550
Timestep Consumption Time: 2.41827
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.59377

Cumulative Model Updates: 151,286
Cumulative Timesteps: 1,261,795,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1261795594...
Checkpoint 1261795594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.55686
Policy Entropy: 3.00754
Value Function Loss: 0.00474

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.60173
Value Function Update Magnitude: 0.53276

Collected Steps per Second: 23,089.03181
Overall Steps per Second: 10,651.76425

Timestep Collection Time: 2.16640
Timestep Consumption Time: 2.52954
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.69594

Cumulative Model Updates: 151,292
Cumulative Timesteps: 1,261,845,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.73168
Policy Entropy: 3.00673
Value Function Loss: 0.00462

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.59334
Value Function Update Magnitude: 0.53239

Collected Steps per Second: 23,258.40812
Overall Steps per Second: 10,900.74024

Timestep Collection Time: 2.15062
Timestep Consumption Time: 2.43806
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.58868

Cumulative Model Updates: 151,298
Cumulative Timesteps: 1,261,895,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1261895634...
Checkpoint 1261895634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.32602
Policy Entropy: 3.01364
Value Function Loss: 0.00449

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.59398
Value Function Update Magnitude: 0.53741

Collected Steps per Second: 22,932.81504
Overall Steps per Second: 10,756.07147

Timestep Collection Time: 2.18081
Timestep Consumption Time: 2.46885
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.64965

Cumulative Model Updates: 151,304
Cumulative Timesteps: 1,261,945,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.33582
Policy Entropy: 3.01382
Value Function Loss: 0.00454

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.59460
Value Function Update Magnitude: 0.56059

Collected Steps per Second: 22,644.50112
Overall Steps per Second: 10,815.51754

Timestep Collection Time: 2.20813
Timestep Consumption Time: 2.41504
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62317

Cumulative Model Updates: 151,310
Cumulative Timesteps: 1,261,995,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1261995648...
Checkpoint 1261995648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,062.18419
Policy Entropy: 3.01181
Value Function Loss: 0.00423

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.59233
Value Function Update Magnitude: 0.56895

Collected Steps per Second: 22,864.50078
Overall Steps per Second: 10,729.87030

Timestep Collection Time: 2.18820
Timestep Consumption Time: 2.47468
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.66287

Cumulative Model Updates: 151,316
Cumulative Timesteps: 1,262,045,680

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,053.48920
Policy Entropy: 3.01676
Value Function Loss: 0.00396

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.58939
Value Function Update Magnitude: 0.55697

Collected Steps per Second: 22,589.60615
Overall Steps per Second: 10,808.30335

Timestep Collection Time: 2.21429
Timestep Consumption Time: 2.41363
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62792

Cumulative Model Updates: 151,322
Cumulative Timesteps: 1,262,095,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1262095700...
Checkpoint 1262095700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.15295
Policy Entropy: 3.01871
Value Function Loss: 0.00395

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.58061
Value Function Update Magnitude: 0.54194

Collected Steps per Second: 22,682.95983
Overall Steps per Second: 10,639.95278

Timestep Collection Time: 2.20483
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.70040

Cumulative Model Updates: 151,328
Cumulative Timesteps: 1,262,145,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.42837
Policy Entropy: 3.00936
Value Function Loss: 0.00430

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.58266
Value Function Update Magnitude: 0.53078

Collected Steps per Second: 23,130.88147
Overall Steps per Second: 10,848.95961

Timestep Collection Time: 2.16256
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.61076

Cumulative Model Updates: 151,334
Cumulative Timesteps: 1,262,195,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1262195734...
Checkpoint 1262195734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.65676
Policy Entropy: 3.00198
Value Function Loss: 0.00434

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.58957
Value Function Update Magnitude: 0.52433

Collected Steps per Second: 23,056.56449
Overall Steps per Second: 10,673.56743

Timestep Collection Time: 2.16858
Timestep Consumption Time: 2.51589
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.68447

Cumulative Model Updates: 151,340
Cumulative Timesteps: 1,262,245,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,525.53123
Policy Entropy: 3.00034
Value Function Loss: 0.00452

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.59253
Value Function Update Magnitude: 0.52652

Collected Steps per Second: 23,275.66069
Overall Steps per Second: 10,922.94663

Timestep Collection Time: 2.14903
Timestep Consumption Time: 2.43032
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.57935

Cumulative Model Updates: 151,346
Cumulative Timesteps: 1,262,295,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1262295754...
Checkpoint 1262295754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.83788
Policy Entropy: 3.01840
Value Function Loss: 0.00439

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.59105
Value Function Update Magnitude: 0.52509

Collected Steps per Second: 22,939.67707
Overall Steps per Second: 10,643.09982

Timestep Collection Time: 2.18102
Timestep Consumption Time: 2.51986
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.70089

Cumulative Model Updates: 151,352
Cumulative Timesteps: 1,262,345,786

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.14321
Policy Entropy: 3.03018
Value Function Loss: 0.00428

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.58280
Value Function Update Magnitude: 0.53529

Collected Steps per Second: 23,111.91914
Overall Steps per Second: 10,857.47377

Timestep Collection Time: 2.16339
Timestep Consumption Time: 2.44174
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60512

Cumulative Model Updates: 151,358
Cumulative Timesteps: 1,262,395,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1262395786...
Checkpoint 1262395786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.73346
Policy Entropy: 3.01793
Value Function Loss: 0.00411

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.52323

Collected Steps per Second: 23,091.87470
Overall Steps per Second: 10,774.49519

Timestep Collection Time: 2.16622
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.64263

Cumulative Model Updates: 151,364
Cumulative Timesteps: 1,262,445,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.05272
Policy Entropy: 3.02725
Value Function Loss: 0.00405

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.56670
Value Function Update Magnitude: 0.48208

Collected Steps per Second: 22,724.71620
Overall Steps per Second: 10,832.18828

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.41563
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61587

Cumulative Model Updates: 151,370
Cumulative Timesteps: 1,262,495,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1262495808...
Checkpoint 1262495808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.27908
Policy Entropy: 3.02599
Value Function Loss: 0.00448

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.57140
Value Function Update Magnitude: 0.49140

Collected Steps per Second: 22,668.35650
Overall Steps per Second: 10,675.85033

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.47805
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.68403

Cumulative Model Updates: 151,376
Cumulative Timesteps: 1,262,545,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,547.53658
Policy Entropy: 3.03401
Value Function Loss: 0.00428

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.57473
Value Function Update Magnitude: 0.51225

Collected Steps per Second: 22,488.15479
Overall Steps per Second: 10,595.48215

Timestep Collection Time: 2.22455
Timestep Consumption Time: 2.49690
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.72145

Cumulative Model Updates: 151,382
Cumulative Timesteps: 1,262,595,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1262595840...
Checkpoint 1262595840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,424.70772
Policy Entropy: 3.02374
Value Function Loss: 0.00440

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.56957
Value Function Update Magnitude: 0.53367

Collected Steps per Second: 22,821.17176
Overall Steps per Second: 10,853.93977

Timestep Collection Time: 2.19147
Timestep Consumption Time: 2.41625
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.60773

Cumulative Model Updates: 151,388
Cumulative Timesteps: 1,262,645,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.60602
Policy Entropy: 3.00598
Value Function Loss: 0.00417

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.54427

Collected Steps per Second: 23,193.73307
Overall Steps per Second: 10,754.68121

Timestep Collection Time: 2.15593
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.64951

Cumulative Model Updates: 151,394
Cumulative Timesteps: 1,262,695,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1262695856...
Checkpoint 1262695856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,804.57527
Policy Entropy: 2.99811
Value Function Loss: 0.00444

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.58155
Value Function Update Magnitude: 0.53650

Collected Steps per Second: 23,158.74694
Overall Steps per Second: 10,871.45159

Timestep Collection Time: 2.15936
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.59994

Cumulative Model Updates: 151,400
Cumulative Timesteps: 1,262,745,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.59160
Policy Entropy: 2.99854
Value Function Loss: 0.00451

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.58554
Value Function Update Magnitude: 0.53631

Collected Steps per Second: 23,204.46045
Overall Steps per Second: 10,903.79814

Timestep Collection Time: 2.15510
Timestep Consumption Time: 2.43119
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.58629

Cumulative Model Updates: 151,406
Cumulative Timesteps: 1,262,795,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1262795872...
Checkpoint 1262795872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.22756
Policy Entropy: 3.00624
Value Function Loss: 0.00470

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.59160
Value Function Update Magnitude: 0.54778

Collected Steps per Second: 23,013.86129
Overall Steps per Second: 10,677.00049

Timestep Collection Time: 2.17278
Timestep Consumption Time: 2.51056
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.68334

Cumulative Model Updates: 151,412
Cumulative Timesteps: 1,262,845,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.43607
Policy Entropy: 3.01050
Value Function Loss: 0.00484

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.60690
Value Function Update Magnitude: 0.56194

Collected Steps per Second: 23,334.96234
Overall Steps per Second: 10,898.40946

Timestep Collection Time: 2.14322
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.58893

Cumulative Model Updates: 151,418
Cumulative Timesteps: 1,262,895,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1262895888...
Checkpoint 1262895888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.62325
Policy Entropy: 3.02403
Value Function Loss: 0.00457

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.60843
Value Function Update Magnitude: 0.55941

Collected Steps per Second: 23,356.02990
Overall Steps per Second: 11,008.46012

Timestep Collection Time: 2.14163
Timestep Consumption Time: 2.40215
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.54378

Cumulative Model Updates: 151,424
Cumulative Timesteps: 1,262,945,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.18979
Policy Entropy: 3.02993
Value Function Loss: 0.00450

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.59547
Value Function Update Magnitude: 0.55993

Collected Steps per Second: 22,708.16946
Overall Steps per Second: 10,597.90662

Timestep Collection Time: 2.20203
Timestep Consumption Time: 2.51626
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.71829

Cumulative Model Updates: 151,430
Cumulative Timesteps: 1,262,995,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1262995912...
Checkpoint 1262995912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,244.56145
Policy Entropy: 3.03922
Value Function Loss: 0.00415

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.59114
Value Function Update Magnitude: 0.55240

Collected Steps per Second: 23,020.56401
Overall Steps per Second: 10,737.32148

Timestep Collection Time: 2.17284
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.65852

Cumulative Model Updates: 151,436
Cumulative Timesteps: 1,263,045,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,160.72738
Policy Entropy: 3.01763
Value Function Loss: 0.00449

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.60470
Value Function Update Magnitude: 0.54726

Collected Steps per Second: 22,851.67770
Overall Steps per Second: 10,761.46466

Timestep Collection Time: 2.18820
Timestep Consumption Time: 2.45838
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.64658

Cumulative Model Updates: 151,442
Cumulative Timesteps: 1,263,095,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1263095936...
Checkpoint 1263095936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.36220
Policy Entropy: 3.00777
Value Function Loss: 0.00444

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.60510
Value Function Update Magnitude: 0.56653

Collected Steps per Second: 22,867.02059
Overall Steps per Second: 10,665.47898

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.50247
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.68990

Cumulative Model Updates: 151,448
Cumulative Timesteps: 1,263,145,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.25622
Policy Entropy: 3.01438
Value Function Loss: 0.00429

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11018
Policy Update Magnitude: 0.59221
Value Function Update Magnitude: 0.55702

Collected Steps per Second: 22,847.93696
Overall Steps per Second: 10,764.62941

Timestep Collection Time: 2.18891
Timestep Consumption Time: 2.45705
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.64596

Cumulative Model Updates: 151,454
Cumulative Timesteps: 1,263,195,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1263195968...
Checkpoint 1263195968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,881.79017
Policy Entropy: 3.01873
Value Function Loss: 0.00422

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.58718
Value Function Update Magnitude: 0.54681

Collected Steps per Second: 23,059.36172
Overall Steps per Second: 10,768.48129

Timestep Collection Time: 2.16901
Timestep Consumption Time: 2.47566
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.64467

Cumulative Model Updates: 151,460
Cumulative Timesteps: 1,263,245,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.89352
Policy Entropy: 3.03363
Value Function Loss: 0.00412

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.57849
Value Function Update Magnitude: 0.53747

Collected Steps per Second: 23,413.76296
Overall Steps per Second: 10,883.11752

Timestep Collection Time: 2.13669
Timestep Consumption Time: 2.46015
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.59684

Cumulative Model Updates: 151,466
Cumulative Timesteps: 1,263,296,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1263296012...
Checkpoint 1263296012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.01165
Policy Entropy: 3.03231
Value Function Loss: 0.00396

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.56946
Value Function Update Magnitude: 0.52804

Collected Steps per Second: 23,029.88535
Overall Steps per Second: 10,708.68854

Timestep Collection Time: 2.17187
Timestep Consumption Time: 2.49891
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.67079

Cumulative Model Updates: 151,472
Cumulative Timesteps: 1,263,346,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.52031
Policy Entropy: 3.03911
Value Function Loss: 0.00407

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.57119
Value Function Update Magnitude: 0.52268

Collected Steps per Second: 21,817.50878
Overall Steps per Second: 10,364.29124

Timestep Collection Time: 2.29192
Timestep Consumption Time: 2.53272
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.82464

Cumulative Model Updates: 151,478
Cumulative Timesteps: 1,263,396,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1263396034...
Checkpoint 1263396034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,042.28975
Policy Entropy: 3.02144
Value Function Loss: 0.00431

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.58470
Value Function Update Magnitude: 0.53806

Collected Steps per Second: 22,927.59929
Overall Steps per Second: 10,712.93079

Timestep Collection Time: 2.18156
Timestep Consumption Time: 2.48737
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.66894

Cumulative Model Updates: 151,484
Cumulative Timesteps: 1,263,446,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.14766
Policy Entropy: 3.01574
Value Function Loss: 0.00460

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.59724
Value Function Update Magnitude: 0.55209

Collected Steps per Second: 23,196.45649
Overall Steps per Second: 10,916.47944

Timestep Collection Time: 2.15619
Timestep Consumption Time: 2.42551
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.58170

Cumulative Model Updates: 151,490
Cumulative Timesteps: 1,263,496,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1263496068...
Checkpoint 1263496068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,618.48819
Policy Entropy: 3.01405
Value Function Loss: 0.00443

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.58283
Value Function Update Magnitude: 0.54247

Collected Steps per Second: 22,745.40267
Overall Steps per Second: 10,620.45211

Timestep Collection Time: 2.19877
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.70903

Cumulative Model Updates: 151,496
Cumulative Timesteps: 1,263,546,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.69403
Policy Entropy: 3.02434
Value Function Loss: 0.00434

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.57222
Value Function Update Magnitude: 0.51973

Collected Steps per Second: 22,512.58282
Overall Steps per Second: 10,635.80408

Timestep Collection Time: 2.22196
Timestep Consumption Time: 2.48121
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.70317

Cumulative Model Updates: 151,502
Cumulative Timesteps: 1,263,596,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1263596102...
Checkpoint 1263596102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,969.38552
Policy Entropy: 3.01618
Value Function Loss: 0.00424

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.57184
Value Function Update Magnitude: 0.51304

Collected Steps per Second: 22,783.03365
Overall Steps per Second: 10,817.43475

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.62402

Cumulative Model Updates: 151,508
Cumulative Timesteps: 1,263,646,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,020.21421
Policy Entropy: 3.01553
Value Function Loss: 0.00427

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.57554
Value Function Update Magnitude: 0.51268

Collected Steps per Second: 22,775.48425
Overall Steps per Second: 10,735.09608

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.46297
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.65892

Cumulative Model Updates: 151,514
Cumulative Timesteps: 1,263,696,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1263696136...
Checkpoint 1263696136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,435.80396
Policy Entropy: 2.99533
Value Function Loss: 0.00448

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.58410
Value Function Update Magnitude: 0.51161

Collected Steps per Second: 23,204.70656
Overall Steps per Second: 10,827.22384

Timestep Collection Time: 2.15542
Timestep Consumption Time: 2.46404
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61947

Cumulative Model Updates: 151,520
Cumulative Timesteps: 1,263,746,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.92787
Policy Entropy: 2.99720
Value Function Loss: 0.00451

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.59222
Value Function Update Magnitude: 0.51397

Collected Steps per Second: 22,865.42188
Overall Steps per Second: 10,661.55515

Timestep Collection Time: 2.18715
Timestep Consumption Time: 2.50354
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.69069

Cumulative Model Updates: 151,526
Cumulative Timesteps: 1,263,796,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1263796162...
Checkpoint 1263796162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.23509
Policy Entropy: 3.00762
Value Function Loss: 0.00438

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.58475
Value Function Update Magnitude: 0.51220

Collected Steps per Second: 23,201.63447
Overall Steps per Second: 10,840.40345

Timestep Collection Time: 2.15606
Timestep Consumption Time: 2.45853
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.61459

Cumulative Model Updates: 151,532
Cumulative Timesteps: 1,263,846,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.97326
Policy Entropy: 3.01201
Value Function Loss: 0.00421

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.58329
Value Function Update Magnitude: 0.52761

Collected Steps per Second: 23,034.37229
Overall Steps per Second: 10,728.65522

Timestep Collection Time: 2.17102
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.66116

Cumulative Model Updates: 151,538
Cumulative Timesteps: 1,263,896,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1263896194...
Checkpoint 1263896194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.54539
Policy Entropy: 3.00285
Value Function Loss: 0.00443

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.58643
Value Function Update Magnitude: 0.55421

Collected Steps per Second: 23,451.00716
Overall Steps per Second: 10,910.40913

Timestep Collection Time: 2.13313
Timestep Consumption Time: 2.45185
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.58498

Cumulative Model Updates: 151,544
Cumulative Timesteps: 1,263,946,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.08196
Policy Entropy: 3.00672
Value Function Loss: 0.00429

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.59057
Value Function Update Magnitude: 0.55401

Collected Steps per Second: 23,098.26458
Overall Steps per Second: 10,851.03189

Timestep Collection Time: 2.16588
Timestep Consumption Time: 2.44456
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.61044

Cumulative Model Updates: 151,550
Cumulative Timesteps: 1,263,996,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1263996246...
Checkpoint 1263996246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.19314
Policy Entropy: 3.01595
Value Function Loss: 0.00454

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.59529
Value Function Update Magnitude: 0.55360

Collected Steps per Second: 22,702.60522
Overall Steps per Second: 10,724.70240

Timestep Collection Time: 2.20257
Timestep Consumption Time: 2.45994
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.66251

Cumulative Model Updates: 151,556
Cumulative Timesteps: 1,264,046,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,059.52938
Policy Entropy: 3.02061
Value Function Loss: 0.00427

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.58333
Value Function Update Magnitude: 0.54605

Collected Steps per Second: 22,593.46053
Overall Steps per Second: 10,657.26712

Timestep Collection Time: 2.21330
Timestep Consumption Time: 2.47890
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.69220

Cumulative Model Updates: 151,562
Cumulative Timesteps: 1,264,096,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1264096256...
Checkpoint 1264096256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,231.03290
Policy Entropy: 3.01863
Value Function Loss: 0.00420

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.57978
Value Function Update Magnitude: 0.54512

Collected Steps per Second: 22,945.18080
Overall Steps per Second: 10,857.38290

Timestep Collection Time: 2.17989
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60682

Cumulative Model Updates: 151,568
Cumulative Timesteps: 1,264,146,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.35135
Policy Entropy: 3.02567
Value Function Loss: 0.00398

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.58044
Value Function Update Magnitude: 0.55316

Collected Steps per Second: 23,078.33976
Overall Steps per Second: 10,622.71257

Timestep Collection Time: 2.16757
Timestep Consumption Time: 2.54158
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.70916

Cumulative Model Updates: 151,574
Cumulative Timesteps: 1,264,196,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1264196298...
Checkpoint 1264196298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,972.26328
Policy Entropy: 3.02641
Value Function Loss: 0.00417

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.51908

Collected Steps per Second: 23,165.42677
Overall Steps per Second: 10,867.45646

Timestep Collection Time: 2.15839
Timestep Consumption Time: 2.44250
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60089

Cumulative Model Updates: 151,580
Cumulative Timesteps: 1,264,246,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,490.12787
Policy Entropy: 3.01937
Value Function Loss: 0.00460

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.58978
Value Function Update Magnitude: 0.51120

Collected Steps per Second: 22,982.92228
Overall Steps per Second: 10,731.14595

Timestep Collection Time: 2.17596
Timestep Consumption Time: 2.48430
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.66027

Cumulative Model Updates: 151,586
Cumulative Timesteps: 1,264,296,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1264296308...
Checkpoint 1264296308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.46099
Policy Entropy: 3.01676
Value Function Loss: 0.00432

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.57766
Value Function Update Magnitude: 0.53406

Collected Steps per Second: 22,987.73442
Overall Steps per Second: 10,836.39065

Timestep Collection Time: 2.17568
Timestep Consumption Time: 2.43969
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.61537

Cumulative Model Updates: 151,592
Cumulative Timesteps: 1,264,346,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.77323
Policy Entropy: 3.02810
Value Function Loss: 0.00437

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.58047
Value Function Update Magnitude: 0.53070

Collected Steps per Second: 23,116.14083
Overall Steps per Second: 10,849.04317

Timestep Collection Time: 2.16342
Timestep Consumption Time: 2.44620
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.60962

Cumulative Model Updates: 151,598
Cumulative Timesteps: 1,264,396,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1264396332...
Checkpoint 1264396332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.49251
Policy Entropy: 3.02122
Value Function Loss: 0.00396

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.57805
Value Function Update Magnitude: 0.52327

Collected Steps per Second: 22,945.96880
Overall Steps per Second: 10,749.68663

Timestep Collection Time: 2.17990
Timestep Consumption Time: 2.47326
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.65316

Cumulative Model Updates: 151,604
Cumulative Timesteps: 1,264,446,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.51811
Policy Entropy: 3.01236
Value Function Loss: 0.00407

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.57859
Value Function Update Magnitude: 0.52483

Collected Steps per Second: 22,882.48301
Overall Steps per Second: 10,850.86718

Timestep Collection Time: 2.18639
Timestep Consumption Time: 2.42430
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.61069

Cumulative Model Updates: 151,610
Cumulative Timesteps: 1,264,496,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1264496382...
Checkpoint 1264496382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.10359
Policy Entropy: 3.00324
Value Function Loss: 0.00420

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.58063
Value Function Update Magnitude: 0.50856

Collected Steps per Second: 22,847.65039
Overall Steps per Second: 10,727.67823

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.47342
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.66271

Cumulative Model Updates: 151,616
Cumulative Timesteps: 1,264,546,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,819.55807
Policy Entropy: 3.00070
Value Function Loss: 0.00464

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.58486
Value Function Update Magnitude: 0.49877

Collected Steps per Second: 22,775.92127
Overall Steps per Second: 10,785.06544

Timestep Collection Time: 2.19618
Timestep Consumption Time: 2.44172
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.63789

Cumulative Model Updates: 151,622
Cumulative Timesteps: 1,264,596,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1264596422...
Checkpoint 1264596422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.64807
Policy Entropy: 3.00655
Value Function Loss: 0.00476

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.59780
Value Function Update Magnitude: 0.53130

Collected Steps per Second: 22,325.32454
Overall Steps per Second: 10,676.28341

Timestep Collection Time: 2.23961
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.68328

Cumulative Model Updates: 151,628
Cumulative Timesteps: 1,264,646,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,551.10947
Policy Entropy: 2.99002
Value Function Loss: 0.00471

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.60003
Value Function Update Magnitude: 0.55318

Collected Steps per Second: 22,921.57316
Overall Steps per Second: 10,883.10629

Timestep Collection Time: 2.18240
Timestep Consumption Time: 2.41408
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.59648

Cumulative Model Updates: 151,634
Cumulative Timesteps: 1,264,696,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1264696446...
Checkpoint 1264696446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.57748
Policy Entropy: 2.97652
Value Function Loss: 0.00457

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.60182
Value Function Update Magnitude: 0.56348

Collected Steps per Second: 22,948.53954
Overall Steps per Second: 10,792.84746

Timestep Collection Time: 2.17949
Timestep Consumption Time: 2.45470
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.63418

Cumulative Model Updates: 151,640
Cumulative Timesteps: 1,264,746,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,240.52345
Policy Entropy: 2.97375
Value Function Loss: 0.00438

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.59758
Value Function Update Magnitude: 0.55095

Collected Steps per Second: 22,937.63046
Overall Steps per Second: 10,812.32418

Timestep Collection Time: 2.18000
Timestep Consumption Time: 2.44472
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62472

Cumulative Model Updates: 151,646
Cumulative Timesteps: 1,264,796,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1264796466...
Checkpoint 1264796466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,202.81406
Policy Entropy: 2.99662
Value Function Loss: 0.00427

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.59063
Value Function Update Magnitude: 0.52162

Collected Steps per Second: 22,859.34101
Overall Steps per Second: 10,715.47753

Timestep Collection Time: 2.18781
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.66727

Cumulative Model Updates: 151,652
Cumulative Timesteps: 1,264,846,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.31119
Policy Entropy: 3.00219
Value Function Loss: 0.00420

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.57766
Value Function Update Magnitude: 0.51060

Collected Steps per Second: 23,091.06530
Overall Steps per Second: 10,860.96152

Timestep Collection Time: 2.16673
Timestep Consumption Time: 2.43986
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.60659

Cumulative Model Updates: 151,658
Cumulative Timesteps: 1,264,896,510

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1264896510...
Checkpoint 1264896510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060.00525
Policy Entropy: 2.99873
Value Function Loss: 0.00412

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.57856
Value Function Update Magnitude: 0.50927

Collected Steps per Second: 23,052.33262
Overall Steps per Second: 10,703.79714

Timestep Collection Time: 2.16898
Timestep Consumption Time: 2.50226
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.67124

Cumulative Model Updates: 151,664
Cumulative Timesteps: 1,264,946,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.49583
Policy Entropy: 2.98658
Value Function Loss: 0.00405

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.57562
Value Function Update Magnitude: 0.49238

Collected Steps per Second: 22,826.40268
Overall Steps per Second: 10,818.17569

Timestep Collection Time: 2.19097
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.62296

Cumulative Model Updates: 151,670
Cumulative Timesteps: 1,264,996,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1264996522...
Checkpoint 1264996522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.79792
Policy Entropy: 2.99535
Value Function Loss: 0.00396

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.57531
Value Function Update Magnitude: 0.49548

Collected Steps per Second: 22,727.36359
Overall Steps per Second: 10,675.06412

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.68625

Cumulative Model Updates: 151,676
Cumulative Timesteps: 1,265,046,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,397.75224
Policy Entropy: 2.99629
Value Function Loss: 0.00406

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.51480

Collected Steps per Second: 22,844.15432
Overall Steps per Second: 10,810.38239

Timestep Collection Time: 2.18883
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62537

Cumulative Model Updates: 151,682
Cumulative Timesteps: 1,265,096,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1265096550...
Checkpoint 1265096550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,534.74347
Policy Entropy: 2.99331
Value Function Loss: 0.00427

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.52799

Collected Steps per Second: 22,702.45149
Overall Steps per Second: 10,721.65838

Timestep Collection Time: 2.20293
Timestep Consumption Time: 2.46164
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.66458

Cumulative Model Updates: 151,688
Cumulative Timesteps: 1,265,146,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.75852
Policy Entropy: 2.98847
Value Function Loss: 0.00459

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.59106
Value Function Update Magnitude: 0.56647

Collected Steps per Second: 22,761.15867
Overall Steps per Second: 10,789.51350

Timestep Collection Time: 2.19708
Timestep Consumption Time: 2.43779
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.63487

Cumulative Model Updates: 151,694
Cumulative Timesteps: 1,265,196,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1265196570...
Checkpoint 1265196570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.67264
Policy Entropy: 2.99850
Value Function Loss: 0.00446

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.59287
Value Function Update Magnitude: 0.55371

Collected Steps per Second: 22,871.45647
Overall Steps per Second: 10,700.54064

Timestep Collection Time: 2.18613
Timestep Consumption Time: 2.48653
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.67266

Cumulative Model Updates: 151,700
Cumulative Timesteps: 1,265,246,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,155.06443
Policy Entropy: 2.98906
Value Function Loss: 0.00451

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.58661
Value Function Update Magnitude: 0.53051

Collected Steps per Second: 23,102.84808
Overall Steps per Second: 10,796.91473

Timestep Collection Time: 2.16545
Timestep Consumption Time: 2.46810
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.63355

Cumulative Model Updates: 151,706
Cumulative Timesteps: 1,265,296,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1265296598...
Checkpoint 1265296598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.27113
Policy Entropy: 3.00753
Value Function Loss: 0.00441

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.58518
Value Function Update Magnitude: 0.53318

Collected Steps per Second: 22,585.44204
Overall Steps per Second: 10,847.17504

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.39654
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.61115

Cumulative Model Updates: 151,712
Cumulative Timesteps: 1,265,346,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.67853
Policy Entropy: 3.00280
Value Function Loss: 0.00469

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.59117
Value Function Update Magnitude: 0.56088

Collected Steps per Second: 23,240.61884
Overall Steps per Second: 10,857.84415

Timestep Collection Time: 2.15201
Timestep Consumption Time: 2.45425
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.60626

Cumulative Model Updates: 151,718
Cumulative Timesteps: 1,265,396,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1265396630...
Checkpoint 1265396630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.64166
Policy Entropy: 3.01262
Value Function Loss: 0.00448

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.58938
Value Function Update Magnitude: 0.54768

Collected Steps per Second: 23,429.42559
Overall Steps per Second: 11,044.76418

Timestep Collection Time: 2.13415
Timestep Consumption Time: 2.39306
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.52721

Cumulative Model Updates: 151,724
Cumulative Timesteps: 1,265,446,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,793.07613
Policy Entropy: 3.01352
Value Function Loss: 0.00405

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.57207
Value Function Update Magnitude: 0.51569

Collected Steps per Second: 23,168.83289
Overall Steps per Second: 10,908.56871

Timestep Collection Time: 2.15963
Timestep Consumption Time: 2.42723
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.58685

Cumulative Model Updates: 151,730
Cumulative Timesteps: 1,265,496,668

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1265496668...
Checkpoint 1265496668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837.97254
Policy Entropy: 3.02288
Value Function Loss: 0.00373

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11165
Policy Update Magnitude: 0.55731
Value Function Update Magnitude: 0.48921

Collected Steps per Second: 22,623.64211
Overall Steps per Second: 10,712.65232

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.45750
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.66775

Cumulative Model Updates: 151,736
Cumulative Timesteps: 1,265,546,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,726.15656
Policy Entropy: 3.02849
Value Function Loss: 0.00382

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.55705
Value Function Update Magnitude: 0.48959

Collected Steps per Second: 22,498.98365
Overall Steps per Second: 10,601.34374

Timestep Collection Time: 2.22241
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.71657

Cumulative Model Updates: 151,742
Cumulative Timesteps: 1,265,596,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1265596674...
Checkpoint 1265596674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.72062
Policy Entropy: 3.01516
Value Function Loss: 0.00393

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.56387
Value Function Update Magnitude: 0.53177

Collected Steps per Second: 22,591.29538
Overall Steps per Second: 10,664.04750

Timestep Collection Time: 2.21404
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.69034

Cumulative Model Updates: 151,748
Cumulative Timesteps: 1,265,646,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.41807
Policy Entropy: 3.00403
Value Function Loss: 0.00419

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.58301
Value Function Update Magnitude: 0.55267

Collected Steps per Second: 22,714.66340
Overall Steps per Second: 10,795.01866

Timestep Collection Time: 2.20201
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.63343

Cumulative Model Updates: 151,754
Cumulative Timesteps: 1,265,696,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1265696710...
Checkpoint 1265696710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.73989
Policy Entropy: 3.00589
Value Function Loss: 0.00422

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.59449
Value Function Update Magnitude: 0.57663

Collected Steps per Second: 22,817.19744
Overall Steps per Second: 10,571.02878

Timestep Collection Time: 2.19150
Timestep Consumption Time: 2.53878
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.73029

Cumulative Model Updates: 151,760
Cumulative Timesteps: 1,265,746,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,399.17983
Policy Entropy: 3.01104
Value Function Loss: 0.00432

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.58825
Value Function Update Magnitude: 0.58676

Collected Steps per Second: 22,935.63255
Overall Steps per Second: 10,832.52445

Timestep Collection Time: 2.18045
Timestep Consumption Time: 2.43620
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61665

Cumulative Model Updates: 151,766
Cumulative Timesteps: 1,265,796,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1265796724...
Checkpoint 1265796724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.33476
Policy Entropy: 3.01497
Value Function Loss: 0.00443

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.57572
Value Function Update Magnitude: 0.54346

Collected Steps per Second: 23,186.76377
Overall Steps per Second: 10,686.84274

Timestep Collection Time: 2.15640
Timestep Consumption Time: 2.52225
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.67865

Cumulative Model Updates: 151,772
Cumulative Timesteps: 1,265,846,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.62894
Policy Entropy: 3.01031
Value Function Loss: 0.00423

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.57395
Value Function Update Magnitude: 0.49724

Collected Steps per Second: 23,290.11094
Overall Steps per Second: 10,902.66293

Timestep Collection Time: 2.14752
Timestep Consumption Time: 2.43998
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.58750

Cumulative Model Updates: 151,778
Cumulative Timesteps: 1,265,896,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1265896740...
Checkpoint 1265896740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.65660
Policy Entropy: 3.00065
Value Function Loss: 0.00409

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.57207
Value Function Update Magnitude: 0.48895

Collected Steps per Second: 22,856.41470
Overall Steps per Second: 10,652.85255

Timestep Collection Time: 2.18792
Timestep Consumption Time: 2.50641
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.69433

Cumulative Model Updates: 151,784
Cumulative Timesteps: 1,265,946,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,604.03284
Policy Entropy: 2.99502
Value Function Loss: 0.00371

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.56933
Value Function Update Magnitude: 0.51515

Collected Steps per Second: 23,043.78199
Overall Steps per Second: 10,847.08473

Timestep Collection Time: 2.17100
Timestep Consumption Time: 2.44112
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61211

Cumulative Model Updates: 151,790
Cumulative Timesteps: 1,265,996,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1265996776...
Checkpoint 1265996776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.56682
Policy Entropy: 2.99312
Value Function Loss: 0.00384

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11165
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.50377

Collected Steps per Second: 22,727.22935
Overall Steps per Second: 10,723.89002

Timestep Collection Time: 2.20044
Timestep Consumption Time: 2.46298
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.66342

Cumulative Model Updates: 151,796
Cumulative Timesteps: 1,266,046,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.23468
Policy Entropy: 2.99414
Value Function Loss: 0.00408

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.57041
Value Function Update Magnitude: 0.50201

Collected Steps per Second: 23,018.25288
Overall Steps per Second: 10,939.72917

Timestep Collection Time: 2.17280
Timestep Consumption Time: 2.39898
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.57178

Cumulative Model Updates: 151,802
Cumulative Timesteps: 1,266,096,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1266096800...
Checkpoint 1266096800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.56374
Policy Entropy: 3.00755
Value Function Loss: 0.00433

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11507
Policy Update Magnitude: 0.57071
Value Function Update Magnitude: 0.52533

Collected Steps per Second: 22,759.57323
Overall Steps per Second: 10,622.09955

Timestep Collection Time: 2.19776
Timestep Consumption Time: 2.51129
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.70905

Cumulative Model Updates: 151,808
Cumulative Timesteps: 1,266,146,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.00716
Policy Entropy: 2.98864
Value Function Loss: 0.00405

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.56210
Value Function Update Magnitude: 0.54452

Collected Steps per Second: 23,124.02904
Overall Steps per Second: 10,879.26569

Timestep Collection Time: 2.16269
Timestep Consumption Time: 2.43413
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.59682

Cumulative Model Updates: 151,814
Cumulative Timesteps: 1,266,196,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1266196830...
Checkpoint 1266196830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078.19184
Policy Entropy: 2.99451
Value Function Loss: 0.00411

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.55823
Value Function Update Magnitude: 0.52067

Collected Steps per Second: 23,151.43410
Overall Steps per Second: 10,826.00626

Timestep Collection Time: 2.15987
Timestep Consumption Time: 2.45901
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.61888

Cumulative Model Updates: 151,820
Cumulative Timesteps: 1,266,246,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.99037
Policy Entropy: 2.98747
Value Function Loss: 0.00394

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.56362
Value Function Update Magnitude: 0.51287

Collected Steps per Second: 23,215.89876
Overall Steps per Second: 10,810.31229

Timestep Collection Time: 2.15387
Timestep Consumption Time: 2.47171
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.62558

Cumulative Model Updates: 151,826
Cumulative Timesteps: 1,266,296,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1266296838...
Checkpoint 1266296838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.84354
Policy Entropy: 3.00281
Value Function Loss: 0.00408

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.57293
Value Function Update Magnitude: 0.53448

Collected Steps per Second: 23,383.81593
Overall Steps per Second: 10,929.20845

Timestep Collection Time: 2.13883
Timestep Consumption Time: 2.43735
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.57618

Cumulative Model Updates: 151,832
Cumulative Timesteps: 1,266,346,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.93088
Policy Entropy: 2.99448
Value Function Loss: 0.00449

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.58110
Value Function Update Magnitude: 0.56573

Collected Steps per Second: 22,938.29205
Overall Steps per Second: 10,905.26138

Timestep Collection Time: 2.18107
Timestep Consumption Time: 2.40662
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.58769

Cumulative Model Updates: 151,838
Cumulative Timesteps: 1,266,396,882

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1266396882...
Checkpoint 1266396882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.74441
Policy Entropy: 2.99877
Value Function Loss: 0.00442

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.58980
Value Function Update Magnitude: 0.57786

Collected Steps per Second: 23,064.27685
Overall Steps per Second: 10,766.87393

Timestep Collection Time: 2.16872
Timestep Consumption Time: 2.47701
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.64573

Cumulative Model Updates: 151,844
Cumulative Timesteps: 1,266,446,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.77956
Policy Entropy: 2.98559
Value Function Loss: 0.00474

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.60151
Value Function Update Magnitude: 0.60143

Collected Steps per Second: 22,647.22256
Overall Steps per Second: 10,813.80076

Timestep Collection Time: 2.20901
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.62631

Cumulative Model Updates: 151,850
Cumulative Timesteps: 1,266,496,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1266496930...
Checkpoint 1266496930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,767.09057
Policy Entropy: 2.97962
Value Function Loss: 0.00497

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.60773
Value Function Update Magnitude: 0.62579

Collected Steps per Second: 22,442.11194
Overall Steps per Second: 10,742.92331

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.42676
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.65516

Cumulative Model Updates: 151,856
Cumulative Timesteps: 1,266,546,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.06394
Policy Entropy: 2.97734
Value Function Loss: 0.00501

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.60959
Value Function Update Magnitude: 0.61460

Collected Steps per Second: 22,764.86337
Overall Steps per Second: 10,773.05266

Timestep Collection Time: 2.19760
Timestep Consumption Time: 2.44621
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.64381

Cumulative Model Updates: 151,862
Cumulative Timesteps: 1,266,596,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1266596968...
Checkpoint 1266596968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.50485
Policy Entropy: 2.98802
Value Function Loss: 0.00460

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.60166
Value Function Update Magnitude: 0.59824

Collected Steps per Second: 23,073.91013
Overall Steps per Second: 10,708.65405

Timestep Collection Time: 2.16808
Timestep Consumption Time: 2.50347
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.67155

Cumulative Model Updates: 151,868
Cumulative Timesteps: 1,266,646,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.37095
Policy Entropy: 3.00142
Value Function Loss: 0.00436

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.59910
Value Function Update Magnitude: 0.59311

Collected Steps per Second: 23,191.13374
Overall Steps per Second: 10,858.89729

Timestep Collection Time: 2.15781
Timestep Consumption Time: 2.45058
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.60839

Cumulative Model Updates: 151,874
Cumulative Timesteps: 1,266,697,036

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1266697036...
Checkpoint 1266697036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,434.14235
Policy Entropy: 3.00443
Value Function Loss: 0.00413

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.59835
Value Function Update Magnitude: 0.59086

Collected Steps per Second: 23,082.79572
Overall Steps per Second: 10,715.63500

Timestep Collection Time: 2.16742
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.66888

Cumulative Model Updates: 151,880
Cumulative Timesteps: 1,266,747,066

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.95318
Policy Entropy: 3.02053
Value Function Loss: 0.00417

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.59635
Value Function Update Magnitude: 0.57267

Collected Steps per Second: 23,107.15192
Overall Steps per Second: 10,954.48178

Timestep Collection Time: 2.16444
Timestep Consumption Time: 2.40118
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.56562

Cumulative Model Updates: 151,886
Cumulative Timesteps: 1,266,797,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1266797080...
Checkpoint 1266797080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.90444
Policy Entropy: 3.01450
Value Function Loss: 0.00417

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.58494
Value Function Update Magnitude: 0.55109

Collected Steps per Second: 23,116.99283
Overall Steps per Second: 10,772.69632

Timestep Collection Time: 2.16300
Timestep Consumption Time: 2.47855
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.64155

Cumulative Model Updates: 151,892
Cumulative Timesteps: 1,266,847,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.17177
Policy Entropy: 2.98438
Value Function Loss: 0.00465

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.59601
Value Function Update Magnitude: 0.54242

Collected Steps per Second: 23,316.02016
Overall Steps per Second: 10,863.87125

Timestep Collection Time: 2.14565
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.60499

Cumulative Model Updates: 151,898
Cumulative Timesteps: 1,266,897,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1266897110...
Checkpoint 1266897110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885.11393
Policy Entropy: 2.97995
Value Function Loss: 0.00469

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.60414
Value Function Update Magnitude: 0.55337

Collected Steps per Second: 22,709.90481
Overall Steps per Second: 10,740.68217

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.45352
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.65520

Cumulative Model Updates: 151,904
Cumulative Timesteps: 1,266,947,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.52558
Policy Entropy: 2.97793
Value Function Loss: 0.00447

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.59541
Value Function Update Magnitude: 0.55135

Collected Steps per Second: 22,725.86733
Overall Steps per Second: 10,683.09574

Timestep Collection Time: 2.20093
Timestep Consumption Time: 2.48105
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.68198

Cumulative Model Updates: 151,910
Cumulative Timesteps: 1,266,997,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1266997128...
Checkpoint 1266997128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.86967
Policy Entropy: 2.99560
Value Function Loss: 0.00430

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.58594
Value Function Update Magnitude: 0.52813

Collected Steps per Second: 22,569.09246
Overall Steps per Second: 10,626.85954

Timestep Collection Time: 2.21560
Timestep Consumption Time: 2.48984
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.70544

Cumulative Model Updates: 151,916
Cumulative Timesteps: 1,267,047,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.19475
Policy Entropy: 2.99454
Value Function Loss: 0.00416

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.57960
Value Function Update Magnitude: 0.53007

Collected Steps per Second: 22,782.20492
Overall Steps per Second: 10,823.72569

Timestep Collection Time: 2.19531
Timestep Consumption Time: 2.42547
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.62077

Cumulative Model Updates: 151,922
Cumulative Timesteps: 1,267,097,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1267097146...
Checkpoint 1267097146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.40347
Policy Entropy: 2.99905
Value Function Loss: 0.00428

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.57704
Value Function Update Magnitude: 0.53457

Collected Steps per Second: 23,170.71087
Overall Steps per Second: 10,759.38185

Timestep Collection Time: 2.15911
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.64971

Cumulative Model Updates: 151,928
Cumulative Timesteps: 1,267,147,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,253.16103
Policy Entropy: 2.99601
Value Function Loss: 0.00418

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.52503

Collected Steps per Second: 23,242.57541
Overall Steps per Second: 10,928.08583

Timestep Collection Time: 2.15122
Timestep Consumption Time: 2.42414
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.57537

Cumulative Model Updates: 151,934
Cumulative Timesteps: 1,267,197,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1267197174...
Checkpoint 1267197174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,471.28853
Policy Entropy: 2.98673
Value Function Loss: 0.00415

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.57222
Value Function Update Magnitude: 0.50710

Collected Steps per Second: 23,117.86878
Overall Steps per Second: 10,625.56173

Timestep Collection Time: 2.16395
Timestep Consumption Time: 2.54413
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.70808

Cumulative Model Updates: 151,940
Cumulative Timesteps: 1,267,247,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.29793
Policy Entropy: 2.97069
Value Function Loss: 0.00412

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.57514
Value Function Update Magnitude: 0.51623

Collected Steps per Second: 23,205.54740
Overall Steps per Second: 10,912.45761

Timestep Collection Time: 2.15535
Timestep Consumption Time: 2.42804
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.58339

Cumulative Model Updates: 151,946
Cumulative Timesteps: 1,267,297,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1267297216...
Checkpoint 1267297216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.81354
Policy Entropy: 2.97136
Value Function Loss: 0.00428

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.58768
Value Function Update Magnitude: 0.54012

Collected Steps per Second: 23,299.88919
Overall Steps per Second: 10,787.58329

Timestep Collection Time: 2.14696
Timestep Consumption Time: 2.49022
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.63718

Cumulative Model Updates: 151,952
Cumulative Timesteps: 1,267,347,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.40874
Policy Entropy: 2.96607
Value Function Loss: 0.00469

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.60388
Value Function Update Magnitude: 0.55249

Collected Steps per Second: 22,872.01159
Overall Steps per Second: 10,717.41376

Timestep Collection Time: 2.18660
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.66642

Cumulative Model Updates: 151,958
Cumulative Timesteps: 1,267,397,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1267397252...
Checkpoint 1267397252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.03047
Policy Entropy: 2.96198
Value Function Loss: 0.00460

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.60297
Value Function Update Magnitude: 0.55009

Collected Steps per Second: 22,592.48315
Overall Steps per Second: 10,629.39606

Timestep Collection Time: 2.21357
Timestep Consumption Time: 2.49131
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.70488

Cumulative Model Updates: 151,964
Cumulative Timesteps: 1,267,447,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.81690
Policy Entropy: 2.95918
Value Function Loss: 0.00462

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.59598
Value Function Update Magnitude: 0.55350

Collected Steps per Second: 22,599.05891
Overall Steps per Second: 10,638.55124

Timestep Collection Time: 2.21372
Timestep Consumption Time: 2.48880
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.70252

Cumulative Model Updates: 151,970
Cumulative Timesteps: 1,267,497,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1267497290...
Checkpoint 1267497290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.27114
Policy Entropy: 2.96746
Value Function Loss: 0.00448

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.59463
Value Function Update Magnitude: 0.53669

Collected Steps per Second: 22,822.52217
Overall Steps per Second: 10,880.30251

Timestep Collection Time: 2.19099
Timestep Consumption Time: 2.40483
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.59583

Cumulative Model Updates: 151,976
Cumulative Timesteps: 1,267,547,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.86381
Policy Entropy: 2.96007
Value Function Loss: 0.00503

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.61063
Value Function Update Magnitude: 0.54448

Collected Steps per Second: 22,366.93596
Overall Steps per Second: 10,630.17654

Timestep Collection Time: 2.23678
Timestep Consumption Time: 2.46963
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.70641

Cumulative Model Updates: 151,982
Cumulative Timesteps: 1,267,597,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1267597324...
Checkpoint 1267597324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.49273
Policy Entropy: 2.96202
Value Function Loss: 0.00504

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.61257
Value Function Update Magnitude: 0.57864

Collected Steps per Second: 23,243.12969
Overall Steps per Second: 10,885.27764

Timestep Collection Time: 2.15117
Timestep Consumption Time: 2.44219
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.59336

Cumulative Model Updates: 151,988
Cumulative Timesteps: 1,267,647,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.06177
Policy Entropy: 2.95398
Value Function Loss: 0.00507

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.60676
Value Function Update Magnitude: 0.58121

Collected Steps per Second: 23,041.36321
Overall Steps per Second: 10,905.66584

Timestep Collection Time: 2.17088
Timestep Consumption Time: 2.41573
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.58661

Cumulative Model Updates: 151,994
Cumulative Timesteps: 1,267,697,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1267697344...
Checkpoint 1267697344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.76053
Policy Entropy: 2.97326
Value Function Loss: 0.00499

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.60852
Value Function Update Magnitude: 0.56747

Collected Steps per Second: 23,051.25425
Overall Steps per Second: 10,698.54505

Timestep Collection Time: 2.16995
Timestep Consumption Time: 2.50546
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.67540

Cumulative Model Updates: 152,000
Cumulative Timesteps: 1,267,747,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.33851
Policy Entropy: 2.97186
Value Function Loss: 0.00503

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.60349
Value Function Update Magnitude: 0.54411

Collected Steps per Second: 22,979.43811
Overall Steps per Second: 10,883.72345

Timestep Collection Time: 2.17725
Timestep Consumption Time: 2.41971
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.59696

Cumulative Model Updates: 152,006
Cumulative Timesteps: 1,267,797,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1267797396...
Checkpoint 1267797396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.40883
Policy Entropy: 2.98611
Value Function Loss: 0.00484

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11592
Policy Update Magnitude: 0.59549
Value Function Update Magnitude: 0.52946

Collected Steps per Second: 22,913.36855
Overall Steps per Second: 10,645.17796

Timestep Collection Time: 2.18231
Timestep Consumption Time: 2.51503
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.69734

Cumulative Model Updates: 152,012
Cumulative Timesteps: 1,267,847,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.13076
Policy Entropy: 2.99306
Value Function Loss: 0.00451

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.58781
Value Function Update Magnitude: 0.51025

Collected Steps per Second: 23,115.28582
Overall Steps per Second: 10,899.92637

Timestep Collection Time: 2.16342
Timestep Consumption Time: 2.42450
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.58792

Cumulative Model Updates: 152,018
Cumulative Timesteps: 1,267,897,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1267897408...
Checkpoint 1267897408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.56356
Policy Entropy: 3.01274
Value Function Loss: 0.00409

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.57303
Value Function Update Magnitude: 0.51045

Collected Steps per Second: 22,682.05688
Overall Steps per Second: 10,674.38966

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.48101
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.68654

Cumulative Model Updates: 152,024
Cumulative Timesteps: 1,267,947,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.12281
Policy Entropy: 3.01597
Value Function Loss: 0.00439

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.57051
Value Function Update Magnitude: 0.52061

Collected Steps per Second: 22,537.53199
Overall Steps per Second: 10,586.71656

Timestep Collection Time: 2.21932
Timestep Consumption Time: 2.50528
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.72460

Cumulative Model Updates: 152,030
Cumulative Timesteps: 1,267,997,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1267997452...
Checkpoint 1267997452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.57183
Policy Entropy: 2.99346
Value Function Loss: 0.00487

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.58951
Value Function Update Magnitude: 0.54240

Collected Steps per Second: 22,705.85336
Overall Steps per Second: 10,682.78931

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.47865
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.68099

Cumulative Model Updates: 152,036
Cumulative Timesteps: 1,268,047,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.85961
Policy Entropy: 2.98480
Value Function Loss: 0.00539

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.60195
Value Function Update Magnitude: 0.55385

Collected Steps per Second: 22,911.62583
Overall Steps per Second: 10,704.46659

Timestep Collection Time: 2.18239
Timestep Consumption Time: 2.48875
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.67113

Cumulative Model Updates: 152,042
Cumulative Timesteps: 1,268,097,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1268097460...
Checkpoint 1268097460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.62388
Policy Entropy: 3.00119
Value Function Loss: 0.00469

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.58226
Value Function Update Magnitude: 0.55300

Collected Steps per Second: 22,682.60627
Overall Steps per Second: 10,673.81668

Timestep Collection Time: 2.20574
Timestep Consumption Time: 2.48161
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.68736

Cumulative Model Updates: 152,048
Cumulative Timesteps: 1,268,147,492

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.52880
Policy Entropy: 3.00257
Value Function Loss: 0.00466

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.58973
Value Function Update Magnitude: 0.55610

Collected Steps per Second: 23,059.82280
Overall Steps per Second: 10,788.58276

Timestep Collection Time: 2.16888
Timestep Consumption Time: 2.46695
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.63583

Cumulative Model Updates: 152,054
Cumulative Timesteps: 1,268,197,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1268197506...
Checkpoint 1268197506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.17100
Policy Entropy: 3.00083
Value Function Loss: 0.00468

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.59130
Value Function Update Magnitude: 0.57394

Collected Steps per Second: 23,164.96527
Overall Steps per Second: 10,795.67166

Timestep Collection Time: 2.15843
Timestep Consumption Time: 2.47305
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.63149

Cumulative Model Updates: 152,060
Cumulative Timesteps: 1,268,247,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298.64056
Policy Entropy: 2.99545
Value Function Loss: 0.00466

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.58111

Collected Steps per Second: 23,205.06355
Overall Steps per Second: 10,905.20650

Timestep Collection Time: 2.15496
Timestep Consumption Time: 2.43056
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.58552

Cumulative Model Updates: 152,066
Cumulative Timesteps: 1,268,297,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1268297512...
Checkpoint 1268297512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,665.14031
Policy Entropy: 2.99245
Value Function Loss: 0.00474

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.58397
Value Function Update Magnitude: 0.57559

Collected Steps per Second: 23,053.09243
Overall Steps per Second: 10,718.29387

Timestep Collection Time: 2.17012
Timestep Consumption Time: 2.49741
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.66753

Cumulative Model Updates: 152,072
Cumulative Timesteps: 1,268,347,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,865.27788
Policy Entropy: 3.00267
Value Function Loss: 0.00471

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.59816
Value Function Update Magnitude: 0.56909

Collected Steps per Second: 23,092.78998
Overall Steps per Second: 10,771.55941

Timestep Collection Time: 2.16561
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.64278

Cumulative Model Updates: 152,078
Cumulative Timesteps: 1,268,397,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1268397550...
Checkpoint 1268397550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.51340
Policy Entropy: 2.99106
Value Function Loss: 0.00466

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.60438
Value Function Update Magnitude: 0.56704

Collected Steps per Second: 22,959.64889
Overall Steps per Second: 10,655.12129

Timestep Collection Time: 2.17913
Timestep Consumption Time: 2.51645
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.69558

Cumulative Model Updates: 152,084
Cumulative Timesteps: 1,268,447,582

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.60262
Policy Entropy: 2.99798
Value Function Loss: 0.00453

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.60103
Value Function Update Magnitude: 0.58197

Collected Steps per Second: 22,680.74650
Overall Steps per Second: 10,853.06860

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.40286
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60773

Cumulative Model Updates: 152,090
Cumulative Timesteps: 1,268,497,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1268497590...
Checkpoint 1268497590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,825.77547
Policy Entropy: 3.00702
Value Function Loss: 0.00431

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.59700
Value Function Update Magnitude: 0.55445

Collected Steps per Second: 22,625.75594
Overall Steps per Second: 10,677.89083

Timestep Collection Time: 2.21014
Timestep Consumption Time: 2.47300
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68313

Cumulative Model Updates: 152,096
Cumulative Timesteps: 1,268,547,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.09730
Policy Entropy: 3.01225
Value Function Loss: 0.00463

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.58841
Value Function Update Magnitude: 0.53674

Collected Steps per Second: 22,728.56299
Overall Steps per Second: 10,801.43101

Timestep Collection Time: 2.20005
Timestep Consumption Time: 2.42934
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.62939

Cumulative Model Updates: 152,102
Cumulative Timesteps: 1,268,597,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1268597600...
Checkpoint 1268597600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.12070
Policy Entropy: 3.00885
Value Function Loss: 0.00505

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.59821
Value Function Update Magnitude: 0.55571

Collected Steps per Second: 22,484.22750
Overall Steps per Second: 10,743.95947

Timestep Collection Time: 2.22431
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.65489

Cumulative Model Updates: 152,108
Cumulative Timesteps: 1,268,647,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,166.37589
Policy Entropy: 3.00383
Value Function Loss: 0.00517

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.61074
Value Function Update Magnitude: 0.57984

Collected Steps per Second: 23,366.17854
Overall Steps per Second: 10,956.70967

Timestep Collection Time: 2.14104
Timestep Consumption Time: 2.42493
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.56597

Cumulative Model Updates: 152,114
Cumulative Timesteps: 1,268,697,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1268697640...
Checkpoint 1268697640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898.09721
Policy Entropy: 3.01348
Value Function Loss: 0.00506

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.60055
Value Function Update Magnitude: 0.58463

Collected Steps per Second: 23,234.58850
Overall Steps per Second: 10,969.65349

Timestep Collection Time: 2.15231
Timestep Consumption Time: 2.40645
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.55876

Cumulative Model Updates: 152,120
Cumulative Timesteps: 1,268,747,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.24362
Policy Entropy: 3.00049
Value Function Loss: 0.00475

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.58991
Value Function Update Magnitude: 0.55756

Collected Steps per Second: 22,403.21148
Overall Steps per Second: 10,616.76379

Timestep Collection Time: 2.23209
Timestep Consumption Time: 2.47801
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.71010

Cumulative Model Updates: 152,126
Cumulative Timesteps: 1,268,797,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1268797654...
Checkpoint 1268797654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.61090
Policy Entropy: 2.99143
Value Function Loss: 0.00466

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.59061
Value Function Update Magnitude: 0.53443

Collected Steps per Second: 23,167.40385
Overall Steps per Second: 10,955.46320

Timestep Collection Time: 2.15941
Timestep Consumption Time: 2.40708
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.56649

Cumulative Model Updates: 152,132
Cumulative Timesteps: 1,268,847,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.22578
Policy Entropy: 2.97252
Value Function Loss: 0.00448

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.58990
Value Function Update Magnitude: 0.53401

Collected Steps per Second: 23,320.59259
Overall Steps per Second: 11,015.68331

Timestep Collection Time: 2.14480
Timestep Consumption Time: 2.39582
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.54062

Cumulative Model Updates: 152,138
Cumulative Timesteps: 1,268,897,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1268897700...
Checkpoint 1268897700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.73436
Policy Entropy: 2.98407
Value Function Loss: 0.00434

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10590
Policy Update Magnitude: 0.58383
Value Function Update Magnitude: 0.51332

Collected Steps per Second: 23,027.83417
Overall Steps per Second: 10,676.19981

Timestep Collection Time: 2.17163
Timestep Consumption Time: 2.51243
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.68406

Cumulative Model Updates: 152,144
Cumulative Timesteps: 1,268,947,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.22214
Policy Entropy: 2.98284
Value Function Loss: 0.00463

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.59213
Value Function Update Magnitude: 0.51598

Collected Steps per Second: 22,649.82282
Overall Steps per Second: 10,781.60285

Timestep Collection Time: 2.20876
Timestep Consumption Time: 2.43137
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.64013

Cumulative Model Updates: 152,150
Cumulative Timesteps: 1,268,997,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1268997736...
Checkpoint 1268997736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.12812
Policy Entropy: 2.97692
Value Function Loss: 0.00530

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.61449
Value Function Update Magnitude: 0.52881

Collected Steps per Second: 22,846.51848
Overall Steps per Second: 10,733.11591

Timestep Collection Time: 2.18860
Timestep Consumption Time: 2.47006
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.65867

Cumulative Model Updates: 152,156
Cumulative Timesteps: 1,269,047,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.83953
Policy Entropy: 2.98467
Value Function Loss: 0.00531

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.61803
Value Function Update Magnitude: 0.53509

Collected Steps per Second: 22,872.65098
Overall Steps per Second: 10,928.58000

Timestep Collection Time: 2.18724
Timestep Consumption Time: 2.39048
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.57772

Cumulative Model Updates: 152,162
Cumulative Timesteps: 1,269,097,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1269097766...
Checkpoint 1269097766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.64697
Policy Entropy: 3.01378
Value Function Loss: 0.00516

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.60819
Value Function Update Magnitude: 0.53791

Collected Steps per Second: 22,750.37934
Overall Steps per Second: 10,595.07501

Timestep Collection Time: 2.19900
Timestep Consumption Time: 2.52282
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.72182

Cumulative Model Updates: 152,168
Cumulative Timesteps: 1,269,147,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.45129
Policy Entropy: 3.03032
Value Function Loss: 0.00490

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.59637
Value Function Update Magnitude: 0.54392

Collected Steps per Second: 21,690.06168
Overall Steps per Second: 10,475.38368

Timestep Collection Time: 2.30613
Timestep Consumption Time: 2.46888
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.77500

Cumulative Model Updates: 152,174
Cumulative Timesteps: 1,269,197,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1269197814...
Checkpoint 1269197814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.69018
Policy Entropy: 3.03277
Value Function Loss: 0.00471

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.58973
Value Function Update Magnitude: 0.56324

Collected Steps per Second: 22,625.65240
Overall Steps per Second: 10,641.48910

Timestep Collection Time: 2.21041
Timestep Consumption Time: 2.48931
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.69972

Cumulative Model Updates: 152,180
Cumulative Timesteps: 1,269,247,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.21172
Policy Entropy: 3.03462
Value Function Loss: 0.00434

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.58367
Value Function Update Magnitude: 0.54846

Collected Steps per Second: 22,926.42504
Overall Steps per Second: 10,813.62262

Timestep Collection Time: 2.18159
Timestep Consumption Time: 2.44369
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.62528

Cumulative Model Updates: 152,186
Cumulative Timesteps: 1,269,297,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1269297842...
Checkpoint 1269297842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.72069
Policy Entropy: 3.05159
Value Function Loss: 0.00386

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.51351

Collected Steps per Second: 22,877.44852
Overall Steps per Second: 10,672.25158

Timestep Collection Time: 2.18669
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.68748

Cumulative Model Updates: 152,192
Cumulative Timesteps: 1,269,347,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,766.73143
Policy Entropy: 3.03337
Value Function Loss: 0.00409

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.55752
Value Function Update Magnitude: 0.50029

Collected Steps per Second: 23,269.58947
Overall Steps per Second: 10,992.33034

Timestep Collection Time: 2.14941
Timestep Consumption Time: 2.40067
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.55008

Cumulative Model Updates: 152,198
Cumulative Timesteps: 1,269,397,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1269397884...
Checkpoint 1269397884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.42783
Policy Entropy: 3.02363
Value Function Loss: 0.00416

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.57075
Value Function Update Magnitude: 0.50600

Collected Steps per Second: 23,193.41599
Overall Steps per Second: 10,970.63849

Timestep Collection Time: 2.15630
Timestep Consumption Time: 2.40241
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.55871

Cumulative Model Updates: 152,204
Cumulative Timesteps: 1,269,447,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770.70516
Policy Entropy: 3.02493
Value Function Loss: 0.00449

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.58635
Value Function Update Magnitude: 0.53779

Collected Steps per Second: 23,283.33139
Overall Steps per Second: 10,975.76610

Timestep Collection Time: 2.14849
Timestep Consumption Time: 2.40919
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.55768

Cumulative Model Updates: 152,210
Cumulative Timesteps: 1,269,497,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1269497920...
Checkpoint 1269497920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.00526
Policy Entropy: 3.02306
Value Function Loss: 0.00441

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.58368
Value Function Update Magnitude: 0.54623

Collected Steps per Second: 23,168.23803
Overall Steps per Second: 10,732.42563

Timestep Collection Time: 2.15951
Timestep Consumption Time: 2.50225
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.66176

Cumulative Model Updates: 152,216
Cumulative Timesteps: 1,269,547,952

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.49021
Policy Entropy: 3.02624
Value Function Loss: 0.00444

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.58370
Value Function Update Magnitude: 0.53673

Collected Steps per Second: 23,312.71434
Overall Steps per Second: 10,845.25916

Timestep Collection Time: 2.14561
Timestep Consumption Time: 2.46654
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.61215

Cumulative Model Updates: 152,222
Cumulative Timesteps: 1,269,597,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1269597972...
Checkpoint 1269597972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.39489
Policy Entropy: 3.00073
Value Function Loss: 0.00446

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.59033
Value Function Update Magnitude: 0.56279

Collected Steps per Second: 22,713.87553
Overall Steps per Second: 10,618.85957

Timestep Collection Time: 2.20297
Timestep Consumption Time: 2.50921
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.71218

Cumulative Model Updates: 152,228
Cumulative Timesteps: 1,269,648,010

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.71205
Policy Entropy: 3.01037
Value Function Loss: 0.00444

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.59485
Value Function Update Magnitude: 0.57682

Collected Steps per Second: 22,927.89924
Overall Steps per Second: 10,830.22977

Timestep Collection Time: 2.18136
Timestep Consumption Time: 2.43664
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61800

Cumulative Model Updates: 152,234
Cumulative Timesteps: 1,269,698,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1269698024...
Checkpoint 1269698024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.11138
Policy Entropy: 2.99907
Value Function Loss: 0.00427

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.57998
Value Function Update Magnitude: 0.55351

Collected Steps per Second: 22,562.81442
Overall Steps per Second: 10,684.50677

Timestep Collection Time: 2.21604
Timestep Consumption Time: 2.46364
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.67967

Cumulative Model Updates: 152,240
Cumulative Timesteps: 1,269,748,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.67013
Policy Entropy: 3.00770
Value Function Loss: 0.00438

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.50858

Collected Steps per Second: 23,005.70369
Overall Steps per Second: 10,732.46603

Timestep Collection Time: 2.17468
Timestep Consumption Time: 2.48688
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.66156

Cumulative Model Updates: 152,246
Cumulative Timesteps: 1,269,798,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1269798054...
Checkpoint 1269798054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,191.74726
Policy Entropy: 3.00891
Value Function Loss: 0.00421

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.57816
Value Function Update Magnitude: 0.50552

Collected Steps per Second: 23,067.29417
Overall Steps per Second: 10,815.93964

Timestep Collection Time: 2.16783
Timestep Consumption Time: 2.45553
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.62336

Cumulative Model Updates: 152,252
Cumulative Timesteps: 1,269,848,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,921.54372
Policy Entropy: 3.00918
Value Function Loss: 0.00443

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.58328
Value Function Update Magnitude: 0.53506

Collected Steps per Second: 23,306.36914
Overall Steps per Second: 10,932.08741

Timestep Collection Time: 2.14654
Timestep Consumption Time: 2.42972
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.57625

Cumulative Model Updates: 152,258
Cumulative Timesteps: 1,269,898,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1269898088...
Checkpoint 1269898088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.23129
Policy Entropy: 3.01481
Value Function Loss: 0.00451

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.59761
Value Function Update Magnitude: 0.54829

Collected Steps per Second: 22,949.46465
Overall Steps per Second: 10,646.50265

Timestep Collection Time: 2.17914
Timestep Consumption Time: 2.51818
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.69732

Cumulative Model Updates: 152,264
Cumulative Timesteps: 1,269,948,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.11855
Policy Entropy: 2.99970
Value Function Loss: 0.00494

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.61219
Value Function Update Magnitude: 0.56598

Collected Steps per Second: 23,343.85676
Overall Steps per Second: 10,938.19176

Timestep Collection Time: 2.14309
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.57370

Cumulative Model Updates: 152,270
Cumulative Timesteps: 1,269,998,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1269998126...
Checkpoint 1269998126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.87693
Policy Entropy: 2.99626
Value Function Loss: 0.00459

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.61150
Value Function Update Magnitude: 0.57458

Collected Steps per Second: 23,255.19010
Overall Steps per Second: 10,892.93424

Timestep Collection Time: 2.15092
Timestep Consumption Time: 2.44105
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.59197

Cumulative Model Updates: 152,276
Cumulative Timesteps: 1,270,048,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,868.45163
Policy Entropy: 2.99586
Value Function Loss: 0.00465

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.60074
Value Function Update Magnitude: 0.57415

Collected Steps per Second: 23,158.09100
Overall Steps per Second: 10,752.03897

Timestep Collection Time: 2.15933
Timestep Consumption Time: 2.49151
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.65084

Cumulative Model Updates: 152,282
Cumulative Timesteps: 1,270,098,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1270098152...
Checkpoint 1270098152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,331.95796
Policy Entropy: 3.01093
Value Function Loss: 0.00460

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10580
Policy Update Magnitude: 0.59839
Value Function Update Magnitude: 0.57664

Collected Steps per Second: 22,714.88927
Overall Steps per Second: 10,643.71993

Timestep Collection Time: 2.20217
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.69967

Cumulative Model Updates: 152,288
Cumulative Timesteps: 1,270,148,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.78610
Policy Entropy: 3.00073
Value Function Loss: 0.00436

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.59171
Value Function Update Magnitude: 0.56995

Collected Steps per Second: 22,769.93133
Overall Steps per Second: 10,773.70717

Timestep Collection Time: 2.19667
Timestep Consumption Time: 2.44593
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.64260

Cumulative Model Updates: 152,294
Cumulative Timesteps: 1,270,198,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1270198192...
Checkpoint 1270198192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,919.61605
Policy Entropy: 2.99910
Value Function Loss: 0.00420

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.57894
Value Function Update Magnitude: 0.56320

Collected Steps per Second: 22,819.02435
Overall Steps per Second: 10,702.02337

Timestep Collection Time: 2.19124
Timestep Consumption Time: 2.48096
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.67220

Cumulative Model Updates: 152,300
Cumulative Timesteps: 1,270,248,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.48596
Policy Entropy: 2.99783
Value Function Loss: 0.00428

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.58223
Value Function Update Magnitude: 0.54542

Collected Steps per Second: 23,076.73677
Overall Steps per Second: 10,850.00113

Timestep Collection Time: 2.16764
Timestep Consumption Time: 2.44268
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.61032

Cumulative Model Updates: 152,306
Cumulative Timesteps: 1,270,298,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1270298216...
Checkpoint 1270298216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.07407
Policy Entropy: 2.99551
Value Function Loss: 0.00457

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.58735
Value Function Update Magnitude: 0.54927

Collected Steps per Second: 23,090.30991
Overall Steps per Second: 10,774.89995

Timestep Collection Time: 2.16688
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.64357

Cumulative Model Updates: 152,312
Cumulative Timesteps: 1,270,348,250

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.73069
Policy Entropy: 2.99129
Value Function Loss: 0.00461

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.58816
Value Function Update Magnitude: 0.56461

Collected Steps per Second: 23,298.31986
Overall Steps per Second: 10,829.87847

Timestep Collection Time: 2.14668
Timestep Consumption Time: 2.47147
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.61815

Cumulative Model Updates: 152,318
Cumulative Timesteps: 1,270,398,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1270398264...
Checkpoint 1270398264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,965.68537
Policy Entropy: 2.99892
Value Function Loss: 0.00450

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.58623
Value Function Update Magnitude: 0.55189

Collected Steps per Second: 23,389.71543
Overall Steps per Second: 11,050.32516

Timestep Collection Time: 2.13795
Timestep Consumption Time: 2.38735
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.52530

Cumulative Model Updates: 152,324
Cumulative Timesteps: 1,270,448,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,256.96974
Policy Entropy: 3.01593
Value Function Loss: 0.00451

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.58678
Value Function Update Magnitude: 0.54058

Collected Steps per Second: 23,410.01814
Overall Steps per Second: 10,916.75953

Timestep Collection Time: 2.13755
Timestep Consumption Time: 2.44623
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.58378

Cumulative Model Updates: 152,330
Cumulative Timesteps: 1,270,498,310

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1270498310...
Checkpoint 1270498310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.03663
Policy Entropy: 3.03688
Value Function Loss: 0.00468

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.58648
Value Function Update Magnitude: 0.55535

Collected Steps per Second: 22,716.91857
Overall Steps per Second: 10,676.27311

Timestep Collection Time: 2.20180
Timestep Consumption Time: 2.48317
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.68497

Cumulative Model Updates: 152,336
Cumulative Timesteps: 1,270,548,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.47053
Policy Entropy: 3.02601
Value Function Loss: 0.00497

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.59206
Value Function Update Magnitude: 0.58906

Collected Steps per Second: 22,198.11771
Overall Steps per Second: 10,612.64544

Timestep Collection Time: 2.25370
Timestep Consumption Time: 2.46029
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.71400

Cumulative Model Updates: 152,342
Cumulative Timesteps: 1,270,598,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1270598356...
Checkpoint 1270598356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.84631
Policy Entropy: 3.01077
Value Function Loss: 0.00491

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.59664
Value Function Update Magnitude: 0.59432

Collected Steps per Second: 22,805.30408
Overall Steps per Second: 10,893.94751

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.39810
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.59136

Cumulative Model Updates: 152,348
Cumulative Timesteps: 1,270,648,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.65869
Policy Entropy: 3.01214
Value Function Loss: 0.00535

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.61198
Value Function Update Magnitude: 0.62268

Collected Steps per Second: 23,126.44295
Overall Steps per Second: 10,928.99925

Timestep Collection Time: 2.16229
Timestep Consumption Time: 2.41325
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.57553

Cumulative Model Updates: 152,354
Cumulative Timesteps: 1,270,698,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1270698380...
Checkpoint 1270698380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,301.89296
Policy Entropy: 3.02202
Value Function Loss: 0.00509

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.61126
Value Function Update Magnitude: 0.62102

Collected Steps per Second: 22,926.90253
Overall Steps per Second: 10,638.87368

Timestep Collection Time: 2.18189
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.70200

Cumulative Model Updates: 152,360
Cumulative Timesteps: 1,270,748,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.65752
Policy Entropy: 3.03464
Value Function Loss: 0.00510

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12144
Policy Update Magnitude: 0.60020
Value Function Update Magnitude: 0.58588

Collected Steps per Second: 23,252.81452
Overall Steps per Second: 10,943.50777

Timestep Collection Time: 2.15157
Timestep Consumption Time: 2.42009
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.57166

Cumulative Model Updates: 152,366
Cumulative Timesteps: 1,270,798,434

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1270798434...
Checkpoint 1270798434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.38052
Policy Entropy: 3.03850
Value Function Loss: 0.00482

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.59179
Value Function Update Magnitude: 0.56408

Collected Steps per Second: 23,070.52804
Overall Steps per Second: 10,806.60390

Timestep Collection Time: 2.16779
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.62791

Cumulative Model Updates: 152,372
Cumulative Timesteps: 1,270,848,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.43696
Policy Entropy: 3.02499
Value Function Loss: 0.00512

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.61103
Value Function Update Magnitude: 0.60089

Collected Steps per Second: 23,277.07149
Overall Steps per Second: 10,812.56118

Timestep Collection Time: 2.14829
Timestep Consumption Time: 2.47651
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.62481

Cumulative Model Updates: 152,378
Cumulative Timesteps: 1,270,898,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1270898452...
Checkpoint 1270898452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.17506
Policy Entropy: 3.01818
Value Function Loss: 0.00507

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.61966
Value Function Update Magnitude: 0.63494

Collected Steps per Second: 23,247.11015
Overall Steps per Second: 11,001.05364

Timestep Collection Time: 2.15089
Timestep Consumption Time: 2.39431
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.54520

Cumulative Model Updates: 152,384
Cumulative Timesteps: 1,270,948,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.74944
Policy Entropy: 3.02352
Value Function Loss: 0.00465

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.60849
Value Function Update Magnitude: 0.63874

Collected Steps per Second: 23,431.74184
Overall Steps per Second: 10,943.77594

Timestep Collection Time: 2.13420
Timestep Consumption Time: 2.43534
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.56954

Cumulative Model Updates: 152,390
Cumulative Timesteps: 1,270,998,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1270998462...
Checkpoint 1270998462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,261.72335
Policy Entropy: 3.04220
Value Function Loss: 0.00450

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.58827
Value Function Update Magnitude: 0.59666

Collected Steps per Second: 22,477.34847
Overall Steps per Second: 10,633.73474

Timestep Collection Time: 2.22473
Timestep Consumption Time: 2.47785
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.70258

Cumulative Model Updates: 152,396
Cumulative Timesteps: 1,271,048,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.33359
Policy Entropy: 3.05917
Value Function Loss: 0.00426

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.58266
Value Function Update Magnitude: 0.56964

Collected Steps per Second: 22,656.03823
Overall Steps per Second: 10,642.16841

Timestep Collection Time: 2.20798
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.70055

Cumulative Model Updates: 152,402
Cumulative Timesteps: 1,271,098,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1271098492...
Checkpoint 1271098492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.72813
Policy Entropy: 3.05217
Value Function Loss: 0.00467

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.56285

Collected Steps per Second: 22,637.82784
Overall Steps per Second: 10,784.12688

Timestep Collection Time: 2.20966
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.63848

Cumulative Model Updates: 152,408
Cumulative Timesteps: 1,271,148,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.43643
Policy Entropy: 3.04837
Value Function Loss: 0.00440

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.58293
Value Function Update Magnitude: 0.55883

Collected Steps per Second: 22,941.74463
Overall Steps per Second: 10,804.16415

Timestep Collection Time: 2.18022
Timestep Consumption Time: 2.44929
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.62951

Cumulative Model Updates: 152,414
Cumulative Timesteps: 1,271,198,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1271198532...
Checkpoint 1271198532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252.03599
Policy Entropy: 3.04308
Value Function Loss: 0.00421

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.57565
Value Function Update Magnitude: 0.54868

Collected Steps per Second: 22,841.03828
Overall Steps per Second: 10,761.53513

Timestep Collection Time: 2.18983
Timestep Consumption Time: 2.45802
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.64785

Cumulative Model Updates: 152,420
Cumulative Timesteps: 1,271,248,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.56497
Policy Entropy: 3.03881
Value Function Loss: 0.00395

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.57019
Value Function Update Magnitude: 0.52197

Collected Steps per Second: 23,417.66086
Overall Steps per Second: 10,929.94987

Timestep Collection Time: 2.13565
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.57568

Cumulative Model Updates: 152,426
Cumulative Timesteps: 1,271,298,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1271298562...
Checkpoint 1271298562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754.06061
Policy Entropy: 3.04419
Value Function Loss: 0.00412

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.56534
Value Function Update Magnitude: 0.50740

Collected Steps per Second: 23,000.91133
Overall Steps per Second: 10,688.78294

Timestep Collection Time: 2.17496
Timestep Consumption Time: 2.50528
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.68023

Cumulative Model Updates: 152,432
Cumulative Timesteps: 1,271,348,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,539.72288
Policy Entropy: 3.05971
Value Function Loss: 0.00428

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.57088
Value Function Update Magnitude: 0.51981

Collected Steps per Second: 23,147.58906
Overall Steps per Second: 10,978.17015

Timestep Collection Time: 2.16126
Timestep Consumption Time: 2.39578
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.55704

Cumulative Model Updates: 152,438
Cumulative Timesteps: 1,271,398,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1271398616...
Checkpoint 1271398616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,494.91028
Policy Entropy: 3.06191
Value Function Loss: 0.00426

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.56917
Value Function Update Magnitude: 0.54092

Collected Steps per Second: 23,161.42206
Overall Steps per Second: 10,981.49240

Timestep Collection Time: 2.15980
Timestep Consumption Time: 2.39550
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.55530

Cumulative Model Updates: 152,444
Cumulative Timesteps: 1,271,448,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.24488
Policy Entropy: 3.06526
Value Function Loss: 0.00415

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.56371
Value Function Update Magnitude: 0.54156

Collected Steps per Second: 23,089.79184
Overall Steps per Second: 10,743.66488

Timestep Collection Time: 2.16684
Timestep Consumption Time: 2.49004
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.65688

Cumulative Model Updates: 152,450
Cumulative Timesteps: 1,271,498,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1271498672...
Checkpoint 1271498672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.49422
Policy Entropy: 3.06100
Value Function Loss: 0.00412

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.53465

Collected Steps per Second: 22,566.97693
Overall Steps per Second: 10,597.99404

Timestep Collection Time: 2.21651
Timestep Consumption Time: 2.50325
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.71976

Cumulative Model Updates: 152,456
Cumulative Timesteps: 1,271,548,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,955.71260
Policy Entropy: 3.05719
Value Function Loss: 0.00411

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.56854
Value Function Update Magnitude: 0.53869

Collected Steps per Second: 22,834.44566
Overall Steps per Second: 10,782.35298

Timestep Collection Time: 2.19002
Timestep Consumption Time: 2.44792
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.63795

Cumulative Model Updates: 152,462
Cumulative Timesteps: 1,271,598,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1271598700...
Checkpoint 1271598700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801.89098
Policy Entropy: 3.06367
Value Function Loss: 0.00412

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.51623

Collected Steps per Second: 22,595.61696
Overall Steps per Second: 10,594.67613

Timestep Collection Time: 2.21397
Timestep Consumption Time: 2.50784
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.72181

Cumulative Model Updates: 152,468
Cumulative Timesteps: 1,271,648,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.16593
Policy Entropy: 3.06589
Value Function Loss: 0.00397

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.55608
Value Function Update Magnitude: 0.51361

Collected Steps per Second: 22,691.10352
Overall Steps per Second: 10,610.81651

Timestep Collection Time: 2.20359
Timestep Consumption Time: 2.50877
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.71236

Cumulative Model Updates: 152,474
Cumulative Timesteps: 1,271,698,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1271698728...
Checkpoint 1271698728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,356.28883
Policy Entropy: 3.07928
Value Function Loss: 0.00387

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.54995
Value Function Update Magnitude: 0.52739

Collected Steps per Second: 22,892.29555
Overall Steps per Second: 10,682.56531

Timestep Collection Time: 2.18501
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.68240

Cumulative Model Updates: 152,480
Cumulative Timesteps: 1,271,748,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015.19942
Policy Entropy: 3.07294
Value Function Loss: 0.00382

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.55322
Value Function Update Magnitude: 0.52146

Collected Steps per Second: 23,376.63467
Overall Steps per Second: 10,754.71219

Timestep Collection Time: 2.13957
Timestep Consumption Time: 2.51104
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.65061

Cumulative Model Updates: 152,486
Cumulative Timesteps: 1,271,798,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1271798764...
Checkpoint 1271798764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,695.32601
Policy Entropy: 3.06283
Value Function Loss: 0.00401

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.56599
Value Function Update Magnitude: 0.49733

Collected Steps per Second: 23,058.44050
Overall Steps per Second: 10,829.33284

Timestep Collection Time: 2.16944
Timestep Consumption Time: 2.44986
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.61931

Cumulative Model Updates: 152,492
Cumulative Timesteps: 1,271,848,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,287.90796
Policy Entropy: 3.04631
Value Function Loss: 0.00426

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.57445
Value Function Update Magnitude: 0.51219

Collected Steps per Second: 23,348.54770
Overall Steps per Second: 10,892.10025

Timestep Collection Time: 2.14232
Timestep Consumption Time: 2.45000
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.59232

Cumulative Model Updates: 152,498
Cumulative Timesteps: 1,271,898,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1271898808...
Checkpoint 1271898808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.38704
Policy Entropy: 3.04161
Value Function Loss: 0.00436

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.52154

Collected Steps per Second: 22,904.85191
Overall Steps per Second: 10,807.04461

Timestep Collection Time: 2.18390
Timestep Consumption Time: 2.44474
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.62865

Cumulative Model Updates: 152,504
Cumulative Timesteps: 1,271,948,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.76342
Policy Entropy: 3.03397
Value Function Loss: 0.00428

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.57775
Value Function Update Magnitude: 0.52893

Collected Steps per Second: 23,220.84216
Overall Steps per Second: 10,876.16697

Timestep Collection Time: 2.15350
Timestep Consumption Time: 2.44426
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.59776

Cumulative Model Updates: 152,510
Cumulative Timesteps: 1,271,998,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1271998836...
Checkpoint 1271998836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,081.08819
Policy Entropy: 3.03803
Value Function Loss: 0.00421

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.57635
Value Function Update Magnitude: 0.53626

Collected Steps per Second: 22,474.03487
Overall Steps per Second: 10,737.33017

Timestep Collection Time: 2.22523
Timestep Consumption Time: 2.43235
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.65758

Cumulative Model Updates: 152,516
Cumulative Timesteps: 1,272,048,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.29583
Policy Entropy: 3.05342
Value Function Loss: 0.00396

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.56619
Value Function Update Magnitude: 0.51959

Collected Steps per Second: 22,725.18017
Overall Steps per Second: 10,671.24021

Timestep Collection Time: 2.20152
Timestep Consumption Time: 2.48678
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.68830

Cumulative Model Updates: 152,522
Cumulative Timesteps: 1,272,098,876

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1272098876...
Checkpoint 1272098876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,954.50997
Policy Entropy: 3.05588
Value Function Loss: 0.00401

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.55049
Value Function Update Magnitude: 0.49991

Collected Steps per Second: 22,642.90254
Overall Steps per Second: 10,809.56054

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.41850
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.62776

Cumulative Model Updates: 152,528
Cumulative Timesteps: 1,272,148,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,050.19581
Policy Entropy: 3.07228
Value Function Loss: 0.00388

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.54211
Value Function Update Magnitude: 0.48883

Collected Steps per Second: 22,438.14709
Overall Steps per Second: 10,638.18454

Timestep Collection Time: 2.22969
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.70287

Cumulative Model Updates: 152,534
Cumulative Timesteps: 1,272,198,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1272198930...
Checkpoint 1272198930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.51441
Policy Entropy: 3.06052
Value Function Loss: 0.00406

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.50705

Collected Steps per Second: 22,766.64845
Overall Steps per Second: 10,753.16320

Timestep Collection Time: 2.19707
Timestep Consumption Time: 2.45458
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.65165

Cumulative Model Updates: 152,540
Cumulative Timesteps: 1,272,248,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,176.26146
Policy Entropy: 3.06848
Value Function Loss: 0.00406

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.50913

Collected Steps per Second: 23,279.30648
Overall Steps per Second: 10,776.56699

Timestep Collection Time: 2.14843
Timestep Consumption Time: 2.49256
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.64100

Cumulative Model Updates: 152,546
Cumulative Timesteps: 1,272,298,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1272298964...
Checkpoint 1272298964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.90298
Policy Entropy: 3.05599
Value Function Loss: 0.00436

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.48611

Collected Steps per Second: 23,131.39477
Overall Steps per Second: 10,756.81833

Timestep Collection Time: 2.16277
Timestep Consumption Time: 2.48804
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.65082

Cumulative Model Updates: 152,552
Cumulative Timesteps: 1,272,348,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.21827
Policy Entropy: 3.05382
Value Function Loss: 0.00442

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.56702
Value Function Update Magnitude: 0.48454

Collected Steps per Second: 23,259.98852
Overall Steps per Second: 10,806.73822

Timestep Collection Time: 2.14979
Timestep Consumption Time: 2.47733
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.62711

Cumulative Model Updates: 152,558
Cumulative Timesteps: 1,272,398,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1272398996...
Checkpoint 1272398996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.28715
Policy Entropy: 3.05827
Value Function Loss: 0.00434

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.56101
Value Function Update Magnitude: 0.50426

Collected Steps per Second: 23,107.82664
Overall Steps per Second: 10,794.32738

Timestep Collection Time: 2.16420
Timestep Consumption Time: 2.46879
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.63299

Cumulative Model Updates: 152,564
Cumulative Timesteps: 1,272,449,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.44938
Policy Entropy: 3.06102
Value Function Loss: 0.00432

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.55964
Value Function Update Magnitude: 0.52147

Collected Steps per Second: 23,370.71511
Overall Steps per Second: 10,799.07381

Timestep Collection Time: 2.13986
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.63095

Cumulative Model Updates: 152,570
Cumulative Timesteps: 1,272,499,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1272499016...
Checkpoint 1272499016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.04209
Policy Entropy: 3.04256
Value Function Loss: 0.00429

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.53352

Collected Steps per Second: 22,770.15549
Overall Steps per Second: 10,886.11239

Timestep Collection Time: 2.19594
Timestep Consumption Time: 2.39725
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.59319

Cumulative Model Updates: 152,576
Cumulative Timesteps: 1,272,549,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.87588
Policy Entropy: 3.03677
Value Function Loss: 0.00432

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.57316
Value Function Update Magnitude: 0.54472

Collected Steps per Second: 22,799.38262
Overall Steps per Second: 10,682.84076

Timestep Collection Time: 2.19409
Timestep Consumption Time: 2.48856
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68265

Cumulative Model Updates: 152,582
Cumulative Timesteps: 1,272,599,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1272599042...
Checkpoint 1272599042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.15873
Policy Entropy: 3.03625
Value Function Loss: 0.00429

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.58041
Value Function Update Magnitude: 0.53132

Collected Steps per Second: 22,882.19024
Overall Steps per Second: 10,860.73459

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.42067
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60761

Cumulative Model Updates: 152,588
Cumulative Timesteps: 1,272,649,084

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.24990
Policy Entropy: 3.05035
Value Function Loss: 0.00451

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.59149
Value Function Update Magnitude: 0.52417

Collected Steps per Second: 22,734.45440
Overall Steps per Second: 10,742.73801

Timestep Collection Time: 2.20036
Timestep Consumption Time: 2.45618
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.65654

Cumulative Model Updates: 152,594
Cumulative Timesteps: 1,272,699,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1272699108...
Checkpoint 1272699108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.42714
Policy Entropy: 3.04138
Value Function Loss: 0.00465

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.59699
Value Function Update Magnitude: 0.54600

Collected Steps per Second: 22,631.83911
Overall Steps per Second: 10,657.39630

Timestep Collection Time: 2.20937
Timestep Consumption Time: 2.48240
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.69177

Cumulative Model Updates: 152,600
Cumulative Timesteps: 1,272,749,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.70779
Policy Entropy: 3.05135
Value Function Loss: 0.00458

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.60098
Value Function Update Magnitude: 0.58382

Collected Steps per Second: 23,413.11195
Overall Steps per Second: 10,693.32091

Timestep Collection Time: 2.13632
Timestep Consumption Time: 2.54117
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.67750

Cumulative Model Updates: 152,606
Cumulative Timesteps: 1,272,799,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1272799128...
Checkpoint 1272799128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.71088
Policy Entropy: 3.07715
Value Function Loss: 0.00437

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.58899
Value Function Update Magnitude: 0.59150

Collected Steps per Second: 23,261.79002
Overall Steps per Second: 10,714.16896

Timestep Collection Time: 2.15005
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.66802

Cumulative Model Updates: 152,612
Cumulative Timesteps: 1,272,849,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780.08245
Policy Entropy: 3.09498
Value Function Loss: 0.00399

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.56440

Collected Steps per Second: 23,225.31467
Overall Steps per Second: 10,812.65003

Timestep Collection Time: 2.15308
Timestep Consumption Time: 2.47169
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.62477

Cumulative Model Updates: 152,618
Cumulative Timesteps: 1,272,899,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1272899148...
Checkpoint 1272899148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.14616
Policy Entropy: 3.09243
Value Function Loss: 0.00420

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.56528
Value Function Update Magnitude: 0.54029

Collected Steps per Second: 22,921.45648
Overall Steps per Second: 10,722.87850

Timestep Collection Time: 2.18223
Timestep Consumption Time: 2.48256
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.66479

Cumulative Model Updates: 152,624
Cumulative Timesteps: 1,272,949,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,615.66471
Policy Entropy: 3.09488
Value Function Loss: 0.00411

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.56854
Value Function Update Magnitude: 0.51744

Collected Steps per Second: 23,252.22575
Overall Steps per Second: 10,859.63506

Timestep Collection Time: 2.15111
Timestep Consumption Time: 2.45476
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.60586

Cumulative Model Updates: 152,630
Cumulative Timesteps: 1,272,999,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1272999186...
Checkpoint 1272999186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,119.36002
Policy Entropy: 3.08174
Value Function Loss: 0.00401

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.56405
Value Function Update Magnitude: 0.51163

Collected Steps per Second: 21,761.41340
Overall Steps per Second: 10,548.33475

Timestep Collection Time: 2.29801
Timestep Consumption Time: 2.44283
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.74084

Cumulative Model Updates: 152,636
Cumulative Timesteps: 1,273,049,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.48128
Policy Entropy: 3.09095
Value Function Loss: 0.00422

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.55840
Value Function Update Magnitude: 0.53704

Collected Steps per Second: 22,676.29315
Overall Steps per Second: 10,573.82179

Timestep Collection Time: 2.20565
Timestep Consumption Time: 2.52452
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.73017

Cumulative Model Updates: 152,642
Cumulative Timesteps: 1,273,099,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1273099210...
Checkpoint 1273099210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.03595
Policy Entropy: 3.07651
Value Function Loss: 0.00459

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.57130
Value Function Update Magnitude: 0.59606

Collected Steps per Second: 22,545.17677
Overall Steps per Second: 10,626.88488

Timestep Collection Time: 2.21892
Timestep Consumption Time: 2.48857
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.70749

Cumulative Model Updates: 152,648
Cumulative Timesteps: 1,273,149,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.53554
Policy Entropy: 3.07657
Value Function Loss: 0.00486

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.58841
Value Function Update Magnitude: 0.63038

Collected Steps per Second: 22,849.46132
Overall Steps per Second: 10,876.82039

Timestep Collection Time: 2.18885
Timestep Consumption Time: 2.40937
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59822

Cumulative Model Updates: 152,654
Cumulative Timesteps: 1,273,199,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1273199250...
Checkpoint 1273199250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.92730
Policy Entropy: 3.05183
Value Function Loss: 0.00465

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.59666
Value Function Update Magnitude: 0.62067

Collected Steps per Second: 23,355.06722
Overall Steps per Second: 10,715.07780

Timestep Collection Time: 2.14103
Timestep Consumption Time: 2.52566
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.66669

Cumulative Model Updates: 152,660
Cumulative Timesteps: 1,273,249,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958.14062
Policy Entropy: 3.07220
Value Function Loss: 0.00463

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.59374
Value Function Update Magnitude: 0.60829

Collected Steps per Second: 23,288.52119
Overall Steps per Second: 10,764.46702

Timestep Collection Time: 2.14724
Timestep Consumption Time: 2.49823
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.64547

Cumulative Model Updates: 152,666
Cumulative Timesteps: 1,273,299,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1273299260...
Checkpoint 1273299260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.81277
Policy Entropy: 3.06738
Value Function Loss: 0.00449

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.59144
Value Function Update Magnitude: 0.60560

Collected Steps per Second: 22,935.05719
Overall Steps per Second: 10,708.66043

Timestep Collection Time: 2.18050
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.67005

Cumulative Model Updates: 152,672
Cumulative Timesteps: 1,273,349,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.74686
Policy Entropy: 3.07392
Value Function Loss: 0.00441

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.58534
Value Function Update Magnitude: 0.57956

Collected Steps per Second: 23,221.79437
Overall Steps per Second: 10,887.54665

Timestep Collection Time: 2.15375
Timestep Consumption Time: 2.43994
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.59369

Cumulative Model Updates: 152,678
Cumulative Timesteps: 1,273,399,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1273399284...
Checkpoint 1273399284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872.05785
Policy Entropy: 3.05289
Value Function Loss: 0.00438

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.57940
Value Function Update Magnitude: 0.56483

Collected Steps per Second: 22,911.78190
Overall Steps per Second: 10,757.04240

Timestep Collection Time: 2.18272
Timestep Consumption Time: 2.46633
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.64905

Cumulative Model Updates: 152,684
Cumulative Timesteps: 1,273,449,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.71388
Policy Entropy: 3.05065
Value Function Loss: 0.00397

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.57524
Value Function Update Magnitude: 0.53779

Collected Steps per Second: 23,231.70511
Overall Steps per Second: 10,829.59402

Timestep Collection Time: 2.15283
Timestep Consumption Time: 2.46544
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.61827

Cumulative Model Updates: 152,690
Cumulative Timesteps: 1,273,499,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1273499308...
Checkpoint 1273499308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,899.09078
Policy Entropy: 3.05897
Value Function Loss: 0.00383

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.56116
Value Function Update Magnitude: 0.50351

Collected Steps per Second: 22,313.30414
Overall Steps per Second: 10,646.31613

Timestep Collection Time: 2.24082
Timestep Consumption Time: 2.45564
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.69646

Cumulative Model Updates: 152,696
Cumulative Timesteps: 1,273,549,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.39068
Policy Entropy: 3.06191
Value Function Loss: 0.00381

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.50028

Collected Steps per Second: 22,977.73046
Overall Steps per Second: 10,837.71657

Timestep Collection Time: 2.17654
Timestep Consumption Time: 2.43808
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61463

Cumulative Model Updates: 152,702
Cumulative Timesteps: 1,273,599,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1273599320...
Checkpoint 1273599320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.23589
Policy Entropy: 3.05181
Value Function Loss: 0.00379

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.55864
Value Function Update Magnitude: 0.50547

Collected Steps per Second: 22,513.28342
Overall Steps per Second: 10,692.36904

Timestep Collection Time: 2.22224
Timestep Consumption Time: 2.45679
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.67904

Cumulative Model Updates: 152,708
Cumulative Timesteps: 1,273,649,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.06855
Policy Entropy: 3.04597
Value Function Loss: 0.00375

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.49498

Collected Steps per Second: 22,657.03723
Overall Steps per Second: 10,660.11039

Timestep Collection Time: 2.20770
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.69226

Cumulative Model Updates: 152,714
Cumulative Timesteps: 1,273,699,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1273699370...
Checkpoint 1273699370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.17474
Policy Entropy: 3.03399
Value Function Loss: 0.00392

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.49716

Collected Steps per Second: 22,596.15884
Overall Steps per Second: 10,616.83930

Timestep Collection Time: 2.21303
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.71006

Cumulative Model Updates: 152,720
Cumulative Timesteps: 1,273,749,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,565.20581
Policy Entropy: 3.01700
Value Function Loss: 0.00421

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.57962
Value Function Update Magnitude: 0.50491

Collected Steps per Second: 23,395.38576
Overall Steps per Second: 10,763.34175

Timestep Collection Time: 2.13760
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.64633

Cumulative Model Updates: 152,726
Cumulative Timesteps: 1,273,799,386

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1273799386...
Checkpoint 1273799386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.47626
Policy Entropy: 3.01819
Value Function Loss: 0.00439

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.58621
Value Function Update Magnitude: 0.51758

Collected Steps per Second: 23,225.21953
Overall Steps per Second: 10,790.56124

Timestep Collection Time: 2.15361
Timestep Consumption Time: 2.48174
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.63535

Cumulative Model Updates: 152,732
Cumulative Timesteps: 1,273,849,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.88242
Policy Entropy: 3.04257
Value Function Loss: 0.00434

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.58608
Value Function Update Magnitude: 0.53461

Collected Steps per Second: 23,486.86508
Overall Steps per Second: 10,904.38407

Timestep Collection Time: 2.13081
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.58953

Cumulative Model Updates: 152,738
Cumulative Timesteps: 1,273,899,450

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1273899450...
Checkpoint 1273899450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,818.92963
Policy Entropy: 3.07242
Value Function Loss: 0.00457

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10720
Policy Update Magnitude: 0.57833
Value Function Update Magnitude: 0.56948

Collected Steps per Second: 23,267.91902
Overall Steps per Second: 10,913.41142

Timestep Collection Time: 2.14940
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.58262

Cumulative Model Updates: 152,744
Cumulative Timesteps: 1,273,949,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.82699
Policy Entropy: 3.07977
Value Function Loss: 0.00433

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.56560

Collected Steps per Second: 23,346.88488
Overall Steps per Second: 10,947.72025

Timestep Collection Time: 2.14170
Timestep Consumption Time: 2.42564
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.56734

Cumulative Model Updates: 152,750
Cumulative Timesteps: 1,273,999,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1273999464...
Checkpoint 1273999464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.81675
Policy Entropy: 3.07338
Value Function Loss: 0.00445

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.58208
Value Function Update Magnitude: 0.54243

Collected Steps per Second: 22,789.04362
Overall Steps per Second: 10,709.62621

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.47565
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.67056

Cumulative Model Updates: 152,756
Cumulative Timesteps: 1,274,049,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,476.15876
Policy Entropy: 3.06832
Value Function Loss: 0.00426

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.57921
Value Function Update Magnitude: 0.54169

Collected Steps per Second: 22,868.22627
Overall Steps per Second: 10,797.48216

Timestep Collection Time: 2.18705
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.63201

Cumulative Model Updates: 152,762
Cumulative Timesteps: 1,274,099,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1274099498...
Checkpoint 1274099498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.07421
Policy Entropy: 3.08595
Value Function Loss: 0.00431

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.57053
Value Function Update Magnitude: 0.55915

Collected Steps per Second: 22,603.70455
Overall Steps per Second: 10,620.54043

Timestep Collection Time: 2.21291
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.70974

Cumulative Model Updates: 152,768
Cumulative Timesteps: 1,274,149,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,571.46887
Policy Entropy: 3.07572
Value Function Loss: 0.00411

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.54067

Collected Steps per Second: 23,102.51132
Overall Steps per Second: 10,669.94073

Timestep Collection Time: 2.16479
Timestep Consumption Time: 2.52240
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.68719

Cumulative Model Updates: 152,774
Cumulative Timesteps: 1,274,199,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1274199530...
Checkpoint 1274199530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739.00777
Policy Entropy: 3.06267
Value Function Loss: 0.00428

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.56308
Value Function Update Magnitude: 0.51080

Collected Steps per Second: 23,142.42039
Overall Steps per Second: 10,965.64940

Timestep Collection Time: 2.16174
Timestep Consumption Time: 2.40050
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.56225

Cumulative Model Updates: 152,780
Cumulative Timesteps: 1,274,249,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.83390
Policy Entropy: 3.04454
Value Function Loss: 0.00430

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.57616
Value Function Update Magnitude: 0.50791

Collected Steps per Second: 23,102.61464
Overall Steps per Second: 10,842.34320

Timestep Collection Time: 2.16512
Timestep Consumption Time: 2.44827
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.61339

Cumulative Model Updates: 152,786
Cumulative Timesteps: 1,274,299,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1274299578...
Checkpoint 1274299578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,093.08614
Policy Entropy: 3.03108
Value Function Loss: 0.00422

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.58800
Value Function Update Magnitude: 0.51352

Collected Steps per Second: 22,851.74269
Overall Steps per Second: 10,719.61250

Timestep Collection Time: 2.18872
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.66584

Cumulative Model Updates: 152,792
Cumulative Timesteps: 1,274,349,594

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,947.80277
Policy Entropy: 3.04966
Value Function Loss: 0.00441

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.59004
Value Function Update Magnitude: 0.52600

Collected Steps per Second: 23,434.31701
Overall Steps per Second: 10,844.16859

Timestep Collection Time: 2.13439
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.61243

Cumulative Model Updates: 152,798
Cumulative Timesteps: 1,274,399,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1274399612...
Checkpoint 1274399612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.44538
Policy Entropy: 3.06149
Value Function Loss: 0.00441

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.58593
Value Function Update Magnitude: 0.52372

Collected Steps per Second: 23,194.70506
Overall Steps per Second: 10,979.44049

Timestep Collection Time: 2.15696
Timestep Consumption Time: 2.39974
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.55670

Cumulative Model Updates: 152,804
Cumulative Timesteps: 1,274,449,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,895.99709
Policy Entropy: 3.07139
Value Function Loss: 0.00438

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.57744
Value Function Update Magnitude: 0.53781

Collected Steps per Second: 22,651.28536
Overall Steps per Second: 10,581.57363

Timestep Collection Time: 2.20835
Timestep Consumption Time: 2.51892
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.72727

Cumulative Model Updates: 152,810
Cumulative Timesteps: 1,274,499,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1274499664...
Checkpoint 1274499664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,339.78013
Policy Entropy: 3.06541
Value Function Loss: 0.00450

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.58690
Value Function Update Magnitude: 0.52846

Collected Steps per Second: 22,486.81251
Overall Steps per Second: 10,610.99466

Timestep Collection Time: 2.22406
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.71322

Cumulative Model Updates: 152,816
Cumulative Timesteps: 1,274,549,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.11073
Policy Entropy: 3.04339
Value Function Loss: 0.00451

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.58772
Value Function Update Magnitude: 0.53122

Collected Steps per Second: 22,793.08608
Overall Steps per Second: 10,697.75226

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.48053
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.67444

Cumulative Model Updates: 152,822
Cumulative Timesteps: 1,274,599,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1274599682...
Checkpoint 1274599682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.16262
Policy Entropy: 3.02649
Value Function Loss: 0.00471

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.60524
Value Function Update Magnitude: 0.56159

Collected Steps per Second: 22,475.31369
Overall Steps per Second: 10,773.04458

Timestep Collection Time: 2.22502
Timestep Consumption Time: 2.41694
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.64196

Cumulative Model Updates: 152,828
Cumulative Timesteps: 1,274,649,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.22655
Policy Entropy: 3.01478
Value Function Loss: 0.00435

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.60188
Value Function Update Magnitude: 0.55233

Collected Steps per Second: 23,601.15799
Overall Steps per Second: 10,937.83946

Timestep Collection Time: 2.11871
Timestep Consumption Time: 2.45294
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.57165

Cumulative Model Updates: 152,834
Cumulative Timesteps: 1,274,699,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1274699694...
Checkpoint 1274699694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,520.90727
Policy Entropy: 3.02124
Value Function Loss: 0.00442

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.59970
Value Function Update Magnitude: 0.53463

Collected Steps per Second: 22,950.40116
Overall Steps per Second: 10,662.54807

Timestep Collection Time: 2.17870
Timestep Consumption Time: 2.51080
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.68950

Cumulative Model Updates: 152,840
Cumulative Timesteps: 1,274,749,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,868.78682
Policy Entropy: 3.02196
Value Function Loss: 0.00446

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.60181
Value Function Update Magnitude: 0.52188

Collected Steps per Second: 22,923.93819
Overall Steps per Second: 10,897.83527

Timestep Collection Time: 2.18209
Timestep Consumption Time: 2.40800
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.59009

Cumulative Model Updates: 152,846
Cumulative Timesteps: 1,274,799,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1274799718...
Checkpoint 1274799718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.01087
Policy Entropy: 3.02512
Value Function Loss: 0.00497

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.61666
Value Function Update Magnitude: 0.53590

Collected Steps per Second: 23,035.62562
Overall Steps per Second: 10,785.97469

Timestep Collection Time: 2.17099
Timestep Consumption Time: 2.46559
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.63658

Cumulative Model Updates: 152,852
Cumulative Timesteps: 1,274,849,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.67881
Policy Entropy: 3.03337
Value Function Loss: 0.00514

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10774
Policy Update Magnitude: 0.62139
Value Function Update Magnitude: 0.56784

Collected Steps per Second: 23,186.86892
Overall Steps per Second: 10,804.36686

Timestep Collection Time: 2.15682
Timestep Consumption Time: 2.47186
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.62868

Cumulative Model Updates: 152,858
Cumulative Timesteps: 1,274,899,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1274899738...
Checkpoint 1274899738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,892.28651
Policy Entropy: 3.03590
Value Function Loss: 0.00520

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.60987
Value Function Update Magnitude: 0.58767

Collected Steps per Second: 22,939.06849
Overall Steps per Second: 10,731.74424

Timestep Collection Time: 2.18082
Timestep Consumption Time: 2.48068
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.66150

Cumulative Model Updates: 152,864
Cumulative Timesteps: 1,274,949,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029.50459
Policy Entropy: 3.02342
Value Function Loss: 0.00550

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.61595
Value Function Update Magnitude: 0.55879

Collected Steps per Second: 22,886.42342
Overall Steps per Second: 10,847.47362

Timestep Collection Time: 2.18575
Timestep Consumption Time: 2.42583
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.61158

Cumulative Model Updates: 152,870
Cumulative Timesteps: 1,274,999,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1274999788...
Checkpoint 1274999788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.79977
Policy Entropy: 3.00346
Value Function Loss: 0.00520

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.62073
Value Function Update Magnitude: 0.55936

Collected Steps per Second: 22,681.56521
Overall Steps per Second: 10,704.09389

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.46756
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.67279

Cumulative Model Updates: 152,876
Cumulative Timesteps: 1,275,049,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.03382
Policy Entropy: 3.02183
Value Function Loss: 0.00488

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.61034
Value Function Update Magnitude: 0.55698

Collected Steps per Second: 23,169.38353
Overall Steps per Second: 10,884.88001

Timestep Collection Time: 2.15802
Timestep Consumption Time: 2.43551
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.59353

Cumulative Model Updates: 152,882
Cumulative Timesteps: 1,275,099,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1275099806...
Checkpoint 1275099806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,166.82972
Policy Entropy: 3.02864
Value Function Loss: 0.00474

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.60280
Value Function Update Magnitude: 0.53894

Collected Steps per Second: 22,699.68411
Overall Steps per Second: 10,647.16147

Timestep Collection Time: 2.20364
Timestep Consumption Time: 2.49451
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.69815

Cumulative Model Updates: 152,888
Cumulative Timesteps: 1,275,149,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.59536
Policy Entropy: 3.01892
Value Function Loss: 0.00517

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.60483
Value Function Update Magnitude: 0.53580

Collected Steps per Second: 23,476.35094
Overall Steps per Second: 10,865.54933

Timestep Collection Time: 2.13074
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.60372

Cumulative Model Updates: 152,894
Cumulative Timesteps: 1,275,199,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1275199850...
Checkpoint 1275199850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.78444
Policy Entropy: 3.01888
Value Function Loss: 0.00522

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.61189
Value Function Update Magnitude: 0.54936

Collected Steps per Second: 23,026.13108
Overall Steps per Second: 10,828.22432

Timestep Collection Time: 2.17266
Timestep Consumption Time: 2.44749
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.62015

Cumulative Model Updates: 152,900
Cumulative Timesteps: 1,275,249,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.11648
Policy Entropy: 3.02887
Value Function Loss: 0.00506

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11419
Policy Update Magnitude: 0.60073
Value Function Update Magnitude: 0.55141

Collected Steps per Second: 23,395.58824
Overall Steps per Second: 10,873.91320

Timestep Collection Time: 2.13758
Timestep Consumption Time: 2.46150
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.59908

Cumulative Model Updates: 152,906
Cumulative Timesteps: 1,275,299,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1275299888...
Checkpoint 1275299888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.04310
Policy Entropy: 3.02101
Value Function Loss: 0.00453

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.58940
Value Function Update Magnitude: 0.54245

Collected Steps per Second: 23,021.16486
Overall Steps per Second: 10,853.00420

Timestep Collection Time: 2.17200
Timestep Consumption Time: 2.43520
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.60720

Cumulative Model Updates: 152,912
Cumulative Timesteps: 1,275,349,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.69752
Policy Entropy: 3.01633
Value Function Loss: 0.00462

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.58916
Value Function Update Magnitude: 0.53102

Collected Steps per Second: 23,037.39619
Overall Steps per Second: 10,938.40806

Timestep Collection Time: 2.17169
Timestep Consumption Time: 2.40211
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.57379

Cumulative Model Updates: 152,918
Cumulative Timesteps: 1,275,399,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1275399920...
Checkpoint 1275399920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,254.80043
Policy Entropy: 3.00869
Value Function Loss: 0.00458

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.59160
Value Function Update Magnitude: 0.52895

Collected Steps per Second: 22,381.73753
Overall Steps per Second: 10,730.37286

Timestep Collection Time: 2.23414
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.66004

Cumulative Model Updates: 152,924
Cumulative Timesteps: 1,275,449,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.17411
Policy Entropy: 3.02849
Value Function Loss: 0.00443

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.52884

Collected Steps per Second: 22,799.92568
Overall Steps per Second: 10,833.98768

Timestep Collection Time: 2.19387
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.61695

Cumulative Model Updates: 152,930
Cumulative Timesteps: 1,275,499,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1275499944...
Checkpoint 1275499944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,529.99768
Policy Entropy: 3.02875
Value Function Loss: 0.00423

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.59068
Value Function Update Magnitude: 0.51436

Collected Steps per Second: 22,536.66760
Overall Steps per Second: 10,690.88383

Timestep Collection Time: 2.21896
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.67763

Cumulative Model Updates: 152,936
Cumulative Timesteps: 1,275,549,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,478.24545
Policy Entropy: 3.03477
Value Function Loss: 0.00425

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.58691
Value Function Update Magnitude: 0.51185

Collected Steps per Second: 22,959.95737
Overall Steps per Second: 10,818.54067

Timestep Collection Time: 2.17779
Timestep Consumption Time: 2.44409
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62188

Cumulative Model Updates: 152,942
Cumulative Timesteps: 1,275,599,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1275599954...
Checkpoint 1275599954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.85226
Policy Entropy: 3.03468
Value Function Loss: 0.00418

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.58487
Value Function Update Magnitude: 0.50299

Collected Steps per Second: 22,757.18912
Overall Steps per Second: 10,789.19370

Timestep Collection Time: 2.19711
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.63427

Cumulative Model Updates: 152,948
Cumulative Timesteps: 1,275,649,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,471.22980
Policy Entropy: 3.03868
Value Function Loss: 0.00417

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.57960
Value Function Update Magnitude: 0.50036

Collected Steps per Second: 23,585.81349
Overall Steps per Second: 10,811.07378

Timestep Collection Time: 2.11992
Timestep Consumption Time: 2.50497
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.62489

Cumulative Model Updates: 152,954
Cumulative Timesteps: 1,275,699,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1275699954...
Checkpoint 1275699954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.70725
Policy Entropy: 3.04353
Value Function Loss: 0.00422

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.51072

Collected Steps per Second: 22,942.80143
Overall Steps per Second: 10,726.08722

Timestep Collection Time: 2.18003
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.66302

Cumulative Model Updates: 152,960
Cumulative Timesteps: 1,275,749,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.73017
Policy Entropy: 3.05005
Value Function Loss: 0.00453

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.58730
Value Function Update Magnitude: 0.52716

Collected Steps per Second: 23,304.77079
Overall Steps per Second: 10,854.71943

Timestep Collection Time: 2.14660
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.60869

Cumulative Model Updates: 152,966
Cumulative Timesteps: 1,275,799,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1275799996...
Checkpoint 1275799996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.17761
Policy Entropy: 3.04263
Value Function Loss: 0.00489

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.59126
Value Function Update Magnitude: 0.52253

Collected Steps per Second: 23,173.90560
Overall Steps per Second: 11,004.53969

Timestep Collection Time: 2.15777
Timestep Consumption Time: 2.38617
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.54394

Cumulative Model Updates: 152,972
Cumulative Timesteps: 1,275,850,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.28254
Policy Entropy: 3.03673
Value Function Loss: 0.00516

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.60474
Value Function Update Magnitude: 0.53168

Collected Steps per Second: 23,304.34625
Overall Steps per Second: 10,976.61428

Timestep Collection Time: 2.14621
Timestep Consumption Time: 2.41039
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.55660

Cumulative Model Updates: 152,978
Cumulative Timesteps: 1,275,900,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1275900016...
Checkpoint 1275900016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.07461
Policy Entropy: 3.03203
Value Function Loss: 0.00495

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.61217
Value Function Update Magnitude: 0.55101

Collected Steps per Second: 22,540.88978
Overall Steps per Second: 10,672.82179

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.46749
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.68648

Cumulative Model Updates: 152,984
Cumulative Timesteps: 1,275,950,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.56913
Policy Entropy: 3.03263
Value Function Loss: 0.00507

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.60590
Value Function Update Magnitude: 0.55964

Collected Steps per Second: 22,789.53119
Overall Steps per Second: 10,882.13423

Timestep Collection Time: 2.19496
Timestep Consumption Time: 2.40175
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.59671

Cumulative Model Updates: 152,990
Cumulative Timesteps: 1,276,000,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1276000056...
Checkpoint 1276000056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.81300
Policy Entropy: 3.02470
Value Function Loss: 0.00494

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.60615
Value Function Update Magnitude: 0.54922

Collected Steps per Second: 22,602.42174
Overall Steps per Second: 10,687.72413

Timestep Collection Time: 2.21428
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68276

Cumulative Model Updates: 152,996
Cumulative Timesteps: 1,276,050,104

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.32425
Policy Entropy: 3.02883
Value Function Loss: 0.00488

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.60212
Value Function Update Magnitude: 0.51853

Collected Steps per Second: 23,148.82602
Overall Steps per Second: 10,868.94545

Timestep Collection Time: 2.16158
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.60376

Cumulative Model Updates: 153,002
Cumulative Timesteps: 1,276,100,142

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1276100142...
Checkpoint 1276100142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.00980
Policy Entropy: 3.02514
Value Function Loss: 0.00499

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.60898
Value Function Update Magnitude: 0.52217

Collected Steps per Second: 22,963.94257
Overall Steps per Second: 10,690.71372

Timestep Collection Time: 2.17820
Timestep Consumption Time: 2.50063
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.67883

Cumulative Model Updates: 153,008
Cumulative Timesteps: 1,276,150,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.84690
Policy Entropy: 3.01052
Value Function Loss: 0.00481

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.62257
Value Function Update Magnitude: 0.55510

Collected Steps per Second: 23,516.89050
Overall Steps per Second: 10,890.78745

Timestep Collection Time: 2.12664
Timestep Consumption Time: 2.46550
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.59214

Cumulative Model Updates: 153,014
Cumulative Timesteps: 1,276,200,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1276200174...
Checkpoint 1276200174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.43394
Policy Entropy: 3.00767
Value Function Loss: 0.00460

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10709
Policy Update Magnitude: 0.61905
Value Function Update Magnitude: 0.57276

Collected Steps per Second: 23,021.63439
Overall Steps per Second: 10,659.24845

Timestep Collection Time: 2.17265
Timestep Consumption Time: 2.51980
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.69245

Cumulative Model Updates: 153,020
Cumulative Timesteps: 1,276,250,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.61268
Policy Entropy: 3.00201
Value Function Loss: 0.00502

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.62816
Value Function Update Magnitude: 0.57504

Collected Steps per Second: 23,215.31295
Overall Steps per Second: 10,892.77220

Timestep Collection Time: 2.15453
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.59185

Cumulative Model Updates: 153,026
Cumulative Timesteps: 1,276,300,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1276300210...
Checkpoint 1276300210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.69187
Policy Entropy: 3.02656
Value Function Loss: 0.00505

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.63084
Value Function Update Magnitude: 0.57563

Collected Steps per Second: 22,924.25789
Overall Steps per Second: 10,756.24916

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.46875
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.65106

Cumulative Model Updates: 153,032
Cumulative Timesteps: 1,276,350,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,421.47207
Policy Entropy: 3.03186
Value Function Loss: 0.00482

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.61590
Value Function Update Magnitude: 0.56395

Collected Steps per Second: 23,297.84955
Overall Steps per Second: 10,809.20219

Timestep Collection Time: 2.14646
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.62643

Cumulative Model Updates: 153,038
Cumulative Timesteps: 1,276,400,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1276400246...
Checkpoint 1276400246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.64007
Policy Entropy: 3.04017
Value Function Loss: 0.00451

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.60803
Value Function Update Magnitude: 0.54624

Collected Steps per Second: 22,472.72402
Overall Steps per Second: 10,644.28216

Timestep Collection Time: 2.22536
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.69830

Cumulative Model Updates: 153,044
Cumulative Timesteps: 1,276,450,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.29238
Policy Entropy: 3.02223
Value Function Loss: 0.00450

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.60597
Value Function Update Magnitude: 0.53181

Collected Steps per Second: 23,302.85521
Overall Steps per Second: 10,902.87365

Timestep Collection Time: 2.14626
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.58723

Cumulative Model Updates: 153,050
Cumulative Timesteps: 1,276,500,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1276500270...
Checkpoint 1276500270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,974.40853
Policy Entropy: 3.01525
Value Function Loss: 0.00483

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.61340
Value Function Update Magnitude: 0.51907

Collected Steps per Second: 22,866.59467
Overall Steps per Second: 10,654.66175

Timestep Collection Time: 2.18782
Timestep Consumption Time: 2.50759
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.69541

Cumulative Model Updates: 153,056
Cumulative Timesteps: 1,276,550,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,612.65697
Policy Entropy: 3.02017
Value Function Loss: 0.00457

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.61502
Value Function Update Magnitude: 0.51718

Collected Steps per Second: 23,395.28097
Overall Steps per Second: 10,834.44980

Timestep Collection Time: 2.13744
Timestep Consumption Time: 2.47802
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.61546

Cumulative Model Updates: 153,062
Cumulative Timesteps: 1,276,600,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1276600304...
Checkpoint 1276600304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.72874
Policy Entropy: 3.04104
Value Function Loss: 0.00433

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.59897
Value Function Update Magnitude: 0.51972

Collected Steps per Second: 23,238.50773
Overall Steps per Second: 10,747.34004

Timestep Collection Time: 2.15220
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.65362

Cumulative Model Updates: 153,068
Cumulative Timesteps: 1,276,650,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,464.66279
Policy Entropy: 3.03909
Value Function Loss: 0.00423

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.58641
Value Function Update Magnitude: 0.51135

Collected Steps per Second: 23,335.00236
Overall Steps per Second: 10,805.30322

Timestep Collection Time: 2.14296
Timestep Consumption Time: 2.48495
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.62791

Cumulative Model Updates: 153,074
Cumulative Timesteps: 1,276,700,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1276700324...
Checkpoint 1276700324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.67428
Policy Entropy: 3.03819
Value Function Loss: 0.00436

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.59157
Value Function Update Magnitude: 0.51658

Collected Steps per Second: 22,510.84410
Overall Steps per Second: 10,638.91053

Timestep Collection Time: 2.22151
Timestep Consumption Time: 2.47897
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.70048

Cumulative Model Updates: 153,080
Cumulative Timesteps: 1,276,750,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.18316
Policy Entropy: 3.03288
Value Function Loss: 0.00438

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.60392
Value Function Update Magnitude: 0.53779

Collected Steps per Second: 23,058.59166
Overall Steps per Second: 10,862.84489

Timestep Collection Time: 2.16900
Timestep Consumption Time: 2.43514
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60413

Cumulative Model Updates: 153,086
Cumulative Timesteps: 1,276,800,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1276800346...
Checkpoint 1276800346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.43438
Policy Entropy: 3.03020
Value Function Loss: 0.00485

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.61426
Value Function Update Magnitude: 0.57457

Collected Steps per Second: 22,875.18900
Overall Steps per Second: 10,746.06939

Timestep Collection Time: 2.18665
Timestep Consumption Time: 2.46808
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.65473

Cumulative Model Updates: 153,092
Cumulative Timesteps: 1,276,850,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,160.18744
Policy Entropy: 3.04439
Value Function Loss: 0.00473

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.61662
Value Function Update Magnitude: 0.59672

Collected Steps per Second: 21,969.61978
Overall Steps per Second: 10,448.52490

Timestep Collection Time: 2.27596
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.78556

Cumulative Model Updates: 153,098
Cumulative Timesteps: 1,276,900,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1276900368...
Checkpoint 1276900368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,595.44387
Policy Entropy: 3.04611
Value Function Loss: 0.00462

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.60862
Value Function Update Magnitude: 0.59356

Collected Steps per Second: 22,358.20340
Overall Steps per Second: 10,625.63138

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.46958
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.70617

Cumulative Model Updates: 153,104
Cumulative Timesteps: 1,276,950,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,233.00146
Policy Entropy: 3.04401
Value Function Loss: 0.00432

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.60510
Value Function Update Magnitude: 0.57689

Collected Steps per Second: 22,757.62844
Overall Steps per Second: 10,854.91825

Timestep Collection Time: 2.19750
Timestep Consumption Time: 2.40962
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.60713

Cumulative Model Updates: 153,110
Cumulative Timesteps: 1,277,000,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1277000384...
Checkpoint 1277000384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.46256
Policy Entropy: 3.03343
Value Function Loss: 0.00443

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.60278
Value Function Update Magnitude: 0.56623

Collected Steps per Second: 22,363.61817
Overall Steps per Second: 10,761.30949

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.41089
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.64702

Cumulative Model Updates: 153,116
Cumulative Timesteps: 1,277,050,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.19539
Policy Entropy: 3.02671
Value Function Loss: 0.00466

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.60687
Value Function Update Magnitude: 0.55982

Collected Steps per Second: 23,352.69478
Overall Steps per Second: 10,860.79238

Timestep Collection Time: 2.14202
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.60574

Cumulative Model Updates: 153,122
Cumulative Timesteps: 1,277,100,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1277100414...
Checkpoint 1277100414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.71773
Policy Entropy: 3.02938
Value Function Loss: 0.00479

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.60671
Value Function Update Magnitude: 0.54637

Collected Steps per Second: 22,927.47069
Overall Steps per Second: 10,754.96144

Timestep Collection Time: 2.18175
Timestep Consumption Time: 2.46931
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.65106

Cumulative Model Updates: 153,128
Cumulative Timesteps: 1,277,150,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.60320
Policy Entropy: 3.03071
Value Function Loss: 0.00503

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.61498
Value Function Update Magnitude: 0.56622

Collected Steps per Second: 23,404.11681
Overall Steps per Second: 10,826.47146

Timestep Collection Time: 2.13672
Timestep Consumption Time: 2.48233
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.61905

Cumulative Model Updates: 153,134
Cumulative Timesteps: 1,277,200,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1277200444...
Checkpoint 1277200444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.09007
Policy Entropy: 3.03580
Value Function Loss: 0.00465

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.61594
Value Function Update Magnitude: 0.59071

Collected Steps per Second: 23,400.19761
Overall Steps per Second: 11,006.09572

Timestep Collection Time: 2.13699
Timestep Consumption Time: 2.40649
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.54348

Cumulative Model Updates: 153,140
Cumulative Timesteps: 1,277,250,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.99587
Policy Entropy: 3.03545
Value Function Loss: 0.00470

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.61383
Value Function Update Magnitude: 0.58027

Collected Steps per Second: 23,411.96397
Overall Steps per Second: 11,001.63104

Timestep Collection Time: 2.13626
Timestep Consumption Time: 2.40979
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.54605

Cumulative Model Updates: 153,146
Cumulative Timesteps: 1,277,300,464

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1277300464...
Checkpoint 1277300464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.56796
Policy Entropy: 3.02524
Value Function Loss: 0.00509

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.61698
Value Function Update Magnitude: 0.57091

Collected Steps per Second: 22,860.40954
Overall Steps per Second: 10,763.48595

Timestep Collection Time: 2.18727
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.64552

Cumulative Model Updates: 153,152
Cumulative Timesteps: 1,277,350,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.86614
Policy Entropy: 3.03198
Value Function Loss: 0.00486

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.60402
Value Function Update Magnitude: 0.57421

Collected Steps per Second: 22,756.02979
Overall Steps per Second: 10,804.80780

Timestep Collection Time: 2.19748
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.62812

Cumulative Model Updates: 153,158
Cumulative Timesteps: 1,277,400,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1277400472...
Checkpoint 1277400472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.66267
Policy Entropy: 3.04075
Value Function Loss: 0.00465

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.59498
Value Function Update Magnitude: 0.55666

Collected Steps per Second: 22,762.32126
Overall Steps per Second: 10,655.00143

Timestep Collection Time: 2.19767
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.69488

Cumulative Model Updates: 153,164
Cumulative Timesteps: 1,277,450,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.08154
Policy Entropy: 3.03784
Value Function Loss: 0.00429

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.60031
Value Function Update Magnitude: 0.54276

Collected Steps per Second: 22,995.57689
Overall Steps per Second: 10,846.51952

Timestep Collection Time: 2.17494
Timestep Consumption Time: 2.43612
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.61106

Cumulative Model Updates: 153,170
Cumulative Timesteps: 1,277,500,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1277500510...
Checkpoint 1277500510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.54807
Policy Entropy: 3.02792
Value Function Loss: 0.00437

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.60644
Value Function Update Magnitude: 0.54286

Collected Steps per Second: 22,280.02353
Overall Steps per Second: 10,693.28067

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.67583

Cumulative Model Updates: 153,176
Cumulative Timesteps: 1,277,550,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.14287
Policy Entropy: 3.02465
Value Function Loss: 0.00461

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.60920
Value Function Update Magnitude: 0.54869

Collected Steps per Second: 23,440.78071
Overall Steps per Second: 10,864.72561

Timestep Collection Time: 2.13321
Timestep Consumption Time: 2.46921
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.60242

Cumulative Model Updates: 153,182
Cumulative Timesteps: 1,277,600,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1277600514...
Checkpoint 1277600514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.73961
Policy Entropy: 3.04237
Value Function Loss: 0.00426

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.60093
Value Function Update Magnitude: 0.54837

Collected Steps per Second: 22,969.97192
Overall Steps per Second: 10,691.05958

Timestep Collection Time: 2.17806
Timestep Consumption Time: 2.50155
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.67961

Cumulative Model Updates: 153,188
Cumulative Timesteps: 1,277,650,544

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903.81234
Policy Entropy: 3.04489
Value Function Loss: 0.00441

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.59714
Value Function Update Magnitude: 0.53225

Collected Steps per Second: 23,254.85676
Overall Steps per Second: 10,830.51782

Timestep Collection Time: 2.15017
Timestep Consumption Time: 2.46659
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.61677

Cumulative Model Updates: 153,194
Cumulative Timesteps: 1,277,700,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1277700546...
Checkpoint 1277700546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.07415
Policy Entropy: 3.02426
Value Function Loss: 0.00438

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.60178
Value Function Update Magnitude: 0.54988

Collected Steps per Second: 22,991.54576
Overall Steps per Second: 10,660.94105

Timestep Collection Time: 2.17558
Timestep Consumption Time: 2.51631
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.69189

Cumulative Model Updates: 153,200
Cumulative Timesteps: 1,277,750,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.01864
Policy Entropy: 3.02380
Value Function Loss: 0.00443

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.60459
Value Function Update Magnitude: 0.56652

Collected Steps per Second: 23,243.01533
Overall Steps per Second: 10,877.90163

Timestep Collection Time: 2.15230
Timestep Consumption Time: 2.44656
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.59886

Cumulative Model Updates: 153,206
Cumulative Timesteps: 1,277,800,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1277800592...
Checkpoint 1277800592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.94276
Policy Entropy: 3.02839
Value Function Loss: 0.00413

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.59327
Value Function Update Magnitude: 0.54481

Collected Steps per Second: 22,929.47564
Overall Steps per Second: 10,680.28355

Timestep Collection Time: 2.18182
Timestep Consumption Time: 2.50232
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.68415

Cumulative Model Updates: 153,212
Cumulative Timesteps: 1,277,850,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,697.04670
Policy Entropy: 3.04431
Value Function Loss: 0.00389

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.57750
Value Function Update Magnitude: 0.51853

Collected Steps per Second: 23,001.93245
Overall Steps per Second: 10,842.52582

Timestep Collection Time: 2.17460
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61332

Cumulative Model Updates: 153,218
Cumulative Timesteps: 1,277,900,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1277900640...
Checkpoint 1277900640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.25251
Policy Entropy: 3.03196
Value Function Loss: 0.00432

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.57732
Value Function Update Magnitude: 0.51744

Collected Steps per Second: 22,481.53784
Overall Steps per Second: 10,700.04060

Timestep Collection Time: 2.22485
Timestep Consumption Time: 2.44971
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.67456

Cumulative Model Updates: 153,224
Cumulative Timesteps: 1,277,950,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,551.68489
Policy Entropy: 3.03564
Value Function Loss: 0.00437

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.58771
Value Function Update Magnitude: 0.52840

Collected Steps per Second: 22,855.94974
Overall Steps per Second: 10,883.12782

Timestep Collection Time: 2.18779
Timestep Consumption Time: 2.40685
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59463

Cumulative Model Updates: 153,230
Cumulative Timesteps: 1,278,000,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1278000662...
Checkpoint 1278000662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.04172
Policy Entropy: 3.04132
Value Function Loss: 0.00434

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.58408
Value Function Update Magnitude: 0.52286

Collected Steps per Second: 22,529.37972
Overall Steps per Second: 10,649.95394

Timestep Collection Time: 2.22066
Timestep Consumption Time: 2.47702
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.69767

Cumulative Model Updates: 153,236
Cumulative Timesteps: 1,278,050,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.62400
Policy Entropy: 3.03245
Value Function Loss: 0.00402

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11416
Policy Update Magnitude: 0.57499
Value Function Update Magnitude: 0.50015

Collected Steps per Second: 23,035.65262
Overall Steps per Second: 10,637.19780

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.53065
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.70180

Cumulative Model Updates: 153,242
Cumulative Timesteps: 1,278,100,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1278100706...
Checkpoint 1278100706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,495.26661
Policy Entropy: 3.03399
Value Function Loss: 0.00430

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.58738
Value Function Update Magnitude: 0.52563

Collected Steps per Second: 23,364.55910
Overall Steps per Second: 10,837.52722

Timestep Collection Time: 2.14085
Timestep Consumption Time: 2.47459
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.61544

Cumulative Model Updates: 153,248
Cumulative Timesteps: 1,278,150,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.18440
Policy Entropy: 3.03502
Value Function Loss: 0.00452

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.59897
Value Function Update Magnitude: 0.55578

Collected Steps per Second: 23,642.59521
Overall Steps per Second: 10,976.23271

Timestep Collection Time: 2.11550
Timestep Consumption Time: 2.44125
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.55675

Cumulative Model Updates: 153,254
Cumulative Timesteps: 1,278,200,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1278200742...
Checkpoint 1278200742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.04188
Policy Entropy: 3.04264
Value Function Loss: 0.00456

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.59528
Value Function Update Magnitude: 0.55224

Collected Steps per Second: 23,154.35900
Overall Steps per Second: 10,848.38312

Timestep Collection Time: 2.16020
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.61064

Cumulative Model Updates: 153,260
Cumulative Timesteps: 1,278,250,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.31346
Policy Entropy: 3.03643
Value Function Loss: 0.00463

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11254
Policy Update Magnitude: 0.59270
Value Function Update Magnitude: 0.54448

Collected Steps per Second: 23,260.13917
Overall Steps per Second: 10,814.16742

Timestep Collection Time: 2.15072
Timestep Consumption Time: 2.47525
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.62597

Cumulative Model Updates: 153,266
Cumulative Timesteps: 1,278,300,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1278300786...
Checkpoint 1278300786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,175.22452
Policy Entropy: 3.03429
Value Function Loss: 0.00426

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.58843
Value Function Update Magnitude: 0.53304

Collected Steps per Second: 22,968.93989
Overall Steps per Second: 10,628.16190

Timestep Collection Time: 2.17703
Timestep Consumption Time: 2.52783
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.70486

Cumulative Model Updates: 153,272
Cumulative Timesteps: 1,278,350,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.86806
Policy Entropy: 3.03192
Value Function Loss: 0.00421

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.57890
Value Function Update Magnitude: 0.54622

Collected Steps per Second: 22,931.38218
Overall Steps per Second: 10,855.26149

Timestep Collection Time: 2.18059
Timestep Consumption Time: 2.42584
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.60643

Cumulative Model Updates: 153,278
Cumulative Timesteps: 1,278,400,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1278400794...
Checkpoint 1278400794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,292.94316
Policy Entropy: 3.04088
Value Function Loss: 0.00408

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.57279
Value Function Update Magnitude: 0.52732

Collected Steps per Second: 22,596.29189
Overall Steps per Second: 10,608.36036

Timestep Collection Time: 2.21328
Timestep Consumption Time: 2.50111
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.71439

Cumulative Model Updates: 153,284
Cumulative Timesteps: 1,278,450,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640.73291
Policy Entropy: 3.04855
Value Function Loss: 0.00431

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.57250
Value Function Update Magnitude: 0.51534

Collected Steps per Second: 22,703.47789
Overall Steps per Second: 10,788.25091

Timestep Collection Time: 2.20292
Timestep Consumption Time: 2.43305
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.63597

Cumulative Model Updates: 153,290
Cumulative Timesteps: 1,278,500,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1278500820...
Checkpoint 1278500820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,476.70156
Policy Entropy: 3.05987
Value Function Loss: 0.00409

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.56739
Value Function Update Magnitude: 0.49575

Collected Steps per Second: 22,529.36532
Overall Steps per Second: 10,718.18871

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.44682
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.66721

Cumulative Model Updates: 153,296
Cumulative Timesteps: 1,278,550,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,325.07209
Policy Entropy: 3.06957
Value Function Loss: 0.00386

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.48304

Collected Steps per Second: 23,086.52545
Overall Steps per Second: 10,642.00206

Timestep Collection Time: 2.16637
Timestep Consumption Time: 2.53331
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.69968

Cumulative Model Updates: 153,302
Cumulative Timesteps: 1,278,600,858

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1278600858...
Checkpoint 1278600858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171.77927
Policy Entropy: 3.05882
Value Function Loss: 0.00367

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.54946
Value Function Update Magnitude: 0.48101

Collected Steps per Second: 23,377.03423
Overall Steps per Second: 10,932.64419

Timestep Collection Time: 2.13996
Timestep Consumption Time: 2.43587
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.57584

Cumulative Model Updates: 153,308
Cumulative Timesteps: 1,278,650,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,771.96937
Policy Entropy: 3.05182
Value Function Loss: 0.00385

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.49029

Collected Steps per Second: 22,920.36125
Overall Steps per Second: 10,821.70293

Timestep Collection Time: 2.18208
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.62164

Cumulative Model Updates: 153,314
Cumulative Timesteps: 1,278,700,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1278700898...
Checkpoint 1278700898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,527.12019
Policy Entropy: 3.04101
Value Function Loss: 0.00385

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.49519

Collected Steps per Second: 22,745.28204
Overall Steps per Second: 10,704.93523

Timestep Collection Time: 2.19861
Timestep Consumption Time: 2.47288
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.67149

Cumulative Model Updates: 153,320
Cumulative Timesteps: 1,278,750,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,766.35758
Policy Entropy: 3.03633
Value Function Loss: 0.00421

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.56854
Value Function Update Magnitude: 0.49816

Collected Steps per Second: 23,179.81787
Overall Steps per Second: 10,870.51836

Timestep Collection Time: 2.15739
Timestep Consumption Time: 2.44294
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.60033

Cumulative Model Updates: 153,326
Cumulative Timesteps: 1,278,800,914

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1278800914...
Checkpoint 1278800914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,965.88914
Policy Entropy: 3.02186
Value Function Loss: 0.00452

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.59251
Value Function Update Magnitude: 0.51144

Collected Steps per Second: 21,673.54601
Overall Steps per Second: 10,591.55863

Timestep Collection Time: 2.30751
Timestep Consumption Time: 2.41436
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.72187

Cumulative Model Updates: 153,332
Cumulative Timesteps: 1,278,850,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.17029
Policy Entropy: 3.03499
Value Function Loss: 0.00461

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10665
Policy Update Magnitude: 0.59976
Value Function Update Magnitude: 0.52925

Collected Steps per Second: 22,682.42411
Overall Steps per Second: 10,607.13268

Timestep Collection Time: 2.20479
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.71475

Cumulative Model Updates: 153,338
Cumulative Timesteps: 1,278,900,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1278900936...
Checkpoint 1278900936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,561.29948
Policy Entropy: 3.04111
Value Function Loss: 0.00438

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.59180
Value Function Update Magnitude: 0.51022

Collected Steps per Second: 22,557.25686
Overall Steps per Second: 10,575.14668

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.51279
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.73053

Cumulative Model Updates: 153,344
Cumulative Timesteps: 1,278,950,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.83167
Policy Entropy: 3.03745
Value Function Loss: 0.00425

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.58286
Value Function Update Magnitude: 0.48663

Collected Steps per Second: 22,893.06076
Overall Steps per Second: 10,874.11183

Timestep Collection Time: 2.18416
Timestep Consumption Time: 2.41411
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.59826

Cumulative Model Updates: 153,350
Cumulative Timesteps: 1,279,000,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1279000964...
Checkpoint 1279000964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.83585
Policy Entropy: 3.04865
Value Function Loss: 0.00399

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.57125
Value Function Update Magnitude: 0.48320

Collected Steps per Second: 23,201.34392
Overall Steps per Second: 10,696.95160

Timestep Collection Time: 2.15608
Timestep Consumption Time: 2.52039
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.67647

Cumulative Model Updates: 153,356
Cumulative Timesteps: 1,279,050,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.03715
Policy Entropy: 3.04993
Value Function Loss: 0.00392

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.47034

Collected Steps per Second: 23,202.95430
Overall Steps per Second: 10,862.00256

Timestep Collection Time: 2.15507
Timestep Consumption Time: 2.44850
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.60357

Cumulative Model Updates: 153,362
Cumulative Timesteps: 1,279,100,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1279100992...
Checkpoint 1279100992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.29180
Policy Entropy: 3.05150
Value Function Loss: 0.00416

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.47424

Collected Steps per Second: 23,146.12557
Overall Steps per Second: 10,857.03947

Timestep Collection Time: 2.16079
Timestep Consumption Time: 2.44580
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.60660

Cumulative Model Updates: 153,368
Cumulative Timesteps: 1,279,151,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.28453
Policy Entropy: 3.03212
Value Function Loss: 0.00420

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.48007

Collected Steps per Second: 23,195.72878
Overall Steps per Second: 10,703.64708

Timestep Collection Time: 2.15609
Timestep Consumption Time: 2.51634
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.67243

Cumulative Model Updates: 153,374
Cumulative Timesteps: 1,279,201,018

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1279201018...
Checkpoint 1279201018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.36014
Policy Entropy: 3.03228
Value Function Loss: 0.00453

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.57634
Value Function Update Magnitude: 0.47813

Collected Steps per Second: 23,267.26036
Overall Steps per Second: 10,768.73590

Timestep Collection Time: 2.14894
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.64307

Cumulative Model Updates: 153,380
Cumulative Timesteps: 1,279,251,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,602.04413
Policy Entropy: 3.03388
Value Function Loss: 0.00451

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.57043
Value Function Update Magnitude: 0.48885

Collected Steps per Second: 23,233.60838
Overall Steps per Second: 10,787.28230

Timestep Collection Time: 2.15335
Timestep Consumption Time: 2.48452
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.63787

Cumulative Model Updates: 153,386
Cumulative Timesteps: 1,279,301,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1279301048...
Checkpoint 1279301048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756.97747
Policy Entropy: 3.02959
Value Function Loss: 0.00470

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.58270
Value Function Update Magnitude: 0.51260

Collected Steps per Second: 22,595.50668
Overall Steps per Second: 10,652.86922

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.69451

Cumulative Model Updates: 153,392
Cumulative Timesteps: 1,279,351,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.43865
Policy Entropy: 3.01383
Value Function Loss: 0.00466

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.59427
Value Function Update Magnitude: 0.53156

Collected Steps per Second: 22,968.26692
Overall Steps per Second: 10,938.66614

Timestep Collection Time: 2.17779
Timestep Consumption Time: 2.39498
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.57277

Cumulative Model Updates: 153,398
Cumulative Timesteps: 1,279,401,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1279401078...
Checkpoint 1279401078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.50907
Policy Entropy: 3.02359
Value Function Loss: 0.00471

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.59394
Value Function Update Magnitude: 0.55426

Collected Steps per Second: 22,779.47272
Overall Steps per Second: 10,617.31345

Timestep Collection Time: 2.19601
Timestep Consumption Time: 2.51554
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.71155

Cumulative Model Updates: 153,404
Cumulative Timesteps: 1,279,451,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.48174
Policy Entropy: 3.02489
Value Function Loss: 0.00476

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11444
Policy Update Magnitude: 0.59964
Value Function Update Magnitude: 0.56835

Collected Steps per Second: 22,864.95542
Overall Steps per Second: 10,810.62435

Timestep Collection Time: 2.18754
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.62674

Cumulative Model Updates: 153,410
Cumulative Timesteps: 1,279,501,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1279501120...
Checkpoint 1279501120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,368.60623
Policy Entropy: 3.04695
Value Function Loss: 0.00439

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.60027
Value Function Update Magnitude: 0.55368

Collected Steps per Second: 22,961.82586
Overall Steps per Second: 10,701.59718

Timestep Collection Time: 2.17883
Timestep Consumption Time: 2.49617
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.67500

Cumulative Model Updates: 153,416
Cumulative Timesteps: 1,279,551,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.68038
Policy Entropy: 3.04153
Value Function Loss: 0.00442

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.55249

Collected Steps per Second: 23,313.95462
Overall Steps per Second: 10,887.42699

Timestep Collection Time: 2.14464
Timestep Consumption Time: 2.44781
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.59245

Cumulative Model Updates: 153,422
Cumulative Timesteps: 1,279,601,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1279601150...
Checkpoint 1279601150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.20800
Policy Entropy: 3.04200
Value Function Loss: 0.00436

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.58235
Value Function Update Magnitude: 0.55398

Collected Steps per Second: 22,854.86743
Overall Steps per Second: 10,662.25348

Timestep Collection Time: 2.18886
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.69188

Cumulative Model Updates: 153,428
Cumulative Timesteps: 1,279,651,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.66727
Policy Entropy: 3.03509
Value Function Loss: 0.00449

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.58941
Value Function Update Magnitude: 0.54181

Collected Steps per Second: 23,169.25821
Overall Steps per Second: 10,953.59532

Timestep Collection Time: 2.15855
Timestep Consumption Time: 2.40726
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.56581

Cumulative Model Updates: 153,434
Cumulative Timesteps: 1,279,701,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1279701188...
Checkpoint 1279701188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.25982
Policy Entropy: 3.03107
Value Function Loss: 0.00469

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.59098
Value Function Update Magnitude: 0.53972

Collected Steps per Second: 22,779.84962
Overall Steps per Second: 10,728.57200

Timestep Collection Time: 2.19501
Timestep Consumption Time: 2.46563
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.66064

Cumulative Model Updates: 153,440
Cumulative Timesteps: 1,279,751,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.51071
Policy Entropy: 3.02151
Value Function Loss: 0.00469

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.58768
Value Function Update Magnitude: 0.55086

Collected Steps per Second: 23,243.53085
Overall Steps per Second: 10,776.72821

Timestep Collection Time: 2.15157
Timestep Consumption Time: 2.48899
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.64055

Cumulative Model Updates: 153,446
Cumulative Timesteps: 1,279,801,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1279801200...
Checkpoint 1279801200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.85148
Policy Entropy: 3.00514
Value Function Loss: 0.00486

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.59607
Value Function Update Magnitude: 0.56883

Collected Steps per Second: 22,812.40405
Overall Steps per Second: 10,704.34363

Timestep Collection Time: 2.19284
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.67324

Cumulative Model Updates: 153,452
Cumulative Timesteps: 1,279,851,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.57119
Policy Entropy: 3.01584
Value Function Loss: 0.00474

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.60873
Value Function Update Magnitude: 0.58952

Collected Steps per Second: 22,370.10818
Overall Steps per Second: 10,773.64742

Timestep Collection Time: 2.23629
Timestep Consumption Time: 2.40708
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.64337

Cumulative Model Updates: 153,458
Cumulative Timesteps: 1,279,901,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1279901250...
Checkpoint 1279901250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.57987
Policy Entropy: 3.01207
Value Function Loss: 0.00480

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.61106
Value Function Update Magnitude: 0.59767

Collected Steps per Second: 22,502.71792
Overall Steps per Second: 10,687.87844

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.45723
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.68007

Cumulative Model Updates: 153,464
Cumulative Timesteps: 1,279,951,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,989.25557
Policy Entropy: 3.02216
Value Function Loss: 0.00448

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.60387
Value Function Update Magnitude: 0.60357

Collected Steps per Second: 22,890.44099
Overall Steps per Second: 10,888.03725

Timestep Collection Time: 2.18432
Timestep Consumption Time: 2.40788
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.59220

Cumulative Model Updates: 153,470
Cumulative Timesteps: 1,280,001,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1280001270...
Checkpoint 1280001270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.12136
Policy Entropy: 3.01852
Value Function Loss: 0.00438

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.59602
Value Function Update Magnitude: 0.57476

Collected Steps per Second: 23,147.16253
Overall Steps per Second: 10,682.86408

Timestep Collection Time: 2.16070
Timestep Consumption Time: 2.52101
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.68170

Cumulative Model Updates: 153,476
Cumulative Timesteps: 1,280,051,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.17371
Policy Entropy: 3.03448
Value Function Loss: 0.00450

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.59759
Value Function Update Magnitude: 0.56486

Collected Steps per Second: 23,193.77202
Overall Steps per Second: 10,879.19146

Timestep Collection Time: 2.15627
Timestep Consumption Time: 2.44076
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.59703

Cumulative Model Updates: 153,482
Cumulative Timesteps: 1,280,101,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1280101296...
Checkpoint 1280101296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938.52775
Policy Entropy: 3.02845
Value Function Loss: 0.00448

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.60122
Value Function Update Magnitude: 0.56149

Collected Steps per Second: 23,043.24088
Overall Steps per Second: 10,789.70424

Timestep Collection Time: 2.17079
Timestep Consumption Time: 2.46530
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.63609

Cumulative Model Updates: 153,488
Cumulative Timesteps: 1,280,151,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,881.72660
Policy Entropy: 3.01773
Value Function Loss: 0.00450

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.59943
Value Function Update Magnitude: 0.54751

Collected Steps per Second: 23,189.06703
Overall Steps per Second: 10,808.14552

Timestep Collection Time: 2.15671
Timestep Consumption Time: 2.47054
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.62725

Cumulative Model Updates: 153,494
Cumulative Timesteps: 1,280,201,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1280201330...
Checkpoint 1280201330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729.81173
Policy Entropy: 3.01634
Value Function Loss: 0.00440

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.59331
Value Function Update Magnitude: 0.53782

Collected Steps per Second: 23,036.10505
Overall Steps per Second: 10,718.90703

Timestep Collection Time: 2.17172
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.66727

Cumulative Model Updates: 153,500
Cumulative Timesteps: 1,280,251,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.65444
Policy Entropy: 3.02121
Value Function Loss: 0.00446

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.59005
Value Function Update Magnitude: 0.53598

Collected Steps per Second: 22,996.56325
Overall Steps per Second: 10,822.38346

Timestep Collection Time: 2.17546
Timestep Consumption Time: 2.44719
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.62264

Cumulative Model Updates: 153,506
Cumulative Timesteps: 1,280,301,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1280301386...
Checkpoint 1280301386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914.56454
Policy Entropy: 3.02632
Value Function Loss: 0.00472

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.59695
Value Function Update Magnitude: 0.54443

Collected Steps per Second: 22,492.12128
Overall Steps per Second: 10,644.09023

Timestep Collection Time: 2.22416
Timestep Consumption Time: 2.47573
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.69988

Cumulative Model Updates: 153,512
Cumulative Timesteps: 1,280,351,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,427.29691
Policy Entropy: 3.02803
Value Function Loss: 0.00445

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.59315
Value Function Update Magnitude: 0.53747

Collected Steps per Second: 22,869.81106
Overall Steps per Second: 10,814.07220

Timestep Collection Time: 2.18716
Timestep Consumption Time: 2.43829
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.62545

Cumulative Model Updates: 153,518
Cumulative Timesteps: 1,280,401,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1280401432...
Checkpoint 1280401432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.55047
Policy Entropy: 3.01613
Value Function Loss: 0.00454

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.57874
Value Function Update Magnitude: 0.52257

Collected Steps per Second: 22,667.51909
Overall Steps per Second: 10,727.63879

Timestep Collection Time: 2.20580
Timestep Consumption Time: 2.45506
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.66086

Cumulative Model Updates: 153,524
Cumulative Timesteps: 1,280,451,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,633.13705
Policy Entropy: 3.01216
Value Function Loss: 0.00441

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11741
Policy Update Magnitude: 0.57583
Value Function Update Magnitude: 0.51859

Collected Steps per Second: 22,808.29972
Overall Steps per Second: 10,863.24112

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.41165
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60489

Cumulative Model Updates: 153,530
Cumulative Timesteps: 1,280,501,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1280501456...
Checkpoint 1280501456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.95099
Policy Entropy: 2.99826
Value Function Loss: 0.00439

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.58303
Value Function Update Magnitude: 0.52303

Collected Steps per Second: 22,775.72580
Overall Steps per Second: 10,648.76269

Timestep Collection Time: 2.19655
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.69801

Cumulative Model Updates: 153,536
Cumulative Timesteps: 1,280,551,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,691.20801
Policy Entropy: 2.98908
Value Function Loss: 0.00461

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.59705
Value Function Update Magnitude: 0.52279

Collected Steps per Second: 23,410.09773
Overall Steps per Second: 10,916.85332

Timestep Collection Time: 2.13694
Timestep Consumption Time: 2.44551
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.58246

Cumulative Model Updates: 153,542
Cumulative Timesteps: 1,280,601,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1280601510...
Checkpoint 1280601510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,598.58381
Policy Entropy: 2.99207
Value Function Loss: 0.00452

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.60327
Value Function Update Magnitude: 0.52760

Collected Steps per Second: 23,173.38031
Overall Steps per Second: 10,837.12945

Timestep Collection Time: 2.15765
Timestep Consumption Time: 2.45612
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.61377

Cumulative Model Updates: 153,548
Cumulative Timesteps: 1,280,651,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.94123
Policy Entropy: 3.01390
Value Function Loss: 0.00425

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.58659
Value Function Update Magnitude: 0.53141

Collected Steps per Second: 23,143.19363
Overall Steps per Second: 10,721.41008

Timestep Collection Time: 2.16133
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.66543

Cumulative Model Updates: 153,554
Cumulative Timesteps: 1,280,701,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1280701530...
Checkpoint 1280701530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,487.32632
Policy Entropy: 3.03472
Value Function Loss: 0.00459

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.58798
Value Function Update Magnitude: 0.53319

Collected Steps per Second: 23,013.52447
Overall Steps per Second: 10,674.85405

Timestep Collection Time: 2.17281
Timestep Consumption Time: 2.51147
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.68428

Cumulative Model Updates: 153,560
Cumulative Timesteps: 1,280,751,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.17878
Policy Entropy: 3.02778
Value Function Loss: 0.00491

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.59355
Value Function Update Magnitude: 0.54161

Collected Steps per Second: 23,084.15540
Overall Steps per Second: 10,888.79714

Timestep Collection Time: 2.16677
Timestep Consumption Time: 2.42676
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.59353

Cumulative Model Updates: 153,566
Cumulative Timesteps: 1,280,801,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1280801552...
Checkpoint 1280801552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,690.96874
Policy Entropy: 3.01739
Value Function Loss: 0.00501

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.58887
Value Function Update Magnitude: 0.55624

Collected Steps per Second: 22,712.47027
Overall Steps per Second: 10,714.84491

Timestep Collection Time: 2.20249
Timestep Consumption Time: 2.46617
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.66866

Cumulative Model Updates: 153,572
Cumulative Timesteps: 1,280,851,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.31489
Policy Entropy: 3.02095
Value Function Loss: 0.00468

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.58420
Value Function Update Magnitude: 0.55068

Collected Steps per Second: 22,832.51905
Overall Steps per Second: 10,837.33837

Timestep Collection Time: 2.19012
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.61423

Cumulative Model Updates: 153,578
Cumulative Timesteps: 1,280,901,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1280901582...
Checkpoint 1280901582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,957.69022
Policy Entropy: 3.03250
Value Function Loss: 0.00429

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.57954
Value Function Update Magnitude: 0.54147

Collected Steps per Second: 22,304.05579
Overall Steps per Second: 10,606.31562

Timestep Collection Time: 2.24219
Timestep Consumption Time: 2.47292
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.71512

Cumulative Model Updates: 153,584
Cumulative Timesteps: 1,280,951,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,321.08979
Policy Entropy: 3.02625
Value Function Loss: 0.00429

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.57953
Value Function Update Magnitude: 0.54238

Collected Steps per Second: 22,957.53741
Overall Steps per Second: 10,909.71535

Timestep Collection Time: 2.17872
Timestep Consumption Time: 2.40600
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.58472

Cumulative Model Updates: 153,590
Cumulative Timesteps: 1,281,001,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1281001610...
Checkpoint 1281001610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.05881
Policy Entropy: 3.02653
Value Function Loss: 0.00421

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.58463
Value Function Update Magnitude: 0.52079

Collected Steps per Second: 22,451.21308
Overall Steps per Second: 10,732.60653

Timestep Collection Time: 2.22732
Timestep Consumption Time: 2.43194
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.65926

Cumulative Model Updates: 153,596
Cumulative Timesteps: 1,281,051,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,285.31926
Policy Entropy: 3.01968
Value Function Loss: 0.00454

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.59437
Value Function Update Magnitude: 0.53303

Collected Steps per Second: 22,941.93249
Overall Steps per Second: 10,748.01634

Timestep Collection Time: 2.18037
Timestep Consumption Time: 2.47369
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.65407

Cumulative Model Updates: 153,602
Cumulative Timesteps: 1,281,101,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1281101638...
Checkpoint 1281101638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,106.87221
Policy Entropy: 3.01833
Value Function Loss: 0.00479

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.60121
Value Function Update Magnitude: 0.54665

Collected Steps per Second: 23,110.74915
Overall Steps per Second: 10,763.28921

Timestep Collection Time: 2.16453
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.64765

Cumulative Model Updates: 153,608
Cumulative Timesteps: 1,281,151,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.13472
Policy Entropy: 3.02368
Value Function Loss: 0.00467

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.59692
Value Function Update Magnitude: 0.54180

Collected Steps per Second: 23,265.64573
Overall Steps per Second: 10,869.10114

Timestep Collection Time: 2.15012
Timestep Consumption Time: 2.45228
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.60240

Cumulative Model Updates: 153,614
Cumulative Timesteps: 1,281,201,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1281201686...
Checkpoint 1281201686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.38254
Policy Entropy: 3.01865
Value Function Loss: 0.00420

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.57665
Value Function Update Magnitude: 0.53339

Collected Steps per Second: 23,303.46489
Overall Steps per Second: 10,877.12615

Timestep Collection Time: 2.14603
Timestep Consumption Time: 2.45169
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.59772

Cumulative Model Updates: 153,620
Cumulative Timesteps: 1,281,251,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.46302
Policy Entropy: 3.02852
Value Function Loss: 0.00391

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.55802
Value Function Update Magnitude: 0.51702

Collected Steps per Second: 23,121.53051
Overall Steps per Second: 10,692.50312

Timestep Collection Time: 2.16318
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.67767

Cumulative Model Updates: 153,626
Cumulative Timesteps: 1,281,301,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1281301712...
Checkpoint 1281301712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,486.83216
Policy Entropy: 3.01496
Value Function Loss: 0.00423

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.50517

Collected Steps per Second: 22,992.94523
Overall Steps per Second: 10,686.41142

Timestep Collection Time: 2.17484
Timestep Consumption Time: 2.50456
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.67940

Cumulative Model Updates: 153,632
Cumulative Timesteps: 1,281,351,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.80197
Policy Entropy: 3.02143
Value Function Loss: 0.00475

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.58332
Value Function Update Magnitude: 0.50058

Collected Steps per Second: 22,868.78162
Overall Steps per Second: 10,875.74822

Timestep Collection Time: 2.18717
Timestep Consumption Time: 2.41187
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.59904

Cumulative Model Updates: 153,638
Cumulative Timesteps: 1,281,401,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1281401736...
Checkpoint 1281401736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.88975
Policy Entropy: 3.03338
Value Function Loss: 0.00490

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.59404
Value Function Update Magnitude: 0.50046

Collected Steps per Second: 22,792.29396
Overall Steps per Second: 10,748.82137

Timestep Collection Time: 2.19372
Timestep Consumption Time: 2.45795
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.65167

Cumulative Model Updates: 153,644
Cumulative Timesteps: 1,281,451,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.36351
Policy Entropy: 3.03190
Value Function Loss: 0.00469

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.57887
Value Function Update Magnitude: 0.50805

Collected Steps per Second: 22,592.42244
Overall Steps per Second: 10,746.74148

Timestep Collection Time: 2.21411
Timestep Consumption Time: 2.44052
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.65462

Cumulative Model Updates: 153,650
Cumulative Timesteps: 1,281,501,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1281501758...
Checkpoint 1281501758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.58432
Policy Entropy: 3.02979
Value Function Loss: 0.00438

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.52047

Collected Steps per Second: 22,795.64853
Overall Steps per Second: 10,644.18991

Timestep Collection Time: 2.19419
Timestep Consumption Time: 2.50490
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.69909

Cumulative Model Updates: 153,656
Cumulative Timesteps: 1,281,551,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.18288
Policy Entropy: 3.00499
Value Function Loss: 0.00452

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.59190
Value Function Update Magnitude: 0.52863

Collected Steps per Second: 22,993.03156
Overall Steps per Second: 10,656.67765

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.51783
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.69283

Cumulative Model Updates: 153,662
Cumulative Timesteps: 1,281,601,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1281601786...
Checkpoint 1281601786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970.56518
Policy Entropy: 3.01147
Value Function Loss: 0.00443

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.59394
Value Function Update Magnitude: 0.52795

Collected Steps per Second: 23,480.86302
Overall Steps per Second: 10,899.21630

Timestep Collection Time: 2.12948
Timestep Consumption Time: 2.45819
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.58767

Cumulative Model Updates: 153,668
Cumulative Timesteps: 1,281,651,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.62647
Policy Entropy: 3.00911
Value Function Loss: 0.00433

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11105
Policy Update Magnitude: 0.58783
Value Function Update Magnitude: 0.52578

Collected Steps per Second: 23,126.30962
Overall Steps per Second: 10,944.06951

Timestep Collection Time: 2.16308
Timestep Consumption Time: 2.40780
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.57088

Cumulative Model Updates: 153,674
Cumulative Timesteps: 1,281,701,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1281701812...
Checkpoint 1281701812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,921.51096
Policy Entropy: 3.03407
Value Function Loss: 0.00399

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.57288
Value Function Update Magnitude: 0.51553

Collected Steps per Second: 23,139.27272
Overall Steps per Second: 10,752.03951

Timestep Collection Time: 2.16135
Timestep Consumption Time: 2.49005
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.65140

Cumulative Model Updates: 153,680
Cumulative Timesteps: 1,281,751,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880.51746
Policy Entropy: 3.03293
Value Function Loss: 0.00408

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.56905
Value Function Update Magnitude: 0.50998

Collected Steps per Second: 23,331.52793
Overall Steps per Second: 10,746.65250

Timestep Collection Time: 2.14319
Timestep Consumption Time: 2.50979
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.65298

Cumulative Model Updates: 153,686
Cumulative Timesteps: 1,281,801,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1281801828...
Checkpoint 1281801828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.10541
Policy Entropy: 3.03493
Value Function Loss: 0.00445

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.57567
Value Function Update Magnitude: 0.52349

Collected Steps per Second: 22,893.97474
Overall Steps per Second: 10,675.65643

Timestep Collection Time: 2.18450
Timestep Consumption Time: 2.50017
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.68468

Cumulative Model Updates: 153,692
Cumulative Timesteps: 1,281,851,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.00001
Policy Entropy: 3.02008
Value Function Loss: 0.00493

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.57663
Value Function Update Magnitude: 0.50697

Collected Steps per Second: 22,516.73328
Overall Steps per Second: 10,810.75591

Timestep Collection Time: 2.22181
Timestep Consumption Time: 2.40580
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.62761

Cumulative Model Updates: 153,698
Cumulative Timesteps: 1,281,901,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1281901868...
Checkpoint 1281901868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.35039
Policy Entropy: 3.03411
Value Function Loss: 0.00459

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.56892
Value Function Update Magnitude: 0.48477

Collected Steps per Second: 22,665.29846
Overall Steps per Second: 10,723.63990

Timestep Collection Time: 2.20707
Timestep Consumption Time: 2.45776
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.66483

Cumulative Model Updates: 153,704
Cumulative Timesteps: 1,281,951,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,733.11112
Policy Entropy: 3.02899
Value Function Loss: 0.00423

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.55607
Value Function Update Magnitude: 0.47704

Collected Steps per Second: 22,515.73502
Overall Steps per Second: 10,621.92203

Timestep Collection Time: 2.22156
Timestep Consumption Time: 2.48757
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.70913

Cumulative Model Updates: 153,710
Cumulative Timesteps: 1,282,001,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1282001912...
Checkpoint 1282001912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,329.87062
Policy Entropy: 3.03394
Value Function Loss: 0.00415

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.49816

Collected Steps per Second: 22,675.12847
Overall Steps per Second: 10,798.28894

Timestep Collection Time: 2.20612
Timestep Consumption Time: 2.42647
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.63259

Cumulative Model Updates: 153,716
Cumulative Timesteps: 1,282,051,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.31035
Policy Entropy: 3.02598
Value Function Loss: 0.00441

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.56579
Value Function Update Magnitude: 0.52255

Collected Steps per Second: 23,193.18220
Overall Steps per Second: 10,623.03429

Timestep Collection Time: 2.15650
Timestep Consumption Time: 2.55176
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.70826

Cumulative Model Updates: 153,722
Cumulative Timesteps: 1,282,101,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1282101952...
Checkpoint 1282101952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,490.28999
Policy Entropy: 3.00637
Value Function Loss: 0.00467

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.58599
Value Function Update Magnitude: 0.54015

Collected Steps per Second: 23,093.55648
Overall Steps per Second: 10,765.08098

Timestep Collection Time: 2.16511
Timestep Consumption Time: 2.47954
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.64465

Cumulative Model Updates: 153,728
Cumulative Timesteps: 1,282,151,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.05458
Policy Entropy: 3.00688
Value Function Loss: 0.00447

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.59820
Value Function Update Magnitude: 0.55302

Collected Steps per Second: 23,140.27384
Overall Steps per Second: 10,692.64352

Timestep Collection Time: 2.16186
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.67854

Cumulative Model Updates: 153,734
Cumulative Timesteps: 1,282,201,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1282201978...
Checkpoint 1282201978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.65780
Policy Entropy: 3.01298
Value Function Loss: 0.00433

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.58129
Value Function Update Magnitude: 0.56397

Collected Steps per Second: 23,178.61408
Overall Steps per Second: 10,863.88317

Timestep Collection Time: 2.15716
Timestep Consumption Time: 2.44524
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.60241

Cumulative Model Updates: 153,740
Cumulative Timesteps: 1,282,251,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,876.75396
Policy Entropy: 3.02578
Value Function Loss: 0.00428

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.55089

Collected Steps per Second: 23,139.19278
Overall Steps per Second: 10,705.56806

Timestep Collection Time: 2.16092
Timestep Consumption Time: 2.50973
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.67065

Cumulative Model Updates: 153,746
Cumulative Timesteps: 1,282,301,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1282301980...
Checkpoint 1282301980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.32461
Policy Entropy: 3.02790
Value Function Loss: 0.00417

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.56698
Value Function Update Magnitude: 0.53328

Collected Steps per Second: 23,251.59325
Overall Steps per Second: 10,796.56111

Timestep Collection Time: 2.15108
Timestep Consumption Time: 2.48151
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.63259

Cumulative Model Updates: 153,752
Cumulative Timesteps: 1,282,351,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.27499
Policy Entropy: 3.02310
Value Function Loss: 0.00424

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.57209
Value Function Update Magnitude: 0.52027

Collected Steps per Second: 23,141.07625
Overall Steps per Second: 10,730.46352

Timestep Collection Time: 2.16101
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.66038

Cumulative Model Updates: 153,758
Cumulative Timesteps: 1,282,402,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1282402004...
Checkpoint 1282402004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,257.92013
Policy Entropy: 3.01690
Value Function Loss: 0.00419

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.53624

Collected Steps per Second: 22,779.72400
Overall Steps per Second: 10,717.60111

Timestep Collection Time: 2.19520
Timestep Consumption Time: 2.47059
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.66578

Cumulative Model Updates: 153,764
Cumulative Timesteps: 1,282,452,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,851.19574
Policy Entropy: 3.02581
Value Function Loss: 0.00423

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.56749
Value Function Update Magnitude: 0.52709

Collected Steps per Second: 22,836.56289
Overall Steps per Second: 10,793.27111

Timestep Collection Time: 2.18965
Timestep Consumption Time: 2.44324
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.63289

Cumulative Model Updates: 153,770
Cumulative Timesteps: 1,282,502,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1282502014...
Checkpoint 1282502014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.93549
Policy Entropy: 3.01592
Value Function Loss: 0.00430

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.56917
Value Function Update Magnitude: 0.51883

Collected Steps per Second: 22,715.90383
Overall Steps per Second: 10,695.94667

Timestep Collection Time: 2.20198
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.67654

Cumulative Model Updates: 153,776
Cumulative Timesteps: 1,282,552,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.87183
Policy Entropy: 3.00247
Value Function Loss: 0.00434

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.57618
Value Function Update Magnitude: 0.53945

Collected Steps per Second: 23,319.87736
Overall Steps per Second: 10,828.23433

Timestep Collection Time: 2.14435
Timestep Consumption Time: 2.47376
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.61811

Cumulative Model Updates: 153,782
Cumulative Timesteps: 1,282,602,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1282602040...
Checkpoint 1282602040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.14080
Policy Entropy: 2.99723
Value Function Loss: 0.00402

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10208
Policy Update Magnitude: 0.57386
Value Function Update Magnitude: 0.52335

Collected Steps per Second: 23,212.05932
Overall Steps per Second: 10,741.87373

Timestep Collection Time: 2.15483
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.65636

Cumulative Model Updates: 153,788
Cumulative Timesteps: 1,282,652,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,167.50460
Policy Entropy: 2.99249
Value Function Loss: 0.00437

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.51316

Collected Steps per Second: 22,064.93007
Overall Steps per Second: 10,438.95333

Timestep Collection Time: 2.26722
Timestep Consumption Time: 2.52503
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.79224

Cumulative Model Updates: 153,794
Cumulative Timesteps: 1,282,702,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1282702084...
Checkpoint 1282702084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.00599
Policy Entropy: 2.99955
Value Function Loss: 0.00439

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.57220
Value Function Update Magnitude: 0.52182

Collected Steps per Second: 23,203.72132
Overall Steps per Second: 10,982.94021

Timestep Collection Time: 2.15577
Timestep Consumption Time: 2.39874
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.55452

Cumulative Model Updates: 153,800
Cumulative Timesteps: 1,282,752,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.81110
Policy Entropy: 2.99541
Value Function Loss: 0.00441

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.57277
Value Function Update Magnitude: 0.52667

Collected Steps per Second: 23,144.11947
Overall Steps per Second: 10,885.04478

Timestep Collection Time: 2.16159
Timestep Consumption Time: 2.43444
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.59603

Cumulative Model Updates: 153,806
Cumulative Timesteps: 1,282,802,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1282802134...
Checkpoint 1282802134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.49795
Policy Entropy: 3.00240
Value Function Loss: 0.00408

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.57662
Value Function Update Magnitude: 0.51155

Collected Steps per Second: 23,064.79637
Overall Steps per Second: 10,748.62262

Timestep Collection Time: 2.16902
Timestep Consumption Time: 2.48534
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.65436

Cumulative Model Updates: 153,812
Cumulative Timesteps: 1,282,852,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,993.93937
Policy Entropy: 2.99370
Value Function Loss: 0.00394

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.56980
Value Function Update Magnitude: 0.49664

Collected Steps per Second: 22,267.59136
Overall Steps per Second: 10,506.60466

Timestep Collection Time: 2.24631
Timestep Consumption Time: 2.51450
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.76081

Cumulative Model Updates: 153,818
Cumulative Timesteps: 1,282,902,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1282902182...
Checkpoint 1282902182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.92340
Policy Entropy: 2.99156
Value Function Loss: 0.00392

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.57633
Value Function Update Magnitude: 0.48959

Collected Steps per Second: 22,750.28267
Overall Steps per Second: 10,642.44473

Timestep Collection Time: 2.19865
Timestep Consumption Time: 2.50139
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.70005

Cumulative Model Updates: 153,824
Cumulative Timesteps: 1,282,952,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,241.20337
Policy Entropy: 2.98092
Value Function Loss: 0.00410

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.57427
Value Function Update Magnitude: 0.49558

Collected Steps per Second: 22,892.53683
Overall Steps per Second: 10,847.81541

Timestep Collection Time: 2.18517
Timestep Consumption Time: 2.42627
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.61144

Cumulative Model Updates: 153,830
Cumulative Timesteps: 1,283,002,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1283002226...
Checkpoint 1283002226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,556.59274
Policy Entropy: 2.98321
Value Function Loss: 0.00425

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.51214

Collected Steps per Second: 22,928.01085
Overall Steps per Second: 10,725.15141

Timestep Collection Time: 2.18170
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.66399

Cumulative Model Updates: 153,836
Cumulative Timesteps: 1,283,052,248

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,384.27573
Policy Entropy: 2.99173
Value Function Loss: 0.00405

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.58168
Value Function Update Magnitude: 0.51893

Collected Steps per Second: 23,133.73561
Overall Steps per Second: 10,774.02424

Timestep Collection Time: 2.16247
Timestep Consumption Time: 2.48074
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.64320

Cumulative Model Updates: 153,842
Cumulative Timesteps: 1,283,102,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1283102274...
Checkpoint 1283102274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.46282
Policy Entropy: 3.00498
Value Function Loss: 0.00455

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.58321
Value Function Update Magnitude: 0.51598

Collected Steps per Second: 23,106.97184
Overall Steps per Second: 10,670.67166

Timestep Collection Time: 2.16515
Timestep Consumption Time: 2.52340
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.68855

Cumulative Model Updates: 153,848
Cumulative Timesteps: 1,283,152,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.44312
Policy Entropy: 3.02496
Value Function Loss: 0.00419

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.56616
Value Function Update Magnitude: 0.52734

Collected Steps per Second: 23,012.67993
Overall Steps per Second: 10,883.97751

Timestep Collection Time: 2.17350
Timestep Consumption Time: 2.42207
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.59556

Cumulative Model Updates: 153,854
Cumulative Timesteps: 1,283,202,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1283202322...
Checkpoint 1283202322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,429.78665
Policy Entropy: 3.02179
Value Function Loss: 0.00445

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.56441
Value Function Update Magnitude: 0.53070

Collected Steps per Second: 23,242.01098
Overall Steps per Second: 10,711.03942

Timestep Collection Time: 2.15188
Timestep Consumption Time: 2.51751
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.66939

Cumulative Model Updates: 153,860
Cumulative Timesteps: 1,283,252,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,942.21906
Policy Entropy: 3.02462
Value Function Loss: 0.00435

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.57024
Value Function Update Magnitude: 0.52493

Collected Steps per Second: 23,005.95933
Overall Steps per Second: 10,867.38372

Timestep Collection Time: 2.17431
Timestep Consumption Time: 2.42864
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.60295

Cumulative Model Updates: 153,866
Cumulative Timesteps: 1,283,302,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1283302358...
Checkpoint 1283302358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.15244
Policy Entropy: 3.00677
Value Function Loss: 0.00461

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.57999
Value Function Update Magnitude: 0.52053

Collected Steps per Second: 23,040.98627
Overall Steps per Second: 10,659.02802

Timestep Collection Time: 2.17022
Timestep Consumption Time: 2.52101
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69123

Cumulative Model Updates: 153,872
Cumulative Timesteps: 1,283,352,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,419.67549
Policy Entropy: 3.00690
Value Function Loss: 0.00464

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.58187
Value Function Update Magnitude: 0.53076

Collected Steps per Second: 22,590.20495
Overall Steps per Second: 10,721.41494

Timestep Collection Time: 2.21344
Timestep Consumption Time: 2.45031
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.66375

Cumulative Model Updates: 153,878
Cumulative Timesteps: 1,283,402,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1283402364...
Checkpoint 1283402364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.48623
Policy Entropy: 3.00444
Value Function Loss: 0.00444

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11358
Policy Update Magnitude: 0.57826
Value Function Update Magnitude: 0.52409

Collected Steps per Second: 22,399.00883
Overall Steps per Second: 10,821.34732

Timestep Collection Time: 2.23251
Timestep Consumption Time: 2.38854
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.62105

Cumulative Model Updates: 153,884
Cumulative Timesteps: 1,283,452,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.96900
Policy Entropy: 3.01247
Value Function Loss: 0.00418

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.51868

Collected Steps per Second: 22,766.88374
Overall Steps per Second: 10,652.46542

Timestep Collection Time: 2.19688
Timestep Consumption Time: 2.49838
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.69525

Cumulative Model Updates: 153,890
Cumulative Timesteps: 1,283,502,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1283502386...
Checkpoint 1283502386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,424.57791
Policy Entropy: 3.01103
Value Function Loss: 0.00416

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.57048
Value Function Update Magnitude: 0.54940

Collected Steps per Second: 23,136.03608
Overall Steps per Second: 10,850.51668

Timestep Collection Time: 2.16191
Timestep Consumption Time: 2.44783
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.60973

Cumulative Model Updates: 153,896
Cumulative Timesteps: 1,283,552,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,292.05013
Policy Entropy: 3.02049
Value Function Loss: 0.00428

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.58098
Value Function Update Magnitude: 0.56309

Collected Steps per Second: 23,161.40112
Overall Steps per Second: 10,876.72885

Timestep Collection Time: 2.15937
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.59826

Cumulative Model Updates: 153,902
Cumulative Timesteps: 1,283,602,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1283602418...
Checkpoint 1283602418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,915.46209
Policy Entropy: 3.00957
Value Function Loss: 0.00467

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11306
Policy Update Magnitude: 0.59464
Value Function Update Magnitude: 0.57611

Collected Steps per Second: 23,074.56360
Overall Steps per Second: 10,762.41674

Timestep Collection Time: 2.16801
Timestep Consumption Time: 2.48020
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.64821

Cumulative Model Updates: 153,908
Cumulative Timesteps: 1,283,652,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,263.14171
Policy Entropy: 3.02279
Value Function Loss: 0.00433

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.58045
Value Function Update Magnitude: 0.58447

Collected Steps per Second: 23,313.11695
Overall Steps per Second: 10,908.62349

Timestep Collection Time: 2.14592
Timestep Consumption Time: 2.44018
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.58610

Cumulative Model Updates: 153,914
Cumulative Timesteps: 1,283,702,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1283702472...
Checkpoint 1283702472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.16479
Policy Entropy: 3.01051
Value Function Loss: 0.00421

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.56992
Value Function Update Magnitude: 0.53725

Collected Steps per Second: 23,210.88305
Overall Steps per Second: 10,841.79037

Timestep Collection Time: 2.15545
Timestep Consumption Time: 2.45910
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.61455

Cumulative Model Updates: 153,920
Cumulative Timesteps: 1,283,752,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.63383
Policy Entropy: 3.01703
Value Function Loss: 0.00456

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.57825
Value Function Update Magnitude: 0.50048

Collected Steps per Second: 23,400.01880
Overall Steps per Second: 10,837.22504

Timestep Collection Time: 2.13709
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.61447

Cumulative Model Updates: 153,926
Cumulative Timesteps: 1,283,802,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1283802510...
Checkpoint 1283802510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.59537
Policy Entropy: 3.02743
Value Function Loss: 0.00452

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.57847
Value Function Update Magnitude: 0.52171

Collected Steps per Second: 23,008.69585
Overall Steps per Second: 10,739.82060

Timestep Collection Time: 2.17405
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.65762

Cumulative Model Updates: 153,932
Cumulative Timesteps: 1,283,852,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,106.24708
Policy Entropy: 3.02423
Value Function Loss: 0.00469

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.58592
Value Function Update Magnitude: 0.55302

Collected Steps per Second: 22,926.94595
Overall Steps per Second: 10,665.03307

Timestep Collection Time: 2.18145
Timestep Consumption Time: 2.50808
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.68953

Cumulative Model Updates: 153,938
Cumulative Timesteps: 1,283,902,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1283902546...
Checkpoint 1283902546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,553.71231
Policy Entropy: 3.01684
Value Function Loss: 0.00482

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.59462
Value Function Update Magnitude: 0.56187

Collected Steps per Second: 22,789.32103
Overall Steps per Second: 10,691.11631

Timestep Collection Time: 2.19462
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.67809

Cumulative Model Updates: 153,944
Cumulative Timesteps: 1,283,952,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.84165
Policy Entropy: 3.01133
Value Function Loss: 0.00496

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.60128
Value Function Update Magnitude: 0.56173

Collected Steps per Second: 22,827.10193
Overall Steps per Second: 10,820.36726

Timestep Collection Time: 2.19099
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62221

Cumulative Model Updates: 153,950
Cumulative Timesteps: 1,284,002,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1284002574...
Checkpoint 1284002574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.22133
Policy Entropy: 3.02328
Value Function Loss: 0.00475

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.59488
Value Function Update Magnitude: 0.57963

Collected Steps per Second: 23,036.17166
Overall Steps per Second: 10,687.04410

Timestep Collection Time: 2.17163
Timestep Consumption Time: 2.50937
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.68100

Cumulative Model Updates: 153,956
Cumulative Timesteps: 1,284,052,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.71055
Policy Entropy: 3.03800
Value Function Loss: 0.00419

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.57528

Collected Steps per Second: 22,947.94740
Overall Steps per Second: 10,807.33250

Timestep Collection Time: 2.17980
Timestep Consumption Time: 2.44872
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.62852

Cumulative Model Updates: 153,962
Cumulative Timesteps: 1,284,102,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1284102622...
Checkpoint 1284102622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.79973
Policy Entropy: 3.03887
Value Function Loss: 0.00401

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.56303
Value Function Update Magnitude: 0.53777

Collected Steps per Second: 23,068.77407
Overall Steps per Second: 10,723.24364

Timestep Collection Time: 2.16865
Timestep Consumption Time: 2.49673
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.66538

Cumulative Model Updates: 153,968
Cumulative Timesteps: 1,284,152,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,926.74140
Policy Entropy: 3.05031
Value Function Loss: 0.00410

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.55739
Value Function Update Magnitude: 0.51151

Collected Steps per Second: 23,058.52355
Overall Steps per Second: 10,862.50289

Timestep Collection Time: 2.16874
Timestep Consumption Time: 2.43498
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.60373

Cumulative Model Updates: 153,974
Cumulative Timesteps: 1,284,202,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1284202658...
Checkpoint 1284202658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.66816
Policy Entropy: 3.05369
Value Function Loss: 0.00419

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.56851
Value Function Update Magnitude: 0.52961

Collected Steps per Second: 23,074.77646
Overall Steps per Second: 10,690.94478

Timestep Collection Time: 2.16799
Timestep Consumption Time: 2.51129
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.67929

Cumulative Model Updates: 153,980
Cumulative Timesteps: 1,284,252,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,642.53509
Policy Entropy: 3.05272
Value Function Loss: 0.00393

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.57189
Value Function Update Magnitude: 0.52206

Collected Steps per Second: 23,006.58495
Overall Steps per Second: 10,839.75234

Timestep Collection Time: 2.17459
Timestep Consumption Time: 2.44082
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.61542

Cumulative Model Updates: 153,986
Cumulative Timesteps: 1,284,302,714

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1284302714...
Checkpoint 1284302714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.63545
Policy Entropy: 3.03597
Value Function Loss: 0.00384

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.56211
Value Function Update Magnitude: 0.50877

Collected Steps per Second: 23,043.24116
Overall Steps per Second: 10,745.88012

Timestep Collection Time: 2.17174
Timestep Consumption Time: 2.48530
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.65704

Cumulative Model Updates: 153,992
Cumulative Timesteps: 1,284,352,758

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,123.67767
Policy Entropy: 3.02979
Value Function Loss: 0.00435

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.56870
Value Function Update Magnitude: 0.52580

Collected Steps per Second: 22,410.84364
Overall Steps per Second: 10,582.54105

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.49530
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.72779

Cumulative Model Updates: 153,998
Cumulative Timesteps: 1,284,402,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1284402790...
Checkpoint 1284402790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.05927
Policy Entropy: 3.01706
Value Function Loss: 0.00481

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.58274
Value Function Update Magnitude: 0.53724

Collected Steps per Second: 22,807.18114
Overall Steps per Second: 10,906.68681

Timestep Collection Time: 2.19299
Timestep Consumption Time: 2.39282
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.58581

Cumulative Model Updates: 154,004
Cumulative Timesteps: 1,284,452,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.23742
Policy Entropy: 3.01238
Value Function Loss: 0.00499

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.58450
Value Function Update Magnitude: 0.53947

Collected Steps per Second: 22,406.91234
Overall Steps per Second: 10,597.84274

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.48758
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.72002

Cumulative Model Updates: 154,010
Cumulative Timesteps: 1,284,502,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1284502828...
Checkpoint 1284502828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.15312
Policy Entropy: 3.03448
Value Function Loss: 0.00464

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.57465
Value Function Update Magnitude: 0.52990

Collected Steps per Second: 22,844.82513
Overall Steps per Second: 10,665.39034

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.69012

Cumulative Model Updates: 154,016
Cumulative Timesteps: 1,284,552,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,039.62711
Policy Entropy: 3.05470
Value Function Loss: 0.00395

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.55181
Value Function Update Magnitude: 0.51897

Collected Steps per Second: 23,754.22809
Overall Steps per Second: 10,801.77758

Timestep Collection Time: 2.10556
Timestep Consumption Time: 2.52479
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.63035

Cumulative Model Updates: 154,022
Cumulative Timesteps: 1,284,602,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1284602866...
Checkpoint 1284602866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,887.50667
Policy Entropy: 3.04938
Value Function Loss: 0.00381

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.49095

Collected Steps per Second: 23,057.62086
Overall Steps per Second: 10,706.08352

Timestep Collection Time: 2.16926
Timestep Consumption Time: 2.50266
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.67192

Cumulative Model Updates: 154,028
Cumulative Timesteps: 1,284,652,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,150.73316
Policy Entropy: 3.02958
Value Function Loss: 0.00389

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.50961

Collected Steps per Second: 23,302.48033
Overall Steps per Second: 10,824.76075

Timestep Collection Time: 2.14621
Timestep Consumption Time: 2.47394
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.62015

Cumulative Model Updates: 154,034
Cumulative Timesteps: 1,284,702,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1284702896...
Checkpoint 1284702896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.69227
Policy Entropy: 3.04158
Value Function Loss: 0.00427

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.57017
Value Function Update Magnitude: 0.53626

Collected Steps per Second: 23,072.82403
Overall Steps per Second: 10,814.83453

Timestep Collection Time: 2.16748
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.62420

Cumulative Model Updates: 154,040
Cumulative Timesteps: 1,284,752,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.41848
Policy Entropy: 3.04050
Value Function Loss: 0.00464

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.58041
Value Function Update Magnitude: 0.55501

Collected Steps per Second: 23,396.95759
Overall Steps per Second: 10,854.14222

Timestep Collection Time: 2.13788
Timestep Consumption Time: 2.47049
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.60838

Cumulative Model Updates: 154,046
Cumulative Timesteps: 1,284,802,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1284802926...
Checkpoint 1284802926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.58298
Policy Entropy: 3.02705
Value Function Loss: 0.00504

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.58799
Value Function Update Magnitude: 0.56219

Collected Steps per Second: 23,351.04604
Overall Steps per Second: 10,996.89782

Timestep Collection Time: 2.14123
Timestep Consumption Time: 2.40551
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.54674

Cumulative Model Updates: 154,052
Cumulative Timesteps: 1,284,852,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.02131
Policy Entropy: 3.01679
Value Function Loss: 0.00494

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.58395
Value Function Update Magnitude: 0.55803

Collected Steps per Second: 22,790.62028
Overall Steps per Second: 10,858.72786

Timestep Collection Time: 2.19467
Timestep Consumption Time: 2.41157
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.60625

Cumulative Model Updates: 154,058
Cumulative Timesteps: 1,284,902,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1284902944...
Checkpoint 1284902944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,374.03320
Policy Entropy: 3.01045
Value Function Loss: 0.00457

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.57810
Value Function Update Magnitude: 0.54603

Collected Steps per Second: 22,487.72340
Overall Steps per Second: 10,645.61620

Timestep Collection Time: 2.22370
Timestep Consumption Time: 2.47363
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.69733

Cumulative Model Updates: 154,064
Cumulative Timesteps: 1,284,952,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,853.51640
Policy Entropy: 3.01731
Value Function Loss: 0.00415

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.53053

Collected Steps per Second: 22,775.11223
Overall Steps per Second: 10,688.48316

Timestep Collection Time: 2.19617
Timestep Consumption Time: 2.48345
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.67962

Cumulative Model Updates: 154,070
Cumulative Timesteps: 1,285,002,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1285002968...
Checkpoint 1285002968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,681.69967
Policy Entropy: 3.00874
Value Function Loss: 0.00394

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.57723
Value Function Update Magnitude: 0.51442

Collected Steps per Second: 22,679.77975
Overall Steps per Second: 10,766.05894

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.64478

Cumulative Model Updates: 154,076
Cumulative Timesteps: 1,285,052,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,148.71132
Policy Entropy: 3.00407
Value Function Loss: 0.00388

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.57876
Value Function Update Magnitude: 0.51577

Collected Steps per Second: 22,833.89782
Overall Steps per Second: 10,656.12599

Timestep Collection Time: 2.19043
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.69364

Cumulative Model Updates: 154,082
Cumulative Timesteps: 1,285,102,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1285102990...
Checkpoint 1285102990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,965.06265
Policy Entropy: 3.01237
Value Function Loss: 0.00370

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.52894

Collected Steps per Second: 22,843.97324
Overall Steps per Second: 10,669.01943

Timestep Collection Time: 2.18876
Timestep Consumption Time: 2.49771
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.68647

Cumulative Model Updates: 154,088
Cumulative Timesteps: 1,285,152,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,517.91552
Policy Entropy: 3.01152
Value Function Loss: 0.00369

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.56664
Value Function Update Magnitude: 0.52622

Collected Steps per Second: 23,347.87612
Overall Steps per Second: 10,762.12481

Timestep Collection Time: 2.14221
Timestep Consumption Time: 2.50520
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.64741

Cumulative Model Updates: 154,094
Cumulative Timesteps: 1,285,203,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1285203006...
Checkpoint 1285203006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.31421
Policy Entropy: 3.00468
Value Function Loss: 0.00391

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.56739
Value Function Update Magnitude: 0.52268

Collected Steps per Second: 23,136.52841
Overall Steps per Second: 10,702.19577

Timestep Collection Time: 2.16247
Timestep Consumption Time: 2.51246
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.67493

Cumulative Model Updates: 154,100
Cumulative Timesteps: 1,285,253,038

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.32103
Policy Entropy: 2.98953
Value Function Loss: 0.00417

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.51115

Collected Steps per Second: 23,176.17353
Overall Steps per Second: 10,861.18946

Timestep Collection Time: 2.15851
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.60594

Cumulative Model Updates: 154,106
Cumulative Timesteps: 1,285,303,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1285303064...
Checkpoint 1285303064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.29527
Policy Entropy: 2.99786
Value Function Loss: 0.00447

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.58898
Value Function Update Magnitude: 0.50774

Collected Steps per Second: 23,198.31937
Overall Steps per Second: 10,870.36855

Timestep Collection Time: 2.15567
Timestep Consumption Time: 2.44472
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.60040

Cumulative Model Updates: 154,112
Cumulative Timesteps: 1,285,353,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.66302
Policy Entropy: 3.01064
Value Function Loss: 0.00427

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.58427
Value Function Update Magnitude: 0.51380

Collected Steps per Second: 22,846.55566
Overall Steps per Second: 10,698.35828

Timestep Collection Time: 2.18895
Timestep Consumption Time: 2.48560
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.67455

Cumulative Model Updates: 154,118
Cumulative Timesteps: 1,285,403,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1285403082...
Checkpoint 1285403082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.84414
Policy Entropy: 3.01667
Value Function Loss: 0.00421

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.50535

Collected Steps per Second: 22,559.46212
Overall Steps per Second: 10,625.58063

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.48926
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.70563

Cumulative Model Updates: 154,124
Cumulative Timesteps: 1,285,453,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,470.85595
Policy Entropy: 3.00953
Value Function Loss: 0.00439

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.58201
Value Function Update Magnitude: 0.48319

Collected Steps per Second: 22,887.23442
Overall Steps per Second: 10,885.32472

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.40891
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.59371

Cumulative Model Updates: 154,130
Cumulative Timesteps: 1,285,503,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1285503086...
Checkpoint 1285503086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.51505
Policy Entropy: 3.00555
Value Function Loss: 0.00481

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.59378
Value Function Update Magnitude: 0.51445

Collected Steps per Second: 23,075.50049
Overall Steps per Second: 10,668.18733

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.52054
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.68777

Cumulative Model Updates: 154,136
Cumulative Timesteps: 1,285,553,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,447.05765
Policy Entropy: 2.99628
Value Function Loss: 0.00482

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.59528
Value Function Update Magnitude: 0.54185

Collected Steps per Second: 23,340.64375
Overall Steps per Second: 10,909.37240

Timestep Collection Time: 2.14347
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.58597

Cumulative Model Updates: 154,142
Cumulative Timesteps: 1,285,603,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1285603126...
Checkpoint 1285603126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,083.96966
Policy Entropy: 3.00331
Value Function Loss: 0.00452

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.59280
Value Function Update Magnitude: 0.54619

Collected Steps per Second: 23,155.03193
Overall Steps per Second: 10,861.43184

Timestep Collection Time: 2.15953
Timestep Consumption Time: 2.44428
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.60381

Cumulative Model Updates: 154,148
Cumulative Timesteps: 1,285,653,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.62901
Policy Entropy: 3.01090
Value Function Loss: 0.00431

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.59089
Value Function Update Magnitude: 0.54993

Collected Steps per Second: 23,140.22464
Overall Steps per Second: 10,680.52519

Timestep Collection Time: 2.16100
Timestep Consumption Time: 2.52098
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.68198

Cumulative Model Updates: 154,154
Cumulative Timesteps: 1,285,703,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1285703136...
Checkpoint 1285703136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.30422
Policy Entropy: 3.02275
Value Function Loss: 0.00453

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.59473
Value Function Update Magnitude: 0.54453

Collected Steps per Second: 22,983.00427
Overall Steps per Second: 10,774.91887

Timestep Collection Time: 2.17622
Timestep Consumption Time: 2.46567
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.64189

Cumulative Model Updates: 154,160
Cumulative Timesteps: 1,285,753,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,308.07719
Policy Entropy: 3.02492
Value Function Loss: 0.00474

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.60006
Value Function Update Magnitude: 0.56040

Collected Steps per Second: 23,075.94714
Overall Steps per Second: 10,778.44379

Timestep Collection Time: 2.16676
Timestep Consumption Time: 2.47213
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.63889

Cumulative Model Updates: 154,166
Cumulative Timesteps: 1,285,803,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1285803152...
Checkpoint 1285803152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.54053
Policy Entropy: 3.02096
Value Function Loss: 0.00478

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.59717
Value Function Update Magnitude: 0.58527

Collected Steps per Second: 22,870.50915
Overall Steps per Second: 10,640.80923

Timestep Collection Time: 2.18631
Timestep Consumption Time: 2.51277
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.69908

Cumulative Model Updates: 154,172
Cumulative Timesteps: 1,285,853,154

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171.99431
Policy Entropy: 3.01883
Value Function Loss: 0.00447

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.56336

Collected Steps per Second: 22,688.31025
Overall Steps per Second: 10,658.10302

Timestep Collection Time: 2.20422
Timestep Consumption Time: 2.48799
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.69220

Cumulative Model Updates: 154,178
Cumulative Timesteps: 1,285,903,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1285903164...
Checkpoint 1285903164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.13050
Policy Entropy: 3.02158
Value Function Loss: 0.00424

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.56601
Value Function Update Magnitude: 0.52253

Collected Steps per Second: 22,629.67540
Overall Steps per Second: 10,799.33306

Timestep Collection Time: 2.21064
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.63232

Cumulative Model Updates: 154,184
Cumulative Timesteps: 1,285,953,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,320.42275
Policy Entropy: 3.02040
Value Function Loss: 0.00411

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.55945
Value Function Update Magnitude: 0.49685

Collected Steps per Second: 23,121.19918
Overall Steps per Second: 10,647.98706

Timestep Collection Time: 2.16338
Timestep Consumption Time: 2.53422
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.69760

Cumulative Model Updates: 154,190
Cumulative Timesteps: 1,286,003,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1286003210...
Checkpoint 1286003210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,693.06568
Policy Entropy: 3.02202
Value Function Loss: 0.00399

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.56535
Value Function Update Magnitude: 0.49542

Collected Steps per Second: 23,038.70084
Overall Steps per Second: 10,735.11665

Timestep Collection Time: 2.17139
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.66003

Cumulative Model Updates: 154,196
Cumulative Timesteps: 1,286,053,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,689.81724
Policy Entropy: 3.01865
Value Function Loss: 0.00399

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10949
Policy Update Magnitude: 0.56817
Value Function Update Magnitude: 0.50563

Collected Steps per Second: 23,260.38667
Overall Steps per Second: 10,675.29774

Timestep Collection Time: 2.15027
Timestep Consumption Time: 2.53494
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.68521

Cumulative Model Updates: 154,202
Cumulative Timesteps: 1,286,103,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1286103252...
Checkpoint 1286103252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.61621
Policy Entropy: 3.03303
Value Function Loss: 0.00411

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.57102
Value Function Update Magnitude: 0.49973

Collected Steps per Second: 23,124.26084
Overall Steps per Second: 10,816.15097

Timestep Collection Time: 2.16284
Timestep Consumption Time: 2.46117
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.62401

Cumulative Model Updates: 154,208
Cumulative Timesteps: 1,286,153,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.55845
Policy Entropy: 3.03242
Value Function Loss: 0.00415

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11644
Policy Update Magnitude: 0.57324
Value Function Update Magnitude: 0.50530

Collected Steps per Second: 23,218.01718
Overall Steps per Second: 10,755.94002

Timestep Collection Time: 2.15436
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.65045

Cumulative Model Updates: 154,214
Cumulative Timesteps: 1,286,203,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1286203286...
Checkpoint 1286203286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.84521
Policy Entropy: 3.03497
Value Function Loss: 0.00407

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.57038
Value Function Update Magnitude: 0.51700

Collected Steps per Second: 23,030.02397
Overall Steps per Second: 10,816.59989

Timestep Collection Time: 2.17221
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.62493

Cumulative Model Updates: 154,220
Cumulative Timesteps: 1,286,253,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.98681
Policy Entropy: 3.01812
Value Function Loss: 0.00415

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.57555
Value Function Update Magnitude: 0.50648

Collected Steps per Second: 23,246.06052
Overall Steps per Second: 10,701.88345

Timestep Collection Time: 2.15142
Timestep Consumption Time: 2.52178
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.67320

Cumulative Model Updates: 154,226
Cumulative Timesteps: 1,286,303,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1286303324...
Checkpoint 1286303324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,254.89078
Policy Entropy: 3.02221
Value Function Loss: 0.00435

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.58296
Value Function Update Magnitude: 0.51738

Collected Steps per Second: 22,604.96493
Overall Steps per Second: 10,636.69793

Timestep Collection Time: 2.21358
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.70428

Cumulative Model Updates: 154,232
Cumulative Timesteps: 1,286,353,362

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.44339
Policy Entropy: 3.01637
Value Function Loss: 0.00442

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.58282
Value Function Update Magnitude: 0.52888

Collected Steps per Second: 22,709.79660
Overall Steps per Second: 10,846.16126

Timestep Collection Time: 2.20249
Timestep Consumption Time: 2.40910
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61159

Cumulative Model Updates: 154,238
Cumulative Timesteps: 1,286,403,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1286403380...
Checkpoint 1286403380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.48777
Policy Entropy: 3.03406
Value Function Loss: 0.00419

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.57935
Value Function Update Magnitude: 0.51222

Collected Steps per Second: 22,215.77677
Overall Steps per Second: 10,658.17559

Timestep Collection Time: 2.25137
Timestep Consumption Time: 2.44136
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.69274

Cumulative Model Updates: 154,244
Cumulative Timesteps: 1,286,453,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.47974
Policy Entropy: 3.02359
Value Function Loss: 0.00426

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.57469
Value Function Update Magnitude: 0.50283

Collected Steps per Second: 22,863.88521
Overall Steps per Second: 10,681.70728

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.49414
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.68109

Cumulative Model Updates: 154,250
Cumulative Timesteps: 1,286,503,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1286503398...
Checkpoint 1286503398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.42404
Policy Entropy: 3.02158
Value Function Loss: 0.00430

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.58034
Value Function Update Magnitude: 0.50315

Collected Steps per Second: 21,351.76148
Overall Steps per Second: 10,493.16623

Timestep Collection Time: 2.34285
Timestep Consumption Time: 2.42444
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.76729

Cumulative Model Updates: 154,256
Cumulative Timesteps: 1,286,553,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800.53022
Policy Entropy: 2.99428
Value Function Loss: 0.00440

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.58700
Value Function Update Magnitude: 0.50737

Collected Steps per Second: 23,277.59547
Overall Steps per Second: 10,855.63794

Timestep Collection Time: 2.14850
Timestep Consumption Time: 2.45850
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.60701

Cumulative Model Updates: 154,262
Cumulative Timesteps: 1,286,603,434

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1286603434...
Checkpoint 1286603434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,683.89674
Policy Entropy: 3.00763
Value Function Loss: 0.00398

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.50671

Collected Steps per Second: 23,012.62815
Overall Steps per Second: 10,759.49239

Timestep Collection Time: 2.17359
Timestep Consumption Time: 2.47533
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.64892

Cumulative Model Updates: 154,268
Cumulative Timesteps: 1,286,653,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,304.80563
Policy Entropy: 3.01287
Value Function Loss: 0.00389

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.57609
Value Function Update Magnitude: 0.49611

Collected Steps per Second: 23,300.99041
Overall Steps per Second: 10,819.61082

Timestep Collection Time: 2.14703
Timestep Consumption Time: 2.47679
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.62383

Cumulative Model Updates: 154,274
Cumulative Timesteps: 1,286,703,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1286703482...
Checkpoint 1286703482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.41031
Policy Entropy: 3.03287
Value Function Loss: 0.00376

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.56807
Value Function Update Magnitude: 0.50335

Collected Steps per Second: 22,991.31915
Overall Steps per Second: 10,626.61311

Timestep Collection Time: 2.17595
Timestep Consumption Time: 2.53185
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.70780

Cumulative Model Updates: 154,280
Cumulative Timesteps: 1,286,753,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,934.74421
Policy Entropy: 3.04286
Value Function Loss: 0.00402

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.57187
Value Function Update Magnitude: 0.52395

Collected Steps per Second: 23,452.77752
Overall Steps per Second: 10,928.24667

Timestep Collection Time: 2.13365
Timestep Consumption Time: 2.44531
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.57896

Cumulative Model Updates: 154,286
Cumulative Timesteps: 1,286,803,550

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1286803550...
Checkpoint 1286803550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,581.98546
Policy Entropy: 3.03826
Value Function Loss: 0.00416

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.57869
Value Function Update Magnitude: 0.51968

Collected Steps per Second: 22,749.42476
Overall Steps per Second: 10,666.10400

Timestep Collection Time: 2.19803
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.68812

Cumulative Model Updates: 154,292
Cumulative Timesteps: 1,286,853,554

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.84009
Policy Entropy: 3.02996
Value Function Loss: 0.00471

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.59043
Value Function Update Magnitude: 0.52247

Collected Steps per Second: 22,818.59459
Overall Steps per Second: 10,808.13824

Timestep Collection Time: 2.19207
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.62799

Cumulative Model Updates: 154,298
Cumulative Timesteps: 1,286,903,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1286903574...
Checkpoint 1286903574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.73469
Policy Entropy: 3.02438
Value Function Loss: 0.00460

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.60390
Value Function Update Magnitude: 0.54865

Collected Steps per Second: 22,669.56475
Overall Steps per Second: 10,715.36620

Timestep Collection Time: 2.20578
Timestep Consumption Time: 2.46079
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.66657

Cumulative Model Updates: 154,304
Cumulative Timesteps: 1,286,953,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,879.42442
Policy Entropy: 3.03141
Value Function Loss: 0.00427

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.59342
Value Function Update Magnitude: 0.54037

Collected Steps per Second: 22,729.11062
Overall Steps per Second: 10,870.73808

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.40112
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60226

Cumulative Model Updates: 154,310
Cumulative Timesteps: 1,287,003,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1287003608...
Checkpoint 1287003608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.26343
Policy Entropy: 3.00407
Value Function Loss: 0.00469

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.58741
Value Function Update Magnitude: 0.52892

Collected Steps per Second: 22,714.80089
Overall Steps per Second: 10,685.42277

Timestep Collection Time: 2.20315
Timestep Consumption Time: 2.48024
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.68339

Cumulative Model Updates: 154,316
Cumulative Timesteps: 1,287,053,652

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,064.06902
Policy Entropy: 3.00712
Value Function Loss: 0.00457

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.59281
Value Function Update Magnitude: 0.52294

Collected Steps per Second: 23,151.31827
Overall Steps per Second: 10,797.83880

Timestep Collection Time: 2.16065
Timestep Consumption Time: 2.47194
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.63259

Cumulative Model Updates: 154,322
Cumulative Timesteps: 1,287,103,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1287103674...
Checkpoint 1287103674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.33871
Policy Entropy: 3.00615
Value Function Loss: 0.00470

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.58507
Value Function Update Magnitude: 0.50292

Collected Steps per Second: 23,064.08872
Overall Steps per Second: 10,726.15660

Timestep Collection Time: 2.16822
Timestep Consumption Time: 2.49403
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.66225

Cumulative Model Updates: 154,328
Cumulative Timesteps: 1,287,153,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.82827
Policy Entropy: 3.04005
Value Function Loss: 0.00429

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.49813

Collected Steps per Second: 23,384.05565
Overall Steps per Second: 10,938.94140

Timestep Collection Time: 2.13949
Timestep Consumption Time: 2.43408
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.57357

Cumulative Model Updates: 154,334
Cumulative Timesteps: 1,287,203,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1287203712...
Checkpoint 1287203712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,333.23038
Policy Entropy: 3.01956
Value Function Loss: 0.00438

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11755
Policy Update Magnitude: 0.57994
Value Function Update Magnitude: 0.50135

Collected Steps per Second: 22,980.04026
Overall Steps per Second: 10,675.33355

Timestep Collection Time: 2.17598
Timestep Consumption Time: 2.50809
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.68407

Cumulative Model Updates: 154,340
Cumulative Timesteps: 1,287,253,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.61684
Policy Entropy: 3.02501
Value Function Loss: 0.00469

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.59178
Value Function Update Magnitude: 0.52620

Collected Steps per Second: 23,460.02199
Overall Steps per Second: 10,839.06268

Timestep Collection Time: 2.13129
Timestep Consumption Time: 2.48166
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.61294

Cumulative Model Updates: 154,346
Cumulative Timesteps: 1,287,303,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1287303716...
Checkpoint 1287303716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,482.42923
Policy Entropy: 3.01321
Value Function Loss: 0.00454

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.59491
Value Function Update Magnitude: 0.52399

Collected Steps per Second: 23,107.36854
Overall Steps per Second: 10,706.60694

Timestep Collection Time: 2.16407
Timestep Consumption Time: 2.50650
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.67057

Cumulative Model Updates: 154,352
Cumulative Timesteps: 1,287,353,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,915.18720
Policy Entropy: 3.02872
Value Function Loss: 0.00440

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.58785
Value Function Update Magnitude: 0.51120

Collected Steps per Second: 22,641.26236
Overall Steps per Second: 10,685.61225

Timestep Collection Time: 2.20853
Timestep Consumption Time: 2.47103
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.67956

Cumulative Model Updates: 154,358
Cumulative Timesteps: 1,287,403,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1287403726...
Checkpoint 1287403726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,432.66905
Policy Entropy: 3.01033
Value Function Loss: 0.00426

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.58842
Value Function Update Magnitude: 0.51282

Collected Steps per Second: 22,510.57493
Overall Steps per Second: 10,764.40396

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.64661

Cumulative Model Updates: 154,364
Cumulative Timesteps: 1,287,453,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,113.14530
Policy Entropy: 3.00244
Value Function Loss: 0.00462

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.59136
Value Function Update Magnitude: 0.52767

Collected Steps per Second: 22,870.29939
Overall Steps per Second: 10,710.28556

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.48296
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.66990

Cumulative Model Updates: 154,370
Cumulative Timesteps: 1,287,503,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1287503760...
Checkpoint 1287503760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.64752
Policy Entropy: 2.99764
Value Function Loss: 0.00446

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.59162
Value Function Update Magnitude: 0.51889

Collected Steps per Second: 22,440.57263
Overall Steps per Second: 10,590.78502

Timestep Collection Time: 2.22944
Timestep Consumption Time: 2.49447
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.72392

Cumulative Model Updates: 154,376
Cumulative Timesteps: 1,287,553,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.11012
Policy Entropy: 3.01164
Value Function Loss: 0.00455

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.58078
Value Function Update Magnitude: 0.48748

Collected Steps per Second: 23,441.37872
Overall Steps per Second: 10,757.74903

Timestep Collection Time: 2.13324
Timestep Consumption Time: 2.51513
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.64837

Cumulative Model Updates: 154,382
Cumulative Timesteps: 1,287,603,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1287603796...
Checkpoint 1287603796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.79688
Policy Entropy: 3.01306
Value Function Loss: 0.00446

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.57820
Value Function Update Magnitude: 0.46581

Collected Steps per Second: 21,920.96115
Overall Steps per Second: 10,373.85483

Timestep Collection Time: 2.28220
Timestep Consumption Time: 2.54031
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.82251

Cumulative Model Updates: 154,388
Cumulative Timesteps: 1,287,653,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,721.45194
Policy Entropy: 3.01630
Value Function Loss: 0.00439

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.57636
Value Function Update Magnitude: 0.47440

Collected Steps per Second: 23,204.33133
Overall Steps per Second: 10,749.07596

Timestep Collection Time: 2.15598
Timestep Consumption Time: 2.49819
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.65417

Cumulative Model Updates: 154,394
Cumulative Timesteps: 1,287,703,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1287703852...
Checkpoint 1287703852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,845.50588
Policy Entropy: 3.01847
Value Function Loss: 0.00414

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.57614
Value Function Update Magnitude: 0.49243

Collected Steps per Second: 23,242.39282
Overall Steps per Second: 10,692.78832

Timestep Collection Time: 2.15124
Timestep Consumption Time: 2.52481
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.67605

Cumulative Model Updates: 154,400
Cumulative Timesteps: 1,287,753,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,796.53979
Policy Entropy: 3.01737
Value Function Loss: 0.00431

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.58224
Value Function Update Magnitude: 0.50895

Collected Steps per Second: 23,461.97744
Overall Steps per Second: 10,851.72335

Timestep Collection Time: 2.13136
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.60812

Cumulative Model Updates: 154,406
Cumulative Timesteps: 1,287,803,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1287803858...
Checkpoint 1287803858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.05199
Policy Entropy: 3.01000
Value Function Loss: 0.00445

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.52486

Collected Steps per Second: 22,831.67563
Overall Steps per Second: 10,731.25234

Timestep Collection Time: 2.19038
Timestep Consumption Time: 2.46984
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.66022

Cumulative Model Updates: 154,412
Cumulative Timesteps: 1,287,853,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,819.56640
Policy Entropy: 3.00757
Value Function Loss: 0.00490

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.59670
Value Function Update Magnitude: 0.53837

Collected Steps per Second: 23,370.15849
Overall Steps per Second: 10,840.30853

Timestep Collection Time: 2.14059
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.61481

Cumulative Model Updates: 154,418
Cumulative Timesteps: 1,287,903,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1287903894...
Checkpoint 1287903894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.36652
Policy Entropy: 3.01903
Value Function Loss: 0.00456

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.59433
Value Function Update Magnitude: 0.55927

Collected Steps per Second: 22,612.47229
Overall Steps per Second: 10,629.50682

Timestep Collection Time: 2.21117
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.70389

Cumulative Model Updates: 154,424
Cumulative Timesteps: 1,287,953,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.16945
Policy Entropy: 3.03037
Value Function Loss: 0.00454

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.58275
Value Function Update Magnitude: 0.55835

Collected Steps per Second: 22,943.65781
Overall Steps per Second: 10,849.98733

Timestep Collection Time: 2.18004
Timestep Consumption Time: 2.42992
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60996

Cumulative Model Updates: 154,430
Cumulative Timesteps: 1,288,003,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1288003912...
Checkpoint 1288003912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,724.23176
Policy Entropy: 3.05427
Value Function Loss: 0.00421

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.57745
Value Function Update Magnitude: 0.54252

Collected Steps per Second: 22,216.48013
Overall Steps per Second: 10,667.88776

Timestep Collection Time: 2.25121
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.68828

Cumulative Model Updates: 154,436
Cumulative Timesteps: 1,288,053,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,022.35369
Policy Entropy: 3.05866
Value Function Loss: 0.00395

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.56993
Value Function Update Magnitude: 0.52353

Collected Steps per Second: 22,812.35145
Overall Steps per Second: 10,679.70535

Timestep Collection Time: 2.19302
Timestep Consumption Time: 2.49138
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.68440

Cumulative Model Updates: 154,442
Cumulative Timesteps: 1,288,103,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1288103954...
Checkpoint 1288103954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.97342
Policy Entropy: 3.05745
Value Function Loss: 0.00388

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.56318
Value Function Update Magnitude: 0.51079

Collected Steps per Second: 22,972.85541
Overall Steps per Second: 10,849.93147

Timestep Collection Time: 2.17718
Timestep Consumption Time: 2.43262
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.60980

Cumulative Model Updates: 154,448
Cumulative Timesteps: 1,288,153,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.92372
Policy Entropy: 3.03667
Value Function Loss: 0.00419

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.56469
Value Function Update Magnitude: 0.53677

Collected Steps per Second: 23,306.46298
Overall Steps per Second: 10,883.25905

Timestep Collection Time: 2.14550
Timestep Consumption Time: 2.44908
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.59458

Cumulative Model Updates: 154,454
Cumulative Timesteps: 1,288,203,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1288203974...
Checkpoint 1288203974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.97542
Policy Entropy: 3.02314
Value Function Loss: 0.00454

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.58223
Value Function Update Magnitude: 0.58315

Collected Steps per Second: 22,720.36809
Overall Steps per Second: 10,677.56299

Timestep Collection Time: 2.20208
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.68571

Cumulative Model Updates: 154,460
Cumulative Timesteps: 1,288,254,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.70388
Policy Entropy: 3.02019
Value Function Loss: 0.00466

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.58684
Value Function Update Magnitude: 0.57810

Collected Steps per Second: 23,429.52316
Overall Steps per Second: 10,932.58864

Timestep Collection Time: 2.13440
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.57421

Cumulative Model Updates: 154,466
Cumulative Timesteps: 1,288,304,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1288304014...
Checkpoint 1288304014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.69721
Policy Entropy: 3.03006
Value Function Loss: 0.00464

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.59073
Value Function Update Magnitude: 0.55885

Collected Steps per Second: 22,842.40272
Overall Steps per Second: 10,632.14326

Timestep Collection Time: 2.18909
Timestep Consumption Time: 2.51401
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.70310

Cumulative Model Updates: 154,472
Cumulative Timesteps: 1,288,354,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,202.86823
Policy Entropy: 3.03293
Value Function Loss: 0.00444

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.58841
Value Function Update Magnitude: 0.57076

Collected Steps per Second: 23,254.65267
Overall Steps per Second: 10,928.80247

Timestep Collection Time: 2.15080
Timestep Consumption Time: 2.42574
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.57653

Cumulative Model Updates: 154,478
Cumulative Timesteps: 1,288,404,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1288404034...
Checkpoint 1288404034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.82659
Policy Entropy: 3.03125
Value Function Loss: 0.00429

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.58403
Value Function Update Magnitude: 0.57863

Collected Steps per Second: 22,452.21485
Overall Steps per Second: 10,631.02854

Timestep Collection Time: 2.22731
Timestep Consumption Time: 2.47666
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.70397

Cumulative Model Updates: 154,484
Cumulative Timesteps: 1,288,454,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085.54203
Policy Entropy: 3.01949
Value Function Loss: 0.00406

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.57381
Value Function Update Magnitude: 0.55177

Collected Steps per Second: 22,570.71988
Overall Steps per Second: 10,825.74100

Timestep Collection Time: 2.21588
Timestep Consumption Time: 2.40403
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.61991

Cumulative Model Updates: 154,490
Cumulative Timesteps: 1,288,504,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1288504056...
Checkpoint 1288504056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,545.34071
Policy Entropy: 3.02759
Value Function Loss: 0.00441

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.57960
Value Function Update Magnitude: 0.53053

Collected Steps per Second: 22,458.85683
Overall Steps per Second: 10,731.68680

Timestep Collection Time: 2.22683
Timestep Consumption Time: 2.43339
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.66022

Cumulative Model Updates: 154,496
Cumulative Timesteps: 1,288,554,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,375.05430
Policy Entropy: 3.02052
Value Function Loss: 0.00466

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.58625
Value Function Update Magnitude: 0.53163

Collected Steps per Second: 22,884.08167
Overall Steps per Second: 10,826.16284

Timestep Collection Time: 2.18510
Timestep Consumption Time: 2.43371
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61881

Cumulative Model Updates: 154,502
Cumulative Timesteps: 1,288,604,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1288604072...
Checkpoint 1288604072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,840.29193
Policy Entropy: 3.02397
Value Function Loss: 0.00451

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.58757
Value Function Update Magnitude: 0.53048

Collected Steps per Second: 22,901.20000
Overall Steps per Second: 10,721.89099

Timestep Collection Time: 2.18355
Timestep Consumption Time: 2.48036
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.66392

Cumulative Model Updates: 154,508
Cumulative Timesteps: 1,288,654,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911.23114
Policy Entropy: 3.01024
Value Function Loss: 0.00432

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.58480
Value Function Update Magnitude: 0.51954

Collected Steps per Second: 23,219.40096
Overall Steps per Second: 10,826.89337

Timestep Collection Time: 2.15372
Timestep Consumption Time: 2.46515
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61887

Cumulative Model Updates: 154,514
Cumulative Timesteps: 1,288,704,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1288704086...
Checkpoint 1288704086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.80747
Policy Entropy: 3.02275
Value Function Loss: 0.00431

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.58725
Value Function Update Magnitude: 0.52672

Collected Steps per Second: 23,191.08559
Overall Steps per Second: 10,713.23987

Timestep Collection Time: 2.15678
Timestep Consumption Time: 2.51203
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.66880

Cumulative Model Updates: 154,520
Cumulative Timesteps: 1,288,754,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.52142
Policy Entropy: 3.02171
Value Function Loss: 0.00466

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.59534
Value Function Update Magnitude: 0.52448

Collected Steps per Second: 23,371.45808
Overall Steps per Second: 10,948.34883

Timestep Collection Time: 2.13970
Timestep Consumption Time: 2.42793
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.56763

Cumulative Model Updates: 154,526
Cumulative Timesteps: 1,288,804,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1288804112...
Checkpoint 1288804112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210.36164
Policy Entropy: 3.01723
Value Function Loss: 0.00477

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.60129
Value Function Update Magnitude: 0.53501

Collected Steps per Second: 23,097.49047
Overall Steps per Second: 10,759.41058

Timestep Collection Time: 2.16586
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.64951

Cumulative Model Updates: 154,532
Cumulative Timesteps: 1,288,854,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,392.54235
Policy Entropy: 3.02762
Value Function Loss: 0.00461

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.59422
Value Function Update Magnitude: 0.55623

Collected Steps per Second: 23,199.14783
Overall Steps per Second: 10,733.95775

Timestep Collection Time: 2.15629
Timestep Consumption Time: 2.50406
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.66035

Cumulative Model Updates: 154,538
Cumulative Timesteps: 1,288,904,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1288904162...
Checkpoint 1288904162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,824.39488
Policy Entropy: 3.00718
Value Function Loss: 0.00402

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.58373
Value Function Update Magnitude: 0.53711

Collected Steps per Second: 22,831.50679
Overall Steps per Second: 10,633.85838

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.51241
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.70271

Cumulative Model Updates: 154,544
Cumulative Timesteps: 1,288,954,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,050.43386
Policy Entropy: 3.00782
Value Function Loss: 0.00434

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.60024
Value Function Update Magnitude: 0.54229

Collected Steps per Second: 22,794.15122
Overall Steps per Second: 10,688.39242

Timestep Collection Time: 2.19469
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.68040

Cumulative Model Updates: 154,550
Cumulative Timesteps: 1,289,004,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1289004196...
Checkpoint 1289004196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.87446
Policy Entropy: 3.00927
Value Function Loss: 0.00463

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.61020
Value Function Update Magnitude: 0.57893

Collected Steps per Second: 22,883.18529
Overall Steps per Second: 10,880.14681

Timestep Collection Time: 2.18615
Timestep Consumption Time: 2.41177
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.59792

Cumulative Model Updates: 154,556
Cumulative Timesteps: 1,289,054,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.15783
Policy Entropy: 3.03579
Value Function Loss: 0.00464

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.60657
Value Function Update Magnitude: 0.59849

Collected Steps per Second: 23,232.95231
Overall Steps per Second: 10,856.52862

Timestep Collection Time: 2.15289
Timestep Consumption Time: 2.45429
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60718

Cumulative Model Updates: 154,562
Cumulative Timesteps: 1,289,104,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1289104240...
Checkpoint 1289104240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.80304
Policy Entropy: 3.04384
Value Function Loss: 0.00448

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.60200
Value Function Update Magnitude: 0.58720

Collected Steps per Second: 22,931.81882
Overall Steps per Second: 10,709.07753

Timestep Collection Time: 2.18125
Timestep Consumption Time: 2.48956
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.67080

Cumulative Model Updates: 154,568
Cumulative Timesteps: 1,289,154,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.99413
Policy Entropy: 3.03712
Value Function Loss: 0.00478

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.59502
Value Function Update Magnitude: 0.57624

Collected Steps per Second: 23,209.95001
Overall Steps per Second: 10,921.48381

Timestep Collection Time: 2.15425
Timestep Consumption Time: 2.42388
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.57813

Cumulative Model Updates: 154,574
Cumulative Timesteps: 1,289,204,260

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1289204260...
Checkpoint 1289204260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.91945
Policy Entropy: 3.02935
Value Function Loss: 0.00466

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.58864
Value Function Update Magnitude: 0.56570

Collected Steps per Second: 22,846.46106
Overall Steps per Second: 10,625.67304

Timestep Collection Time: 2.18861
Timestep Consumption Time: 2.51716
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.70577

Cumulative Model Updates: 154,580
Cumulative Timesteps: 1,289,254,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.92034
Policy Entropy: 3.02079
Value Function Loss: 0.00483

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.58954
Value Function Update Magnitude: 0.56525

Collected Steps per Second: 23,245.00513
Overall Steps per Second: 10,850.03323

Timestep Collection Time: 2.15177
Timestep Consumption Time: 2.45817
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.60994

Cumulative Model Updates: 154,586
Cumulative Timesteps: 1,289,304,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1289304280...
Checkpoint 1289304280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.62545
Policy Entropy: 3.01867
Value Function Loss: 0.00445

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.59254
Value Function Update Magnitude: 0.56938

Collected Steps per Second: 22,755.30648
Overall Steps per Second: 10,706.76760

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.47354
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.67162

Cumulative Model Updates: 154,592
Cumulative Timesteps: 1,289,354,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,260.69881
Policy Entropy: 3.04050
Value Function Loss: 0.00421

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.58504
Value Function Update Magnitude: 0.56602

Collected Steps per Second: 22,865.53542
Overall Steps per Second: 10,832.41357

Timestep Collection Time: 2.18670
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.61578

Cumulative Model Updates: 154,598
Cumulative Timesteps: 1,289,404,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1289404298...
Checkpoint 1289404298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,705.47111
Policy Entropy: 3.04172
Value Function Loss: 0.00386

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.57523
Value Function Update Magnitude: 0.54707

Collected Steps per Second: 22,335.50011
Overall Steps per Second: 10,745.09718

Timestep Collection Time: 2.23904
Timestep Consumption Time: 2.41518
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.65422

Cumulative Model Updates: 154,604
Cumulative Timesteps: 1,289,454,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,101.08356
Policy Entropy: 3.05373
Value Function Loss: 0.00379

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.57799
Value Function Update Magnitude: 0.55372

Collected Steps per Second: 22,984.75284
Overall Steps per Second: 10,828.12985

Timestep Collection Time: 2.17640
Timestep Consumption Time: 2.44342
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61982

Cumulative Model Updates: 154,610
Cumulative Timesteps: 1,289,504,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1289504332...
Checkpoint 1289504332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,307.72328
Policy Entropy: 3.04712
Value Function Loss: 0.00385

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.57683
Value Function Update Magnitude: 0.55490

Collected Steps per Second: 22,682.45273
Overall Steps per Second: 10,700.96724

Timestep Collection Time: 2.20620
Timestep Consumption Time: 2.47020
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.67640

Cumulative Model Updates: 154,616
Cumulative Timesteps: 1,289,554,374

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,092.98174
Policy Entropy: 3.04287
Value Function Loss: 0.00427

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.58817
Value Function Update Magnitude: 0.57033

Collected Steps per Second: 23,435.07271
Overall Steps per Second: 10,888.62252

Timestep Collection Time: 2.13458
Timestep Consumption Time: 2.45957
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.59415

Cumulative Model Updates: 154,622
Cumulative Timesteps: 1,289,604,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1289604398...
Checkpoint 1289604398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.45265
Policy Entropy: 3.04944
Value Function Loss: 0.00466

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.60566
Value Function Update Magnitude: 0.60650

Collected Steps per Second: 23,125.13925
Overall Steps per Second: 10,696.50743

Timestep Collection Time: 2.16241
Timestep Consumption Time: 2.51258
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.67498

Cumulative Model Updates: 154,628
Cumulative Timesteps: 1,289,654,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.77833
Policy Entropy: 3.03688
Value Function Loss: 0.00483

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.60438
Value Function Update Magnitude: 0.61085

Collected Steps per Second: 23,359.50725
Overall Steps per Second: 10,882.26891

Timestep Collection Time: 2.14088
Timestep Consumption Time: 2.45466
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.59555

Cumulative Model Updates: 154,634
Cumulative Timesteps: 1,289,704,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1289704414...
Checkpoint 1289704414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.87548
Policy Entropy: 3.04099
Value Function Loss: 0.00468

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.58412
Value Function Update Magnitude: 0.57972

Collected Steps per Second: 22,836.99599
Overall Steps per Second: 10,753.63581

Timestep Collection Time: 2.19066
Timestep Consumption Time: 2.46154
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.65219

Cumulative Model Updates: 154,640
Cumulative Timesteps: 1,289,754,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.20746
Policy Entropy: 3.02891
Value Function Loss: 0.00488

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.58586
Value Function Update Magnitude: 0.55334

Collected Steps per Second: 23,451.10171
Overall Steps per Second: 10,765.36855

Timestep Collection Time: 2.13312
Timestep Consumption Time: 2.51363
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.64675

Cumulative Model Updates: 154,646
Cumulative Timesteps: 1,289,804,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1289804466...
Checkpoint 1289804466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.54996
Policy Entropy: 3.02373
Value Function Loss: 0.00485

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.58735
Value Function Update Magnitude: 0.56547

Collected Steps per Second: 22,600.72145
Overall Steps per Second: 10,676.48703

Timestep Collection Time: 2.21303
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.68469

Cumulative Model Updates: 154,652
Cumulative Timesteps: 1,289,854,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.02465
Policy Entropy: 3.02229
Value Function Loss: 0.00452

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.57929
Value Function Update Magnitude: 0.57130

Collected Steps per Second: 23,037.34704
Overall Steps per Second: 10,854.56963

Timestep Collection Time: 2.17039
Timestep Consumption Time: 2.43597
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.60635

Cumulative Model Updates: 154,658
Cumulative Timesteps: 1,289,904,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1289904482...
Checkpoint 1289904482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,441.39662
Policy Entropy: 3.02859
Value Function Loss: 0.00419

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.58015
Value Function Update Magnitude: 0.56634

Collected Steps per Second: 22,657.46430
Overall Steps per Second: 10,716.69327

Timestep Collection Time: 2.20793
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.66804

Cumulative Model Updates: 154,664
Cumulative Timesteps: 1,289,954,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.73444
Policy Entropy: 3.02900
Value Function Loss: 0.00441

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.59309
Value Function Update Magnitude: 0.58256

Collected Steps per Second: 22,824.06600
Overall Steps per Second: 10,899.89174

Timestep Collection Time: 2.19085
Timestep Consumption Time: 2.39672
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.58757

Cumulative Model Updates: 154,670
Cumulative Timesteps: 1,290,004,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1290004512...
Checkpoint 1290004512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.78418
Policy Entropy: 3.02414
Value Function Loss: 0.00453

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.59249
Value Function Update Magnitude: 0.60032

Collected Steps per Second: 22,339.81036
Overall Steps per Second: 10,634.04194

Timestep Collection Time: 2.23860
Timestep Consumption Time: 2.46422
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.70282

Cumulative Model Updates: 154,676
Cumulative Timesteps: 1,290,054,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,240.16972
Policy Entropy: 3.00230
Value Function Loss: 0.00451

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.58392
Value Function Update Magnitude: 0.59868

Collected Steps per Second: 23,472.15716
Overall Steps per Second: 10,881.23304

Timestep Collection Time: 2.13112
Timestep Consumption Time: 2.46597
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.59709

Cumulative Model Updates: 154,682
Cumulative Timesteps: 1,290,104,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1290104544...
Checkpoint 1290104544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,784.42477
Policy Entropy: 3.00247
Value Function Loss: 0.00407

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.58404
Value Function Update Magnitude: 0.57101

Collected Steps per Second: 23,141.81964
Overall Steps per Second: 10,725.93234

Timestep Collection Time: 2.16137
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.66328

Cumulative Model Updates: 154,688
Cumulative Timesteps: 1,290,154,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,040.96982
Policy Entropy: 2.98963
Value Function Loss: 0.00394

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.57542
Value Function Update Magnitude: 0.53482

Collected Steps per Second: 23,516.33545
Overall Steps per Second: 10,855.31447

Timestep Collection Time: 2.12652
Timestep Consumption Time: 2.48025
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.60678

Cumulative Model Updates: 154,694
Cumulative Timesteps: 1,290,204,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1290204570...
Checkpoint 1290204570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.54202
Policy Entropy: 2.99276
Value Function Loss: 0.00424

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.56868
Value Function Update Magnitude: 0.52688

Collected Steps per Second: 23,070.85880
Overall Steps per Second: 10,834.01300

Timestep Collection Time: 2.16793
Timestep Consumption Time: 2.44864
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.61657

Cumulative Model Updates: 154,700
Cumulative Timesteps: 1,290,254,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,443.62595
Policy Entropy: 2.99099
Value Function Loss: 0.00428

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.57267
Value Function Update Magnitude: 0.53328

Collected Steps per Second: 23,483.43980
Overall Steps per Second: 10,889.78783

Timestep Collection Time: 2.13035
Timestep Consumption Time: 2.46368
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.59403

Cumulative Model Updates: 154,706
Cumulative Timesteps: 1,290,304,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1290304614...
Checkpoint 1290304614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867.47492
Policy Entropy: 2.99842
Value Function Loss: 0.00430

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.56808
Value Function Update Magnitude: 0.51868

Collected Steps per Second: 22,938.31464
Overall Steps per Second: 10,913.58225

Timestep Collection Time: 2.18063
Timestep Consumption Time: 2.40265
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.58328

Cumulative Model Updates: 154,712
Cumulative Timesteps: 1,290,354,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.91284
Policy Entropy: 3.02019
Value Function Loss: 0.00399

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.56752
Value Function Update Magnitude: 0.51351

Collected Steps per Second: 22,216.55536
Overall Steps per Second: 10,467.18695

Timestep Collection Time: 2.25129
Timestep Consumption Time: 2.52707
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.77836

Cumulative Model Updates: 154,718
Cumulative Timesteps: 1,290,404,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1290404650...
Checkpoint 1290404650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,209.82217
Policy Entropy: 3.02982
Value Function Loss: 0.00377

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11774
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.50925

Collected Steps per Second: 22,300.98963
Overall Steps per Second: 10,638.78447

Timestep Collection Time: 2.24340
Timestep Consumption Time: 2.45921
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.70260

Cumulative Model Updates: 154,724
Cumulative Timesteps: 1,290,454,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.75452
Policy Entropy: 3.01862
Value Function Loss: 0.00414

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.56019
Value Function Update Magnitude: 0.51733

Collected Steps per Second: 22,863.93849
Overall Steps per Second: 10,819.58146

Timestep Collection Time: 2.18729
Timestep Consumption Time: 2.43489
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.62218

Cumulative Model Updates: 154,730
Cumulative Timesteps: 1,290,504,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1290504690...
Checkpoint 1290504690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298.58760
Policy Entropy: 3.00579
Value Function Loss: 0.00416

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.57575
Value Function Update Magnitude: 0.52480

Collected Steps per Second: 22,677.96018
Overall Steps per Second: 10,703.45372

Timestep Collection Time: 2.20514
Timestep Consumption Time: 2.46700
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.67214

Cumulative Model Updates: 154,736
Cumulative Timesteps: 1,290,554,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.16500
Policy Entropy: 3.00079
Value Function Loss: 0.00407

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.51013

Collected Steps per Second: 23,773.15815
Overall Steps per Second: 10,912.62518

Timestep Collection Time: 2.10363
Timestep Consumption Time: 2.47913
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.58277

Cumulative Model Updates: 154,742
Cumulative Timesteps: 1,290,604,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1290604708...
Checkpoint 1290604708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.19775
Policy Entropy: 3.02025
Value Function Loss: 0.00389

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.56831
Value Function Update Magnitude: 0.51283

Collected Steps per Second: 22,808.58878
Overall Steps per Second: 10,663.72918

Timestep Collection Time: 2.19260
Timestep Consumption Time: 2.49713
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.68973

Cumulative Model Updates: 154,748
Cumulative Timesteps: 1,290,654,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,464.42431
Policy Entropy: 3.02075
Value Function Loss: 0.00364

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11140
Policy Update Magnitude: 0.55760
Value Function Update Magnitude: 0.50761

Collected Steps per Second: 23,417.03569
Overall Steps per Second: 10,883.65256

Timestep Collection Time: 2.13554
Timestep Consumption Time: 2.45924
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.59478

Cumulative Model Updates: 154,754
Cumulative Timesteps: 1,290,704,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1290704726...
Checkpoint 1290704726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,272.20873
Policy Entropy: 3.02665
Value Function Loss: 0.00383

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.55598
Value Function Update Magnitude: 0.50538

Collected Steps per Second: 23,099.33031
Overall Steps per Second: 10,714.93578

Timestep Collection Time: 2.16465
Timestep Consumption Time: 2.50192
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.66657

Cumulative Model Updates: 154,760
Cumulative Timesteps: 1,290,754,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,356.10328
Policy Entropy: 3.01318
Value Function Loss: 0.00384

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.55438
Value Function Update Magnitude: 0.52012

Collected Steps per Second: 23,426.57867
Overall Steps per Second: 10,855.87147

Timestep Collection Time: 2.13458
Timestep Consumption Time: 2.47177
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.60636

Cumulative Model Updates: 154,766
Cumulative Timesteps: 1,290,804,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1290804734...
Checkpoint 1290804734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,732.63816
Policy Entropy: 3.00496
Value Function Loss: 0.00392

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.51465

Collected Steps per Second: 22,903.35655
Overall Steps per Second: 10,624.86581

Timestep Collection Time: 2.18335
Timestep Consumption Time: 2.52316
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.70651

Cumulative Model Updates: 154,772
Cumulative Timesteps: 1,290,854,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970.71750
Policy Entropy: 2.99729
Value Function Loss: 0.00390

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.57105
Value Function Update Magnitude: 0.50443

Collected Steps per Second: 22,744.04224
Overall Steps per Second: 10,798.95494

Timestep Collection Time: 2.19961
Timestep Consumption Time: 2.43306
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.63267

Cumulative Model Updates: 154,778
Cumulative Timesteps: 1,290,904,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1290904768...
Checkpoint 1290904768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.30338
Policy Entropy: 3.00294
Value Function Loss: 0.00419

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.57388
Value Function Update Magnitude: 0.51013

Collected Steps per Second: 22,681.10713
Overall Steps per Second: 10,783.83043

Timestep Collection Time: 2.20501
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.63768

Cumulative Model Updates: 154,784
Cumulative Timesteps: 1,290,954,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,067.86912
Policy Entropy: 3.01324
Value Function Loss: 0.00444

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.58133
Value Function Update Magnitude: 0.51223

Collected Steps per Second: 22,895.52430
Overall Steps per Second: 10,865.57197

Timestep Collection Time: 2.18427
Timestep Consumption Time: 2.41834
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.60261

Cumulative Model Updates: 154,790
Cumulative Timesteps: 1,291,004,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1291004790...
Checkpoint 1291004790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.02395
Policy Entropy: 3.01595
Value Function Loss: 0.00472

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.58639
Value Function Update Magnitude: 0.50202

Collected Steps per Second: 22,556.02620
Overall Steps per Second: 10,641.09389

Timestep Collection Time: 2.21786
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.70121

Cumulative Model Updates: 154,796
Cumulative Timesteps: 1,291,054,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,321.11163
Policy Entropy: 3.02275
Value Function Loss: 0.00480

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.58037
Value Function Update Magnitude: 0.50534

Collected Steps per Second: 23,201.67099
Overall Steps per Second: 10,805.73798

Timestep Collection Time: 2.15528
Timestep Consumption Time: 2.47245
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.62773

Cumulative Model Updates: 154,802
Cumulative Timesteps: 1,291,104,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1291104822...
Checkpoint 1291104822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.75581
Policy Entropy: 3.03086
Value Function Loss: 0.00461

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.57349
Value Function Update Magnitude: 0.51070

Collected Steps per Second: 23,007.59771
Overall Steps per Second: 10,673.40727

Timestep Collection Time: 2.17363
Timestep Consumption Time: 2.51185
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.68548

Cumulative Model Updates: 154,808
Cumulative Timesteps: 1,291,154,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,337.38150
Policy Entropy: 3.03437
Value Function Loss: 0.00447

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.57909
Value Function Update Magnitude: 0.53118

Collected Steps per Second: 23,248.88498
Overall Steps per Second: 10,908.12770

Timestep Collection Time: 2.15073
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.58392

Cumulative Model Updates: 154,814
Cumulative Timesteps: 1,291,204,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1291204834...
Checkpoint 1291204834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.64876
Policy Entropy: 3.01684
Value Function Loss: 0.00446

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.59696
Value Function Update Magnitude: 0.56610

Collected Steps per Second: 22,932.96985
Overall Steps per Second: 10,728.45838

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.48103
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.66199

Cumulative Model Updates: 154,820
Cumulative Timesteps: 1,291,254,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,734.49361
Policy Entropy: 3.01194
Value Function Loss: 0.00426

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.60378
Value Function Update Magnitude: 0.56510

Collected Steps per Second: 23,344.80889
Overall Steps per Second: 10,910.95142

Timestep Collection Time: 2.14206
Timestep Consumption Time: 2.44104
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.58310

Cumulative Model Updates: 154,826
Cumulative Timesteps: 1,291,304,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1291304856...
Checkpoint 1291304856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.91462
Policy Entropy: 2.99296
Value Function Loss: 0.00439

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.59628
Value Function Update Magnitude: 0.55041

Collected Steps per Second: 22,833.68163
Overall Steps per Second: 10,627.89874

Timestep Collection Time: 2.18992
Timestep Consumption Time: 2.51505
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.70498

Cumulative Model Updates: 154,832
Cumulative Timesteps: 1,291,354,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,182.32053
Policy Entropy: 2.99636
Value Function Loss: 0.00428

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.58985
Value Function Update Magnitude: 0.54201

Collected Steps per Second: 22,918.83138
Overall Steps per Second: 10,825.40662

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.43744
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.61932

Cumulative Model Updates: 154,838
Cumulative Timesteps: 1,291,404,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1291404866...
Checkpoint 1291404866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.09298
Policy Entropy: 2.99865
Value Function Loss: 0.00443

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.52621

Collected Steps per Second: 22,702.36595
Overall Steps per Second: 10,707.31776

Timestep Collection Time: 2.20294
Timestep Consumption Time: 2.46788
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.67082

Cumulative Model Updates: 154,844
Cumulative Timesteps: 1,291,454,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,625.33291
Policy Entropy: 3.00020
Value Function Loss: 0.00418

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.50661

Collected Steps per Second: 22,909.49801
Overall Steps per Second: 10,802.57432

Timestep Collection Time: 2.18407
Timestep Consumption Time: 2.44779
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.63186

Cumulative Model Updates: 154,850
Cumulative Timesteps: 1,291,504,914

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1291504914...
Checkpoint 1291504914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,028.81515
Policy Entropy: 2.98645
Value Function Loss: 0.00405

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.56998
Value Function Update Magnitude: 0.49471

Collected Steps per Second: 22,930.35465
Overall Steps per Second: 10,792.68847

Timestep Collection Time: 2.18148
Timestep Consumption Time: 2.45333
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.63480

Cumulative Model Updates: 154,856
Cumulative Timesteps: 1,291,554,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,777.98505
Policy Entropy: 2.98612
Value Function Loss: 0.00367

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.46869

Collected Steps per Second: 23,430.31989
Overall Steps per Second: 10,715.68058

Timestep Collection Time: 2.13458
Timestep Consumption Time: 2.53278
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.66737

Cumulative Model Updates: 154,862
Cumulative Timesteps: 1,291,604,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1291604950...
Checkpoint 1291604950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,843.50934
Policy Entropy: 2.97847
Value Function Loss: 0.00409

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.56968
Value Function Update Magnitude: 0.48511

Collected Steps per Second: 22,762.52031
Overall Steps per Second: 10,790.67639

Timestep Collection Time: 2.19712
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.63474

Cumulative Model Updates: 154,868
Cumulative Timesteps: 1,291,654,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.80758
Policy Entropy: 2.98796
Value Function Loss: 0.00443

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.59434
Value Function Update Magnitude: 0.52473

Collected Steps per Second: 23,350.66387
Overall Steps per Second: 10,946.82652

Timestep Collection Time: 2.14204
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.56918

Cumulative Model Updates: 154,874
Cumulative Timesteps: 1,291,704,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1291704980...
Checkpoint 1291704980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,021.24990
Policy Entropy: 2.98624
Value Function Loss: 0.00434

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.58647
Value Function Update Magnitude: 0.55059

Collected Steps per Second: 22,971.96303
Overall Steps per Second: 10,681.72059

Timestep Collection Time: 2.17674
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.68127

Cumulative Model Updates: 154,880
Cumulative Timesteps: 1,291,754,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,769.14538
Policy Entropy: 2.99696
Value Function Loss: 0.00428

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.57774
Value Function Update Magnitude: 0.54224

Collected Steps per Second: 23,251.76523
Overall Steps per Second: 10,850.99687

Timestep Collection Time: 2.15055
Timestep Consumption Time: 2.45769
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.60824

Cumulative Model Updates: 154,886
Cumulative Timesteps: 1,291,804,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1291804988...
Checkpoint 1291804988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,588.37555
Policy Entropy: 3.00273
Value Function Loss: 0.00416

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.57155
Value Function Update Magnitude: 0.53372

Collected Steps per Second: 22,524.54458
Overall Steps per Second: 10,616.11402

Timestep Collection Time: 2.21989
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.71001

Cumulative Model Updates: 154,892
Cumulative Timesteps: 1,291,854,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,985.75394
Policy Entropy: 3.00815
Value Function Loss: 0.00393

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.50301

Collected Steps per Second: 22,963.66226
Overall Steps per Second: 10,838.32573

Timestep Collection Time: 2.17805
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61473

Cumulative Model Updates: 154,898
Cumulative Timesteps: 1,291,905,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1291905006...
Checkpoint 1291905006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,411.22251
Policy Entropy: 3.01236
Value Function Loss: 0.00409

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.56762
Value Function Update Magnitude: 0.49741

Collected Steps per Second: 22,606.34542
Overall Steps per Second: 10,785.39452

Timestep Collection Time: 2.21292
Timestep Consumption Time: 2.42539
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.63831

Cumulative Model Updates: 154,904
Cumulative Timesteps: 1,291,955,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.75610
Policy Entropy: 3.00791
Value Function Loss: 0.00455

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.53844

Collected Steps per Second: 23,404.12382
Overall Steps per Second: 10,881.31755

Timestep Collection Time: 2.13740
Timestep Consumption Time: 2.45984
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.59724

Cumulative Model Updates: 154,910
Cumulative Timesteps: 1,292,005,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1292005056...
Checkpoint 1292005056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.05757
Policy Entropy: 3.01247
Value Function Loss: 0.00492

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.58612
Value Function Update Magnitude: 0.59571

Collected Steps per Second: 22,987.06814
Overall Steps per Second: 10,778.30371

Timestep Collection Time: 2.17635
Timestep Consumption Time: 2.46519
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.64155

Cumulative Model Updates: 154,916
Cumulative Timesteps: 1,292,055,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,501.95222
Policy Entropy: 3.00826
Value Function Loss: 0.00473

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.58320
Value Function Update Magnitude: 0.60564

Collected Steps per Second: 23,627.50256
Overall Steps per Second: 10,925.51325

Timestep Collection Time: 2.11626
Timestep Consumption Time: 2.46036
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.57663

Cumulative Model Updates: 154,922
Cumulative Timesteps: 1,292,105,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1292105086...
Checkpoint 1292105086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,615.02387
Policy Entropy: 3.01526
Value Function Loss: 0.00427

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.58228
Value Function Update Magnitude: 0.58516

Collected Steps per Second: 23,332.15826
Overall Steps per Second: 10,950.77107

Timestep Collection Time: 2.14314
Timestep Consumption Time: 2.42312
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.56625

Cumulative Model Updates: 154,928
Cumulative Timesteps: 1,292,155,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.01427
Policy Entropy: 2.99218
Value Function Loss: 0.00441

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.59386
Value Function Update Magnitude: 0.58262

Collected Steps per Second: 23,681.96443
Overall Steps per Second: 10,858.53586

Timestep Collection Time: 2.11173
Timestep Consumption Time: 2.49386
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.60559

Cumulative Model Updates: 154,934
Cumulative Timesteps: 1,292,205,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1292205100...
Checkpoint 1292205100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,745.42217
Policy Entropy: 3.00784
Value Function Loss: 0.00414

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.59029
Value Function Update Magnitude: 0.58619

Collected Steps per Second: 22,969.17059
Overall Steps per Second: 10,677.11855

Timestep Collection Time: 2.17744
Timestep Consumption Time: 2.50678
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.68422

Cumulative Model Updates: 154,940
Cumulative Timesteps: 1,292,255,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.15142
Policy Entropy: 3.01136
Value Function Loss: 0.00372

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.56367
Value Function Update Magnitude: 0.55754

Collected Steps per Second: 22,690.21232
Overall Steps per Second: 10,672.11562

Timestep Collection Time: 2.20439
Timestep Consumption Time: 2.48241
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.68679

Cumulative Model Updates: 154,946
Cumulative Timesteps: 1,292,305,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1292305132...
Checkpoint 1292305132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.41545
Policy Entropy: 3.03270
Value Function Loss: 0.00389

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.52857

Collected Steps per Second: 21,897.18911
Overall Steps per Second: 10,450.99492

Timestep Collection Time: 2.28340
Timestep Consumption Time: 2.50084
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.78423

Cumulative Model Updates: 154,952
Cumulative Timesteps: 1,292,355,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,089.06621
Policy Entropy: 3.01950
Value Function Loss: 0.00439

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.56946
Value Function Update Magnitude: 0.54965

Collected Steps per Second: 22,723.31497
Overall Steps per Second: 10,833.16213

Timestep Collection Time: 2.20109
Timestep Consumption Time: 2.41585
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.61693

Cumulative Model Updates: 154,958
Cumulative Timesteps: 1,292,405,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1292405148...
Checkpoint 1292405148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439.96865
Policy Entropy: 3.01411
Value Function Loss: 0.00478

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.58745
Value Function Update Magnitude: 0.59125

Collected Steps per Second: 22,485.12068
Overall Steps per Second: 10,685.66127

Timestep Collection Time: 2.22396
Timestep Consumption Time: 2.45577
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.67973

Cumulative Model Updates: 154,964
Cumulative Timesteps: 1,292,455,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.52144
Policy Entropy: 3.00169
Value Function Loss: 0.00459

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.59454
Value Function Update Magnitude: 0.59247

Collected Steps per Second: 23,336.75696
Overall Steps per Second: 10,843.69707

Timestep Collection Time: 2.14383
Timestep Consumption Time: 2.46991
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.61374

Cumulative Model Updates: 154,970
Cumulative Timesteps: 1,292,505,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1292505184...
Checkpoint 1292505184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,563.56712
Policy Entropy: 2.99894
Value Function Loss: 0.00442

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.58447
Value Function Update Magnitude: 0.55100

Collected Steps per Second: 23,004.43980
Overall Steps per Second: 10,661.09441

Timestep Collection Time: 2.17462
Timestep Consumption Time: 2.51777
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.69239

Cumulative Model Updates: 154,976
Cumulative Timesteps: 1,292,555,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,938.01409
Policy Entropy: 3.00772
Value Function Loss: 0.00454

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.57704
Value Function Update Magnitude: 0.53259

Collected Steps per Second: 23,170.80075
Overall Steps per Second: 10,893.01652

Timestep Collection Time: 2.15841
Timestep Consumption Time: 2.43279
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.59120

Cumulative Model Updates: 154,982
Cumulative Timesteps: 1,292,605,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1292605222...
Checkpoint 1292605222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.23293
Policy Entropy: 3.00432
Value Function Loss: 0.00449

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.58535
Value Function Update Magnitude: 0.54335

Collected Steps per Second: 23,035.70963
Overall Steps per Second: 10,719.18787

Timestep Collection Time: 2.17185
Timestep Consumption Time: 2.49549
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.66733

Cumulative Model Updates: 154,988
Cumulative Timesteps: 1,292,655,252

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.21893
Policy Entropy: 2.99049
Value Function Loss: 0.00471

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.59378
Value Function Update Magnitude: 0.55756

Collected Steps per Second: 23,136.56747
Overall Steps per Second: 10,844.66545

Timestep Collection Time: 2.16117
Timestep Consumption Time: 2.44958
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.61075

Cumulative Model Updates: 154,994
Cumulative Timesteps: 1,292,705,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1292705254...
Checkpoint 1292705254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.90081
Policy Entropy: 2.99385
Value Function Loss: 0.00486

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11862
Policy Update Magnitude: 0.59933
Value Function Update Magnitude: 0.55919

Collected Steps per Second: 22,739.54097
Overall Steps per Second: 10,676.86204

Timestep Collection Time: 2.19969
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.68490

Cumulative Model Updates: 155,000
Cumulative Timesteps: 1,292,755,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.50074
Policy Entropy: 3.01650
Value Function Loss: 0.00472

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.59118
Value Function Update Magnitude: 0.54633

Collected Steps per Second: 23,291.94752
Overall Steps per Second: 10,924.23831

Timestep Collection Time: 2.14727
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57826

Cumulative Model Updates: 155,006
Cumulative Timesteps: 1,292,805,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1292805288...
Checkpoint 1292805288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.63973
Policy Entropy: 3.03860
Value Function Loss: 0.00460

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.52331

Collected Steps per Second: 22,676.81437
Overall Steps per Second: 10,606.15744

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.71594

Cumulative Model Updates: 155,012
Cumulative Timesteps: 1,292,855,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.73911
Policy Entropy: 3.02351
Value Function Loss: 0.00470

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.57883
Value Function Update Magnitude: 0.51561

Collected Steps per Second: 23,035.13558
Overall Steps per Second: 10,838.81927

Timestep Collection Time: 2.17181
Timestep Consumption Time: 2.44382
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61563

Cumulative Model Updates: 155,018
Cumulative Timesteps: 1,292,905,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1292905334...
Checkpoint 1292905334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,281.01138
Policy Entropy: 3.01447
Value Function Loss: 0.00466

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.58264
Value Function Update Magnitude: 0.50842

Collected Steps per Second: 22,550.60910
Overall Steps per Second: 10,713.05812

Timestep Collection Time: 2.21732
Timestep Consumption Time: 2.45006
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.66739

Cumulative Model Updates: 155,024
Cumulative Timesteps: 1,292,955,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.81224
Policy Entropy: 3.01513
Value Function Loss: 0.00447

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.50044

Collected Steps per Second: 23,006.60990
Overall Steps per Second: 10,795.87575

Timestep Collection Time: 2.17338
Timestep Consumption Time: 2.45821
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.63158

Cumulative Model Updates: 155,030
Cumulative Timesteps: 1,293,005,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1293005338...
Checkpoint 1293005338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,404.11675
Policy Entropy: 3.01319
Value Function Loss: 0.00448

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.59110
Value Function Update Magnitude: 0.50141

Collected Steps per Second: 22,732.12803
Overall Steps per Second: 10,714.28434

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.46822
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.66872

Cumulative Model Updates: 155,036
Cumulative Timesteps: 1,293,055,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.13472
Policy Entropy: 2.99423
Value Function Loss: 0.00434

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.59578
Value Function Update Magnitude: 0.51283

Collected Steps per Second: 23,360.70284
Overall Steps per Second: 10,906.45387

Timestep Collection Time: 2.14120
Timestep Consumption Time: 2.44507
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.58628

Cumulative Model Updates: 155,042
Cumulative Timesteps: 1,293,105,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1293105380...
Checkpoint 1293105380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,070.80092
Policy Entropy: 2.98527
Value Function Loss: 0.00469

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.60142
Value Function Update Magnitude: 0.52754

Collected Steps per Second: 23,012.18577
Overall Steps per Second: 10,671.12143

Timestep Collection Time: 2.17294
Timestep Consumption Time: 2.51298
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.68592

Cumulative Model Updates: 155,048
Cumulative Timesteps: 1,293,155,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.83156
Policy Entropy: 2.98180
Value Function Loss: 0.00458

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.60322
Value Function Update Magnitude: 0.54871

Collected Steps per Second: 23,388.95021
Overall Steps per Second: 10,905.18366

Timestep Collection Time: 2.13845
Timestep Consumption Time: 2.44800
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.58644

Cumulative Model Updates: 155,054
Cumulative Timesteps: 1,293,205,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1293205400...
Checkpoint 1293205400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,998.36197
Policy Entropy: 2.99598
Value Function Loss: 0.00450

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.59015
Value Function Update Magnitude: 0.54850

Collected Steps per Second: 22,953.38018
Overall Steps per Second: 10,787.42557

Timestep Collection Time: 2.17964
Timestep Consumption Time: 2.45817
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.63781

Cumulative Model Updates: 155,060
Cumulative Timesteps: 1,293,255,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,546.33756
Policy Entropy: 3.00038
Value Function Loss: 0.00423

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.57647
Value Function Update Magnitude: 0.54051

Collected Steps per Second: 23,405.94340
Overall Steps per Second: 10,808.26454

Timestep Collection Time: 2.13664
Timestep Consumption Time: 2.49038
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.62701

Cumulative Model Updates: 155,066
Cumulative Timesteps: 1,293,305,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1293305440...
Checkpoint 1293305440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.26451
Policy Entropy: 3.01906
Value Function Loss: 0.00441

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.57847
Value Function Update Magnitude: 0.51405

Collected Steps per Second: 22,541.68727
Overall Steps per Second: 10,636.93029

Timestep Collection Time: 2.21820
Timestep Consumption Time: 2.48259
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.70079

Cumulative Model Updates: 155,072
Cumulative Timesteps: 1,293,355,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.78134
Policy Entropy: 3.04023
Value Function Loss: 0.00459

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.58896
Value Function Update Magnitude: 0.52597

Collected Steps per Second: 22,780.30503
Overall Steps per Second: 10,842.57332

Timestep Collection Time: 2.19532
Timestep Consumption Time: 2.41706
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61237

Cumulative Model Updates: 155,078
Cumulative Timesteps: 1,293,405,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1293405452...
Checkpoint 1293405452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.08592
Policy Entropy: 3.05211
Value Function Loss: 0.00451

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.59116
Value Function Update Magnitude: 0.55517

Collected Steps per Second: 22,579.28611
Overall Steps per Second: 10,666.53562

Timestep Collection Time: 2.21477
Timestep Consumption Time: 2.47353
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.68831

Cumulative Model Updates: 155,084
Cumulative Timesteps: 1,293,455,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,798.89669
Policy Entropy: 3.04106
Value Function Loss: 0.00465

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.60182
Value Function Update Magnitude: 0.55759

Collected Steps per Second: 22,842.87003
Overall Steps per Second: 10,804.16018

Timestep Collection Time: 2.18965
Timestep Consumption Time: 2.43986
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.62951

Cumulative Model Updates: 155,090
Cumulative Timesteps: 1,293,505,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1293505478...
Checkpoint 1293505478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041.78374
Policy Entropy: 3.01335
Value Function Loss: 0.00512

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.61181
Value Function Update Magnitude: 0.56520

Collected Steps per Second: 22,856.08568
Overall Steps per Second: 10,732.23984

Timestep Collection Time: 2.18804
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.65979

Cumulative Model Updates: 155,096
Cumulative Timesteps: 1,293,555,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.43164
Policy Entropy: 3.00247
Value Function Loss: 0.00608

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.62201
Value Function Update Magnitude: 0.59052

Collected Steps per Second: 23,377.12389
Overall Steps per Second: 10,902.77648

Timestep Collection Time: 2.14013
Timestep Consumption Time: 2.44861
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.58874

Cumulative Model Updates: 155,102
Cumulative Timesteps: 1,293,605,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1293605518...
Checkpoint 1293605518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,690.27920
Policy Entropy: 3.01134
Value Function Loss: 0.00570

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.60585
Value Function Update Magnitude: 0.58686

Collected Steps per Second: 23,159.88356
Overall Steps per Second: 10,718.87439

Timestep Collection Time: 2.15891
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.66467

Cumulative Model Updates: 155,108
Cumulative Timesteps: 1,293,655,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561.48053
Policy Entropy: 3.03100
Value Function Loss: 0.00519

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.59288
Value Function Update Magnitude: 0.57003

Collected Steps per Second: 23,320.41479
Overall Steps per Second: 10,874.69895

Timestep Collection Time: 2.14516
Timestep Consumption Time: 2.45506
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.60022

Cumulative Model Updates: 155,114
Cumulative Timesteps: 1,293,705,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1293705544...
Checkpoint 1293705544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.68031
Policy Entropy: 3.03517
Value Function Loss: 0.00453

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.58844
Value Function Update Magnitude: 0.55774

Collected Steps per Second: 23,072.43090
Overall Steps per Second: 10,838.44537

Timestep Collection Time: 2.16822
Timestep Consumption Time: 2.44739
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.61561

Cumulative Model Updates: 155,120
Cumulative Timesteps: 1,293,755,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.44351
Policy Entropy: 3.01357
Value Function Loss: 0.00436

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.58552
Value Function Update Magnitude: 0.53106

Collected Steps per Second: 23,414.74524
Overall Steps per Second: 10,895.54836

Timestep Collection Time: 2.13575
Timestep Consumption Time: 2.45402
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.58976

Cumulative Model Updates: 155,126
Cumulative Timesteps: 1,293,805,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1293805578...
Checkpoint 1293805578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.42171
Policy Entropy: 3.01007
Value Function Loss: 0.00483

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.59036
Value Function Update Magnitude: 0.51072

Collected Steps per Second: 22,614.05383
Overall Steps per Second: 10,840.73567

Timestep Collection Time: 2.21110
Timestep Consumption Time: 2.40131
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.61242

Cumulative Model Updates: 155,132
Cumulative Timesteps: 1,293,855,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.00913
Policy Entropy: 3.02969
Value Function Loss: 0.00419

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.57995
Value Function Update Magnitude: 0.51815

Collected Steps per Second: 22,639.27430
Overall Steps per Second: 10,702.27396

Timestep Collection Time: 2.20864
Timestep Consumption Time: 2.46345
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.67209

Cumulative Model Updates: 155,138
Cumulative Timesteps: 1,293,905,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1293905582...
Checkpoint 1293905582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.54781
Policy Entropy: 3.04497
Value Function Loss: 0.00437

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.53090

Collected Steps per Second: 22,794.95255
Overall Steps per Second: 10,859.11523

Timestep Collection Time: 2.19382
Timestep Consumption Time: 2.41134
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.60516

Cumulative Model Updates: 155,144
Cumulative Timesteps: 1,293,955,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,399.17215
Policy Entropy: 3.05204
Value Function Loss: 0.00413

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.57812
Value Function Update Magnitude: 0.52196

Collected Steps per Second: 22,666.42919
Overall Steps per Second: 10,602.60776

Timestep Collection Time: 2.20599
Timestep Consumption Time: 2.51002
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.71601

Cumulative Model Updates: 155,150
Cumulative Timesteps: 1,294,005,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1294005592...
Checkpoint 1294005592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.31029
Policy Entropy: 3.04057
Value Function Loss: 0.00401

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10506
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.51050

Collected Steps per Second: 23,009.99477
Overall Steps per Second: 10,726.14827

Timestep Collection Time: 2.17358
Timestep Consumption Time: 2.48923
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.66281

Cumulative Model Updates: 155,156
Cumulative Timesteps: 1,294,055,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,341.56843
Policy Entropy: 3.03850
Value Function Loss: 0.00382

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.50202

Collected Steps per Second: 23,135.77134
Overall Steps per Second: 10,669.04572

Timestep Collection Time: 2.16167
Timestep Consumption Time: 2.52591
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.68758

Cumulative Model Updates: 155,162
Cumulative Timesteps: 1,294,105,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1294105618...
Checkpoint 1294105618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.32791
Policy Entropy: 3.01972
Value Function Loss: 0.00403

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.57317
Value Function Update Magnitude: 0.50675

Collected Steps per Second: 23,167.48110
Overall Steps per Second: 10,732.94092

Timestep Collection Time: 2.15941
Timestep Consumption Time: 2.50176
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.66116

Cumulative Model Updates: 155,168
Cumulative Timesteps: 1,294,155,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,287.45947
Policy Entropy: 3.02319
Value Function Loss: 0.00398

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.57035
Value Function Update Magnitude: 0.49994

Collected Steps per Second: 23,047.00377
Overall Steps per Second: 10,850.39711

Timestep Collection Time: 2.16991
Timestep Consumption Time: 2.43913
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.60905

Cumulative Model Updates: 155,174
Cumulative Timesteps: 1,294,205,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1294205656...
Checkpoint 1294205656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.23404
Policy Entropy: 3.01775
Value Function Loss: 0.00430

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.57397
Value Function Update Magnitude: 0.49103

Collected Steps per Second: 22,924.11188
Overall Steps per Second: 10,676.27415

Timestep Collection Time: 2.18233
Timestep Consumption Time: 2.50357
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.68590

Cumulative Model Updates: 155,180
Cumulative Timesteps: 1,294,255,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,010.17844
Policy Entropy: 3.02130
Value Function Loss: 0.00434

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.59219
Value Function Update Magnitude: 0.50141

Collected Steps per Second: 23,468.32485
Overall Steps per Second: 10,841.72023

Timestep Collection Time: 2.13104
Timestep Consumption Time: 2.48188
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.61292

Cumulative Model Updates: 155,186
Cumulative Timesteps: 1,294,305,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1294305696...
Checkpoint 1294305696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.87521
Policy Entropy: 3.02516
Value Function Loss: 0.00430

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.58405
Value Function Update Magnitude: 0.50529

Collected Steps per Second: 22,762.66230
Overall Steps per Second: 10,690.96323

Timestep Collection Time: 2.19781
Timestep Consumption Time: 2.48166
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.67947

Cumulative Model Updates: 155,192
Cumulative Timesteps: 1,294,355,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.87380
Policy Entropy: 3.02172
Value Function Loss: 0.00424

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.57046
Value Function Update Magnitude: 0.50346

Collected Steps per Second: 22,697.52920
Overall Steps per Second: 10,658.17672

Timestep Collection Time: 2.20376
Timestep Consumption Time: 2.48935
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.69311

Cumulative Model Updates: 155,198
Cumulative Timesteps: 1,294,405,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1294405744...
Checkpoint 1294405744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,644.59665
Policy Entropy: 3.02488
Value Function Loss: 0.00439

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.57537
Value Function Update Magnitude: 0.51483

Collected Steps per Second: 22,927.95191
Overall Steps per Second: 10,939.86903

Timestep Collection Time: 2.18109
Timestep Consumption Time: 2.39008
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.57117

Cumulative Model Updates: 155,204
Cumulative Timesteps: 1,294,455,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.00473
Policy Entropy: 3.01660
Value Function Loss: 0.00422

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.57067
Value Function Update Magnitude: 0.51729

Collected Steps per Second: 23,326.88618
Overall Steps per Second: 10,802.28352

Timestep Collection Time: 2.14482
Timestep Consumption Time: 2.48679
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.63161

Cumulative Model Updates: 155,210
Cumulative Timesteps: 1,294,505,784

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1294505784...
Checkpoint 1294505784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.85352
Policy Entropy: 3.00562
Value Function Loss: 0.00418

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.52187

Collected Steps per Second: 23,282.10024
Overall Steps per Second: 10,750.44032

Timestep Collection Time: 2.14826
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.65246

Cumulative Model Updates: 155,216
Cumulative Timesteps: 1,294,555,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,500.51551
Policy Entropy: 3.00043
Value Function Loss: 0.00422

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.57510
Value Function Update Magnitude: 0.52406

Collected Steps per Second: 23,064.13403
Overall Steps per Second: 10,883.12598

Timestep Collection Time: 2.16856
Timestep Consumption Time: 2.42718
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.59574

Cumulative Model Updates: 155,222
Cumulative Timesteps: 1,294,605,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1294605816...
Checkpoint 1294605816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.04445
Policy Entropy: 2.99164
Value Function Loss: 0.00429

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.58658
Value Function Update Magnitude: 0.50463

Collected Steps per Second: 23,125.15974
Overall Steps per Second: 10,827.51921

Timestep Collection Time: 2.16293
Timestep Consumption Time: 2.45660
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.61953

Cumulative Model Updates: 155,228
Cumulative Timesteps: 1,294,655,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.09219
Policy Entropy: 2.98408
Value Function Loss: 0.00481

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.60819
Value Function Update Magnitude: 0.51977

Collected Steps per Second: 23,469.94517
Overall Steps per Second: 10,917.87683

Timestep Collection Time: 2.13158
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.58221

Cumulative Model Updates: 155,234
Cumulative Timesteps: 1,294,705,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1294705862...
Checkpoint 1294705862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.32760
Policy Entropy: 2.98960
Value Function Loss: 0.00455

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11759
Policy Update Magnitude: 0.60711
Value Function Update Magnitude: 0.54743

Collected Steps per Second: 22,987.10083
Overall Steps per Second: 10,901.92450

Timestep Collection Time: 2.17626
Timestep Consumption Time: 2.41247
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.58873

Cumulative Model Updates: 155,240
Cumulative Timesteps: 1,294,755,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,454.79040
Policy Entropy: 2.99947
Value Function Loss: 0.00460

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11507
Policy Update Magnitude: 0.60122
Value Function Update Magnitude: 0.54587

Collected Steps per Second: 22,756.84672
Overall Steps per Second: 10,795.62169

Timestep Collection Time: 2.19811
Timestep Consumption Time: 2.43544
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.63355

Cumulative Model Updates: 155,246
Cumulative Timesteps: 1,294,805,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1294805910...
Checkpoint 1294805910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770.96835
Policy Entropy: 3.00882
Value Function Loss: 0.00435

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.59951
Value Function Update Magnitude: 0.52714

Collected Steps per Second: 22,373.21198
Overall Steps per Second: 10,737.82785

Timestep Collection Time: 2.23553
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.65793

Cumulative Model Updates: 155,252
Cumulative Timesteps: 1,294,855,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,016.48563
Policy Entropy: 3.02700
Value Function Loss: 0.00468

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.60233
Value Function Update Magnitude: 0.51250

Collected Steps per Second: 22,967.32030
Overall Steps per Second: 10,839.49889

Timestep Collection Time: 2.17814
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61516

Cumulative Model Updates: 155,258
Cumulative Timesteps: 1,294,905,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1294905952...
Checkpoint 1294905952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.35020
Policy Entropy: 3.02529
Value Function Loss: 0.00449

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.59946
Value Function Update Magnitude: 0.53736

Collected Steps per Second: 22,729.81218
Overall Steps per Second: 10,699.64129

Timestep Collection Time: 2.20072
Timestep Consumption Time: 2.47439
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.67511

Cumulative Model Updates: 155,264
Cumulative Timesteps: 1,294,955,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,248.34491
Policy Entropy: 3.03444
Value Function Loss: 0.00464

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.60669
Value Function Update Magnitude: 0.55119

Collected Steps per Second: 22,809.24368
Overall Steps per Second: 10,802.03443

Timestep Collection Time: 2.19332
Timestep Consumption Time: 2.43803
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.63135

Cumulative Model Updates: 155,270
Cumulative Timesteps: 1,295,006,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1295006002...
Checkpoint 1295006002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,978.08446
Policy Entropy: 3.04316
Value Function Loss: 0.00429

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.59704
Value Function Update Magnitude: 0.55823

Collected Steps per Second: 23,032.29933
Overall Steps per Second: 10,709.15968

Timestep Collection Time: 2.17147
Timestep Consumption Time: 2.49874
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.67021

Cumulative Model Updates: 155,276
Cumulative Timesteps: 1,295,056,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.45795
Policy Entropy: 3.03850
Value Function Loss: 0.00427

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.58664
Value Function Update Magnitude: 0.53889

Collected Steps per Second: 23,358.02929
Overall Steps per Second: 10,929.12744

Timestep Collection Time: 2.14188
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.57768

Cumulative Model Updates: 155,282
Cumulative Timesteps: 1,295,106,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1295106046...
Checkpoint 1295106046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,390.22393
Policy Entropy: 3.04121
Value Function Loss: 0.00422

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.58917
Value Function Update Magnitude: 0.53272

Collected Steps per Second: 23,231.49080
Overall Steps per Second: 10,743.83170

Timestep Collection Time: 2.15251
Timestep Consumption Time: 2.50188
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.65439

Cumulative Model Updates: 155,288
Cumulative Timesteps: 1,295,156,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.46597
Policy Entropy: 3.03928
Value Function Loss: 0.00418

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.58248
Value Function Update Magnitude: 0.52806

Collected Steps per Second: 23,342.05693
Overall Steps per Second: 10,813.85582

Timestep Collection Time: 2.14300
Timestep Consumption Time: 2.48273
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.62573

Cumulative Model Updates: 155,294
Cumulative Timesteps: 1,295,206,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1295206074...
Checkpoint 1295206074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744.91143
Policy Entropy: 3.05774
Value Function Loss: 0.00387

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.56905
Value Function Update Magnitude: 0.50054

Collected Steps per Second: 23,095.11169
Overall Steps per Second: 10,693.86741

Timestep Collection Time: 2.16513
Timestep Consumption Time: 2.51082
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.67595

Cumulative Model Updates: 155,300
Cumulative Timesteps: 1,295,256,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.84923
Policy Entropy: 3.05906
Value Function Loss: 0.00397

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.48967

Collected Steps per Second: 22,678.85634
Overall Steps per Second: 10,762.53168

Timestep Collection Time: 2.20478
Timestep Consumption Time: 2.44115
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.64593

Cumulative Model Updates: 155,306
Cumulative Timesteps: 1,295,306,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1295306080...
Checkpoint 1295306080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.31003
Policy Entropy: 3.03680
Value Function Loss: 0.00446

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.51239

Collected Steps per Second: 22,654.69934
Overall Steps per Second: 10,687.03748

Timestep Collection Time: 2.20758
Timestep Consumption Time: 2.47211
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.67969

Cumulative Model Updates: 155,312
Cumulative Timesteps: 1,295,356,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.58729
Policy Entropy: 3.03503
Value Function Loss: 0.00474

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.58265
Value Function Update Magnitude: 0.52562

Collected Steps per Second: 22,796.22234
Overall Steps per Second: 10,661.93932

Timestep Collection Time: 2.19370
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.69033

Cumulative Model Updates: 155,318
Cumulative Timesteps: 1,295,406,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1295406100...
Checkpoint 1295406100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.74796
Policy Entropy: 3.03303
Value Function Loss: 0.00465

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.58077
Value Function Update Magnitude: 0.52314

Collected Steps per Second: 23,265.32238
Overall Steps per Second: 10,939.56360

Timestep Collection Time: 2.14938
Timestep Consumption Time: 2.42174
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.57111

Cumulative Model Updates: 155,324
Cumulative Timesteps: 1,295,456,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.82536
Policy Entropy: 3.04491
Value Function Loss: 0.00431

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.51311

Collected Steps per Second: 23,122.23585
Overall Steps per Second: 10,860.09103

Timestep Collection Time: 2.16346
Timestep Consumption Time: 2.44276
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60622

Cumulative Model Updates: 155,330
Cumulative Timesteps: 1,295,506,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1295506130...
Checkpoint 1295506130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.10314
Policy Entropy: 3.03559
Value Function Loss: 0.00405

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.56063
Value Function Update Magnitude: 0.48201

Collected Steps per Second: 23,138.42728
Overall Steps per Second: 10,705.23382

Timestep Collection Time: 2.16125
Timestep Consumption Time: 2.51011
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.67136

Cumulative Model Updates: 155,336
Cumulative Timesteps: 1,295,556,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,756.85735
Policy Entropy: 3.03367
Value Function Loss: 0.00370

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.55094
Value Function Update Magnitude: 0.46140

Collected Steps per Second: 23,261.88642
Overall Steps per Second: 10,914.11435

Timestep Collection Time: 2.15038
Timestep Consumption Time: 2.43285
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.58324

Cumulative Model Updates: 155,342
Cumulative Timesteps: 1,295,606,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1295606160...
Checkpoint 1295606160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.54822
Policy Entropy: 3.02433
Value Function Loss: 0.00372

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.44374

Collected Steps per Second: 23,202.20157
Overall Steps per Second: 10,805.64078

Timestep Collection Time: 2.15617
Timestep Consumption Time: 2.47363
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.62980

Cumulative Model Updates: 155,348
Cumulative Timesteps: 1,295,656,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,272.62800
Policy Entropy: 3.02344
Value Function Loss: 0.00390

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.55752
Value Function Update Magnitude: 0.45080

Collected Steps per Second: 23,337.24900
Overall Steps per Second: 10,731.68632

Timestep Collection Time: 2.14327
Timestep Consumption Time: 2.51751
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.66078

Cumulative Model Updates: 155,354
Cumulative Timesteps: 1,295,706,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1295706206...
Checkpoint 1295706206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.51852
Policy Entropy: 3.01489
Value Function Loss: 0.00413

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.47091

Collected Steps per Second: 22,829.09151
Overall Steps per Second: 10,630.33914

Timestep Collection Time: 2.19019
Timestep Consumption Time: 2.51333
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.70352

Cumulative Model Updates: 155,360
Cumulative Timesteps: 1,295,756,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,450.31771
Policy Entropy: 3.02652
Value Function Loss: 0.00428

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.48098

Collected Steps per Second: 22,670.98072
Overall Steps per Second: 10,655.47329

Timestep Collection Time: 2.20643
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.69449

Cumulative Model Updates: 155,366
Cumulative Timesteps: 1,295,806,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1295806228...
Checkpoint 1295806228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.40928
Policy Entropy: 3.01470
Value Function Loss: 0.00429

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.57792
Value Function Update Magnitude: 0.48739

Collected Steps per Second: 22,338.53251
Overall Steps per Second: 10,785.56792

Timestep Collection Time: 2.23828
Timestep Consumption Time: 2.39754
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.63582

Cumulative Model Updates: 155,372
Cumulative Timesteps: 1,295,856,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.56839
Policy Entropy: 3.01482
Value Function Loss: 0.00420

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.58548
Value Function Update Magnitude: 0.48432

Collected Steps per Second: 22,661.98652
Overall Steps per Second: 10,710.55801

Timestep Collection Time: 2.20731
Timestep Consumption Time: 2.46304
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.67034

Cumulative Model Updates: 155,378
Cumulative Timesteps: 1,295,906,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1295906250...
Checkpoint 1295906250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,498.18363
Policy Entropy: 3.00171
Value Function Loss: 0.00396

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.58459
Value Function Update Magnitude: 0.48853

Collected Steps per Second: 22,559.23728
Overall Steps per Second: 10,611.39807

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.71399

Cumulative Model Updates: 155,384
Cumulative Timesteps: 1,295,956,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.92267
Policy Entropy: 3.00252
Value Function Loss: 0.00428

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.58394
Value Function Update Magnitude: 0.48102

Collected Steps per Second: 23,238.94598
Overall Steps per Second: 10,779.19230

Timestep Collection Time: 2.15242
Timestep Consumption Time: 2.48800
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.64042

Cumulative Model Updates: 155,390
Cumulative Timesteps: 1,296,006,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1296006292...
Checkpoint 1296006292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.77924
Policy Entropy: 3.00626
Value Function Loss: 0.00426

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.58002
Value Function Update Magnitude: 0.47761

Collected Steps per Second: 23,110.10794
Overall Steps per Second: 10,834.38659

Timestep Collection Time: 2.16468
Timestep Consumption Time: 2.45266
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.61734

Cumulative Model Updates: 155,396
Cumulative Timesteps: 1,296,056,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.41482
Policy Entropy: 3.00569
Value Function Loss: 0.00460

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11617
Policy Update Magnitude: 0.59211
Value Function Update Magnitude: 0.51108

Collected Steps per Second: 23,328.44125
Overall Steps per Second: 10,755.65590

Timestep Collection Time: 2.14408
Timestep Consumption Time: 2.50631
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.65039

Cumulative Model Updates: 155,402
Cumulative Timesteps: 1,296,106,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1296106336...
Checkpoint 1296106336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.56481
Policy Entropy: 2.99938
Value Function Loss: 0.00439

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.60168
Value Function Update Magnitude: 0.53688

Collected Steps per Second: 22,822.82030
Overall Steps per Second: 10,651.08363

Timestep Collection Time: 2.19158
Timestep Consumption Time: 2.50447
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.69605

Cumulative Model Updates: 155,408
Cumulative Timesteps: 1,296,156,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,973.51911
Policy Entropy: 3.00394
Value Function Loss: 0.00429

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.60253
Value Function Update Magnitude: 0.51312

Collected Steps per Second: 21,746.50564
Overall Steps per Second: 10,428.19507

Timestep Collection Time: 2.30060
Timestep Consumption Time: 2.49697
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.79757

Cumulative Model Updates: 155,414
Cumulative Timesteps: 1,296,206,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1296206384...
Checkpoint 1296206384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.31277
Policy Entropy: 3.00068
Value Function Loss: 0.00463

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.59506
Value Function Update Magnitude: 0.48347

Collected Steps per Second: 22,693.91364
Overall Steps per Second: 10,607.72982

Timestep Collection Time: 2.20412
Timestep Consumption Time: 2.51131
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.71543

Cumulative Model Updates: 155,420
Cumulative Timesteps: 1,296,256,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.50339
Policy Entropy: 3.01600
Value Function Loss: 0.00461

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.59129
Value Function Update Magnitude: 0.47776

Collected Steps per Second: 22,678.35992
Overall Steps per Second: 10,651.36616

Timestep Collection Time: 2.20536
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.69555

Cumulative Model Updates: 155,426
Cumulative Timesteps: 1,296,306,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1296306418...
Checkpoint 1296306418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,024.78980
Policy Entropy: 3.00176
Value Function Loss: 0.00442

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.58740
Value Function Update Magnitude: 0.48865

Collected Steps per Second: 23,221.52325
Overall Steps per Second: 10,857.37913

Timestep Collection Time: 2.15395
Timestep Consumption Time: 2.45287
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.60682

Cumulative Model Updates: 155,432
Cumulative Timesteps: 1,296,356,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.42430
Policy Entropy: 3.00350
Value Function Loss: 0.00466

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.59670
Value Function Update Magnitude: 0.48512

Collected Steps per Second: 22,973.35888
Overall Steps per Second: 10,848.62164

Timestep Collection Time: 2.17670
Timestep Consumption Time: 2.43274
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60943

Cumulative Model Updates: 155,438
Cumulative Timesteps: 1,296,406,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1296406442...
Checkpoint 1296406442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.99879
Policy Entropy: 2.99647
Value Function Loss: 0.00463

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11305
Policy Update Magnitude: 0.60273
Value Function Update Magnitude: 0.49997

Collected Steps per Second: 23,090.92844
Overall Steps per Second: 10,749.47841

Timestep Collection Time: 2.16648
Timestep Consumption Time: 2.48733
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.65381

Cumulative Model Updates: 155,444
Cumulative Timesteps: 1,296,456,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.15756
Policy Entropy: 3.02231
Value Function Loss: 0.00483

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.59196
Value Function Update Magnitude: 0.50743

Collected Steps per Second: 23,094.62425
Overall Steps per Second: 10,860.82963

Timestep Collection Time: 2.16596
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.60573

Cumulative Model Updates: 155,450
Cumulative Timesteps: 1,296,506,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1296506490...
Checkpoint 1296506490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.76370
Policy Entropy: 3.01817
Value Function Loss: 0.00476

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.58122
Value Function Update Magnitude: 0.50678

Collected Steps per Second: 22,914.46962
Overall Steps per Second: 10,704.69897

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.48922
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.67159

Cumulative Model Updates: 155,456
Cumulative Timesteps: 1,296,556,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.18180
Policy Entropy: 3.02410
Value Function Loss: 0.00475

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.58151
Value Function Update Magnitude: 0.51647

Collected Steps per Second: 23,303.79810
Overall Steps per Second: 10,885.95592

Timestep Collection Time: 2.14557
Timestep Consumption Time: 2.44750
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.59307

Cumulative Model Updates: 155,462
Cumulative Timesteps: 1,296,606,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1296606498...
Checkpoint 1296606498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.71682
Policy Entropy: 2.99784
Value Function Loss: 0.00449

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.58560
Value Function Update Magnitude: 0.50278

Collected Steps per Second: 22,921.93419
Overall Steps per Second: 10,683.40533

Timestep Collection Time: 2.18315
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.68409

Cumulative Model Updates: 155,468
Cumulative Timesteps: 1,296,656,540

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.28878
Policy Entropy: 3.00321
Value Function Loss: 0.00448

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.59169
Value Function Update Magnitude: 0.49281

Collected Steps per Second: 22,432.45096
Overall Steps per Second: 10,468.84320

Timestep Collection Time: 2.22998
Timestep Consumption Time: 2.54839
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.77837

Cumulative Model Updates: 155,474
Cumulative Timesteps: 1,296,706,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1296706564...
Checkpoint 1296706564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.87566
Policy Entropy: 3.00861
Value Function Loss: 0.00427

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11847
Policy Update Magnitude: 0.58759
Value Function Update Magnitude: 0.49259

Collected Steps per Second: 22,701.27366
Overall Steps per Second: 10,633.12410

Timestep Collection Time: 2.20340
Timestep Consumption Time: 2.50077
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.70417

Cumulative Model Updates: 155,480
Cumulative Timesteps: 1,296,756,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,807.23199
Policy Entropy: 3.01955
Value Function Loss: 0.00433

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.48922

Collected Steps per Second: 22,816.58514
Overall Steps per Second: 10,797.33644

Timestep Collection Time: 2.19139
Timestep Consumption Time: 2.43938
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.63077

Cumulative Model Updates: 155,486
Cumulative Timesteps: 1,296,806,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1296806584...
Checkpoint 1296806584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,769.47360
Policy Entropy: 3.01811
Value Function Loss: 0.00424

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.58489
Value Function Update Magnitude: 0.49570

Collected Steps per Second: 22,978.06723
Overall Steps per Second: 10,706.81232

Timestep Collection Time: 2.17651
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.67104

Cumulative Model Updates: 155,492
Cumulative Timesteps: 1,296,856,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.48781
Policy Entropy: 3.01980
Value Function Loss: 0.00420

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.57844
Value Function Update Magnitude: 0.48769

Collected Steps per Second: 23,356.69563
Overall Steps per Second: 10,855.47255

Timestep Collection Time: 2.14080
Timestep Consumption Time: 2.46536
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.60616

Cumulative Model Updates: 155,498
Cumulative Timesteps: 1,296,906,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1296906598...
Checkpoint 1296906598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,471.45967
Policy Entropy: 3.00776
Value Function Loss: 0.00421

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.57029
Value Function Update Magnitude: 0.48647

Collected Steps per Second: 23,215.64165
Overall Steps per Second: 10,858.25672

Timestep Collection Time: 2.15415
Timestep Consumption Time: 2.45156
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.60571

Cumulative Model Updates: 155,504
Cumulative Timesteps: 1,296,956,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120.17309
Policy Entropy: 3.01509
Value Function Loss: 0.00423

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.57545
Value Function Update Magnitude: 0.48066

Collected Steps per Second: 23,476.75851
Overall Steps per Second: 10,898.16011

Timestep Collection Time: 2.13079
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.59013

Cumulative Model Updates: 155,510
Cumulative Timesteps: 1,297,006,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1297006632...
Checkpoint 1297006632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.86897
Policy Entropy: 2.99654
Value Function Loss: 0.00415

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.57303
Value Function Update Magnitude: 0.47283

Collected Steps per Second: 23,146.06724
Overall Steps per Second: 10,892.35560

Timestep Collection Time: 2.16140
Timestep Consumption Time: 2.43154
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.59295

Cumulative Model Updates: 155,516
Cumulative Timesteps: 1,297,056,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,299.26364
Policy Entropy: 3.00035
Value Function Loss: 0.00445

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.58359
Value Function Update Magnitude: 0.48539

Collected Steps per Second: 22,984.00392
Overall Steps per Second: 10,903.33101

Timestep Collection Time: 2.17638
Timestep Consumption Time: 2.41139
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.58777

Cumulative Model Updates: 155,522
Cumulative Timesteps: 1,297,106,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1297106682...
Checkpoint 1297106682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.67597
Policy Entropy: 2.97949
Value Function Loss: 0.00458

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.59662
Value Function Update Magnitude: 0.49824

Collected Steps per Second: 22,952.77529
Overall Steps per Second: 10,733.80153

Timestep Collection Time: 2.17934
Timestep Consumption Time: 2.48089
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.66023

Cumulative Model Updates: 155,528
Cumulative Timesteps: 1,297,156,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,200.78288
Policy Entropy: 2.99227
Value Function Loss: 0.00469

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.60481
Value Function Update Magnitude: 0.51425

Collected Steps per Second: 22,661.92965
Overall Steps per Second: 10,845.45560

Timestep Collection Time: 2.20758
Timestep Consumption Time: 2.40523
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.61281

Cumulative Model Updates: 155,534
Cumulative Timesteps: 1,297,206,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1297206732...
Checkpoint 1297206732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,353.13196
Policy Entropy: 2.99514
Value Function Loss: 0.00435

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.59589
Value Function Update Magnitude: 0.51991

Collected Steps per Second: 22,271.34985
Overall Steps per Second: 10,667.83916

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.44195
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.68698

Cumulative Model Updates: 155,540
Cumulative Timesteps: 1,297,256,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937.69677
Policy Entropy: 3.00461
Value Function Loss: 0.00421

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.58776
Value Function Update Magnitude: 0.50828

Collected Steps per Second: 22,934.66044
Overall Steps per Second: 10,874.54221

Timestep Collection Time: 2.18011
Timestep Consumption Time: 2.41779
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.59789

Cumulative Model Updates: 155,546
Cumulative Timesteps: 1,297,306,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1297306732...
Checkpoint 1297306732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.43282
Policy Entropy: 2.99251
Value Function Loss: 0.00415

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.59095
Value Function Update Magnitude: 0.50225

Collected Steps per Second: 23,226.05587
Overall Steps per Second: 10,799.84040

Timestep Collection Time: 2.15310
Timestep Consumption Time: 2.47734
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.63044

Cumulative Model Updates: 155,552
Cumulative Timesteps: 1,297,356,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,728.57755
Policy Entropy: 3.00789
Value Function Loss: 0.00382

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.57981
Value Function Update Magnitude: 0.51177

Collected Steps per Second: 23,096.05372
Overall Steps per Second: 10,779.18062

Timestep Collection Time: 2.16487
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63857

Cumulative Model Updates: 155,558
Cumulative Timesteps: 1,297,406,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1297406740...
Checkpoint 1297406740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,382.53522
Policy Entropy: 3.00260
Value Function Loss: 0.00391

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.57632
Value Function Update Magnitude: 0.49832

Collected Steps per Second: 23,093.69095
Overall Steps per Second: 10,809.88813

Timestep Collection Time: 2.16527
Timestep Consumption Time: 2.46050
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.62576

Cumulative Model Updates: 155,564
Cumulative Timesteps: 1,297,456,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,220.52478
Policy Entropy: 2.99553
Value Function Loss: 0.00389

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.57945
Value Function Update Magnitude: 0.50591

Collected Steps per Second: 23,386.81403
Overall Steps per Second: 10,823.11427

Timestep Collection Time: 2.13804
Timestep Consumption Time: 2.48188
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.61993

Cumulative Model Updates: 155,570
Cumulative Timesteps: 1,297,506,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1297506746...
Checkpoint 1297506746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252.25324
Policy Entropy: 2.98612
Value Function Loss: 0.00385

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.57928
Value Function Update Magnitude: 0.49565

Collected Steps per Second: 23,310.60240
Overall Steps per Second: 10,921.03343

Timestep Collection Time: 2.14546
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.57942

Cumulative Model Updates: 155,576
Cumulative Timesteps: 1,297,556,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,903.70695
Policy Entropy: 2.98835
Value Function Loss: 0.00382

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.57145
Value Function Update Magnitude: 0.47624

Collected Steps per Second: 23,024.94536
Overall Steps per Second: 10,755.43985

Timestep Collection Time: 2.17182
Timestep Consumption Time: 2.47755
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.64937

Cumulative Model Updates: 155,582
Cumulative Timesteps: 1,297,606,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1297606764...
Checkpoint 1297606764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,533.85030
Policy Entropy: 2.99607
Value Function Loss: 0.00393

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10582
Policy Update Magnitude: 0.56917
Value Function Update Magnitude: 0.46184

Collected Steps per Second: 22,964.45474
Overall Steps per Second: 10,844.88325

Timestep Collection Time: 2.17736
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61065

Cumulative Model Updates: 155,588
Cumulative Timesteps: 1,297,656,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729.85339
Policy Entropy: 2.99356
Value Function Loss: 0.00412

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.46900

Collected Steps per Second: 22,766.37448
Overall Steps per Second: 10,831.60150

Timestep Collection Time: 2.19631
Timestep Consumption Time: 2.42000
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.61631

Cumulative Model Updates: 155,594
Cumulative Timesteps: 1,297,706,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1297706768...
Checkpoint 1297706768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.87454
Policy Entropy: 2.99808
Value Function Loss: 0.00433

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.57550
Value Function Update Magnitude: 0.50355

Collected Steps per Second: 22,568.61427
Overall Steps per Second: 10,735.88491

Timestep Collection Time: 2.21591
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.65821

Cumulative Model Updates: 155,600
Cumulative Timesteps: 1,297,756,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.05691
Policy Entropy: 2.99493
Value Function Loss: 0.00473

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11054
Policy Update Magnitude: 0.58755
Value Function Update Magnitude: 0.53528

Collected Steps per Second: 22,546.76288
Overall Steps per Second: 10,598.14724

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.50139
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.72007

Cumulative Model Updates: 155,606
Cumulative Timesteps: 1,297,806,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1297806802...
Checkpoint 1297806802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.12056
Policy Entropy: 3.00638
Value Function Loss: 0.00477

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.59249
Value Function Update Magnitude: 0.55098

Collected Steps per Second: 22,794.11115
Overall Steps per Second: 10,669.86299

Timestep Collection Time: 2.19478
Timestep Consumption Time: 2.49394
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.68872

Cumulative Model Updates: 155,612
Cumulative Timesteps: 1,297,856,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,264.12384
Policy Entropy: 3.00151
Value Function Loss: 0.00479

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.58979
Value Function Update Magnitude: 0.56400

Collected Steps per Second: 23,210.39084
Overall Steps per Second: 10,751.88219

Timestep Collection Time: 2.15498
Timestep Consumption Time: 2.49704
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.65202

Cumulative Model Updates: 155,618
Cumulative Timesteps: 1,297,906,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1297906848...
Checkpoint 1297906848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.33780
Policy Entropy: 3.01641
Value Function Loss: 0.00434

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.58944
Value Function Update Magnitude: 0.57270

Collected Steps per Second: 23,143.53913
Overall Steps per Second: 10,816.56712

Timestep Collection Time: 2.16112
Timestep Consumption Time: 2.46290
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.62402

Cumulative Model Updates: 155,624
Cumulative Timesteps: 1,297,956,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.13940
Policy Entropy: 3.00143
Value Function Loss: 0.00482

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.60385
Value Function Update Magnitude: 0.56487

Collected Steps per Second: 23,226.08705
Overall Steps per Second: 10,781.63768

Timestep Collection Time: 2.15301
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.63807

Cumulative Model Updates: 155,630
Cumulative Timesteps: 1,298,006,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1298006870...
Checkpoint 1298006870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.85115
Policy Entropy: 3.00730
Value Function Loss: 0.00483

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.59856
Value Function Update Magnitude: 0.54638

Collected Steps per Second: 23,283.00629
Overall Steps per Second: 10,967.06034

Timestep Collection Time: 2.14835
Timestep Consumption Time: 2.41258
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.56093

Cumulative Model Updates: 155,636
Cumulative Timesteps: 1,298,056,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126.09014
Policy Entropy: 3.01734
Value Function Loss: 0.00473

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.57633
Value Function Update Magnitude: 0.53420

Collected Steps per Second: 23,265.96657
Overall Steps per Second: 10,953.69217

Timestep Collection Time: 2.15044
Timestep Consumption Time: 2.41716
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.56759

Cumulative Model Updates: 155,642
Cumulative Timesteps: 1,298,106,922

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1298106922...
Checkpoint 1298106922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.55917
Policy Entropy: 3.03684
Value Function Loss: 0.00402

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.55930
Value Function Update Magnitude: 0.51578

Collected Steps per Second: 22,686.00565
Overall Steps per Second: 10,686.75270

Timestep Collection Time: 2.20471
Timestep Consumption Time: 2.47548
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.68019

Cumulative Model Updates: 155,648
Cumulative Timesteps: 1,298,156,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.51899
Policy Entropy: 3.04141
Value Function Loss: 0.00375

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.54078
Value Function Update Magnitude: 0.49478

Collected Steps per Second: 23,013.19967
Overall Steps per Second: 10,923.59147

Timestep Collection Time: 2.17327
Timestep Consumption Time: 2.40526
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.57853

Cumulative Model Updates: 155,654
Cumulative Timesteps: 1,298,206,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1298206952...
Checkpoint 1298206952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,321.12023
Policy Entropy: 3.05162
Value Function Loss: 0.00367

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.47783

Collected Steps per Second: 22,783.15009
Overall Steps per Second: 10,624.69851

Timestep Collection Time: 2.19592
Timestep Consumption Time: 2.51292
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.70884

Cumulative Model Updates: 155,660
Cumulative Timesteps: 1,298,256,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,354.91522
Policy Entropy: 3.05021
Value Function Loss: 0.00365

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.54610
Value Function Update Magnitude: 0.47138

Collected Steps per Second: 22,891.42123
Overall Steps per Second: 10,891.79672

Timestep Collection Time: 2.18553
Timestep Consumption Time: 2.40783
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.59337

Cumulative Model Updates: 155,666
Cumulative Timesteps: 1,298,307,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1298307012...
Checkpoint 1298307012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,641.22025
Policy Entropy: 3.05268
Value Function Loss: 0.00374

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.55337
Value Function Update Magnitude: 0.46823

Collected Steps per Second: 23,010.84454
Overall Steps per Second: 10,639.92885

Timestep Collection Time: 2.17332
Timestep Consumption Time: 2.52690
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.70022

Cumulative Model Updates: 155,672
Cumulative Timesteps: 1,298,357,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,454.04077
Policy Entropy: 3.04488
Value Function Loss: 0.00381

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.55501
Value Function Update Magnitude: 0.47803

Collected Steps per Second: 22,634.47736
Overall Steps per Second: 10,481.35727

Timestep Collection Time: 2.20928
Timestep Consumption Time: 2.56166
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.77095

Cumulative Model Updates: 155,678
Cumulative Timesteps: 1,298,407,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1298407028...
Checkpoint 1298407028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.50863
Policy Entropy: 3.05050
Value Function Loss: 0.00412

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.56382
Value Function Update Magnitude: 0.47530

Collected Steps per Second: 22,753.47840
Overall Steps per Second: 10,622.88961

Timestep Collection Time: 2.19826
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.70851

Cumulative Model Updates: 155,684
Cumulative Timesteps: 1,298,457,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,243.21112
Policy Entropy: 3.04529
Value Function Loss: 0.00390

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.48650

Collected Steps per Second: 23,198.76577
Overall Steps per Second: 10,873.14705

Timestep Collection Time: 2.15624
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.60051

Cumulative Model Updates: 155,690
Cumulative Timesteps: 1,298,507,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1298507068...
Checkpoint 1298507068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,758.73622
Policy Entropy: 3.04192
Value Function Loss: 0.00423

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.57306
Value Function Update Magnitude: 0.49502

Collected Steps per Second: 23,145.12668
Overall Steps per Second: 10,698.94422

Timestep Collection Time: 2.16123
Timestep Consumption Time: 2.51418
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.67541

Cumulative Model Updates: 155,696
Cumulative Timesteps: 1,298,557,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,347.14806
Policy Entropy: 3.04191
Value Function Loss: 0.00429

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11791
Policy Update Magnitude: 0.58716
Value Function Update Magnitude: 0.51682

Collected Steps per Second: 22,789.81437
Overall Steps per Second: 10,857.89769

Timestep Collection Time: 2.19414
Timestep Consumption Time: 2.41117
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60531

Cumulative Model Updates: 155,702
Cumulative Timesteps: 1,298,607,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1298607094...
Checkpoint 1298607094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274.08767
Policy Entropy: 3.04924
Value Function Loss: 0.00454

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.58058
Value Function Update Magnitude: 0.51618

Collected Steps per Second: 23,270.97121
Overall Steps per Second: 10,772.03582

Timestep Collection Time: 2.14894
Timestep Consumption Time: 2.49345
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.64239

Cumulative Model Updates: 155,708
Cumulative Timesteps: 1,298,657,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,096.40669
Policy Entropy: 3.06573
Value Function Loss: 0.00423

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.52435

Collected Steps per Second: 22,643.70867
Overall Steps per Second: 10,758.70786

Timestep Collection Time: 2.20900
Timestep Consumption Time: 2.44026
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.64926

Cumulative Model Updates: 155,714
Cumulative Timesteps: 1,298,707,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1298707122...
Checkpoint 1298707122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.55993
Policy Entropy: 3.07708
Value Function Loss: 0.00416

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.56364
Value Function Update Magnitude: 0.54100

Collected Steps per Second: 22,736.05951
Overall Steps per Second: 10,691.58090

Timestep Collection Time: 2.19933
Timestep Consumption Time: 2.47763
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.67695

Cumulative Model Updates: 155,720
Cumulative Timesteps: 1,298,757,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,961.82508
Policy Entropy: 3.08254
Value Function Loss: 0.00392

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.53084

Collected Steps per Second: 22,506.33927
Overall Steps per Second: 10,572.22802

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.50888
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.73145

Cumulative Model Updates: 155,726
Cumulative Timesteps: 1,298,807,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1298807148...
Checkpoint 1298807148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.81489
Policy Entropy: 3.08543
Value Function Loss: 0.00395

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.55007
Value Function Update Magnitude: 0.50950

Collected Steps per Second: 23,077.71867
Overall Steps per Second: 10,690.83260

Timestep Collection Time: 2.16772
Timestep Consumption Time: 2.51162
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.67934

Cumulative Model Updates: 155,732
Cumulative Timesteps: 1,298,857,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.14181
Policy Entropy: 3.06288
Value Function Loss: 0.00415

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.55759
Value Function Update Magnitude: 0.49240

Collected Steps per Second: 23,265.54186
Overall Steps per Second: 10,791.79884

Timestep Collection Time: 2.15013
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.63537

Cumulative Model Updates: 155,738
Cumulative Timesteps: 1,298,907,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1298907198...
Checkpoint 1298907198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,009.47915
Policy Entropy: 3.05814
Value Function Loss: 0.00431

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.50716

Collected Steps per Second: 23,314.32543
Overall Steps per Second: 10,780.58049

Timestep Collection Time: 2.14563
Timestep Consumption Time: 2.49456
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.64020

Cumulative Model Updates: 155,744
Cumulative Timesteps: 1,298,957,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.79605
Policy Entropy: 3.04719
Value Function Loss: 0.00409

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.55541
Value Function Update Magnitude: 0.52402

Collected Steps per Second: 23,036.58459
Overall Steps per Second: 10,727.55483

Timestep Collection Time: 2.17124
Timestep Consumption Time: 2.49133
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.66257

Cumulative Model Updates: 155,750
Cumulative Timesteps: 1,299,007,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1299007240...
Checkpoint 1299007240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,392.26871
Policy Entropy: 3.06136
Value Function Loss: 0.00408

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11168
Policy Update Magnitude: 0.56091
Value Function Update Magnitude: 0.53902

Collected Steps per Second: 23,019.38294
Overall Steps per Second: 10,806.51349

Timestep Collection Time: 2.17234
Timestep Consumption Time: 2.45505
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.62739

Cumulative Model Updates: 155,756
Cumulative Timesteps: 1,299,057,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.04132
Policy Entropy: 3.05900
Value Function Loss: 0.00392

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.56942
Value Function Update Magnitude: 0.53891

Collected Steps per Second: 23,284.76646
Overall Steps per Second: 10,720.99070

Timestep Collection Time: 2.14819
Timestep Consumption Time: 2.51743
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.66561

Cumulative Model Updates: 155,762
Cumulative Timesteps: 1,299,107,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1299107266...
Checkpoint 1299107266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831.74214
Policy Entropy: 3.04629
Value Function Loss: 0.00425

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.57998
Value Function Update Magnitude: 0.53353

Collected Steps per Second: 22,890.74386
Overall Steps per Second: 10,663.37087

Timestep Collection Time: 2.18490
Timestep Consumption Time: 2.50536
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.69026

Cumulative Model Updates: 155,768
Cumulative Timesteps: 1,299,157,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.26884
Policy Entropy: 3.06207
Value Function Loss: 0.00418

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.58522
Value Function Update Magnitude: 0.51732

Collected Steps per Second: 22,732.30856
Overall Steps per Second: 10,633.58056

Timestep Collection Time: 2.19969
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.70246

Cumulative Model Updates: 155,774
Cumulative Timesteps: 1,299,207,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1299207284...
Checkpoint 1299207284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,524.92290
Policy Entropy: 3.07165
Value Function Loss: 0.00383

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.56926
Value Function Update Magnitude: 0.50256

Collected Steps per Second: 22,662.51982
Overall Steps per Second: 10,801.82048

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.62996

Cumulative Model Updates: 155,780
Cumulative Timesteps: 1,299,257,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,712.69595
Policy Entropy: 3.07601
Value Function Loss: 0.00392

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.54944
Value Function Update Magnitude: 0.48135

Collected Steps per Second: 22,555.25609
Overall Steps per Second: 10,581.35487

Timestep Collection Time: 2.21678
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.72529

Cumulative Model Updates: 155,786
Cumulative Timesteps: 1,299,307,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1299307296...
Checkpoint 1299307296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.90627
Policy Entropy: 3.06938
Value Function Loss: 0.00401

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.56506
Value Function Update Magnitude: 0.50575

Collected Steps per Second: 22,889.98537
Overall Steps per Second: 10,650.44686

Timestep Collection Time: 2.18497
Timestep Consumption Time: 2.51098
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.69595

Cumulative Model Updates: 155,792
Cumulative Timesteps: 1,299,357,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.87678
Policy Entropy: 3.05765
Value Function Loss: 0.00402

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.53643

Collected Steps per Second: 23,207.92203
Overall Steps per Second: 10,770.50510

Timestep Collection Time: 2.15461
Timestep Consumption Time: 2.48807
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.64268

Cumulative Model Updates: 155,798
Cumulative Timesteps: 1,299,407,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1299407314...
Checkpoint 1299407314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,023.46295
Policy Entropy: 3.05235
Value Function Loss: 0.00415

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11257
Policy Update Magnitude: 0.56731
Value Function Update Magnitude: 0.55443

Collected Steps per Second: 23,206.09118
Overall Steps per Second: 10,722.51324

Timestep Collection Time: 2.15581
Timestep Consumption Time: 2.50988
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.66570

Cumulative Model Updates: 155,804
Cumulative Timesteps: 1,299,457,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,159.09950
Policy Entropy: 3.05065
Value Function Loss: 0.00380

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.55776
Value Function Update Magnitude: 0.54703

Collected Steps per Second: 23,262.70052
Overall Steps per Second: 10,916.82654

Timestep Collection Time: 2.14945
Timestep Consumption Time: 2.43082
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.58027

Cumulative Model Updates: 155,810
Cumulative Timesteps: 1,299,507,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1299507344...
Checkpoint 1299507344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.27112
Policy Entropy: 3.06031
Value Function Loss: 0.00388

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10641
Policy Update Magnitude: 0.55203
Value Function Update Magnitude: 0.51836

Collected Steps per Second: 23,308.61243
Overall Steps per Second: 10,816.11623

Timestep Collection Time: 2.14616
Timestep Consumption Time: 2.47879
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.62495

Cumulative Model Updates: 155,816
Cumulative Timesteps: 1,299,557,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,822.82632
Policy Entropy: 3.08050
Value Function Loss: 0.00349

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.53453
Value Function Update Magnitude: 0.48926

Collected Steps per Second: 23,144.15829
Overall Steps per Second: 10,694.97449

Timestep Collection Time: 2.16115
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.67678

Cumulative Model Updates: 155,822
Cumulative Timesteps: 1,299,607,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1299607386...
Checkpoint 1299607386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,461.52733
Policy Entropy: 3.08517
Value Function Loss: 0.00365

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.51617
Value Function Update Magnitude: 0.47162

Collected Steps per Second: 23,305.00569
Overall Steps per Second: 10,827.09576

Timestep Collection Time: 2.14675
Timestep Consumption Time: 2.47407
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.62081

Cumulative Model Updates: 155,828
Cumulative Timesteps: 1,299,657,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,101.57191
Policy Entropy: 3.06216
Value Function Loss: 0.00393

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.52816
Value Function Update Magnitude: 0.46390

Collected Steps per Second: 22,511.42380
Overall Steps per Second: 10,747.57781

Timestep Collection Time: 2.22207
Timestep Consumption Time: 2.43219
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.65426

Cumulative Model Updates: 155,834
Cumulative Timesteps: 1,299,707,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1299707438...
Checkpoint 1299707438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,334.48301
Policy Entropy: 3.05058
Value Function Loss: 0.00437

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.56518
Value Function Update Magnitude: 0.50440

Collected Steps per Second: 21,715.42478
Overall Steps per Second: 10,554.37231

Timestep Collection Time: 2.30343
Timestep Consumption Time: 2.43584
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.73927

Cumulative Model Updates: 155,840
Cumulative Timesteps: 1,299,757,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.97124
Policy Entropy: 3.04668
Value Function Loss: 0.00440

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11644
Policy Update Magnitude: 0.57176
Value Function Update Magnitude: 0.53082

Collected Steps per Second: 21,954.29779
Overall Steps per Second: 10,673.52974

Timestep Collection Time: 2.27764
Timestep Consumption Time: 2.40722
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.68486

Cumulative Model Updates: 155,846
Cumulative Timesteps: 1,299,807,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1299807462...
Checkpoint 1299807462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.83149
Policy Entropy: 3.06803
Value Function Loss: 0.00414

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.56694
Value Function Update Magnitude: 0.52942

Collected Steps per Second: 22,106.20624
Overall Steps per Second: 10,691.98308

Timestep Collection Time: 2.26235
Timestep Consumption Time: 2.41517
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.67752

Cumulative Model Updates: 155,852
Cumulative Timesteps: 1,299,857,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,096.93520
Policy Entropy: 3.08210
Value Function Loss: 0.00390

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11305
Policy Update Magnitude: 0.55404
Value Function Update Magnitude: 0.53046

Collected Steps per Second: 22,681.56581
Overall Steps per Second: 10,783.94636

Timestep Collection Time: 2.20461
Timestep Consumption Time: 2.43228
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.63689

Cumulative Model Updates: 155,858
Cumulative Timesteps: 1,299,907,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1299907478...
Checkpoint 1299907478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,437.15311
Policy Entropy: 3.09174
Value Function Loss: 0.00354

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10973
Policy Update Magnitude: 0.53932
Value Function Update Magnitude: 0.51758

Collected Steps per Second: 22,449.19607
Overall Steps per Second: 10,935.21676

Timestep Collection Time: 2.22859
Timestep Consumption Time: 2.34654
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.57513

Cumulative Model Updates: 155,864
Cumulative Timesteps: 1,299,957,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,071.42158
Policy Entropy: 3.08994
Value Function Loss: 0.00336

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.53313
Value Function Update Magnitude: 0.51459

Collected Steps per Second: 22,350.78176
Overall Steps per Second: 10,506.23509

Timestep Collection Time: 2.23715
Timestep Consumption Time: 2.52212
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.75927

Cumulative Model Updates: 155,870
Cumulative Timesteps: 1,300,007,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1300007510...
Checkpoint 1300007510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.69985
Policy Entropy: 3.07164
Value Function Loss: 0.00367

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.55557
Value Function Update Magnitude: 0.51562

Collected Steps per Second: 21,716.52396
Overall Steps per Second: 10,553.55513

Timestep Collection Time: 2.30359
Timestep Consumption Time: 2.43661
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.74020

Cumulative Model Updates: 155,876
Cumulative Timesteps: 1,300,057,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.26987
Policy Entropy: 3.04959
Value Function Loss: 0.00376

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.52743

Collected Steps per Second: 22,681.00322
Overall Steps per Second: 10,680.60878

Timestep Collection Time: 2.20546
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.68344

Cumulative Model Updates: 155,882
Cumulative Timesteps: 1,300,107,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1300107558...
Checkpoint 1300107558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,062.50636
Policy Entropy: 3.05418
Value Function Loss: 0.00405

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.56677
Value Function Update Magnitude: 0.53568

Collected Steps per Second: 22,561.54557
Overall Steps per Second: 10,709.37123

Timestep Collection Time: 2.21687
Timestep Consumption Time: 2.45343
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.67030

Cumulative Model Updates: 155,888
Cumulative Timesteps: 1,300,157,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,960.76806
Policy Entropy: 3.04446
Value Function Loss: 0.00408

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.57616
Value Function Update Magnitude: 0.54312

Collected Steps per Second: 23,154.92523
Overall Steps per Second: 10,701.26720

Timestep Collection Time: 2.16006
Timestep Consumption Time: 2.51378
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.67384

Cumulative Model Updates: 155,894
Cumulative Timesteps: 1,300,207,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1300207590...
Checkpoint 1300207590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,470.04241
Policy Entropy: 3.04519
Value Function Loss: 0.00427

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.58176
Value Function Update Magnitude: 0.55092

Collected Steps per Second: 23,275.35130
Overall Steps per Second: 10,775.37725

Timestep Collection Time: 2.14854
Timestep Consumption Time: 2.49241
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.64095

Cumulative Model Updates: 155,900
Cumulative Timesteps: 1,300,257,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,213.89938
Policy Entropy: 3.03554
Value Function Loss: 0.00430

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.57950
Value Function Update Magnitude: 0.56327

Collected Steps per Second: 23,074.28912
Overall Steps per Second: 10,793.90501

Timestep Collection Time: 2.16726
Timestep Consumption Time: 2.46572
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.63299

Cumulative Model Updates: 155,906
Cumulative Timesteps: 1,300,307,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1300307606...
Checkpoint 1300307606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.92788
Policy Entropy: 3.03326
Value Function Loss: 0.00445

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.57752
Value Function Update Magnitude: 0.55800

Collected Steps per Second: 23,118.17650
Overall Steps per Second: 10,744.88779

Timestep Collection Time: 2.16323
Timestep Consumption Time: 2.49107
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.65431

Cumulative Model Updates: 155,912
Cumulative Timesteps: 1,300,357,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,075.95530
Policy Entropy: 3.02003
Value Function Loss: 0.00433

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.57779
Value Function Update Magnitude: 0.54947

Collected Steps per Second: 23,087.90531
Overall Steps per Second: 10,779.76322

Timestep Collection Time: 2.16616
Timestep Consumption Time: 2.47328
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.63943

Cumulative Model Updates: 155,918
Cumulative Timesteps: 1,300,407,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1300407628...
Checkpoint 1300407628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.82340
Policy Entropy: 3.02099
Value Function Loss: 0.00430

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.57448
Value Function Update Magnitude: 0.54722

Collected Steps per Second: 22,877.11680
Overall Steps per Second: 10,622.26909

Timestep Collection Time: 2.18559
Timestep Consumption Time: 2.52150
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.70709

Cumulative Model Updates: 155,924
Cumulative Timesteps: 1,300,457,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,240.26518
Policy Entropy: 3.02766
Value Function Loss: 0.00420

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.53353

Collected Steps per Second: 23,318.26641
Overall Steps per Second: 10,957.14598

Timestep Collection Time: 2.14519
Timestep Consumption Time: 2.42005
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.56524

Cumulative Model Updates: 155,930
Cumulative Timesteps: 1,300,507,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1300507650...
Checkpoint 1300507650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,928.26605
Policy Entropy: 3.01626
Value Function Loss: 0.00409

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.49459

Collected Steps per Second: 22,741.22724
Overall Steps per Second: 10,605.15721

Timestep Collection Time: 2.19935
Timestep Consumption Time: 2.51684
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.71620

Cumulative Model Updates: 155,936
Cumulative Timesteps: 1,300,557,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.12794
Policy Entropy: 3.02372
Value Function Loss: 0.00409

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.56365
Value Function Update Magnitude: 0.48570

Collected Steps per Second: 22,719.70062
Overall Steps per Second: 10,653.35833

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.49322
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.69448

Cumulative Model Updates: 155,942
Cumulative Timesteps: 1,300,607,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1300607678...
Checkpoint 1300607678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.20929
Policy Entropy: 3.02476
Value Function Loss: 0.00376

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.56406
Value Function Update Magnitude: 0.50095

Collected Steps per Second: 22,655.91197
Overall Steps per Second: 10,796.83149

Timestep Collection Time: 2.20878
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.63488

Cumulative Model Updates: 155,948
Cumulative Timesteps: 1,300,657,720

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,385.34009
Policy Entropy: 3.05292
Value Function Loss: 0.00363

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.55725
Value Function Update Magnitude: 0.48507

Collected Steps per Second: 22,786.51113
Overall Steps per Second: 10,612.54292

Timestep Collection Time: 2.19498
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.71291

Cumulative Model Updates: 155,954
Cumulative Timesteps: 1,300,707,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1300707736...
Checkpoint 1300707736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,738.86277
Policy Entropy: 3.04025
Value Function Loss: 0.00375

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.55046
Value Function Update Magnitude: 0.46737

Collected Steps per Second: 22,953.17382
Overall Steps per Second: 10,614.94879

Timestep Collection Time: 2.18018
Timestep Consumption Time: 2.53412
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.71430

Cumulative Model Updates: 155,960
Cumulative Timesteps: 1,300,757,778

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.23588
Policy Entropy: 3.01919
Value Function Loss: 0.00392

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.55840
Value Function Update Magnitude: 0.48387

Collected Steps per Second: 23,032.56910
Overall Steps per Second: 10,828.67416

Timestep Collection Time: 2.17153
Timestep Consumption Time: 2.44731
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.61885

Cumulative Model Updates: 155,966
Cumulative Timesteps: 1,300,807,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1300807794...
Checkpoint 1300807794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.89564
Policy Entropy: 2.98529
Value Function Loss: 0.00454

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.58734
Value Function Update Magnitude: 0.49985

Collected Steps per Second: 22,966.39961
Overall Steps per Second: 10,740.15553

Timestep Collection Time: 2.17779
Timestep Consumption Time: 2.47913
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.65692

Cumulative Model Updates: 155,972
Cumulative Timesteps: 1,300,857,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.72083
Policy Entropy: 2.99303
Value Function Loss: 0.00441

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.59587
Value Function Update Magnitude: 0.53062

Collected Steps per Second: 23,036.17782
Overall Steps per Second: 10,839.01624

Timestep Collection Time: 2.17067
Timestep Consumption Time: 2.44266
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61333

Cumulative Model Updates: 155,978
Cumulative Timesteps: 1,300,907,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1300907814...
Checkpoint 1300907814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.16329
Policy Entropy: 3.00842
Value Function Loss: 0.00447

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.59076
Value Function Update Magnitude: 0.54109

Collected Steps per Second: 22,904.65035
Overall Steps per Second: 10,756.34202

Timestep Collection Time: 2.18384
Timestep Consumption Time: 2.46644
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.65028

Cumulative Model Updates: 155,984
Cumulative Timesteps: 1,300,957,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,535.26889
Policy Entropy: 3.02770
Value Function Loss: 0.00418

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.59108
Value Function Update Magnitude: 0.55093

Collected Steps per Second: 23,213.04365
Overall Steps per Second: 10,822.77062

Timestep Collection Time: 2.15396
Timestep Consumption Time: 2.46593
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.61989

Cumulative Model Updates: 155,990
Cumulative Timesteps: 1,301,007,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1301007834...
Checkpoint 1301007834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603.76740
Policy Entropy: 3.02536
Value Function Loss: 0.00442

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.59652
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 22,809.38530
Overall Steps per Second: 10,619.48699

Timestep Collection Time: 2.19217
Timestep Consumption Time: 2.51635
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.70851

Cumulative Model Updates: 155,996
Cumulative Timesteps: 1,301,057,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.11503
Policy Entropy: 3.01711
Value Function Loss: 0.00459

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.60049
Value Function Update Magnitude: 0.55675

Collected Steps per Second: 23,050.73134
Overall Steps per Second: 10,844.05849

Timestep Collection Time: 2.16956
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61174

Cumulative Model Updates: 156,002
Cumulative Timesteps: 1,301,107,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1301107846...
Checkpoint 1301107846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,944.51694
Policy Entropy: 3.00804
Value Function Loss: 0.00462

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.60120
Value Function Update Magnitude: 0.57403

Collected Steps per Second: 22,430.09967
Overall Steps per Second: 10,694.02869

Timestep Collection Time: 2.22986
Timestep Consumption Time: 2.44714
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.67700

Cumulative Model Updates: 156,008
Cumulative Timesteps: 1,301,157,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,045.30570
Policy Entropy: 3.00026
Value Function Loss: 0.00461

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.61097
Value Function Update Magnitude: 0.58460

Collected Steps per Second: 22,604.74475
Overall Steps per Second: 10,651.21425

Timestep Collection Time: 2.21308
Timestep Consumption Time: 2.48367
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.69674

Cumulative Model Updates: 156,014
Cumulative Timesteps: 1,301,207,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1301207888...
Checkpoint 1301207888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,208.72459
Policy Entropy: 3.01451
Value Function Loss: 0.00439

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.61883
Value Function Update Magnitude: 0.55711

Collected Steps per Second: 22,586.25384
Overall Steps per Second: 10,645.38152

Timestep Collection Time: 2.21489
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.69931

Cumulative Model Updates: 156,020
Cumulative Timesteps: 1,301,257,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,482.58527
Policy Entropy: 3.00159
Value Function Loss: 0.00439

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.61058
Value Function Update Magnitude: 0.53189

Collected Steps per Second: 23,357.77113
Overall Steps per Second: 10,740.80917

Timestep Collection Time: 2.14130
Timestep Consumption Time: 2.51533
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.65663

Cumulative Model Updates: 156,026
Cumulative Timesteps: 1,301,307,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1301307930...
Checkpoint 1301307930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.92637
Policy Entropy: 3.00584
Value Function Loss: 0.00424

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.59311
Value Function Update Magnitude: 0.50552

Collected Steps per Second: 22,958.59181
Overall Steps per Second: 10,692.77015

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.49882
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.67718

Cumulative Model Updates: 156,032
Cumulative Timesteps: 1,301,357,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.06597
Policy Entropy: 2.99693
Value Function Loss: 0.00439

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.57794
Value Function Update Magnitude: 0.50467

Collected Steps per Second: 23,384.55297
Overall Steps per Second: 10,815.30751

Timestep Collection Time: 2.13945
Timestep Consumption Time: 2.48640
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.62585

Cumulative Model Updates: 156,038
Cumulative Timesteps: 1,301,407,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1301407972...
Checkpoint 1301407972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,318.79852
Policy Entropy: 3.00299
Value Function Loss: 0.00471

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.58539
Value Function Update Magnitude: 0.50187

Collected Steps per Second: 23,108.72008
Overall Steps per Second: 10,717.63167

Timestep Collection Time: 2.16498
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.66801

Cumulative Model Updates: 156,044
Cumulative Timesteps: 1,301,458,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.52423
Policy Entropy: 2.99640
Value Function Loss: 0.00474

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.58591
Value Function Update Magnitude: 0.51354

Collected Steps per Second: 23,270.20867
Overall Steps per Second: 10,927.16253

Timestep Collection Time: 2.14953
Timestep Consumption Time: 2.42805
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.57758

Cumulative Model Updates: 156,050
Cumulative Timesteps: 1,301,508,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1301508022...
Checkpoint 1301508022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,215.07241
Policy Entropy: 3.00014
Value Function Loss: 0.00484

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.59724
Value Function Update Magnitude: 0.52589

Collected Steps per Second: 22,908.38268
Overall Steps per Second: 10,688.29386

Timestep Collection Time: 2.18348
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.67989

Cumulative Model Updates: 156,056
Cumulative Timesteps: 1,301,558,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,113.43313
Policy Entropy: 2.99716
Value Function Loss: 0.00434

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.60434
Value Function Update Magnitude: 0.54533

Collected Steps per Second: 22,989.83636
Overall Steps per Second: 10,774.27027

Timestep Collection Time: 2.17514
Timestep Consumption Time: 2.46611
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.64124

Cumulative Model Updates: 156,062
Cumulative Timesteps: 1,301,608,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1301608048...
Checkpoint 1301608048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,819.22080
Policy Entropy: 3.00248
Value Function Loss: 0.00418

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.59147
Value Function Update Magnitude: 0.53344

Collected Steps per Second: 22,333.11348
Overall Steps per Second: 10,661.25754

Timestep Collection Time: 2.23999
Timestep Consumption Time: 2.45232
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.69232

Cumulative Model Updates: 156,068
Cumulative Timesteps: 1,301,658,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,355.67466
Policy Entropy: 3.01538
Value Function Loss: 0.00389

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.58152
Value Function Update Magnitude: 0.51518

Collected Steps per Second: 22,800.49038
Overall Steps per Second: 10,824.77661

Timestep Collection Time: 2.19399
Timestep Consumption Time: 2.42726
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62125

Cumulative Model Updates: 156,074
Cumulative Timesteps: 1,301,708,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1301708098...
Checkpoint 1301708098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,073.24548
Policy Entropy: 3.01600
Value Function Loss: 0.00402

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.58253
Value Function Update Magnitude: 0.49971

Collected Steps per Second: 22,798.63347
Overall Steps per Second: 10,719.01396

Timestep Collection Time: 2.19346
Timestep Consumption Time: 2.47189
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.66535

Cumulative Model Updates: 156,080
Cumulative Timesteps: 1,301,758,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,306.39200
Policy Entropy: 2.99522
Value Function Loss: 0.00436

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.59310
Value Function Update Magnitude: 0.50548

Collected Steps per Second: 23,439.92994
Overall Steps per Second: 10,834.64038

Timestep Collection Time: 2.13354
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.61575

Cumulative Model Updates: 156,086
Cumulative Timesteps: 1,301,808,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1301808116...
Checkpoint 1301808116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,543.25686
Policy Entropy: 2.98467
Value Function Loss: 0.00472

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.61274
Value Function Update Magnitude: 0.54472

Collected Steps per Second: 22,936.49279
Overall Steps per Second: 10,648.91294

Timestep Collection Time: 2.18107
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.69776

Cumulative Model Updates: 156,092
Cumulative Timesteps: 1,301,858,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,941.88615
Policy Entropy: 2.99832
Value Function Loss: 0.00430

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.60691
Value Function Update Magnitude: 0.55475

Collected Steps per Second: 23,351.85662
Overall Steps per Second: 10,905.16415

Timestep Collection Time: 2.14287
Timestep Consumption Time: 2.44578
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.58865

Cumulative Model Updates: 156,098
Cumulative Timesteps: 1,301,908,182

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1301908182...
Checkpoint 1301908182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.36919
Policy Entropy: 3.04325
Value Function Loss: 0.00380

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.58360
Value Function Update Magnitude: 0.51366

Collected Steps per Second: 23,016.30335
Overall Steps per Second: 10,696.84230

Timestep Collection Time: 2.17368
Timestep Consumption Time: 2.50340
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.67708

Cumulative Model Updates: 156,104
Cumulative Timesteps: 1,301,958,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,860.88349
Policy Entropy: 3.06636
Value Function Loss: 0.00346

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.55503
Value Function Update Magnitude: 0.47540

Collected Steps per Second: 23,264.23351
Overall Steps per Second: 10,896.53398

Timestep Collection Time: 2.14948
Timestep Consumption Time: 2.43969
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.58917

Cumulative Model Updates: 156,110
Cumulative Timesteps: 1,302,008,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1302008218...
Checkpoint 1302008218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,838.97180
Policy Entropy: 3.08521
Value Function Loss: 0.00367

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10872
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.45933

Collected Steps per Second: 22,964.96571
Overall Steps per Second: 10,679.48216

Timestep Collection Time: 2.17775
Timestep Consumption Time: 2.50525
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.68300

Cumulative Model Updates: 156,116
Cumulative Timesteps: 1,302,058,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.42672
Policy Entropy: 3.08125
Value Function Loss: 0.00365

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.54298
Value Function Update Magnitude: 0.45606

Collected Steps per Second: 22,845.17690
Overall Steps per Second: 10,792.05026

Timestep Collection Time: 2.18926
Timestep Consumption Time: 2.44508
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.63434

Cumulative Model Updates: 156,122
Cumulative Timesteps: 1,302,108,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1302108244...
Checkpoint 1302108244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.10267
Policy Entropy: 3.09060
Value Function Loss: 0.00382

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.55020
Value Function Update Magnitude: 0.45810

Collected Steps per Second: 22,396.52491
Overall Steps per Second: 10,712.37210

Timestep Collection Time: 2.23267
Timestep Consumption Time: 2.43521
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.66787

Cumulative Model Updates: 156,128
Cumulative Timesteps: 1,302,158,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,217.34743
Policy Entropy: 3.09286
Value Function Loss: 0.00391

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.51264

Collected Steps per Second: 22,781.18129
Overall Steps per Second: 10,670.45112

Timestep Collection Time: 2.19479
Timestep Consumption Time: 2.49104
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.68584

Cumulative Model Updates: 156,134
Cumulative Timesteps: 1,302,208,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1302208248...
Checkpoint 1302208248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,107.03183
Policy Entropy: 3.07827
Value Function Loss: 0.00412

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.57546
Value Function Update Magnitude: 0.52349

Collected Steps per Second: 23,230.43201
Overall Steps per Second: 10,917.07251

Timestep Collection Time: 2.15269
Timestep Consumption Time: 2.42802
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.58072

Cumulative Model Updates: 156,140
Cumulative Timesteps: 1,302,258,256

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.33556
Policy Entropy: 3.06551
Value Function Loss: 0.00413

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.57529
Value Function Update Magnitude: 0.49899

Collected Steps per Second: 23,324.49967
Overall Steps per Second: 10,863.55798

Timestep Collection Time: 2.14513
Timestep Consumption Time: 2.46055
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.60567

Cumulative Model Updates: 156,146
Cumulative Timesteps: 1,302,308,290

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1302308290...
Checkpoint 1302308290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,491.80096
Policy Entropy: 3.05487
Value Function Loss: 0.00405

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.49547

Collected Steps per Second: 22,897.17756
Overall Steps per Second: 10,656.21615

Timestep Collection Time: 2.18376
Timestep Consumption Time: 2.50852
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.69228

Cumulative Model Updates: 156,152
Cumulative Timesteps: 1,302,358,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.04510
Policy Entropy: 3.07267
Value Function Loss: 0.00358

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11088
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.49901

Collected Steps per Second: 23,453.16239
Overall Steps per Second: 10,949.07383

Timestep Collection Time: 2.13285
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.56861

Cumulative Model Updates: 156,158
Cumulative Timesteps: 1,302,408,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1302408314...
Checkpoint 1302408314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,795.95138
Policy Entropy: 3.08227
Value Function Loss: 0.00349

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.54864
Value Function Update Magnitude: 0.48325

Collected Steps per Second: 23,011.33126
Overall Steps per Second: 10,699.36179

Timestep Collection Time: 2.17371
Timestep Consumption Time: 2.50133
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.67505

Cumulative Model Updates: 156,164
Cumulative Timesteps: 1,302,458,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,503.36349
Policy Entropy: 3.08737
Value Function Loss: 0.00351

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.54435
Value Function Update Magnitude: 0.48590

Collected Steps per Second: 23,257.94759
Overall Steps per Second: 10,817.77289

Timestep Collection Time: 2.15049
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.62350

Cumulative Model Updates: 156,170
Cumulative Timesteps: 1,302,508,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1302508350...
Checkpoint 1302508350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,527.35545
Policy Entropy: 3.08358
Value Function Loss: 0.00359

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.54147
Value Function Update Magnitude: 0.47859

Collected Steps per Second: 22,508.55673
Overall Steps per Second: 10,651.31426

Timestep Collection Time: 2.22164
Timestep Consumption Time: 2.47318
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.69482

Cumulative Model Updates: 156,176
Cumulative Timesteps: 1,302,558,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,303.14801
Policy Entropy: 3.07413
Value Function Loss: 0.00373

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.54942
Value Function Update Magnitude: 0.51338

Collected Steps per Second: 22,444.90115
Overall Steps per Second: 10,560.85028

Timestep Collection Time: 2.22839
Timestep Consumption Time: 2.50759
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.73598

Cumulative Model Updates: 156,182
Cumulative Timesteps: 1,302,608,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1302608372...
Checkpoint 1302608372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,591.49319
Policy Entropy: 3.06815
Value Function Loss: 0.00389

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.56168

Collected Steps per Second: 22,728.02780
Overall Steps per Second: 10,623.57415

Timestep Collection Time: 2.20028
Timestep Consumption Time: 2.50699
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.70727

Cumulative Model Updates: 156,188
Cumulative Timesteps: 1,302,658,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,551.54296
Policy Entropy: 3.04849
Value Function Loss: 0.00397

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.57472
Value Function Update Magnitude: 0.58587

Collected Steps per Second: 23,152.39281
Overall Steps per Second: 10,822.01763

Timestep Collection Time: 2.16012
Timestep Consumption Time: 2.46120
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.62132

Cumulative Model Updates: 156,194
Cumulative Timesteps: 1,302,708,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1302708392...
Checkpoint 1302708392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,042.92066
Policy Entropy: 3.05293
Value Function Loss: 0.00384

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.57839
Value Function Update Magnitude: 0.56172

Collected Steps per Second: 22,841.15574
Overall Steps per Second: 10,602.40909

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.52789
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.71780

Cumulative Model Updates: 156,200
Cumulative Timesteps: 1,302,758,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.50099
Policy Entropy: 3.04105
Value Function Loss: 0.00368

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.57494
Value Function Update Magnitude: 0.52602

Collected Steps per Second: 22,865.20588
Overall Steps per Second: 10,677.30341

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.49680
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.68414

Cumulative Model Updates: 156,206
Cumulative Timesteps: 1,302,808,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1302808426...
Checkpoint 1302808426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,096.99427
Policy Entropy: 3.05975
Value Function Loss: 0.00377

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.58076
Value Function Update Magnitude: 0.52248

Collected Steps per Second: 22,908.74873
Overall Steps per Second: 10,847.34458

Timestep Collection Time: 2.18310
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.61053

Cumulative Model Updates: 156,212
Cumulative Timesteps: 1,302,858,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.96013
Policy Entropy: 3.06596
Value Function Loss: 0.00358

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.57064
Value Function Update Magnitude: 0.51381

Collected Steps per Second: 23,472.54162
Overall Steps per Second: 10,910.69707

Timestep Collection Time: 2.13117
Timestep Consumption Time: 2.45369
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.58486

Cumulative Model Updates: 156,218
Cumulative Timesteps: 1,302,908,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1302908462...
Checkpoint 1302908462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,119.48780
Policy Entropy: 3.07349
Value Function Loss: 0.00336

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.55337
Value Function Update Magnitude: 0.49138

Collected Steps per Second: 22,759.24684
Overall Steps per Second: 10,655.52069

Timestep Collection Time: 2.19823
Timestep Consumption Time: 2.49699
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.69522

Cumulative Model Updates: 156,224
Cumulative Timesteps: 1,302,958,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,804.59087
Policy Entropy: 3.06562
Value Function Loss: 0.00336

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.46238

Collected Steps per Second: 23,406.67897
Overall Steps per Second: 10,972.23497

Timestep Collection Time: 2.13666
Timestep Consumption Time: 2.42140
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.55805

Cumulative Model Updates: 156,230
Cumulative Timesteps: 1,303,008,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1303008504...
Checkpoint 1303008504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,591.05540
Policy Entropy: 3.05572
Value Function Loss: 0.00352

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.54370
Value Function Update Magnitude: 0.45813

Collected Steps per Second: 22,749.62527
Overall Steps per Second: 10,632.78172

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.50460
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.70244

Cumulative Model Updates: 156,236
Cumulative Timesteps: 1,303,058,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,845.33813
Policy Entropy: 3.06309
Value Function Loss: 0.00367

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.47955

Collected Steps per Second: 22,962.24736
Overall Steps per Second: 10,868.58067

Timestep Collection Time: 2.17958
Timestep Consumption Time: 2.42526
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.60483

Cumulative Model Updates: 156,242
Cumulative Timesteps: 1,303,108,552

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1303108552...
Checkpoint 1303108552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,256.15253
Policy Entropy: 3.06197
Value Function Loss: 0.00374

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10601
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.50652

Collected Steps per Second: 22,390.92606
Overall Steps per Second: 10,687.15847

Timestep Collection Time: 2.23332
Timestep Consumption Time: 2.44576
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.67907

Cumulative Model Updates: 156,248
Cumulative Timesteps: 1,303,158,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.07563
Policy Entropy: 3.05802
Value Function Loss: 0.00381

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.56940
Value Function Update Magnitude: 0.51318

Collected Steps per Second: 22,573.85358
Overall Steps per Second: 10,886.47130

Timestep Collection Time: 2.21522
Timestep Consumption Time: 2.37819
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.59341

Cumulative Model Updates: 156,254
Cumulative Timesteps: 1,303,208,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1303208564...
Checkpoint 1303208564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,270.63083
Policy Entropy: 3.03066
Value Function Loss: 0.00401

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12234
Policy Update Magnitude: 0.58042
Value Function Update Magnitude: 0.51275

Collected Steps per Second: 22,267.03829
Overall Steps per Second: 10,619.38627

Timestep Collection Time: 2.24592
Timestep Consumption Time: 2.46339
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.70931

Cumulative Model Updates: 156,260
Cumulative Timesteps: 1,303,258,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,951.03674
Policy Entropy: 3.02474
Value Function Loss: 0.00382

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.58768
Value Function Update Magnitude: 0.53327

Collected Steps per Second: 22,668.47214
Overall Steps per Second: 10,919.13924

Timestep Collection Time: 2.20677
Timestep Consumption Time: 2.37455
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.58131

Cumulative Model Updates: 156,266
Cumulative Timesteps: 1,303,308,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1303308598...
Checkpoint 1303308598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639.60699
Policy Entropy: 3.03024
Value Function Loss: 0.00386

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.58659
Value Function Update Magnitude: 0.54280

Collected Steps per Second: 22,152.90911
Overall Steps per Second: 10,645.42271

Timestep Collection Time: 2.25758
Timestep Consumption Time: 2.44040
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.69798

Cumulative Model Updates: 156,272
Cumulative Timesteps: 1,303,358,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,067.73496
Policy Entropy: 3.03236
Value Function Loss: 0.00401

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.59354
Value Function Update Magnitude: 0.54104

Collected Steps per Second: 22,690.81733
Overall Steps per Second: 10,911.09569

Timestep Collection Time: 2.20406
Timestep Consumption Time: 2.37953
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.58359

Cumulative Model Updates: 156,278
Cumulative Timesteps: 1,303,408,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1303408622...
Checkpoint 1303408622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,748.82725
Policy Entropy: 3.03138
Value Function Loss: 0.00415

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.59028
Value Function Update Magnitude: 0.52969

Collected Steps per Second: 22,464.69848
Overall Steps per Second: 10,786.61850

Timestep Collection Time: 2.22580
Timestep Consumption Time: 2.40976
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.63556

Cumulative Model Updates: 156,284
Cumulative Timesteps: 1,303,458,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,652.48515
Policy Entropy: 3.02127
Value Function Loss: 0.00439

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.59259
Value Function Update Magnitude: 0.53856

Collected Steps per Second: 22,650.80153
Overall Steps per Second: 10,776.22482

Timestep Collection Time: 2.20752
Timestep Consumption Time: 2.43251
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.64003

Cumulative Model Updates: 156,290
Cumulative Timesteps: 1,303,508,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1303508626...
Checkpoint 1303508626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943.28293
Policy Entropy: 3.00917
Value Function Loss: 0.00448

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.60131
Value Function Update Magnitude: 0.55839

Collected Steps per Second: 21,740.04399
Overall Steps per Second: 10,668.22575

Timestep Collection Time: 2.30110
Timestep Consumption Time: 2.38815
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.68925

Cumulative Model Updates: 156,296
Cumulative Timesteps: 1,303,558,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,424.87835
Policy Entropy: 3.01741
Value Function Loss: 0.00442

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.60049
Value Function Update Magnitude: 0.56081

Collected Steps per Second: 22,417.84665
Overall Steps per Second: 10,792.66420

Timestep Collection Time: 2.23117
Timestep Consumption Time: 2.40328
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.63444

Cumulative Model Updates: 156,302
Cumulative Timesteps: 1,303,608,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1303608670...
Checkpoint 1303608670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,074.46461
Policy Entropy: 3.01405
Value Function Loss: 0.00433

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.59366
Value Function Update Magnitude: 0.54036

Collected Steps per Second: 22,350.23526
Overall Steps per Second: 10,770.54036

Timestep Collection Time: 2.23837
Timestep Consumption Time: 2.40653
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.64489

Cumulative Model Updates: 156,308
Cumulative Timesteps: 1,303,658,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.88846
Policy Entropy: 3.03192
Value Function Loss: 0.00440

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.58883
Value Function Update Magnitude: 0.54319

Collected Steps per Second: 23,445.91259
Overall Steps per Second: 10,875.84967

Timestep Collection Time: 2.13334
Timestep Consumption Time: 2.46566
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.59900

Cumulative Model Updates: 156,314
Cumulative Timesteps: 1,303,708,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1303708716...
Checkpoint 1303708716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,206.23076
Policy Entropy: 3.04598
Value Function Loss: 0.00440

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.58807
Value Function Update Magnitude: 0.55494

Collected Steps per Second: 22,936.54781
Overall Steps per Second: 10,752.69257

Timestep Collection Time: 2.18010
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.65037

Cumulative Model Updates: 156,320
Cumulative Timesteps: 1,303,758,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770.55338
Policy Entropy: 3.05712
Value Function Loss: 0.00404

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.57943
Value Function Update Magnitude: 0.55571

Collected Steps per Second: 23,421.05986
Overall Steps per Second: 10,804.36430

Timestep Collection Time: 2.13611
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.63054

Cumulative Model Updates: 156,326
Cumulative Timesteps: 1,303,808,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1303808750...
Checkpoint 1303808750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.23942
Policy Entropy: 3.04508
Value Function Loss: 0.00390

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.52760

Collected Steps per Second: 23,307.43380
Overall Steps per Second: 11,002.49423

Timestep Collection Time: 2.14601
Timestep Consumption Time: 2.40005
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.54606

Cumulative Model Updates: 156,332
Cumulative Timesteps: 1,303,858,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.92810
Policy Entropy: 3.03990
Value Function Loss: 0.00392

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.50314

Collected Steps per Second: 22,033.12670
Overall Steps per Second: 10,542.12582

Timestep Collection Time: 2.26976
Timestep Consumption Time: 2.47406
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.74383

Cumulative Model Updates: 156,338
Cumulative Timesteps: 1,303,908,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1303908778...
Checkpoint 1303908778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.58229
Policy Entropy: 3.03326
Value Function Loss: 0.00439

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.51634

Collected Steps per Second: 23,122.49872
Overall Steps per Second: 10,853.08983

Timestep Collection Time: 2.16352
Timestep Consumption Time: 2.44586
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.60938

Cumulative Model Updates: 156,344
Cumulative Timesteps: 1,303,958,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.80417
Policy Entropy: 3.02267
Value Function Loss: 0.00445

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.58494
Value Function Update Magnitude: 0.54378

Collected Steps per Second: 23,054.90012
Overall Steps per Second: 10,745.85679

Timestep Collection Time: 2.16917
Timestep Consumption Time: 2.48472
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.65389

Cumulative Model Updates: 156,350
Cumulative Timesteps: 1,304,008,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1304008814...
Checkpoint 1304008814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,633.13924
Policy Entropy: 3.02342
Value Function Loss: 0.00437

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.58943
Value Function Update Magnitude: 0.55061

Collected Steps per Second: 22,821.08037
Overall Steps per Second: 10,623.21058

Timestep Collection Time: 2.19131
Timestep Consumption Time: 2.51612
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.70743

Cumulative Model Updates: 156,356
Cumulative Timesteps: 1,304,058,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.73886
Policy Entropy: 3.00253
Value Function Loss: 0.00441

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.59520
Value Function Update Magnitude: 0.53760

Collected Steps per Second: 22,836.21562
Overall Steps per Second: 10,863.81158

Timestep Collection Time: 2.19056
Timestep Consumption Time: 2.41409
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.60465

Cumulative Model Updates: 156,362
Cumulative Timesteps: 1,304,108,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1304108846...
Checkpoint 1304108846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854.97919
Policy Entropy: 3.01545
Value Function Loss: 0.00449

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.60060
Value Function Update Magnitude: 0.54213

Collected Steps per Second: 22,741.64119
Overall Steps per Second: 10,673.81811

Timestep Collection Time: 2.19958
Timestep Consumption Time: 2.48684
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68642

Cumulative Model Updates: 156,368
Cumulative Timesteps: 1,304,158,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,448.72300
Policy Entropy: 3.02466
Value Function Loss: 0.00454

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.60309
Value Function Update Magnitude: 0.55179

Collected Steps per Second: 23,328.93836
Overall Steps per Second: 10,861.30656

Timestep Collection Time: 2.14343
Timestep Consumption Time: 2.46043
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.60387

Cumulative Model Updates: 156,374
Cumulative Timesteps: 1,304,208,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1304208872...
Checkpoint 1304208872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.43281
Policy Entropy: 3.05949
Value Function Loss: 0.00431

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.59431
Value Function Update Magnitude: 0.56969

Collected Steps per Second: 22,982.78700
Overall Steps per Second: 10,659.54279

Timestep Collection Time: 2.17554
Timestep Consumption Time: 2.51509
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.69063

Cumulative Model Updates: 156,380
Cumulative Timesteps: 1,304,258,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.85448
Policy Entropy: 3.05912
Value Function Loss: 0.00428

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.58318
Value Function Update Magnitude: 0.54608

Collected Steps per Second: 23,434.91008
Overall Steps per Second: 10,938.01412

Timestep Collection Time: 2.13357
Timestep Consumption Time: 2.43764
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.57121

Cumulative Model Updates: 156,386
Cumulative Timesteps: 1,304,308,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1304308872...
Checkpoint 1304308872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754.76739
Policy Entropy: 3.04910
Value Function Loss: 0.00414

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.57468
Value Function Update Magnitude: 0.52332

Collected Steps per Second: 23,056.91607
Overall Steps per Second: 10,833.39242

Timestep Collection Time: 2.16889
Timestep Consumption Time: 2.44720
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.61610

Cumulative Model Updates: 156,392
Cumulative Timesteps: 1,304,358,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,898.32926
Policy Entropy: 3.01519
Value Function Loss: 0.00465

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.58406
Value Function Update Magnitude: 0.51553

Collected Steps per Second: 23,443.48425
Overall Steps per Second: 10,894.18472

Timestep Collection Time: 2.13373
Timestep Consumption Time: 2.45790
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.59162

Cumulative Model Updates: 156,398
Cumulative Timesteps: 1,304,408,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1304408902...
Checkpoint 1304408902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.76410
Policy Entropy: 3.01366
Value Function Loss: 0.00487

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.59656
Value Function Update Magnitude: 0.53623

Collected Steps per Second: 22,738.19645
Overall Steps per Second: 10,862.93498

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.40521
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60539

Cumulative Model Updates: 156,404
Cumulative Timesteps: 1,304,458,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.03127
Policy Entropy: 3.01653
Value Function Loss: 0.00481

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.59441
Value Function Update Magnitude: 0.54437

Collected Steps per Second: 22,993.93164
Overall Steps per Second: 10,829.58318

Timestep Collection Time: 2.17518
Timestep Consumption Time: 2.44328
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.61846

Cumulative Model Updates: 156,410
Cumulative Timesteps: 1,304,508,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1304508946...
Checkpoint 1304508946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.42599
Policy Entropy: 3.03891
Value Function Loss: 0.00486

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.59927
Value Function Update Magnitude: 0.54713

Collected Steps per Second: 22,592.31069
Overall Steps per Second: 10,774.92007

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.64208

Cumulative Model Updates: 156,416
Cumulative Timesteps: 1,304,558,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.05120
Policy Entropy: 3.01651
Value Function Loss: 0.00498

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.60834
Value Function Update Magnitude: 0.54286

Collected Steps per Second: 23,054.32791
Overall Steps per Second: 10,929.33591

Timestep Collection Time: 2.16983
Timestep Consumption Time: 2.40721
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.57704

Cumulative Model Updates: 156,422
Cumulative Timesteps: 1,304,608,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1304608988...
Checkpoint 1304608988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,072.36930
Policy Entropy: 3.00797
Value Function Loss: 0.00497

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.60056
Value Function Update Magnitude: 0.55084

Collected Steps per Second: 22,830.69903
Overall Steps per Second: 10,583.10254

Timestep Collection Time: 2.19082
Timestep Consumption Time: 2.53539
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.72621

Cumulative Model Updates: 156,428
Cumulative Timesteps: 1,304,659,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.48678
Policy Entropy: 3.00469
Value Function Loss: 0.00473

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.60034
Value Function Update Magnitude: 0.55492

Collected Steps per Second: 23,265.48489
Overall Steps per Second: 10,747.19519

Timestep Collection Time: 2.15005
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.65442

Cumulative Model Updates: 156,434
Cumulative Timesteps: 1,304,709,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1304709028...
Checkpoint 1304709028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.30892
Policy Entropy: 3.03122
Value Function Loss: 0.00459

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.59973
Value Function Update Magnitude: 0.56727

Collected Steps per Second: 22,751.16797
Overall Steps per Second: 10,814.87164

Timestep Collection Time: 2.19804
Timestep Consumption Time: 2.42596
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.62400

Cumulative Model Updates: 156,440
Cumulative Timesteps: 1,304,759,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.91991
Policy Entropy: 3.03624
Value Function Loss: 0.00455

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.60157
Value Function Update Magnitude: 0.56314

Collected Steps per Second: 23,360.10459
Overall Steps per Second: 10,937.92894

Timestep Collection Time: 2.14160
Timestep Consumption Time: 2.43221
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.57381

Cumulative Model Updates: 156,446
Cumulative Timesteps: 1,304,809,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1304809064...
Checkpoint 1304809064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.83275
Policy Entropy: 3.04109
Value Function Loss: 0.00450

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.59597
Value Function Update Magnitude: 0.55857

Collected Steps per Second: 22,907.44413
Overall Steps per Second: 10,663.66058

Timestep Collection Time: 2.18401
Timestep Consumption Time: 2.50763
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69163

Cumulative Model Updates: 156,452
Cumulative Timesteps: 1,304,859,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.04515
Policy Entropy: 3.02940
Value Function Loss: 0.00466

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.59787
Value Function Update Magnitude: 0.56088

Collected Steps per Second: 23,258.93577
Overall Steps per Second: 10,845.14374

Timestep Collection Time: 2.15066
Timestep Consumption Time: 2.46173
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.61239

Cumulative Model Updates: 156,458
Cumulative Timesteps: 1,304,909,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1304909116...
Checkpoint 1304909116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.88042
Policy Entropy: 3.03216
Value Function Loss: 0.00465

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.60600
Value Function Update Magnitude: 0.57614

Collected Steps per Second: 22,510.88751
Overall Steps per Second: 10,651.18191

Timestep Collection Time: 2.22186
Timestep Consumption Time: 2.47396
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.69582

Cumulative Model Updates: 156,464
Cumulative Timesteps: 1,304,959,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,717.53527
Policy Entropy: 3.03326
Value Function Loss: 0.00490

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.61033
Value Function Update Magnitude: 0.58134

Collected Steps per Second: 22,835.62269
Overall Steps per Second: 10,815.06794

Timestep Collection Time: 2.19000
Timestep Consumption Time: 2.43410
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62410

Cumulative Model Updates: 156,470
Cumulative Timesteps: 1,305,009,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1305009142...
Checkpoint 1305009142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.69593
Policy Entropy: 3.02910
Value Function Loss: 0.00507

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.60916
Value Function Update Magnitude: 0.57280

Collected Steps per Second: 22,638.03142
Overall Steps per Second: 10,750.68563

Timestep Collection Time: 2.20903
Timestep Consumption Time: 2.44258
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.65161

Cumulative Model Updates: 156,476
Cumulative Timesteps: 1,305,059,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.32802
Policy Entropy: 3.00270
Value Function Loss: 0.00538

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.61642
Value Function Update Magnitude: 0.57196

Collected Steps per Second: 23,561.84409
Overall Steps per Second: 10,915.96637

Timestep Collection Time: 2.12301
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.58246

Cumulative Model Updates: 156,482
Cumulative Timesteps: 1,305,109,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1305109172...
Checkpoint 1305109172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.86012
Policy Entropy: 2.98037
Value Function Loss: 0.00528

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.62084
Value Function Update Magnitude: 0.57741

Collected Steps per Second: 23,094.53467
Overall Steps per Second: 10,756.20523

Timestep Collection Time: 2.16579
Timestep Consumption Time: 2.48436
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.65015

Cumulative Model Updates: 156,488
Cumulative Timesteps: 1,305,159,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.56621
Policy Entropy: 2.99680
Value Function Loss: 0.00489

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.61526
Value Function Update Magnitude: 0.57542

Collected Steps per Second: 23,382.57253
Overall Steps per Second: 10,811.64011

Timestep Collection Time: 2.13860
Timestep Consumption Time: 2.48660
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.62520

Cumulative Model Updates: 156,494
Cumulative Timesteps: 1,305,209,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1305209196...
Checkpoint 1305209196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.91398
Policy Entropy: 3.00358
Value Function Loss: 0.00487

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.62040
Value Function Update Magnitude: 0.58286

Collected Steps per Second: 23,262.91293
Overall Steps per Second: 10,773.48308

Timestep Collection Time: 2.14934
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.64102

Cumulative Model Updates: 156,500
Cumulative Timesteps: 1,305,259,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.59041
Policy Entropy: 3.00523
Value Function Loss: 0.00462

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.62577
Value Function Update Magnitude: 0.57400

Collected Steps per Second: 23,634.78644
Overall Steps per Second: 10,850.36108

Timestep Collection Time: 2.11561
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.60833

Cumulative Model Updates: 156,506
Cumulative Timesteps: 1,305,309,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1305309198...
Checkpoint 1305309198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.53601
Policy Entropy: 2.99638
Value Function Loss: 0.00476

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.62538
Value Function Update Magnitude: 0.56919

Collected Steps per Second: 23,141.09389
Overall Steps per Second: 10,864.22753

Timestep Collection Time: 2.16083
Timestep Consumption Time: 2.44180
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60263

Cumulative Model Updates: 156,512
Cumulative Timesteps: 1,305,359,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.14331
Policy Entropy: 3.00006
Value Function Loss: 0.00497

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.62698
Value Function Update Magnitude: 0.57737

Collected Steps per Second: 22,318.24714
Overall Steps per Second: 10,555.30549

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.49813
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.73980

Cumulative Model Updates: 156,518
Cumulative Timesteps: 1,305,409,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1305409232...
Checkpoint 1305409232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.43831
Policy Entropy: 3.00957
Value Function Loss: 0.00522

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.63009
Value Function Update Magnitude: 0.57783

Collected Steps per Second: 22,578.41814
Overall Steps per Second: 10,661.71210

Timestep Collection Time: 2.21459
Timestep Consumption Time: 2.47527
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.68987

Cumulative Model Updates: 156,524
Cumulative Timesteps: 1,305,459,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109.76430
Policy Entropy: 3.01171
Value Function Loss: 0.00568

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.63110
Value Function Update Magnitude: 0.58894

Collected Steps per Second: 22,546.73641
Overall Steps per Second: 10,607.78570

Timestep Collection Time: 2.21859
Timestep Consumption Time: 2.49700
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.71559

Cumulative Model Updates: 156,530
Cumulative Timesteps: 1,305,509,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1305509256...
Checkpoint 1305509256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.71716
Policy Entropy: 3.00535
Value Function Loss: 0.00549

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.63347
Value Function Update Magnitude: 0.60056

Collected Steps per Second: 22,131.53292
Overall Steps per Second: 10,559.29334

Timestep Collection Time: 2.25985
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.73649

Cumulative Model Updates: 156,536
Cumulative Timesteps: 1,305,559,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,464.32659
Policy Entropy: 3.01034
Value Function Loss: 0.00494

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.62354
Value Function Update Magnitude: 0.59451

Collected Steps per Second: 23,214.85435
Overall Steps per Second: 10,842.78521

Timestep Collection Time: 2.15397
Timestep Consumption Time: 2.45776
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.61173

Cumulative Model Updates: 156,542
Cumulative Timesteps: 1,305,609,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1305609274...
Checkpoint 1305609274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,610.01509
Policy Entropy: 3.00688
Value Function Loss: 0.00418

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.61265
Value Function Update Magnitude: 0.59978

Collected Steps per Second: 22,969.54943
Overall Steps per Second: 10,763.36554

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.46889
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.64594

Cumulative Model Updates: 156,548
Cumulative Timesteps: 1,305,659,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.34706
Policy Entropy: 3.01512
Value Function Loss: 0.00429

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.61327
Value Function Update Magnitude: 0.58083

Collected Steps per Second: 23,024.93011
Overall Steps per Second: 10,756.24713

Timestep Collection Time: 2.17260
Timestep Consumption Time: 2.47809
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.65069

Cumulative Model Updates: 156,554
Cumulative Timesteps: 1,305,709,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1305709304...
Checkpoint 1305709304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.61290
Policy Entropy: 3.01099
Value Function Loss: 0.00447

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.61364
Value Function Update Magnitude: 0.57138

Collected Steps per Second: 22,774.01529
Overall Steps per Second: 10,692.76711

Timestep Collection Time: 2.19636
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.67793

Cumulative Model Updates: 156,560
Cumulative Timesteps: 1,305,759,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.27579
Policy Entropy: 3.02546
Value Function Loss: 0.00455

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.59785
Value Function Update Magnitude: 0.55505

Collected Steps per Second: 23,162.79802
Overall Steps per Second: 10,842.14657

Timestep Collection Time: 2.15967
Timestep Consumption Time: 2.45418
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.61385

Cumulative Model Updates: 156,566
Cumulative Timesteps: 1,305,809,348

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1305809348...
Checkpoint 1305809348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.57176
Policy Entropy: 3.03578
Value Function Loss: 0.00431

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.59328
Value Function Update Magnitude: 0.53708

Collected Steps per Second: 22,777.01895
Overall Steps per Second: 10,647.05832

Timestep Collection Time: 2.19651
Timestep Consumption Time: 2.50244
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69895

Cumulative Model Updates: 156,572
Cumulative Timesteps: 1,305,859,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.37963
Policy Entropy: 3.03543
Value Function Loss: 0.00447

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.59252
Value Function Update Magnitude: 0.52346

Collected Steps per Second: 22,595.05095
Overall Steps per Second: 10,656.12527

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.69383

Cumulative Model Updates: 156,578
Cumulative Timesteps: 1,305,909,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1305909396...
Checkpoint 1305909396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.56157
Policy Entropy: 3.03974
Value Function Loss: 0.00463

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.58973
Value Function Update Magnitude: 0.53247

Collected Steps per Second: 22,680.13237
Overall Steps per Second: 10,799.27992

Timestep Collection Time: 2.20545
Timestep Consumption Time: 2.42634
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63179

Cumulative Model Updates: 156,584
Cumulative Timesteps: 1,305,959,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,056.61910
Policy Entropy: 3.03752
Value Function Loss: 0.00457

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.58654
Value Function Update Magnitude: 0.55444

Collected Steps per Second: 22,836.38348
Overall Steps per Second: 10,668.71380

Timestep Collection Time: 2.19010
Timestep Consumption Time: 2.49781
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.68791

Cumulative Model Updates: 156,590
Cumulative Timesteps: 1,306,009,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1306009430...
Checkpoint 1306009430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.22474
Policy Entropy: 3.04073
Value Function Loss: 0.00462

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.58467
Value Function Update Magnitude: 0.55685

Collected Steps per Second: 22,501.79700
Overall Steps per Second: 10,569.71119

Timestep Collection Time: 2.22329
Timestep Consumption Time: 2.50986
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.73315

Cumulative Model Updates: 156,596
Cumulative Timesteps: 1,306,059,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,339.73581
Policy Entropy: 3.02565
Value Function Loss: 0.00460

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.58915
Value Function Update Magnitude: 0.57550

Collected Steps per Second: 23,310.38933
Overall Steps per Second: 10,873.76818

Timestep Collection Time: 2.14617
Timestep Consumption Time: 2.45463
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.60080

Cumulative Model Updates: 156,602
Cumulative Timesteps: 1,306,109,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1306109486...
Checkpoint 1306109486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.27344
Policy Entropy: 3.02066
Value Function Loss: 0.00453

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.58875
Value Function Update Magnitude: 0.58442

Collected Steps per Second: 23,080.85263
Overall Steps per Second: 10,703.91809

Timestep Collection Time: 2.16682
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.67231

Cumulative Model Updates: 156,608
Cumulative Timesteps: 1,306,159,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.45816
Policy Entropy: 3.02411
Value Function Loss: 0.00415

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.57376
Value Function Update Magnitude: 0.56681

Collected Steps per Second: 23,456.77559
Overall Steps per Second: 10,808.03548

Timestep Collection Time: 2.13243
Timestep Consumption Time: 2.49561
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.62804

Cumulative Model Updates: 156,614
Cumulative Timesteps: 1,306,209,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1306209518...
Checkpoint 1306209518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,745.42377
Policy Entropy: 3.01489
Value Function Loss: 0.00422

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.55582

Collected Steps per Second: 22,919.61679
Overall Steps per Second: 10,636.12979

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.52033
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.70265

Cumulative Model Updates: 156,620
Cumulative Timesteps: 1,306,259,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,706.58685
Policy Entropy: 3.01081
Value Function Loss: 0.00414

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.59335
Value Function Update Magnitude: 0.55260

Collected Steps per Second: 23,279.50911
Overall Steps per Second: 10,908.39154

Timestep Collection Time: 2.14841
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.58491

Cumulative Model Updates: 156,626
Cumulative Timesteps: 1,306,309,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1306309550...
Checkpoint 1306309550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,154.62140
Policy Entropy: 3.01049
Value Function Loss: 0.00441

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.59166
Value Function Update Magnitude: 0.56215

Collected Steps per Second: 22,852.07074
Overall Steps per Second: 10,664.47564

Timestep Collection Time: 2.18877
Timestep Consumption Time: 2.50138
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.69015

Cumulative Model Updates: 156,632
Cumulative Timesteps: 1,306,359,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.15095
Policy Entropy: 3.02876
Value Function Loss: 0.00425

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.57616
Value Function Update Magnitude: 0.54460

Collected Steps per Second: 23,238.01751
Overall Steps per Second: 10,884.15527

Timestep Collection Time: 2.15251
Timestep Consumption Time: 2.44316
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.59567

Cumulative Model Updates: 156,638
Cumulative Timesteps: 1,306,409,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1306409588...
Checkpoint 1306409588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,899.65981
Policy Entropy: 3.02803
Value Function Loss: 0.00464

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.57225
Value Function Update Magnitude: 0.54508

Collected Steps per Second: 22,828.24953
Overall Steps per Second: 10,648.42301

Timestep Collection Time: 2.19123
Timestep Consumption Time: 2.50636
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.69760

Cumulative Model Updates: 156,644
Cumulative Timesteps: 1,306,459,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.67711
Policy Entropy: 3.03386
Value Function Loss: 0.00460

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.56967
Value Function Update Magnitude: 0.55500

Collected Steps per Second: 22,980.09077
Overall Steps per Second: 10,853.53267

Timestep Collection Time: 2.17701
Timestep Consumption Time: 2.43236
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60937

Cumulative Model Updates: 156,650
Cumulative Timesteps: 1,306,509,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1306509638...
Checkpoint 1306509638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,301.38767
Policy Entropy: 3.04456
Value Function Loss: 0.00432

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.56586
Value Function Update Magnitude: 0.56123

Collected Steps per Second: 22,366.90146
Overall Steps per Second: 10,691.38759

Timestep Collection Time: 2.23554
Timestep Consumption Time: 2.44131
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.67685

Cumulative Model Updates: 156,656
Cumulative Timesteps: 1,306,559,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.11378
Policy Entropy: 3.04796
Value Function Loss: 0.00422

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.56839
Value Function Update Magnitude: 0.53598

Collected Steps per Second: 23,015.44169
Overall Steps per Second: 10,838.11819

Timestep Collection Time: 2.17272
Timestep Consumption Time: 2.44119
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.61390

Cumulative Model Updates: 156,662
Cumulative Timesteps: 1,306,609,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1306609646...
Checkpoint 1306609646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,288.58385
Policy Entropy: 3.03379
Value Function Loss: 0.00412

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.56147
Value Function Update Magnitude: 0.51567

Collected Steps per Second: 22,974.22858
Overall Steps per Second: 10,698.07793

Timestep Collection Time: 2.17661
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.67430

Cumulative Model Updates: 156,668
Cumulative Timesteps: 1,306,659,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,361.87611
Policy Entropy: 3.03331
Value Function Loss: 0.00408

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.49422

Collected Steps per Second: 23,240.52423
Overall Steps per Second: 10,909.29066

Timestep Collection Time: 2.15253
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.58563

Cumulative Model Updates: 156,674
Cumulative Timesteps: 1,306,709,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1306709678...
Checkpoint 1306709678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,576.87560
Policy Entropy: 3.03466
Value Function Loss: 0.00422

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.56279
Value Function Update Magnitude: 0.50068

Collected Steps per Second: 22,950.88496
Overall Steps per Second: 10,687.63005

Timestep Collection Time: 2.17952
Timestep Consumption Time: 2.50084
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.68036

Cumulative Model Updates: 156,680
Cumulative Timesteps: 1,306,759,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,005.17147
Policy Entropy: 3.03237
Value Function Loss: 0.00432

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.57537
Value Function Update Magnitude: 0.53108

Collected Steps per Second: 23,377.49472
Overall Steps per Second: 10,868.59113

Timestep Collection Time: 2.14001
Timestep Consumption Time: 2.46298
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.60299

Cumulative Model Updates: 156,686
Cumulative Timesteps: 1,306,809,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1306809728...
Checkpoint 1306809728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,079.08998
Policy Entropy: 3.03710
Value Function Loss: 0.00427

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.58419
Value Function Update Magnitude: 0.55119

Collected Steps per Second: 23,115.17833
Overall Steps per Second: 10,721.47350

Timestep Collection Time: 2.16395
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.66540

Cumulative Model Updates: 156,692
Cumulative Timesteps: 1,306,859,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,573.82059
Policy Entropy: 3.04986
Value Function Loss: 0.00411

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.57520
Value Function Update Magnitude: 0.53308

Collected Steps per Second: 22,672.46747
Overall Steps per Second: 10,859.28323

Timestep Collection Time: 2.20620
Timestep Consumption Time: 2.40000
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.60620

Cumulative Model Updates: 156,698
Cumulative Timesteps: 1,306,909,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1306909768...
Checkpoint 1306909768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.36249
Policy Entropy: 3.07409
Value Function Loss: 0.00392

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.55998
Value Function Update Magnitude: 0.53310

Collected Steps per Second: 21,781.98497
Overall Steps per Second: 10,654.58970

Timestep Collection Time: 2.29639
Timestep Consumption Time: 2.39830
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.69469

Cumulative Model Updates: 156,704
Cumulative Timesteps: 1,306,959,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.54975
Policy Entropy: 3.07336
Value Function Loss: 0.00382

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.54918
Value Function Update Magnitude: 0.51600

Collected Steps per Second: 22,347.51703
Overall Steps per Second: 10,878.04664

Timestep Collection Time: 2.23792
Timestep Consumption Time: 2.35959
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.59752

Cumulative Model Updates: 156,710
Cumulative Timesteps: 1,307,009,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1307009800...
Checkpoint 1307009800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,106.50235
Policy Entropy: 3.07417
Value Function Loss: 0.00418

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.50647

Collected Steps per Second: 21,976.44167
Overall Steps per Second: 10,656.16823

Timestep Collection Time: 2.27525
Timestep Consumption Time: 2.41705
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.69231

Cumulative Model Updates: 156,716
Cumulative Timesteps: 1,307,059,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.20489
Policy Entropy: 3.07581
Value Function Loss: 0.00401

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.50635

Collected Steps per Second: 22,248.58604
Overall Steps per Second: 10,842.48385

Timestep Collection Time: 2.24769
Timestep Consumption Time: 2.36453
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61223

Cumulative Model Updates: 156,722
Cumulative Timesteps: 1,307,109,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1307109810...
Checkpoint 1307109810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.36421
Policy Entropy: 3.10048
Value Function Loss: 0.00376

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.53546
Value Function Update Magnitude: 0.50989

Collected Steps per Second: 22,185.46042
Overall Steps per Second: 10,709.29228

Timestep Collection Time: 2.25373
Timestep Consumption Time: 2.41511
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.66884

Cumulative Model Updates: 156,728
Cumulative Timesteps: 1,307,159,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,756.36191
Policy Entropy: 3.10576
Value Function Loss: 0.00339

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.52761
Value Function Update Magnitude: 0.48844

Collected Steps per Second: 22,795.19802
Overall Steps per Second: 10,873.53208

Timestep Collection Time: 2.19362
Timestep Consumption Time: 2.40507
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.59869

Cumulative Model Updates: 156,734
Cumulative Timesteps: 1,307,209,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1307209814...
Checkpoint 1307209814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,547.75457
Policy Entropy: 3.09264
Value Function Loss: 0.00348

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.53136
Value Function Update Magnitude: 0.45920

Collected Steps per Second: 22,558.80577
Overall Steps per Second: 10,630.50761

Timestep Collection Time: 2.21723
Timestep Consumption Time: 2.48791
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.70514

Cumulative Model Updates: 156,740
Cumulative Timesteps: 1,307,259,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.50234
Policy Entropy: 3.06883
Value Function Loss: 0.00382

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.53969
Value Function Update Magnitude: 0.46029

Collected Steps per Second: 23,470.73933
Overall Steps per Second: 10,962.90698

Timestep Collection Time: 2.13031
Timestep Consumption Time: 2.43052
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.56083

Cumulative Model Updates: 156,746
Cumulative Timesteps: 1,307,309,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1307309832...
Checkpoint 1307309832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,746.29106
Policy Entropy: 3.06509
Value Function Loss: 0.00387

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.54643
Value Function Update Magnitude: 0.48011

Collected Steps per Second: 23,141.11018
Overall Steps per Second: 10,843.04784

Timestep Collection Time: 2.16221
Timestep Consumption Time: 2.45236
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.61457

Cumulative Model Updates: 156,752
Cumulative Timesteps: 1,307,359,868

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.79540
Policy Entropy: 3.05814
Value Function Loss: 0.00405

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.49400

Collected Steps per Second: 23,136.84870
Overall Steps per Second: 10,789.25620

Timestep Collection Time: 2.16149
Timestep Consumption Time: 2.47368
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.63517

Cumulative Model Updates: 156,758
Cumulative Timesteps: 1,307,409,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1307409878...
Checkpoint 1307409878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.58036
Policy Entropy: 3.04527
Value Function Loss: 0.00431

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.53308

Collected Steps per Second: 22,497.53898
Overall Steps per Second: 10,688.97699

Timestep Collection Time: 2.22327
Timestep Consumption Time: 2.45613
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.67940

Cumulative Model Updates: 156,764
Cumulative Timesteps: 1,307,459,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,825.99441
Policy Entropy: 3.05197
Value Function Loss: 0.00398

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.57154
Value Function Update Magnitude: 0.56570

Collected Steps per Second: 22,958.23140
Overall Steps per Second: 10,742.50403

Timestep Collection Time: 2.17900
Timestep Consumption Time: 2.47783
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.65683

Cumulative Model Updates: 156,770
Cumulative Timesteps: 1,307,509,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1307509922...
Checkpoint 1307509922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,186.52342
Policy Entropy: 3.04836
Value Function Loss: 0.00405

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.56973
Value Function Update Magnitude: 0.56442

Collected Steps per Second: 22,697.51113
Overall Steps per Second: 10,675.24157

Timestep Collection Time: 2.20403
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.68617

Cumulative Model Updates: 156,776
Cumulative Timesteps: 1,307,559,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,893.84673
Policy Entropy: 3.05645
Value Function Loss: 0.00397

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.57372
Value Function Update Magnitude: 0.55840

Collected Steps per Second: 22,922.65869
Overall Steps per Second: 10,834.75434

Timestep Collection Time: 2.18221
Timestep Consumption Time: 2.43460
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.61681

Cumulative Model Updates: 156,782
Cumulative Timesteps: 1,307,609,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1307609970...
Checkpoint 1307609970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,931.17972
Policy Entropy: 3.06448
Value Function Loss: 0.00411

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.57515
Value Function Update Magnitude: 0.52826

Collected Steps per Second: 22,990.29683
Overall Steps per Second: 10,682.73702

Timestep Collection Time: 2.17553
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.68195

Cumulative Model Updates: 156,788
Cumulative Timesteps: 1,307,659,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,411.63555
Policy Entropy: 3.05529
Value Function Loss: 0.00454

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.58232
Value Function Update Magnitude: 0.52573

Collected Steps per Second: 23,198.64343
Overall Steps per Second: 10,893.44954

Timestep Collection Time: 2.15573
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.59083

Cumulative Model Updates: 156,794
Cumulative Timesteps: 1,307,709,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1307709996...
Checkpoint 1307709996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278.17440
Policy Entropy: 3.04866
Value Function Loss: 0.00397

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.57579
Value Function Update Magnitude: 0.53003

Collected Steps per Second: 21,761.68053
Overall Steps per Second: 10,380.81970

Timestep Collection Time: 2.29817
Timestep Consumption Time: 2.51956
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.81773

Cumulative Model Updates: 156,800
Cumulative Timesteps: 1,307,760,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.17821
Policy Entropy: 3.05615
Value Function Loss: 0.00391

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.56368
Value Function Update Magnitude: 0.49435

Collected Steps per Second: 23,529.73385
Overall Steps per Second: 10,744.16326

Timestep Collection Time: 2.12582
Timestep Consumption Time: 2.52973
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.65555

Cumulative Model Updates: 156,806
Cumulative Timesteps: 1,307,810,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1307810028...
Checkpoint 1307810028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,013.51032
Policy Entropy: 3.05649
Value Function Loss: 0.00406

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.50399

Collected Steps per Second: 23,231.10181
Overall Steps per Second: 10,771.32564

Timestep Collection Time: 2.15298
Timestep Consumption Time: 2.49046
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.64344

Cumulative Model Updates: 156,812
Cumulative Timesteps: 1,307,860,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,343.28190
Policy Entropy: 3.07812
Value Function Loss: 0.00405

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.58719
Value Function Update Magnitude: 0.54615

Collected Steps per Second: 23,337.63547
Overall Steps per Second: 10,770.45805

Timestep Collection Time: 2.14366
Timestep Consumption Time: 2.50127
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.64493

Cumulative Model Updates: 156,818
Cumulative Timesteps: 1,307,910,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1307910072...
Checkpoint 1307910072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,174.82538
Policy Entropy: 3.08601
Value Function Loss: 0.00384

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.57179
Value Function Update Magnitude: 0.54809

Collected Steps per Second: 23,311.44311
Overall Steps per Second: 10,832.43760

Timestep Collection Time: 2.14581
Timestep Consumption Time: 2.47198
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.61780

Cumulative Model Updates: 156,824
Cumulative Timesteps: 1,307,960,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,068.62890
Policy Entropy: 3.08006
Value Function Loss: 0.00402

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09317
Policy Update Magnitude: 0.57825
Value Function Update Magnitude: 0.53094

Collected Steps per Second: 23,004.91198
Overall Steps per Second: 10,701.52598

Timestep Collection Time: 2.17397
Timestep Consumption Time: 2.49938
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.67335

Cumulative Model Updates: 156,830
Cumulative Timesteps: 1,308,010,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1308010106...
Checkpoint 1308010106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,095.54716
Policy Entropy: 3.05247
Value Function Loss: 0.00429

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.59040
Value Function Update Magnitude: 0.54512

Collected Steps per Second: 22,788.08308
Overall Steps per Second: 10,663.93864

Timestep Collection Time: 2.19606
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.69283

Cumulative Model Updates: 156,836
Cumulative Timesteps: 1,308,060,150

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252.68299
Policy Entropy: 3.04399
Value Function Loss: 0.00423

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.59070
Value Function Update Magnitude: 0.55162

Collected Steps per Second: 22,675.79555
Overall Steps per Second: 10,680.99511

Timestep Collection Time: 2.20614
Timestep Consumption Time: 2.47751
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.68365

Cumulative Model Updates: 156,842
Cumulative Timesteps: 1,308,110,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1308110176...
Checkpoint 1308110176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,413.35912
Policy Entropy: 3.04419
Value Function Loss: 0.00414

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.58437
Value Function Update Magnitude: 0.53512

Collected Steps per Second: 22,762.35367
Overall Steps per Second: 10,787.43046

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.43978
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.63762

Cumulative Model Updates: 156,848
Cumulative Timesteps: 1,308,160,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.05860
Policy Entropy: 3.04860
Value Function Loss: 0.00433

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10230
Policy Update Magnitude: 0.58182
Value Function Update Magnitude: 0.51104

Collected Steps per Second: 23,258.60939
Overall Steps per Second: 10,657.54527

Timestep Collection Time: 2.15052
Timestep Consumption Time: 2.54269
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.69320

Cumulative Model Updates: 156,854
Cumulative Timesteps: 1,308,210,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1308210222...
Checkpoint 1308210222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.86679
Policy Entropy: 3.04544
Value Function Loss: 0.00462

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.52301

Collected Steps per Second: 23,255.74584
Overall Steps per Second: 10,894.14502

Timestep Collection Time: 2.15112
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59201

Cumulative Model Updates: 156,860
Cumulative Timesteps: 1,308,260,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,895.16503
Policy Entropy: 3.04658
Value Function Loss: 0.00465

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.58708
Value Function Update Magnitude: 0.53959

Collected Steps per Second: 22,991.63553
Overall Steps per Second: 10,746.61116

Timestep Collection Time: 2.17488
Timestep Consumption Time: 2.47812
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.65300

Cumulative Model Updates: 156,866
Cumulative Timesteps: 1,308,310,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1308310252...
Checkpoint 1308310252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,706.07606
Policy Entropy: 3.05842
Value Function Loss: 0.00409

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.57760
Value Function Update Magnitude: 0.51470

Collected Steps per Second: 23,257.25226
Overall Steps per Second: 10,918.32586

Timestep Collection Time: 2.15047
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.58074

Cumulative Model Updates: 156,872
Cumulative Timesteps: 1,308,360,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,581.84828
Policy Entropy: 3.06183
Value Function Loss: 0.00390

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.56482
Value Function Update Magnitude: 0.51608

Collected Steps per Second: 23,226.44517
Overall Steps per Second: 10,897.98760

Timestep Collection Time: 2.15392
Timestep Consumption Time: 2.43665
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59057

Cumulative Model Updates: 156,878
Cumulative Timesteps: 1,308,410,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1308410294...
Checkpoint 1308410294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.61824
Policy Entropy: 3.05113
Value Function Loss: 0.00412

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.50052

Collected Steps per Second: 23,010.26672
Overall Steps per Second: 10,688.69818

Timestep Collection Time: 2.17399
Timestep Consumption Time: 2.50610
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.68008

Cumulative Model Updates: 156,884
Cumulative Timesteps: 1,308,460,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.75324
Policy Entropy: 3.04410
Value Function Loss: 0.00443

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12064
Policy Update Magnitude: 0.58206
Value Function Update Magnitude: 0.47976

Collected Steps per Second: 22,647.21562
Overall Steps per Second: 10,778.95040

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63997

Cumulative Model Updates: 156,890
Cumulative Timesteps: 1,308,510,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1308510332...
Checkpoint 1308510332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,976.71472
Policy Entropy: 3.01554
Value Function Loss: 0.00451

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.57315
Value Function Update Magnitude: 0.49608

Collected Steps per Second: 22,519.92638
Overall Steps per Second: 10,721.71357

Timestep Collection Time: 2.22177
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.66660

Cumulative Model Updates: 156,896
Cumulative Timesteps: 1,308,560,366

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,705.82536
Policy Entropy: 3.01220
Value Function Loss: 0.00425

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.57541
Value Function Update Magnitude: 0.51414

Collected Steps per Second: 23,034.19568
Overall Steps per Second: 10,923.38774

Timestep Collection Time: 2.17121
Timestep Consumption Time: 2.40723
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.57843

Cumulative Model Updates: 156,902
Cumulative Timesteps: 1,308,610,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1308610378...
Checkpoint 1308610378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,629.48310
Policy Entropy: 3.00778
Value Function Loss: 0.00433

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.58397
Value Function Update Magnitude: 0.53016

Collected Steps per Second: 23,255.40943
Overall Steps per Second: 10,789.50676

Timestep Collection Time: 2.15012
Timestep Consumption Time: 2.48419
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.63432

Cumulative Model Updates: 156,908
Cumulative Timesteps: 1,308,660,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.06487
Policy Entropy: 3.01180
Value Function Loss: 0.00441

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.58300
Value Function Update Magnitude: 0.51468

Collected Steps per Second: 23,185.93088
Overall Steps per Second: 10,672.97222

Timestep Collection Time: 2.15683
Timestep Consumption Time: 2.52866
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.68548

Cumulative Model Updates: 156,914
Cumulative Timesteps: 1,308,710,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1308710388...
Checkpoint 1308710388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,882.44185
Policy Entropy: 3.00091
Value Function Loss: 0.00446

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.59048
Value Function Update Magnitude: 0.53237

Collected Steps per Second: 22,965.60934
Overall Steps per Second: 10,683.18683

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.50418
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.68231

Cumulative Model Updates: 156,920
Cumulative Timesteps: 1,308,760,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.42588
Policy Entropy: 3.01519
Value Function Loss: 0.00463

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.61122
Value Function Update Magnitude: 0.55204

Collected Steps per Second: 23,459.72947
Overall Steps per Second: 10,914.56053

Timestep Collection Time: 2.13216
Timestep Consumption Time: 2.45070
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.58287

Cumulative Model Updates: 156,926
Cumulative Timesteps: 1,308,810,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1308810430...
Checkpoint 1308810430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.38193
Policy Entropy: 3.00673
Value Function Loss: 0.00464

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.62357
Value Function Update Magnitude: 0.55788

Collected Steps per Second: 23,197.05281
Overall Steps per Second: 10,782.87772

Timestep Collection Time: 2.15579
Timestep Consumption Time: 2.48193
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.63772

Cumulative Model Updates: 156,932
Cumulative Timesteps: 1,308,860,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.69284
Policy Entropy: 3.02680
Value Function Loss: 0.00475

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.62460
Value Function Update Magnitude: 0.58133

Collected Steps per Second: 23,338.67303
Overall Steps per Second: 10,829.84898

Timestep Collection Time: 2.14357
Timestep Consumption Time: 2.47589
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.61946

Cumulative Model Updates: 156,938
Cumulative Timesteps: 1,308,910,466

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1308910466...
Checkpoint 1308910466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.01501
Policy Entropy: 3.01315
Value Function Loss: 0.00395

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.60464
Value Function Update Magnitude: 0.58887

Collected Steps per Second: 22,614.18617
Overall Steps per Second: 10,621.25258

Timestep Collection Time: 2.21118
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.70792

Cumulative Model Updates: 156,944
Cumulative Timesteps: 1,308,960,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.94243
Policy Entropy: 3.02148
Value Function Loss: 0.00388

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.58733
Value Function Update Magnitude: 0.53779

Collected Steps per Second: 22,862.25173
Overall Steps per Second: 10,850.41011

Timestep Collection Time: 2.18824
Timestep Consumption Time: 2.42247
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61070

Cumulative Model Updates: 156,950
Cumulative Timesteps: 1,309,010,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1309010498...
Checkpoint 1309010498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.26604
Policy Entropy: 3.02204
Value Function Loss: 0.00425

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.57392
Value Function Update Magnitude: 0.49975

Collected Steps per Second: 22,763.68972
Overall Steps per Second: 10,691.19866

Timestep Collection Time: 2.19815
Timestep Consumption Time: 2.48215
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.68030

Cumulative Model Updates: 156,956
Cumulative Timesteps: 1,309,060,536

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803.56492
Policy Entropy: 3.03018
Value Function Loss: 0.00443

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.57077
Value Function Update Magnitude: 0.50391

Collected Steps per Second: 23,348.57731
Overall Steps per Second: 10,869.85880

Timestep Collection Time: 2.14249
Timestep Consumption Time: 2.45960
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.60208

Cumulative Model Updates: 156,962
Cumulative Timesteps: 1,309,110,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1309110560...
Checkpoint 1309110560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085.91791
Policy Entropy: 3.03315
Value Function Loss: 0.00427

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.56520
Value Function Update Magnitude: 0.50781

Collected Steps per Second: 23,111.80484
Overall Steps per Second: 10,725.34247

Timestep Collection Time: 2.16340
Timestep Consumption Time: 2.49846
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.66186

Cumulative Model Updates: 156,968
Cumulative Timesteps: 1,309,160,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.44135
Policy Entropy: 3.01992
Value Function Loss: 0.00441

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.57614
Value Function Update Magnitude: 0.50522

Collected Steps per Second: 23,399.84922
Overall Steps per Second: 10,809.77500

Timestep Collection Time: 2.13736
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.62674

Cumulative Model Updates: 156,974
Cumulative Timesteps: 1,309,210,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1309210574...
Checkpoint 1309210574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.59272
Policy Entropy: 3.02168
Value Function Loss: 0.00435

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.58091
Value Function Update Magnitude: 0.51251

Collected Steps per Second: 23,371.66038
Overall Steps per Second: 11,021.07844

Timestep Collection Time: 2.13994
Timestep Consumption Time: 2.39809
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.53803

Cumulative Model Updates: 156,980
Cumulative Timesteps: 1,309,260,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,893.23473
Policy Entropy: 3.01780
Value Function Loss: 0.00417

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.52177

Collected Steps per Second: 23,106.01028
Overall Steps per Second: 10,747.50006

Timestep Collection Time: 2.16463
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.65373

Cumulative Model Updates: 156,986
Cumulative Timesteps: 1,309,310,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1309310604...
Checkpoint 1309310604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,727.29789
Policy Entropy: 3.02552
Value Function Loss: 0.00381

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.56929
Value Function Update Magnitude: 0.51287

Collected Steps per Second: 23,067.89964
Overall Steps per Second: 10,864.22092

Timestep Collection Time: 2.16769
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.60263

Cumulative Model Updates: 156,992
Cumulative Timesteps: 1,309,360,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.73385
Policy Entropy: 3.00762
Value Function Loss: 0.00405

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.57935
Value Function Update Magnitude: 0.52997

Collected Steps per Second: 22,806.96914
Overall Steps per Second: 10,858.83431

Timestep Collection Time: 2.19284
Timestep Consumption Time: 2.41281
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60565

Cumulative Model Updates: 156,998
Cumulative Timesteps: 1,309,410,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1309410620...
Checkpoint 1309410620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.32068
Policy Entropy: 2.99241
Value Function Loss: 0.00441

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.60020
Value Function Update Magnitude: 0.55531

Collected Steps per Second: 22,885.99124
Overall Steps per Second: 10,712.92089

Timestep Collection Time: 2.18474
Timestep Consumption Time: 2.48252
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.66726

Cumulative Model Updates: 157,004
Cumulative Timesteps: 1,309,460,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.87722
Policy Entropy: 2.97897
Value Function Loss: 0.00442

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.59885
Value Function Update Magnitude: 0.56187

Collected Steps per Second: 22,684.96746
Overall Steps per Second: 10,849.55349

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.60996

Cumulative Model Updates: 157,010
Cumulative Timesteps: 1,309,510,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1309510636...
Checkpoint 1309510636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,349.68687
Policy Entropy: 2.98444
Value Function Loss: 0.00411

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.59305
Value Function Update Magnitude: 0.55109

Collected Steps per Second: 23,097.73792
Overall Steps per Second: 10,745.96412

Timestep Collection Time: 2.16506
Timestep Consumption Time: 2.48859
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.65365

Cumulative Model Updates: 157,016
Cumulative Timesteps: 1,309,560,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.95223
Policy Entropy: 2.98389
Value Function Loss: 0.00415

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.59063
Value Function Update Magnitude: 0.52309

Collected Steps per Second: 23,139.97725
Overall Steps per Second: 10,760.24883

Timestep Collection Time: 2.16215
Timestep Consumption Time: 2.48756
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.64971

Cumulative Model Updates: 157,022
Cumulative Timesteps: 1,309,610,676

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1309610676...
Checkpoint 1309610676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.21751
Policy Entropy: 2.97871
Value Function Loss: 0.00442

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.59198
Value Function Update Magnitude: 0.54444

Collected Steps per Second: 23,098.29816
Overall Steps per Second: 10,748.29115

Timestep Collection Time: 2.16492
Timestep Consumption Time: 2.48754
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.65246

Cumulative Model Updates: 157,028
Cumulative Timesteps: 1,309,660,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,938.96168
Policy Entropy: 2.98371
Value Function Loss: 0.00443

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.59569
Value Function Update Magnitude: 0.55377

Collected Steps per Second: 21,924.68957
Overall Steps per Second: 10,491.65049

Timestep Collection Time: 2.28053
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.76569

Cumulative Model Updates: 157,034
Cumulative Timesteps: 1,309,710,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1309710682...
Checkpoint 1309710682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,324.76433
Policy Entropy: 2.99173
Value Function Loss: 0.00445

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.60406
Value Function Update Magnitude: 0.56224

Collected Steps per Second: 22,949.34095
Overall Steps per Second: 10,699.36061

Timestep Collection Time: 2.17889
Timestep Consumption Time: 2.49466
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.67355

Cumulative Model Updates: 157,040
Cumulative Timesteps: 1,309,760,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.93873
Policy Entropy: 2.97473
Value Function Loss: 0.00449

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.59531
Value Function Update Magnitude: 0.55074

Collected Steps per Second: 23,203.82462
Overall Steps per Second: 10,800.03393

Timestep Collection Time: 2.15697
Timestep Consumption Time: 2.47727
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.63424

Cumulative Model Updates: 157,046
Cumulative Timesteps: 1,309,810,736

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1309810736...
Checkpoint 1309810736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.91890
Policy Entropy: 2.96428
Value Function Loss: 0.00430

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.59324
Value Function Update Magnitude: 0.52430

Collected Steps per Second: 23,205.76564
Overall Steps per Second: 10,742.55610

Timestep Collection Time: 2.15550
Timestep Consumption Time: 2.50075
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.65625

Cumulative Model Updates: 157,052
Cumulative Timesteps: 1,309,860,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.39183
Policy Entropy: 2.96381
Value Function Loss: 0.00441

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.59202
Value Function Update Magnitude: 0.49735

Collected Steps per Second: 23,194.81385
Overall Steps per Second: 10,803.66049

Timestep Collection Time: 2.15634
Timestep Consumption Time: 2.47320
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.62954

Cumulative Model Updates: 157,058
Cumulative Timesteps: 1,309,910,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1309910772...
Checkpoint 1309910772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.44821
Policy Entropy: 2.96473
Value Function Loss: 0.00475

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11708
Policy Update Magnitude: 0.59719
Value Function Update Magnitude: 0.49537

Collected Steps per Second: 23,138.41268
Overall Steps per Second: 10,714.77605

Timestep Collection Time: 2.16134
Timestep Consumption Time: 2.50605
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.66739

Cumulative Model Updates: 157,064
Cumulative Timesteps: 1,309,960,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.60130
Policy Entropy: 2.96404
Value Function Loss: 0.00513

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.60564
Value Function Update Magnitude: 0.52017

Collected Steps per Second: 23,143.52580
Overall Steps per Second: 10,884.92973

Timestep Collection Time: 2.16190
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.59663

Cumulative Model Updates: 157,070
Cumulative Timesteps: 1,310,010,816

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1310010816...
Checkpoint 1310010816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,552.49068
Policy Entropy: 2.96618
Value Function Loss: 0.00472

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.60374
Value Function Update Magnitude: 0.53973

Collected Steps per Second: 23,003.28729
Overall Steps per Second: 10,715.94375

Timestep Collection Time: 2.17404
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.66688

Cumulative Model Updates: 157,076
Cumulative Timesteps: 1,310,060,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.02370
Policy Entropy: 2.97292
Value Function Loss: 0.00444

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.59449
Value Function Update Magnitude: 0.53095

Collected Steps per Second: 23,385.77906
Overall Steps per Second: 10,830.50946

Timestep Collection Time: 2.13805
Timestep Consumption Time: 2.47854
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.61659

Cumulative Model Updates: 157,082
Cumulative Timesteps: 1,310,110,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1310110826...
Checkpoint 1310110826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.96617
Policy Entropy: 2.98236
Value Function Loss: 0.00458

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.60119
Value Function Update Magnitude: 0.53322

Collected Steps per Second: 22,922.86203
Overall Steps per Second: 10,792.15622

Timestep Collection Time: 2.18140
Timestep Consumption Time: 2.45196
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.63337

Cumulative Model Updates: 157,088
Cumulative Timesteps: 1,310,160,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943.04053
Policy Entropy: 2.97155
Value Function Loss: 0.00486

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.62211
Value Function Update Magnitude: 0.56247

Collected Steps per Second: 23,128.57235
Overall Steps per Second: 10,746.33893

Timestep Collection Time: 2.16313
Timestep Consumption Time: 2.49241
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.65554

Cumulative Model Updates: 157,094
Cumulative Timesteps: 1,310,210,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1310210860...
Checkpoint 1310210860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.05813
Policy Entropy: 2.97033
Value Function Loss: 0.00505

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.63094
Value Function Update Magnitude: 0.58548

Collected Steps per Second: 22,744.21934
Overall Steps per Second: 10,601.05242

Timestep Collection Time: 2.19915
Timestep Consumption Time: 2.51906
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.71821

Cumulative Model Updates: 157,100
Cumulative Timesteps: 1,310,260,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,887.98238
Policy Entropy: 2.97083
Value Function Loss: 0.00457

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.61821
Value Function Update Magnitude: 0.58587

Collected Steps per Second: 22,760.12106
Overall Steps per Second: 10,666.16377

Timestep Collection Time: 2.19770
Timestep Consumption Time: 2.49189
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.68960

Cumulative Model Updates: 157,106
Cumulative Timesteps: 1,310,310,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1310310898...
Checkpoint 1310310898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.23073
Policy Entropy: 2.97475
Value Function Loss: 0.00465

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.60862
Value Function Update Magnitude: 0.56371

Collected Steps per Second: 22,710.43443
Overall Steps per Second: 10,832.96498

Timestep Collection Time: 2.20304
Timestep Consumption Time: 2.41546
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.61850

Cumulative Model Updates: 157,112
Cumulative Timesteps: 1,310,360,930

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,148.19458
Policy Entropy: 2.99274
Value Function Loss: 0.00441

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.60673
Value Function Update Magnitude: 0.54122

Collected Steps per Second: 23,331.37887
Overall Steps per Second: 10,947.55518

Timestep Collection Time: 2.14364
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.56851

Cumulative Model Updates: 157,118
Cumulative Timesteps: 1,310,410,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1310410944...
Checkpoint 1310410944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,281.97627
Policy Entropy: 2.99429
Value Function Loss: 0.00438

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.59624
Value Function Update Magnitude: 0.53552

Collected Steps per Second: 23,201.84216
Overall Steps per Second: 10,714.73007

Timestep Collection Time: 2.15612
Timestep Consumption Time: 2.51278
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.66890

Cumulative Model Updates: 157,124
Cumulative Timesteps: 1,310,460,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,406.95949
Policy Entropy: 3.00908
Value Function Loss: 0.00417

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.59172
Value Function Update Magnitude: 0.53769

Collected Steps per Second: 23,225.15503
Overall Steps per Second: 10,914.67990

Timestep Collection Time: 2.15310
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.58154

Cumulative Model Updates: 157,130
Cumulative Timesteps: 1,310,510,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1310510976...
Checkpoint 1310510976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.84653
Policy Entropy: 2.99958
Value Function Loss: 0.00434

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.59131
Value Function Update Magnitude: 0.54221

Collected Steps per Second: 23,196.24088
Overall Steps per Second: 10,803.70286

Timestep Collection Time: 2.15604
Timestep Consumption Time: 2.47311
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.62915

Cumulative Model Updates: 157,136
Cumulative Timesteps: 1,310,560,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.32955
Policy Entropy: 3.01481
Value Function Loss: 0.00424

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.58848
Value Function Update Magnitude: 0.54939

Collected Steps per Second: 23,094.76501
Overall Steps per Second: 10,741.66298

Timestep Collection Time: 2.16534
Timestep Consumption Time: 2.49018
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.65552

Cumulative Model Updates: 157,142
Cumulative Timesteps: 1,310,610,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1310610996...
Checkpoint 1310610996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,725.04541
Policy Entropy: 2.99173
Value Function Loss: 0.00459

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.59792
Value Function Update Magnitude: 0.55672

Collected Steps per Second: 23,125.28057
Overall Steps per Second: 10,977.13998

Timestep Collection Time: 2.16231
Timestep Consumption Time: 2.39298
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.55528

Cumulative Model Updates: 157,148
Cumulative Timesteps: 1,310,661,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.48977
Policy Entropy: 3.00210
Value Function Loss: 0.00428

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.60249
Value Function Update Magnitude: 0.53747

Collected Steps per Second: 22,439.42144
Overall Steps per Second: 10,563.17945

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.50540
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.73380

Cumulative Model Updates: 157,154
Cumulative Timesteps: 1,310,711,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1310711004...
Checkpoint 1310711004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,680.34864
Policy Entropy: 2.98451
Value Function Loss: 0.00431

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.58791
Value Function Update Magnitude: 0.51876

Collected Steps per Second: 22,713.79591
Overall Steps per Second: 10,640.25135

Timestep Collection Time: 2.20210
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.70083

Cumulative Model Updates: 157,160
Cumulative Timesteps: 1,310,761,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,162.75216
Policy Entropy: 2.99605
Value Function Loss: 0.00441

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.60074
Value Function Update Magnitude: 0.53027

Collected Steps per Second: 22,780.28511
Overall Steps per Second: 10,811.54129

Timestep Collection Time: 2.19567
Timestep Consumption Time: 2.43068
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62635

Cumulative Model Updates: 157,166
Cumulative Timesteps: 1,310,811,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1310811040...
Checkpoint 1310811040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,634.72003
Policy Entropy: 2.96765
Value Function Loss: 0.00494

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.61875
Value Function Update Magnitude: 0.55762

Collected Steps per Second: 22,582.60605
Overall Steps per Second: 10,678.25647

Timestep Collection Time: 2.21542
Timestep Consumption Time: 2.46980
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.68522

Cumulative Model Updates: 157,172
Cumulative Timesteps: 1,310,861,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,403.63984
Policy Entropy: 2.95554
Value Function Loss: 0.00496

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.14604
Policy Update Magnitude: 0.63317
Value Function Update Magnitude: 0.57717

Collected Steps per Second: 23,038.89808
Overall Steps per Second: 10,853.62206

Timestep Collection Time: 2.17128
Timestep Consumption Time: 2.43768
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.60897

Cumulative Model Updates: 157,178
Cumulative Timesteps: 1,310,911,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1310911094...
Checkpoint 1310911094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.51666
Policy Entropy: 2.95896
Value Function Loss: 0.00513

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.63026
Value Function Update Magnitude: 0.58463

Collected Steps per Second: 23,141.20047
Overall Steps per Second: 10,785.83249

Timestep Collection Time: 2.16099
Timestep Consumption Time: 2.47546
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.63645

Cumulative Model Updates: 157,184
Cumulative Timesteps: 1,310,961,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948.43365
Policy Entropy: 2.97594
Value Function Loss: 0.00516

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.63236
Value Function Update Magnitude: 0.57597

Collected Steps per Second: 23,138.20362
Overall Steps per Second: 10,849.33391

Timestep Collection Time: 2.16222
Timestep Consumption Time: 2.44912
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.61134

Cumulative Model Updates: 157,190
Cumulative Timesteps: 1,311,011,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1311011132...
Checkpoint 1311011132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.69461
Policy Entropy: 2.95966
Value Function Loss: 0.00552

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.62709
Value Function Update Magnitude: 0.56538

Collected Steps per Second: 23,270.21855
Overall Steps per Second: 10,979.56191

Timestep Collection Time: 2.14918
Timestep Consumption Time: 2.40582
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.55501

Cumulative Model Updates: 157,196
Cumulative Timesteps: 1,311,061,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.96704
Policy Entropy: 2.96839
Value Function Loss: 0.00507

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.61907
Value Function Update Magnitude: 0.58234

Collected Steps per Second: 23,306.98900
Overall Steps per Second: 10,968.47526

Timestep Collection Time: 2.14562
Timestep Consumption Time: 2.41363
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.55925

Cumulative Model Updates: 157,202
Cumulative Timesteps: 1,311,111,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1311111152...
Checkpoint 1311111152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022.11675
Policy Entropy: 2.95644
Value Function Loss: 0.00510

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.62321
Value Function Update Magnitude: 0.56842

Collected Steps per Second: 23,157.55579
Overall Steps per Second: 10,809.90580

Timestep Collection Time: 2.15964
Timestep Consumption Time: 2.46686
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.62650

Cumulative Model Updates: 157,208
Cumulative Timesteps: 1,311,161,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.54842
Policy Entropy: 2.98226
Value Function Loss: 0.00486

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.62926
Value Function Update Magnitude: 0.57121

Collected Steps per Second: 22,898.18704
Overall Steps per Second: 10,816.50933

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.62349

Cumulative Model Updates: 157,214
Cumulative Timesteps: 1,311,211,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1311211174...
Checkpoint 1311211174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.67900
Policy Entropy: 2.98482
Value Function Loss: 0.00482

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11162
Policy Update Magnitude: 0.62341
Value Function Update Magnitude: 0.56705

Collected Steps per Second: 22,702.70221
Overall Steps per Second: 10,607.85581

Timestep Collection Time: 2.20238
Timestep Consumption Time: 2.51111
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.71349

Cumulative Model Updates: 157,220
Cumulative Timesteps: 1,311,261,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.92287
Policy Entropy: 2.97275
Value Function Loss: 0.00460

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.61491
Value Function Update Magnitude: 0.55657

Collected Steps per Second: 22,513.83991
Overall Steps per Second: 10,599.17775

Timestep Collection Time: 2.22174
Timestep Consumption Time: 2.49749
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.71923

Cumulative Model Updates: 157,226
Cumulative Timesteps: 1,311,311,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1311311194...
Checkpoint 1311311194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.96994
Policy Entropy: 2.97271
Value Function Loss: 0.00445

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.61054
Value Function Update Magnitude: 0.52960

Collected Steps per Second: 22,790.67650
Overall Steps per Second: 10,897.35409

Timestep Collection Time: 2.19406
Timestep Consumption Time: 2.39458
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.58864

Cumulative Model Updates: 157,232
Cumulative Timesteps: 1,311,361,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.28380
Policy Entropy: 2.98583
Value Function Loss: 0.00435

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11644
Policy Update Magnitude: 0.60859
Value Function Update Magnitude: 0.51481

Collected Steps per Second: 23,021.94760
Overall Steps per Second: 10,780.93477

Timestep Collection Time: 2.17210
Timestep Consumption Time: 2.46627
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.63837

Cumulative Model Updates: 157,238
Cumulative Timesteps: 1,311,411,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1311411204...
Checkpoint 1311411204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.54884
Policy Entropy: 3.00404
Value Function Loss: 0.00492

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.61761
Value Function Update Magnitude: 0.52557

Collected Steps per Second: 23,119.81152
Overall Steps per Second: 10,823.51625

Timestep Collection Time: 2.16282
Timestep Consumption Time: 2.45712
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.61994

Cumulative Model Updates: 157,244
Cumulative Timesteps: 1,311,461,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.54316
Policy Entropy: 2.99859
Value Function Loss: 0.00510

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.62647
Value Function Update Magnitude: 0.56440

Collected Steps per Second: 23,032.23172
Overall Steps per Second: 10,945.93844

Timestep Collection Time: 2.17104
Timestep Consumption Time: 2.39723
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.56827

Cumulative Model Updates: 157,250
Cumulative Timesteps: 1,311,511,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1311511212...
Checkpoint 1311511212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.15930
Policy Entropy: 3.00466
Value Function Loss: 0.00489

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.62103
Value Function Update Magnitude: 0.57272

Collected Steps per Second: 23,147.93387
Overall Steps per Second: 10,766.01863

Timestep Collection Time: 2.16054
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.64536

Cumulative Model Updates: 157,256
Cumulative Timesteps: 1,311,561,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.62136
Policy Entropy: 3.01252
Value Function Loss: 0.00486

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.60580
Value Function Update Magnitude: 0.56117

Collected Steps per Second: 22,778.24850
Overall Steps per Second: 10,684.00355

Timestep Collection Time: 2.19543
Timestep Consumption Time: 2.48521
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.68064

Cumulative Model Updates: 157,262
Cumulative Timesteps: 1,311,611,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1311611232...
Checkpoint 1311611232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.47355
Policy Entropy: 3.01942
Value Function Loss: 0.00459

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.59909
Value Function Update Magnitude: 0.54125

Collected Steps per Second: 22,931.21991
Overall Steps per Second: 10,686.50015

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.49897
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.67992

Cumulative Model Updates: 157,268
Cumulative Timesteps: 1,311,661,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.51823
Policy Entropy: 3.01990
Value Function Loss: 0.00453

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.60865
Value Function Update Magnitude: 0.54865

Collected Steps per Second: 22,641.45033
Overall Steps per Second: 10,632.73240

Timestep Collection Time: 2.20913
Timestep Consumption Time: 2.49502
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.70415

Cumulative Model Updates: 157,274
Cumulative Timesteps: 1,311,711,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1311711262...
Checkpoint 1311711262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.27422
Policy Entropy: 3.02633
Value Function Loss: 0.00441

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.60703
Value Function Update Magnitude: 0.56562

Collected Steps per Second: 22,930.13091
Overall Steps per Second: 10,918.99067

Timestep Collection Time: 2.18115
Timestep Consumption Time: 2.39931
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.58046

Cumulative Model Updates: 157,280
Cumulative Timesteps: 1,311,761,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.22199
Policy Entropy: 3.01961
Value Function Loss: 0.00430

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.60873
Value Function Update Magnitude: 0.56389

Collected Steps per Second: 22,966.32980
Overall Steps per Second: 10,833.10372

Timestep Collection Time: 2.17736
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61604

Cumulative Model Updates: 157,286
Cumulative Timesteps: 1,311,811,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1311811282...
Checkpoint 1311811282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.72262
Policy Entropy: 3.00376
Value Function Loss: 0.00432

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.60537
Value Function Update Magnitude: 0.54820

Collected Steps per Second: 22,679.07307
Overall Steps per Second: 10,680.62497

Timestep Collection Time: 2.20565
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.68343

Cumulative Model Updates: 157,292
Cumulative Timesteps: 1,311,861,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,856.58417
Policy Entropy: 2.98564
Value Function Loss: 0.00464

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11780
Policy Update Magnitude: 0.60587
Value Function Update Magnitude: 0.55526

Collected Steps per Second: 22,965.10289
Overall Steps per Second: 10,628.37675

Timestep Collection Time: 2.17844
Timestep Consumption Time: 2.52859
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.70702

Cumulative Model Updates: 157,298
Cumulative Timesteps: 1,311,911,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1311911332...
Checkpoint 1311911332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.47322
Policy Entropy: 2.97753
Value Function Loss: 0.00475

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.61683
Value Function Update Magnitude: 0.56943

Collected Steps per Second: 23,140.49908
Overall Steps per Second: 10,923.82539

Timestep Collection Time: 2.16166
Timestep Consumption Time: 2.41750
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.57917

Cumulative Model Updates: 157,304
Cumulative Timesteps: 1,311,961,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.89746
Policy Entropy: 2.96583
Value Function Loss: 0.00478

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.61109
Value Function Update Magnitude: 0.56781

Collected Steps per Second: 23,444.41830
Overall Steps per Second: 10,970.05353

Timestep Collection Time: 2.13270
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.55786

Cumulative Model Updates: 157,310
Cumulative Timesteps: 1,312,011,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1312011354...
Checkpoint 1312011354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.11352
Policy Entropy: 2.97716
Value Function Loss: 0.00470

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.60396
Value Function Update Magnitude: 0.54689

Collected Steps per Second: 23,159.60145
Overall Steps per Second: 10,855.32628

Timestep Collection Time: 2.16014
Timestep Consumption Time: 2.44847
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.60861

Cumulative Model Updates: 157,316
Cumulative Timesteps: 1,312,061,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.84887
Policy Entropy: 2.97464
Value Function Loss: 0.00448

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.60474
Value Function Update Magnitude: 0.53213

Collected Steps per Second: 23,041.45768
Overall Steps per Second: 10,811.43835

Timestep Collection Time: 2.17200
Timestep Consumption Time: 2.45699
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.62899

Cumulative Model Updates: 157,322
Cumulative Timesteps: 1,312,111,428

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1312111428...
Checkpoint 1312111428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,454.37449
Policy Entropy: 2.98324
Value Function Loss: 0.00425

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.60933
Value Function Update Magnitude: 0.53446

Collected Steps per Second: 23,346.04299
Overall Steps per Second: 10,944.54889

Timestep Collection Time: 2.14186
Timestep Consumption Time: 2.42699
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.56885

Cumulative Model Updates: 157,328
Cumulative Timesteps: 1,312,161,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.19957
Policy Entropy: 2.96820
Value Function Loss: 0.00448

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.61242
Value Function Update Magnitude: 0.52722

Collected Steps per Second: 22,685.03208
Overall Steps per Second: 10,643.26746

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.69837

Cumulative Model Updates: 157,334
Cumulative Timesteps: 1,312,211,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1312211438...
Checkpoint 1312211438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.34877
Policy Entropy: 2.97123
Value Function Loss: 0.00444

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.61658
Value Function Update Magnitude: 0.54888

Collected Steps per Second: 22,698.41000
Overall Steps per Second: 10,704.42690

Timestep Collection Time: 2.20306
Timestep Consumption Time: 2.46846
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.67153

Cumulative Model Updates: 157,340
Cumulative Timesteps: 1,312,261,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.35902
Policy Entropy: 2.95339
Value Function Loss: 0.00470

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.62393
Value Function Update Magnitude: 0.56204

Collected Steps per Second: 22,923.67540
Overall Steps per Second: 10,714.99836

Timestep Collection Time: 2.18133
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.66673

Cumulative Model Updates: 157,346
Cumulative Timesteps: 1,312,311,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1312311448...
Checkpoint 1312311448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.48035
Policy Entropy: 2.97063
Value Function Loss: 0.00466

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.62534
Value Function Update Magnitude: 0.57236

Collected Steps per Second: 22,737.86622
Overall Steps per Second: 10,724.60515

Timestep Collection Time: 2.19968
Timestep Consumption Time: 2.46399
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.66367

Cumulative Model Updates: 157,352
Cumulative Timesteps: 1,312,361,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.31036
Policy Entropy: 2.97553
Value Function Loss: 0.00502

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.63206
Value Function Update Magnitude: 0.57799

Collected Steps per Second: 23,228.24493
Overall Steps per Second: 10,820.95780

Timestep Collection Time: 2.15333
Timestep Consumption Time: 2.46900
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.62233

Cumulative Model Updates: 157,358
Cumulative Timesteps: 1,312,411,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1312411482...
Checkpoint 1312411482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,400.31690
Policy Entropy: 2.96931
Value Function Loss: 0.00526

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.63859
Value Function Update Magnitude: 0.58804

Collected Steps per Second: 23,194.27314
Overall Steps per Second: 10,760.94961

Timestep Collection Time: 2.15588
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.64680

Cumulative Model Updates: 157,364
Cumulative Timesteps: 1,312,461,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.76030
Policy Entropy: 2.97202
Value Function Loss: 0.00538

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.63916
Value Function Update Magnitude: 0.60050

Collected Steps per Second: 23,353.86301
Overall Steps per Second: 10,784.40966

Timestep Collection Time: 2.14114
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.63669

Cumulative Model Updates: 157,370
Cumulative Timesteps: 1,312,511,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1312511490...
Checkpoint 1312511490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,836.22675
Policy Entropy: 2.98973
Value Function Loss: 0.00523

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.61967
Value Function Update Magnitude: 0.58823

Collected Steps per Second: 23,300.93650
Overall Steps per Second: 10,976.24807

Timestep Collection Time: 2.14635
Timestep Consumption Time: 2.41003
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.55638

Cumulative Model Updates: 157,376
Cumulative Timesteps: 1,312,561,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,620.20577
Policy Entropy: 3.01697
Value Function Loss: 0.00483

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.60346
Value Function Update Magnitude: 0.57325

Collected Steps per Second: 23,174.41054
Overall Steps per Second: 10,881.27209

Timestep Collection Time: 2.15833
Timestep Consumption Time: 2.43838
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59671

Cumulative Model Updates: 157,382
Cumulative Timesteps: 1,312,611,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1312611520...
Checkpoint 1312611520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.53413
Policy Entropy: 3.01189
Value Function Loss: 0.00487

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.59683
Value Function Update Magnitude: 0.56057

Collected Steps per Second: 23,387.38923
Overall Steps per Second: 10,729.05080

Timestep Collection Time: 2.13790
Timestep Consumption Time: 2.52234
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.66024

Cumulative Model Updates: 157,388
Cumulative Timesteps: 1,312,661,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.08859
Policy Entropy: 2.98763
Value Function Loss: 0.00442

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.58582
Value Function Update Magnitude: 0.53718

Collected Steps per Second: 22,638.48194
Overall Steps per Second: 10,631.58736

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.49554
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.70522

Cumulative Model Updates: 157,394
Cumulative Timesteps: 1,312,711,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1312711544...
Checkpoint 1312711544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.88778
Policy Entropy: 2.99349
Value Function Loss: 0.00443

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.57950
Value Function Update Magnitude: 0.51028

Collected Steps per Second: 22,884.78487
Overall Steps per Second: 10,869.24189

Timestep Collection Time: 2.18591
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60234

Cumulative Model Updates: 157,400
Cumulative Timesteps: 1,312,761,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.04916
Policy Entropy: 3.00801
Value Function Loss: 0.00402

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.57584
Value Function Update Magnitude: 0.50304

Collected Steps per Second: 22,575.76672
Overall Steps per Second: 10,556.02827

Timestep Collection Time: 2.21574
Timestep Consumption Time: 2.52298
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.73871

Cumulative Model Updates: 157,406
Cumulative Timesteps: 1,312,811,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1312811590...
Checkpoint 1312811590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.59662
Policy Entropy: 3.00640
Value Function Loss: 0.00406

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.57722
Value Function Update Magnitude: 0.49482

Collected Steps per Second: 22,440.82256
Overall Steps per Second: 10,606.85034

Timestep Collection Time: 2.22915
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.71620

Cumulative Model Updates: 157,412
Cumulative Timesteps: 1,312,861,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,619.97328
Policy Entropy: 2.97781
Value Function Loss: 0.00444

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11916
Policy Update Magnitude: 0.59318
Value Function Update Magnitude: 0.51758

Collected Steps per Second: 22,890.64270
Overall Steps per Second: 10,650.08622

Timestep Collection Time: 2.18509
Timestep Consumption Time: 2.51140
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.69649

Cumulative Model Updates: 157,418
Cumulative Timesteps: 1,312,911,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1312911632...
Checkpoint 1312911632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.58422
Policy Entropy: 2.97799
Value Function Loss: 0.00475

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.61179
Value Function Update Magnitude: 0.54650

Collected Steps per Second: 23,043.37221
Overall Steps per Second: 10,841.83409

Timestep Collection Time: 2.16991
Timestep Consumption Time: 2.44204
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.61195

Cumulative Model Updates: 157,424
Cumulative Timesteps: 1,312,961,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.57218
Policy Entropy: 2.98698
Value Function Loss: 0.00484

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11645
Policy Update Magnitude: 0.62086
Value Function Update Magnitude: 0.58508

Collected Steps per Second: 23,023.63224
Overall Steps per Second: 10,751.96311

Timestep Collection Time: 2.17186
Timestep Consumption Time: 2.47883
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.65069

Cumulative Model Updates: 157,430
Cumulative Timesteps: 1,313,011,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1313011638...
Checkpoint 1313011638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.04685
Policy Entropy: 3.00668
Value Function Loss: 0.00458

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.61397
Value Function Update Magnitude: 0.60059

Collected Steps per Second: 22,907.64484
Overall Steps per Second: 10,891.05047

Timestep Collection Time: 2.18320
Timestep Consumption Time: 2.40883
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.59203

Cumulative Model Updates: 157,436
Cumulative Timesteps: 1,313,061,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,880.42492
Policy Entropy: 3.01014
Value Function Loss: 0.00443

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.60502
Value Function Update Magnitude: 0.63136

Collected Steps per Second: 23,035.55595
Overall Steps per Second: 10,849.65533

Timestep Collection Time: 2.17073
Timestep Consumption Time: 2.43808
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60881

Cumulative Model Updates: 157,442
Cumulative Timesteps: 1,313,111,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1313111654...
Checkpoint 1313111654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.99980
Policy Entropy: 3.01139
Value Function Loss: 0.00434

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.59433
Value Function Update Magnitude: 0.62616

Collected Steps per Second: 23,180.00604
Overall Steps per Second: 10,732.18940

Timestep Collection Time: 2.15824
Timestep Consumption Time: 2.50325
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.66149

Cumulative Model Updates: 157,448
Cumulative Timesteps: 1,313,161,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,574.34459
Policy Entropy: 3.02656
Value Function Loss: 0.00426

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.59259
Value Function Update Magnitude: 0.61161

Collected Steps per Second: 22,737.74854
Overall Steps per Second: 10,746.74982

Timestep Collection Time: 2.20031
Timestep Consumption Time: 2.45506
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.65536

Cumulative Model Updates: 157,454
Cumulative Timesteps: 1,313,211,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1313211712...
Checkpoint 1313211712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,651.99005
Policy Entropy: 3.03585
Value Function Loss: 0.00417

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.58613
Value Function Update Magnitude: 0.60112

Collected Steps per Second: 22,651.54402
Overall Steps per Second: 10,711.94950

Timestep Collection Time: 2.20806
Timestep Consumption Time: 2.46112
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.66918

Cumulative Model Updates: 157,460
Cumulative Timesteps: 1,313,261,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.20914
Policy Entropy: 3.04387
Value Function Loss: 0.00431

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.57964
Value Function Update Magnitude: 0.60187

Collected Steps per Second: 22,769.67173
Overall Steps per Second: 10,648.06042

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.50029
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.69663

Cumulative Model Updates: 157,466
Cumulative Timesteps: 1,313,311,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1313311738...
Checkpoint 1313311738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,462.49143
Policy Entropy: 3.03265
Value Function Loss: 0.00438

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.58208
Value Function Update Magnitude: 0.59887

Collected Steps per Second: 23,498.42768
Overall Steps per Second: 10,923.43882

Timestep Collection Time: 2.12823
Timestep Consumption Time: 2.45000
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.57823

Cumulative Model Updates: 157,472
Cumulative Timesteps: 1,313,361,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,746.61190
Policy Entropy: 3.02318
Value Function Loss: 0.00432

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.58616
Value Function Update Magnitude: 0.59064

Collected Steps per Second: 23,339.26148
Overall Steps per Second: 10,878.71815

Timestep Collection Time: 2.14300
Timestep Consumption Time: 2.45460
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.59760

Cumulative Model Updates: 157,478
Cumulative Timesteps: 1,313,411,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1313411764...
Checkpoint 1313411764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.80014
Policy Entropy: 3.01271
Value Function Loss: 0.00444

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.58939
Value Function Update Magnitude: 0.59479

Collected Steps per Second: 23,177.28346
Overall Steps per Second: 10,851.46906

Timestep Collection Time: 2.15772
Timestep Consumption Time: 2.45088
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.60859

Cumulative Model Updates: 157,484
Cumulative Timesteps: 1,313,461,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.48603
Policy Entropy: 3.00819
Value Function Loss: 0.00440

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.58694
Value Function Update Magnitude: 0.57924

Collected Steps per Second: 23,180.48815
Overall Steps per Second: 10,692.06668

Timestep Collection Time: 2.15699
Timestep Consumption Time: 2.51938
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.67636

Cumulative Model Updates: 157,490
Cumulative Timesteps: 1,313,511,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1313511774...
Checkpoint 1313511774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.17373
Policy Entropy: 2.99260
Value Function Loss: 0.00477

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.57117
Value Function Update Magnitude: 0.53882

Collected Steps per Second: 22,012.36892
Overall Steps per Second: 10,702.31268

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.40092
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.67282

Cumulative Model Updates: 157,496
Cumulative Timesteps: 1,313,561,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.58601
Policy Entropy: 3.00571
Value Function Loss: 0.00423

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.57145
Value Function Update Magnitude: 0.52885

Collected Steps per Second: 22,567.36005
Overall Steps per Second: 10,754.44123

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.43433
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.65054

Cumulative Model Updates: 157,502
Cumulative Timesteps: 1,313,611,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1313611798...
Checkpoint 1313611798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,111.86388
Policy Entropy: 3.01421
Value Function Loss: 0.00413

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.56491
Value Function Update Magnitude: 0.51493

Collected Steps per Second: 22,733.83661
Overall Steps per Second: 10,760.88542

Timestep Collection Time: 2.19936
Timestep Consumption Time: 2.44709
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.64646

Cumulative Model Updates: 157,508
Cumulative Timesteps: 1,313,661,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,240.34255
Policy Entropy: 3.02182
Value Function Loss: 0.00423

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.56589
Value Function Update Magnitude: 0.51756

Collected Steps per Second: 22,978.50791
Overall Steps per Second: 10,802.95681

Timestep Collection Time: 2.17725
Timestep Consumption Time: 2.45389
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.63114

Cumulative Model Updates: 157,514
Cumulative Timesteps: 1,313,711,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1313711828...
Checkpoint 1313711828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,157.39106
Policy Entropy: 3.01926
Value Function Loss: 0.00437

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.58590
Value Function Update Magnitude: 0.53652

Collected Steps per Second: 23,169.13669
Overall Steps per Second: 10,721.96907

Timestep Collection Time: 2.15847
Timestep Consumption Time: 2.50578
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.66426

Cumulative Model Updates: 157,520
Cumulative Timesteps: 1,313,761,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,548.45545
Policy Entropy: 3.01720
Value Function Loss: 0.00411

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.58868
Value Function Update Magnitude: 0.55528

Collected Steps per Second: 22,805.30621
Overall Steps per Second: 10,796.64168

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.43909
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.63200

Cumulative Model Updates: 157,526
Cumulative Timesteps: 1,313,811,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1313811848...
Checkpoint 1313811848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.05868
Policy Entropy: 3.01830
Value Function Loss: 0.00423

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.58646
Value Function Update Magnitude: 0.57283

Collected Steps per Second: 22,956.92925
Overall Steps per Second: 10,729.50369

Timestep Collection Time: 2.17825
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.66061

Cumulative Model Updates: 157,532
Cumulative Timesteps: 1,313,861,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.96006
Policy Entropy: 3.01403
Value Function Loss: 0.00409

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.58769
Value Function Update Magnitude: 0.57299

Collected Steps per Second: 23,155.06061
Overall Steps per Second: 10,936.56312

Timestep Collection Time: 2.15961
Timestep Consumption Time: 2.41275
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.57237

Cumulative Model Updates: 157,538
Cumulative Timesteps: 1,313,911,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1313911860...
Checkpoint 1313911860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293.78431
Policy Entropy: 3.00799
Value Function Loss: 0.00436

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.59555
Value Function Update Magnitude: 0.56678

Collected Steps per Second: 22,933.95102
Overall Steps per Second: 10,643.34327

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.51850
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.69946

Cumulative Model Updates: 157,544
Cumulative Timesteps: 1,313,961,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.99094
Policy Entropy: 3.00938
Value Function Loss: 0.00433

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.59563
Value Function Update Magnitude: 0.58861

Collected Steps per Second: 23,377.93715
Overall Steps per Second: 10,913.03620

Timestep Collection Time: 2.13997
Timestep Consumption Time: 2.44428
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.58424

Cumulative Model Updates: 157,550
Cumulative Timesteps: 1,314,011,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1314011906...
Checkpoint 1314011906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.68499
Policy Entropy: 3.01091
Value Function Loss: 0.00481

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.60426
Value Function Update Magnitude: 0.58957

Collected Steps per Second: 22,701.83827
Overall Steps per Second: 10,650.77990

Timestep Collection Time: 2.20335
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.69637

Cumulative Model Updates: 157,556
Cumulative Timesteps: 1,314,061,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,795.12405
Policy Entropy: 3.02353
Value Function Loss: 0.00489

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.60033
Value Function Update Magnitude: 0.60215

Collected Steps per Second: 22,898.88346
Overall Steps per Second: 10,896.16680

Timestep Collection Time: 2.18421
Timestep Consumption Time: 2.40603
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59024

Cumulative Model Updates: 157,562
Cumulative Timesteps: 1,314,111,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1314111942...
Checkpoint 1314111942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.78701
Policy Entropy: 3.03738
Value Function Loss: 0.00483

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.59402
Value Function Update Magnitude: 0.62060

Collected Steps per Second: 22,620.79269
Overall Steps per Second: 10,685.18144

Timestep Collection Time: 2.21044
Timestep Consumption Time: 2.46912
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.67956

Cumulative Model Updates: 157,568
Cumulative Timesteps: 1,314,161,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014.03947
Policy Entropy: 3.02508
Value Function Loss: 0.00445

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.58338
Value Function Update Magnitude: 0.58863

Collected Steps per Second: 22,861.18628
Overall Steps per Second: 10,828.71436

Timestep Collection Time: 2.18711
Timestep Consumption Time: 2.43024
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61735

Cumulative Model Updates: 157,574
Cumulative Timesteps: 1,314,211,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1314211944...
Checkpoint 1314211944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,062.63292
Policy Entropy: 3.01089
Value Function Loss: 0.00440

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.58842
Value Function Update Magnitude: 0.55588

Collected Steps per Second: 23,047.87001
Overall Steps per Second: 10,700.86379

Timestep Collection Time: 2.17035
Timestep Consumption Time: 2.50422
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.67458

Cumulative Model Updates: 157,580
Cumulative Timesteps: 1,314,261,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.87158
Policy Entropy: 3.00021
Value Function Loss: 0.00433

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.59632
Value Function Update Magnitude: 0.51496

Collected Steps per Second: 23,122.11950
Overall Steps per Second: 10,921.52478

Timestep Collection Time: 2.16304
Timestep Consumption Time: 2.41636
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.57940

Cumulative Model Updates: 157,586
Cumulative Timesteps: 1,314,311,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1314311980...
Checkpoint 1314311980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.63345
Policy Entropy: 3.01665
Value Function Loss: 0.00412

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.49762

Collected Steps per Second: 23,385.95938
Overall Steps per Second: 10,806.92211

Timestep Collection Time: 2.13838
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.62740

Cumulative Model Updates: 157,592
Cumulative Timesteps: 1,314,361,988

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,338.32044
Policy Entropy: 3.02118
Value Function Loss: 0.00419

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.57323
Value Function Update Magnitude: 0.49323

Collected Steps per Second: 23,165.69884
Overall Steps per Second: 10,722.03149

Timestep Collection Time: 2.15949
Timestep Consumption Time: 2.50623
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.66572

Cumulative Model Updates: 157,598
Cumulative Timesteps: 1,314,412,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1314412014...
Checkpoint 1314412014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,943.07642
Policy Entropy: 3.02297
Value Function Loss: 0.00424

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.58236
Value Function Update Magnitude: 0.50886

Collected Steps per Second: 23,199.32316
Overall Steps per Second: 10,742.63024

Timestep Collection Time: 2.15532
Timestep Consumption Time: 2.49922
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.65454

Cumulative Model Updates: 157,604
Cumulative Timesteps: 1,314,462,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.43336
Policy Entropy: 3.00533
Value Function Loss: 0.00435

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.52601

Collected Steps per Second: 23,411.12638
Overall Steps per Second: 10,821.93543

Timestep Collection Time: 2.13625
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.62135

Cumulative Model Updates: 157,610
Cumulative Timesteps: 1,314,512,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1314512028...
Checkpoint 1314512028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,436.28028
Policy Entropy: 2.99949
Value Function Loss: 0.00431

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.51425

Collected Steps per Second: 22,595.65256
Overall Steps per Second: 10,628.94984

Timestep Collection Time: 2.21459
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.70790

Cumulative Model Updates: 157,616
Cumulative Timesteps: 1,314,562,068

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,928.02085
Policy Entropy: 3.00779
Value Function Loss: 0.00402

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.57596
Value Function Update Magnitude: 0.49646

Collected Steps per Second: 22,883.40301
Overall Steps per Second: 10,825.10175

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.62111

Cumulative Model Updates: 157,622
Cumulative Timesteps: 1,314,612,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1314612092...
Checkpoint 1314612092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.90871
Policy Entropy: 3.00454
Value Function Loss: 0.00397

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.56170
Value Function Update Magnitude: 0.48190

Collected Steps per Second: 22,750.32924
Overall Steps per Second: 10,689.24152

Timestep Collection Time: 2.19865
Timestep Consumption Time: 2.48082
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.67947

Cumulative Model Updates: 157,628
Cumulative Timesteps: 1,314,662,112

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,066.15363
Policy Entropy: 3.01761
Value Function Loss: 0.00379

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.55657
Value Function Update Magnitude: 0.46216

Collected Steps per Second: 22,771.93529
Overall Steps per Second: 10,670.50719

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.49142
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.68825

Cumulative Model Updates: 157,634
Cumulative Timesteps: 1,314,712,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1314712138...
Checkpoint 1314712138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.75053
Policy Entropy: 3.00071
Value Function Loss: 0.00436

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.56850
Value Function Update Magnitude: 0.48423

Collected Steps per Second: 23,098.76361
Overall Steps per Second: 10,858.84224

Timestep Collection Time: 2.16531
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.60602

Cumulative Model Updates: 157,640
Cumulative Timesteps: 1,314,762,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.23133
Policy Entropy: 3.00083
Value Function Loss: 0.00459

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.58409
Value Function Update Magnitude: 0.52523

Collected Steps per Second: 23,395.26030
Overall Steps per Second: 10,812.07386

Timestep Collection Time: 2.13804
Timestep Consumption Time: 2.48827
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.62631

Cumulative Model Updates: 157,646
Cumulative Timesteps: 1,314,812,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1314812174...
Checkpoint 1314812174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.61238
Policy Entropy: 2.99555
Value Function Loss: 0.00465

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.59347
Value Function Update Magnitude: 0.56179

Collected Steps per Second: 23,083.18322
Overall Steps per Second: 10,788.85395

Timestep Collection Time: 2.16695
Timestep Consumption Time: 2.46932
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.63627

Cumulative Model Updates: 157,652
Cumulative Timesteps: 1,314,862,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080.25055
Policy Entropy: 3.00785
Value Function Loss: 0.00449

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10530
Policy Update Magnitude: 0.58333
Value Function Update Magnitude: 0.56582

Collected Steps per Second: 23,029.30936
Overall Steps per Second: 10,912.47200

Timestep Collection Time: 2.17132
Timestep Consumption Time: 2.41096
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.58228

Cumulative Model Updates: 157,658
Cumulative Timesteps: 1,314,912,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1314912198...
Checkpoint 1314912198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.78162
Policy Entropy: 2.99771
Value Function Loss: 0.00452

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.57909
Value Function Update Magnitude: 0.55293

Collected Steps per Second: 23,068.76484
Overall Steps per Second: 10,844.38210

Timestep Collection Time: 2.16761
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.61105

Cumulative Model Updates: 157,664
Cumulative Timesteps: 1,314,962,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,454.89041
Policy Entropy: 2.99093
Value Function Loss: 0.00456

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.58270
Value Function Update Magnitude: 0.55495

Collected Steps per Second: 23,568.20049
Overall Steps per Second: 10,833.61409

Timestep Collection Time: 2.12227
Timestep Consumption Time: 2.49466
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.61693

Cumulative Model Updates: 157,670
Cumulative Timesteps: 1,315,012,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1315012220...
Checkpoint 1315012220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,544.23594
Policy Entropy: 2.98623
Value Function Loss: 0.00472

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11068
Policy Update Magnitude: 0.58501
Value Function Update Magnitude: 0.57348

Collected Steps per Second: 22,747.86517
Overall Steps per Second: 10,679.61041

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.48500
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.68407

Cumulative Model Updates: 157,676
Cumulative Timesteps: 1,315,062,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,204.39379
Policy Entropy: 3.01124
Value Function Loss: 0.00463

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.59283
Value Function Update Magnitude: 0.58244

Collected Steps per Second: 22,689.19800
Overall Steps per Second: 10,743.18892

Timestep Collection Time: 2.20440
Timestep Consumption Time: 2.45120
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.65560

Cumulative Model Updates: 157,682
Cumulative Timesteps: 1,315,112,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1315112260...
Checkpoint 1315112260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.99972
Policy Entropy: 3.01939
Value Function Loss: 0.00431

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.57348
Value Function Update Magnitude: 0.56724

Collected Steps per Second: 22,726.32587
Overall Steps per Second: 10,621.87622

Timestep Collection Time: 2.20106
Timestep Consumption Time: 2.50828
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.70934

Cumulative Model Updates: 157,688
Cumulative Timesteps: 1,315,162,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,327.92331
Policy Entropy: 3.01598
Value Function Loss: 0.00426

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.57075
Value Function Update Magnitude: 0.54787

Collected Steps per Second: 22,755.74606
Overall Steps per Second: 10,652.56493

Timestep Collection Time: 2.19751
Timestep Consumption Time: 2.49676
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.69427

Cumulative Model Updates: 157,694
Cumulative Timesteps: 1,315,212,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1315212288...
Checkpoint 1315212288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.69187
Policy Entropy: 2.98964
Value Function Loss: 0.00442

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.52395

Collected Steps per Second: 22,632.34860
Overall Steps per Second: 10,584.81416

Timestep Collection Time: 2.21064
Timestep Consumption Time: 2.51613
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.72677

Cumulative Model Updates: 157,700
Cumulative Timesteps: 1,315,262,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.29794
Policy Entropy: 2.97797
Value Function Loss: 0.00435

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.58505
Value Function Update Magnitude: 0.52487

Collected Steps per Second: 23,119.69916
Overall Steps per Second: 10,750.67943

Timestep Collection Time: 2.16404
Timestep Consumption Time: 2.48980
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.65385

Cumulative Model Updates: 157,706
Cumulative Timesteps: 1,315,312,352

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1315312352...
Checkpoint 1315312352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,317.31156
Policy Entropy: 2.97435
Value Function Loss: 0.00420

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.58571
Value Function Update Magnitude: 0.52619

Collected Steps per Second: 22,672.10751
Overall Steps per Second: 10,602.69859

Timestep Collection Time: 2.20544
Timestep Consumption Time: 2.51053
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.71597

Cumulative Model Updates: 157,712
Cumulative Timesteps: 1,315,362,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894.62437
Policy Entropy: 2.99033
Value Function Loss: 0.00406

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.58252
Value Function Update Magnitude: 0.53573

Collected Steps per Second: 23,272.50710
Overall Steps per Second: 10,960.94300

Timestep Collection Time: 2.14975
Timestep Consumption Time: 2.41464
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.56439

Cumulative Model Updates: 157,718
Cumulative Timesteps: 1,315,412,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1315412384...
Checkpoint 1315412384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,520.32459
Policy Entropy: 2.99283
Value Function Loss: 0.00426

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.59079
Value Function Update Magnitude: 0.54297

Collected Steps per Second: 23,065.53878
Overall Steps per Second: 10,645.70988

Timestep Collection Time: 2.16817
Timestep Consumption Time: 2.52950
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.69767

Cumulative Model Updates: 157,724
Cumulative Timesteps: 1,315,462,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,783.38299
Policy Entropy: 2.99761
Value Function Loss: 0.00439

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.59847
Value Function Update Magnitude: 0.55546

Collected Steps per Second: 22,907.82454
Overall Steps per Second: 10,914.60745

Timestep Collection Time: 2.18353
Timestep Consumption Time: 2.39932
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.58285

Cumulative Model Updates: 157,730
Cumulative Timesteps: 1,315,512,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1315512414...
Checkpoint 1315512414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.06861
Policy Entropy: 2.98323
Value Function Loss: 0.00475

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.60101
Value Function Update Magnitude: 0.56509

Collected Steps per Second: 23,051.69102
Overall Steps per Second: 10,835.92555

Timestep Collection Time: 2.16965
Timestep Consumption Time: 2.44593
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.61557

Cumulative Model Updates: 157,736
Cumulative Timesteps: 1,315,562,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.93773
Policy Entropy: 2.98206
Value Function Loss: 0.00491

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.60263
Value Function Update Magnitude: 0.54138

Collected Steps per Second: 23,102.08273
Overall Steps per Second: 10,672.89711

Timestep Collection Time: 2.16439
Timestep Consumption Time: 2.52056
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.68495

Cumulative Model Updates: 157,742
Cumulative Timesteps: 1,315,612,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1315612430...
Checkpoint 1315612430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,986.43055
Policy Entropy: 2.98925
Value Function Loss: 0.00464

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.57859
Value Function Update Magnitude: 0.51559

Collected Steps per Second: 22,590.87232
Overall Steps per Second: 10,650.30148

Timestep Collection Time: 2.21390
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.69602

Cumulative Model Updates: 157,748
Cumulative Timesteps: 1,315,662,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,062.35296
Policy Entropy: 3.01056
Value Function Loss: 0.00425

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.56234
Value Function Update Magnitude: 0.50127

Collected Steps per Second: 22,654.45610
Overall Steps per Second: 10,656.20485

Timestep Collection Time: 2.20813
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.69435

Cumulative Model Updates: 157,754
Cumulative Timesteps: 1,315,712,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1315712468...
Checkpoint 1315712468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,121.35410
Policy Entropy: 3.00253
Value Function Loss: 0.00398

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.55014
Value Function Update Magnitude: 0.51634

Collected Steps per Second: 22,730.23923
Overall Steps per Second: 10,808.99985

Timestep Collection Time: 2.20033
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.62707

Cumulative Model Updates: 157,760
Cumulative Timesteps: 1,315,762,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,326.79891
Policy Entropy: 3.00449
Value Function Loss: 0.00397

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.55162
Value Function Update Magnitude: 0.51170

Collected Steps per Second: 23,406.19645
Overall Steps per Second: 10,728.55306

Timestep Collection Time: 2.13661
Timestep Consumption Time: 2.52478
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.66139

Cumulative Model Updates: 157,766
Cumulative Timesteps: 1,315,812,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1315812492...
Checkpoint 1315812492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,143.54660
Policy Entropy: 3.00707
Value Function Loss: 0.00428

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.57113
Value Function Update Magnitude: 0.50325

Collected Steps per Second: 22,986.43010
Overall Steps per Second: 10,820.32943

Timestep Collection Time: 2.17520
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.62093

Cumulative Model Updates: 157,772
Cumulative Timesteps: 1,315,862,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.30467
Policy Entropy: 3.03650
Value Function Loss: 0.00396

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09669
Policy Update Magnitude: 0.56023
Value Function Update Magnitude: 0.47844

Collected Steps per Second: 23,233.73139
Overall Steps per Second: 10,841.43337

Timestep Collection Time: 2.15239
Timestep Consumption Time: 2.46029
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.61267

Cumulative Model Updates: 157,778
Cumulative Timesteps: 1,315,912,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1315912500...
Checkpoint 1315912500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,890.48350
Policy Entropy: 3.05978
Value Function Loss: 0.00403

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.54774
Value Function Update Magnitude: 0.46578

Collected Steps per Second: 22,878.81839
Overall Steps per Second: 10,802.04761

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.44362
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.62931

Cumulative Model Updates: 157,784
Cumulative Timesteps: 1,315,962,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,613.28636
Policy Entropy: 3.07081
Value Function Loss: 0.00383

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.53992
Value Function Update Magnitude: 0.48009

Collected Steps per Second: 23,209.75684
Overall Steps per Second: 10,869.82419

Timestep Collection Time: 2.15435
Timestep Consumption Time: 2.44572
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.60007

Cumulative Model Updates: 157,790
Cumulative Timesteps: 1,316,012,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1316012508...
Checkpoint 1316012508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,869.51977
Policy Entropy: 3.04696
Value Function Loss: 0.00367

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.53452
Value Function Update Magnitude: 0.47401

Collected Steps per Second: 22,978.00770
Overall Steps per Second: 10,640.74773

Timestep Collection Time: 2.17599
Timestep Consumption Time: 2.52292
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.69892

Cumulative Model Updates: 157,796
Cumulative Timesteps: 1,316,062,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.15450
Policy Entropy: 3.02303
Value Function Loss: 0.00361

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.46479

Collected Steps per Second: 22,690.79212
Overall Steps per Second: 10,684.71614

Timestep Collection Time: 2.20354
Timestep Consumption Time: 2.47604
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.67958

Cumulative Model Updates: 157,802
Cumulative Timesteps: 1,316,112,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1316112508...
Checkpoint 1316112508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,726.65543
Policy Entropy: 2.99705
Value Function Loss: 0.00358

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.54562
Value Function Update Magnitude: 0.45741

Collected Steps per Second: 22,614.73193
Overall Steps per Second: 10,796.30932

Timestep Collection Time: 2.21104
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.63140

Cumulative Model Updates: 157,808
Cumulative Timesteps: 1,316,162,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.39840
Policy Entropy: 2.97820
Value Function Loss: 0.00398

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.46803

Collected Steps per Second: 23,020.56786
Overall Steps per Second: 10,729.60430

Timestep Collection Time: 2.17258
Timestep Consumption Time: 2.48873
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.66131

Cumulative Model Updates: 157,814
Cumulative Timesteps: 1,316,212,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1316212524...
Checkpoint 1316212524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.74826
Policy Entropy: 2.96755
Value Function Loss: 0.00417

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.56934
Value Function Update Magnitude: 0.48342

Collected Steps per Second: 23,100.77677
Overall Steps per Second: 10,862.39219

Timestep Collection Time: 2.16512
Timestep Consumption Time: 2.43939
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60451

Cumulative Model Updates: 157,820
Cumulative Timesteps: 1,316,262,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.23969
Policy Entropy: 2.97333
Value Function Loss: 0.00452

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.59485
Value Function Update Magnitude: 0.50041

Collected Steps per Second: 23,258.56222
Overall Steps per Second: 10,856.90752

Timestep Collection Time: 2.15104
Timestep Consumption Time: 2.45709
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.60813

Cumulative Model Updates: 157,826
Cumulative Timesteps: 1,316,312,570

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1316312570...
Checkpoint 1316312570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,940.40913
Policy Entropy: 2.98248
Value Function Loss: 0.00458

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.58961
Value Function Update Magnitude: 0.52262

Collected Steps per Second: 22,811.23837
Overall Steps per Second: 10,744.38718

Timestep Collection Time: 2.19243
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.65471

Cumulative Model Updates: 157,832
Cumulative Timesteps: 1,316,362,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,253.42028
Policy Entropy: 2.97953
Value Function Loss: 0.00424

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.58247
Value Function Update Magnitude: 0.51680

Collected Steps per Second: 23,229.47689
Overall Steps per Second: 10,865.82400

Timestep Collection Time: 2.15321
Timestep Consumption Time: 2.45003
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.60324

Cumulative Model Updates: 157,838
Cumulative Timesteps: 1,316,412,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1316412600...
Checkpoint 1316412600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,275.57078
Policy Entropy: 2.98481
Value Function Loss: 0.00454

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.59225
Value Function Update Magnitude: 0.51230

Collected Steps per Second: 22,911.62566
Overall Steps per Second: 10,734.96145

Timestep Collection Time: 2.18256
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.65824

Cumulative Model Updates: 157,844
Cumulative Timesteps: 1,316,462,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,225.33943
Policy Entropy: 2.98456
Value Function Loss: 0.00470

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.59923
Value Function Update Magnitude: 0.54494

Collected Steps per Second: 23,408.70250
Overall Steps per Second: 10,872.06921

Timestep Collection Time: 2.13647
Timestep Consumption Time: 2.46357
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.60004

Cumulative Model Updates: 157,850
Cumulative Timesteps: 1,316,512,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1316512618...
Checkpoint 1316512618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.96640
Policy Entropy: 2.99259
Value Function Loss: 0.00461

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.60338
Value Function Update Magnitude: 0.56908

Collected Steps per Second: 22,878.74476
Overall Steps per Second: 10,777.68816

Timestep Collection Time: 2.18552
Timestep Consumption Time: 2.45388
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.63940

Cumulative Model Updates: 157,856
Cumulative Timesteps: 1,316,562,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,496.09755
Policy Entropy: 2.99763
Value Function Loss: 0.00458

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.59907
Value Function Update Magnitude: 0.57294

Collected Steps per Second: 23,088.30288
Overall Steps per Second: 10,767.90385

Timestep Collection Time: 2.16612
Timestep Consumption Time: 2.47843
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.64454

Cumulative Model Updates: 157,862
Cumulative Timesteps: 1,316,612,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1316612632...
Checkpoint 1316612632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,310.37609
Policy Entropy: 2.99006
Value Function Loss: 0.00486

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.60974
Value Function Update Magnitude: 0.58264

Collected Steps per Second: 22,646.09661
Overall Steps per Second: 10,658.01867

Timestep Collection Time: 2.20895
Timestep Consumption Time: 2.48461
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.69356

Cumulative Model Updates: 157,868
Cumulative Timesteps: 1,316,662,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,406.41816
Policy Entropy: 2.97602
Value Function Loss: 0.00480

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.62429
Value Function Update Magnitude: 0.59061

Collected Steps per Second: 22,899.65863
Overall Steps per Second: 10,797.51604

Timestep Collection Time: 2.18353
Timestep Consumption Time: 2.44735
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.63088

Cumulative Model Updates: 157,874
Cumulative Timesteps: 1,316,712,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1316712658...
Checkpoint 1316712658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.36883
Policy Entropy: 2.96921
Value Function Loss: 0.00466

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.61821
Value Function Update Magnitude: 0.57602

Collected Steps per Second: 22,826.39375
Overall Steps per Second: 10,704.92079

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.67336

Cumulative Model Updates: 157,880
Cumulative Timesteps: 1,316,762,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,953.56053
Policy Entropy: 2.99606
Value Function Loss: 0.00445

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.60404
Value Function Update Magnitude: 0.56122

Collected Steps per Second: 22,773.22635
Overall Steps per Second: 10,632.07982

Timestep Collection Time: 2.19609
Timestep Consumption Time: 2.50779
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.70388

Cumulative Model Updates: 157,886
Cumulative Timesteps: 1,316,812,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1316812698...
Checkpoint 1316812698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,445.39969
Policy Entropy: 3.02281
Value Function Loss: 0.00438

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.59181
Value Function Update Magnitude: 0.55050

Collected Steps per Second: 23,023.94209
Overall Steps per Second: 10,838.12790

Timestep Collection Time: 2.17252
Timestep Consumption Time: 2.44267
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.61519

Cumulative Model Updates: 157,892
Cumulative Timesteps: 1,316,862,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,286.15048
Policy Entropy: 3.02524
Value Function Loss: 0.00411

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.58211
Value Function Update Magnitude: 0.53741

Collected Steps per Second: 23,126.87074
Overall Steps per Second: 10,875.58411

Timestep Collection Time: 2.16268
Timestep Consumption Time: 2.43625
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.59893

Cumulative Model Updates: 157,898
Cumulative Timesteps: 1,316,912,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1316912734...
Checkpoint 1316912734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,773.16869
Policy Entropy: 3.02011
Value Function Loss: 0.00414

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.57953
Value Function Update Magnitude: 0.52284

Collected Steps per Second: 22,923.64097
Overall Steps per Second: 10,728.17976

Timestep Collection Time: 2.18194
Timestep Consumption Time: 2.48036
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.66230

Cumulative Model Updates: 157,904
Cumulative Timesteps: 1,316,962,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060.86771
Policy Entropy: 3.00557
Value Function Loss: 0.00427

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.52258

Collected Steps per Second: 23,367.66202
Overall Steps per Second: 10,939.18707

Timestep Collection Time: 2.14074
Timestep Consumption Time: 2.43218
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.57292

Cumulative Model Updates: 157,910
Cumulative Timesteps: 1,317,012,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1317012776...
Checkpoint 1317012776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,574.20327
Policy Entropy: 3.01228
Value Function Loss: 0.00426

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.57579
Value Function Update Magnitude: 0.52162

Collected Steps per Second: 22,478.31564
Overall Steps per Second: 10,644.01595

Timestep Collection Time: 2.22526
Timestep Consumption Time: 2.47410
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.69935

Cumulative Model Updates: 157,916
Cumulative Timesteps: 1,317,062,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.90461
Policy Entropy: 3.00048
Value Function Loss: 0.00460

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.58651
Value Function Update Magnitude: 0.52998

Collected Steps per Second: 23,067.79333
Overall Steps per Second: 10,873.36821

Timestep Collection Time: 2.16865
Timestep Consumption Time: 2.43213
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.60078

Cumulative Model Updates: 157,922
Cumulative Timesteps: 1,317,112,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1317112822...
Checkpoint 1317112822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.24422
Policy Entropy: 2.99695
Value Function Loss: 0.00462

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.60356
Value Function Update Magnitude: 0.53536

Collected Steps per Second: 22,420.56856
Overall Steps per Second: 10,672.85633

Timestep Collection Time: 2.23018
Timestep Consumption Time: 2.45478
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.68497

Cumulative Model Updates: 157,928
Cumulative Timesteps: 1,317,162,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,199.14550
Policy Entropy: 2.98285
Value Function Loss: 0.00420

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.59289
Value Function Update Magnitude: 0.54751

Collected Steps per Second: 22,984.69309
Overall Steps per Second: 10,832.11621

Timestep Collection Time: 2.17606
Timestep Consumption Time: 2.44132
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.61738

Cumulative Model Updates: 157,934
Cumulative Timesteps: 1,317,212,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1317212840...
Checkpoint 1317212840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.87592
Policy Entropy: 2.99999
Value Function Loss: 0.00368

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.56533
Value Function Update Magnitude: 0.52069

Collected Steps per Second: 22,657.16027
Overall Steps per Second: 10,685.09261

Timestep Collection Time: 2.20804
Timestep Consumption Time: 2.47399
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.68204

Cumulative Model Updates: 157,940
Cumulative Timesteps: 1,317,262,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.07978
Policy Entropy: 3.00729
Value Function Loss: 0.00355

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.56085
Value Function Update Magnitude: 0.50166

Collected Steps per Second: 23,103.57038
Overall Steps per Second: 10,853.04631

Timestep Collection Time: 2.16434
Timestep Consumption Time: 2.44303
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.60737

Cumulative Model Updates: 157,946
Cumulative Timesteps: 1,317,312,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1317312872...
Checkpoint 1317312872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,204.38191
Policy Entropy: 3.01442
Value Function Loss: 0.00360

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10208
Policy Update Magnitude: 0.56666
Value Function Update Magnitude: 0.50174

Collected Steps per Second: 22,894.56509
Overall Steps per Second: 10,730.02170

Timestep Collection Time: 2.18419
Timestep Consumption Time: 2.47620
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.66038

Cumulative Model Updates: 157,952
Cumulative Timesteps: 1,317,362,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.71857
Policy Entropy: 3.00347
Value Function Loss: 0.00406

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.50207

Collected Steps per Second: 22,036.24122
Overall Steps per Second: 10,421.69500

Timestep Collection Time: 2.26944
Timestep Consumption Time: 2.52920
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.79864

Cumulative Model Updates: 157,958
Cumulative Timesteps: 1,317,412,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1317412888...
Checkpoint 1317412888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,869.02237
Policy Entropy: 2.99434
Value Function Loss: 0.00399

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.58201
Value Function Update Magnitude: 0.52060

Collected Steps per Second: 23,031.36713
Overall Steps per Second: 10,654.15021

Timestep Collection Time: 2.17113
Timestep Consumption Time: 2.52226
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.69338

Cumulative Model Updates: 157,964
Cumulative Timesteps: 1,317,462,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.70849
Policy Entropy: 2.99303
Value Function Loss: 0.00443

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.58379
Value Function Update Magnitude: 0.53489

Collected Steps per Second: 23,186.30606
Overall Steps per Second: 10,883.83472

Timestep Collection Time: 2.15679
Timestep Consumption Time: 2.43791
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.59470

Cumulative Model Updates: 157,970
Cumulative Timesteps: 1,317,512,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1317512900...
Checkpoint 1317512900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,182.34360
Policy Entropy: 3.00040
Value Function Loss: 0.00449

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.58866
Value Function Update Magnitude: 0.53185

Collected Steps per Second: 23,013.42988
Overall Steps per Second: 10,812.28093

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.45310
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.62696

Cumulative Model Updates: 157,976
Cumulative Timesteps: 1,317,562,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.86287
Policy Entropy: 2.99850
Value Function Loss: 0.00428

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.57641
Value Function Update Magnitude: 0.51252

Collected Steps per Second: 22,682.27726
Overall Steps per Second: 10,755.98638

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.64932

Cumulative Model Updates: 157,982
Cumulative Timesteps: 1,317,612,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1317612936...
Checkpoint 1317612936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,618.55757
Policy Entropy: 2.99496
Value Function Loss: 0.00398

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.57532
Value Function Update Magnitude: 0.52785

Collected Steps per Second: 22,782.36498
Overall Steps per Second: 10,634.72850

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.50820
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70402

Cumulative Model Updates: 157,988
Cumulative Timesteps: 1,317,662,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,012.11174
Policy Entropy: 3.00012
Value Function Loss: 0.00367

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.56540
Value Function Update Magnitude: 0.51013

Collected Steps per Second: 22,583.96533
Overall Steps per Second: 10,602.23505

Timestep Collection Time: 2.21520
Timestep Consumption Time: 2.50343
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.71863

Cumulative Model Updates: 157,994
Cumulative Timesteps: 1,317,712,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1317712990...
Checkpoint 1317712990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,161.43536
Policy Entropy: 3.00978
Value Function Loss: 0.00350

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.55899
Value Function Update Magnitude: 0.48643

Collected Steps per Second: 22,589.93807
Overall Steps per Second: 10,577.58785

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.72906

Cumulative Model Updates: 158,000
Cumulative Timesteps: 1,317,763,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,841.45234
Policy Entropy: 3.02568
Value Function Loss: 0.00377

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.55500
Value Function Update Magnitude: 0.48650

Collected Steps per Second: 23,369.13320
Overall Steps per Second: 10,891.23184

Timestep Collection Time: 2.14026
Timestep Consumption Time: 2.45206
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.59232

Cumulative Model Updates: 158,006
Cumulative Timesteps: 1,317,813,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1317813028...
Checkpoint 1317813028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.48268
Policy Entropy: 3.02770
Value Function Loss: 0.00363

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.48422

Collected Steps per Second: 22,786.53101
Overall Steps per Second: 10,635.82962

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.50721
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.70184

Cumulative Model Updates: 158,012
Cumulative Timesteps: 1,317,863,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,897.71423
Policy Entropy: 3.01744
Value Function Loss: 0.00385

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.55275
Value Function Update Magnitude: 0.49936

Collected Steps per Second: 23,424.48550
Overall Steps per Second: 10,864.00025

Timestep Collection Time: 2.13452
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.60236

Cumulative Model Updates: 158,018
Cumulative Timesteps: 1,317,913,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1317913036...
Checkpoint 1317913036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.61847
Policy Entropy: 3.00119
Value Function Loss: 0.00379

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.56117
Value Function Update Magnitude: 0.51817

Collected Steps per Second: 23,008.43210
Overall Steps per Second: 10,780.55147

Timestep Collection Time: 2.17329
Timestep Consumption Time: 2.46506
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.63835

Cumulative Model Updates: 158,024
Cumulative Timesteps: 1,317,963,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,074.05008
Policy Entropy: 2.99601
Value Function Loss: 0.00422

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.56874
Value Function Update Magnitude: 0.52660

Collected Steps per Second: 23,294.56044
Overall Steps per Second: 10,759.79093

Timestep Collection Time: 2.14771
Timestep Consumption Time: 2.50201
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.64972

Cumulative Model Updates: 158,030
Cumulative Timesteps: 1,318,013,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1318013070...
Checkpoint 1318013070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,714.79842
Policy Entropy: 2.99935
Value Function Loss: 0.00430

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.57502
Value Function Update Magnitude: 0.53470

Collected Steps per Second: 22,696.71549
Overall Steps per Second: 10,607.49211

Timestep Collection Time: 2.20428
Timestep Consumption Time: 2.51219
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.71648

Cumulative Model Updates: 158,036
Cumulative Timesteps: 1,318,063,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.02921
Policy Entropy: 2.98807
Value Function Loss: 0.00438

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.58059
Value Function Update Magnitude: 0.54381

Collected Steps per Second: 22,828.80184
Overall Steps per Second: 10,706.75045

Timestep Collection Time: 2.19030
Timestep Consumption Time: 2.47983
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.67014

Cumulative Model Updates: 158,042
Cumulative Timesteps: 1,318,113,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1318113102...
Checkpoint 1318113102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.85982
Policy Entropy: 2.98964
Value Function Loss: 0.00448

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.58913
Value Function Update Magnitude: 0.54627

Collected Steps per Second: 22,722.74324
Overall Steps per Second: 10,801.27969

Timestep Collection Time: 2.20123
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.63075

Cumulative Model Updates: 158,048
Cumulative Timesteps: 1,318,163,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.72614
Policy Entropy: 2.99221
Value Function Loss: 0.00419

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.58286
Value Function Update Magnitude: 0.53339

Collected Steps per Second: 22,532.68131
Overall Steps per Second: 10,548.34342

Timestep Collection Time: 2.21927
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.74065

Cumulative Model Updates: 158,054
Cumulative Timesteps: 1,318,213,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1318213126...
Checkpoint 1318213126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,551.96478
Policy Entropy: 2.99851
Value Function Loss: 0.00400

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.56272
Value Function Update Magnitude: 0.51550

Collected Steps per Second: 22,355.01814
Overall Steps per Second: 10,598.33634

Timestep Collection Time: 2.23789
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.72036

Cumulative Model Updates: 158,060
Cumulative Timesteps: 1,318,263,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.67727
Policy Entropy: 3.00846
Value Function Loss: 0.00410

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.52311

Collected Steps per Second: 23,252.96901
Overall Steps per Second: 10,889.27963

Timestep Collection Time: 2.15069
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.59259

Cumulative Model Updates: 158,066
Cumulative Timesteps: 1,318,313,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1318313164...
Checkpoint 1318313164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,263.23664
Policy Entropy: 3.01458
Value Function Loss: 0.00401

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.56351
Value Function Update Magnitude: 0.52383

Collected Steps per Second: 22,723.86049
Overall Steps per Second: 10,666.72899

Timestep Collection Time: 2.20130
Timestep Consumption Time: 2.48824
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.68954

Cumulative Model Updates: 158,072
Cumulative Timesteps: 1,318,363,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,773.49634
Policy Entropy: 3.03328
Value Function Loss: 0.00405

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.55772
Value Function Update Magnitude: 0.51168

Collected Steps per Second: 23,311.71138
Overall Steps per Second: 10,914.71742

Timestep Collection Time: 2.14587
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.58317

Cumulative Model Updates: 158,078
Cumulative Timesteps: 1,318,413,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1318413210...
Checkpoint 1318413210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.93965
Policy Entropy: 3.02267
Value Function Loss: 0.00392

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.56186
Value Function Update Magnitude: 0.50706

Collected Steps per Second: 22,663.06100
Overall Steps per Second: 10,637.34022

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.70230

Cumulative Model Updates: 158,084
Cumulative Timesteps: 1,318,463,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.31828
Policy Entropy: 3.01677
Value Function Loss: 0.00387

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.56391
Value Function Update Magnitude: 0.50661

Collected Steps per Second: 23,403.28619
Overall Steps per Second: 10,888.78511

Timestep Collection Time: 2.13748
Timestep Consumption Time: 2.45661
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.59408

Cumulative Model Updates: 158,090
Cumulative Timesteps: 1,318,513,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1318513254...
Checkpoint 1318513254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,367.15908
Policy Entropy: 3.02053
Value Function Loss: 0.00385

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.50935

Collected Steps per Second: 23,125.51125
Overall Steps per Second: 10,738.57532

Timestep Collection Time: 2.16246
Timestep Consumption Time: 2.49440
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.65686

Cumulative Model Updates: 158,096
Cumulative Timesteps: 1,318,563,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.78164
Policy Entropy: 3.03505
Value Function Loss: 0.00448

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.57285
Value Function Update Magnitude: 0.51370

Collected Steps per Second: 22,919.25186
Overall Steps per Second: 10,807.76566

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.44600
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.62871

Cumulative Model Updates: 158,102
Cumulative Timesteps: 1,318,613,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1318613288...
Checkpoint 1318613288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,378.28020
Policy Entropy: 3.03212
Value Function Loss: 0.00456

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.58246
Value Function Update Magnitude: 0.52553

Collected Steps per Second: 22,613.79072
Overall Steps per Second: 10,667.55158

Timestep Collection Time: 2.21192
Timestep Consumption Time: 2.47706
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.68899

Cumulative Model Updates: 158,108
Cumulative Timesteps: 1,318,663,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,065.44970
Policy Entropy: 3.04311
Value Function Loss: 0.00487

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.58830
Value Function Update Magnitude: 0.54828

Collected Steps per Second: 22,852.95735
Overall Steps per Second: 10,843.95403

Timestep Collection Time: 2.18878
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.61271

Cumulative Model Updates: 158,114
Cumulative Timesteps: 1,318,713,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1318713328...
Checkpoint 1318713328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,539.06836
Policy Entropy: 3.03052
Value Function Loss: 0.00504

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.59880
Value Function Update Magnitude: 0.59377

Collected Steps per Second: 22,852.55076
Overall Steps per Second: 10,703.28277

Timestep Collection Time: 2.18960
Timestep Consumption Time: 2.48541
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.67501

Cumulative Model Updates: 158,120
Cumulative Timesteps: 1,318,763,366

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,108.34875
Policy Entropy: 3.01369
Value Function Loss: 0.00507

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.60534
Value Function Update Magnitude: 0.62485

Collected Steps per Second: 23,298.38839
Overall Steps per Second: 10,866.34069

Timestep Collection Time: 2.14650
Timestep Consumption Time: 2.45578
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.60229

Cumulative Model Updates: 158,126
Cumulative Timesteps: 1,318,813,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1318813376...
Checkpoint 1318813376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,239.92867
Policy Entropy: 2.99943
Value Function Loss: 0.00449

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.60190
Value Function Update Magnitude: 0.62695

Collected Steps per Second: 22,988.75716
Overall Steps per Second: 10,673.94091

Timestep Collection Time: 2.17619
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.68693

Cumulative Model Updates: 158,132
Cumulative Timesteps: 1,318,863,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.05197
Policy Entropy: 3.00150
Value Function Loss: 0.00415

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.59780
Value Function Update Magnitude: 0.58629

Collected Steps per Second: 23,338.89030
Overall Steps per Second: 10,947.68561

Timestep Collection Time: 2.14278
Timestep Consumption Time: 2.42531
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.56809

Cumulative Model Updates: 158,138
Cumulative Timesteps: 1,318,913,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1318913414...
Checkpoint 1318913414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.72772
Policy Entropy: 3.02698
Value Function Loss: 0.00430

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.58692
Value Function Update Magnitude: 0.55000

Collected Steps per Second: 23,068.62635
Overall Steps per Second: 10,686.53030

Timestep Collection Time: 2.16814
Timestep Consumption Time: 2.51214
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.68028

Cumulative Model Updates: 158,144
Cumulative Timesteps: 1,318,963,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.64216
Policy Entropy: 3.02853
Value Function Loss: 0.00433

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.58136
Value Function Update Magnitude: 0.53432

Collected Steps per Second: 23,202.23835
Overall Steps per Second: 10,824.59201

Timestep Collection Time: 2.15505
Timestep Consumption Time: 2.46425
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.61930

Cumulative Model Updates: 158,150
Cumulative Timesteps: 1,319,013,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1319013432...
Checkpoint 1319013432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,652.60180
Policy Entropy: 3.03349
Value Function Loss: 0.00425

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.57442
Value Function Update Magnitude: 0.53141

Collected Steps per Second: 22,498.83404
Overall Steps per Second: 10,660.79701

Timestep Collection Time: 2.22349
Timestep Consumption Time: 2.46903
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.69252

Cumulative Model Updates: 158,156
Cumulative Timesteps: 1,319,063,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,755.03395
Policy Entropy: 3.02615
Value Function Loss: 0.00393

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.51180

Collected Steps per Second: 22,905.01025
Overall Steps per Second: 10,840.83732

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61311

Cumulative Model Updates: 158,162
Cumulative Timesteps: 1,319,113,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1319113468...
Checkpoint 1319113468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,784.22409
Policy Entropy: 3.00902
Value Function Loss: 0.00418

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.48289

Collected Steps per Second: 22,804.37047
Overall Steps per Second: 10,707.49316

Timestep Collection Time: 2.19361
Timestep Consumption Time: 2.47825
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.67187

Cumulative Model Updates: 158,168
Cumulative Timesteps: 1,319,163,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,191.91060
Policy Entropy: 2.98774
Value Function Loss: 0.00437

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.58392
Value Function Update Magnitude: 0.51575

Collected Steps per Second: 23,473.02496
Overall Steps per Second: 10,881.43472

Timestep Collection Time: 2.13079
Timestep Consumption Time: 2.46567
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.59645

Cumulative Model Updates: 158,174
Cumulative Timesteps: 1,319,213,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1319213508...
Checkpoint 1319213508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,629.65403
Policy Entropy: 2.96979
Value Function Loss: 0.00450

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.59465
Value Function Update Magnitude: 0.54825

Collected Steps per Second: 23,105.24327
Overall Steps per Second: 10,632.30594

Timestep Collection Time: 2.16505
Timestep Consumption Time: 2.53986
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.70491

Cumulative Model Updates: 158,180
Cumulative Timesteps: 1,319,263,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,333.65217
Policy Entropy: 2.98180
Value Function Loss: 0.00431

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.59664
Value Function Update Magnitude: 0.56258

Collected Steps per Second: 23,541.37849
Overall Steps per Second: 10,986.86070

Timestep Collection Time: 2.12511
Timestep Consumption Time: 2.42833
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.55344

Cumulative Model Updates: 158,186
Cumulative Timesteps: 1,319,313,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1319313560...
Checkpoint 1319313560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.24471
Policy Entropy: 2.98577
Value Function Loss: 0.00444

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.60089
Value Function Update Magnitude: 0.55850

Collected Steps per Second: 22,862.22747
Overall Steps per Second: 10,792.85215

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.44666
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.63455

Cumulative Model Updates: 158,192
Cumulative Timesteps: 1,319,363,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,507.59009
Policy Entropy: 2.99114
Value Function Loss: 0.00459

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.59909
Value Function Update Magnitude: 0.54203

Collected Steps per Second: 23,019.02438
Overall Steps per Second: 10,731.27076

Timestep Collection Time: 2.17316
Timestep Consumption Time: 2.48836
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.66152

Cumulative Model Updates: 158,198
Cumulative Timesteps: 1,319,413,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1319413604...
Checkpoint 1319413604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.51640
Policy Entropy: 2.99757
Value Function Loss: 0.00495

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.60178
Value Function Update Magnitude: 0.54042

Collected Steps per Second: 22,529.50038
Overall Steps per Second: 10,619.64986

Timestep Collection Time: 2.22002
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.70976

Cumulative Model Updates: 158,204
Cumulative Timesteps: 1,319,463,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.78156
Policy Entropy: 3.00665
Value Function Loss: 0.00482

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.59771
Value Function Update Magnitude: 0.54153

Collected Steps per Second: 23,081.77777
Overall Steps per Second: 10,943.35678

Timestep Collection Time: 2.16682
Timestep Consumption Time: 2.40344
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.57026

Cumulative Model Updates: 158,210
Cumulative Timesteps: 1,319,513,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1319513634...
Checkpoint 1319513634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744.66816
Policy Entropy: 3.01466
Value Function Loss: 0.00477

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.58639
Value Function Update Magnitude: 0.53661

Collected Steps per Second: 22,998.22495
Overall Steps per Second: 10,621.24291

Timestep Collection Time: 2.17486
Timestep Consumption Time: 2.53438
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.70924

Cumulative Model Updates: 158,216
Cumulative Timesteps: 1,319,563,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,175.25603
Policy Entropy: 2.99376
Value Function Loss: 0.00461

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.57649
Value Function Update Magnitude: 0.54044

Collected Steps per Second: 23,186.97688
Overall Steps per Second: 10,856.12760

Timestep Collection Time: 2.15750
Timestep Consumption Time: 2.45058
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.60809

Cumulative Model Updates: 158,222
Cumulative Timesteps: 1,319,613,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1319613678...
Checkpoint 1319613678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,957.57779
Policy Entropy: 2.98661
Value Function Loss: 0.00470

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.58737
Value Function Update Magnitude: 0.53546

Collected Steps per Second: 22,897.83244
Overall Steps per Second: 10,684.66957

Timestep Collection Time: 2.18361
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.67960

Cumulative Model Updates: 158,228
Cumulative Timesteps: 1,319,663,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600.84793
Policy Entropy: 2.97838
Value Function Loss: 0.00479

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11710
Policy Update Magnitude: 0.59189
Value Function Update Magnitude: 0.53607

Collected Steps per Second: 23,252.44180
Overall Steps per Second: 10,931.98970

Timestep Collection Time: 2.15169
Timestep Consumption Time: 2.42497
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.57666

Cumulative Model Updates: 158,234
Cumulative Timesteps: 1,319,713,710

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1319713710...
Checkpoint 1319713710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.93290
Policy Entropy: 2.99319
Value Function Loss: 0.00480

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.58817
Value Function Update Magnitude: 0.52880

Collected Steps per Second: 23,224.04987
Overall Steps per Second: 10,985.72493

Timestep Collection Time: 2.15389
Timestep Consumption Time: 2.39948
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.55336

Cumulative Model Updates: 158,240
Cumulative Timesteps: 1,319,763,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,419.32221
Policy Entropy: 2.99994
Value Function Loss: 0.00456

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.58638
Value Function Update Magnitude: 0.51360

Collected Steps per Second: 23,331.00406
Overall Steps per Second: 10,886.81871

Timestep Collection Time: 2.14316
Timestep Consumption Time: 2.44974
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.59289

Cumulative Model Updates: 158,246
Cumulative Timesteps: 1,319,813,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1319813734...
Checkpoint 1319813734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.36722
Policy Entropy: 3.00310
Value Function Loss: 0.00482

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.60351
Value Function Update Magnitude: 0.51144

Collected Steps per Second: 22,361.53869
Overall Steps per Second: 10,706.73367

Timestep Collection Time: 2.23714
Timestep Consumption Time: 2.43524
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.67239

Cumulative Model Updates: 158,252
Cumulative Timesteps: 1,319,863,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,326.56358
Policy Entropy: 2.99270
Value Function Loss: 0.00459

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.60416
Value Function Update Magnitude: 0.51093

Collected Steps per Second: 22,625.34116
Overall Steps per Second: 10,606.84600

Timestep Collection Time: 2.21062
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.71545

Cumulative Model Updates: 158,258
Cumulative Timesteps: 1,319,913,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1319913776...
Checkpoint 1319913776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.77672
Policy Entropy: 2.99971
Value Function Loss: 0.00436

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.59148
Value Function Update Magnitude: 0.51250

Collected Steps per Second: 22,828.22151
Overall Steps per Second: 10,779.07543

Timestep Collection Time: 2.19132
Timestep Consumption Time: 2.44952
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.64084

Cumulative Model Updates: 158,264
Cumulative Timesteps: 1,319,963,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,547.69178
Policy Entropy: 2.98904
Value Function Loss: 0.00420

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.58651
Value Function Update Magnitude: 0.52938

Collected Steps per Second: 22,820.86162
Overall Steps per Second: 10,703.20562

Timestep Collection Time: 2.19177
Timestep Consumption Time: 2.48141
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.67318

Cumulative Model Updates: 158,270
Cumulative Timesteps: 1,320,013,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1320013818...
Checkpoint 1320013818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.28544
Policy Entropy: 3.01694
Value Function Loss: 0.00406

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.58327
Value Function Update Magnitude: 0.53422

Collected Steps per Second: 22,244.00607
Overall Steps per Second: 10,580.72813

Timestep Collection Time: 2.24897
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.72803

Cumulative Model Updates: 158,276
Cumulative Timesteps: 1,320,063,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948.74239
Policy Entropy: 3.01757
Value Function Loss: 0.00397

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.56237
Value Function Update Magnitude: 0.51834

Collected Steps per Second: 23,214.68083
Overall Steps per Second: 10,881.76956

Timestep Collection Time: 2.15398
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.59521

Cumulative Model Updates: 158,282
Cumulative Timesteps: 1,320,113,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1320113848...
Checkpoint 1320113848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.47972
Policy Entropy: 3.04795
Value Function Loss: 0.00380

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10372
Policy Update Magnitude: 0.54163
Value Function Update Magnitude: 0.49145

Collected Steps per Second: 23,090.35117
Overall Steps per Second: 10,666.41889

Timestep Collection Time: 2.16567
Timestep Consumption Time: 2.52250
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.68817

Cumulative Model Updates: 158,288
Cumulative Timesteps: 1,320,163,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,043.35858
Policy Entropy: 3.03857
Value Function Loss: 0.00386

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.53558
Value Function Update Magnitude: 0.48872

Collected Steps per Second: 23,289.15102
Overall Steps per Second: 10,911.65265

Timestep Collection Time: 2.14692
Timestep Consumption Time: 2.43533
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.58226

Cumulative Model Updates: 158,294
Cumulative Timesteps: 1,320,213,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1320213854...
Checkpoint 1320213854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,137.99945
Policy Entropy: 3.04734
Value Function Loss: 0.00406

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.54546
Value Function Update Magnitude: 0.50299

Collected Steps per Second: 23,118.85718
Overall Steps per Second: 10,720.90474

Timestep Collection Time: 2.16308
Timestep Consumption Time: 2.50145
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.66453

Cumulative Model Updates: 158,300
Cumulative Timesteps: 1,320,263,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.69993
Policy Entropy: 3.02479
Value Function Loss: 0.00457

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.55797

Collected Steps per Second: 23,356.82264
Overall Steps per Second: 10,865.91019

Timestep Collection Time: 2.14122
Timestep Consumption Time: 2.46144
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.60265

Cumulative Model Updates: 158,306
Cumulative Timesteps: 1,320,313,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1320313874...
Checkpoint 1320313874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.26828
Policy Entropy: 3.03695
Value Function Loss: 0.00479

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.58158
Value Function Update Magnitude: 0.59615

Collected Steps per Second: 22,980.68226
Overall Steps per Second: 10,718.44027

Timestep Collection Time: 2.17618
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.66579

Cumulative Model Updates: 158,312
Cumulative Timesteps: 1,320,363,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.33777
Policy Entropy: 3.02912
Value Function Loss: 0.00467

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.57306
Value Function Update Magnitude: 0.56602

Collected Steps per Second: 23,062.26179
Overall Steps per Second: 10,838.39479

Timestep Collection Time: 2.16934
Timestep Consumption Time: 2.44665
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.61600

Cumulative Model Updates: 158,318
Cumulative Timesteps: 1,320,413,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1320413914...
Checkpoint 1320413914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.93475
Policy Entropy: 3.04870
Value Function Loss: 0.00454

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.52723

Collected Steps per Second: 22,568.99473
Overall Steps per Second: 10,675.58316

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.68621

Cumulative Model Updates: 158,324
Cumulative Timesteps: 1,320,463,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.50035
Policy Entropy: 3.03242
Value Function Loss: 0.00441

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.55992
Value Function Update Magnitude: 0.51340

Collected Steps per Second: 22,889.98566
Overall Steps per Second: 10,880.09015

Timestep Collection Time: 2.18454
Timestep Consumption Time: 2.41138
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.59592

Cumulative Model Updates: 158,330
Cumulative Timesteps: 1,320,513,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1320513946...
Checkpoint 1320513946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853.50244
Policy Entropy: 3.03206
Value Function Loss: 0.00418

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10820
Policy Update Magnitude: 0.55603
Value Function Update Magnitude: 0.51263

Collected Steps per Second: 22,808.85139
Overall Steps per Second: 10,602.56850

Timestep Collection Time: 2.19231
Timestep Consumption Time: 2.52391
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.71622

Cumulative Model Updates: 158,336
Cumulative Timesteps: 1,320,563,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,767.57301
Policy Entropy: 3.01127
Value Function Loss: 0.00424

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.51645

Collected Steps per Second: 23,578.82445
Overall Steps per Second: 10,917.61445

Timestep Collection Time: 2.12106
Timestep Consumption Time: 2.45980
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.58085

Cumulative Model Updates: 158,342
Cumulative Timesteps: 1,320,613,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1320613962...
Checkpoint 1320613962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,238.44662
Policy Entropy: 3.00665
Value Function Loss: 0.00411

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.56783
Value Function Update Magnitude: 0.51867

Collected Steps per Second: 22,987.53140
Overall Steps per Second: 10,691.56916

Timestep Collection Time: 2.17535
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.67714

Cumulative Model Updates: 158,348
Cumulative Timesteps: 1,320,663,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.43367
Policy Entropy: 3.01313
Value Function Loss: 0.00420

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.51565

Collected Steps per Second: 23,058.74666
Overall Steps per Second: 10,848.33032

Timestep Collection Time: 2.16968
Timestep Consumption Time: 2.44209
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.61177

Cumulative Model Updates: 158,354
Cumulative Timesteps: 1,320,713,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1320713998...
Checkpoint 1320713998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.75312
Policy Entropy: 3.01467
Value Function Loss: 0.00437

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.57844
Value Function Update Magnitude: 0.50757

Collected Steps per Second: 23,094.60825
Overall Steps per Second: 10,810.03911

Timestep Collection Time: 2.16587
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.62718

Cumulative Model Updates: 158,360
Cumulative Timesteps: 1,320,764,018

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,772.02336
Policy Entropy: 3.02958
Value Function Loss: 0.00430

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.58534
Value Function Update Magnitude: 0.50334

Collected Steps per Second: 23,333.21185
Overall Steps per Second: 10,721.93444

Timestep Collection Time: 2.14287
Timestep Consumption Time: 2.52047
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.66334

Cumulative Model Updates: 158,366
Cumulative Timesteps: 1,320,814,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1320814018...
Checkpoint 1320814018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.96473
Policy Entropy: 3.03275
Value Function Loss: 0.00393

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.57548
Value Function Update Magnitude: 0.49934

Collected Steps per Second: 22,858.08099
Overall Steps per Second: 10,746.03462

Timestep Collection Time: 2.18794
Timestep Consumption Time: 2.46606
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.65400

Cumulative Model Updates: 158,372
Cumulative Timesteps: 1,320,864,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,190.71728
Policy Entropy: 3.04035
Value Function Loss: 0.00416

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.57406
Value Function Update Magnitude: 0.49891

Collected Steps per Second: 22,970.76776
Overall Steps per Second: 10,840.49848

Timestep Collection Time: 2.17703
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.61307

Cumulative Model Updates: 158,378
Cumulative Timesteps: 1,320,914,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1320914038...
Checkpoint 1320914038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,070.64127
Policy Entropy: 3.02034
Value Function Loss: 0.00446

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.58776
Value Function Update Magnitude: 0.52123

Collected Steps per Second: 22,883.12975
Overall Steps per Second: 10,753.29835

Timestep Collection Time: 2.18537
Timestep Consumption Time: 2.46511
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.65048

Cumulative Model Updates: 158,384
Cumulative Timesteps: 1,320,964,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.67410
Policy Entropy: 3.00369
Value Function Loss: 0.00466

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.58958
Value Function Update Magnitude: 0.54991

Collected Steps per Second: 23,005.59516
Overall Steps per Second: 10,737.51762

Timestep Collection Time: 2.17356
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.65694

Cumulative Model Updates: 158,390
Cumulative Timesteps: 1,321,014,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1321014050...
Checkpoint 1321014050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.04398
Policy Entropy: 2.99682
Value Function Loss: 0.00467

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.58353
Value Function Update Magnitude: 0.57288

Collected Steps per Second: 22,765.94070
Overall Steps per Second: 10,688.68377

Timestep Collection Time: 2.19661
Timestep Consumption Time: 2.48198
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.67859

Cumulative Model Updates: 158,396
Cumulative Timesteps: 1,321,064,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.20028
Policy Entropy: 3.00070
Value Function Loss: 0.00441

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.58392
Value Function Update Magnitude: 0.58144

Collected Steps per Second: 23,426.43201
Overall Steps per Second: 10,911.54287

Timestep Collection Time: 2.13545
Timestep Consumption Time: 2.44924
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.58469

Cumulative Model Updates: 158,402
Cumulative Timesteps: 1,321,114,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1321114084...
Checkpoint 1321114084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,275.96487
Policy Entropy: 3.01329
Value Function Loss: 0.00421

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.57690
Value Function Update Magnitude: 0.57249

Collected Steps per Second: 23,012.78916
Overall Steps per Second: 10,680.25509

Timestep Collection Time: 2.17366
Timestep Consumption Time: 2.50994
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.68360

Cumulative Model Updates: 158,408
Cumulative Timesteps: 1,321,164,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532.55379
Policy Entropy: 3.01628
Value Function Loss: 0.00399

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.57146
Value Function Update Magnitude: 0.55835

Collected Steps per Second: 23,175.01184
Overall Steps per Second: 10,821.29721

Timestep Collection Time: 2.15819
Timestep Consumption Time: 2.46381
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.62200

Cumulative Model Updates: 158,414
Cumulative Timesteps: 1,321,214,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1321214122...
Checkpoint 1321214122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.42184
Policy Entropy: 3.00867
Value Function Loss: 0.00424

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.58327
Value Function Update Magnitude: 0.56625

Collected Steps per Second: 21,660.59824
Overall Steps per Second: 10,558.69630

Timestep Collection Time: 2.30991
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.73865

Cumulative Model Updates: 158,420
Cumulative Timesteps: 1,321,264,156

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.32192
Policy Entropy: 3.01858
Value Function Loss: 0.00453

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.58763
Value Function Update Magnitude: 0.58944

Collected Steps per Second: 23,243.81990
Overall Steps per Second: 10,950.51418

Timestep Collection Time: 2.15145
Timestep Consumption Time: 2.41527
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.56673

Cumulative Model Updates: 158,426
Cumulative Timesteps: 1,321,314,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1321314164...
Checkpoint 1321314164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.61740
Policy Entropy: 3.02242
Value Function Loss: 0.00444

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10017
Policy Update Magnitude: 0.57644
Value Function Update Magnitude: 0.54796

Collected Steps per Second: 22,774.11632
Overall Steps per Second: 10,706.18455

Timestep Collection Time: 2.19609
Timestep Consumption Time: 2.47542
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.67151

Cumulative Model Updates: 158,432
Cumulative Timesteps: 1,321,364,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,945.75524
Policy Entropy: 3.02152
Value Function Loss: 0.00470

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.56567
Value Function Update Magnitude: 0.52324

Collected Steps per Second: 22,604.90416
Overall Steps per Second: 10,837.08036

Timestep Collection Time: 2.21191
Timestep Consumption Time: 2.40188
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61379

Cumulative Model Updates: 158,438
Cumulative Timesteps: 1,321,414,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1321414178...
Checkpoint 1321414178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623.14854
Policy Entropy: 3.02187
Value Function Loss: 0.00494

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.58390
Value Function Update Magnitude: 0.52208

Collected Steps per Second: 22,277.63020
Overall Steps per Second: 10,731.66831

Timestep Collection Time: 2.24476
Timestep Consumption Time: 2.41509
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.65985

Cumulative Model Updates: 158,444
Cumulative Timesteps: 1,321,464,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.80206
Policy Entropy: 3.01359
Value Function Loss: 0.00526

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.59295
Value Function Update Magnitude: 0.55222

Collected Steps per Second: 22,993.67603
Overall Steps per Second: 10,836.25025

Timestep Collection Time: 2.17512
Timestep Consumption Time: 2.44031
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61543

Cumulative Model Updates: 158,450
Cumulative Timesteps: 1,321,514,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1321514200...
Checkpoint 1321514200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.40080
Policy Entropy: 3.02673
Value Function Loss: 0.00514

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.59616
Value Function Update Magnitude: 0.56132

Collected Steps per Second: 22,728.70911
Overall Steps per Second: 10,698.35442

Timestep Collection Time: 2.20092
Timestep Consumption Time: 2.47494
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.67586

Cumulative Model Updates: 158,456
Cumulative Timesteps: 1,321,564,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,604.77250
Policy Entropy: 3.03530
Value Function Loss: 0.00449

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.58279
Value Function Update Magnitude: 0.53232

Collected Steps per Second: 23,360.41853
Overall Steps per Second: 10,890.56310

Timestep Collection Time: 2.14089
Timestep Consumption Time: 2.45135
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.59223

Cumulative Model Updates: 158,462
Cumulative Timesteps: 1,321,614,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1321614236...
Checkpoint 1321614236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.05084
Policy Entropy: 3.03748
Value Function Loss: 0.00435

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.50919

Collected Steps per Second: 22,662.20715
Overall Steps per Second: 10,655.90057

Timestep Collection Time: 2.20693
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.69355

Cumulative Model Updates: 158,468
Cumulative Timesteps: 1,321,664,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,843.67811
Policy Entropy: 3.03045
Value Function Loss: 0.00438

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.57255
Value Function Update Magnitude: 0.49615

Collected Steps per Second: 23,401.67627
Overall Steps per Second: 10,931.52029

Timestep Collection Time: 2.13703
Timestep Consumption Time: 2.43782
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.57484

Cumulative Model Updates: 158,474
Cumulative Timesteps: 1,321,714,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1321714260...
Checkpoint 1321714260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.49991
Policy Entropy: 3.01130
Value Function Loss: 0.00454

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.56688
Value Function Update Magnitude: 0.49513

Collected Steps per Second: 23,071.49150
Overall Steps per Second: 10,718.95215

Timestep Collection Time: 2.16752
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.66538

Cumulative Model Updates: 158,480
Cumulative Timesteps: 1,321,764,268

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.49757
Policy Entropy: 2.99733
Value Function Loss: 0.00484

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.57889
Value Function Update Magnitude: 0.49559

Collected Steps per Second: 23,197.40737
Overall Steps per Second: 10,772.45739

Timestep Collection Time: 2.15602
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.64277

Cumulative Model Updates: 158,486
Cumulative Timesteps: 1,321,814,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1321814282...
Checkpoint 1321814282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.44677
Policy Entropy: 2.99906
Value Function Loss: 0.00507

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.60132
Value Function Update Magnitude: 0.53021

Collected Steps per Second: 22,625.36087
Overall Steps per Second: 10,643.54040

Timestep Collection Time: 2.21000
Timestep Consumption Time: 2.48787
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.69787

Cumulative Model Updates: 158,492
Cumulative Timesteps: 1,321,864,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657.29885
Policy Entropy: 3.02804
Value Function Loss: 0.00481

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.60076
Value Function Update Magnitude: 0.54118

Collected Steps per Second: 23,046.79092
Overall Steps per Second: 10,852.96740

Timestep Collection Time: 2.16967
Timestep Consumption Time: 2.43773
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60740

Cumulative Model Updates: 158,498
Cumulative Timesteps: 1,321,914,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1321914288...
Checkpoint 1321914288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.02575
Policy Entropy: 3.03857
Value Function Loss: 0.00467

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.53118

Collected Steps per Second: 22,513.04864
Overall Steps per Second: 10,741.17869

Timestep Collection Time: 2.22209
Timestep Consumption Time: 2.43531
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.65740

Cumulative Model Updates: 158,504
Cumulative Timesteps: 1,321,964,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.96255
Policy Entropy: 3.03219
Value Function Loss: 0.00456

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11118
Policy Update Magnitude: 0.59467
Value Function Update Magnitude: 0.54517

Collected Steps per Second: 23,126.30447
Overall Steps per Second: 10,877.30976

Timestep Collection Time: 2.16299
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.59875

Cumulative Model Updates: 158,510
Cumulative Timesteps: 1,322,014,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1322014336...
Checkpoint 1322014336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.07398
Policy Entropy: 3.01821
Value Function Loss: 0.00492

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.60651
Value Function Update Magnitude: 0.54439

Collected Steps per Second: 22,928.54644
Overall Steps per Second: 10,639.82896

Timestep Collection Time: 2.18121
Timestep Consumption Time: 2.51924
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.70045

Cumulative Model Updates: 158,516
Cumulative Timesteps: 1,322,064,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,281.19173
Policy Entropy: 3.00846
Value Function Loss: 0.00507

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.61056
Value Function Update Magnitude: 0.55035

Collected Steps per Second: 23,251.30933
Overall Steps per Second: 10,891.90197

Timestep Collection Time: 2.15128
Timestep Consumption Time: 2.44113
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.59240

Cumulative Model Updates: 158,522
Cumulative Timesteps: 1,322,114,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1322114368...
Checkpoint 1322114368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,721.07842
Policy Entropy: 3.01127
Value Function Loss: 0.00502

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.60804
Value Function Update Magnitude: 0.55593

Collected Steps per Second: 22,921.97627
Overall Steps per Second: 10,642.87561

Timestep Collection Time: 2.18166
Timestep Consumption Time: 2.51707
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.69873

Cumulative Model Updates: 158,528
Cumulative Timesteps: 1,322,164,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,000.66897
Policy Entropy: 3.01105
Value Function Loss: 0.00511

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.61344
Value Function Update Magnitude: 0.56153

Collected Steps per Second: 23,199.44255
Overall Steps per Second: 10,889.84400

Timestep Collection Time: 2.15522
Timestep Consumption Time: 2.43621
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.59143

Cumulative Model Updates: 158,534
Cumulative Timesteps: 1,322,214,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1322214376...
Checkpoint 1322214376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,046.89209
Policy Entropy: 3.01594
Value Function Loss: 0.00490

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.61725
Value Function Update Magnitude: 0.58038

Collected Steps per Second: 23,054.71360
Overall Steps per Second: 10,684.12763

Timestep Collection Time: 2.16962
Timestep Consumption Time: 2.51209
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.68171

Cumulative Model Updates: 158,540
Cumulative Timesteps: 1,322,264,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,711.31466
Policy Entropy: 3.02269
Value Function Loss: 0.00479

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.61190
Value Function Update Magnitude: 0.59414

Collected Steps per Second: 23,060.41000
Overall Steps per Second: 10,858.93239

Timestep Collection Time: 2.16830
Timestep Consumption Time: 2.43638
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60469

Cumulative Model Updates: 158,546
Cumulative Timesteps: 1,322,314,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1322314398...
Checkpoint 1322314398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.36857
Policy Entropy: 3.00603
Value Function Loss: 0.00468

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.60236
Value Function Update Magnitude: 0.56573

Collected Steps per Second: 22,509.51373
Overall Steps per Second: 10,699.03355

Timestep Collection Time: 2.22182
Timestep Consumption Time: 2.45262
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.67444

Cumulative Model Updates: 158,552
Cumulative Timesteps: 1,322,364,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.43808
Policy Entropy: 3.00213
Value Function Loss: 0.00442

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.60032
Value Function Update Magnitude: 0.54695

Collected Steps per Second: 22,929.47333
Overall Steps per Second: 10,938.30532

Timestep Collection Time: 2.18138
Timestep Consumption Time: 2.39135
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.57274

Cumulative Model Updates: 158,558
Cumulative Timesteps: 1,322,414,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1322414428...
Checkpoint 1322414428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.38626
Policy Entropy: 2.98629
Value Function Loss: 0.00453

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.60501
Value Function Update Magnitude: 0.52100

Collected Steps per Second: 22,356.17546
Overall Steps per Second: 10,642.09846

Timestep Collection Time: 2.23652
Timestep Consumption Time: 2.46180
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.69832

Cumulative Model Updates: 158,564
Cumulative Timesteps: 1,322,464,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.13525
Policy Entropy: 3.00467
Value Function Loss: 0.00422

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.60186
Value Function Update Magnitude: 0.50505

Collected Steps per Second: 23,020.66148
Overall Steps per Second: 10,817.80251

Timestep Collection Time: 2.17283
Timestep Consumption Time: 2.45103
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.62386

Cumulative Model Updates: 158,570
Cumulative Timesteps: 1,322,514,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1322514448...
Checkpoint 1322514448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,373.73675
Policy Entropy: 3.00562
Value Function Loss: 0.00414

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.58454
Value Function Update Magnitude: 0.47727

Collected Steps per Second: 22,911.29457
Overall Steps per Second: 10,687.82904

Timestep Collection Time: 2.18312
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.67990

Cumulative Model Updates: 158,576
Cumulative Timesteps: 1,322,564,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,502.15534
Policy Entropy: 3.00000
Value Function Loss: 0.00417

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.57865
Value Function Update Magnitude: 0.47085

Collected Steps per Second: 23,049.34373
Overall Steps per Second: 10,831.98970

Timestep Collection Time: 2.16943
Timestep Consumption Time: 2.44689
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.61633

Cumulative Model Updates: 158,582
Cumulative Timesteps: 1,322,614,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1322614470...
Checkpoint 1322614470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210.61701
Policy Entropy: 3.01473
Value Function Loss: 0.00409

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.57979
Value Function Update Magnitude: 0.48274

Collected Steps per Second: 22,884.59150
Overall Steps per Second: 10,721.37613

Timestep Collection Time: 2.18540
Timestep Consumption Time: 2.47930
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.66470

Cumulative Model Updates: 158,588
Cumulative Timesteps: 1,322,664,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,243.31158
Policy Entropy: 3.01215
Value Function Loss: 0.00405

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.57181
Value Function Update Magnitude: 0.46785

Collected Steps per Second: 23,304.65769
Overall Steps per Second: 10,913.03929

Timestep Collection Time: 2.14567
Timestep Consumption Time: 2.43638
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.58204

Cumulative Model Updates: 158,594
Cumulative Timesteps: 1,322,714,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1322714486...
Checkpoint 1322714486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,323.18596
Policy Entropy: 3.01655
Value Function Loss: 0.00423

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.46586

Collected Steps per Second: 23,029.71570
Overall Steps per Second: 10,690.97229

Timestep Collection Time: 2.17111
Timestep Consumption Time: 2.50574
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.67684

Cumulative Model Updates: 158,600
Cumulative Timesteps: 1,322,764,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.00647
Policy Entropy: 3.00590
Value Function Loss: 0.00473

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.57765
Value Function Update Magnitude: 0.49216

Collected Steps per Second: 23,191.84500
Overall Steps per Second: 10,863.46007

Timestep Collection Time: 2.15722
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.60535

Cumulative Model Updates: 158,606
Cumulative Timesteps: 1,322,814,516

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1322814516...
Checkpoint 1322814516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.15235
Policy Entropy: 3.00480
Value Function Loss: 0.00493

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.58714
Value Function Update Magnitude: 0.51297

Collected Steps per Second: 22,532.92369
Overall Steps per Second: 10,642.96015

Timestep Collection Time: 2.21995
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.70001

Cumulative Model Updates: 158,612
Cumulative Timesteps: 1,322,864,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.98170
Policy Entropy: 3.01053
Value Function Loss: 0.00481

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.58876
Value Function Update Magnitude: 0.51815

Collected Steps per Second: 22,560.61745
Overall Steps per Second: 10,664.40542

Timestep Collection Time: 2.21643
Timestep Consumption Time: 2.47244
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.68887

Cumulative Model Updates: 158,618
Cumulative Timesteps: 1,322,914,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1322914542...
Checkpoint 1322914542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.67253
Policy Entropy: 3.00916
Value Function Loss: 0.00465

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.58337
Value Function Update Magnitude: 0.51816

Collected Steps per Second: 22,242.17205
Overall Steps per Second: 10,775.99459

Timestep Collection Time: 2.24942
Timestep Consumption Time: 2.39349
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.64291

Cumulative Model Updates: 158,624
Cumulative Timesteps: 1,322,964,574

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.12433
Policy Entropy: 3.01289
Value Function Loss: 0.00437

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.58255
Value Function Update Magnitude: 0.51701

Collected Steps per Second: 22,936.05968
Overall Steps per Second: 10,910.11670

Timestep Collection Time: 2.17997
Timestep Consumption Time: 2.40293
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.58290

Cumulative Model Updates: 158,630
Cumulative Timesteps: 1,323,014,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1323014574...
Checkpoint 1323014574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.68452
Policy Entropy: 3.00887
Value Function Loss: 0.00414

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.58071
Value Function Update Magnitude: 0.50946

Collected Steps per Second: 22,791.40132
Overall Steps per Second: 10,713.76927

Timestep Collection Time: 2.19495
Timestep Consumption Time: 2.47437
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.66932

Cumulative Model Updates: 158,636
Cumulative Timesteps: 1,323,064,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,648.32074
Policy Entropy: 2.98820
Value Function Loss: 0.00466

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.59630
Value Function Update Magnitude: 0.52117

Collected Steps per Second: 23,084.58740
Overall Steps per Second: 10,829.69308

Timestep Collection Time: 2.16638
Timestep Consumption Time: 2.45148
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61786

Cumulative Model Updates: 158,642
Cumulative Timesteps: 1,323,114,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1323114610...
Checkpoint 1323114610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,563.02330
Policy Entropy: 3.00522
Value Function Loss: 0.00443

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.60160
Value Function Update Magnitude: 0.55922

Collected Steps per Second: 23,125.53478
Overall Steps per Second: 10,690.82669

Timestep Collection Time: 2.16246
Timestep Consumption Time: 2.51520
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.67766

Cumulative Model Updates: 158,648
Cumulative Timesteps: 1,323,164,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.64638
Policy Entropy: 2.99708
Value Function Loss: 0.00455

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.59826
Value Function Update Magnitude: 0.58510

Collected Steps per Second: 22,681.96064
Overall Steps per Second: 10,842.70094

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.40729
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61195

Cumulative Model Updates: 158,654
Cumulative Timesteps: 1,323,214,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1323214624...
Checkpoint 1323214624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.46479
Policy Entropy: 3.02217
Value Function Loss: 0.00415

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.59274
Value Function Update Magnitude: 0.57206

Collected Steps per Second: 22,268.09720
Overall Steps per Second: 10,678.03858

Timestep Collection Time: 2.24581
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.68344

Cumulative Model Updates: 158,660
Cumulative Timesteps: 1,323,264,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,751.91842
Policy Entropy: 3.00997
Value Function Loss: 0.00457

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.59518
Value Function Update Magnitude: 0.54673

Collected Steps per Second: 22,902.06633
Overall Steps per Second: 10,887.21154

Timestep Collection Time: 2.18408
Timestep Consumption Time: 2.41030
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59438

Cumulative Model Updates: 158,666
Cumulative Timesteps: 1,323,314,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1323314654...
Checkpoint 1323314654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.47340
Policy Entropy: 3.03293
Value Function Loss: 0.00466

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.59083
Value Function Update Magnitude: 0.53289

Collected Steps per Second: 22,974.49246
Overall Steps per Second: 10,710.69714

Timestep Collection Time: 2.17659
Timestep Consumption Time: 2.49220
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.66879

Cumulative Model Updates: 158,672
Cumulative Timesteps: 1,323,364,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.16731
Policy Entropy: 3.03617
Value Function Loss: 0.00428

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.58454
Value Function Update Magnitude: 0.52426

Collected Steps per Second: 23,076.58453
Overall Steps per Second: 10,819.37084

Timestep Collection Time: 2.16765
Timestep Consumption Time: 2.45572
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.62337

Cumulative Model Updates: 158,678
Cumulative Timesteps: 1,323,414,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1323414682...
Checkpoint 1323414682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,978.60963
Policy Entropy: 3.03433
Value Function Loss: 0.00426

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.58360
Value Function Update Magnitude: 0.52333

Collected Steps per Second: 23,186.98562
Overall Steps per Second: 10,701.01032

Timestep Collection Time: 2.15690
Timestep Consumption Time: 2.51668
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.67358

Cumulative Model Updates: 158,684
Cumulative Timesteps: 1,323,464,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,683.28136
Policy Entropy: 3.03257
Value Function Loss: 0.00411

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.58202
Value Function Update Magnitude: 0.51287

Collected Steps per Second: 23,262.93936
Overall Steps per Second: 10,930.21860

Timestep Collection Time: 2.14986
Timestep Consumption Time: 2.42571
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.57557

Cumulative Model Updates: 158,690
Cumulative Timesteps: 1,323,514,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1323514706...
Checkpoint 1323514706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,763.70248
Policy Entropy: 3.01629
Value Function Loss: 0.00448

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.49585

Collected Steps per Second: 23,073.49447
Overall Steps per Second: 10,840.42279

Timestep Collection Time: 2.16751
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.61347

Cumulative Model Updates: 158,696
Cumulative Timesteps: 1,323,564,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.91718
Policy Entropy: 2.99356
Value Function Loss: 0.00481

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.60134
Value Function Update Magnitude: 0.51633

Collected Steps per Second: 23,237.65010
Overall Steps per Second: 10,802.36043

Timestep Collection Time: 2.15263
Timestep Consumption Time: 2.47803
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.63065

Cumulative Model Updates: 158,702
Cumulative Timesteps: 1,323,614,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1323614740...
Checkpoint 1323614740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.46027
Policy Entropy: 2.98981
Value Function Loss: 0.00502

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.61531
Value Function Update Magnitude: 0.53732

Collected Steps per Second: 22,707.95779
Overall Steps per Second: 10,617.91808

Timestep Collection Time: 2.20249
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.71034

Cumulative Model Updates: 158,708
Cumulative Timesteps: 1,323,664,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.26708
Policy Entropy: 2.99414
Value Function Loss: 0.00565

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.62832
Value Function Update Magnitude: 0.55797

Collected Steps per Second: 22,966.22752
Overall Steps per Second: 10,895.68192

Timestep Collection Time: 2.17903
Timestep Consumption Time: 2.41399
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.59301

Cumulative Model Updates: 158,714
Cumulative Timesteps: 1,323,714,798

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1323714798...
Checkpoint 1323714798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.90347
Policy Entropy: 3.01969
Value Function Loss: 0.00505

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.62032
Value Function Update Magnitude: 0.57312

Collected Steps per Second: 22,862.34095
Overall Steps per Second: 10,704.13103

Timestep Collection Time: 2.18762
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.67240

Cumulative Model Updates: 158,720
Cumulative Timesteps: 1,323,764,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.52418
Policy Entropy: 3.02064
Value Function Loss: 0.00490

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.59717
Value Function Update Magnitude: 0.54329

Collected Steps per Second: 23,158.34196
Overall Steps per Second: 10,793.96118

Timestep Collection Time: 2.15931
Timestep Consumption Time: 2.47347
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.63278

Cumulative Model Updates: 158,726
Cumulative Timesteps: 1,323,814,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1323814818...
Checkpoint 1323814818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.44681
Policy Entropy: 3.01599
Value Function Loss: 0.00444

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.57866
Value Function Update Magnitude: 0.49199

Collected Steps per Second: 23,015.63427
Overall Steps per Second: 10,635.67156

Timestep Collection Time: 2.17339
Timestep Consumption Time: 2.52984
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.70323

Cumulative Model Updates: 158,732
Cumulative Timesteps: 1,323,864,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.38639
Policy Entropy: 2.98973
Value Function Loss: 0.00477

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.47563

Collected Steps per Second: 23,362.01252
Overall Steps per Second: 10,934.28394

Timestep Collection Time: 2.14143
Timestep Consumption Time: 2.43391
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.57533

Cumulative Model Updates: 158,738
Cumulative Timesteps: 1,323,914,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1323914868...
Checkpoint 1323914868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.44199
Policy Entropy: 2.97577
Value Function Loss: 0.00445

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.58359
Value Function Update Magnitude: 0.47808

Collected Steps per Second: 22,936.89400
Overall Steps per Second: 10,664.65235

Timestep Collection Time: 2.17998
Timestep Consumption Time: 2.50859
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.68857

Cumulative Model Updates: 158,744
Cumulative Timesteps: 1,323,964,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.49039
Policy Entropy: 2.98382
Value Function Loss: 0.00434

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.58290
Value Function Update Magnitude: 0.49749

Collected Steps per Second: 23,070.46129
Overall Steps per Second: 10,844.17719

Timestep Collection Time: 2.16849
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.61335

Cumulative Model Updates: 158,750
Cumulative Timesteps: 1,324,014,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1324014898...
Checkpoint 1324014898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.81363
Policy Entropy: 2.99828
Value Function Loss: 0.00444

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.59753
Value Function Update Magnitude: 0.53040

Collected Steps per Second: 23,021.67389
Overall Steps per Second: 10,691.54404

Timestep Collection Time: 2.17187
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.67659

Cumulative Model Updates: 158,756
Cumulative Timesteps: 1,324,064,898

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.24077
Policy Entropy: 3.01083
Value Function Loss: 0.00455

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11204
Policy Update Magnitude: 0.60181
Value Function Update Magnitude: 0.57387

Collected Steps per Second: 23,509.97872
Overall Steps per Second: 10,917.44040

Timestep Collection Time: 2.12761
Timestep Consumption Time: 2.45405
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.58166

Cumulative Model Updates: 158,762
Cumulative Timesteps: 1,324,114,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1324114918...
Checkpoint 1324114918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,572.66587
Policy Entropy: 3.00741
Value Function Loss: 0.00443

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.59621
Value Function Update Magnitude: 0.58187

Collected Steps per Second: 22,750.73835
Overall Steps per Second: 10,709.87059

Timestep Collection Time: 2.19896
Timestep Consumption Time: 2.47224
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.67120

Cumulative Model Updates: 158,768
Cumulative Timesteps: 1,324,164,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,054.38713
Policy Entropy: 3.01569
Value Function Loss: 0.00447

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.60115
Value Function Update Magnitude: 0.56207

Collected Steps per Second: 22,775.38186
Overall Steps per Second: 10,787.19268

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.44065
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.63679

Cumulative Model Updates: 158,774
Cumulative Timesteps: 1,324,214,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1324214964...
Checkpoint 1324214964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,502.91975
Policy Entropy: 2.99418
Value Function Loss: 0.00453

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.60876
Value Function Update Magnitude: 0.54726

Collected Steps per Second: 22,445.18531
Overall Steps per Second: 10,660.47595

Timestep Collection Time: 2.22854
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.69210

Cumulative Model Updates: 158,780
Cumulative Timesteps: 1,324,264,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,155.14654
Policy Entropy: 3.01050
Value Function Loss: 0.00448

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.61588
Value Function Update Magnitude: 0.56018

Collected Steps per Second: 22,779.77757
Overall Steps per Second: 10,643.39914

Timestep Collection Time: 2.19633
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70075

Cumulative Model Updates: 158,786
Cumulative Timesteps: 1,324,315,016

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1324315016...
Checkpoint 1324315016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,701.11557
Policy Entropy: 2.99509
Value Function Loss: 0.00460

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.61822
Value Function Update Magnitude: 0.58004

Collected Steps per Second: 23,209.14571
Overall Steps per Second: 10,831.57791

Timestep Collection Time: 2.15450
Timestep Consumption Time: 2.46201
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61650

Cumulative Model Updates: 158,792
Cumulative Timesteps: 1,324,365,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.76951
Policy Entropy: 3.00390
Value Function Loss: 0.00461

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.61240
Value Function Update Magnitude: 0.58124

Collected Steps per Second: 22,918.47455
Overall Steps per Second: 10,669.07466

Timestep Collection Time: 2.18234
Timestep Consumption Time: 2.50560
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.68794

Cumulative Model Updates: 158,798
Cumulative Timesteps: 1,324,415,036

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1324415036...
Checkpoint 1324415036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.65678
Policy Entropy: 3.00177
Value Function Loss: 0.00486

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.61252
Value Function Update Magnitude: 0.59403

Collected Steps per Second: 23,216.67264
Overall Steps per Second: 10,906.46727

Timestep Collection Time: 2.15474
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.58682

Cumulative Model Updates: 158,804
Cumulative Timesteps: 1,324,465,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.03649
Policy Entropy: 3.00352
Value Function Loss: 0.00492

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.61199
Value Function Update Magnitude: 0.61194

Collected Steps per Second: 23,040.02534
Overall Steps per Second: 10,922.65073

Timestep Collection Time: 2.17170
Timestep Consumption Time: 2.40924
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.58094

Cumulative Model Updates: 158,810
Cumulative Timesteps: 1,324,515,098

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1324515098...
Checkpoint 1324515098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.89954
Policy Entropy: 3.00485
Value Function Loss: 0.00472

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.61005
Value Function Update Magnitude: 0.60406

Collected Steps per Second: 23,208.68248
Overall Steps per Second: 10,860.53994

Timestep Collection Time: 2.15523
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.60566

Cumulative Model Updates: 158,816
Cumulative Timesteps: 1,324,565,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,723.91471
Policy Entropy: 2.98781
Value Function Loss: 0.00448

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.60063
Value Function Update Magnitude: 0.56517

Collected Steps per Second: 23,131.19341
Overall Steps per Second: 10,763.58402

Timestep Collection Time: 2.16262
Timestep Consumption Time: 2.48490
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.64752

Cumulative Model Updates: 158,822
Cumulative Timesteps: 1,324,615,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1324615142...
Checkpoint 1324615142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,470.96727
Policy Entropy: 2.98823
Value Function Loss: 0.00423

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.59256
Value Function Update Magnitude: 0.52634

Collected Steps per Second: 22,719.33788
Overall Steps per Second: 10,608.21875

Timestep Collection Time: 2.20174
Timestep Consumption Time: 2.51366
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.71540

Cumulative Model Updates: 158,828
Cumulative Timesteps: 1,324,665,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,250.00679
Policy Entropy: 2.99930
Value Function Loss: 0.00422

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.59410
Value Function Update Magnitude: 0.52412

Collected Steps per Second: 22,825.06567
Overall Steps per Second: 10,826.24417

Timestep Collection Time: 2.19171
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62081

Cumulative Model Updates: 158,834
Cumulative Timesteps: 1,324,715,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1324715190...
Checkpoint 1324715190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,856.22961
Policy Entropy: 3.00527
Value Function Loss: 0.00417

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.59558
Value Function Update Magnitude: 0.54051

Collected Steps per Second: 22,396.96900
Overall Steps per Second: 10,724.21711

Timestep Collection Time: 2.23387
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.66533

Cumulative Model Updates: 158,840
Cumulative Timesteps: 1,324,765,222

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.49407
Policy Entropy: 3.01002
Value Function Loss: 0.00441

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.60474
Value Function Update Magnitude: 0.56558

Collected Steps per Second: 22,717.45912
Overall Steps per Second: 10,655.55383

Timestep Collection Time: 2.20218
Timestep Consumption Time: 2.49283
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69502

Cumulative Model Updates: 158,846
Cumulative Timesteps: 1,324,815,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1324815250...
Checkpoint 1324815250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.97851
Policy Entropy: 2.99267
Value Function Loss: 0.00444

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.60757
Value Function Update Magnitude: 0.58540

Collected Steps per Second: 23,218.29895
Overall Steps per Second: 10,902.40985

Timestep Collection Time: 2.15399
Timestep Consumption Time: 2.43325
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.58724

Cumulative Model Updates: 158,852
Cumulative Timesteps: 1,324,865,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.55130
Policy Entropy: 2.99554
Value Function Loss: 0.00430

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.60069
Value Function Update Magnitude: 0.56132

Collected Steps per Second: 23,304.74672
Overall Steps per Second: 10,938.35056

Timestep Collection Time: 2.14609
Timestep Consumption Time: 2.42627
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.57235

Cumulative Model Updates: 158,858
Cumulative Timesteps: 1,324,915,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1324915276...
Checkpoint 1324915276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.01334
Policy Entropy: 2.99655
Value Function Loss: 0.00413

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.58933
Value Function Update Magnitude: 0.53979

Collected Steps per Second: 22,959.25299
Overall Steps per Second: 10,701.03847

Timestep Collection Time: 2.17856
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.67413

Cumulative Model Updates: 158,864
Cumulative Timesteps: 1,324,965,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,035.09189
Policy Entropy: 3.01602
Value Function Loss: 0.00398

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.58449
Value Function Update Magnitude: 0.52079

Collected Steps per Second: 22,912.24383
Overall Steps per Second: 10,831.57215

Timestep Collection Time: 2.18346
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61872

Cumulative Model Updates: 158,870
Cumulative Timesteps: 1,325,015,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1325015322...
Checkpoint 1325015322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,771.06515
Policy Entropy: 3.00787
Value Function Loss: 0.00428

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.58445
Value Function Update Magnitude: 0.53429

Collected Steps per Second: 23,171.28595
Overall Steps per Second: 10,978.53832

Timestep Collection Time: 2.15897
Timestep Consumption Time: 2.39774
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.55671

Cumulative Model Updates: 158,876
Cumulative Timesteps: 1,325,065,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014.47904
Policy Entropy: 3.02536
Value Function Loss: 0.00453

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.59855
Value Function Update Magnitude: 0.54111

Collected Steps per Second: 22,838.40935
Overall Steps per Second: 10,564.50794

Timestep Collection Time: 2.18999
Timestep Consumption Time: 2.54435
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.73434

Cumulative Model Updates: 158,882
Cumulative Timesteps: 1,325,115,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1325115364...
Checkpoint 1325115364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.63116
Policy Entropy: 3.01633
Value Function Loss: 0.00478

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.59856
Value Function Update Magnitude: 0.55258

Collected Steps per Second: 22,553.94915
Overall Steps per Second: 10,599.15972

Timestep Collection Time: 2.21824
Timestep Consumption Time: 2.50195
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.72019

Cumulative Model Updates: 158,888
Cumulative Timesteps: 1,325,165,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.44907
Policy Entropy: 3.02136
Value Function Loss: 0.00451

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.59619
Value Function Update Magnitude: 0.56658

Collected Steps per Second: 22,952.91995
Overall Steps per Second: 10,682.95049

Timestep Collection Time: 2.17942
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.68260

Cumulative Model Updates: 158,894
Cumulative Timesteps: 1,325,215,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1325215418...
Checkpoint 1325215418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.42556
Policy Entropy: 3.01918
Value Function Loss: 0.00424

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.58396
Value Function Update Magnitude: 0.54394

Collected Steps per Second: 22,671.51762
Overall Steps per Second: 10,781.92316

Timestep Collection Time: 2.20559
Timestep Consumption Time: 2.43218
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.63776

Cumulative Model Updates: 158,900
Cumulative Timesteps: 1,325,265,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.14252
Policy Entropy: 3.01373
Value Function Loss: 0.00400

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.58214
Value Function Update Magnitude: 0.51644

Collected Steps per Second: 22,916.13186
Overall Steps per Second: 10,675.99185

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.68341

Cumulative Model Updates: 158,906
Cumulative Timesteps: 1,325,315,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1325315422...
Checkpoint 1325315422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.96478
Policy Entropy: 3.00048
Value Function Loss: 0.00427

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.59696
Value Function Update Magnitude: 0.52269

Collected Steps per Second: 22,916.93541
Overall Steps per Second: 10,675.18451

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.50337
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.68638

Cumulative Model Updates: 158,912
Cumulative Timesteps: 1,325,365,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,001.92700
Policy Entropy: 2.99304
Value Function Loss: 0.00422

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.61203
Value Function Update Magnitude: 0.53786

Collected Steps per Second: 23,177.83955
Overall Steps per Second: 10,770.95148

Timestep Collection Time: 2.15792
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.64360

Cumulative Model Updates: 158,918
Cumulative Timesteps: 1,325,415,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1325415466...
Checkpoint 1325415466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,093.82575
Policy Entropy: 2.99721
Value Function Loss: 0.00419

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.59479
Value Function Update Magnitude: 0.52533

Collected Steps per Second: 23,202.61383
Overall Steps per Second: 10,793.82987

Timestep Collection Time: 2.15579
Timestep Consumption Time: 2.47834
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.63413

Cumulative Model Updates: 158,924
Cumulative Timesteps: 1,325,465,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.60608
Policy Entropy: 3.00425
Value Function Loss: 0.00428

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.58474
Value Function Update Magnitude: 0.51610

Collected Steps per Second: 23,204.10746
Overall Steps per Second: 10,738.48853

Timestep Collection Time: 2.15600
Timestep Consumption Time: 2.50276
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.65876

Cumulative Model Updates: 158,930
Cumulative Timesteps: 1,325,515,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1325515514...
Checkpoint 1325515514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.66477
Policy Entropy: 3.01080
Value Function Loss: 0.00438

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.59136
Value Function Update Magnitude: 0.51514

Collected Steps per Second: 22,836.63217
Overall Steps per Second: 10,643.45859

Timestep Collection Time: 2.18946
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.69772

Cumulative Model Updates: 158,936
Cumulative Timesteps: 1,325,565,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.01791
Policy Entropy: 3.01395
Value Function Loss: 0.00426

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.58530
Value Function Update Magnitude: 0.52312

Collected Steps per Second: 23,056.95708
Overall Steps per Second: 10,949.59837

Timestep Collection Time: 2.16880
Timestep Consumption Time: 2.39812
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.56693

Cumulative Model Updates: 158,942
Cumulative Timesteps: 1,325,615,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1325615520...
Checkpoint 1325615520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,119.93235
Policy Entropy: 3.02286
Value Function Loss: 0.00410

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.57529
Value Function Update Magnitude: 0.50422

Collected Steps per Second: 22,917.71306
Overall Steps per Second: 10,798.82332

Timestep Collection Time: 2.18189
Timestep Consumption Time: 2.44861
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.63050

Cumulative Model Updates: 158,948
Cumulative Timesteps: 1,325,665,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,473.12664
Policy Entropy: 3.02369
Value Function Loss: 0.00420

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.58269
Value Function Update Magnitude: 0.51677

Collected Steps per Second: 22,614.09783
Overall Steps per Second: 10,711.49153

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.45746
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.66900

Cumulative Model Updates: 158,954
Cumulative Timesteps: 1,325,715,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1325715536...
Checkpoint 1325715536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,251.46357
Policy Entropy: 3.01814
Value Function Loss: 0.00429

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.58656
Value Function Update Magnitude: 0.52034

Collected Steps per Second: 22,844.63320
Overall Steps per Second: 10,605.93637

Timestep Collection Time: 2.18949
Timestep Consumption Time: 2.52655
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.71604

Cumulative Model Updates: 158,960
Cumulative Timesteps: 1,325,765,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,893.84358
Policy Entropy: 3.03119
Value Function Loss: 0.00398

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.58161
Value Function Update Magnitude: 0.52198

Collected Steps per Second: 22,641.40556
Overall Steps per Second: 10,621.84410

Timestep Collection Time: 2.20870
Timestep Consumption Time: 2.49934
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.70803

Cumulative Model Updates: 158,966
Cumulative Timesteps: 1,325,815,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1325815562...
Checkpoint 1325815562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.63192
Policy Entropy: 3.02676
Value Function Loss: 0.00420

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.58094
Value Function Update Magnitude: 0.51957

Collected Steps per Second: 22,845.05899
Overall Steps per Second: 10,706.14650

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.48225
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.67152

Cumulative Model Updates: 158,972
Cumulative Timesteps: 1,325,865,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.58821
Policy Entropy: 3.03844
Value Function Loss: 0.00421

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.58576
Value Function Update Magnitude: 0.52948

Collected Steps per Second: 20,654.24666
Overall Steps per Second: 10,216.62423

Timestep Collection Time: 2.42091
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.89418

Cumulative Model Updates: 158,978
Cumulative Timesteps: 1,325,915,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1325915578...
Checkpoint 1325915578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,256.94366
Policy Entropy: 3.02657
Value Function Loss: 0.00468

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.59223
Value Function Update Magnitude: 0.54991

Collected Steps per Second: 21,798.32760
Overall Steps per Second: 10,319.17472

Timestep Collection Time: 2.29495
Timestep Consumption Time: 2.55292
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.84787

Cumulative Model Updates: 158,984
Cumulative Timesteps: 1,325,965,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,330.17766
Policy Entropy: 3.01736
Value Function Loss: 0.00457

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.59622
Value Function Update Magnitude: 0.56756

Collected Steps per Second: 23,066.58386
Overall Steps per Second: 10,791.88166

Timestep Collection Time: 2.16859
Timestep Consumption Time: 2.46656
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.63515

Cumulative Model Updates: 158,990
Cumulative Timesteps: 1,326,015,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1326015626...
Checkpoint 1326015626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,271.52143
Policy Entropy: 3.00935
Value Function Loss: 0.00444

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.60055
Value Function Update Magnitude: 0.55557

Collected Steps per Second: 22,990.15450
Overall Steps per Second: 10,637.77872

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.52569
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.70079

Cumulative Model Updates: 158,996
Cumulative Timesteps: 1,326,065,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,315.02174
Policy Entropy: 3.01145
Value Function Loss: 0.00439

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.60028
Value Function Update Magnitude: 0.55092

Collected Steps per Second: 23,335.61506
Overall Steps per Second: 11,003.67200

Timestep Collection Time: 2.14385
Timestep Consumption Time: 2.40263
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.54648

Cumulative Model Updates: 159,002
Cumulative Timesteps: 1,326,115,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1326115660...
Checkpoint 1326115660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.97405
Policy Entropy: 3.02567
Value Function Loss: 0.00441

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.59875
Value Function Update Magnitude: 0.54703

Collected Steps per Second: 23,277.62253
Overall Steps per Second: 10,819.00766

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.47460
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.62353

Cumulative Model Updates: 159,008
Cumulative Timesteps: 1,326,165,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,268.00694
Policy Entropy: 3.02120
Value Function Loss: 0.00470

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.59848
Value Function Update Magnitude: 0.55111

Collected Steps per Second: 23,295.03517
Overall Steps per Second: 10,749.45248

Timestep Collection Time: 2.14715
Timestep Consumption Time: 2.50592
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.65307

Cumulative Model Updates: 159,014
Cumulative Timesteps: 1,326,215,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1326215700...
Checkpoint 1326215700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,889.14705
Policy Entropy: 3.01077
Value Function Loss: 0.00479

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.60381
Value Function Update Magnitude: 0.55941

Collected Steps per Second: 22,736.84268
Overall Steps per Second: 10,638.27118

Timestep Collection Time: 2.20031
Timestep Consumption Time: 2.50234
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.70264

Cumulative Model Updates: 159,020
Cumulative Timesteps: 1,326,265,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.20580
Policy Entropy: 3.01629
Value Function Loss: 0.00458

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.60960
Value Function Update Magnitude: 0.58595

Collected Steps per Second: 22,834.78363
Overall Steps per Second: 10,823.71946

Timestep Collection Time: 2.19052
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.62133

Cumulative Model Updates: 159,026
Cumulative Timesteps: 1,326,315,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1326315748...
Checkpoint 1326315748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.62302
Policy Entropy: 3.01358
Value Function Loss: 0.00440

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.60380
Value Function Update Magnitude: 0.61847

Collected Steps per Second: 22,733.33469
Overall Steps per Second: 10,663.61850

Timestep Collection Time: 2.20038
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69090

Cumulative Model Updates: 159,032
Cumulative Timesteps: 1,326,365,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,312.31908
Policy Entropy: 3.01111
Value Function Loss: 0.00419

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.60218
Value Function Update Magnitude: 0.61704

Collected Steps per Second: 22,798.40405
Overall Steps per Second: 10,846.12645

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.41767
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.61160

Cumulative Model Updates: 159,038
Cumulative Timesteps: 1,326,415,788

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1326415788...
Checkpoint 1326415788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439.59018
Policy Entropy: 2.99532
Value Function Loss: 0.00463

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.60355
Value Function Update Magnitude: 0.58778

Collected Steps per Second: 23,032.97513
Overall Steps per Second: 10,695.35585

Timestep Collection Time: 2.17280
Timestep Consumption Time: 2.50643
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.67923

Cumulative Model Updates: 159,044
Cumulative Timesteps: 1,326,465,834

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.46178
Policy Entropy: 2.99826
Value Function Loss: 0.00441

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.59462
Value Function Update Magnitude: 0.55244

Collected Steps per Second: 23,034.36359
Overall Steps per Second: 10,825.80498

Timestep Collection Time: 2.17128
Timestep Consumption Time: 2.44861
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.61989

Cumulative Model Updates: 159,050
Cumulative Timesteps: 1,326,515,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1326515848...
Checkpoint 1326515848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657.28954
Policy Entropy: 3.00209
Value Function Loss: 0.00433

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.58625
Value Function Update Magnitude: 0.51739

Collected Steps per Second: 22,932.87743
Overall Steps per Second: 10,723.88266

Timestep Collection Time: 2.18106
Timestep Consumption Time: 2.48311
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.66417

Cumulative Model Updates: 159,056
Cumulative Timesteps: 1,326,565,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.28253
Policy Entropy: 3.00352
Value Function Loss: 0.00425

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.59137
Value Function Update Magnitude: 0.52309

Collected Steps per Second: 22,900.29330
Overall Steps per Second: 10,801.59192

Timestep Collection Time: 2.18425
Timestep Consumption Time: 2.44655
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.63080

Cumulative Model Updates: 159,062
Cumulative Timesteps: 1,326,615,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1326615886...
Checkpoint 1326615886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.95585
Policy Entropy: 3.00817
Value Function Loss: 0.00437

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.59240
Value Function Update Magnitude: 0.54185

Collected Steps per Second: 23,114.44423
Overall Steps per Second: 10,757.27722

Timestep Collection Time: 2.16393
Timestep Consumption Time: 2.48576
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.64969

Cumulative Model Updates: 159,068
Cumulative Timesteps: 1,326,665,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.43302
Policy Entropy: 3.01940
Value Function Loss: 0.00443

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.58037
Value Function Update Magnitude: 0.52058

Collected Steps per Second: 22,824.97889
Overall Steps per Second: 10,826.31551

Timestep Collection Time: 2.19085
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61893

Cumulative Model Updates: 159,074
Cumulative Timesteps: 1,326,715,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1326715910...
Checkpoint 1326715910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,936.63878
Policy Entropy: 3.02705
Value Function Loss: 0.00452

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.58456
Value Function Update Magnitude: 0.52550

Collected Steps per Second: 22,860.56527
Overall Steps per Second: 10,751.06772

Timestep Collection Time: 2.18726
Timestep Consumption Time: 2.46363
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.65089

Cumulative Model Updates: 159,080
Cumulative Timesteps: 1,326,765,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.10416
Policy Entropy: 3.03119
Value Function Loss: 0.00432

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.58840
Value Function Update Magnitude: 0.51398

Collected Steps per Second: 22,933.42572
Overall Steps per Second: 10,835.36300

Timestep Collection Time: 2.18144
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.61710

Cumulative Model Updates: 159,086
Cumulative Timesteps: 1,326,815,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1326815940...
Checkpoint 1326815940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936.13704
Policy Entropy: 3.02443
Value Function Loss: 0.00457

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.58255
Value Function Update Magnitude: 0.50586

Collected Steps per Second: 22,433.47089
Overall Steps per Second: 10,704.79330

Timestep Collection Time: 2.22935
Timestep Consumption Time: 2.44258
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.67193

Cumulative Model Updates: 159,092
Cumulative Timesteps: 1,326,865,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,458.24489
Policy Entropy: 3.02825
Value Function Loss: 0.00473

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.59270
Value Function Update Magnitude: 0.53076

Collected Steps per Second: 22,897.51779
Overall Steps per Second: 10,819.75158

Timestep Collection Time: 2.18478
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.62358

Cumulative Model Updates: 159,098
Cumulative Timesteps: 1,326,915,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1326915978...
Checkpoint 1326915978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080.28178
Policy Entropy: 3.01916
Value Function Loss: 0.00474

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.59535
Value Function Update Magnitude: 0.55817

Collected Steps per Second: 22,415.96087
Overall Steps per Second: 10,733.37347

Timestep Collection Time: 2.23216
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.66172

Cumulative Model Updates: 159,104
Cumulative Timesteps: 1,326,966,014

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.72165
Policy Entropy: 3.02495
Value Function Loss: 0.00469

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.60038
Value Function Update Magnitude: 0.57112

Collected Steps per Second: 23,117.21710
Overall Steps per Second: 10,861.44676

Timestep Collection Time: 2.16289
Timestep Consumption Time: 2.44055
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.60344

Cumulative Model Updates: 159,110
Cumulative Timesteps: 1,327,016,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1327016014...
Checkpoint 1327016014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,048.36116
Policy Entropy: 3.01534
Value Function Loss: 0.00471

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.60276
Value Function Update Magnitude: 0.56618

Collected Steps per Second: 22,822.36245
Overall Steps per Second: 10,666.67940

Timestep Collection Time: 2.19197
Timestep Consumption Time: 2.49796
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.68993

Cumulative Model Updates: 159,116
Cumulative Timesteps: 1,327,066,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.88745
Policy Entropy: 3.01441
Value Function Loss: 0.00481

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.60603
Value Function Update Magnitude: 0.55352

Collected Steps per Second: 22,881.10866
Overall Steps per Second: 10,731.53689

Timestep Collection Time: 2.18626
Timestep Consumption Time: 2.47514
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.66140

Cumulative Model Updates: 159,122
Cumulative Timesteps: 1,327,116,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1327116064...
Checkpoint 1327116064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.70796
Policy Entropy: 3.01174
Value Function Loss: 0.00470

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.59967
Value Function Update Magnitude: 0.52720

Collected Steps per Second: 22,806.24805
Overall Steps per Second: 10,847.34514

Timestep Collection Time: 2.19352
Timestep Consumption Time: 2.41830
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61182

Cumulative Model Updates: 159,128
Cumulative Timesteps: 1,327,166,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,806.29252
Policy Entropy: 2.99990
Value Function Loss: 0.00497

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.59795
Value Function Update Magnitude: 0.52472

Collected Steps per Second: 23,104.91646
Overall Steps per Second: 10,877.88986

Timestep Collection Time: 2.16491
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.59832

Cumulative Model Updates: 159,134
Cumulative Timesteps: 1,327,216,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1327216110...
Checkpoint 1327216110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,490.39926
Policy Entropy: 3.00491
Value Function Loss: 0.00463

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.60026
Value Function Update Magnitude: 0.53269

Collected Steps per Second: 23,102.11551
Overall Steps per Second: 10,714.62181

Timestep Collection Time: 2.16604
Timestep Consumption Time: 2.50422
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.67025

Cumulative Model Updates: 159,140
Cumulative Timesteps: 1,327,266,150

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.64089
Policy Entropy: 3.01114
Value Function Loss: 0.00424

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.58780
Value Function Update Magnitude: 0.50756

Collected Steps per Second: 22,589.58464
Overall Steps per Second: 10,650.75872

Timestep Collection Time: 2.21403
Timestep Consumption Time: 2.48179
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.69582

Cumulative Model Updates: 159,146
Cumulative Timesteps: 1,327,316,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1327316164...
Checkpoint 1327316164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.63595
Policy Entropy: 3.02320
Value Function Loss: 0.00402

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.47330

Collected Steps per Second: 22,582.16511
Overall Steps per Second: 10,822.27009

Timestep Collection Time: 2.21485
Timestep Consumption Time: 2.40674
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.62158

Cumulative Model Updates: 159,152
Cumulative Timesteps: 1,327,366,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,871.44094
Policy Entropy: 3.03529
Value Function Loss: 0.00403

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.47891

Collected Steps per Second: 22,736.14700
Overall Steps per Second: 10,644.16842

Timestep Collection Time: 2.19967
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.69854

Cumulative Model Updates: 159,158
Cumulative Timesteps: 1,327,416,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1327416192...
Checkpoint 1327416192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,409.29286
Policy Entropy: 3.02036
Value Function Loss: 0.00426

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.58095
Value Function Update Magnitude: 0.49614

Collected Steps per Second: 22,706.80045
Overall Steps per Second: 10,661.26422

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.48839
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.69081

Cumulative Model Updates: 159,164
Cumulative Timesteps: 1,327,466,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,782.18455
Policy Entropy: 3.03907
Value Function Loss: 0.00415

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10863
Policy Update Magnitude: 0.58386
Value Function Update Magnitude: 0.51374

Collected Steps per Second: 23,183.11644
Overall Steps per Second: 10,727.74689

Timestep Collection Time: 2.15691
Timestep Consumption Time: 2.50427
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.66118

Cumulative Model Updates: 159,170
Cumulative Timesteps: 1,327,516,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1327516206...
Checkpoint 1327516206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,507.49578
Policy Entropy: 3.01975
Value Function Loss: 0.00436

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.58799
Value Function Update Magnitude: 0.51049

Collected Steps per Second: 23,184.57706
Overall Steps per Second: 10,850.65245

Timestep Collection Time: 2.15730
Timestep Consumption Time: 2.45220
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.60949

Cumulative Model Updates: 159,176
Cumulative Timesteps: 1,327,566,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,083.93646
Policy Entropy: 3.03474
Value Function Loss: 0.00409

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.58491
Value Function Update Magnitude: 0.50433

Collected Steps per Second: 23,173.28815
Overall Steps per Second: 10,682.38717

Timestep Collection Time: 2.15930
Timestep Consumption Time: 2.52486
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.68416

Cumulative Model Updates: 159,182
Cumulative Timesteps: 1,327,616,260

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1327616260...
Checkpoint 1327616260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.47253
Policy Entropy: 3.03070
Value Function Loss: 0.00400

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.57275
Value Function Update Magnitude: 0.50099

Collected Steps per Second: 23,017.85916
Overall Steps per Second: 10,686.38570

Timestep Collection Time: 2.17336
Timestep Consumption Time: 2.50793
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.68128

Cumulative Model Updates: 159,188
Cumulative Timesteps: 1,327,666,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,438.40587
Policy Entropy: 3.03426
Value Function Loss: 0.00392

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.57183
Value Function Update Magnitude: 0.48553

Collected Steps per Second: 23,289.12450
Overall Steps per Second: 10,940.73983

Timestep Collection Time: 2.14821
Timestep Consumption Time: 2.42460
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.57282

Cumulative Model Updates: 159,194
Cumulative Timesteps: 1,327,716,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1327716316...
Checkpoint 1327716316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,181.38823
Policy Entropy: 3.02530
Value Function Loss: 0.00426

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.58712
Value Function Update Magnitude: 0.50757

Collected Steps per Second: 23,280.27476
Overall Steps per Second: 10,784.91297

Timestep Collection Time: 2.14886
Timestep Consumption Time: 2.48966
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.63852

Cumulative Model Updates: 159,200
Cumulative Timesteps: 1,327,766,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,569.78861
Policy Entropy: 3.02967
Value Function Loss: 0.00410

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.58337
Value Function Update Magnitude: 0.52241

Collected Steps per Second: 22,877.16938
Overall Steps per Second: 10,680.37687

Timestep Collection Time: 2.18567
Timestep Consumption Time: 2.49600
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.68167

Cumulative Model Updates: 159,206
Cumulative Timesteps: 1,327,816,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1327816344...
Checkpoint 1327816344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,016.97527
Policy Entropy: 3.03010
Value Function Loss: 0.00423

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.50218

Collected Steps per Second: 22,549.01294
Overall Steps per Second: 10,667.80211

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.47099
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.68963

Cumulative Model Updates: 159,212
Cumulative Timesteps: 1,327,866,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,021.35922
Policy Entropy: 3.02756
Value Function Loss: 0.00415

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.57427
Value Function Update Magnitude: 0.50563

Collected Steps per Second: 22,721.27767
Overall Steps per Second: 10,865.27867

Timestep Collection Time: 2.20181
Timestep Consumption Time: 2.40258
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.60439

Cumulative Model Updates: 159,218
Cumulative Timesteps: 1,327,916,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1327916400...
Checkpoint 1327916400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171.22881
Policy Entropy: 3.03754
Value Function Loss: 0.00416

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.49932

Collected Steps per Second: 22,645.16587
Overall Steps per Second: 10,651.37672

Timestep Collection Time: 2.20815
Timestep Consumption Time: 2.48645
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.69460

Cumulative Model Updates: 159,224
Cumulative Timesteps: 1,327,966,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,061.75058
Policy Entropy: 3.05722
Value Function Loss: 0.00410

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.57082
Value Function Update Magnitude: 0.50480

Collected Steps per Second: 22,568.96565
Overall Steps per Second: 10,559.80056

Timestep Collection Time: 2.21587
Timestep Consumption Time: 2.52001
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.73588

Cumulative Model Updates: 159,230
Cumulative Timesteps: 1,328,016,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1328016414...
Checkpoint 1328016414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.20955
Policy Entropy: 3.05374
Value Function Loss: 0.00446

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.58320
Value Function Update Magnitude: 0.51403

Collected Steps per Second: 23,234.94945
Overall Steps per Second: 10,659.45630

Timestep Collection Time: 2.15365
Timestep Consumption Time: 2.54077
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.69442

Cumulative Model Updates: 159,236
Cumulative Timesteps: 1,328,066,454

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.75895
Policy Entropy: 3.05637
Value Function Loss: 0.00417

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.58140
Value Function Update Magnitude: 0.52588

Collected Steps per Second: 23,310.09067
Overall Steps per Second: 10,763.44993

Timestep Collection Time: 2.14542
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.64628

Cumulative Model Updates: 159,242
Cumulative Timesteps: 1,328,116,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1328116464...
Checkpoint 1328116464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,568.08205
Policy Entropy: 3.04846
Value Function Loss: 0.00446

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.57500
Value Function Update Magnitude: 0.52283

Collected Steps per Second: 23,249.97763
Overall Steps per Second: 10,753.94373

Timestep Collection Time: 2.15252
Timestep Consumption Time: 2.50122
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.65373

Cumulative Model Updates: 159,248
Cumulative Timesteps: 1,328,166,510

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,336.71017
Policy Entropy: 3.05581
Value Function Loss: 0.00381

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.56498
Value Function Update Magnitude: 0.49379

Collected Steps per Second: 22,859.26606
Overall Steps per Second: 10,789.43513

Timestep Collection Time: 2.18861
Timestep Consumption Time: 2.44833
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.63694

Cumulative Model Updates: 159,254
Cumulative Timesteps: 1,328,216,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1328216540...
Checkpoint 1328216540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,814.49685
Policy Entropy: 3.03798
Value Function Loss: 0.00433

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.56377
Value Function Update Magnitude: 0.48121

Collected Steps per Second: 23,156.95494
Overall Steps per Second: 10,724.94029

Timestep Collection Time: 2.15926
Timestep Consumption Time: 2.50295
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.66222

Cumulative Model Updates: 159,260
Cumulative Timesteps: 1,328,266,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,115.30234
Policy Entropy: 3.03803
Value Function Loss: 0.00400

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.56429
Value Function Update Magnitude: 0.47459

Collected Steps per Second: 23,334.57106
Overall Steps per Second: 10,879.61978

Timestep Collection Time: 2.14291
Timestep Consumption Time: 2.45320
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.59612

Cumulative Model Updates: 159,266
Cumulative Timesteps: 1,328,316,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1328316546...
Checkpoint 1328316546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,211.11838
Policy Entropy: 3.02321
Value Function Loss: 0.00394

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.55731
Value Function Update Magnitude: 0.47096

Collected Steps per Second: 22,745.52169
Overall Steps per Second: 10,632.52402

Timestep Collection Time: 2.19938
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.70500

Cumulative Model Updates: 159,272
Cumulative Timesteps: 1,328,366,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,397.22266
Policy Entropy: 3.04121
Value Function Loss: 0.00379

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.55975
Value Function Update Magnitude: 0.46638

Collected Steps per Second: 22,482.84823
Overall Steps per Second: 10,610.01610

Timestep Collection Time: 2.22436
Timestep Consumption Time: 2.48911
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.71347

Cumulative Model Updates: 159,278
Cumulative Timesteps: 1,328,416,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1328416582...
Checkpoint 1328416582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.91188
Policy Entropy: 3.02438
Value Function Loss: 0.00421

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.48109

Collected Steps per Second: 22,374.24366
Overall Steps per Second: 10,538.35810

Timestep Collection Time: 2.23480
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.74476

Cumulative Model Updates: 159,284
Cumulative Timesteps: 1,328,466,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,633.44319
Policy Entropy: 3.02802
Value Function Loss: 0.00430

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.58194
Value Function Update Magnitude: 0.51472

Collected Steps per Second: 22,680.65396
Overall Steps per Second: 10,761.89889

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.64769

Cumulative Model Updates: 159,290
Cumulative Timesteps: 1,328,516,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1328516602...
Checkpoint 1328516602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.34517
Policy Entropy: 3.01843
Value Function Loss: 0.00421

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.51214

Collected Steps per Second: 22,940.23945
Overall Steps per Second: 10,705.39899

Timestep Collection Time: 2.18062
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.67278

Cumulative Model Updates: 159,296
Cumulative Timesteps: 1,328,566,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.41004
Policy Entropy: 3.02168
Value Function Loss: 0.00412

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.56789
Value Function Update Magnitude: 0.49200

Collected Steps per Second: 23,379.40618
Overall Steps per Second: 10,901.82944

Timestep Collection Time: 2.13958
Timestep Consumption Time: 2.44883
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.58840

Cumulative Model Updates: 159,302
Cumulative Timesteps: 1,328,616,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1328616648...
Checkpoint 1328616648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,345.66207
Policy Entropy: 3.02998
Value Function Loss: 0.00425

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.57744
Value Function Update Magnitude: 0.51306

Collected Steps per Second: 22,830.22225
Overall Steps per Second: 10,706.25975

Timestep Collection Time: 2.19218
Timestep Consumption Time: 2.48247
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.67465

Cumulative Model Updates: 159,308
Cumulative Timesteps: 1,328,666,696

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,410.72719
Policy Entropy: 3.04283
Value Function Loss: 0.00415

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.58892
Value Function Update Magnitude: 0.55237

Collected Steps per Second: 23,104.44428
Overall Steps per Second: 10,876.90838

Timestep Collection Time: 2.16435
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.59745

Cumulative Model Updates: 159,314
Cumulative Timesteps: 1,328,716,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1328716702...
Checkpoint 1328716702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.07981
Policy Entropy: 3.05756
Value Function Loss: 0.00399

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.53972

Collected Steps per Second: 22,956.12154
Overall Steps per Second: 10,693.73797

Timestep Collection Time: 2.17894
Timestep Consumption Time: 2.49856
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.67750

Cumulative Model Updates: 159,320
Cumulative Timesteps: 1,328,766,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.22428
Policy Entropy: 3.06331
Value Function Loss: 0.00371

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.57024
Value Function Update Magnitude: 0.50948

Collected Steps per Second: 23,248.79083
Overall Steps per Second: 10,892.21078

Timestep Collection Time: 2.15203
Timestep Consumption Time: 2.44135
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.59337

Cumulative Model Updates: 159,326
Cumulative Timesteps: 1,328,816,754

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1328816754...
Checkpoint 1328816754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.69323
Policy Entropy: 3.05123
Value Function Loss: 0.00371

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.55862
Value Function Update Magnitude: 0.49922

Collected Steps per Second: 22,659.33483
Overall Steps per Second: 10,649.44590

Timestep Collection Time: 2.20783
Timestep Consumption Time: 2.48988
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.69771

Cumulative Model Updates: 159,332
Cumulative Timesteps: 1,328,866,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,367.25185
Policy Entropy: 3.03787
Value Function Loss: 0.00393

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.56127
Value Function Update Magnitude: 0.51273

Collected Steps per Second: 22,856.46586
Overall Steps per Second: 10,821.62810

Timestep Collection Time: 2.18783
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.62093

Cumulative Model Updates: 159,338
Cumulative Timesteps: 1,328,916,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1328916788...
Checkpoint 1328916788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,382.08453
Policy Entropy: 3.03362
Value Function Loss: 0.00380

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.55906
Value Function Update Magnitude: 0.50729

Collected Steps per Second: 20,497.38850
Overall Steps per Second: 10,285.41894

Timestep Collection Time: 2.44168
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.86592

Cumulative Model Updates: 159,344
Cumulative Timesteps: 1,328,966,836

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.78009
Policy Entropy: 3.03082
Value Function Loss: 0.00423

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.57446
Value Function Update Magnitude: 0.49820

Collected Steps per Second: 22,386.95167
Overall Steps per Second: 10,857.28778

Timestep Collection Time: 2.23469
Timestep Consumption Time: 2.37309
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.60778

Cumulative Model Updates: 159,350
Cumulative Timesteps: 1,329,016,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1329016864...
Checkpoint 1329016864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.43111
Policy Entropy: 3.02577
Value Function Loss: 0.00435

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.58512
Value Function Update Magnitude: 0.51037

Collected Steps per Second: 22,252.01063
Overall Steps per Second: 10,669.83548

Timestep Collection Time: 2.24726
Timestep Consumption Time: 2.43941
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.68667

Cumulative Model Updates: 159,356
Cumulative Timesteps: 1,329,066,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.43887
Policy Entropy: 3.02191
Value Function Loss: 0.00447

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.58674
Value Function Update Magnitude: 0.52416

Collected Steps per Second: 22,402.31959
Overall Steps per Second: 10,890.20692

Timestep Collection Time: 2.23280
Timestep Consumption Time: 2.36031
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.59312

Cumulative Model Updates: 159,362
Cumulative Timesteps: 1,329,116,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1329116890...
Checkpoint 1329116890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,874.87757
Policy Entropy: 3.02788
Value Function Loss: 0.00440

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.58542
Value Function Update Magnitude: 0.52851

Collected Steps per Second: 22,222.87797
Overall Steps per Second: 10,657.95809

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.69189

Cumulative Model Updates: 159,368
Cumulative Timesteps: 1,329,166,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,091.87051
Policy Entropy: 3.03114
Value Function Loss: 0.00434

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.59046
Value Function Update Magnitude: 0.51773

Collected Steps per Second: 22,576.92684
Overall Steps per Second: 10,892.93396

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.37615
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.59142

Cumulative Model Updates: 159,374
Cumulative Timesteps: 1,329,216,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1329216910...
Checkpoint 1329216910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,280.23643
Policy Entropy: 3.03085
Value Function Loss: 0.00437

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.59265
Value Function Update Magnitude: 0.53231

Collected Steps per Second: 22,129.01677
Overall Steps per Second: 10,709.29319

Timestep Collection Time: 2.25948
Timestep Consumption Time: 2.40937
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.66884

Cumulative Model Updates: 159,380
Cumulative Timesteps: 1,329,266,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.85899
Policy Entropy: 3.01087
Value Function Loss: 0.00451

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.60462
Value Function Update Magnitude: 0.52896

Collected Steps per Second: 22,077.20319
Overall Steps per Second: 10,817.68395

Timestep Collection Time: 2.26505
Timestep Consumption Time: 2.35756
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62262

Cumulative Model Updates: 159,386
Cumulative Timesteps: 1,329,316,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1329316916...
Checkpoint 1329316916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,425.11539
Policy Entropy: 3.01817
Value Function Loss: 0.00447

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.60412
Value Function Update Magnitude: 0.52779

Collected Steps per Second: 21,747.97406
Overall Steps per Second: 10,755.58108

Timestep Collection Time: 2.29962
Timestep Consumption Time: 2.35025
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.64986

Cumulative Model Updates: 159,392
Cumulative Timesteps: 1,329,366,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,376.74712
Policy Entropy: 3.00113
Value Function Loss: 0.00468

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.60053
Value Function Update Magnitude: 0.50838

Collected Steps per Second: 22,021.77077
Overall Steps per Second: 10,794.54693

Timestep Collection Time: 2.27166
Timestep Consumption Time: 2.36272
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.63438

Cumulative Model Updates: 159,398
Cumulative Timesteps: 1,329,416,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1329416954...
Checkpoint 1329416954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,468.47970
Policy Entropy: 2.99872
Value Function Loss: 0.00445

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.59928
Value Function Update Magnitude: 0.50016

Collected Steps per Second: 21,886.44661
Overall Steps per Second: 10,669.59940

Timestep Collection Time: 2.28479
Timestep Consumption Time: 2.40198
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.68677

Cumulative Model Updates: 159,404
Cumulative Timesteps: 1,329,466,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.44820
Policy Entropy: 2.97798
Value Function Loss: 0.00465

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.60224
Value Function Update Magnitude: 0.48370

Collected Steps per Second: 22,778.31479
Overall Steps per Second: 10,934.06551

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.37779
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.57286

Cumulative Model Updates: 159,410
Cumulative Timesteps: 1,329,516,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1329516960...
Checkpoint 1329516960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,304.35012
Policy Entropy: 2.98808
Value Function Loss: 0.00485

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.60990
Value Function Update Magnitude: 0.49017

Collected Steps per Second: 22,441.00666
Overall Steps per Second: 10,760.88590

Timestep Collection Time: 2.22869
Timestep Consumption Time: 2.41907
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.64776

Cumulative Model Updates: 159,416
Cumulative Timesteps: 1,329,566,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.54249
Policy Entropy: 2.99315
Value Function Loss: 0.00503

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.61341
Value Function Update Magnitude: 0.51191

Collected Steps per Second: 22,685.49802
Overall Steps per Second: 10,778.72738

Timestep Collection Time: 2.20414
Timestep Consumption Time: 2.43481
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.63895

Cumulative Model Updates: 159,422
Cumulative Timesteps: 1,329,616,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1329616976...
Checkpoint 1329616976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.18367
Policy Entropy: 3.01881
Value Function Loss: 0.00446

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.60053
Value Function Update Magnitude: 0.51932

Collected Steps per Second: 22,176.61144
Overall Steps per Second: 10,695.81412

Timestep Collection Time: 2.25517
Timestep Consumption Time: 2.42068
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.67585

Cumulative Model Updates: 159,428
Cumulative Timesteps: 1,329,666,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.75463
Policy Entropy: 2.99603
Value Function Loss: 0.00439

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.58057
Value Function Update Magnitude: 0.49722

Collected Steps per Second: 22,671.39171
Overall Steps per Second: 10,865.42207

Timestep Collection Time: 2.20586
Timestep Consumption Time: 2.39681
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.60267

Cumulative Model Updates: 159,434
Cumulative Timesteps: 1,329,716,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1329716998...
Checkpoint 1329716998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742.52601
Policy Entropy: 2.98963
Value Function Loss: 0.00445

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11933
Policy Update Magnitude: 0.58168
Value Function Update Magnitude: 0.48722

Collected Steps per Second: 21,964.67054
Overall Steps per Second: 10,617.60633

Timestep Collection Time: 2.27757
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.71161

Cumulative Model Updates: 159,440
Cumulative Timesteps: 1,329,767,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.54030
Policy Entropy: 2.99290
Value Function Loss: 0.00440

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.48067

Collected Steps per Second: 21,704.70862
Overall Steps per Second: 10,559.22033

Timestep Collection Time: 2.30485
Timestep Consumption Time: 2.43281
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.73766

Cumulative Model Updates: 159,446
Cumulative Timesteps: 1,329,817,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1329817050...
Checkpoint 1329817050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,850.42640
Policy Entropy: 3.02016
Value Function Loss: 0.00413

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.47342

Collected Steps per Second: 22,156.52961
Overall Steps per Second: 10,534.11017

Timestep Collection Time: 2.25775
Timestep Consumption Time: 2.49101
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.74876

Cumulative Model Updates: 159,452
Cumulative Timesteps: 1,329,867,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.84592
Policy Entropy: 3.03641
Value Function Loss: 0.00407

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.56520
Value Function Update Magnitude: 0.46978

Collected Steps per Second: 22,839.49921
Overall Steps per Second: 10,867.50366

Timestep Collection Time: 2.19015
Timestep Consumption Time: 2.41274
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60290

Cumulative Model Updates: 159,458
Cumulative Timesteps: 1,329,917,096

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1329917096...
Checkpoint 1329917096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.19660
Policy Entropy: 3.02755
Value Function Loss: 0.00423

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.57109
Value Function Update Magnitude: 0.47344

Collected Steps per Second: 22,651.79591
Overall Steps per Second: 10,685.35207

Timestep Collection Time: 2.20733
Timestep Consumption Time: 2.47197
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.67930

Cumulative Model Updates: 159,464
Cumulative Timesteps: 1,329,967,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,424.45512
Policy Entropy: 3.02488
Value Function Loss: 0.00403

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.56689
Value Function Update Magnitude: 0.48569

Collected Steps per Second: 23,122.38596
Overall Steps per Second: 10,857.05506

Timestep Collection Time: 2.16241
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.60530

Cumulative Model Updates: 159,470
Cumulative Timesteps: 1,330,017,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1330017096...
Checkpoint 1330017096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,931.85522
Policy Entropy: 3.03353
Value Function Loss: 0.00393

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11862
Policy Update Magnitude: 0.56008
Value Function Update Magnitude: 0.48330

Collected Steps per Second: 22,633.57451
Overall Steps per Second: 10,641.57034

Timestep Collection Time: 2.21043
Timestep Consumption Time: 2.49094
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.70137

Cumulative Model Updates: 159,476
Cumulative Timesteps: 1,330,067,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.23537
Policy Entropy: 3.03538
Value Function Loss: 0.00404

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.47092

Collected Steps per Second: 23,396.04212
Overall Steps per Second: 11,012.56523

Timestep Collection Time: 2.13771
Timestep Consumption Time: 2.40383
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.54154

Cumulative Model Updates: 159,482
Cumulative Timesteps: 1,330,117,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1330117140...
Checkpoint 1330117140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.11870
Policy Entropy: 3.03584
Value Function Loss: 0.00431

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.57266
Value Function Update Magnitude: 0.47772

Collected Steps per Second: 22,792.98348
Overall Steps per Second: 10,616.35249

Timestep Collection Time: 2.19454
Timestep Consumption Time: 2.51706
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.71160

Cumulative Model Updates: 159,488
Cumulative Timesteps: 1,330,167,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025.33565
Policy Entropy: 3.02008
Value Function Loss: 0.00471

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.58319
Value Function Update Magnitude: 0.50223

Collected Steps per Second: 23,308.03442
Overall Steps per Second: 10,871.78959

Timestep Collection Time: 2.14596
Timestep Consumption Time: 2.45476
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.60071

Cumulative Model Updates: 159,494
Cumulative Timesteps: 1,330,217,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1330217178...
Checkpoint 1330217178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.80818
Policy Entropy: 3.02069
Value Function Loss: 0.00448

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.49068

Collected Steps per Second: 22,940.35252
Overall Steps per Second: 10,750.85700

Timestep Collection Time: 2.18087
Timestep Consumption Time: 2.47271
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.65358

Cumulative Model Updates: 159,500
Cumulative Timesteps: 1,330,267,208

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.49982
Policy Entropy: 3.01898
Value Function Loss: 0.00452

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.58197
Value Function Update Magnitude: 0.49497

Collected Steps per Second: 22,816.23573
Overall Steps per Second: 10,791.24683

Timestep Collection Time: 2.19195
Timestep Consumption Time: 2.44255
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.63450

Cumulative Model Updates: 159,506
Cumulative Timesteps: 1,330,317,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1330317220...
Checkpoint 1330317220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.72396
Policy Entropy: 3.02167
Value Function Loss: 0.00406

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.57858
Value Function Update Magnitude: 0.50662

Collected Steps per Second: 22,415.71359
Overall Steps per Second: 10,637.43570

Timestep Collection Time: 2.23093
Timestep Consumption Time: 2.47020
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.70113

Cumulative Model Updates: 159,512
Cumulative Timesteps: 1,330,367,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.42869
Policy Entropy: 3.01351
Value Function Loss: 0.00411

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.48675

Collected Steps per Second: 22,825.11063
Overall Steps per Second: 10,683.65547

Timestep Collection Time: 2.19101
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.68098

Cumulative Model Updates: 159,518
Cumulative Timesteps: 1,330,417,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1330417238...
Checkpoint 1330417238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,574.71377
Policy Entropy: 3.02036
Value Function Loss: 0.00403

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.56970
Value Function Update Magnitude: 0.47435

Collected Steps per Second: 22,895.95310
Overall Steps per Second: 10,795.35090

Timestep Collection Time: 2.18458
Timestep Consumption Time: 2.44871
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.63329

Cumulative Model Updates: 159,524
Cumulative Timesteps: 1,330,467,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.81859
Policy Entropy: 3.03079
Value Function Loss: 0.00388

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.56523
Value Function Update Magnitude: 0.47694

Collected Steps per Second: 23,253.81120
Overall Steps per Second: 10,902.48379

Timestep Collection Time: 2.15053
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.58684

Cumulative Model Updates: 159,530
Cumulative Timesteps: 1,330,517,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1330517264...
Checkpoint 1330517264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.15043
Policy Entropy: 3.01933
Value Function Loss: 0.00388

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.57133
Value Function Update Magnitude: 0.47030

Collected Steps per Second: 22,690.42716
Overall Steps per Second: 10,735.44263

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.45517
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.65989

Cumulative Model Updates: 159,536
Cumulative Timesteps: 1,330,567,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.28720
Policy Entropy: 3.00488
Value Function Loss: 0.00388

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.48153

Collected Steps per Second: 23,371.05761
Overall Steps per Second: 10,916.85619

Timestep Collection Time: 2.14068
Timestep Consumption Time: 2.44214
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.58282

Cumulative Model Updates: 159,542
Cumulative Timesteps: 1,330,617,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1330617320...
Checkpoint 1330617320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.04714
Policy Entropy: 2.99979
Value Function Loss: 0.00412

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.59065
Value Function Update Magnitude: 0.48439

Collected Steps per Second: 22,872.80240
Overall Steps per Second: 10,650.41067

Timestep Collection Time: 2.18696
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.69672

Cumulative Model Updates: 159,548
Cumulative Timesteps: 1,330,667,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.64045
Policy Entropy: 2.99873
Value Function Loss: 0.00415

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.59308
Value Function Update Magnitude: 0.49193

Collected Steps per Second: 23,134.98626
Overall Steps per Second: 10,863.87197

Timestep Collection Time: 2.16235
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.60480

Cumulative Model Updates: 159,554
Cumulative Timesteps: 1,330,717,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1330717368...
Checkpoint 1330717368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,445.26513
Policy Entropy: 2.99832
Value Function Loss: 0.00396

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.58404
Value Function Update Magnitude: 0.48241

Collected Steps per Second: 22,431.16343
Overall Steps per Second: 10,746.72233

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.42470
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.65481

Cumulative Model Updates: 159,560
Cumulative Timesteps: 1,330,767,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,271.08908
Policy Entropy: 3.00133
Value Function Loss: 0.00375

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.57458
Value Function Update Magnitude: 0.46276

Collected Steps per Second: 22,936.95025
Overall Steps per Second: 10,808.67262

Timestep Collection Time: 2.18102
Timestep Consumption Time: 2.44730
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62832

Cumulative Model Updates: 159,566
Cumulative Timesteps: 1,330,817,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1330817418...
Checkpoint 1330817418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,726.18406
Policy Entropy: 2.99369
Value Function Loss: 0.00394

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.57642
Value Function Update Magnitude: 0.45211

Collected Steps per Second: 22,608.88180
Overall Steps per Second: 10,662.85557

Timestep Collection Time: 2.21232
Timestep Consumption Time: 2.47855
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.69086

Cumulative Model Updates: 159,572
Cumulative Timesteps: 1,330,867,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,907.07709
Policy Entropy: 2.99011
Value Function Loss: 0.00417

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.46434

Collected Steps per Second: 22,774.95444
Overall Steps per Second: 10,853.77920

Timestep Collection Time: 2.19610
Timestep Consumption Time: 2.41207
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60816

Cumulative Model Updates: 159,578
Cumulative Timesteps: 1,330,917,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1330917452...
Checkpoint 1330917452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.15040
Policy Entropy: 2.97870
Value Function Loss: 0.00456

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.59128
Value Function Update Magnitude: 0.50020

Collected Steps per Second: 22,417.39402
Overall Steps per Second: 10,723.98177

Timestep Collection Time: 2.23095
Timestep Consumption Time: 2.43262
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.66357

Cumulative Model Updates: 159,584
Cumulative Timesteps: 1,330,967,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,816.86030
Policy Entropy: 2.99467
Value Function Loss: 0.00447

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.59755
Value Function Update Magnitude: 0.53029

Collected Steps per Second: 23,204.80645
Overall Steps per Second: 10,882.92813

Timestep Collection Time: 2.15559
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.59619

Cumulative Model Updates: 159,590
Cumulative Timesteps: 1,331,017,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1331017484...
Checkpoint 1331017484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.83646
Policy Entropy: 3.00057
Value Function Loss: 0.00479

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.59690
Value Function Update Magnitude: 0.51131

Collected Steps per Second: 22,866.16309
Overall Steps per Second: 10,736.82376

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.47102
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.65836

Cumulative Model Updates: 159,596
Cumulative Timesteps: 1,331,067,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,862.08540
Policy Entropy: 3.00783
Value Function Loss: 0.00453

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.50602

Collected Steps per Second: 23,598.74655
Overall Steps per Second: 10,803.63136

Timestep Collection Time: 2.11876
Timestep Consumption Time: 2.50932
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.62807

Cumulative Model Updates: 159,602
Cumulative Timesteps: 1,331,117,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1331117500...
Checkpoint 1331117500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159.85982
Policy Entropy: 2.98339
Value Function Loss: 0.00457

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.59379
Value Function Update Magnitude: 0.51917

Collected Steps per Second: 22,892.37522
Overall Steps per Second: 10,645.01435

Timestep Collection Time: 2.18474
Timestep Consumption Time: 2.51360
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.69835

Cumulative Model Updates: 159,608
Cumulative Timesteps: 1,331,167,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.99648
Policy Entropy: 2.97312
Value Function Loss: 0.00416

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10983
Policy Update Magnitude: 0.59725
Value Function Update Magnitude: 0.52370

Collected Steps per Second: 23,243.40244
Overall Steps per Second: 10,964.25672

Timestep Collection Time: 2.15235
Timestep Consumption Time: 2.41047
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.56283

Cumulative Model Updates: 159,614
Cumulative Timesteps: 1,331,217,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1331217542...
Checkpoint 1331217542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,678.57476
Policy Entropy: 2.97882
Value Function Loss: 0.00411

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10942
Policy Update Magnitude: 0.58342
Value Function Update Magnitude: 0.51566

Collected Steps per Second: 22,868.43658
Overall Steps per Second: 10,669.27506

Timestep Collection Time: 2.18721
Timestep Consumption Time: 2.50083
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.68804

Cumulative Model Updates: 159,620
Cumulative Timesteps: 1,331,267,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.34277
Policy Entropy: 2.99031
Value Function Loss: 0.00429

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.59034
Value Function Update Magnitude: 0.52409

Collected Steps per Second: 22,811.07381
Overall Steps per Second: 10,816.17468

Timestep Collection Time: 2.19288
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.62474

Cumulative Model Updates: 159,626
Cumulative Timesteps: 1,331,317,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1331317582...
Checkpoint 1331317582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.08258
Policy Entropy: 2.98862
Value Function Loss: 0.00418

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.59309
Value Function Update Magnitude: 0.55287

Collected Steps per Second: 22,196.94831
Overall Steps per Second: 10,700.79988

Timestep Collection Time: 2.25265
Timestep Consumption Time: 2.42008
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.67273

Cumulative Model Updates: 159,632
Cumulative Timesteps: 1,331,367,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.31709
Policy Entropy: 2.98637
Value Function Loss: 0.00409

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.59248
Value Function Update Magnitude: 0.54834

Collected Steps per Second: 22,967.28067
Overall Steps per Second: 10,909.23070

Timestep Collection Time: 2.17840
Timestep Consumption Time: 2.40780
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.58621

Cumulative Model Updates: 159,638
Cumulative Timesteps: 1,331,417,616

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1331417616...
Checkpoint 1331417616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,926.59455
Policy Entropy: 3.00232
Value Function Loss: 0.00374

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.57759
Value Function Update Magnitude: 0.51507

Collected Steps per Second: 22,571.89863
Overall Steps per Second: 10,620.54877

Timestep Collection Time: 2.21603
Timestep Consumption Time: 2.49371
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.70974

Cumulative Model Updates: 159,644
Cumulative Timesteps: 1,331,467,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,865.43413
Policy Entropy: 3.01096
Value Function Loss: 0.00394

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.56636
Value Function Update Magnitude: 0.48272

Collected Steps per Second: 23,103.45976
Overall Steps per Second: 10,824.11787

Timestep Collection Time: 2.16504
Timestep Consumption Time: 2.45612
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.62116

Cumulative Model Updates: 159,650
Cumulative Timesteps: 1,331,517,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1331517656...
Checkpoint 1331517656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,898.74818
Policy Entropy: 2.99476
Value Function Loss: 0.00413

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.49055

Collected Steps per Second: 22,711.08567
Overall Steps per Second: 10,680.89875

Timestep Collection Time: 2.20210
Timestep Consumption Time: 2.48028
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.68238

Cumulative Model Updates: 159,656
Cumulative Timesteps: 1,331,567,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,745.07281
Policy Entropy: 2.98514
Value Function Loss: 0.00448

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.58493
Value Function Update Magnitude: 0.51083

Collected Steps per Second: 23,421.56346
Overall Steps per Second: 10,908.83513

Timestep Collection Time: 2.13478
Timestep Consumption Time: 2.44866
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.58344

Cumulative Model Updates: 159,662
Cumulative Timesteps: 1,331,617,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1331617668...
Checkpoint 1331617668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.48975
Policy Entropy: 2.98669
Value Function Loss: 0.00451

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.59483
Value Function Update Magnitude: 0.54708

Collected Steps per Second: 22,984.20760
Overall Steps per Second: 10,768.47733

Timestep Collection Time: 2.17575
Timestep Consumption Time: 2.46817
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.64392

Cumulative Model Updates: 159,668
Cumulative Timesteps: 1,331,667,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,759.02599
Policy Entropy: 2.99527
Value Function Loss: 0.00425

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.58261
Value Function Update Magnitude: 0.54731

Collected Steps per Second: 23,538.07183
Overall Steps per Second: 10,867.92330

Timestep Collection Time: 2.12524
Timestep Consumption Time: 2.47767
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.60290

Cumulative Model Updates: 159,674
Cumulative Timesteps: 1,331,717,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1331717700...
Checkpoint 1331717700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,016.67994
Policy Entropy: 3.00471
Value Function Loss: 0.00413

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.57665
Value Function Update Magnitude: 0.52438

Collected Steps per Second: 22,897.74811
Overall Steps per Second: 10,688.09780

Timestep Collection Time: 2.18432
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.67960

Cumulative Model Updates: 159,680
Cumulative Timesteps: 1,331,767,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,524.39329
Policy Entropy: 2.99775
Value Function Loss: 0.00419

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.57990
Value Function Update Magnitude: 0.50817

Collected Steps per Second: 22,913.16340
Overall Steps per Second: 10,837.13229

Timestep Collection Time: 2.18320
Timestep Consumption Time: 2.43278
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.61598

Cumulative Model Updates: 159,686
Cumulative Timesteps: 1,331,817,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1331817740...
Checkpoint 1331817740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.79829
Policy Entropy: 2.99755
Value Function Loss: 0.00426

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.59808
Value Function Update Magnitude: 0.50743

Collected Steps per Second: 22,798.64459
Overall Steps per Second: 10,770.62405

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.45061
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.64504

Cumulative Model Updates: 159,692
Cumulative Timesteps: 1,331,867,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.02290
Policy Entropy: 3.00015
Value Function Loss: 0.00453

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.60286
Value Function Update Magnitude: 0.52418

Collected Steps per Second: 22,803.90786
Overall Steps per Second: 10,765.20615

Timestep Collection Time: 2.19366
Timestep Consumption Time: 2.45316
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.64682

Cumulative Model Updates: 159,698
Cumulative Timesteps: 1,331,917,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1331917794...
Checkpoint 1331917794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.10564
Policy Entropy: 2.99831
Value Function Loss: 0.00442

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.59245
Value Function Update Magnitude: 0.52194

Collected Steps per Second: 22,475.30371
Overall Steps per Second: 10,647.48570

Timestep Collection Time: 2.22627
Timestep Consumption Time: 2.47306
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.69933

Cumulative Model Updates: 159,704
Cumulative Timesteps: 1,331,967,830

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,584.70853
Policy Entropy: 2.99050
Value Function Loss: 0.00482

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.59986
Value Function Update Magnitude: 0.51330

Collected Steps per Second: 22,815.79551
Overall Steps per Second: 10,533.47583

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.55541
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.74696

Cumulative Model Updates: 159,710
Cumulative Timesteps: 1,332,017,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1332017832...
Checkpoint 1332017832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.08966
Policy Entropy: 2.98783
Value Function Loss: 0.00468

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.60273
Value Function Update Magnitude: 0.52492

Collected Steps per Second: 23,081.27231
Overall Steps per Second: 10,918.71483

Timestep Collection Time: 2.16660
Timestep Consumption Time: 2.41342
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.58003

Cumulative Model Updates: 159,716
Cumulative Timesteps: 1,332,067,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.82860
Policy Entropy: 2.99328
Value Function Loss: 0.00480

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.60168
Value Function Update Magnitude: 0.52231

Collected Steps per Second: 23,409.08363
Overall Steps per Second: 10,909.84252

Timestep Collection Time: 2.13686
Timestep Consumption Time: 2.44817
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.58503

Cumulative Model Updates: 159,722
Cumulative Timesteps: 1,332,117,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1332117862...
Checkpoint 1332117862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.39847
Policy Entropy: 2.99548
Value Function Loss: 0.00471

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.59942
Value Function Update Magnitude: 0.52804

Collected Steps per Second: 22,890.35317
Overall Steps per Second: 10,693.94567

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.49152
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.67610

Cumulative Model Updates: 159,728
Cumulative Timesteps: 1,332,167,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.60448
Policy Entropy: 3.00345
Value Function Loss: 0.00470

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.59320
Value Function Update Magnitude: 0.52965

Collected Steps per Second: 23,378.35568
Overall Steps per Second: 10,912.51879

Timestep Collection Time: 2.13873
Timestep Consumption Time: 2.44316
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.58189

Cumulative Model Updates: 159,734
Cumulative Timesteps: 1,332,217,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1332217868...
Checkpoint 1332217868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,967.82695
Policy Entropy: 2.99293
Value Function Loss: 0.00479

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.60510
Value Function Update Magnitude: 0.54430

Collected Steps per Second: 22,972.83326
Overall Steps per Second: 10,677.17374

Timestep Collection Time: 2.17718
Timestep Consumption Time: 2.50721
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.68439

Cumulative Model Updates: 159,740
Cumulative Timesteps: 1,332,267,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.00898
Policy Entropy: 2.98267
Value Function Loss: 0.00447

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.60044
Value Function Update Magnitude: 0.56558

Collected Steps per Second: 22,773.77866
Overall Steps per Second: 10,776.21131

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.44473
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.64059

Cumulative Model Updates: 159,746
Cumulative Timesteps: 1,332,317,892

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1332317892...
Checkpoint 1332317892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,932.00782
Policy Entropy: 2.97395
Value Function Loss: 0.00467

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.60606
Value Function Update Magnitude: 0.55266

Collected Steps per Second: 22,156.27909
Overall Steps per Second: 10,677.42240

Timestep Collection Time: 2.25814
Timestep Consumption Time: 2.42763
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.68578

Cumulative Model Updates: 159,752
Cumulative Timesteps: 1,332,367,924

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744.50458
Policy Entropy: 2.97059
Value Function Loss: 0.00492

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.61754
Value Function Update Magnitude: 0.54089

Collected Steps per Second: 23,103.01298
Overall Steps per Second: 10,927.98754

Timestep Collection Time: 2.16500
Timestep Consumption Time: 2.41206
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.57706

Cumulative Model Updates: 159,758
Cumulative Timesteps: 1,332,417,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1332417942...
Checkpoint 1332417942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,866.53204
Policy Entropy: 2.97754
Value Function Loss: 0.00494

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.61007
Value Function Update Magnitude: 0.55049

Collected Steps per Second: 22,938.14998
Overall Steps per Second: 10,704.33254

Timestep Collection Time: 2.18117
Timestep Consumption Time: 2.49283
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.67400

Cumulative Model Updates: 159,764
Cumulative Timesteps: 1,332,467,974

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.46383
Policy Entropy: 2.97279
Value Function Loss: 0.00500

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.60687
Value Function Update Magnitude: 0.54065

Collected Steps per Second: 23,505.00599
Overall Steps per Second: 10,862.99932

Timestep Collection Time: 2.12746
Timestep Consumption Time: 2.47587
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.60333

Cumulative Model Updates: 159,770
Cumulative Timesteps: 1,332,517,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1332517980...
Checkpoint 1332517980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,391.59306
Policy Entropy: 2.99978
Value Function Loss: 0.00468

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.60350
Value Function Update Magnitude: 0.53676

Collected Steps per Second: 22,682.07821
Overall Steps per Second: 10,689.60862

Timestep Collection Time: 2.20527
Timestep Consumption Time: 2.47405
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.67931

Cumulative Model Updates: 159,776
Cumulative Timesteps: 1,332,568,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,668.62802
Policy Entropy: 3.00385
Value Function Loss: 0.00458

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.60649
Value Function Update Magnitude: 0.53592

Collected Steps per Second: 23,194.43315
Overall Steps per Second: 10,872.61108

Timestep Collection Time: 2.15578
Timestep Consumption Time: 2.44312
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.59890

Cumulative Model Updates: 159,782
Cumulative Timesteps: 1,332,618,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1332618002...
Checkpoint 1332618002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,234.50229
Policy Entropy: 3.00701
Value Function Loss: 0.00466

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.59673
Value Function Update Magnitude: 0.53958

Collected Steps per Second: 23,050.02459
Overall Steps per Second: 10,658.94115

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.52322
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.69371

Cumulative Model Updates: 159,788
Cumulative Timesteps: 1,332,668,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,655.75168
Policy Entropy: 2.99003
Value Function Loss: 0.00448

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10577
Policy Update Magnitude: 0.59891
Value Function Update Magnitude: 0.53527

Collected Steps per Second: 23,138.64917
Overall Steps per Second: 10,902.95809

Timestep Collection Time: 2.16227
Timestep Consumption Time: 2.42658
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.58885

Cumulative Model Updates: 159,794
Cumulative Timesteps: 1,332,718,064

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1332718064...
Checkpoint 1332718064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.09760
Policy Entropy: 2.99603
Value Function Loss: 0.00437

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.60159
Value Function Update Magnitude: 0.52728

Collected Steps per Second: 22,647.58041
Overall Steps per Second: 10,702.75412

Timestep Collection Time: 2.20809
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.67244

Cumulative Model Updates: 159,800
Cumulative Timesteps: 1,332,768,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.26142
Policy Entropy: 3.00028
Value Function Loss: 0.00402

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.59323
Value Function Update Magnitude: 0.51830

Collected Steps per Second: 22,303.92419
Overall Steps per Second: 10,488.10960

Timestep Collection Time: 2.24230
Timestep Consumption Time: 2.52615
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.76845

Cumulative Model Updates: 159,806
Cumulative Timesteps: 1,332,818,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1332818084...
Checkpoint 1332818084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.86039
Policy Entropy: 2.98882
Value Function Loss: 0.00394

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.59267
Value Function Update Magnitude: 0.50871

Collected Steps per Second: 22,519.63951
Overall Steps per Second: 10,589.02309

Timestep Collection Time: 2.22099
Timestep Consumption Time: 2.50239
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.72338

Cumulative Model Updates: 159,812
Cumulative Timesteps: 1,332,868,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.85099
Policy Entropy: 2.98114
Value Function Loss: 0.00433

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.59959
Value Function Update Magnitude: 0.50050

Collected Steps per Second: 22,920.89007
Overall Steps per Second: 10,805.62162

Timestep Collection Time: 2.18194
Timestep Consumption Time: 2.44639
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62833

Cumulative Model Updates: 159,818
Cumulative Timesteps: 1,332,918,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1332918112...
Checkpoint 1332918112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.35847
Policy Entropy: 2.98914
Value Function Loss: 0.00445

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.59862
Value Function Update Magnitude: 0.48128

Collected Steps per Second: 22,376.20736
Overall Steps per Second: 10,667.49441

Timestep Collection Time: 2.23496
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.68807

Cumulative Model Updates: 159,824
Cumulative Timesteps: 1,332,968,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,278.46926
Policy Entropy: 3.00661
Value Function Loss: 0.00454

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.59107
Value Function Update Magnitude: 0.47631

Collected Steps per Second: 23,478.85723
Overall Steps per Second: 10,879.71315

Timestep Collection Time: 2.13077
Timestep Consumption Time: 2.46751
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.59828

Cumulative Model Updates: 159,830
Cumulative Timesteps: 1,333,018,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1333018150...
Checkpoint 1333018150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.82460
Policy Entropy: 3.01315
Value Function Loss: 0.00433

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.59040
Value Function Update Magnitude: 0.47972

Collected Steps per Second: 23,092.58665
Overall Steps per Second: 10,739.36484

Timestep Collection Time: 2.16598
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.65744

Cumulative Model Updates: 159,836
Cumulative Timesteps: 1,333,068,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.59160
Policy Entropy: 3.01008
Value Function Loss: 0.00460

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.59600
Value Function Update Magnitude: 0.53208

Collected Steps per Second: 23,483.60042
Overall Steps per Second: 10,932.42972

Timestep Collection Time: 2.12991
Timestep Consumption Time: 2.44528
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.57520

Cumulative Model Updates: 159,842
Cumulative Timesteps: 1,333,118,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1333118186...
Checkpoint 1333118186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,352.60571
Policy Entropy: 3.00858
Value Function Loss: 0.00447

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.60086
Value Function Update Magnitude: 0.55197

Collected Steps per Second: 22,858.86715
Overall Steps per Second: 10,629.45595

Timestep Collection Time: 2.18856
Timestep Consumption Time: 2.51798
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.70654

Cumulative Model Updates: 159,848
Cumulative Timesteps: 1,333,168,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.60267
Policy Entropy: 3.01595
Value Function Loss: 0.00465

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.59941
Value Function Update Magnitude: 0.54433

Collected Steps per Second: 23,528.08982
Overall Steps per Second: 10,882.48150

Timestep Collection Time: 2.12520
Timestep Consumption Time: 2.46952
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.59472

Cumulative Model Updates: 159,854
Cumulative Timesteps: 1,333,218,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1333218216...
Checkpoint 1333218216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.40173
Policy Entropy: 3.00721
Value Function Loss: 0.00433

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11804
Policy Update Magnitude: 0.59848
Value Function Update Magnitude: 0.52619

Collected Steps per Second: 22,979.15499
Overall Steps per Second: 10,636.90036

Timestep Collection Time: 2.17623
Timestep Consumption Time: 2.52514
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.70137

Cumulative Model Updates: 159,860
Cumulative Timesteps: 1,333,268,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,516.09139
Policy Entropy: 3.00751
Value Function Loss: 0.00431

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.59747
Value Function Update Magnitude: 0.50636

Collected Steps per Second: 22,407.50697
Overall Steps per Second: 10,563.02718

Timestep Collection Time: 2.23148
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.73368

Cumulative Model Updates: 159,866
Cumulative Timesteps: 1,333,318,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1333318226...
Checkpoint 1333318226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.58289
Policy Entropy: 3.01931
Value Function Loss: 0.00397

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.58678
Value Function Update Magnitude: 0.49724

Collected Steps per Second: 22,976.69356
Overall Steps per Second: 10,756.94613

Timestep Collection Time: 2.17621
Timestep Consumption Time: 2.47214
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.64835

Cumulative Model Updates: 159,872
Cumulative Timesteps: 1,333,368,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,944.37277
Policy Entropy: 3.03844
Value Function Loss: 0.00415

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.57970
Value Function Update Magnitude: 0.48496

Collected Steps per Second: 22,987.95008
Overall Steps per Second: 10,749.33275

Timestep Collection Time: 2.17610
Timestep Consumption Time: 2.47759
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.65368

Cumulative Model Updates: 159,878
Cumulative Timesteps: 1,333,418,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1333418252...
Checkpoint 1333418252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,125.98228
Policy Entropy: 3.04414
Value Function Loss: 0.00405

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.47622

Collected Steps per Second: 22,528.59181
Overall Steps per Second: 10,559.78876

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.51564
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.73513

Cumulative Model Updates: 159,884
Cumulative Timesteps: 1,333,468,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,460.86625
Policy Entropy: 3.03529
Value Function Loss: 0.00432

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.58313
Value Function Update Magnitude: 0.48631

Collected Steps per Second: 23,273.83656
Overall Steps per Second: 10,931.77534

Timestep Collection Time: 2.14834
Timestep Consumption Time: 2.42549
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.57382

Cumulative Model Updates: 159,890
Cumulative Timesteps: 1,333,518,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1333518254...
Checkpoint 1333518254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,809.66817
Policy Entropy: 3.03374
Value Function Loss: 0.00426

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.58724
Value Function Update Magnitude: 0.50412

Collected Steps per Second: 22,890.96838
Overall Steps per Second: 10,650.70342

Timestep Collection Time: 2.18479
Timestep Consumption Time: 2.51086
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.69565

Cumulative Model Updates: 159,896
Cumulative Timesteps: 1,333,568,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843.60912
Policy Entropy: 3.01226
Value Function Loss: 0.00453

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.58692
Value Function Update Magnitude: 0.49905

Collected Steps per Second: 23,375.54432
Overall Steps per Second: 10,941.39820

Timestep Collection Time: 2.13967
Timestep Consumption Time: 2.43159
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.57126

Cumulative Model Updates: 159,902
Cumulative Timesteps: 1,333,618,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1333618282...
Checkpoint 1333618282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912.53441
Policy Entropy: 3.01168
Value Function Loss: 0.00459

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.59154
Value Function Update Magnitude: 0.50610

Collected Steps per Second: 23,242.71911
Overall Steps per Second: 10,804.53647

Timestep Collection Time: 2.15121
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.62769

Cumulative Model Updates: 159,908
Cumulative Timesteps: 1,333,668,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539.05447
Policy Entropy: 3.00556
Value Function Loss: 0.00452

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.59424
Value Function Update Magnitude: 0.53831

Collected Steps per Second: 23,570.43129
Overall Steps per Second: 10,811.56544

Timestep Collection Time: 2.12249
Timestep Consumption Time: 2.50478
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.62727

Cumulative Model Updates: 159,914
Cumulative Timesteps: 1,333,718,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1333718310...
Checkpoint 1333718310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.10010
Policy Entropy: 3.02471
Value Function Loss: 0.00422

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.59573
Value Function Update Magnitude: 0.54194

Collected Steps per Second: 23,019.65166
Overall Steps per Second: 10,732.66913

Timestep Collection Time: 2.17301
Timestep Consumption Time: 2.48771
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.66072

Cumulative Model Updates: 159,920
Cumulative Timesteps: 1,333,768,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,072.06315
Policy Entropy: 3.02370
Value Function Loss: 0.00404

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.53623

Collected Steps per Second: 23,011.11090
Overall Steps per Second: 10,734.64664

Timestep Collection Time: 2.17304
Timestep Consumption Time: 2.48515
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.65819

Cumulative Model Updates: 159,926
Cumulative Timesteps: 1,333,818,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1333818336...
Checkpoint 1333818336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,637.16502
Policy Entropy: 3.03294
Value Function Loss: 0.00390

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.57417
Value Function Update Magnitude: 0.51366

Collected Steps per Second: 22,627.53703
Overall Steps per Second: 10,618.97583

Timestep Collection Time: 2.21093
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.71119

Cumulative Model Updates: 159,932
Cumulative Timesteps: 1,333,868,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.69752
Policy Entropy: 3.02791
Value Function Loss: 0.00401

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.58003
Value Function Update Magnitude: 0.49735

Collected Steps per Second: 22,923.17724
Overall Steps per Second: 10,829.79844

Timestep Collection Time: 2.18155
Timestep Consumption Time: 2.43608
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61763

Cumulative Model Updates: 159,938
Cumulative Timesteps: 1,333,918,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1333918372...
Checkpoint 1333918372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.58829
Policy Entropy: 3.03307
Value Function Loss: 0.00408

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.59202
Value Function Update Magnitude: 0.50900

Collected Steps per Second: 22,331.68033
Overall Steps per Second: 10,789.89244

Timestep Collection Time: 2.23960
Timestep Consumption Time: 2.39567
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.63526

Cumulative Model Updates: 159,944
Cumulative Timesteps: 1,333,968,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.76969
Policy Entropy: 3.02094
Value Function Loss: 0.00442

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.51940

Collected Steps per Second: 23,016.26104
Overall Steps per Second: 10,814.21123

Timestep Collection Time: 2.17359
Timestep Consumption Time: 2.45254
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.62613

Cumulative Model Updates: 159,950
Cumulative Timesteps: 1,334,018,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1334018414...
Checkpoint 1334018414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,640.99655
Policy Entropy: 3.00968
Value Function Loss: 0.00471

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.58703
Value Function Update Magnitude: 0.53194

Collected Steps per Second: 22,751.58335
Overall Steps per Second: 10,679.15502

Timestep Collection Time: 2.19844
Timestep Consumption Time: 2.48526
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.68370

Cumulative Model Updates: 159,956
Cumulative Timesteps: 1,334,068,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937.81355
Policy Entropy: 2.98199
Value Function Loss: 0.00501

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.60173
Value Function Update Magnitude: 0.53263

Collected Steps per Second: 23,062.08660
Overall Steps per Second: 10,936.99454

Timestep Collection Time: 2.16867
Timestep Consumption Time: 2.40425
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.57292

Cumulative Model Updates: 159,962
Cumulative Timesteps: 1,334,118,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1334118446...
Checkpoint 1334118446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.12475
Policy Entropy: 2.99276
Value Function Loss: 0.00494

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.60407
Value Function Update Magnitude: 0.54100

Collected Steps per Second: 23,091.10137
Overall Steps per Second: 10,838.70507

Timestep Collection Time: 2.16534
Timestep Consumption Time: 2.44776
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.61310

Cumulative Model Updates: 159,968
Cumulative Timesteps: 1,334,168,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.13060
Policy Entropy: 3.00341
Value Function Loss: 0.00453

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.59340
Value Function Update Magnitude: 0.54778

Collected Steps per Second: 23,390.76684
Overall Steps per Second: 10,760.73276

Timestep Collection Time: 2.13785
Timestep Consumption Time: 2.50923
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.64708

Cumulative Model Updates: 159,974
Cumulative Timesteps: 1,334,218,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1334218452...
Checkpoint 1334218452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,494.16325
Policy Entropy: 3.02383
Value Function Loss: 0.00434

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.58634
Value Function Update Magnitude: 0.54054

Collected Steps per Second: 22,805.70118
Overall Steps per Second: 10,782.75968

Timestep Collection Time: 2.19357
Timestep Consumption Time: 2.44587
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.63944

Cumulative Model Updates: 159,980
Cumulative Timesteps: 1,334,268,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.76910
Policy Entropy: 3.01658
Value Function Loss: 0.00438

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.59470
Value Function Update Magnitude: 0.53369

Collected Steps per Second: 23,343.91041
Overall Steps per Second: 10,878.92143

Timestep Collection Time: 2.14300
Timestep Consumption Time: 2.45543
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.59843

Cumulative Model Updates: 159,986
Cumulative Timesteps: 1,334,318,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1334318504...
Checkpoint 1334318504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.16605
Policy Entropy: 3.01910
Value Function Loss: 0.00464

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.60798
Value Function Update Magnitude: 0.55599

Collected Steps per Second: 22,717.62830
Overall Steps per Second: 10,825.09639

Timestep Collection Time: 2.20217
Timestep Consumption Time: 2.41932
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.62148

Cumulative Model Updates: 159,992
Cumulative Timesteps: 1,334,368,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.87395
Policy Entropy: 3.02626
Value Function Loss: 0.00472

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.60858
Value Function Update Magnitude: 0.55979

Collected Steps per Second: 22,614.97252
Overall Steps per Second: 10,589.66415

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.51136
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.72291

Cumulative Model Updates: 159,998
Cumulative Timesteps: 1,334,418,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1334418546...
Checkpoint 1334418546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.35088
Policy Entropy: 3.03912
Value Function Loss: 0.00439

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.59858
Value Function Update Magnitude: 0.54463

Collected Steps per Second: 22,628.10564
Overall Steps per Second: 10,580.47417

Timestep Collection Time: 2.21053
Timestep Consumption Time: 2.51705
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.72758

Cumulative Model Updates: 160,004
Cumulative Timesteps: 1,334,468,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,793.39667
Policy Entropy: 3.03403
Value Function Loss: 0.00399

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.57834
Value Function Update Magnitude: 0.48922

Collected Steps per Second: 22,808.16919
Overall Steps per Second: 10,884.81635

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.40213
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.59502

Cumulative Model Updates: 160,010
Cumulative Timesteps: 1,334,518,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1334518582...
Checkpoint 1334518582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,218.78797
Policy Entropy: 3.02336
Value Function Loss: 0.00387

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.56677
Value Function Update Magnitude: 0.45963

Collected Steps per Second: 22,548.05052
Overall Steps per Second: 10,673.99014

Timestep Collection Time: 2.21837
Timestep Consumption Time: 2.46778
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.68616

Cumulative Model Updates: 160,016
Cumulative Timesteps: 1,334,568,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.00103
Policy Entropy: 3.03765
Value Function Loss: 0.00367

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.46087

Collected Steps per Second: 23,237.15514
Overall Steps per Second: 10,853.14779

Timestep Collection Time: 2.15198
Timestep Consumption Time: 2.45553
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.60751

Cumulative Model Updates: 160,022
Cumulative Timesteps: 1,334,618,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1334618608...
Checkpoint 1334618608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,802.08187
Policy Entropy: 3.04017
Value Function Loss: 0.00378

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.44787

Collected Steps per Second: 23,248.55566
Overall Steps per Second: 10,752.86549

Timestep Collection Time: 2.15119
Timestep Consumption Time: 2.49985
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.65104

Cumulative Model Updates: 160,028
Cumulative Timesteps: 1,334,668,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.73099
Policy Entropy: 3.05149
Value Function Loss: 0.00412

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.56335
Value Function Update Magnitude: 0.43712

Collected Steps per Second: 23,326.32542
Overall Steps per Second: 10,844.59052

Timestep Collection Time: 2.14410
Timestep Consumption Time: 2.46778
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.61188

Cumulative Model Updates: 160,034
Cumulative Timesteps: 1,334,718,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1334718634...
Checkpoint 1334718634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.23733
Policy Entropy: 3.03417
Value Function Loss: 0.00447

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.58354
Value Function Update Magnitude: 0.47512

Collected Steps per Second: 22,001.53315
Overall Steps per Second: 10,630.38751

Timestep Collection Time: 2.27257
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.70350

Cumulative Model Updates: 160,040
Cumulative Timesteps: 1,334,768,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,631.51253
Policy Entropy: 3.03070
Value Function Loss: 0.00441

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10723
Policy Update Magnitude: 0.59634
Value Function Update Magnitude: 0.51639

Collected Steps per Second: 22,428.15529
Overall Steps per Second: 10,590.11814

Timestep Collection Time: 2.22943
Timestep Consumption Time: 2.49214
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.72157

Cumulative Model Updates: 160,046
Cumulative Timesteps: 1,334,818,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1334818636...
Checkpoint 1334818636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,338.02472
Policy Entropy: 3.01105
Value Function Loss: 0.00427

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.59990
Value Function Update Magnitude: 0.52812

Collected Steps per Second: 22,224.80820
Overall Steps per Second: 10,604.34389

Timestep Collection Time: 2.24974
Timestep Consumption Time: 2.46531
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.71505

Cumulative Model Updates: 160,052
Cumulative Timesteps: 1,334,868,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.56523
Policy Entropy: 3.01225
Value Function Loss: 0.00444

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.60448
Value Function Update Magnitude: 0.54592

Collected Steps per Second: 22,676.60765
Overall Steps per Second: 10,755.88462

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.44478
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.65066

Cumulative Model Updates: 160,058
Cumulative Timesteps: 1,334,918,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1334918658...
Checkpoint 1334918658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,545.03196
Policy Entropy: 2.98381
Value Function Loss: 0.00492

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.63035
Value Function Update Magnitude: 0.55072

Collected Steps per Second: 22,865.84146
Overall Steps per Second: 10,690.89692

Timestep Collection Time: 2.18728
Timestep Consumption Time: 2.49091
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.67819

Cumulative Model Updates: 160,064
Cumulative Timesteps: 1,334,968,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.39787
Policy Entropy: 2.98954
Value Function Loss: 0.00496

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.63771
Value Function Update Magnitude: 0.56161

Collected Steps per Second: 23,488.75214
Overall Steps per Second: 10,922.56309

Timestep Collection Time: 2.12953
Timestep Consumption Time: 2.44998
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.57951

Cumulative Model Updates: 160,070
Cumulative Timesteps: 1,335,018,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1335018692...
Checkpoint 1335018692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.04492
Policy Entropy: 2.98574
Value Function Loss: 0.00463

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.62311
Value Function Update Magnitude: 0.55483

Collected Steps per Second: 23,136.52251
Overall Steps per Second: 10,722.93679

Timestep Collection Time: 2.16117
Timestep Consumption Time: 2.50192
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.66309

Cumulative Model Updates: 160,076
Cumulative Timesteps: 1,335,068,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,934.35425
Policy Entropy: 3.00542
Value Function Loss: 0.00419

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.60708
Value Function Update Magnitude: 0.54398

Collected Steps per Second: 23,675.45368
Overall Steps per Second: 10,899.18042

Timestep Collection Time: 2.11206
Timestep Consumption Time: 2.47581
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.58787

Cumulative Model Updates: 160,082
Cumulative Timesteps: 1,335,118,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1335118698...
Checkpoint 1335118698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.84388
Policy Entropy: 3.00854
Value Function Loss: 0.00398

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.59708
Value Function Update Magnitude: 0.52753

Collected Steps per Second: 23,063.37692
Overall Steps per Second: 10,953.02559

Timestep Collection Time: 2.16820
Timestep Consumption Time: 2.39730
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.56550

Cumulative Model Updates: 160,088
Cumulative Timesteps: 1,335,168,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,392.40985
Policy Entropy: 3.01435
Value Function Loss: 0.00453

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.61125
Value Function Update Magnitude: 0.52915

Collected Steps per Second: 23,086.36826
Overall Steps per Second: 10,744.23534

Timestep Collection Time: 2.16708
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.65645

Cumulative Model Updates: 160,094
Cumulative Timesteps: 1,335,218,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1335218734...
Checkpoint 1335218734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.32894
Policy Entropy: 3.00861
Value Function Loss: 0.00487

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.62034
Value Function Update Magnitude: 0.55464

Collected Steps per Second: 22,823.00831
Overall Steps per Second: 10,909.80585

Timestep Collection Time: 2.19086
Timestep Consumption Time: 2.39236
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.58322

Cumulative Model Updates: 160,100
Cumulative Timesteps: 1,335,268,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.55406
Policy Entropy: 3.01591
Value Function Loss: 0.00478

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.60604
Value Function Update Magnitude: 0.55287

Collected Steps per Second: 22,895.52249
Overall Steps per Second: 10,907.32452

Timestep Collection Time: 2.18497
Timestep Consumption Time: 2.40149
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.58646

Cumulative Model Updates: 160,106
Cumulative Timesteps: 1,335,318,762

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1335318762...
Checkpoint 1335318762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.28991
Policy Entropy: 3.01454
Value Function Loss: 0.00446

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.59188
Value Function Update Magnitude: 0.53531

Collected Steps per Second: 22,375.98802
Overall Steps per Second: 10,607.70975

Timestep Collection Time: 2.23454
Timestep Consumption Time: 2.47901
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.71355

Cumulative Model Updates: 160,112
Cumulative Timesteps: 1,335,368,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.04285
Policy Entropy: 3.01167
Value Function Loss: 0.00417

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.58299
Value Function Update Magnitude: 0.52445

Collected Steps per Second: 22,680.00845
Overall Steps per Second: 10,628.23063

Timestep Collection Time: 2.20467
Timestep Consumption Time: 2.49997
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.70464

Cumulative Model Updates: 160,118
Cumulative Timesteps: 1,335,418,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1335418764...
Checkpoint 1335418764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.59909
Policy Entropy: 3.00065
Value Function Loss: 0.00428

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.58559
Value Function Update Magnitude: 0.52660

Collected Steps per Second: 23,145.04133
Overall Steps per Second: 10,808.81771

Timestep Collection Time: 2.16072
Timestep Consumption Time: 2.46606
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62678

Cumulative Model Updates: 160,124
Cumulative Timesteps: 1,335,468,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.77955
Policy Entropy: 2.98813
Value Function Loss: 0.00488

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.60222
Value Function Update Magnitude: 0.54375

Collected Steps per Second: 23,182.58106
Overall Steps per Second: 10,949.27711

Timestep Collection Time: 2.15791
Timestep Consumption Time: 2.41097
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.56889

Cumulative Model Updates: 160,130
Cumulative Timesteps: 1,335,518,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1335518800...
Checkpoint 1335518800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.70839
Policy Entropy: 3.01529
Value Function Loss: 0.00466

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.61098
Value Function Update Magnitude: 0.56053

Collected Steps per Second: 22,689.61352
Overall Steps per Second: 10,665.71682

Timestep Collection Time: 2.20392
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.68848

Cumulative Model Updates: 160,136
Cumulative Timesteps: 1,335,568,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894.85146
Policy Entropy: 3.01800
Value Function Loss: 0.00461

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.60648
Value Function Update Magnitude: 0.54813

Collected Steps per Second: 23,373.61916
Overall Steps per Second: 10,899.01748

Timestep Collection Time: 2.13968
Timestep Consumption Time: 2.44899
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.58867

Cumulative Model Updates: 160,142
Cumulative Timesteps: 1,335,618,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1335618818...
Checkpoint 1335618818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,324.12684
Policy Entropy: 3.03263
Value Function Loss: 0.00405

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.59791
Value Function Update Magnitude: 0.51412

Collected Steps per Second: 22,787.97471
Overall Steps per Second: 10,710.96769

Timestep Collection Time: 2.19414
Timestep Consumption Time: 2.47397
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.66811

Cumulative Model Updates: 160,148
Cumulative Timesteps: 1,335,668,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,430.23142
Policy Entropy: 3.01757
Value Function Loss: 0.00435

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.59965
Value Function Update Magnitude: 0.52012

Collected Steps per Second: 23,248.79742
Overall Steps per Second: 10,917.20457

Timestep Collection Time: 2.15073
Timestep Consumption Time: 2.42938
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.58011

Cumulative Model Updates: 160,154
Cumulative Timesteps: 1,335,718,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1335718820...
Checkpoint 1335718820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.61911
Policy Entropy: 3.00823
Value Function Loss: 0.00445

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.60772
Value Function Update Magnitude: 0.54248

Collected Steps per Second: 22,749.17812
Overall Steps per Second: 10,616.64038

Timestep Collection Time: 2.19788
Timestep Consumption Time: 2.51171
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.70959

Cumulative Model Updates: 160,160
Cumulative Timesteps: 1,335,768,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.01902
Policy Entropy: 3.01344
Value Function Loss: 0.00441

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.60284
Value Function Update Magnitude: 0.52657

Collected Steps per Second: 22,739.40317
Overall Steps per Second: 10,818.94502

Timestep Collection Time: 2.19883
Timestep Consumption Time: 2.42270
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.62152

Cumulative Model Updates: 160,166
Cumulative Timesteps: 1,335,818,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1335818820...
Checkpoint 1335818820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837.58970
Policy Entropy: 3.01226
Value Function Loss: 0.00402

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.58890
Value Function Update Magnitude: 0.49033

Collected Steps per Second: 22,667.89740
Overall Steps per Second: 10,684.99117

Timestep Collection Time: 2.20638
Timestep Consumption Time: 2.47439
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.68077

Cumulative Model Updates: 160,172
Cumulative Timesteps: 1,335,868,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,207.81846
Policy Entropy: 3.03137
Value Function Loss: 0.00406

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.58155
Value Function Update Magnitude: 0.46166

Collected Steps per Second: 22,957.20667
Overall Steps per Second: 10,701.39895

Timestep Collection Time: 2.17927
Timestep Consumption Time: 2.49582
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.67509

Cumulative Model Updates: 160,178
Cumulative Timesteps: 1,335,918,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1335918864...
Checkpoint 1335918864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,156.83056
Policy Entropy: 3.02908
Value Function Loss: 0.00419

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.57870
Value Function Update Magnitude: 0.46053

Collected Steps per Second: 22,983.09639
Overall Steps per Second: 10,653.63188

Timestep Collection Time: 2.17673
Timestep Consumption Time: 2.51913
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.69586

Cumulative Model Updates: 160,184
Cumulative Timesteps: 1,335,968,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.37619
Policy Entropy: 3.04302
Value Function Loss: 0.00437

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.57729
Value Function Update Magnitude: 0.46934

Collected Steps per Second: 23,175.67564
Overall Steps per Second: 10,683.51758

Timestep Collection Time: 2.15761
Timestep Consumption Time: 2.52287
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.68048

Cumulative Model Updates: 160,190
Cumulative Timesteps: 1,336,018,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1336018896...
Checkpoint 1336018896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,968.49629
Policy Entropy: 3.02521
Value Function Loss: 0.00449

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10590
Policy Update Magnitude: 0.58353
Value Function Update Magnitude: 0.47858

Collected Steps per Second: 22,991.40532
Overall Steps per Second: 10,667.32911

Timestep Collection Time: 2.17551
Timestep Consumption Time: 2.51339
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.68890

Cumulative Model Updates: 160,196
Cumulative Timesteps: 1,336,068,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.08182
Policy Entropy: 3.01116
Value Function Loss: 0.00476

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.59864
Value Function Update Magnitude: 0.49675

Collected Steps per Second: 23,333.56749
Overall Steps per Second: 10,879.27149

Timestep Collection Time: 2.14386
Timestep Consumption Time: 2.45424
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.59810

Cumulative Model Updates: 160,202
Cumulative Timesteps: 1,336,118,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1336118938...
Checkpoint 1336118938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.25672
Policy Entropy: 2.98599
Value Function Loss: 0.00442

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.60175
Value Function Update Magnitude: 0.50774

Collected Steps per Second: 23,031.82001
Overall Steps per Second: 10,674.67682

Timestep Collection Time: 2.17273
Timestep Consumption Time: 2.51518
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.68792

Cumulative Model Updates: 160,208
Cumulative Timesteps: 1,336,168,980

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,852.53977
Policy Entropy: 2.98906
Value Function Loss: 0.00447

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.60358
Value Function Update Magnitude: 0.50252

Collected Steps per Second: 23,219.96049
Overall Steps per Second: 10,872.74200

Timestep Collection Time: 2.15392
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.59994

Cumulative Model Updates: 160,214
Cumulative Timesteps: 1,336,218,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1336218994...
Checkpoint 1336218994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.76050
Policy Entropy: 2.99076
Value Function Loss: 0.00455

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.60297
Value Function Update Magnitude: 0.50807

Collected Steps per Second: 22,800.28385
Overall Steps per Second: 10,632.55655

Timestep Collection Time: 2.19366
Timestep Consumption Time: 2.51039
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.70404

Cumulative Model Updates: 160,220
Cumulative Timesteps: 1,336,269,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,184.04697
Policy Entropy: 3.00538
Value Function Loss: 0.00509

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.61069
Value Function Update Magnitude: 0.53964

Collected Steps per Second: 22,734.97990
Overall Steps per Second: 10,852.98660

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.40874
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60887

Cumulative Model Updates: 160,226
Cumulative Timesteps: 1,336,319,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1336319030...
Checkpoint 1336319030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,952.47484
Policy Entropy: 3.01155
Value Function Loss: 0.00507

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.60893
Value Function Update Magnitude: 0.53511

Collected Steps per Second: 22,935.93967
Overall Steps per Second: 10,704.73182

Timestep Collection Time: 2.18094
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.67289

Cumulative Model Updates: 160,232
Cumulative Timesteps: 1,336,369,052

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.09198
Policy Entropy: 3.02269
Value Function Loss: 0.00487

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.59852
Value Function Update Magnitude: 0.52123

Collected Steps per Second: 23,337.99605
Overall Steps per Second: 10,829.82946

Timestep Collection Time: 2.14303
Timestep Consumption Time: 2.47514
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61817

Cumulative Model Updates: 160,238
Cumulative Timesteps: 1,336,419,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1336419066...
Checkpoint 1336419066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.78582
Policy Entropy: 3.00847
Value Function Loss: 0.00460

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.58492
Value Function Update Magnitude: 0.50205

Collected Steps per Second: 23,192.81474
Overall Steps per Second: 10,691.39931

Timestep Collection Time: 2.15662
Timestep Consumption Time: 2.52172
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.67834

Cumulative Model Updates: 160,244
Cumulative Timesteps: 1,336,469,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.05182
Policy Entropy: 3.00123
Value Function Loss: 0.00427

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.58274
Value Function Update Magnitude: 0.50588

Collected Steps per Second: 23,081.91130
Overall Steps per Second: 10,847.80562

Timestep Collection Time: 2.16741
Timestep Consumption Time: 2.44440
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61181

Cumulative Model Updates: 160,250
Cumulative Timesteps: 1,336,519,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1336519112...
Checkpoint 1336519112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.41761
Policy Entropy: 2.99400
Value Function Loss: 0.00412

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.57894
Value Function Update Magnitude: 0.49875

Collected Steps per Second: 22,883.98199
Overall Steps per Second: 10,744.21715

Timestep Collection Time: 2.18572
Timestep Consumption Time: 2.46962
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.65534

Cumulative Model Updates: 160,256
Cumulative Timesteps: 1,336,569,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,900.64834
Policy Entropy: 2.98895
Value Function Loss: 0.00390

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.57507
Value Function Update Magnitude: 0.47623

Collected Steps per Second: 23,291.30882
Overall Steps per Second: 10,907.02278

Timestep Collection Time: 2.14672
Timestep Consumption Time: 2.43748
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.58420

Cumulative Model Updates: 160,262
Cumulative Timesteps: 1,336,619,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1336619130...
Checkpoint 1336619130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.26247
Policy Entropy: 2.99087
Value Function Loss: 0.00412

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.47648

Collected Steps per Second: 22,563.10179
Overall Steps per Second: 10,593.45408

Timestep Collection Time: 2.21716
Timestep Consumption Time: 2.50519
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.72235

Cumulative Model Updates: 160,268
Cumulative Timesteps: 1,336,669,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465.49021
Policy Entropy: 3.00054
Value Function Loss: 0.00415

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.58304
Value Function Update Magnitude: 0.49297

Collected Steps per Second: 22,983.77774
Overall Steps per Second: 10,907.10526

Timestep Collection Time: 2.17632
Timestep Consumption Time: 2.40968
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.58600

Cumulative Model Updates: 160,274
Cumulative Timesteps: 1,336,719,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1336719176...
Checkpoint 1336719176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.17869
Policy Entropy: 2.98276
Value Function Loss: 0.00421

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.57907
Value Function Update Magnitude: 0.51184

Collected Steps per Second: 22,558.99483
Overall Steps per Second: 10,686.34793

Timestep Collection Time: 2.21765
Timestep Consumption Time: 2.46384
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.68149

Cumulative Model Updates: 160,280
Cumulative Timesteps: 1,336,769,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.96610
Policy Entropy: 2.99643
Value Function Loss: 0.00431

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.58460
Value Function Update Magnitude: 0.51064

Collected Steps per Second: 22,767.94174
Overall Steps per Second: 10,847.65064

Timestep Collection Time: 2.19633
Timestep Consumption Time: 2.41351
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60985

Cumulative Model Updates: 160,286
Cumulative Timesteps: 1,336,819,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1336819210...
Checkpoint 1336819210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,645.06109
Policy Entropy: 2.99801
Value Function Loss: 0.00445

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.58301
Value Function Update Magnitude: 0.50612

Collected Steps per Second: 22,433.03409
Overall Steps per Second: 10,713.49549

Timestep Collection Time: 2.22921
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.66776

Cumulative Model Updates: 160,292
Cumulative Timesteps: 1,336,869,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,472.77509
Policy Entropy: 3.00406
Value Function Loss: 0.00460

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.59529
Value Function Update Magnitude: 0.50187

Collected Steps per Second: 22,989.90700
Overall Steps per Second: 10,795.84494

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.45713
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.63252

Cumulative Model Updates: 160,298
Cumulative Timesteps: 1,336,919,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1336919230...
Checkpoint 1336919230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.94429
Policy Entropy: 2.99773
Value Function Loss: 0.00461

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.60216
Value Function Update Magnitude: 0.50720

Collected Steps per Second: 23,122.41450
Overall Steps per Second: 10,724.69484

Timestep Collection Time: 2.16310
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.66363

Cumulative Model Updates: 160,304
Cumulative Timesteps: 1,336,969,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,182.41731
Policy Entropy: 2.99217
Value Function Loss: 0.00439

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.59773
Value Function Update Magnitude: 0.50088

Collected Steps per Second: 23,380.82941
Overall Steps per Second: 10,924.09729

Timestep Collection Time: 2.13910
Timestep Consumption Time: 2.43922
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.57832

Cumulative Model Updates: 160,310
Cumulative Timesteps: 1,337,019,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1337019260...
Checkpoint 1337019260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.63668
Policy Entropy: 3.01238
Value Function Loss: 0.00418

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.59224
Value Function Update Magnitude: 0.48231

Collected Steps per Second: 23,047.61957
Overall Steps per Second: 10,734.98662

Timestep Collection Time: 2.16994
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.65879

Cumulative Model Updates: 160,316
Cumulative Timesteps: 1,337,069,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.02421
Policy Entropy: 3.01288
Value Function Loss: 0.00399

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.58185
Value Function Update Magnitude: 0.47567

Collected Steps per Second: 23,247.19657
Overall Steps per Second: 10,777.72232

Timestep Collection Time: 2.15114
Timestep Consumption Time: 2.48880
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.63994

Cumulative Model Updates: 160,322
Cumulative Timesteps: 1,337,119,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1337119280...
Checkpoint 1337119280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,857.38682
Policy Entropy: 3.00317
Value Function Loss: 0.00427

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.58112
Value Function Update Magnitude: 0.48564

Collected Steps per Second: 22,978.14094
Overall Steps per Second: 10,746.16961

Timestep Collection Time: 2.17624
Timestep Consumption Time: 2.47714
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.65338

Cumulative Model Updates: 160,328
Cumulative Timesteps: 1,337,169,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.18082
Policy Entropy: 3.00389
Value Function Loss: 0.00441

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.58711
Value Function Update Magnitude: 0.50866

Collected Steps per Second: 23,153.20043
Overall Steps per Second: 10,811.64068

Timestep Collection Time: 2.16074
Timestep Consumption Time: 2.46650
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.62723

Cumulative Model Updates: 160,334
Cumulative Timesteps: 1,337,219,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1337219314...
Checkpoint 1337219314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,582.06330
Policy Entropy: 2.99103
Value Function Loss: 0.00451

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.59898
Value Function Update Magnitude: 0.53406

Collected Steps per Second: 22,785.20659
Overall Steps per Second: 10,612.70046

Timestep Collection Time: 2.19537
Timestep Consumption Time: 2.51804
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.71341

Cumulative Model Updates: 160,340
Cumulative Timesteps: 1,337,269,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,175.44561
Policy Entropy: 3.00491
Value Function Loss: 0.00418

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.60429
Value Function Update Magnitude: 0.55939

Collected Steps per Second: 22,159.36644
Overall Steps per Second: 10,486.54881

Timestep Collection Time: 2.25638
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.76801

Cumulative Model Updates: 160,346
Cumulative Timesteps: 1,337,319,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1337319336...
Checkpoint 1337319336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.13212
Policy Entropy: 2.98232
Value Function Loss: 0.00432

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.59967
Value Function Update Magnitude: 0.57568

Collected Steps per Second: 22,657.37385
Overall Steps per Second: 10,688.74197

Timestep Collection Time: 2.20767
Timestep Consumption Time: 2.47202
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.67969

Cumulative Model Updates: 160,352
Cumulative Timesteps: 1,337,369,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,176.04306
Policy Entropy: 2.99942
Value Function Loss: 0.00384

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.58991
Value Function Update Magnitude: 0.57100

Collected Steps per Second: 22,963.77699
Overall Steps per Second: 10,824.47945

Timestep Collection Time: 2.17830
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.62119

Cumulative Model Updates: 160,358
Cumulative Timesteps: 1,337,419,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1337419378...
Checkpoint 1337419378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,854.31608
Policy Entropy: 2.99398
Value Function Loss: 0.00386

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.57185
Value Function Update Magnitude: 0.52206

Collected Steps per Second: 23,270.66828
Overall Steps per Second: 10,727.67884

Timestep Collection Time: 2.14940
Timestep Consumption Time: 2.51312
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.66252

Cumulative Model Updates: 160,364
Cumulative Timesteps: 1,337,469,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,689.81231
Policy Entropy: 3.03203
Value Function Loss: 0.00369

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.56667
Value Function Update Magnitude: 0.49418

Collected Steps per Second: 23,387.92245
Overall Steps per Second: 10,803.65290

Timestep Collection Time: 2.13871
Timestep Consumption Time: 2.49120
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.62992

Cumulative Model Updates: 160,370
Cumulative Timesteps: 1,337,519,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1337519416...
Checkpoint 1337519416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,433.61445
Policy Entropy: 3.00828
Value Function Loss: 0.00400

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.58083
Value Function Update Magnitude: 0.50771

Collected Steps per Second: 22,901.46503
Overall Steps per Second: 10,667.98882

Timestep Collection Time: 2.18344
Timestep Consumption Time: 2.50385
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.68729

Cumulative Model Updates: 160,376
Cumulative Timesteps: 1,337,569,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.28938
Policy Entropy: 3.00542
Value Function Loss: 0.00426

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.59686
Value Function Update Magnitude: 0.53077

Collected Steps per Second: 23,399.04260
Overall Steps per Second: 10,904.40032

Timestep Collection Time: 2.13769
Timestep Consumption Time: 2.44944
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.58714

Cumulative Model Updates: 160,382
Cumulative Timesteps: 1,337,619,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1337619440...
Checkpoint 1337619440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,809.81655
Policy Entropy: 2.99621
Value Function Loss: 0.00425

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.58910
Value Function Update Magnitude: 0.52267

Collected Steps per Second: 23,313.94979
Overall Steps per Second: 10,780.56228

Timestep Collection Time: 2.14550
Timestep Consumption Time: 2.49434
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.63983

Cumulative Model Updates: 160,388
Cumulative Timesteps: 1,337,669,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,445.83778
Policy Entropy: 3.02066
Value Function Loss: 0.00450

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.58131
Value Function Update Magnitude: 0.50618

Collected Steps per Second: 23,252.00911
Overall Steps per Second: 10,773.85801

Timestep Collection Time: 2.15087
Timestep Consumption Time: 2.49111
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.64198

Cumulative Model Updates: 160,394
Cumulative Timesteps: 1,337,719,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1337719472...
Checkpoint 1337719472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.13781
Policy Entropy: 3.01034
Value Function Loss: 0.00466

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.58944
Value Function Update Magnitude: 0.50802

Collected Steps per Second: 23,017.94776
Overall Steps per Second: 10,700.68735

Timestep Collection Time: 2.17361
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.67559

Cumulative Model Updates: 160,400
Cumulative Timesteps: 1,337,769,504

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,717.32874
Policy Entropy: 3.00137
Value Function Loss: 0.00484

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.60140
Value Function Update Magnitude: 0.53208

Collected Steps per Second: 23,116.58602
Overall Steps per Second: 10,874.77834

Timestep Collection Time: 2.16321
Timestep Consumption Time: 2.43514
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.59835

Cumulative Model Updates: 160,406
Cumulative Timesteps: 1,337,819,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1337819510...
Checkpoint 1337819510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,023.37387
Policy Entropy: 3.00647
Value Function Loss: 0.00429

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.59938
Value Function Update Magnitude: 0.54456

Collected Steps per Second: 22,682.59043
Overall Steps per Second: 10,609.97560

Timestep Collection Time: 2.20522
Timestep Consumption Time: 2.50922
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.71443

Cumulative Model Updates: 160,412
Cumulative Timesteps: 1,337,869,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,751.28793
Policy Entropy: 3.00875
Value Function Loss: 0.00434

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.60726
Value Function Update Magnitude: 0.55013

Collected Steps per Second: 22,505.89676
Overall Steps per Second: 10,673.23325

Timestep Collection Time: 2.22262
Timestep Consumption Time: 2.46406
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.68668

Cumulative Model Updates: 160,418
Cumulative Timesteps: 1,337,919,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1337919552...
Checkpoint 1337919552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,220.24719
Policy Entropy: 2.99400
Value Function Loss: 0.00450

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.62183
Value Function Update Magnitude: 0.54735

Collected Steps per Second: 22,828.05043
Overall Steps per Second: 10,857.46917

Timestep Collection Time: 2.19116
Timestep Consumption Time: 2.41580
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.60697

Cumulative Model Updates: 160,424
Cumulative Timesteps: 1,337,969,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,186.87598
Policy Entropy: 2.99080
Value Function Loss: 0.00452

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.61318
Value Function Update Magnitude: 0.53205

Collected Steps per Second: 23,433.16431
Overall Steps per Second: 10,884.95143

Timestep Collection Time: 2.13381
Timestep Consumption Time: 2.45987
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59368

Cumulative Model Updates: 160,430
Cumulative Timesteps: 1,338,019,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1338019574...
Checkpoint 1338019574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.74937
Policy Entropy: 3.00099
Value Function Loss: 0.00466

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.60724
Value Function Update Magnitude: 0.53085

Collected Steps per Second: 22,967.63120
Overall Steps per Second: 10,680.01193

Timestep Collection Time: 2.17776
Timestep Consumption Time: 2.50557
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.68333

Cumulative Model Updates: 160,436
Cumulative Timesteps: 1,338,069,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.04476
Policy Entropy: 3.02550
Value Function Loss: 0.00419

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.58956
Value Function Update Magnitude: 0.55492

Collected Steps per Second: 23,053.04256
Overall Steps per Second: 10,837.80638

Timestep Collection Time: 2.16952
Timestep Consumption Time: 2.44525
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61477

Cumulative Model Updates: 160,442
Cumulative Timesteps: 1,338,119,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1338119606...
Checkpoint 1338119606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,862.34506
Policy Entropy: 3.03112
Value Function Loss: 0.00395

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.57593
Value Function Update Magnitude: 0.54181

Collected Steps per Second: 23,107.28768
Overall Steps per Second: 10,722.21097

Timestep Collection Time: 2.16494
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.66564

Cumulative Model Updates: 160,448
Cumulative Timesteps: 1,338,169,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,149.29502
Policy Entropy: 3.02945
Value Function Loss: 0.00373

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.57974
Value Function Update Magnitude: 0.52298

Collected Steps per Second: 23,291.73640
Overall Steps per Second: 10,906.02077

Timestep Collection Time: 2.14771
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.58682

Cumulative Model Updates: 160,454
Cumulative Timesteps: 1,338,219,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1338219656...
Checkpoint 1338219656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.91830
Policy Entropy: 3.03002
Value Function Loss: 0.00375

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.58652
Value Function Update Magnitude: 0.53196

Collected Steps per Second: 23,189.28702
Overall Steps per Second: 10,739.42692

Timestep Collection Time: 2.15643
Timestep Consumption Time: 2.49987
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.65630

Cumulative Model Updates: 160,460
Cumulative Timesteps: 1,338,269,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.89513
Policy Entropy: 3.03072
Value Function Loss: 0.00387

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.51356

Collected Steps per Second: 22,819.01907
Overall Steps per Second: 10,800.38904

Timestep Collection Time: 2.19142
Timestep Consumption Time: 2.43860
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.63002

Cumulative Model Updates: 160,466
Cumulative Timesteps: 1,338,319,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1338319668...
Checkpoint 1338319668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,758.96251
Policy Entropy: 3.03211
Value Function Loss: 0.00366

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.56651
Value Function Update Magnitude: 0.50097

Collected Steps per Second: 22,648.48116
Overall Steps per Second: 10,671.88356

Timestep Collection Time: 2.20827
Timestep Consumption Time: 2.47825
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.68652

Cumulative Model Updates: 160,472
Cumulative Timesteps: 1,338,369,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,284.51090
Policy Entropy: 3.02871
Value Function Loss: 0.00427

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.57215
Value Function Update Magnitude: 0.50699

Collected Steps per Second: 22,796.30930
Overall Steps per Second: 10,808.85214

Timestep Collection Time: 2.19465
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.62861

Cumulative Model Updates: 160,478
Cumulative Timesteps: 1,338,419,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1338419712...
Checkpoint 1338419712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,754.43895
Policy Entropy: 3.01791
Value Function Loss: 0.00460

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.59689
Value Function Update Magnitude: 0.56930

Collected Steps per Second: 22,539.37663
Overall Steps per Second: 10,731.61029

Timestep Collection Time: 2.21843
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.65932

Cumulative Model Updates: 160,484
Cumulative Timesteps: 1,338,469,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,661.32365
Policy Entropy: 3.00346
Value Function Loss: 0.00455

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.59575
Value Function Update Magnitude: 0.57752

Collected Steps per Second: 23,131.65631
Overall Steps per Second: 10,820.79564

Timestep Collection Time: 2.16240
Timestep Consumption Time: 2.46018
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.62258

Cumulative Model Updates: 160,490
Cumulative Timesteps: 1,338,519,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1338519734...
Checkpoint 1338519734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,325.82728
Policy Entropy: 3.00432
Value Function Loss: 0.00425

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11486
Policy Update Magnitude: 0.59433
Value Function Update Magnitude: 0.56488

Collected Steps per Second: 23,078.97533
Overall Steps per Second: 10,696.85336

Timestep Collection Time: 2.16647
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.67427

Cumulative Model Updates: 160,496
Cumulative Timesteps: 1,338,569,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.91659
Policy Entropy: 2.99574
Value Function Loss: 0.00396

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.58756
Value Function Update Magnitude: 0.53534

Collected Steps per Second: 21,888.20243
Overall Steps per Second: 10,459.58536

Timestep Collection Time: 2.28571
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.78317

Cumulative Model Updates: 160,502
Cumulative Timesteps: 1,338,619,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1338619764...
Checkpoint 1338619764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,691.93709
Policy Entropy: 3.01034
Value Function Loss: 0.00397

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.58114
Value Function Update Magnitude: 0.51462

Collected Steps per Second: 22,497.38018
Overall Steps per Second: 10,647.32794

Timestep Collection Time: 2.22248
Timestep Consumption Time: 2.47353
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.69601

Cumulative Model Updates: 160,508
Cumulative Timesteps: 1,338,669,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,723.71505
Policy Entropy: 3.02347
Value Function Loss: 0.00390

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.57720
Value Function Update Magnitude: 0.48130

Collected Steps per Second: 22,682.82112
Overall Steps per Second: 10,658.61858

Timestep Collection Time: 2.20510
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.69273

Cumulative Model Updates: 160,514
Cumulative Timesteps: 1,338,719,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1338719782...
Checkpoint 1338719782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,967.41394
Policy Entropy: 3.04004
Value Function Loss: 0.00393

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.56623
Value Function Update Magnitude: 0.47351

Collected Steps per Second: 22,452.67611
Overall Steps per Second: 10,630.07371

Timestep Collection Time: 2.22780
Timestep Consumption Time: 2.47772
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.70552

Cumulative Model Updates: 160,520
Cumulative Timesteps: 1,338,769,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.96545
Policy Entropy: 3.03884
Value Function Loss: 0.00422

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.57001
Value Function Update Magnitude: 0.49514

Collected Steps per Second: 23,742.50083
Overall Steps per Second: 10,884.01677

Timestep Collection Time: 2.10635
Timestep Consumption Time: 2.48846
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.59481

Cumulative Model Updates: 160,526
Cumulative Timesteps: 1,338,819,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1338819812...
Checkpoint 1338819812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.67595
Policy Entropy: 3.02624
Value Function Loss: 0.00433

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.57403
Value Function Update Magnitude: 0.51841

Collected Steps per Second: 23,168.30616
Overall Steps per Second: 10,904.15928

Timestep Collection Time: 2.15898
Timestep Consumption Time: 2.42826
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.58724

Cumulative Model Updates: 160,532
Cumulative Timesteps: 1,338,869,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,120.94923
Policy Entropy: 3.01045
Value Function Loss: 0.00448

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.59129
Value Function Update Magnitude: 0.53342

Collected Steps per Second: 23,138.22077
Overall Steps per Second: 10,862.62689

Timestep Collection Time: 2.16153
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60423

Cumulative Model Updates: 160,538
Cumulative Timesteps: 1,338,919,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1338919846...
Checkpoint 1338919846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,829.35168
Policy Entropy: 3.02105
Value Function Loss: 0.00442

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.60115
Value Function Update Magnitude: 0.55750

Collected Steps per Second: 22,809.31143
Overall Steps per Second: 10,707.44699

Timestep Collection Time: 2.19217
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.66983

Cumulative Model Updates: 160,544
Cumulative Timesteps: 1,338,969,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.72145
Policy Entropy: 3.02385
Value Function Loss: 0.00443

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.59598
Value Function Update Magnitude: 0.57532

Collected Steps per Second: 23,076.01105
Overall Steps per Second: 10,830.93448

Timestep Collection Time: 2.16762
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.61825

Cumulative Model Updates: 160,550
Cumulative Timesteps: 1,339,019,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1339019868...
Checkpoint 1339019868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,006.25955
Policy Entropy: 3.04222
Value Function Loss: 0.00473

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.60911
Value Function Update Magnitude: 0.56280

Collected Steps per Second: 22,706.70310
Overall Steps per Second: 10,684.36767

Timestep Collection Time: 2.20305
Timestep Consumption Time: 2.47893
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.68198

Cumulative Model Updates: 160,556
Cumulative Timesteps: 1,339,069,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.23823
Policy Entropy: 3.03263
Value Function Loss: 0.00449

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.61460
Value Function Update Magnitude: 0.55137

Collected Steps per Second: 22,288.81786
Overall Steps per Second: 10,489.01762

Timestep Collection Time: 2.24346
Timestep Consumption Time: 2.52382
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.76727

Cumulative Model Updates: 160,562
Cumulative Timesteps: 1,339,119,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1339119896...
Checkpoint 1339119896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,383.51282
Policy Entropy: 3.03306
Value Function Loss: 0.00418

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11088
Policy Update Magnitude: 0.60114
Value Function Update Magnitude: 0.52369

Collected Steps per Second: 22,619.55381
Overall Steps per Second: 10,658.74728

Timestep Collection Time: 2.21118
Timestep Consumption Time: 2.48130
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.69248

Cumulative Model Updates: 160,568
Cumulative Timesteps: 1,339,169,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.09578
Policy Entropy: 3.02006
Value Function Loss: 0.00431

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.59022
Value Function Update Magnitude: 0.49485

Collected Steps per Second: 22,496.16654
Overall Steps per Second: 10,592.75511

Timestep Collection Time: 2.22260
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.72021

Cumulative Model Updates: 160,574
Cumulative Timesteps: 1,339,219,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1339219912...
Checkpoint 1339219912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,893.74565
Policy Entropy: 3.01233
Value Function Loss: 0.00415

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.58604
Value Function Update Magnitude: 0.51556

Collected Steps per Second: 22,813.29133
Overall Steps per Second: 10,727.68920

Timestep Collection Time: 2.19197
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.66140

Cumulative Model Updates: 160,580
Cumulative Timesteps: 1,339,269,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,784.89384
Policy Entropy: 3.00679
Value Function Loss: 0.00422

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.59101
Value Function Update Magnitude: 0.52980

Collected Steps per Second: 22,861.22496
Overall Steps per Second: 10,645.39042

Timestep Collection Time: 2.18711
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.69687

Cumulative Model Updates: 160,586
Cumulative Timesteps: 1,339,319,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1339319918...
Checkpoint 1339319918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,155.84467
Policy Entropy: 3.01082
Value Function Loss: 0.00411

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.58581
Value Function Update Magnitude: 0.52388

Collected Steps per Second: 23,200.58182
Overall Steps per Second: 10,737.45380

Timestep Collection Time: 2.15572
Timestep Consumption Time: 2.50218
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.65790

Cumulative Model Updates: 160,592
Cumulative Timesteps: 1,339,369,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,039.59437
Policy Entropy: 3.01415
Value Function Loss: 0.00406

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.58822
Value Function Update Magnitude: 0.50956

Collected Steps per Second: 23,442.40815
Overall Steps per Second: 10,826.29553

Timestep Collection Time: 2.13357
Timestep Consumption Time: 2.48629
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.61986

Cumulative Model Updates: 160,598
Cumulative Timesteps: 1,339,419,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1339419948...
Checkpoint 1339419948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.13292
Policy Entropy: 3.01035
Value Function Loss: 0.00435

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.59355
Value Function Update Magnitude: 0.52428

Collected Steps per Second: 23,165.25220
Overall Steps per Second: 10,757.64403

Timestep Collection Time: 2.15944
Timestep Consumption Time: 2.49065
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.65009

Cumulative Model Updates: 160,604
Cumulative Timesteps: 1,339,469,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.28395
Policy Entropy: 3.01300
Value Function Loss: 0.00425

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.59739
Value Function Update Magnitude: 0.55095

Collected Steps per Second: 23,066.54083
Overall Steps per Second: 10,795.08898

Timestep Collection Time: 2.16790
Timestep Consumption Time: 2.46439
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.63229

Cumulative Model Updates: 160,610
Cumulative Timesteps: 1,339,519,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1339519978...
Checkpoint 1339519978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,866.00588
Policy Entropy: 3.01190
Value Function Loss: 0.00443

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.59686
Value Function Update Magnitude: 0.54953

Collected Steps per Second: 23,239.60676
Overall Steps per Second: 10,786.65550

Timestep Collection Time: 2.15279
Timestep Consumption Time: 2.48535
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.63814

Cumulative Model Updates: 160,616
Cumulative Timesteps: 1,339,570,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,790.21653
Policy Entropy: 3.00751
Value Function Loss: 0.00397

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.58276
Value Function Update Magnitude: 0.54048

Collected Steps per Second: 22,605.43294
Overall Steps per Second: 10,733.13020

Timestep Collection Time: 2.21310
Timestep Consumption Time: 2.44799
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.66108

Cumulative Model Updates: 160,622
Cumulative Timesteps: 1,339,620,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1339620036...
Checkpoint 1339620036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,264.42117
Policy Entropy: 3.01791
Value Function Loss: 0.00372

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.56472
Value Function Update Magnitude: 0.49658

Collected Steps per Second: 22,839.27111
Overall Steps per Second: 10,637.50503

Timestep Collection Time: 2.18982
Timestep Consumption Time: 2.51184
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.70167

Cumulative Model Updates: 160,628
Cumulative Timesteps: 1,339,670,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,409.35078
Policy Entropy: 3.00872
Value Function Loss: 0.00405

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.56540
Value Function Update Magnitude: 0.48958

Collected Steps per Second: 22,495.09876
Overall Steps per Second: 10,541.80970

Timestep Collection Time: 2.22377
Timestep Consumption Time: 2.52152
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.74530

Cumulative Model Updates: 160,634
Cumulative Timesteps: 1,339,720,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1339720074...
Checkpoint 1339720074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.81712
Policy Entropy: 3.00196
Value Function Loss: 0.00449

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.58069
Value Function Update Magnitude: 0.50676

Collected Steps per Second: 22,439.09961
Overall Steps per Second: 10,584.63199

Timestep Collection Time: 2.22825
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.72383

Cumulative Model Updates: 160,640
Cumulative Timesteps: 1,339,770,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,966.23641
Policy Entropy: 2.98557
Value Function Loss: 0.00466

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.59483
Value Function Update Magnitude: 0.53003

Collected Steps per Second: 23,444.25088
Overall Steps per Second: 10,894.67723

Timestep Collection Time: 2.13340
Timestep Consumption Time: 2.45746
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.59087

Cumulative Model Updates: 160,646
Cumulative Timesteps: 1,339,820,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1339820090...
Checkpoint 1339820090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.12511
Policy Entropy: 3.00506
Value Function Loss: 0.00443

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.58991
Value Function Update Magnitude: 0.53018

Collected Steps per Second: 23,203.93535
Overall Steps per Second: 10,712.62948

Timestep Collection Time: 2.15593
Timestep Consumption Time: 2.51389
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.66982

Cumulative Model Updates: 160,652
Cumulative Timesteps: 1,339,870,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.59948
Policy Entropy: 3.02950
Value Function Loss: 0.00421

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10641
Policy Update Magnitude: 0.57745
Value Function Update Magnitude: 0.49944

Collected Steps per Second: 22,982.79139
Overall Steps per Second: 10,813.12214

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.44945
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.62586

Cumulative Model Updates: 160,658
Cumulative Timesteps: 1,339,920,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1339920136...
Checkpoint 1339920136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.93176
Policy Entropy: 3.03367
Value Function Loss: 0.00419

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.57264
Value Function Update Magnitude: 0.47755

Collected Steps per Second: 23,306.24192
Overall Steps per Second: 10,783.99190

Timestep Collection Time: 2.14706
Timestep Consumption Time: 2.49315
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.64021

Cumulative Model Updates: 160,664
Cumulative Timesteps: 1,339,970,176

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.44297
Policy Entropy: 3.03234
Value Function Loss: 0.00405

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.47979

Collected Steps per Second: 23,270.69989
Overall Steps per Second: 10,776.06617

Timestep Collection Time: 2.14905
Timestep Consumption Time: 2.49179
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.64084

Cumulative Model Updates: 160,670
Cumulative Timesteps: 1,340,020,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1340020186...
Checkpoint 1340020186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,331.01462
Policy Entropy: 3.00798
Value Function Loss: 0.00423

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.57662
Value Function Update Magnitude: 0.49062

Collected Steps per Second: 23,154.47028
Overall Steps per Second: 10,780.87121

Timestep Collection Time: 2.16062
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.64044

Cumulative Model Updates: 160,676
Cumulative Timesteps: 1,340,070,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.96659
Policy Entropy: 2.99960
Value Function Loss: 0.00415

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.49609

Collected Steps per Second: 22,937.77769
Overall Steps per Second: 10,820.33952

Timestep Collection Time: 2.18007
Timestep Consumption Time: 2.44141
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.62148

Cumulative Model Updates: 160,682
Cumulative Timesteps: 1,340,120,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1340120220...
Checkpoint 1340120220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,549.30938
Policy Entropy: 3.01280
Value Function Loss: 0.00427

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.56882
Value Function Update Magnitude: 0.49589

Collected Steps per Second: 22,771.58238
Overall Steps per Second: 10,716.39676

Timestep Collection Time: 2.19581
Timestep Consumption Time: 2.47013
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.66593

Cumulative Model Updates: 160,688
Cumulative Timesteps: 1,340,170,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.25260
Policy Entropy: 3.01280
Value Function Loss: 0.00449

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.56806
Value Function Update Magnitude: 0.49220

Collected Steps per Second: 22,813.36842
Overall Steps per Second: 10,795.57085

Timestep Collection Time: 2.19249
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.63320

Cumulative Model Updates: 160,694
Cumulative Timesteps: 1,340,220,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1340220240...
Checkpoint 1340220240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,760.57673
Policy Entropy: 3.02411
Value Function Loss: 0.00429

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.49718

Collected Steps per Second: 22,925.91155
Overall Steps per Second: 10,668.29729

Timestep Collection Time: 2.18103
Timestep Consumption Time: 2.50595
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.68697

Cumulative Model Updates: 160,700
Cumulative Timesteps: 1,340,270,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.43051
Policy Entropy: 3.02805
Value Function Loss: 0.00422

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11791
Policy Update Magnitude: 0.55897
Value Function Update Magnitude: 0.49867

Collected Steps per Second: 22,972.94510
Overall Steps per Second: 10,772.76682

Timestep Collection Time: 2.17717
Timestep Consumption Time: 2.46565
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.64282

Cumulative Model Updates: 160,706
Cumulative Timesteps: 1,340,320,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1340320258...
Checkpoint 1340320258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.42347
Policy Entropy: 3.04136
Value Function Loss: 0.00388

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11389
Policy Update Magnitude: 0.55601
Value Function Update Magnitude: 0.50992

Collected Steps per Second: 23,193.70510
Overall Steps per Second: 10,801.54534

Timestep Collection Time: 2.15593
Timestep Consumption Time: 2.47341
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.62934

Cumulative Model Updates: 160,712
Cumulative Timesteps: 1,340,370,262

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,387.38130
Policy Entropy: 3.04400
Value Function Loss: 0.00436

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.49456

Collected Steps per Second: 22,894.71421
Overall Steps per Second: 10,798.46782

Timestep Collection Time: 2.18452
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.63158

Cumulative Model Updates: 160,718
Cumulative Timesteps: 1,340,420,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1340420276...
Checkpoint 1340420276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,188.97677
Policy Entropy: 3.03586
Value Function Loss: 0.00458

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12216
Policy Update Magnitude: 0.58368
Value Function Update Magnitude: 0.49869

Collected Steps per Second: 22,992.58172
Overall Steps per Second: 10,648.49945

Timestep Collection Time: 2.17479
Timestep Consumption Time: 2.52108
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.69587

Cumulative Model Updates: 160,724
Cumulative Timesteps: 1,340,470,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.94756
Policy Entropy: 3.02315
Value Function Loss: 0.00448

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.58650
Value Function Update Magnitude: 0.49735

Collected Steps per Second: 22,676.02381
Overall Steps per Second: 10,526.86616

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.54539
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.75089

Cumulative Model Updates: 160,730
Cumulative Timesteps: 1,340,520,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1340520292...
Checkpoint 1340520292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.11874
Policy Entropy: 3.01826
Value Function Loss: 0.00422

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.57453
Value Function Update Magnitude: 0.48689

Collected Steps per Second: 22,913.90736
Overall Steps per Second: 10,638.97179

Timestep Collection Time: 2.18269
Timestep Consumption Time: 2.51833
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.70102

Cumulative Model Updates: 160,736
Cumulative Timesteps: 1,340,570,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,156.55384
Policy Entropy: 3.01175
Value Function Loss: 0.00429

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.57494
Value Function Update Magnitude: 0.48760

Collected Steps per Second: 22,784.45022
Overall Steps per Second: 10,788.46977

Timestep Collection Time: 2.19536
Timestep Consumption Time: 2.44107
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.63643

Cumulative Model Updates: 160,742
Cumulative Timesteps: 1,340,620,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1340620326...
Checkpoint 1340620326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,236.36324
Policy Entropy: 3.00920
Value Function Loss: 0.00426

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10601
Policy Update Magnitude: 0.57598
Value Function Update Magnitude: 0.49003

Collected Steps per Second: 22,561.57015
Overall Steps per Second: 10,763.98253

Timestep Collection Time: 2.21651
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.64586

Cumulative Model Updates: 160,748
Cumulative Timesteps: 1,340,670,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.30312
Policy Entropy: 2.99344
Value Function Loss: 0.00403

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.56471
Value Function Update Magnitude: 0.46756

Collected Steps per Second: 22,649.10476
Overall Steps per Second: 10,823.73647

Timestep Collection Time: 2.20821
Timestep Consumption Time: 2.41256
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.62077

Cumulative Model Updates: 160,754
Cumulative Timesteps: 1,340,720,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1340720348...
Checkpoint 1340720348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,795.96358
Policy Entropy: 3.00129
Value Function Loss: 0.00392

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.44911

Collected Steps per Second: 23,080.39574
Overall Steps per Second: 10,659.42694

Timestep Collection Time: 2.16703
Timestep Consumption Time: 2.52515
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.69218

Cumulative Model Updates: 160,760
Cumulative Timesteps: 1,340,770,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,623.10417
Policy Entropy: 3.01264
Value Function Loss: 0.00414

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.44816

Collected Steps per Second: 23,202.26613
Overall Steps per Second: 10,848.72352

Timestep Collection Time: 2.15617
Timestep Consumption Time: 2.45525
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.61142

Cumulative Model Updates: 160,766
Cumulative Timesteps: 1,340,820,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1340820392...
Checkpoint 1340820392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506.64102
Policy Entropy: 3.01497
Value Function Loss: 0.00434

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.58009
Value Function Update Magnitude: 0.48763

Collected Steps per Second: 22,851.82243
Overall Steps per Second: 10,684.57116

Timestep Collection Time: 2.18801
Timestep Consumption Time: 2.49164
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.67965

Cumulative Model Updates: 160,772
Cumulative Timesteps: 1,340,870,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,310.85832
Policy Entropy: 3.00791
Value Function Loss: 0.00461

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.58936
Value Function Update Magnitude: 0.52313

Collected Steps per Second: 23,009.44055
Overall Steps per Second: 10,838.58985

Timestep Collection Time: 2.17424
Timestep Consumption Time: 2.44149
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.61573

Cumulative Model Updates: 160,778
Cumulative Timesteps: 1,340,920,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1340920420...
Checkpoint 1340920420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.35599
Policy Entropy: 2.98854
Value Function Loss: 0.00500

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.60641
Value Function Update Magnitude: 0.53327

Collected Steps per Second: 23,156.91460
Overall Steps per Second: 10,721.25899

Timestep Collection Time: 2.15996
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.66531

Cumulative Model Updates: 160,784
Cumulative Timesteps: 1,340,970,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.48523
Policy Entropy: 2.97610
Value Function Loss: 0.00487

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.61507
Value Function Update Magnitude: 0.56559

Collected Steps per Second: 23,205.15091
Overall Steps per Second: 10,907.81420

Timestep Collection Time: 2.15487
Timestep Consumption Time: 2.42937
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.58424

Cumulative Model Updates: 160,790
Cumulative Timesteps: 1,341,020,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1341020442...
Checkpoint 1341020442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.40082
Policy Entropy: 2.97925
Value Function Loss: 0.00460

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.61497
Value Function Update Magnitude: 0.57628

Collected Steps per Second: 22,761.90254
Overall Steps per Second: 10,697.92412

Timestep Collection Time: 2.19674
Timestep Consumption Time: 2.47725
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.67399

Cumulative Model Updates: 160,796
Cumulative Timesteps: 1,341,070,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.89137
Policy Entropy: 2.98232
Value Function Loss: 0.00421

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.59493
Value Function Update Magnitude: 0.53685

Collected Steps per Second: 22,598.35246
Overall Steps per Second: 10,776.21816

Timestep Collection Time: 2.21361
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.64207

Cumulative Model Updates: 160,802
Cumulative Timesteps: 1,341,120,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1341120468...
Checkpoint 1341120468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.25023
Policy Entropy: 2.99072
Value Function Loss: 0.00462

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.59203
Value Function Update Magnitude: 0.51567

Collected Steps per Second: 22,844.19761
Overall Steps per Second: 10,732.04467

Timestep Collection Time: 2.18926
Timestep Consumption Time: 2.47080
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.66006

Cumulative Model Updates: 160,808
Cumulative Timesteps: 1,341,170,480

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,294.15575
Policy Entropy: 2.96667
Value Function Loss: 0.00493

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.60092
Value Function Update Magnitude: 0.50235

Collected Steps per Second: 23,037.66760
Overall Steps per Second: 10,794.46740

Timestep Collection Time: 2.17036
Timestep Consumption Time: 2.46164
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.63200

Cumulative Model Updates: 160,814
Cumulative Timesteps: 1,341,220,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1341220480...
Checkpoint 1341220480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,977.13102
Policy Entropy: 2.97533
Value Function Loss: 0.00532

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.59984
Value Function Update Magnitude: 0.51447

Collected Steps per Second: 22,973.17769
Overall Steps per Second: 10,701.40002

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.67359

Cumulative Model Updates: 160,820
Cumulative Timesteps: 1,341,270,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.37549
Policy Entropy: 2.96856
Value Function Loss: 0.00535

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.62201
Value Function Update Magnitude: 0.54162

Collected Steps per Second: 23,169.36188
Overall Steps per Second: 10,966.86628

Timestep Collection Time: 2.15837
Timestep Consumption Time: 2.40155
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.55992

Cumulative Model Updates: 160,826
Cumulative Timesteps: 1,341,320,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1341320502...
Checkpoint 1341320502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578.12419
Policy Entropy: 2.98164
Value Function Loss: 0.00499

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.62904
Value Function Update Magnitude: 0.58349

Collected Steps per Second: 23,073.28073
Overall Steps per Second: 10,825.80481

Timestep Collection Time: 2.16788
Timestep Consumption Time: 2.45257
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.62044

Cumulative Model Updates: 160,832
Cumulative Timesteps: 1,341,370,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.24086
Policy Entropy: 2.98579
Value Function Loss: 0.00480

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.61871
Value Function Update Magnitude: 0.61038

Collected Steps per Second: 23,605.31535
Overall Steps per Second: 11,045.11142

Timestep Collection Time: 2.11817
Timestep Consumption Time: 2.40872
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.52689

Cumulative Model Updates: 160,838
Cumulative Timesteps: 1,341,420,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1341420522...
Checkpoint 1341420522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,147.17086
Policy Entropy: 2.98711
Value Function Loss: 0.00462

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.62242
Value Function Update Magnitude: 0.60965

Collected Steps per Second: 23,053.80339
Overall Steps per Second: 10,736.46449

Timestep Collection Time: 2.16945
Timestep Consumption Time: 2.48888
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.65833

Cumulative Model Updates: 160,844
Cumulative Timesteps: 1,341,470,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.78683
Policy Entropy: 2.98701
Value Function Loss: 0.00453

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.61949
Value Function Update Magnitude: 0.59689

Collected Steps per Second: 22,506.12549
Overall Steps per Second: 10,578.76777

Timestep Collection Time: 2.22162
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.72645

Cumulative Model Updates: 160,850
Cumulative Timesteps: 1,341,520,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1341520536...
Checkpoint 1341520536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.29725
Policy Entropy: 2.99235
Value Function Loss: 0.00494

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.61537
Value Function Update Magnitude: 0.58268

Collected Steps per Second: 22,884.91711
Overall Steps per Second: 10,893.97605

Timestep Collection Time: 2.18546
Timestep Consumption Time: 2.40552
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.59098

Cumulative Model Updates: 160,856
Cumulative Timesteps: 1,341,570,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.34529
Policy Entropy: 3.03076
Value Function Loss: 0.00456

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.60076
Value Function Update Magnitude: 0.56586

Collected Steps per Second: 22,914.05644
Overall Steps per Second: 10,681.55218

Timestep Collection Time: 2.18268
Timestep Consumption Time: 2.49960
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.68228

Cumulative Model Updates: 160,862
Cumulative Timesteps: 1,341,620,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1341620564...
Checkpoint 1341620564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.88078
Policy Entropy: 3.05442
Value Function Loss: 0.00462

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.58910
Value Function Update Magnitude: 0.55436

Collected Steps per Second: 23,132.23009
Overall Steps per Second: 10,697.57385

Timestep Collection Time: 2.16270
Timestep Consumption Time: 2.51388
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.67657

Cumulative Model Updates: 160,868
Cumulative Timesteps: 1,341,670,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,457.73118
Policy Entropy: 3.05180
Value Function Loss: 0.00440

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.58815
Value Function Update Magnitude: 0.54360

Collected Steps per Second: 23,040.17123
Overall Steps per Second: 10,672.36907

Timestep Collection Time: 2.17082
Timestep Consumption Time: 2.51568
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.68649

Cumulative Model Updates: 160,874
Cumulative Timesteps: 1,341,720,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1341720608...
Checkpoint 1341720608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.16117
Policy Entropy: 3.03496
Value Function Loss: 0.00420

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.58133
Value Function Update Magnitude: 0.53233

Collected Steps per Second: 23,128.59028
Overall Steps per Second: 10,742.53123

Timestep Collection Time: 2.16191
Timestep Consumption Time: 2.49267
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.65458

Cumulative Model Updates: 160,880
Cumulative Timesteps: 1,341,770,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,301.79092
Policy Entropy: 3.02098
Value Function Loss: 0.00399

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.57290
Value Function Update Magnitude: 0.52679

Collected Steps per Second: 23,383.94820
Overall Steps per Second: 10,788.10960

Timestep Collection Time: 2.13822
Timestep Consumption Time: 2.49651
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.63473

Cumulative Model Updates: 160,886
Cumulative Timesteps: 1,341,820,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1341820610...
Checkpoint 1341820610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,345.35027
Policy Entropy: 3.02996
Value Function Loss: 0.00410

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.58082
Value Function Update Magnitude: 0.53729

Collected Steps per Second: 23,039.62790
Overall Steps per Second: 10,648.49682

Timestep Collection Time: 2.17096
Timestep Consumption Time: 2.52623
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.69719

Cumulative Model Updates: 160,892
Cumulative Timesteps: 1,341,870,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,371.47829
Policy Entropy: 3.02244
Value Function Loss: 0.00408

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.58389
Value Function Update Magnitude: 0.53796

Collected Steps per Second: 23,200.94269
Overall Steps per Second: 10,886.72947

Timestep Collection Time: 2.15646
Timestep Consumption Time: 2.43922
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.59569

Cumulative Model Updates: 160,898
Cumulative Timesteps: 1,341,920,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1341920660...
Checkpoint 1341920660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.79898
Policy Entropy: 3.02595
Value Function Loss: 0.00407

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.57757
Value Function Update Magnitude: 0.53657

Collected Steps per Second: 22,938.09402
Overall Steps per Second: 10,753.56301

Timestep Collection Time: 2.18039
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.65092

Cumulative Model Updates: 160,904
Cumulative Timesteps: 1,341,970,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,368.84623
Policy Entropy: 3.01678
Value Function Loss: 0.00389

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.57093
Value Function Update Magnitude: 0.50353

Collected Steps per Second: 22,739.38041
Overall Steps per Second: 10,855.39492

Timestep Collection Time: 2.19883
Timestep Consumption Time: 2.40718
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60600

Cumulative Model Updates: 160,910
Cumulative Timesteps: 1,342,020,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1342020674...
Checkpoint 1342020674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,657.03307
Policy Entropy: 3.00117
Value Function Loss: 0.00409

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.56920
Value Function Update Magnitude: 0.48990

Collected Steps per Second: 22,655.26891
Overall Steps per Second: 10,614.56466

Timestep Collection Time: 2.20752
Timestep Consumption Time: 2.50412
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.71164

Cumulative Model Updates: 160,916
Cumulative Timesteps: 1,342,070,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.98641
Policy Entropy: 2.99716
Value Function Loss: 0.00412

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.57166
Value Function Update Magnitude: 0.49054

Collected Steps per Second: 22,545.47350
Overall Steps per Second: 10,607.21636

Timestep Collection Time: 2.21801
Timestep Consumption Time: 2.49633
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.71434

Cumulative Model Updates: 160,922
Cumulative Timesteps: 1,342,120,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1342120692...
Checkpoint 1342120692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.51326
Policy Entropy: 2.98199
Value Function Loss: 0.00431

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.49386

Collected Steps per Second: 22,833.51734
Overall Steps per Second: 10,895.67878

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.39998
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59044

Cumulative Model Updates: 160,928
Cumulative Timesteps: 1,342,170,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.03537
Policy Entropy: 3.01353
Value Function Loss: 0.00445

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10239
Policy Update Magnitude: 0.58185
Value Function Update Magnitude: 0.49466

Collected Steps per Second: 23,235.37602
Overall Steps per Second: 10,702.56528

Timestep Collection Time: 2.15206
Timestep Consumption Time: 2.52009
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.67215

Cumulative Model Updates: 160,934
Cumulative Timesteps: 1,342,220,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1342220712...
Checkpoint 1342220712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.35533
Policy Entropy: 3.01783
Value Function Loss: 0.00455

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.57813
Value Function Update Magnitude: 0.49579

Collected Steps per Second: 23,321.34757
Overall Steps per Second: 10,882.84128

Timestep Collection Time: 2.14404
Timestep Consumption Time: 2.45053
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.59457

Cumulative Model Updates: 160,940
Cumulative Timesteps: 1,342,270,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.28666
Policy Entropy: 3.03783
Value Function Loss: 0.00441

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11472
Policy Update Magnitude: 0.57354
Value Function Update Magnitude: 0.51975

Collected Steps per Second: 23,227.45086
Overall Steps per Second: 10,886.99371

Timestep Collection Time: 2.15314
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59374

Cumulative Model Updates: 160,946
Cumulative Timesteps: 1,342,320,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1342320726...
Checkpoint 1342320726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.31539
Policy Entropy: 3.00317
Value Function Loss: 0.00433

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.57364
Value Function Update Magnitude: 0.52245

Collected Steps per Second: 22,824.15078
Overall Steps per Second: 10,669.77279

Timestep Collection Time: 2.19163
Timestep Consumption Time: 2.49657
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.68820

Cumulative Model Updates: 160,952
Cumulative Timesteps: 1,342,370,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,270.85313
Policy Entropy: 3.01202
Value Function Loss: 0.00426

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.52921

Collected Steps per Second: 23,311.49640
Overall Steps per Second: 10,927.48743

Timestep Collection Time: 2.14572
Timestep Consumption Time: 2.43173
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.57745

Cumulative Model Updates: 160,958
Cumulative Timesteps: 1,342,420,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1342420768...
Checkpoint 1342420768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,420.28629
Policy Entropy: 2.99250
Value Function Loss: 0.00437

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.57125
Value Function Update Magnitude: 0.53666

Collected Steps per Second: 21,924.38385
Overall Steps per Second: 10,593.56710

Timestep Collection Time: 2.28057
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.71985

Cumulative Model Updates: 160,964
Cumulative Timesteps: 1,342,470,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,438.64387
Policy Entropy: 2.99579
Value Function Loss: 0.00464

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.59237
Value Function Update Magnitude: 0.53612

Collected Steps per Second: 22,993.50306
Overall Steps per Second: 10,902.24741

Timestep Collection Time: 2.17496
Timestep Consumption Time: 2.41217
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.58713

Cumulative Model Updates: 160,970
Cumulative Timesteps: 1,342,520,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1342520778...
Checkpoint 1342520778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.21943
Policy Entropy: 2.99579
Value Function Loss: 0.00451

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.59990
Value Function Update Magnitude: 0.55600

Collected Steps per Second: 22,792.09551
Overall Steps per Second: 10,702.62713

Timestep Collection Time: 2.19392
Timestep Consumption Time: 2.47821
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.67212

Cumulative Model Updates: 160,976
Cumulative Timesteps: 1,342,570,782

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,952.85545
Policy Entropy: 3.02708
Value Function Loss: 0.00457

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.59579
Value Function Update Magnitude: 0.56499

Collected Steps per Second: 23,015.66175
Overall Steps per Second: 10,646.92736

Timestep Collection Time: 2.17356
Timestep Consumption Time: 2.52507
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.69863

Cumulative Model Updates: 160,982
Cumulative Timesteps: 1,342,620,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1342620808...
Checkpoint 1342620808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,348.80296
Policy Entropy: 3.04111
Value Function Loss: 0.00419

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10848
Policy Update Magnitude: 0.58514
Value Function Update Magnitude: 0.55128

Collected Steps per Second: 23,077.32199
Overall Steps per Second: 10,823.40917

Timestep Collection Time: 2.16741
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.62128

Cumulative Model Updates: 160,988
Cumulative Timesteps: 1,342,670,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,036.98839
Policy Entropy: 3.03759
Value Function Loss: 0.00450

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.58203
Value Function Update Magnitude: 0.53745

Collected Steps per Second: 23,241.15263
Overall Steps per Second: 10,894.18630

Timestep Collection Time: 2.15248
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.59199

Cumulative Model Updates: 160,994
Cumulative Timesteps: 1,342,720,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1342720852...
Checkpoint 1342720852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,982.59557
Policy Entropy: 3.01709
Value Function Loss: 0.00425

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.57739
Value Function Update Magnitude: 0.51722

Collected Steps per Second: 23,097.14574
Overall Steps per Second: 10,795.61549

Timestep Collection Time: 2.16520
Timestep Consumption Time: 2.46723
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.63244

Cumulative Model Updates: 161,000
Cumulative Timesteps: 1,342,770,862

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,563.75962
Policy Entropy: 3.02300
Value Function Loss: 0.00419

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.50497

Collected Steps per Second: 23,192.64553
Overall Steps per Second: 10,819.29066

Timestep Collection Time: 2.15655
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.62285

Cumulative Model Updates: 161,006
Cumulative Timesteps: 1,342,820,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1342820878...
Checkpoint 1342820878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,893.22423
Policy Entropy: 3.01760
Value Function Loss: 0.00382

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.56237
Value Function Update Magnitude: 0.48197

Collected Steps per Second: 22,901.56553
Overall Steps per Second: 10,638.49157

Timestep Collection Time: 2.18396
Timestep Consumption Time: 2.51746
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.70142

Cumulative Model Updates: 161,012
Cumulative Timesteps: 1,342,870,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.18561
Policy Entropy: 3.02431
Value Function Loss: 0.00424

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.55940
Value Function Update Magnitude: 0.48432

Collected Steps per Second: 22,952.04740
Overall Steps per Second: 10,856.76046

Timestep Collection Time: 2.17915
Timestep Consumption Time: 2.42775
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.60690

Cumulative Model Updates: 161,018
Cumulative Timesteps: 1,342,920,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1342920910...
Checkpoint 1342920910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,141.51481
Policy Entropy: 3.01735
Value Function Loss: 0.00450

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.57855
Value Function Update Magnitude: 0.50025

Collected Steps per Second: 22,562.20393
Overall Steps per Second: 10,712.99730

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.45211
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.66909

Cumulative Model Updates: 161,024
Cumulative Timesteps: 1,342,970,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,290.53888
Policy Entropy: 3.03168
Value Function Loss: 0.00471

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.52062

Collected Steps per Second: 22,989.61326
Overall Steps per Second: 10,918.07568

Timestep Collection Time: 2.17533
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.58048

Cumulative Model Updates: 161,030
Cumulative Timesteps: 1,343,020,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1343020940...
Checkpoint 1343020940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,623.19706
Policy Entropy: 3.02212
Value Function Loss: 0.00478

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.59441
Value Function Update Magnitude: 0.53808

Collected Steps per Second: 22,468.59390
Overall Steps per Second: 10,635.44487

Timestep Collection Time: 2.22604
Timestep Consumption Time: 2.47672
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.70277

Cumulative Model Updates: 161,036
Cumulative Timesteps: 1,343,070,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.75669
Policy Entropy: 3.02262
Value Function Loss: 0.00479

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11410
Policy Update Magnitude: 0.59767
Value Function Update Magnitude: 0.57810

Collected Steps per Second: 22,641.43361
Overall Steps per Second: 10,578.26093

Timestep Collection Time: 2.20958
Timestep Consumption Time: 2.51974
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.72932

Cumulative Model Updates: 161,042
Cumulative Timesteps: 1,343,120,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1343120984...
Checkpoint 1343120984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.02923
Policy Entropy: 3.03186
Value Function Loss: 0.00432

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.58918

Collected Steps per Second: 23,176.01994
Overall Steps per Second: 10,628.42823

Timestep Collection Time: 2.15861
Timestep Consumption Time: 2.54839
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.70700

Cumulative Model Updates: 161,048
Cumulative Timesteps: 1,343,171,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.11827
Policy Entropy: 3.04283
Value Function Loss: 0.00437

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.54167

Collected Steps per Second: 23,274.56558
Overall Steps per Second: 10,763.66263

Timestep Collection Time: 2.14964
Timestep Consumption Time: 2.49859
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.64823

Cumulative Model Updates: 161,054
Cumulative Timesteps: 1,343,221,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1343221044...
Checkpoint 1343221044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,678.94823
Policy Entropy: 3.04058
Value Function Loss: 0.00422

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.52394

Collected Steps per Second: 23,066.07406
Overall Steps per Second: 10,696.20662

Timestep Collection Time: 2.16829
Timestep Consumption Time: 2.50757
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.67586

Cumulative Model Updates: 161,060
Cumulative Timesteps: 1,343,271,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,819.86377
Policy Entropy: 3.02802
Value Function Loss: 0.00403

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.51916

Collected Steps per Second: 23,044.17304
Overall Steps per Second: 10,851.52540

Timestep Collection Time: 2.17061
Timestep Consumption Time: 2.43888
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60949

Cumulative Model Updates: 161,066
Cumulative Timesteps: 1,343,321,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1343321078...
Checkpoint 1343321078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.54304
Policy Entropy: 3.03559
Value Function Loss: 0.00380

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.55904
Value Function Update Magnitude: 0.48912

Collected Steps per Second: 23,233.34928
Overall Steps per Second: 10,766.25635

Timestep Collection Time: 2.15242
Timestep Consumption Time: 2.49246
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.64488

Cumulative Model Updates: 161,072
Cumulative Timesteps: 1,343,371,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.27581
Policy Entropy: 3.03946
Value Function Loss: 0.00385

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.48370

Collected Steps per Second: 23,550.40765
Overall Steps per Second: 10,821.41884

Timestep Collection Time: 2.12311
Timestep Consumption Time: 2.49736
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.62047

Cumulative Model Updates: 161,078
Cumulative Timesteps: 1,343,421,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1343421086...
Checkpoint 1343421086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.09547
Policy Entropy: 3.04465
Value Function Loss: 0.00366

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.55311
Value Function Update Magnitude: 0.47611

Collected Steps per Second: 22,368.88105
Overall Steps per Second: 10,648.04319

Timestep Collection Time: 2.23570
Timestep Consumption Time: 2.46094
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.69664

Cumulative Model Updates: 161,084
Cumulative Timesteps: 1,343,471,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,902.12939
Policy Entropy: 3.06030
Value Function Loss: 0.00379

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.45912

Collected Steps per Second: 22,416.17658
Overall Steps per Second: 10,587.26504

Timestep Collection Time: 2.23080
Timestep Consumption Time: 2.49242
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.72322

Cumulative Model Updates: 161,090
Cumulative Timesteps: 1,343,521,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1343521102...
Checkpoint 1343521102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,321.22749
Policy Entropy: 3.06318
Value Function Loss: 0.00427

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.56314
Value Function Update Magnitude: 0.47352

Collected Steps per Second: 22,703.33544
Overall Steps per Second: 10,651.13189

Timestep Collection Time: 2.20320
Timestep Consumption Time: 2.49301
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.69621

Cumulative Model Updates: 161,096
Cumulative Timesteps: 1,343,571,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,470.19010
Policy Entropy: 3.05935
Value Function Loss: 0.00432

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.58022
Value Function Update Magnitude: 0.50210

Collected Steps per Second: 22,754.73608
Overall Steps per Second: 10,761.50110

Timestep Collection Time: 2.19814
Timestep Consumption Time: 2.44973
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.64786

Cumulative Model Updates: 161,102
Cumulative Timesteps: 1,343,621,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1343621140...
Checkpoint 1343621140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.74979
Policy Entropy: 3.04948
Value Function Loss: 0.00461

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.15388
Policy Update Magnitude: 0.59574
Value Function Update Magnitude: 0.54769

Collected Steps per Second: 22,395.49575
Overall Steps per Second: 10,590.38652

Timestep Collection Time: 2.23277
Timestep Consumption Time: 2.48887
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.72164

Cumulative Model Updates: 161,108
Cumulative Timesteps: 1,343,671,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.64958
Policy Entropy: 3.05713
Value Function Loss: 0.00444

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.59886
Value Function Update Magnitude: 0.55870

Collected Steps per Second: 23,242.21347
Overall Steps per Second: 10,839.61842

Timestep Collection Time: 2.15126
Timestep Consumption Time: 2.46145
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61271

Cumulative Model Updates: 161,114
Cumulative Timesteps: 1,343,721,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1343721144...
Checkpoint 1343721144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,068.12804
Policy Entropy: 3.04761
Value Function Loss: 0.00471

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.59295
Value Function Update Magnitude: 0.54110

Collected Steps per Second: 22,862.12248
Overall Steps per Second: 10,736.24894

Timestep Collection Time: 2.18720
Timestep Consumption Time: 2.47029
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.65749

Cumulative Model Updates: 161,120
Cumulative Timesteps: 1,343,771,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,065.68868
Policy Entropy: 3.04909
Value Function Loss: 0.00454

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.58098
Value Function Update Magnitude: 0.51921

Collected Steps per Second: 23,459.41082
Overall Steps per Second: 10,895.13581

Timestep Collection Time: 2.13194
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.59049

Cumulative Model Updates: 161,126
Cumulative Timesteps: 1,343,821,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1343821162...
Checkpoint 1343821162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.93806
Policy Entropy: 3.04817
Value Function Loss: 0.00453

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.56966
Value Function Update Magnitude: 0.50730

Collected Steps per Second: 23,232.56538
Overall Steps per Second: 10,850.41005

Timestep Collection Time: 2.15327
Timestep Consumption Time: 2.45725
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.61052

Cumulative Model Updates: 161,132
Cumulative Timesteps: 1,343,871,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,498.25541
Policy Entropy: 3.05545
Value Function Loss: 0.00478

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.58812
Value Function Update Magnitude: 0.51519

Collected Steps per Second: 23,354.75665
Overall Steps per Second: 10,763.18031

Timestep Collection Time: 2.14089
Timestep Consumption Time: 2.50458
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.64547

Cumulative Model Updates: 161,138
Cumulative Timesteps: 1,343,921,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1343921188...
Checkpoint 1343921188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,641.07220
Policy Entropy: 3.03997
Value Function Loss: 0.00496

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.61034
Value Function Update Magnitude: 0.54801

Collected Steps per Second: 22,635.80350
Overall Steps per Second: 10,618.48513

Timestep Collection Time: 2.20889
Timestep Consumption Time: 2.49988
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.70877

Cumulative Model Updates: 161,144
Cumulative Timesteps: 1,343,971,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.34276
Policy Entropy: 3.04074
Value Function Loss: 0.00484

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.60666
Value Function Update Magnitude: 0.54162

Collected Steps per Second: 22,987.47772
Overall Steps per Second: 10,919.86000

Timestep Collection Time: 2.17579
Timestep Consumption Time: 2.40449
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.58028

Cumulative Model Updates: 161,150
Cumulative Timesteps: 1,344,021,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1344021204...
Checkpoint 1344021204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756.31810
Policy Entropy: 3.01931
Value Function Loss: 0.00471

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11486
Policy Update Magnitude: 0.59324
Value Function Update Magnitude: 0.52792

Collected Steps per Second: 22,610.68012
Overall Steps per Second: 10,589.66413

Timestep Collection Time: 2.21223
Timestep Consumption Time: 2.51124
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.72347

Cumulative Model Updates: 161,156
Cumulative Timesteps: 1,344,071,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.97827
Policy Entropy: 3.01927
Value Function Loss: 0.00449

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.59447
Value Function Update Magnitude: 0.52062

Collected Steps per Second: 22,904.40624
Overall Steps per Second: 10,877.01591

Timestep Collection Time: 2.18307
Timestep Consumption Time: 2.41396
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59703

Cumulative Model Updates: 161,162
Cumulative Timesteps: 1,344,121,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1344121226...
Checkpoint 1344121226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.59033
Policy Entropy: 3.00354
Value Function Loss: 0.00426

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.58971
Value Function Update Magnitude: 0.51487

Collected Steps per Second: 22,796.40798
Overall Steps per Second: 10,696.18240

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.48302
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.67793

Cumulative Model Updates: 161,168
Cumulative Timesteps: 1,344,171,262

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.18231
Policy Entropy: 2.99857
Value Function Loss: 0.00431

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.59108
Value Function Update Magnitude: 0.50956

Collected Steps per Second: 23,265.84860
Overall Steps per Second: 10,824.34592

Timestep Collection Time: 2.14976
Timestep Consumption Time: 2.47093
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.62069

Cumulative Model Updates: 161,174
Cumulative Timesteps: 1,344,221,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1344221278...
Checkpoint 1344221278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.53323
Policy Entropy: 3.01446
Value Function Loss: 0.00395

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.58360
Value Function Update Magnitude: 0.49298

Collected Steps per Second: 22,602.04750
Overall Steps per Second: 10,570.28740

Timestep Collection Time: 2.21263
Timestep Consumption Time: 2.51856
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.73119

Cumulative Model Updates: 161,180
Cumulative Timesteps: 1,344,271,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.77254
Policy Entropy: 3.01576
Value Function Loss: 0.00408

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.56992
Value Function Update Magnitude: 0.45733

Collected Steps per Second: 23,237.32325
Overall Steps per Second: 10,795.61185

Timestep Collection Time: 2.15206
Timestep Consumption Time: 2.48020
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.63225

Cumulative Model Updates: 161,186
Cumulative Timesteps: 1,344,321,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1344321296...
Checkpoint 1344321296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.57718
Policy Entropy: 3.04108
Value Function Loss: 0.00400

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.55699
Value Function Update Magnitude: 0.43489

Collected Steps per Second: 22,714.57047
Overall Steps per Second: 10,570.66822

Timestep Collection Time: 2.20308
Timestep Consumption Time: 2.53096
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.73404

Cumulative Model Updates: 161,192
Cumulative Timesteps: 1,344,371,338

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,099.10880
Policy Entropy: 3.02448
Value Function Loss: 0.00428

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.55400
Value Function Update Magnitude: 0.44370

Collected Steps per Second: 23,375.73043
Overall Steps per Second: 10,756.77494

Timestep Collection Time: 2.14000
Timestep Consumption Time: 2.51047
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.65046

Cumulative Model Updates: 161,198
Cumulative Timesteps: 1,344,421,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1344421362...
Checkpoint 1344421362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,446.25360
Policy Entropy: 3.02800
Value Function Loss: 0.00446

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.56480
Value Function Update Magnitude: 0.45215

Collected Steps per Second: 22,630.20253
Overall Steps per Second: 10,616.62009

Timestep Collection Time: 2.20944
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.70960

Cumulative Model Updates: 161,204
Cumulative Timesteps: 1,344,471,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.33075
Policy Entropy: 3.01552
Value Function Loss: 0.00475

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.59540
Value Function Update Magnitude: 0.47453

Collected Steps per Second: 23,028.95606
Overall Steps per Second: 10,870.84956

Timestep Collection Time: 2.17170
Timestep Consumption Time: 2.42886
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60056

Cumulative Model Updates: 161,210
Cumulative Timesteps: 1,344,521,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1344521374...
Checkpoint 1344521374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,874.15182
Policy Entropy: 3.01881
Value Function Loss: 0.00459

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.59340
Value Function Update Magnitude: 0.49483

Collected Steps per Second: 22,622.09857
Overall Steps per Second: 10,733.27580

Timestep Collection Time: 2.21032
Timestep Consumption Time: 2.44828
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.65860

Cumulative Model Updates: 161,216
Cumulative Timesteps: 1,344,571,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.94892
Policy Entropy: 3.00816
Value Function Loss: 0.00451

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.58465
Value Function Update Magnitude: 0.48887

Collected Steps per Second: 22,826.22229
Overall Steps per Second: 10,851.71919

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.41865
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.61051

Cumulative Model Updates: 161,222
Cumulative Timesteps: 1,344,621,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1344621408...
Checkpoint 1344621408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.21438
Policy Entropy: 2.99806
Value Function Loss: 0.00451

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11168
Policy Update Magnitude: 0.58086
Value Function Update Magnitude: 0.49062

Collected Steps per Second: 22,597.29564
Overall Steps per Second: 10,662.27101

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.47757
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.69093

Cumulative Model Updates: 161,228
Cumulative Timesteps: 1,344,671,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,875.25700
Policy Entropy: 2.97705
Value Function Loss: 0.00475

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.58724
Value Function Update Magnitude: 0.50860

Collected Steps per Second: 22,808.24044
Overall Steps per Second: 10,840.75207

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61444

Cumulative Model Updates: 161,234
Cumulative Timesteps: 1,344,721,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1344721448...
Checkpoint 1344721448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.27457
Policy Entropy: 2.98071
Value Function Loss: 0.00459

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.58495
Value Function Update Magnitude: 0.50739

Collected Steps per Second: 23,141.65420
Overall Steps per Second: 10,728.42147

Timestep Collection Time: 2.16156
Timestep Consumption Time: 2.50101
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.66257

Cumulative Model Updates: 161,240
Cumulative Timesteps: 1,344,771,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,555.40495
Policy Entropy: 2.99502
Value Function Loss: 0.00426

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.57584
Value Function Update Magnitude: 0.47666

Collected Steps per Second: 23,579.56107
Overall Steps per Second: 10,906.47465

Timestep Collection Time: 2.12082
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.58517

Cumulative Model Updates: 161,246
Cumulative Timesteps: 1,344,821,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1344821478...
Checkpoint 1344821478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,827.15083
Policy Entropy: 3.00928
Value Function Loss: 0.00463

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.59041
Value Function Update Magnitude: 0.48286

Collected Steps per Second: 22,930.68688
Overall Steps per Second: 10,775.80633

Timestep Collection Time: 2.18057
Timestep Consumption Time: 2.45964
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.64021

Cumulative Model Updates: 161,252
Cumulative Timesteps: 1,344,871,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,688.87976
Policy Entropy: 3.01169
Value Function Loss: 0.00481

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.60302
Value Function Update Magnitude: 0.52339

Collected Steps per Second: 23,214.99662
Overall Steps per Second: 10,768.21887

Timestep Collection Time: 2.15395
Timestep Consumption Time: 2.48971
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.64366

Cumulative Model Updates: 161,258
Cumulative Timesteps: 1,344,921,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1344921484...
Checkpoint 1344921484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.55318
Policy Entropy: 3.01057
Value Function Loss: 0.00509

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.61007
Value Function Update Magnitude: 0.55201

Collected Steps per Second: 23,019.29537
Overall Steps per Second: 10,812.63457

Timestep Collection Time: 2.17322
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.62662

Cumulative Model Updates: 161,264
Cumulative Timesteps: 1,344,971,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.32726
Policy Entropy: 3.01168
Value Function Loss: 0.00474

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.61032
Value Function Update Magnitude: 0.53039

Collected Steps per Second: 23,276.52057
Overall Steps per Second: 10,802.17876

Timestep Collection Time: 2.14817
Timestep Consumption Time: 2.48071
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.62888

Cumulative Model Updates: 161,270
Cumulative Timesteps: 1,345,021,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1345021512...
Checkpoint 1345021512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.09530
Policy Entropy: 3.01013
Value Function Loss: 0.00477

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.59638
Value Function Update Magnitude: 0.51855

Collected Steps per Second: 22,460.95956
Overall Steps per Second: 10,533.99604

Timestep Collection Time: 2.22635
Timestep Consumption Time: 2.52075
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.74711

Cumulative Model Updates: 161,276
Cumulative Timesteps: 1,345,071,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.71366
Policy Entropy: 3.02093
Value Function Loss: 0.00443

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.58653
Value Function Update Magnitude: 0.51758

Collected Steps per Second: 22,866.76266
Overall Steps per Second: 10,876.60680

Timestep Collection Time: 2.18763
Timestep Consumption Time: 2.41160
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.59923

Cumulative Model Updates: 161,282
Cumulative Timesteps: 1,345,121,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1345121542...
Checkpoint 1345121542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.64104
Policy Entropy: 3.02629
Value Function Loss: 0.00474

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.59460
Value Function Update Magnitude: 0.52786

Collected Steps per Second: 22,592.63142
Overall Steps per Second: 10,721.49619

Timestep Collection Time: 2.21329
Timestep Consumption Time: 2.45061
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.66390

Cumulative Model Updates: 161,288
Cumulative Timesteps: 1,345,171,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.92647
Policy Entropy: 3.04844
Value Function Loss: 0.00424

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.58740
Value Function Update Magnitude: 0.53602

Collected Steps per Second: 23,254.20099
Overall Steps per Second: 10,873.77253

Timestep Collection Time: 2.15118
Timestep Consumption Time: 2.44925
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60043

Cumulative Model Updates: 161,294
Cumulative Timesteps: 1,345,221,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1345221570...
Checkpoint 1345221570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,156.99624
Policy Entropy: 3.04856
Value Function Loss: 0.00398

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.57351
Value Function Update Magnitude: 0.51170

Collected Steps per Second: 23,111.12105
Overall Steps per Second: 10,655.56891

Timestep Collection Time: 2.16389
Timestep Consumption Time: 2.52943
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.69332

Cumulative Model Updates: 161,300
Cumulative Timesteps: 1,345,271,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,250.80500
Policy Entropy: 3.03633
Value Function Loss: 0.00401

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.57587
Value Function Update Magnitude: 0.48685

Collected Steps per Second: 23,235.86981
Overall Steps per Second: 10,874.61490

Timestep Collection Time: 2.15322
Timestep Consumption Time: 2.44758
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.60081

Cumulative Model Updates: 161,306
Cumulative Timesteps: 1,345,321,612

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1345321612...
Checkpoint 1345321612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.86630
Policy Entropy: 3.01553
Value Function Loss: 0.00473

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.60265
Value Function Update Magnitude: 0.49453

Collected Steps per Second: 22,847.99530
Overall Steps per Second: 10,728.34084

Timestep Collection Time: 2.18838
Timestep Consumption Time: 2.47218
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.66055

Cumulative Model Updates: 161,312
Cumulative Timesteps: 1,345,371,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.73540
Policy Entropy: 3.00177
Value Function Loss: 0.00522

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.61280
Value Function Update Magnitude: 0.52399

Collected Steps per Second: 23,356.32468
Overall Steps per Second: 10,830.06768

Timestep Collection Time: 2.14169
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.61881

Cumulative Model Updates: 161,318
Cumulative Timesteps: 1,345,421,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1345421634...
Checkpoint 1345421634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.52181
Policy Entropy: 2.99733
Value Function Loss: 0.00531

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.61374
Value Function Update Magnitude: 0.53915

Collected Steps per Second: 22,954.83513
Overall Steps per Second: 10,731.11066

Timestep Collection Time: 2.17871
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.66047

Cumulative Model Updates: 161,324
Cumulative Timesteps: 1,345,471,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120.23175
Policy Entropy: 2.99054
Value Function Loss: 0.00481

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.61082
Value Function Update Magnitude: 0.55369

Collected Steps per Second: 23,429.03131
Overall Steps per Second: 10,833.56735

Timestep Collection Time: 2.13470
Timestep Consumption Time: 2.48188
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.61658

Cumulative Model Updates: 161,330
Cumulative Timesteps: 1,345,521,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1345521660...
Checkpoint 1345521660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.72027
Policy Entropy: 2.98587
Value Function Loss: 0.00451

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.60866
Value Function Update Magnitude: 0.54320

Collected Steps per Second: 22,151.21316
Overall Steps per Second: 10,687.50529

Timestep Collection Time: 2.25812
Timestep Consumption Time: 2.42212
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.68023

Cumulative Model Updates: 161,336
Cumulative Timesteps: 1,345,571,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.09030
Policy Entropy: 2.99676
Value Function Loss: 0.00454

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11832
Policy Update Magnitude: 0.60789
Value Function Update Magnitude: 0.53216

Collected Steps per Second: 22,860.48164
Overall Steps per Second: 10,817.50005

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.43584
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62380

Cumulative Model Updates: 161,342
Cumulative Timesteps: 1,345,621,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1345621698...
Checkpoint 1345621698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,228.09634
Policy Entropy: 3.00997
Value Function Loss: 0.00452

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.60201
Value Function Update Magnitude: 0.53606

Collected Steps per Second: 22,377.14158
Overall Steps per Second: 10,688.99252

Timestep Collection Time: 2.23523
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.67939

Cumulative Model Updates: 161,348
Cumulative Timesteps: 1,345,671,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914.64084
Policy Entropy: 3.02596
Value Function Loss: 0.00425

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11346
Policy Update Magnitude: 0.59927
Value Function Update Magnitude: 0.54053

Collected Steps per Second: 22,905.62133
Overall Steps per Second: 10,815.81769

Timestep Collection Time: 2.18418
Timestep Consumption Time: 2.44145
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.62563

Cumulative Model Updates: 161,354
Cumulative Timesteps: 1,345,721,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1345721746...
Checkpoint 1345721746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.36354
Policy Entropy: 3.02584
Value Function Loss: 0.00418

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.59712
Value Function Update Magnitude: 0.52260

Collected Steps per Second: 22,634.56263
Overall Steps per Second: 10,780.54973

Timestep Collection Time: 2.20989
Timestep Consumption Time: 2.42994
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.63984

Cumulative Model Updates: 161,360
Cumulative Timesteps: 1,345,771,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.75956
Policy Entropy: 3.03615
Value Function Loss: 0.00417

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.58654
Value Function Update Magnitude: 0.51710

Collected Steps per Second: 23,450.13926
Overall Steps per Second: 10,750.87763

Timestep Collection Time: 2.13218
Timestep Consumption Time: 2.51860
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.65078

Cumulative Model Updates: 161,366
Cumulative Timesteps: 1,345,821,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1345821766...
Checkpoint 1345821766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.84493
Policy Entropy: 3.03490
Value Function Loss: 0.00446

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.58546
Value Function Update Magnitude: 0.51642

Collected Steps per Second: 22,918.13429
Overall Steps per Second: 10,692.73377

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.67757

Cumulative Model Updates: 161,372
Cumulative Timesteps: 1,345,871,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,424.29722
Policy Entropy: 3.03848
Value Function Loss: 0.00430

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.58567
Value Function Update Magnitude: 0.51273

Collected Steps per Second: 23,379.15646
Overall Steps per Second: 11,012.78235

Timestep Collection Time: 2.13968
Timestep Consumption Time: 2.40267
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.54236

Cumulative Model Updates: 161,378
Cumulative Timesteps: 1,345,921,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1345921806...
Checkpoint 1345921806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,373.98024
Policy Entropy: 3.02144
Value Function Loss: 0.00464

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.60893
Value Function Update Magnitude: 0.50328

Collected Steps per Second: 23,067.58172
Overall Steps per Second: 10,711.37882

Timestep Collection Time: 2.16893
Timestep Consumption Time: 2.50199
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.67092

Cumulative Model Updates: 161,384
Cumulative Timesteps: 1,345,971,838

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.60237
Policy Entropy: 3.01880
Value Function Loss: 0.00490

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.61206
Value Function Update Magnitude: 0.52655

Collected Steps per Second: 23,473.49329
Overall Steps per Second: 10,841.05722

Timestep Collection Time: 2.13117
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.61449

Cumulative Model Updates: 161,390
Cumulative Timesteps: 1,346,021,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1346021864...
Checkpoint 1346021864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.16227
Policy Entropy: 3.00810
Value Function Loss: 0.00499

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12619
Policy Update Magnitude: 0.60076
Value Function Update Magnitude: 0.54424

Collected Steps per Second: 22,434.80488
Overall Steps per Second: 10,619.11189

Timestep Collection Time: 2.22895
Timestep Consumption Time: 2.48011
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.70906

Cumulative Model Updates: 161,396
Cumulative Timesteps: 1,346,071,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.29976
Policy Entropy: 3.01780
Value Function Loss: 0.00467

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.59252
Value Function Update Magnitude: 0.51444

Collected Steps per Second: 22,952.41328
Overall Steps per Second: 10,918.17752

Timestep Collection Time: 2.17920
Timestep Consumption Time: 2.40196
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.58117

Cumulative Model Updates: 161,402
Cumulative Timesteps: 1,346,121,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1346121888...
Checkpoint 1346121888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.02919
Policy Entropy: 3.03478
Value Function Loss: 0.00442

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.58184
Value Function Update Magnitude: 0.49788

Collected Steps per Second: 22,745.21345
Overall Steps per Second: 10,604.70080

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.51693
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.71546

Cumulative Model Updates: 161,408
Cumulative Timesteps: 1,346,171,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.49781
Policy Entropy: 3.04778
Value Function Loss: 0.00409

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.57595
Value Function Update Magnitude: 0.49300

Collected Steps per Second: 23,033.74030
Overall Steps per Second: 10,666.66712

Timestep Collection Time: 2.17177
Timestep Consumption Time: 2.51798
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.68975

Cumulative Model Updates: 161,414
Cumulative Timesteps: 1,346,221,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1346221918...
Checkpoint 1346221918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.14914
Policy Entropy: 3.05141
Value Function Loss: 0.00435

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.58736
Value Function Update Magnitude: 0.51326

Collected Steps per Second: 22,857.43330
Overall Steps per Second: 10,751.28610

Timestep Collection Time: 2.18782
Timestep Consumption Time: 2.46353
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.65135

Cumulative Model Updates: 161,420
Cumulative Timesteps: 1,346,271,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.86611
Policy Entropy: 3.03698
Value Function Loss: 0.00415

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.59111
Value Function Update Magnitude: 0.53883

Collected Steps per Second: 22,164.19165
Overall Steps per Second: 10,586.95185

Timestep Collection Time: 2.25670
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.72449

Cumulative Model Updates: 161,426
Cumulative Timesteps: 1,346,321,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1346321944...
Checkpoint 1346321944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,058.29511
Policy Entropy: 3.02339
Value Function Loss: 0.00426

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.58967
Value Function Update Magnitude: 0.52860

Collected Steps per Second: 22,624.35459
Overall Steps per Second: 10,651.12455

Timestep Collection Time: 2.21133
Timestep Consumption Time: 2.48582
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.69716

Cumulative Model Updates: 161,432
Cumulative Timesteps: 1,346,371,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,015.83586
Policy Entropy: 3.01701
Value Function Loss: 0.00429

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.59238
Value Function Update Magnitude: 0.53757

Collected Steps per Second: 22,870.75867
Overall Steps per Second: 10,882.34109

Timestep Collection Time: 2.18620
Timestep Consumption Time: 2.40840
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59460

Cumulative Model Updates: 161,438
Cumulative Timesteps: 1,346,421,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1346421974...
Checkpoint 1346421974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715.58183
Policy Entropy: 3.02244
Value Function Loss: 0.00443

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10641
Policy Update Magnitude: 0.60070
Value Function Update Magnitude: 0.53655

Collected Steps per Second: 22,757.78227
Overall Steps per Second: 10,658.44253

Timestep Collection Time: 2.19723
Timestep Consumption Time: 2.49427
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.69149

Cumulative Model Updates: 161,444
Cumulative Timesteps: 1,346,471,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.96423
Policy Entropy: 3.02841
Value Function Loss: 0.00445

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.59879
Value Function Update Magnitude: 0.52646

Collected Steps per Second: 23,399.75397
Overall Steps per Second: 10,907.46397

Timestep Collection Time: 2.13737
Timestep Consumption Time: 2.44793
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.58530

Cumulative Model Updates: 161,450
Cumulative Timesteps: 1,346,521,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1346521992...
Checkpoint 1346521992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.62750
Policy Entropy: 3.03768
Value Function Loss: 0.00427

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.58826
Value Function Update Magnitude: 0.50597

Collected Steps per Second: 23,143.43122
Overall Steps per Second: 10,746.39456

Timestep Collection Time: 2.16174
Timestep Consumption Time: 2.49378
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.65551

Cumulative Model Updates: 161,456
Cumulative Timesteps: 1,346,572,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.27893
Policy Entropy: 3.04265
Value Function Loss: 0.00415

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.57211
Value Function Update Magnitude: 0.47382

Collected Steps per Second: 23,070.51352
Overall Steps per Second: 10,787.02804

Timestep Collection Time: 2.16840
Timestep Consumption Time: 2.46921
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.63761

Cumulative Model Updates: 161,462
Cumulative Timesteps: 1,346,622,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1346622048...
Checkpoint 1346622048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.05329
Policy Entropy: 3.04235
Value Function Loss: 0.00446

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.57253
Value Function Update Magnitude: 0.48331

Collected Steps per Second: 22,972.15696
Overall Steps per Second: 10,644.70191

Timestep Collection Time: 2.17655
Timestep Consumption Time: 2.52062
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.69717

Cumulative Model Updates: 161,468
Cumulative Timesteps: 1,346,672,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.15760
Policy Entropy: 3.04413
Value Function Loss: 0.00465

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.59213
Value Function Update Magnitude: 0.53099

Collected Steps per Second: 23,293.47209
Overall Steps per Second: 10,925.22371

Timestep Collection Time: 2.14704
Timestep Consumption Time: 2.43062
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.57766

Cumulative Model Updates: 161,474
Cumulative Timesteps: 1,346,722,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1346722060...
Checkpoint 1346722060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.25456
Policy Entropy: 3.02586
Value Function Loss: 0.00459

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.60021
Value Function Update Magnitude: 0.55547

Collected Steps per Second: 22,622.42595
Overall Steps per Second: 10,659.82197

Timestep Collection Time: 2.21126
Timestep Consumption Time: 2.48150
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.69276

Cumulative Model Updates: 161,480
Cumulative Timesteps: 1,346,772,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,060.05934
Policy Entropy: 3.01694
Value Function Loss: 0.00452

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.60517
Value Function Update Magnitude: 0.57644

Collected Steps per Second: 22,760.09175
Overall Steps per Second: 10,796.89041

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.63096

Cumulative Model Updates: 161,486
Cumulative Timesteps: 1,346,822,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1346822084...
Checkpoint 1346822084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,908.33827
Policy Entropy: 3.01060
Value Function Loss: 0.00445

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.60579
Value Function Update Magnitude: 0.56959

Collected Steps per Second: 21,924.25556
Overall Steps per Second: 10,686.89162

Timestep Collection Time: 2.28158
Timestep Consumption Time: 2.39910
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.68069

Cumulative Model Updates: 161,492
Cumulative Timesteps: 1,346,872,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759.80533
Policy Entropy: 3.01971
Value Function Loss: 0.00443

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.60549
Value Function Update Magnitude: 0.55769

Collected Steps per Second: 23,266.80735
Overall Steps per Second: 10,886.80591

Timestep Collection Time: 2.14907
Timestep Consumption Time: 2.44383
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.59290

Cumulative Model Updates: 161,498
Cumulative Timesteps: 1,346,922,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1346922108...
Checkpoint 1346922108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.88757
Policy Entropy: 3.04165
Value Function Loss: 0.00407

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.59604
Value Function Update Magnitude: 0.52125

Collected Steps per Second: 23,194.06678
Overall Steps per Second: 10,690.88606

Timestep Collection Time: 2.15684
Timestep Consumption Time: 2.52247
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.67931

Cumulative Model Updates: 161,504
Cumulative Timesteps: 1,346,972,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,249.79025
Policy Entropy: 3.03583
Value Function Loss: 0.00421

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10872
Policy Update Magnitude: 0.58943
Value Function Update Magnitude: 0.49835

Collected Steps per Second: 23,284.70822
Overall Steps per Second: 10,940.22497

Timestep Collection Time: 2.14785
Timestep Consumption Time: 2.42354
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.57139

Cumulative Model Updates: 161,510
Cumulative Timesteps: 1,347,022,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1347022146...
Checkpoint 1347022146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,094.79571
Policy Entropy: 3.04467
Value Function Loss: 0.00421

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.58287
Value Function Update Magnitude: 0.48929

Collected Steps per Second: 22,905.72186
Overall Steps per Second: 10,626.45759

Timestep Collection Time: 2.18408
Timestep Consumption Time: 2.52379
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.70787

Cumulative Model Updates: 161,516
Cumulative Timesteps: 1,347,072,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.08744
Policy Entropy: 3.03009
Value Function Loss: 0.00435

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.58615
Value Function Update Magnitude: 0.49871

Collected Steps per Second: 23,281.59821
Overall Steps per Second: 10,910.43126

Timestep Collection Time: 2.14788
Timestep Consumption Time: 2.43544
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.58332

Cumulative Model Updates: 161,522
Cumulative Timesteps: 1,347,122,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1347122180...
Checkpoint 1347122180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.16298
Policy Entropy: 3.01993
Value Function Loss: 0.00443

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.59272
Value Function Update Magnitude: 0.49777

Collected Steps per Second: 23,019.59731
Overall Steps per Second: 10,794.68631

Timestep Collection Time: 2.17267
Timestep Consumption Time: 2.46054
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.63321

Cumulative Model Updates: 161,528
Cumulative Timesteps: 1,347,172,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.17516
Policy Entropy: 3.01036
Value Function Loss: 0.00444

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.59283
Value Function Update Magnitude: 0.50767

Collected Steps per Second: 22,804.73644
Overall Steps per Second: 10,797.97534

Timestep Collection Time: 2.19384
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.63328

Cumulative Model Updates: 161,534
Cumulative Timesteps: 1,347,222,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1347222224...
Checkpoint 1347222224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.14029
Policy Entropy: 3.00805
Value Function Loss: 0.00461

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.60413
Value Function Update Magnitude: 0.52111

Collected Steps per Second: 22,437.34473
Overall Steps per Second: 10,615.87192

Timestep Collection Time: 2.22896
Timestep Consumption Time: 2.48210
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.71106

Cumulative Model Updates: 161,540
Cumulative Timesteps: 1,347,272,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,840.39069
Policy Entropy: 2.99549
Value Function Loss: 0.00466

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.61237
Value Function Update Magnitude: 0.53433

Collected Steps per Second: 22,914.10825
Overall Steps per Second: 10,882.39347

Timestep Collection Time: 2.18250
Timestep Consumption Time: 2.41300
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.59550

Cumulative Model Updates: 161,546
Cumulative Timesteps: 1,347,322,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1347322246...
Checkpoint 1347322246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,304.99032
Policy Entropy: 2.99956
Value Function Loss: 0.00461

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.60979
Value Function Update Magnitude: 0.52957

Collected Steps per Second: 22,807.86908
Overall Steps per Second: 10,642.36997

Timestep Collection Time: 2.19337
Timestep Consumption Time: 2.50728
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.70064

Cumulative Model Updates: 161,552
Cumulative Timesteps: 1,347,372,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,895.50315
Policy Entropy: 3.00067
Value Function Loss: 0.00458

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.61530
Value Function Update Magnitude: 0.52398

Collected Steps per Second: 23,375.14005
Overall Steps per Second: 10,879.39759

Timestep Collection Time: 2.13928
Timestep Consumption Time: 2.45711
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59639

Cumulative Model Updates: 161,558
Cumulative Timesteps: 1,347,422,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1347422278...
Checkpoint 1347422278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.61207
Policy Entropy: 3.01399
Value Function Loss: 0.00433

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.61710
Value Function Update Magnitude: 0.52806

Collected Steps per Second: 22,745.55857
Overall Steps per Second: 10,697.29646

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.67501

Cumulative Model Updates: 161,564
Cumulative Timesteps: 1,347,472,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.75390
Policy Entropy: 3.02259
Value Function Loss: 0.00444

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11873
Policy Update Magnitude: 0.61176
Value Function Update Magnitude: 0.52664

Collected Steps per Second: 22,849.98148
Overall Steps per Second: 10,805.04662

Timestep Collection Time: 2.18889
Timestep Consumption Time: 2.44006
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.62895

Cumulative Model Updates: 161,570
Cumulative Timesteps: 1,347,522,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1347522304...
Checkpoint 1347522304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,629.34269
Policy Entropy: 3.03643
Value Function Loss: 0.00440

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.60470
Value Function Update Magnitude: 0.54468

Collected Steps per Second: 23,174.90125
Overall Steps per Second: 10,791.50860

Timestep Collection Time: 2.15863
Timestep Consumption Time: 2.47705
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.63568

Cumulative Model Updates: 161,576
Cumulative Timesteps: 1,347,572,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674.16993
Policy Entropy: 3.04834
Value Function Loss: 0.00436

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.59818
Value Function Update Magnitude: 0.52616

Collected Steps per Second: 23,183.52971
Overall Steps per Second: 10,882.37018

Timestep Collection Time: 2.15782
Timestep Consumption Time: 2.43915
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.59698

Cumulative Model Updates: 161,582
Cumulative Timesteps: 1,347,622,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1347622356...
Checkpoint 1347622356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.08760
Policy Entropy: 3.05363
Value Function Loss: 0.00416

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.58843
Value Function Update Magnitude: 0.52756

Collected Steps per Second: 22,885.00040
Overall Steps per Second: 10,740.56390

Timestep Collection Time: 2.18606
Timestep Consumption Time: 2.47180
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.65786

Cumulative Model Updates: 161,588
Cumulative Timesteps: 1,347,672,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.48049
Policy Entropy: 3.06319
Value Function Loss: 0.00414

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.58456
Value Function Update Magnitude: 0.53237

Collected Steps per Second: 22,893.24249
Overall Steps per Second: 10,793.81237

Timestep Collection Time: 2.18405
Timestep Consumption Time: 2.44823
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.63228

Cumulative Model Updates: 161,594
Cumulative Timesteps: 1,347,722,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1347722384...
Checkpoint 1347722384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,897.44298
Policy Entropy: 3.07045
Value Function Loss: 0.00414

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.58587
Value Function Update Magnitude: 0.51378

Collected Steps per Second: 22,682.87604
Overall Steps per Second: 10,660.66672

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.48623
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.69089

Cumulative Model Updates: 161,600
Cumulative Timesteps: 1,347,772,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.33909
Policy Entropy: 3.08364
Value Function Loss: 0.00442

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10997
Policy Update Magnitude: 0.57876
Value Function Update Magnitude: 0.51274

Collected Steps per Second: 22,864.27689
Overall Steps per Second: 10,827.16914

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.43178
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61912

Cumulative Model Updates: 161,606
Cumulative Timesteps: 1,347,822,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1347822404...
Checkpoint 1347822404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.00161
Policy Entropy: 3.08030
Value Function Loss: 0.00483

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.58610
Value Function Update Magnitude: 0.55204

Collected Steps per Second: 22,569.47436
Overall Steps per Second: 10,759.44359

Timestep Collection Time: 2.21724
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.65098

Cumulative Model Updates: 161,612
Cumulative Timesteps: 1,347,872,446

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,004.48730
Policy Entropy: 3.06974
Value Function Loss: 0.00500

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.59800
Value Function Update Magnitude: 0.56884

Collected Steps per Second: 23,278.23345
Overall Steps per Second: 10,865.10787

Timestep Collection Time: 2.14836
Timestep Consumption Time: 2.45445
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60281

Cumulative Model Updates: 161,618
Cumulative Timesteps: 1,347,922,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1347922456...
Checkpoint 1347922456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,113.02854
Policy Entropy: 3.05848
Value Function Loss: 0.00517

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.60836
Value Function Update Magnitude: 0.56502

Collected Steps per Second: 23,189.11168
Overall Steps per Second: 10,844.18618

Timestep Collection Time: 2.15662
Timestep Consumption Time: 2.45507
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.61169

Cumulative Model Updates: 161,624
Cumulative Timesteps: 1,347,972,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.64388
Policy Entropy: 3.03896
Value Function Loss: 0.00523

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.60650
Value Function Update Magnitude: 0.54176

Collected Steps per Second: 23,422.09673
Overall Steps per Second: 10,877.13913

Timestep Collection Time: 2.13550
Timestep Consumption Time: 2.46295
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.59845

Cumulative Model Updates: 161,630
Cumulative Timesteps: 1,348,022,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1348022484...
Checkpoint 1348022484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.21338
Policy Entropy: 3.04605
Value Function Loss: 0.00505

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.60775
Value Function Update Magnitude: 0.53544

Collected Steps per Second: 23,034.85028
Overall Steps per Second: 10,924.52877

Timestep Collection Time: 2.17080
Timestep Consumption Time: 2.40642
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.57722

Cumulative Model Updates: 161,636
Cumulative Timesteps: 1,348,072,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.01482
Policy Entropy: 3.01832
Value Function Loss: 0.00484

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.60483
Value Function Update Magnitude: 0.51203

Collected Steps per Second: 23,522.75176
Overall Steps per Second: 10,937.14543

Timestep Collection Time: 2.12577
Timestep Consumption Time: 2.44617
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.57194

Cumulative Model Updates: 161,642
Cumulative Timesteps: 1,348,122,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1348122492...
Checkpoint 1348122492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.72469
Policy Entropy: 3.00444
Value Function Loss: 0.00514

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.61258
Value Function Update Magnitude: 0.49766

Collected Steps per Second: 22,581.12944
Overall Steps per Second: 10,659.81116

Timestep Collection Time: 2.21548
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.69314

Cumulative Model Updates: 161,648
Cumulative Timesteps: 1,348,172,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.80113
Policy Entropy: 2.99557
Value Function Loss: 0.00504

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.61744
Value Function Update Magnitude: 0.50344

Collected Steps per Second: 22,890.07515
Overall Steps per Second: 10,811.97607

Timestep Collection Time: 2.18540
Timestep Consumption Time: 2.44132
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.62672

Cumulative Model Updates: 161,654
Cumulative Timesteps: 1,348,222,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1348222544...
Checkpoint 1348222544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.25311
Policy Entropy: 3.00224
Value Function Loss: 0.00503

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.61542
Value Function Update Magnitude: 0.50840

Collected Steps per Second: 22,640.54640
Overall Steps per Second: 10,742.79358

Timestep Collection Time: 2.20922
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.65596

Cumulative Model Updates: 161,660
Cumulative Timesteps: 1,348,272,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,368.79312
Policy Entropy: 3.01993
Value Function Loss: 0.00444

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.60602
Value Function Update Magnitude: 0.51517

Collected Steps per Second: 23,203.31062
Overall Steps per Second: 10,840.31402

Timestep Collection Time: 2.15512
Timestep Consumption Time: 2.45784
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.61297

Cumulative Model Updates: 161,666
Cumulative Timesteps: 1,348,322,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1348322568...
Checkpoint 1348322568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,787.07821
Policy Entropy: 3.00924
Value Function Loss: 0.00438

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.59865
Value Function Update Magnitude: 0.50566

Collected Steps per Second: 22,912.88331
Overall Steps per Second: 10,741.33853

Timestep Collection Time: 2.18314
Timestep Consumption Time: 2.47382
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.65696

Cumulative Model Updates: 161,672
Cumulative Timesteps: 1,348,372,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.49994
Policy Entropy: 3.00679
Value Function Loss: 0.00496

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.61553
Value Function Update Magnitude: 0.52578

Collected Steps per Second: 23,389.32895
Overall Steps per Second: 10,854.63914

Timestep Collection Time: 2.13773
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.60633

Cumulative Model Updates: 161,678
Cumulative Timesteps: 1,348,422,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1348422590...
Checkpoint 1348422590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.16601
Policy Entropy: 3.01644
Value Function Loss: 0.00525

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.62323
Value Function Update Magnitude: 0.55982

Collected Steps per Second: 22,879.21054
Overall Steps per Second: 10,712.92555

Timestep Collection Time: 2.18600
Timestep Consumption Time: 2.48256
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.66857

Cumulative Model Updates: 161,684
Cumulative Timesteps: 1,348,472,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.51084
Policy Entropy: 3.03665
Value Function Loss: 0.00564

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.62343
Value Function Update Magnitude: 0.56896

Collected Steps per Second: 23,410.04478
Overall Steps per Second: 10,805.70777

Timestep Collection Time: 2.13635
Timestep Consumption Time: 2.49195
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.62829

Cumulative Model Updates: 161,690
Cumulative Timesteps: 1,348,522,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1348522616...
Checkpoint 1348522616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.41539
Policy Entropy: 3.03156
Value Function Loss: 0.00549

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.61332
Value Function Update Magnitude: 0.56850

Collected Steps per Second: 22,911.26539
Overall Steps per Second: 10,737.95692

Timestep Collection Time: 2.18286
Timestep Consumption Time: 2.47464
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.65750

Cumulative Model Updates: 161,696
Cumulative Timesteps: 1,348,572,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.97720
Policy Entropy: 3.01631
Value Function Loss: 0.00568

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.61758
Value Function Update Magnitude: 0.56881

Collected Steps per Second: 22,800.25059
Overall Steps per Second: 10,881.32772

Timestep Collection Time: 2.19366
Timestep Consumption Time: 2.40284
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.59650

Cumulative Model Updates: 161,702
Cumulative Timesteps: 1,348,622,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1348622644...
Checkpoint 1348622644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,919.63016
Policy Entropy: 2.99364
Value Function Loss: 0.00540

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.62365
Value Function Update Magnitude: 0.57802

Collected Steps per Second: 22,514.39528
Overall Steps per Second: 10,660.55678

Timestep Collection Time: 2.22142
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.69150

Cumulative Model Updates: 161,708
Cumulative Timesteps: 1,348,672,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.76812
Policy Entropy: 3.01079
Value Function Loss: 0.00533

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.62979
Value Function Update Magnitude: 0.57634

Collected Steps per Second: 22,950.55707
Overall Steps per Second: 10,873.43719

Timestep Collection Time: 2.17868
Timestep Consumption Time: 2.41986
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.59855

Cumulative Model Updates: 161,714
Cumulative Timesteps: 1,348,722,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1348722660...
Checkpoint 1348722660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.79434
Policy Entropy: 3.00309
Value Function Loss: 0.00485

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.62094
Value Function Update Magnitude: 0.56287

Collected Steps per Second: 22,605.43373
Overall Steps per Second: 10,657.65931

Timestep Collection Time: 2.21283
Timestep Consumption Time: 2.48070
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.69353

Cumulative Model Updates: 161,720
Cumulative Timesteps: 1,348,772,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.68715
Policy Entropy: 3.02764
Value Function Loss: 0.00461

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.60367
Value Function Update Magnitude: 0.54663

Collected Steps per Second: 22,742.01724
Overall Steps per Second: 10,818.45777

Timestep Collection Time: 2.19928
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62321

Cumulative Model Updates: 161,726
Cumulative Timesteps: 1,348,822,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1348822698...
Checkpoint 1348822698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.95560
Policy Entropy: 3.02725
Value Function Loss: 0.00435

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.59361
Value Function Update Magnitude: 0.53434

Collected Steps per Second: 22,750.96441
Overall Steps per Second: 10,695.73813

Timestep Collection Time: 2.19841
Timestep Consumption Time: 2.47784
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.67626

Cumulative Model Updates: 161,732
Cumulative Timesteps: 1,348,872,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.56120
Policy Entropy: 3.04218
Value Function Loss: 0.00516

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.62037
Value Function Update Magnitude: 0.56947

Collected Steps per Second: 23,107.83837
Overall Steps per Second: 10,832.42411

Timestep Collection Time: 2.16403
Timestep Consumption Time: 2.45230
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.61633

Cumulative Model Updates: 161,738
Cumulative Timesteps: 1,348,922,720

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1348922720...
Checkpoint 1348922720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.87832
Policy Entropy: 3.03460
Value Function Loss: 0.00526

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.62510
Value Function Update Magnitude: 0.60372

Collected Steps per Second: 22,839.86356
Overall Steps per Second: 10,698.04017

Timestep Collection Time: 2.18924
Timestep Consumption Time: 2.48470
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.67394

Cumulative Model Updates: 161,744
Cumulative Timesteps: 1,348,972,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,613.80267
Policy Entropy: 3.03432
Value Function Loss: 0.00540

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.61974
Value Function Update Magnitude: 0.59625

Collected Steps per Second: 23,361.64419
Overall Steps per Second: 10,998.56315

Timestep Collection Time: 2.14095
Timestep Consumption Time: 2.40656
PPO Batch Consumption Time: 0.27539
Total Iteration Time: 4.54750

Cumulative Model Updates: 161,750
Cumulative Timesteps: 1,349,022,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1349022738...
Checkpoint 1349022738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.06197
Policy Entropy: 3.02682
Value Function Loss: 0.00504

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.61546
Value Function Update Magnitude: 0.58072

Collected Steps per Second: 22,887.85450
Overall Steps per Second: 10,931.73315

Timestep Collection Time: 2.18579
Timestep Consumption Time: 2.39061
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.57640

Cumulative Model Updates: 161,756
Cumulative Timesteps: 1,349,072,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.78788
Policy Entropy: 3.02583
Value Function Loss: 0.00481

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.62329
Value Function Update Magnitude: 0.57907

Collected Steps per Second: 22,912.80027
Overall Steps per Second: 10,765.18692

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.46360
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.64683

Cumulative Model Updates: 161,762
Cumulative Timesteps: 1,349,122,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1349122790...
Checkpoint 1349122790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.28937
Policy Entropy: 3.01781
Value Function Loss: 0.00466

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.62419
Value Function Update Magnitude: 0.58216

Collected Steps per Second: 22,681.48852
Overall Steps per Second: 10,829.44262

Timestep Collection Time: 2.20585
Timestep Consumption Time: 2.41415
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.62000

Cumulative Model Updates: 161,768
Cumulative Timesteps: 1,349,172,822

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.84873
Policy Entropy: 3.02856
Value Function Loss: 0.00432

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.60555
Value Function Update Magnitude: 0.56666

Collected Steps per Second: 22,937.43646
Overall Steps per Second: 10,721.61649

Timestep Collection Time: 2.18054
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.66497

Cumulative Model Updates: 161,774
Cumulative Timesteps: 1,349,222,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1349222838...
Checkpoint 1349222838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.92884
Policy Entropy: 3.03137
Value Function Loss: 0.00436

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.59391
Value Function Update Magnitude: 0.53567

Collected Steps per Second: 23,033.41563
Overall Steps per Second: 10,766.93866

Timestep Collection Time: 2.17119
Timestep Consumption Time: 2.47358
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.64477

Cumulative Model Updates: 161,780
Cumulative Timesteps: 1,349,272,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.92118
Policy Entropy: 3.01618
Value Function Loss: 0.00432

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12239
Policy Update Magnitude: 0.59124
Value Function Update Magnitude: 0.51732

Collected Steps per Second: 23,337.91543
Overall Steps per Second: 10,852.17545

Timestep Collection Time: 2.14312
Timestep Consumption Time: 2.46572
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.60885

Cumulative Model Updates: 161,786
Cumulative Timesteps: 1,349,322,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1349322864...
Checkpoint 1349322864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,288.21099
Policy Entropy: 3.01040
Value Function Loss: 0.00431

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.59952
Value Function Update Magnitude: 0.51896

Collected Steps per Second: 23,146.95927
Overall Steps per Second: 10,802.23048

Timestep Collection Time: 2.16123
Timestep Consumption Time: 2.46985
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.63108

Cumulative Model Updates: 161,792
Cumulative Timesteps: 1,349,372,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,119.98011
Policy Entropy: 3.00821
Value Function Loss: 0.00456

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.59570
Value Function Update Magnitude: 0.53274

Collected Steps per Second: 23,486.78298
Overall Steps per Second: 10,924.62700

Timestep Collection Time: 2.12886
Timestep Consumption Time: 2.44796
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.57682

Cumulative Model Updates: 161,798
Cumulative Timesteps: 1,349,422,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1349422890...
Checkpoint 1349422890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.43098
Policy Entropy: 3.02280
Value Function Loss: 0.00466

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.59844
Value Function Update Magnitude: 0.53877

Collected Steps per Second: 22,827.86800
Overall Steps per Second: 10,658.19525

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.50102
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.69141

Cumulative Model Updates: 161,804
Cumulative Timesteps: 1,349,472,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.81932
Policy Entropy: 3.04092
Value Function Loss: 0.00468

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.59300
Value Function Update Magnitude: 0.51189

Collected Steps per Second: 23,091.91352
Overall Steps per Second: 10,921.58772

Timestep Collection Time: 2.16656
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.58084

Cumulative Model Updates: 161,810
Cumulative Timesteps: 1,349,522,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1349522922...
Checkpoint 1349522922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,346.19863
Policy Entropy: 3.05666
Value Function Loss: 0.00462

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.58842
Value Function Update Magnitude: 0.52761

Collected Steps per Second: 22,594.79937
Overall Steps per Second: 10,642.86709

Timestep Collection Time: 2.21343
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.69911

Cumulative Model Updates: 161,816
Cumulative Timesteps: 1,349,572,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.86533
Policy Entropy: 3.06425
Value Function Loss: 0.00422

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.58319
Value Function Update Magnitude: 0.54121

Collected Steps per Second: 22,781.13652
Overall Steps per Second: 10,675.73921

Timestep Collection Time: 2.19603
Timestep Consumption Time: 2.49011
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.68614

Cumulative Model Updates: 161,822
Cumulative Timesteps: 1,349,622,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1349622962...
Checkpoint 1349622962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.18775
Policy Entropy: 3.06271
Value Function Loss: 0.00438

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.57811
Value Function Update Magnitude: 0.53219

Collected Steps per Second: 22,405.05444
Overall Steps per Second: 10,638.49434

Timestep Collection Time: 2.23164
Timestep Consumption Time: 2.46827
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.69991

Cumulative Model Updates: 161,828
Cumulative Timesteps: 1,349,672,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,243.47592
Policy Entropy: 3.07634
Value Function Loss: 0.00435

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.57814
Value Function Update Magnitude: 0.54161

Collected Steps per Second: 23,028.97179
Overall Steps per Second: 10,675.99944

Timestep Collection Time: 2.17222
Timestep Consumption Time: 2.51343
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.68565

Cumulative Model Updates: 161,834
Cumulative Timesteps: 1,349,722,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1349722986...
Checkpoint 1349722986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,416.53463
Policy Entropy: 3.06790
Value Function Loss: 0.00417

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.57133
Value Function Update Magnitude: 0.53175

Collected Steps per Second: 22,627.23864
Overall Steps per Second: 10,663.88846

Timestep Collection Time: 2.21061
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.69060

Cumulative Model Updates: 161,840
Cumulative Timesteps: 1,349,773,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.81130
Policy Entropy: 3.07697
Value Function Loss: 0.00408

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.56559
Value Function Update Magnitude: 0.53042

Collected Steps per Second: 23,428.15334
Overall Steps per Second: 10,876.47824

Timestep Collection Time: 2.13504
Timestep Consumption Time: 2.46388
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.59892

Cumulative Model Updates: 161,846
Cumulative Timesteps: 1,349,823,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1349823026...
Checkpoint 1349823026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,693.89751
Policy Entropy: 3.05368
Value Function Loss: 0.00430

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.57708
Value Function Update Magnitude: 0.53365

Collected Steps per Second: 22,844.90122
Overall Steps per Second: 10,720.04199

Timestep Collection Time: 2.18981
Timestep Consumption Time: 2.47678
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.66659

Cumulative Model Updates: 161,852
Cumulative Timesteps: 1,349,873,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,313.54709
Policy Entropy: 3.04163
Value Function Loss: 0.00444

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.58451
Value Function Update Magnitude: 0.53116

Collected Steps per Second: 23,254.78866
Overall Steps per Second: 10,838.50008

Timestep Collection Time: 2.15027
Timestep Consumption Time: 2.46329
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.61355

Cumulative Model Updates: 161,858
Cumulative Timesteps: 1,349,923,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1349923056...
Checkpoint 1349923056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,060.44946
Policy Entropy: 3.04104
Value Function Loss: 0.00440

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.58713
Value Function Update Magnitude: 0.54419

Collected Steps per Second: 22,920.04488
Overall Steps per Second: 10,730.54871

Timestep Collection Time: 2.18237
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.66146

Cumulative Model Updates: 161,864
Cumulative Timesteps: 1,349,973,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.96317
Policy Entropy: 3.04581
Value Function Loss: 0.00472

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.59745
Value Function Update Magnitude: 0.55862

Collected Steps per Second: 23,628.46486
Overall Steps per Second: 10,840.57393

Timestep Collection Time: 2.11635
Timestep Consumption Time: 2.49651
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.61286

Cumulative Model Updates: 161,870
Cumulative Timesteps: 1,350,023,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1350023082...
Checkpoint 1350023082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.36856
Policy Entropy: 3.04950
Value Function Loss: 0.00466

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.60090
Value Function Update Magnitude: 0.56120

Collected Steps per Second: 22,967.09320
Overall Steps per Second: 10,767.92270

Timestep Collection Time: 2.17833
Timestep Consumption Time: 2.46787
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.64621

Cumulative Model Updates: 161,876
Cumulative Timesteps: 1,350,073,112

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,330.71841
Policy Entropy: 3.03386
Value Function Loss: 0.00448

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.58945
Value Function Update Magnitude: 0.56357

Collected Steps per Second: 23,091.97585
Overall Steps per Second: 10,781.53422

Timestep Collection Time: 2.16525
Timestep Consumption Time: 2.47230
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.63756

Cumulative Model Updates: 161,882
Cumulative Timesteps: 1,350,123,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1350123112...
Checkpoint 1350123112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,782.49298
Policy Entropy: 3.04528
Value Function Loss: 0.00421

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.58024
Value Function Update Magnitude: 0.54814

Collected Steps per Second: 21,453.94499
Overall Steps per Second: 10,310.74937

Timestep Collection Time: 2.33179
Timestep Consumption Time: 2.52004
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.85183

Cumulative Model Updates: 161,888
Cumulative Timesteps: 1,350,173,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.09625
Policy Entropy: 3.05194
Value Function Loss: 0.00392

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.57208
Value Function Update Magnitude: 0.51601

Collected Steps per Second: 23,000.06645
Overall Steps per Second: 10,800.55753

Timestep Collection Time: 2.17443
Timestep Consumption Time: 2.45607
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.63050

Cumulative Model Updates: 161,894
Cumulative Timesteps: 1,350,223,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1350223150...
Checkpoint 1350223150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,383.96701
Policy Entropy: 3.05072
Value Function Loss: 0.00406

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.49254

Collected Steps per Second: 23,315.61883
Overall Steps per Second: 10,746.82134

Timestep Collection Time: 2.14457
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.65272

Cumulative Model Updates: 161,900
Cumulative Timesteps: 1,350,273,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.83370
Policy Entropy: 3.04812
Value Function Loss: 0.00454

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.58432
Value Function Update Magnitude: 0.53289

Collected Steps per Second: 23,290.04638
Overall Steps per Second: 10,822.81102

Timestep Collection Time: 2.14770
Timestep Consumption Time: 2.47402
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.62172

Cumulative Model Updates: 161,906
Cumulative Timesteps: 1,350,323,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1350323172...
Checkpoint 1350323172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.40516
Policy Entropy: 3.05749
Value Function Loss: 0.00469

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.59747
Value Function Update Magnitude: 0.55760

Collected Steps per Second: 23,180.89403
Overall Steps per Second: 10,987.69761

Timestep Collection Time: 2.15747
Timestep Consumption Time: 2.39417
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.55164

Cumulative Model Updates: 161,912
Cumulative Timesteps: 1,350,373,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,596.77661
Policy Entropy: 3.04579
Value Function Loss: 0.00479

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.59384
Value Function Update Magnitude: 0.56853

Collected Steps per Second: 22,915.54484
Overall Steps per Second: 10,683.17594

Timestep Collection Time: 2.18227
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68100

Cumulative Model Updates: 161,918
Cumulative Timesteps: 1,350,423,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1350423192...
Checkpoint 1350423192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,569.40779
Policy Entropy: 3.05088
Value Function Loss: 0.00452

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.59473
Value Function Update Magnitude: 0.56563

Collected Steps per Second: 23,029.08317
Overall Steps per Second: 10,876.99431

Timestep Collection Time: 2.17204
Timestep Consumption Time: 2.42666
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.59870

Cumulative Model Updates: 161,924
Cumulative Timesteps: 1,350,473,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,195.43554
Policy Entropy: 3.03994
Value Function Loss: 0.00498

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.60509
Value Function Update Magnitude: 0.56492

Collected Steps per Second: 22,649.72737
Overall Steps per Second: 10,685.69605

Timestep Collection Time: 2.20824
Timestep Consumption Time: 2.47241
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.68065

Cumulative Model Updates: 161,930
Cumulative Timesteps: 1,350,523,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1350523228...
Checkpoint 1350523228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.26258
Policy Entropy: 3.03764
Value Function Loss: 0.00487

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.61742
Value Function Update Magnitude: 0.57756

Collected Steps per Second: 22,668.16954
Overall Steps per Second: 10,664.51847

Timestep Collection Time: 2.20662
Timestep Consumption Time: 2.48370
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69032

Cumulative Model Updates: 161,936
Cumulative Timesteps: 1,350,573,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,449.66109
Policy Entropy: 3.02904
Value Function Loss: 0.00507

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.61015
Value Function Update Magnitude: 0.59016

Collected Steps per Second: 23,087.66819
Overall Steps per Second: 10,726.27171

Timestep Collection Time: 2.16635
Timestep Consumption Time: 2.49659
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.66294

Cumulative Model Updates: 161,942
Cumulative Timesteps: 1,350,623,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1350623264...
Checkpoint 1350623264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.78437
Policy Entropy: 3.02203
Value Function Loss: 0.00489

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.60863
Value Function Update Magnitude: 0.59624

Collected Steps per Second: 22,899.67226
Overall Steps per Second: 10,676.18409

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.49998
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.68351

Cumulative Model Updates: 161,948
Cumulative Timesteps: 1,350,673,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.50049
Policy Entropy: 3.01585
Value Function Loss: 0.00493

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.60607
Value Function Update Magnitude: 0.59865

Collected Steps per Second: 23,296.39899
Overall Steps per Second: 10,844.23951

Timestep Collection Time: 2.14634
Timestep Consumption Time: 2.46459
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.61093

Cumulative Model Updates: 161,954
Cumulative Timesteps: 1,350,723,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1350723268...
Checkpoint 1350723268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.70395
Policy Entropy: 3.02070
Value Function Loss: 0.00542

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.61754
Value Function Update Magnitude: 0.61646

Collected Steps per Second: 23,273.20468
Overall Steps per Second: 10,852.48454

Timestep Collection Time: 2.14857
Timestep Consumption Time: 2.45904
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.60761

Cumulative Model Updates: 161,960
Cumulative Timesteps: 1,350,773,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.66912
Policy Entropy: 3.04014
Value Function Loss: 0.00510

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.62028
Value Function Update Magnitude: 0.63040

Collected Steps per Second: 23,563.10534
Overall Steps per Second: 10,968.91954

Timestep Collection Time: 2.12196
Timestep Consumption Time: 2.43637
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.55833

Cumulative Model Updates: 161,966
Cumulative Timesteps: 1,350,823,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1350823272...
Checkpoint 1350823272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.26773
Policy Entropy: 3.04567
Value Function Loss: 0.00484

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.61716
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 23,135.77570
Overall Steps per Second: 10,859.65053

Timestep Collection Time: 2.16150
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.60494

Cumulative Model Updates: 161,972
Cumulative Timesteps: 1,350,873,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.45431
Policy Entropy: 3.04708
Value Function Loss: 0.00445

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.61178
Value Function Update Magnitude: 0.59683

Collected Steps per Second: 22,926.40666
Overall Steps per Second: 10,859.99535

Timestep Collection Time: 2.18098
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.60424

Cumulative Model Updates: 161,978
Cumulative Timesteps: 1,350,923,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1350923282...
Checkpoint 1350923282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,226.25050
Policy Entropy: 3.03674
Value Function Loss: 0.00435

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.60960
Value Function Update Magnitude: 0.58718

Collected Steps per Second: 22,659.08175
Overall Steps per Second: 10,684.35379

Timestep Collection Time: 2.20750
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.68161

Cumulative Model Updates: 161,984
Cumulative Timesteps: 1,350,973,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,493.67457
Policy Entropy: 3.03793
Value Function Loss: 0.00437

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.60550
Value Function Update Magnitude: 0.56039

Collected Steps per Second: 22,868.14774
Overall Steps per Second: 10,834.98172

Timestep Collection Time: 2.18750
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.61690

Cumulative Model Updates: 161,990
Cumulative Timesteps: 1,351,023,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1351023326...
Checkpoint 1351023326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.05382
Policy Entropy: 3.04585
Value Function Loss: 0.00431

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10705
Policy Update Magnitude: 0.58857
Value Function Update Magnitude: 0.55649

Collected Steps per Second: 22,342.32972
Overall Steps per Second: 10,703.50341

Timestep Collection Time: 2.23907
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.67380

Cumulative Model Updates: 161,996
Cumulative Timesteps: 1,351,073,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.48405
Policy Entropy: 3.06313
Value Function Loss: 0.00407

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.57214
Value Function Update Magnitude: 0.55770

Collected Steps per Second: 22,828.17869
Overall Steps per Second: 10,855.34420

Timestep Collection Time: 2.19045
Timestep Consumption Time: 2.41594
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.60639

Cumulative Model Updates: 162,002
Cumulative Timesteps: 1,351,123,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1351123356...
Checkpoint 1351123356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,520.90243
Policy Entropy: 3.05529
Value Function Loss: 0.00404

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.53165

Collected Steps per Second: 22,990.34500
Overall Steps per Second: 10,705.22499

Timestep Collection Time: 2.17604
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.67323

Cumulative Model Updates: 162,008
Cumulative Timesteps: 1,351,173,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.61786
Policy Entropy: 3.05154
Value Function Loss: 0.00437

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.55830

Collected Steps per Second: 23,130.02372
Overall Steps per Second: 10,843.32445

Timestep Collection Time: 2.16290
Timestep Consumption Time: 2.45081
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.61371

Cumulative Model Updates: 162,014
Cumulative Timesteps: 1,351,223,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1351223412...
Checkpoint 1351223412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.74875
Policy Entropy: 3.04478
Value Function Loss: 0.00451

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.59158
Value Function Update Magnitude: 0.59149

Collected Steps per Second: 23,105.20785
Overall Steps per Second: 10,698.58853

Timestep Collection Time: 2.16531
Timestep Consumption Time: 2.51101
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.67632

Cumulative Model Updates: 162,020
Cumulative Timesteps: 1,351,273,442

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,882.21520
Policy Entropy: 3.04893
Value Function Loss: 0.00461

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.60118
Value Function Update Magnitude: 0.56851

Collected Steps per Second: 23,427.35758
Overall Steps per Second: 10,890.88071

Timestep Collection Time: 2.13460
Timestep Consumption Time: 2.45713
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.59173

Cumulative Model Updates: 162,026
Cumulative Timesteps: 1,351,323,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1351323450...
Checkpoint 1351323450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537.68320
Policy Entropy: 3.05377
Value Function Loss: 0.00434

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.58609
Value Function Update Magnitude: 0.54584

Collected Steps per Second: 23,133.85186
Overall Steps per Second: 10,712.69614

Timestep Collection Time: 2.16159
Timestep Consumption Time: 2.50632
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.66792

Cumulative Model Updates: 162,032
Cumulative Timesteps: 1,351,373,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,720.68331
Policy Entropy: 3.04368
Value Function Loss: 0.00396

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.56487
Value Function Update Magnitude: 0.50675

Collected Steps per Second: 22,966.16379
Overall Steps per Second: 10,819.26332

Timestep Collection Time: 2.17816
Timestep Consumption Time: 2.44544
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.62361

Cumulative Model Updates: 162,038
Cumulative Timesteps: 1,351,423,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1351423480...
Checkpoint 1351423480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298.82320
Policy Entropy: 3.04399
Value Function Loss: 0.00364

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.56035
Value Function Update Magnitude: 0.48619

Collected Steps per Second: 22,800.24406
Overall Steps per Second: 10,694.17177

Timestep Collection Time: 2.19305
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.67563

Cumulative Model Updates: 162,044
Cumulative Timesteps: 1,351,473,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,416.91993
Policy Entropy: 3.03789
Value Function Loss: 0.00365

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.56583
Value Function Update Magnitude: 0.49982

Collected Steps per Second: 22,611.22147
Overall Steps per Second: 10,605.47855

Timestep Collection Time: 2.21297
Timestep Consumption Time: 2.50516
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.71813

Cumulative Model Updates: 162,050
Cumulative Timesteps: 1,351,523,520

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1351523520...
Checkpoint 1351523520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.54886
Policy Entropy: 3.03177
Value Function Loss: 0.00389

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.56919
Value Function Update Magnitude: 0.50877

Collected Steps per Second: 22,848.61649
Overall Steps per Second: 10,911.06117

Timestep Collection Time: 2.18884
Timestep Consumption Time: 2.39476
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.58361

Cumulative Model Updates: 162,056
Cumulative Timesteps: 1,351,573,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,814.13896
Policy Entropy: 3.02762
Value Function Loss: 0.00385

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.56376
Value Function Update Magnitude: 0.49522

Collected Steps per Second: 22,710.48226
Overall Steps per Second: 10,645.90468

Timestep Collection Time: 2.20268
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.69890

Cumulative Model Updates: 162,062
Cumulative Timesteps: 1,351,623,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1351623556...
Checkpoint 1351623556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,256.92900
Policy Entropy: 3.02475
Value Function Loss: 0.00399

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.55990
Value Function Update Magnitude: 0.47403

Collected Steps per Second: 22,580.86276
Overall Steps per Second: 10,634.51267

Timestep Collection Time: 2.21480
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.70280

Cumulative Model Updates: 162,068
Cumulative Timesteps: 1,351,673,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,400.05483
Policy Entropy: 3.03490
Value Function Loss: 0.00394

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.57127
Value Function Update Magnitude: 0.49622

Collected Steps per Second: 22,955.99171
Overall Steps per Second: 10,743.40275

Timestep Collection Time: 2.17886
Timestep Consumption Time: 2.47683
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.65569

Cumulative Model Updates: 162,074
Cumulative Timesteps: 1,351,723,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1351723586...
Checkpoint 1351723586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,980.11430
Policy Entropy: 3.04349
Value Function Loss: 0.00405

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.57704
Value Function Update Magnitude: 0.54035

Collected Steps per Second: 23,025.73545
Overall Steps per Second: 10,799.98794

Timestep Collection Time: 2.17148
Timestep Consumption Time: 2.45815
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.62963

Cumulative Model Updates: 162,080
Cumulative Timesteps: 1,351,773,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,462.01109
Policy Entropy: 3.03028
Value Function Loss: 0.00398

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.57472
Value Function Update Magnitude: 0.52930

Collected Steps per Second: 23,329.33022
Overall Steps per Second: 10,721.48926

Timestep Collection Time: 2.14400
Timestep Consumption Time: 2.52121
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.66521

Cumulative Model Updates: 162,086
Cumulative Timesteps: 1,351,823,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1351823604...
Checkpoint 1351823604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.60126
Policy Entropy: 3.03557
Value Function Loss: 0.00406

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.57350
Value Function Update Magnitude: 0.49591

Collected Steps per Second: 23,220.24925
Overall Steps per Second: 10,744.74261

Timestep Collection Time: 2.15467
Timestep Consumption Time: 2.50175
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.65642

Cumulative Model Updates: 162,092
Cumulative Timesteps: 1,351,873,636

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,235.79299
Policy Entropy: 3.05152
Value Function Loss: 0.00422

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.48758

Collected Steps per Second: 23,133.35216
Overall Steps per Second: 10,875.32237

Timestep Collection Time: 2.16259
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60014

Cumulative Model Updates: 162,098
Cumulative Timesteps: 1,351,923,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1351923664...
Checkpoint 1351923664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.31622
Policy Entropy: 3.05832
Value Function Loss: 0.00426

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.57769
Value Function Update Magnitude: 0.50556

Collected Steps per Second: 22,936.21217
Overall Steps per Second: 10,760.91838

Timestep Collection Time: 2.18031
Timestep Consumption Time: 2.46688
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.64719

Cumulative Model Updates: 162,104
Cumulative Timesteps: 1,351,973,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,894.96402
Policy Entropy: 3.06128
Value Function Loss: 0.00397

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.57756
Value Function Update Magnitude: 0.52225

Collected Steps per Second: 22,915.30251
Overall Steps per Second: 10,739.76551

Timestep Collection Time: 2.18221
Timestep Consumption Time: 2.47394
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.65615

Cumulative Model Updates: 162,110
Cumulative Timesteps: 1,352,023,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1352023678...
Checkpoint 1352023678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.11342
Policy Entropy: 3.05762
Value Function Loss: 0.00389

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.57116
Value Function Update Magnitude: 0.49755

Collected Steps per Second: 22,560.35443
Overall Steps per Second: 10,645.20765

Timestep Collection Time: 2.21725
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.69902

Cumulative Model Updates: 162,116
Cumulative Timesteps: 1,352,073,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.97190
Policy Entropy: 3.07414
Value Function Loss: 0.00384

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.55779
Value Function Update Magnitude: 0.47455

Collected Steps per Second: 22,522.42520
Overall Steps per Second: 10,600.89552

Timestep Collection Time: 2.22161
Timestep Consumption Time: 2.49837
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.71998

Cumulative Model Updates: 162,122
Cumulative Timesteps: 1,352,123,736

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1352123736...
Checkpoint 1352123736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,384.00815
Policy Entropy: 3.06371
Value Function Loss: 0.00390

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.55476
Value Function Update Magnitude: 0.46946

Collected Steps per Second: 22,718.44457
Overall Steps per Second: 10,638.75166

Timestep Collection Time: 2.20112
Timestep Consumption Time: 2.49924
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.70036

Cumulative Model Updates: 162,128
Cumulative Timesteps: 1,352,173,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.59487
Policy Entropy: 3.06345
Value Function Loss: 0.00385

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.48537

Collected Steps per Second: 22,833.33587
Overall Steps per Second: 10,743.88782

Timestep Collection Time: 2.19057
Timestep Consumption Time: 2.46492
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.65548

Cumulative Model Updates: 162,134
Cumulative Timesteps: 1,352,223,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1352223760...
Checkpoint 1352223760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,247.51572
Policy Entropy: 3.05096
Value Function Loss: 0.00426

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.47803

Collected Steps per Second: 23,085.34106
Overall Steps per Second: 10,662.42854

Timestep Collection Time: 2.16588
Timestep Consumption Time: 2.52349
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.68936

Cumulative Model Updates: 162,140
Cumulative Timesteps: 1,352,273,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,546.31633
Policy Entropy: 3.07267
Value Function Loss: 0.00409

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.57253
Value Function Update Magnitude: 0.49211

Collected Steps per Second: 23,424.32178
Overall Steps per Second: 10,937.05437

Timestep Collection Time: 2.13462
Timestep Consumption Time: 2.43718
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.57180

Cumulative Model Updates: 162,146
Cumulative Timesteps: 1,352,323,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1352323762...
Checkpoint 1352323762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.48632
Policy Entropy: 3.08038
Value Function Loss: 0.00391

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.54292
Value Function Update Magnitude: 0.49204

Collected Steps per Second: 22,736.27642
Overall Steps per Second: 10,717.94071

Timestep Collection Time: 2.20036
Timestep Consumption Time: 2.46733
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.66769

Cumulative Model Updates: 162,152
Cumulative Timesteps: 1,352,373,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,428.51058
Policy Entropy: 3.06806
Value Function Loss: 0.00372

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.53326
Value Function Update Magnitude: 0.46305

Collected Steps per Second: 23,305.27997
Overall Steps per Second: 10,798.48826

Timestep Collection Time: 2.14655
Timestep Consumption Time: 2.48613
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.63269

Cumulative Model Updates: 162,158
Cumulative Timesteps: 1,352,423,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1352423816...
Checkpoint 1352423816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,788.35203
Policy Entropy: 3.05296
Value Function Loss: 0.00425

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.55492
Value Function Update Magnitude: 0.45822

Collected Steps per Second: 22,993.22925
Overall Steps per Second: 10,673.57220

Timestep Collection Time: 2.17499
Timestep Consumption Time: 2.51042
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.68540

Cumulative Model Updates: 162,164
Cumulative Timesteps: 1,352,473,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.08437
Policy Entropy: 3.03833
Value Function Loss: 0.00430

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.58223
Value Function Update Magnitude: 0.48812

Collected Steps per Second: 23,203.02297
Overall Steps per Second: 10,878.59145

Timestep Collection Time: 2.15549
Timestep Consumption Time: 2.44198
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.59747

Cumulative Model Updates: 162,170
Cumulative Timesteps: 1,352,523,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1352523840...
Checkpoint 1352523840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,810.54114
Policy Entropy: 3.04676
Value Function Loss: 0.00448

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.59390
Value Function Update Magnitude: 0.53052

Collected Steps per Second: 22,740.40106
Overall Steps per Second: 10,623.12186

Timestep Collection Time: 2.19996
Timestep Consumption Time: 2.50939
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.70935

Cumulative Model Updates: 162,176
Cumulative Timesteps: 1,352,573,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.29204
Policy Entropy: 3.05363
Value Function Loss: 0.00427

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.59513
Value Function Update Magnitude: 0.54418

Collected Steps per Second: 22,540.26212
Overall Steps per Second: 10,625.27125

Timestep Collection Time: 2.21879
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.70689

Cumulative Model Updates: 162,182
Cumulative Timesteps: 1,352,623,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1352623880...
Checkpoint 1352623880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,307.05855
Policy Entropy: 3.05352
Value Function Loss: 0.00432

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.59228
Value Function Update Magnitude: 0.54215

Collected Steps per Second: 22,696.98329
Overall Steps per Second: 10,618.52888

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.70950

Cumulative Model Updates: 162,188
Cumulative Timesteps: 1,352,673,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.67731
Policy Entropy: 3.05082
Value Function Loss: 0.00400

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.58030
Value Function Update Magnitude: 0.52866

Collected Steps per Second: 22,906.26790
Overall Steps per Second: 10,721.99076

Timestep Collection Time: 2.18307
Timestep Consumption Time: 2.48080
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.66387

Cumulative Model Updates: 162,194
Cumulative Timesteps: 1,352,723,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1352723894...
Checkpoint 1352723894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.32782
Policy Entropy: 3.05289
Value Function Loss: 0.00371

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.56942
Value Function Update Magnitude: 0.50314

Collected Steps per Second: 23,092.53492
Overall Steps per Second: 10,669.37501

Timestep Collection Time: 2.16650
Timestep Consumption Time: 2.52262
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.68912

Cumulative Model Updates: 162,200
Cumulative Timesteps: 1,352,773,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,032.13109
Policy Entropy: 3.05983
Value Function Loss: 0.00359

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.56010
Value Function Update Magnitude: 0.48509

Collected Steps per Second: 23,270.53542
Overall Steps per Second: 10,876.02976

Timestep Collection Time: 2.14984
Timestep Consumption Time: 2.45000
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.59984

Cumulative Model Updates: 162,206
Cumulative Timesteps: 1,352,823,952

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1352823952...
Checkpoint 1352823952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,010.82314
Policy Entropy: 3.04744
Value Function Loss: 0.00403

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.57810
Value Function Update Magnitude: 0.48686

Collected Steps per Second: 23,121.29004
Overall Steps per Second: 10,820.86489

Timestep Collection Time: 2.16363
Timestep Consumption Time: 2.45947
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.62311

Cumulative Model Updates: 162,212
Cumulative Timesteps: 1,352,873,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,091.01219
Policy Entropy: 3.03558
Value Function Loss: 0.00420

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10686
Policy Update Magnitude: 0.58904
Value Function Update Magnitude: 0.51201

Collected Steps per Second: 23,200.41262
Overall Steps per Second: 10,765.49665

Timestep Collection Time: 2.15539
Timestep Consumption Time: 2.48963
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.64502

Cumulative Model Updates: 162,218
Cumulative Timesteps: 1,352,923,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1352923984...
Checkpoint 1352923984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,590.20399
Policy Entropy: 3.03663
Value Function Loss: 0.00443

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.60075
Value Function Update Magnitude: 0.50788

Collected Steps per Second: 23,397.16598
Overall Steps per Second: 11,012.42139

Timestep Collection Time: 2.13812
Timestep Consumption Time: 2.40457
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.54269

Cumulative Model Updates: 162,224
Cumulative Timesteps: 1,352,974,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.36771
Policy Entropy: 3.03815
Value Function Loss: 0.00434

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.61030
Value Function Update Magnitude: 0.53277

Collected Steps per Second: 22,896.76235
Overall Steps per Second: 10,707.35069

Timestep Collection Time: 2.18380
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.66988

Cumulative Model Updates: 162,230
Cumulative Timesteps: 1,353,024,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1353024012...
Checkpoint 1353024012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.66875
Policy Entropy: 3.03161
Value Function Loss: 0.00427

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.58646
Value Function Update Magnitude: 0.50744

Collected Steps per Second: 22,699.88009
Overall Steps per Second: 10,863.61906

Timestep Collection Time: 2.20398
Timestep Consumption Time: 2.40130
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.60528

Cumulative Model Updates: 162,236
Cumulative Timesteps: 1,353,074,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.90596
Policy Entropy: 3.03080
Value Function Loss: 0.00438

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.57931
Value Function Update Magnitude: 0.49319

Collected Steps per Second: 22,903.54122
Overall Steps per Second: 10,886.86134

Timestep Collection Time: 2.18412
Timestep Consumption Time: 2.41078
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.59490

Cumulative Model Updates: 162,242
Cumulative Timesteps: 1,353,124,066

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1353124066...
Checkpoint 1353124066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.50156
Policy Entropy: 3.04653
Value Function Loss: 0.00423

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.57012
Value Function Update Magnitude: 0.48792

Collected Steps per Second: 22,744.07062
Overall Steps per Second: 10,747.33875

Timestep Collection Time: 2.19846
Timestep Consumption Time: 2.45404
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.65250

Cumulative Model Updates: 162,248
Cumulative Timesteps: 1,353,174,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759.50895
Policy Entropy: 3.04972
Value Function Loss: 0.00454

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10606
Policy Update Magnitude: 0.57736
Value Function Update Magnitude: 0.49326

Collected Steps per Second: 22,730.84799
Overall Steps per Second: 10,660.35450

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.49112
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.69121

Cumulative Model Updates: 162,254
Cumulative Timesteps: 1,353,224,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1353224078...
Checkpoint 1353224078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.24065
Policy Entropy: 3.05193
Value Function Loss: 0.00448

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.58722
Value Function Update Magnitude: 0.51187

Collected Steps per Second: 23,410.04112
Overall Steps per Second: 10,834.78122

Timestep Collection Time: 2.13626
Timestep Consumption Time: 2.47943
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61569

Cumulative Model Updates: 162,260
Cumulative Timesteps: 1,353,274,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,473.03491
Policy Entropy: 3.04376
Value Function Loss: 0.00446

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.58474
Value Function Update Magnitude: 0.51149

Collected Steps per Second: 23,155.40695
Overall Steps per Second: 10,806.43881

Timestep Collection Time: 2.16053
Timestep Consumption Time: 2.46893
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.62946

Cumulative Model Updates: 162,266
Cumulative Timesteps: 1,353,324,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1353324116...
Checkpoint 1353324116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,200.40711
Policy Entropy: 3.05746
Value Function Loss: 0.00410

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.57977
Value Function Update Magnitude: 0.51083

Collected Steps per Second: 23,089.62171
Overall Steps per Second: 10,800.32191

Timestep Collection Time: 2.16565
Timestep Consumption Time: 2.46421
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.62986

Cumulative Model Updates: 162,272
Cumulative Timesteps: 1,353,374,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,957.32930
Policy Entropy: 3.06203
Value Function Loss: 0.00382

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.57330
Value Function Update Magnitude: 0.49186

Collected Steps per Second: 23,054.36665
Overall Steps per Second: 10,857.60091

Timestep Collection Time: 2.16957
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.60673

Cumulative Model Updates: 162,278
Cumulative Timesteps: 1,353,424,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1353424138...
Checkpoint 1353424138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,161.10511
Policy Entropy: 3.07641
Value Function Loss: 0.00373

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.47297

Collected Steps per Second: 23,267.11193
Overall Steps per Second: 10,757.67827

Timestep Collection Time: 2.14939
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.64877

Cumulative Model Updates: 162,284
Cumulative Timesteps: 1,353,474,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,470.20464
Policy Entropy: 3.08487
Value Function Loss: 0.00402

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.46695

Collected Steps per Second: 23,531.51168
Overall Steps per Second: 10,818.59927

Timestep Collection Time: 2.12558
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.62333

Cumulative Model Updates: 162,290
Cumulative Timesteps: 1,353,524,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1353524166...
Checkpoint 1353524166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,434.42199
Policy Entropy: 3.08611
Value Function Loss: 0.00401

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.56238
Value Function Update Magnitude: 0.46662

Collected Steps per Second: 22,720.84427
Overall Steps per Second: 10,657.42881

Timestep Collection Time: 2.20115
Timestep Consumption Time: 2.49154
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.69269

Cumulative Model Updates: 162,296
Cumulative Timesteps: 1,353,574,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,810.26891
Policy Entropy: 3.06940
Value Function Loss: 0.00389

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.56408
Value Function Update Magnitude: 0.46204

Collected Steps per Second: 22,400.15211
Overall Steps per Second: 10,593.86001

Timestep Collection Time: 2.23213
Timestep Consumption Time: 2.48759
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71971

Cumulative Model Updates: 162,302
Cumulative Timesteps: 1,353,624,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1353624178...
Checkpoint 1353624178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,199.83760
Policy Entropy: 3.06516
Value Function Loss: 0.00354

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.55703
Value Function Update Magnitude: 0.45752

Collected Steps per Second: 22,826.46801
Overall Steps per Second: 10,716.23230

Timestep Collection Time: 2.19132
Timestep Consumption Time: 2.47637
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.66769

Cumulative Model Updates: 162,308
Cumulative Timesteps: 1,353,674,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,184.93715
Policy Entropy: 3.04594
Value Function Loss: 0.00375

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.55234
Value Function Update Magnitude: 0.45869

Collected Steps per Second: 22,759.75658
Overall Steps per Second: 10,661.05991

Timestep Collection Time: 2.19704
Timestep Consumption Time: 2.49330
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.69034

Cumulative Model Updates: 162,314
Cumulative Timesteps: 1,353,724,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1353724202...
Checkpoint 1353724202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.08984
Policy Entropy: 3.04089
Value Function Loss: 0.00392

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.45694

Collected Steps per Second: 22,832.76467
Overall Steps per Second: 10,632.50434

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.51363
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.70425

Cumulative Model Updates: 162,320
Cumulative Timesteps: 1,353,774,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.58065
Policy Entropy: 3.02629
Value Function Loss: 0.00396

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.56536
Value Function Update Magnitude: 0.45837

Collected Steps per Second: 23,163.91728
Overall Steps per Second: 10,838.92152

Timestep Collection Time: 2.15905
Timestep Consumption Time: 2.45506
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.61411

Cumulative Model Updates: 162,326
Cumulative Timesteps: 1,353,824,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1353824232...
Checkpoint 1353824232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.84445
Policy Entropy: 3.04043
Value Function Loss: 0.00402

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.56415
Value Function Update Magnitude: 0.46363

Collected Steps per Second: 23,080.73834
Overall Steps per Second: 10,728.41453

Timestep Collection Time: 2.16761
Timestep Consumption Time: 2.49571
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.66332

Cumulative Model Updates: 162,332
Cumulative Timesteps: 1,353,874,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,456.62069
Policy Entropy: 3.05564
Value Function Loss: 0.00418

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.46832

Collected Steps per Second: 23,369.82545
Overall Steps per Second: 10,879.14363

Timestep Collection Time: 2.13977
Timestep Consumption Time: 2.45673
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.59650

Cumulative Model Updates: 162,338
Cumulative Timesteps: 1,353,924,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1353924268...
Checkpoint 1353924268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,385.00746
Policy Entropy: 3.05465
Value Function Loss: 0.00426

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.55925
Value Function Update Magnitude: 0.47238

Collected Steps per Second: 22,895.64059
Overall Steps per Second: 10,650.37463

Timestep Collection Time: 2.18408
Timestep Consumption Time: 2.51115
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.69523

Cumulative Model Updates: 162,344
Cumulative Timesteps: 1,353,974,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,357.51775
Policy Entropy: 3.05981
Value Function Loss: 0.00394

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.47173

Collected Steps per Second: 21,893.67651
Overall Steps per Second: 10,436.22106

Timestep Collection Time: 2.28440
Timestep Consumption Time: 2.50794
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.79235

Cumulative Model Updates: 162,350
Cumulative Timesteps: 1,354,024,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1354024288...
Checkpoint 1354024288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.37641
Policy Entropy: 3.05405
Value Function Loss: 0.00415

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.55980
Value Function Update Magnitude: 0.46549

Collected Steps per Second: 23,074.29934
Overall Steps per Second: 10,694.39027

Timestep Collection Time: 2.16778
Timestep Consumption Time: 2.50944
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.67722

Cumulative Model Updates: 162,356
Cumulative Timesteps: 1,354,074,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.64560
Policy Entropy: 3.04794
Value Function Loss: 0.00425

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.56752
Value Function Update Magnitude: 0.47111

Collected Steps per Second: 22,825.98578
Overall Steps per Second: 10,803.09495

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.43782
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.62830

Cumulative Model Updates: 162,362
Cumulative Timesteps: 1,354,124,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1354124308...
Checkpoint 1354124308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.87629
Policy Entropy: 3.02765
Value Function Loss: 0.00420

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.56479
Value Function Update Magnitude: 0.47076

Collected Steps per Second: 21,918.00746
Overall Steps per Second: 10,709.28220

Timestep Collection Time: 2.28260
Timestep Consumption Time: 2.38905
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.67165

Cumulative Model Updates: 162,368
Cumulative Timesteps: 1,354,174,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,527.16332
Policy Entropy: 3.04470
Value Function Loss: 0.00404

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.57590
Value Function Update Magnitude: 0.46222

Collected Steps per Second: 22,230.59010
Overall Steps per Second: 10,862.41814

Timestep Collection Time: 2.24987
Timestep Consumption Time: 2.35463
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.60450

Cumulative Model Updates: 162,374
Cumulative Timesteps: 1,354,224,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1354224354...
Checkpoint 1354224354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,919.59236
Policy Entropy: 3.04859
Value Function Loss: 0.00391

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.57501
Value Function Update Magnitude: 0.46821

Collected Steps per Second: 22,527.91083
Overall Steps per Second: 10,716.36524

Timestep Collection Time: 2.22036
Timestep Consumption Time: 2.44727
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.66763

Cumulative Model Updates: 162,380
Cumulative Timesteps: 1,354,274,374

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,990.50086
Policy Entropy: 3.04842
Value Function Loss: 0.00381

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.56801
Value Function Update Magnitude: 0.45075

Collected Steps per Second: 22,577.53853
Overall Steps per Second: 10,771.33912

Timestep Collection Time: 2.21565
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.64418

Cumulative Model Updates: 162,386
Cumulative Timesteps: 1,354,324,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1354324398...
Checkpoint 1354324398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,080.62800
Policy Entropy: 3.03463
Value Function Loss: 0.00392

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.56435
Value Function Update Magnitude: 0.43176

Collected Steps per Second: 22,504.66005
Overall Steps per Second: 10,748.36819

Timestep Collection Time: 2.22256
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.65354

Cumulative Model Updates: 162,392
Cumulative Timesteps: 1,354,374,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.00095
Policy Entropy: 3.04007
Value Function Loss: 0.00406

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.43218

Collected Steps per Second: 22,483.29150
Overall Steps per Second: 10,889.00121

Timestep Collection Time: 2.22441
Timestep Consumption Time: 2.36848
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.59289

Cumulative Model Updates: 162,398
Cumulative Timesteps: 1,354,424,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1354424428...
Checkpoint 1354424428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,680.81839
Policy Entropy: 3.03300
Value Function Loss: 0.00409

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.57142
Value Function Update Magnitude: 0.43801

Collected Steps per Second: 22,286.06829
Overall Steps per Second: 10,694.64446

Timestep Collection Time: 2.24418
Timestep Consumption Time: 2.43236
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.67655

Cumulative Model Updates: 162,404
Cumulative Timesteps: 1,354,474,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.36190
Policy Entropy: 3.02259
Value Function Loss: 0.00400

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.43745

Collected Steps per Second: 22,582.47325
Overall Steps per Second: 10,856.96730

Timestep Collection Time: 2.21526
Timestep Consumption Time: 2.39247
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.60773

Cumulative Model Updates: 162,410
Cumulative Timesteps: 1,354,524,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1354524468...
Checkpoint 1354524468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.52369
Policy Entropy: 3.04596
Value Function Loss: 0.00383

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.56552
Value Function Update Magnitude: 0.45199

Collected Steps per Second: 21,953.76673
Overall Steps per Second: 10,663.92404

Timestep Collection Time: 2.27833
Timestep Consumption Time: 2.41206
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.69039

Cumulative Model Updates: 162,416
Cumulative Timesteps: 1,354,574,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,720.75951
Policy Entropy: 3.05007
Value Function Loss: 0.00403

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.57344
Value Function Update Magnitude: 0.48488

Collected Steps per Second: 21,848.41772
Overall Steps per Second: 10,659.27185

Timestep Collection Time: 2.28932
Timestep Consumption Time: 2.40312
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.69244

Cumulative Model Updates: 162,422
Cumulative Timesteps: 1,354,624,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1354624504...
Checkpoint 1354624504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.47230
Policy Entropy: 3.06385
Value Function Loss: 0.00404

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.50914

Collected Steps per Second: 22,132.64893
Overall Steps per Second: 10,597.31710

Timestep Collection Time: 2.26037
Timestep Consumption Time: 2.46045
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.72082

Cumulative Model Updates: 162,428
Cumulative Timesteps: 1,354,674,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.66926
Policy Entropy: 3.05701
Value Function Loss: 0.00425

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.57407
Value Function Update Magnitude: 0.52366

Collected Steps per Second: 22,772.47174
Overall Steps per Second: 10,740.70688

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.46103
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.65798

Cumulative Model Updates: 162,434
Cumulative Timesteps: 1,354,724,562

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1354724562...
Checkpoint 1354724562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,000.60421
Policy Entropy: 3.04688
Value Function Loss: 0.00416

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.57868
Value Function Update Magnitude: 0.51951

Collected Steps per Second: 23,266.61573
Overall Steps per Second: 10,774.69896

Timestep Collection Time: 2.14995
Timestep Consumption Time: 2.49260
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.64254

Cumulative Model Updates: 162,440
Cumulative Timesteps: 1,354,774,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.69978
Policy Entropy: 3.04077
Value Function Loss: 0.00420

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.58352
Value Function Update Magnitude: 0.50203

Collected Steps per Second: 23,235.56712
Overall Steps per Second: 10,777.18641

Timestep Collection Time: 2.15308
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.64203

Cumulative Model Updates: 162,446
Cumulative Timesteps: 1,354,824,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1354824612...
Checkpoint 1354824612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.77194
Policy Entropy: 3.03596
Value Function Loss: 0.00413

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.57688
Value Function Update Magnitude: 0.50217

Collected Steps per Second: 23,345.35970
Overall Steps per Second: 11,023.78055

Timestep Collection Time: 2.14218
Timestep Consumption Time: 2.39437
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.53656

Cumulative Model Updates: 162,452
Cumulative Timesteps: 1,354,874,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.73222
Policy Entropy: 3.03309
Value Function Loss: 0.00427

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11767
Policy Update Magnitude: 0.57414
Value Function Update Magnitude: 0.50243

Collected Steps per Second: 23,319.02117
Overall Steps per Second: 10,955.00438

Timestep Collection Time: 2.14477
Timestep Consumption Time: 2.42063
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.56540

Cumulative Model Updates: 162,458
Cumulative Timesteps: 1,354,924,636

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1354924636...
Checkpoint 1354924636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.71079
Policy Entropy: 3.01871
Value Function Loss: 0.00418

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.58271
Value Function Update Magnitude: 0.51029

Collected Steps per Second: 23,100.53538
Overall Steps per Second: 10,802.77962

Timestep Collection Time: 2.16445
Timestep Consumption Time: 2.46399
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.62844

Cumulative Model Updates: 162,464
Cumulative Timesteps: 1,354,974,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,975.06484
Policy Entropy: 3.01921
Value Function Loss: 0.00440

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.59475
Value Function Update Magnitude: 0.53934

Collected Steps per Second: 22,757.37886
Overall Steps per Second: 10,793.27344

Timestep Collection Time: 2.19753
Timestep Consumption Time: 2.43591
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.63344

Cumulative Model Updates: 162,470
Cumulative Timesteps: 1,355,024,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1355024646...
Checkpoint 1355024646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,919.93788
Policy Entropy: 3.02578
Value Function Loss: 0.00433

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.59182
Value Function Update Magnitude: 0.55541

Collected Steps per Second: 22,774.62964
Overall Steps per Second: 10,746.37372

Timestep Collection Time: 2.19551
Timestep Consumption Time: 2.45741
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.65292

Cumulative Model Updates: 162,476
Cumulative Timesteps: 1,355,074,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,510.89217
Policy Entropy: 3.02888
Value Function Loss: 0.00404

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.59023
Value Function Update Magnitude: 0.55258

Collected Steps per Second: 22,784.91740
Overall Steps per Second: 10,723.65248

Timestep Collection Time: 2.19487
Timestep Consumption Time: 2.46865
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.66352

Cumulative Model Updates: 162,482
Cumulative Timesteps: 1,355,124,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1355124658...
Checkpoint 1355124658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.28860
Policy Entropy: 3.03041
Value Function Loss: 0.00397

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.57930
Value Function Update Magnitude: 0.53084

Collected Steps per Second: 23,018.55952
Overall Steps per Second: 10,691.76525

Timestep Collection Time: 2.17312
Timestep Consumption Time: 2.50544
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.67855

Cumulative Model Updates: 162,488
Cumulative Timesteps: 1,355,174,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.99615
Policy Entropy: 3.02954
Value Function Loss: 0.00384

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.57339
Value Function Update Magnitude: 0.53245

Collected Steps per Second: 23,104.82858
Overall Steps per Second: 10,850.47633

Timestep Collection Time: 2.16431
Timestep Consumption Time: 2.44434
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.60865

Cumulative Model Updates: 162,494
Cumulative Timesteps: 1,355,224,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1355224686...
Checkpoint 1355224686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,081.38949
Policy Entropy: 3.01889
Value Function Loss: 0.00413

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.58598
Value Function Update Magnitude: 0.53984

Collected Steps per Second: 22,895.12772
Overall Steps per Second: 10,708.37750

Timestep Collection Time: 2.18457
Timestep Consumption Time: 2.48617
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.67074

Cumulative Model Updates: 162,500
Cumulative Timesteps: 1,355,274,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.19024
Policy Entropy: 3.01452
Value Function Loss: 0.00435

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.60147
Value Function Update Magnitude: 0.55231

Collected Steps per Second: 23,000.60746
Overall Steps per Second: 10,831.91982

Timestep Collection Time: 2.17429
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.61691

Cumulative Model Updates: 162,506
Cumulative Timesteps: 1,355,324,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1355324712...
Checkpoint 1355324712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.70950
Policy Entropy: 3.01932
Value Function Loss: 0.00412

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.59052
Value Function Update Magnitude: 0.53042

Collected Steps per Second: 23,082.94520
Overall Steps per Second: 10,677.57334

Timestep Collection Time: 2.16688
Timestep Consumption Time: 2.51752
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.68440

Cumulative Model Updates: 162,512
Cumulative Timesteps: 1,355,374,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180.07948
Policy Entropy: 3.03640
Value Function Loss: 0.00401

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.56806
Value Function Update Magnitude: 0.50165

Collected Steps per Second: 23,002.93457
Overall Steps per Second: 10,837.62247

Timestep Collection Time: 2.17381
Timestep Consumption Time: 2.44012
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.61393

Cumulative Model Updates: 162,518
Cumulative Timesteps: 1,355,424,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1355424734...
Checkpoint 1355424734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.49021
Policy Entropy: 3.02569
Value Function Loss: 0.00391

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.49297

Collected Steps per Second: 22,824.21272
Overall Steps per Second: 10,759.09528

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.45746
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.64890

Cumulative Model Updates: 162,524
Cumulative Timesteps: 1,355,474,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,707.78107
Policy Entropy: 3.01934
Value Function Loss: 0.00423

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.58543
Value Function Update Magnitude: 0.51787

Collected Steps per Second: 22,815.77677
Overall Steps per Second: 10,796.43310

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.43979
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.63134

Cumulative Model Updates: 162,530
Cumulative Timesteps: 1,355,524,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1355524754...
Checkpoint 1355524754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.99306
Policy Entropy: 3.01967
Value Function Loss: 0.00427

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.59012
Value Function Update Magnitude: 0.52242

Collected Steps per Second: 22,646.50351
Overall Steps per Second: 10,720.60504

Timestep Collection Time: 2.20820
Timestep Consumption Time: 2.45646
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.66466

Cumulative Model Updates: 162,536
Cumulative Timesteps: 1,355,574,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872.00059
Policy Entropy: 3.03621
Value Function Loss: 0.00447

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.58624
Value Function Update Magnitude: 0.51597

Collected Steps per Second: 22,787.26870
Overall Steps per Second: 10,868.58775

Timestep Collection Time: 2.19526
Timestep Consumption Time: 2.40736
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.60262

Cumulative Model Updates: 162,542
Cumulative Timesteps: 1,355,624,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1355624786...
Checkpoint 1355624786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,685.71107
Policy Entropy: 3.02857
Value Function Loss: 0.00432

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.58753
Value Function Update Magnitude: 0.51251

Collected Steps per Second: 22,551.60610
Overall Steps per Second: 10,765.44691

Timestep Collection Time: 2.21767
Timestep Consumption Time: 2.42793
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.64560

Cumulative Model Updates: 162,548
Cumulative Timesteps: 1,355,674,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,383.77240
Policy Entropy: 3.03664
Value Function Loss: 0.00404

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.58976
Value Function Update Magnitude: 0.51603

Collected Steps per Second: 23,158.07213
Overall Steps per Second: 10,820.86938

Timestep Collection Time: 2.15994
Timestep Consumption Time: 2.46261
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.62255

Cumulative Model Updates: 162,554
Cumulative Timesteps: 1,355,724,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1355724818...
Checkpoint 1355724818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561.06976
Policy Entropy: 3.04523
Value Function Loss: 0.00394

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.58319
Value Function Update Magnitude: 0.49333

Collected Steps per Second: 23,127.84840
Overall Steps per Second: 10,687.01047

Timestep Collection Time: 2.16216
Timestep Consumption Time: 2.51698
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.67914

Cumulative Model Updates: 162,560
Cumulative Timesteps: 1,355,774,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,230.79357
Policy Entropy: 3.06256
Value Function Loss: 0.00429

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.58193
Value Function Update Magnitude: 0.49614

Collected Steps per Second: 23,121.17351
Overall Steps per Second: 10,894.18012

Timestep Collection Time: 2.16313
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.59089

Cumulative Model Updates: 162,566
Cumulative Timesteps: 1,355,824,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1355824838...
Checkpoint 1355824838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,172.92914
Policy Entropy: 3.05375
Value Function Loss: 0.00464

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.58812
Value Function Update Magnitude: 0.52896

Collected Steps per Second: 23,144.50435
Overall Steps per Second: 10,749.93405

Timestep Collection Time: 2.16120
Timestep Consumption Time: 2.49185
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.65305

Cumulative Model Updates: 162,572
Cumulative Timesteps: 1,355,874,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,525.24590
Policy Entropy: 3.05192
Value Function Loss: 0.00463

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.59311
Value Function Update Magnitude: 0.54936

Collected Steps per Second: 22,893.19597
Overall Steps per Second: 10,817.49470

Timestep Collection Time: 2.18414
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.62233

Cumulative Model Updates: 162,578
Cumulative Timesteps: 1,355,924,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1355924860...
Checkpoint 1355924860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,391.28229
Policy Entropy: 3.06092
Value Function Loss: 0.00410

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.58648
Value Function Update Magnitude: 0.54789

Collected Steps per Second: 22,574.64412
Overall Steps per Second: 10,613.96130

Timestep Collection Time: 2.21558
Timestep Consumption Time: 2.49670
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.71228

Cumulative Model Updates: 162,584
Cumulative Timesteps: 1,355,974,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,203.34078
Policy Entropy: 3.05598
Value Function Loss: 0.00394

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.56846

Collected Steps per Second: 22,660.41399
Overall Steps per Second: 10,613.44101

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.71157

Cumulative Model Updates: 162,590
Cumulative Timesteps: 1,356,024,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1356024882...
Checkpoint 1356024882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,037.56690
Policy Entropy: 3.05798
Value Function Loss: 0.00393

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.55274

Collected Steps per Second: 22,863.77335
Overall Steps per Second: 10,903.90023

Timestep Collection Time: 2.18695
Timestep Consumption Time: 2.39875
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.58570

Cumulative Model Updates: 162,596
Cumulative Timesteps: 1,356,074,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.20259
Policy Entropy: 3.03608
Value Function Loss: 0.00385

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.57085
Value Function Update Magnitude: 0.52862

Collected Steps per Second: 22,823.73842
Overall Steps per Second: 10,681.37830

Timestep Collection Time: 2.19105
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.68179

Cumulative Model Updates: 162,602
Cumulative Timesteps: 1,356,124,892

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1356124892...
Checkpoint 1356124892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,971.29533
Policy Entropy: 3.03333
Value Function Loss: 0.00390

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.56999
Value Function Update Magnitude: 0.50379

Collected Steps per Second: 23,112.91562
Overall Steps per Second: 10,876.87252

Timestep Collection Time: 2.16485
Timestep Consumption Time: 2.43537
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60022

Cumulative Model Updates: 162,608
Cumulative Timesteps: 1,356,174,928

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,120.85341
Policy Entropy: 3.03420
Value Function Loss: 0.00381

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.57012
Value Function Update Magnitude: 0.52746

Collected Steps per Second: 22,956.21180
Overall Steps per Second: 10,637.07954

Timestep Collection Time: 2.17919
Timestep Consumption Time: 2.52379
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.70298

Cumulative Model Updates: 162,614
Cumulative Timesteps: 1,356,224,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1356224954...
Checkpoint 1356224954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,452.52697
Policy Entropy: 3.04001
Value Function Loss: 0.00401

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.57741
Value Function Update Magnitude: 0.54766

Collected Steps per Second: 23,297.62745
Overall Steps per Second: 10,940.10079

Timestep Collection Time: 2.14674
Timestep Consumption Time: 2.42488
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.57162

Cumulative Model Updates: 162,620
Cumulative Timesteps: 1,356,274,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843.98862
Policy Entropy: 3.06402
Value Function Loss: 0.00401

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11644
Policy Update Magnitude: 0.57048
Value Function Update Magnitude: 0.52882

Collected Steps per Second: 22,997.29583
Overall Steps per Second: 10,828.36517

Timestep Collection Time: 2.17513
Timestep Consumption Time: 2.44441
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.61953

Cumulative Model Updates: 162,626
Cumulative Timesteps: 1,356,324,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1356324990...
Checkpoint 1356324990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.60656
Policy Entropy: 3.05478
Value Function Loss: 0.00409

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.56661
Value Function Update Magnitude: 0.50588

Collected Steps per Second: 22,886.35191
Overall Steps per Second: 10,698.24853

Timestep Collection Time: 2.18523
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.67478

Cumulative Model Updates: 162,632
Cumulative Timesteps: 1,356,375,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.25723
Policy Entropy: 3.05558
Value Function Loss: 0.00430

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.57310
Value Function Update Magnitude: 0.51673

Collected Steps per Second: 23,117.91072
Overall Steps per Second: 10,863.09139

Timestep Collection Time: 2.16412
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.60550

Cumulative Model Updates: 162,638
Cumulative Timesteps: 1,356,425,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1356425032...
Checkpoint 1356425032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,132.41414
Policy Entropy: 3.04218
Value Function Loss: 0.00449

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.58935
Value Function Update Magnitude: 0.55773

Collected Steps per Second: 22,739.45390
Overall Steps per Second: 10,724.22651

Timestep Collection Time: 2.19900
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.66271

Cumulative Model Updates: 162,644
Cumulative Timesteps: 1,356,475,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.69071
Policy Entropy: 3.04953
Value Function Loss: 0.00454

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.59427
Value Function Update Magnitude: 0.57140

Collected Steps per Second: 22,616.29011
Overall Steps per Second: 10,633.98444

Timestep Collection Time: 2.21097
Timestep Consumption Time: 2.49131
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.70228

Cumulative Model Updates: 162,650
Cumulative Timesteps: 1,356,525,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1356525040...
Checkpoint 1356525040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,214.87008
Policy Entropy: 3.03650
Value Function Loss: 0.00478

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.59832
Value Function Update Magnitude: 0.56656

Collected Steps per Second: 22,591.15602
Overall Steps per Second: 10,677.93490

Timestep Collection Time: 2.21476
Timestep Consumption Time: 2.47098
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.68574

Cumulative Model Updates: 162,656
Cumulative Timesteps: 1,356,575,074

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.09392
Policy Entropy: 3.04373
Value Function Loss: 0.00504

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.59921
Value Function Update Magnitude: 0.60074

Collected Steps per Second: 22,915.55946
Overall Steps per Second: 10,694.06515

Timestep Collection Time: 2.18192
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.67549

Cumulative Model Updates: 162,662
Cumulative Timesteps: 1,356,625,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1356625074...
Checkpoint 1356625074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.74837
Policy Entropy: 3.05055
Value Function Loss: 0.00497

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.60330
Value Function Update Magnitude: 0.58906

Collected Steps per Second: 22,946.23888
Overall Steps per Second: 10,665.85985

Timestep Collection Time: 2.17909
Timestep Consumption Time: 2.50895
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.68804

Cumulative Model Updates: 162,668
Cumulative Timesteps: 1,356,675,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,567.47877
Policy Entropy: 3.05251
Value Function Loss: 0.00481

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.60800
Value Function Update Magnitude: 0.57178

Collected Steps per Second: 23,239.51323
Overall Steps per Second: 10,779.90226

Timestep Collection Time: 2.15185
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.63900

Cumulative Model Updates: 162,674
Cumulative Timesteps: 1,356,725,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1356725084...
Checkpoint 1356725084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.17074
Policy Entropy: 3.04748
Value Function Loss: 0.00448

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.59983
Value Function Update Magnitude: 0.57087

Collected Steps per Second: 23,166.80045
Overall Steps per Second: 10,671.93455

Timestep Collection Time: 2.15878
Timestep Consumption Time: 2.52753
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.68631

Cumulative Model Updates: 162,680
Cumulative Timesteps: 1,356,775,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.09826
Policy Entropy: 3.06473
Value Function Loss: 0.00420

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.59052
Value Function Update Magnitude: 0.55811

Collected Steps per Second: 23,066.35570
Overall Steps per Second: 10,851.39650

Timestep Collection Time: 2.16792
Timestep Consumption Time: 2.44034
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.60825

Cumulative Model Updates: 162,686
Cumulative Timesteps: 1,356,825,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1356825102...
Checkpoint 1356825102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.86043
Policy Entropy: 3.07216
Value Function Loss: 0.00453

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.59432
Value Function Update Magnitude: 0.56364

Collected Steps per Second: 23,139.59635
Overall Steps per Second: 10,697.25303

Timestep Collection Time: 2.16166
Timestep Consumption Time: 2.51430
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.67597

Cumulative Model Updates: 162,692
Cumulative Timesteps: 1,356,875,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109.88233
Policy Entropy: 3.07479
Value Function Loss: 0.00474

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.59685
Value Function Update Magnitude: 0.58256

Collected Steps per Second: 23,302.10155
Overall Steps per Second: 10,919.25420

Timestep Collection Time: 2.14599
Timestep Consumption Time: 2.43363
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.57962

Cumulative Model Updates: 162,698
Cumulative Timesteps: 1,356,925,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1356925128...
Checkpoint 1356925128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.83823
Policy Entropy: 3.08133
Value Function Loss: 0.00453

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.58732
Value Function Update Magnitude: 0.58239

Collected Steps per Second: 22,951.12514
Overall Steps per Second: 10,642.42557

Timestep Collection Time: 2.17889
Timestep Consumption Time: 2.52004
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.69893

Cumulative Model Updates: 162,704
Cumulative Timesteps: 1,356,975,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 972.92000
Policy Entropy: 3.07781
Value Function Loss: 0.00476

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.58953
Value Function Update Magnitude: 0.55966

Collected Steps per Second: 23,022.99331
Overall Steps per Second: 10,912.88930

Timestep Collection Time: 2.17270
Timestep Consumption Time: 2.41106
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.58375

Cumulative Model Updates: 162,710
Cumulative Timesteps: 1,357,025,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1357025158...
Checkpoint 1357025158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.93364
Policy Entropy: 3.08267
Value Function Loss: 0.00450

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.59284
Value Function Update Magnitude: 0.55121

Collected Steps per Second: 22,573.86179
Overall Steps per Second: 10,671.36776

Timestep Collection Time: 2.21495
Timestep Consumption Time: 2.47048
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.68543

Cumulative Model Updates: 162,716
Cumulative Timesteps: 1,357,075,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.91365
Policy Entropy: 3.05981
Value Function Loss: 0.00469

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.59305
Value Function Update Magnitude: 0.54634

Collected Steps per Second: 22,921.76641
Overall Steps per Second: 10,806.46671

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62908

Cumulative Model Updates: 162,722
Cumulative Timesteps: 1,357,125,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1357125182...
Checkpoint 1357125182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,569.40592
Policy Entropy: 3.06956
Value Function Loss: 0.00408

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.58543
Value Function Update Magnitude: 0.53485

Collected Steps per Second: 22,834.94552
Overall Steps per Second: 10,723.61664

Timestep Collection Time: 2.19033
Timestep Consumption Time: 2.47377
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.66410

Cumulative Model Updates: 162,728
Cumulative Timesteps: 1,357,175,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,810.65501
Policy Entropy: 3.06800
Value Function Loss: 0.00416

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.58101
Value Function Update Magnitude: 0.53840

Collected Steps per Second: 22,715.13931
Overall Steps per Second: 10,650.83799

Timestep Collection Time: 2.20241
Timestep Consumption Time: 2.49469
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.69710

Cumulative Model Updates: 162,734
Cumulative Timesteps: 1,357,225,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1357225226...
Checkpoint 1357225226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,864.60517
Policy Entropy: 3.07094
Value Function Loss: 0.00375

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11597
Policy Update Magnitude: 0.56875
Value Function Update Magnitude: 0.54181

Collected Steps per Second: 23,088.42614
Overall Steps per Second: 10,867.63556

Timestep Collection Time: 2.16671
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.60321

Cumulative Model Updates: 162,740
Cumulative Timesteps: 1,357,275,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,046.37139
Policy Entropy: 3.05826
Value Function Loss: 0.00379

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.55355
Value Function Update Magnitude: 0.53477

Collected Steps per Second: 23,188.17739
Overall Steps per Second: 10,892.83205

Timestep Collection Time: 2.15739
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59256

Cumulative Model Updates: 162,746
Cumulative Timesteps: 1,357,325,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1357325278...
Checkpoint 1357325278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,997.48867
Policy Entropy: 3.06876
Value Function Loss: 0.00366

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.55574
Value Function Update Magnitude: 0.50305

Collected Steps per Second: 22,765.48721
Overall Steps per Second: 10,693.96570

Timestep Collection Time: 2.19639
Timestep Consumption Time: 2.47933
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.67572

Cumulative Model Updates: 162,752
Cumulative Timesteps: 1,357,375,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.00010
Policy Entropy: 3.08236
Value Function Loss: 0.00353

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.54275
Value Function Update Magnitude: 0.47151

Collected Steps per Second: 22,806.10769
Overall Steps per Second: 10,812.08399

Timestep Collection Time: 2.19354
Timestep Consumption Time: 2.43332
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62686

Cumulative Model Updates: 162,758
Cumulative Timesteps: 1,357,425,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1357425306...
Checkpoint 1357425306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,122.36391
Policy Entropy: 3.09279
Value Function Loss: 0.00357

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.46584

Collected Steps per Second: 22,830.95020
Overall Steps per Second: 10,737.66671

Timestep Collection Time: 2.19115
Timestep Consumption Time: 2.46778
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.65893

Cumulative Model Updates: 162,764
Cumulative Timesteps: 1,357,475,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,315.06822
Policy Entropy: 3.07126
Value Function Loss: 0.00400

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.48387

Collected Steps per Second: 22,858.34517
Overall Steps per Second: 10,704.23202

Timestep Collection Time: 2.18817
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.67273

Cumulative Model Updates: 162,770
Cumulative Timesteps: 1,357,525,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1357525350...
Checkpoint 1357525350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,096.19222
Policy Entropy: 3.03135
Value Function Loss: 0.00452

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.50548

Collected Steps per Second: 22,548.91846
Overall Steps per Second: 10,827.81979

Timestep Collection Time: 2.21855
Timestep Consumption Time: 2.40158
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.62014

Cumulative Model Updates: 162,776
Cumulative Timesteps: 1,357,575,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,723.91226
Policy Entropy: 3.02363
Value Function Loss: 0.00468

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.59160
Value Function Update Magnitude: 0.52449

Collected Steps per Second: 22,798.37621
Overall Steps per Second: 10,676.63118

Timestep Collection Time: 2.19331
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.68350

Cumulative Model Updates: 162,782
Cumulative Timesteps: 1,357,625,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1357625380...
Checkpoint 1357625380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.61351
Policy Entropy: 3.00892
Value Function Loss: 0.00432

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.59727
Value Function Update Magnitude: 0.52585

Collected Steps per Second: 22,672.80100
Overall Steps per Second: 10,847.22341

Timestep Collection Time: 2.20581
Timestep Consumption Time: 2.40477
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61058

Cumulative Model Updates: 162,788
Cumulative Timesteps: 1,357,675,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.34244
Policy Entropy: 3.03636
Value Function Loss: 0.00400

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.59697
Value Function Update Magnitude: 0.51418

Collected Steps per Second: 23,165.25336
Overall Steps per Second: 10,926.34028

Timestep Collection Time: 2.15970
Timestep Consumption Time: 2.41914
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.57884

Cumulative Model Updates: 162,794
Cumulative Timesteps: 1,357,725,422

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1357725422...
Checkpoint 1357725422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.57721
Policy Entropy: 3.03529
Value Function Loss: 0.00452

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.59846
Value Function Update Magnitude: 0.51089

Collected Steps per Second: 23,206.71825
Overall Steps per Second: 10,700.64782

Timestep Collection Time: 2.15455
Timestep Consumption Time: 2.51807
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.67261

Cumulative Model Updates: 162,800
Cumulative Timesteps: 1,357,775,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872.44794
Policy Entropy: 3.03135
Value Function Loss: 0.00472

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.60125
Value Function Update Magnitude: 0.52267

Collected Steps per Second: 23,211.89493
Overall Steps per Second: 10,897.72492

Timestep Collection Time: 2.15545
Timestep Consumption Time: 2.43560
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.59105

Cumulative Model Updates: 162,806
Cumulative Timesteps: 1,357,825,454

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1357825454...
Checkpoint 1357825454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,181.77711
Policy Entropy: 3.03948
Value Function Loss: 0.00444

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.59667
Value Function Update Magnitude: 0.51747

Collected Steps per Second: 22,498.00937
Overall Steps per Second: 10,567.44126

Timestep Collection Time: 2.22366
Timestep Consumption Time: 2.51050
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.73416

Cumulative Model Updates: 162,812
Cumulative Timesteps: 1,357,875,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.95634
Policy Entropy: 3.04622
Value Function Loss: 0.00411

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.59348
Value Function Update Magnitude: 0.50081

Collected Steps per Second: 23,109.40106
Overall Steps per Second: 10,720.06252

Timestep Collection Time: 2.16414
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.66527

Cumulative Model Updates: 162,818
Cumulative Timesteps: 1,357,925,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1357925494...
Checkpoint 1357925494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,738.31115
Policy Entropy: 3.04152
Value Function Loss: 0.00444

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.60165
Value Function Update Magnitude: 0.51377

Collected Steps per Second: 23,008.39902
Overall Steps per Second: 10,948.75103

Timestep Collection Time: 2.17321
Timestep Consumption Time: 2.39371
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.56691

Cumulative Model Updates: 162,824
Cumulative Timesteps: 1,357,975,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756.76506
Policy Entropy: 3.02322
Value Function Loss: 0.00493

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.61848
Value Function Update Magnitude: 0.56102

Collected Steps per Second: 22,952.76890
Overall Steps per Second: 10,828.80405

Timestep Collection Time: 2.17908
Timestep Consumption Time: 2.43971
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.61879

Cumulative Model Updates: 162,830
Cumulative Timesteps: 1,358,025,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1358025512...
Checkpoint 1358025512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,630.04943
Policy Entropy: 3.03344
Value Function Loss: 0.00466

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.61358
Value Function Update Magnitude: 0.58524

Collected Steps per Second: 22,478.01267
Overall Steps per Second: 10,714.38498

Timestep Collection Time: 2.22600
Timestep Consumption Time: 2.44399
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.66998

Cumulative Model Updates: 162,836
Cumulative Timesteps: 1,358,075,548

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,576.27147
Policy Entropy: 3.04735
Value Function Loss: 0.00425

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.59594
Value Function Update Magnitude: 0.55327

Collected Steps per Second: 23,009.12851
Overall Steps per Second: 10,797.86183

Timestep Collection Time: 2.17314
Timestep Consumption Time: 2.45759
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.63073

Cumulative Model Updates: 162,842
Cumulative Timesteps: 1,358,125,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1358125550...
Checkpoint 1358125550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,517.85116
Policy Entropy: 3.04490
Value Function Loss: 0.00402

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.59265
Value Function Update Magnitude: 0.53246

Collected Steps per Second: 22,427.03981
Overall Steps per Second: 10,712.42580

Timestep Collection Time: 2.22990
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.66841

Cumulative Model Updates: 162,848
Cumulative Timesteps: 1,358,175,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.38865
Policy Entropy: 3.02515
Value Function Loss: 0.00456

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.60081
Value Function Update Magnitude: 0.53807

Collected Steps per Second: 23,415.39928
Overall Steps per Second: 10,855.66309

Timestep Collection Time: 2.13603
Timestep Consumption Time: 2.47133
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.60736

Cumulative Model Updates: 162,854
Cumulative Timesteps: 1,358,225,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1358225576...
Checkpoint 1358225576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.04654
Policy Entropy: 3.01943
Value Function Loss: 0.00482

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.61232
Value Function Update Magnitude: 0.55355

Collected Steps per Second: 23,311.91591
Overall Steps per Second: 10,760.61308

Timestep Collection Time: 2.14551
Timestep Consumption Time: 2.50255
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.64806

Cumulative Model Updates: 162,860
Cumulative Timesteps: 1,358,275,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.11452
Policy Entropy: 3.04374
Value Function Loss: 0.00473

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.60978
Value Function Update Magnitude: 0.56715

Collected Steps per Second: 23,320.83070
Overall Steps per Second: 10,841.25522

Timestep Collection Time: 2.14435
Timestep Consumption Time: 2.46840
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.61275

Cumulative Model Updates: 162,866
Cumulative Timesteps: 1,358,325,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1358325600...
Checkpoint 1358325600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.99128
Policy Entropy: 3.04777
Value Function Loss: 0.00444

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.59208
Value Function Update Magnitude: 0.55860

Collected Steps per Second: 23,066.55555
Overall Steps per Second: 10,691.59433

Timestep Collection Time: 2.16764
Timestep Consumption Time: 2.50893
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.67657

Cumulative Model Updates: 162,872
Cumulative Timesteps: 1,358,375,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.35474
Policy Entropy: 3.05608
Value Function Loss: 0.00450

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.59294
Value Function Update Magnitude: 0.54407

Collected Steps per Second: 23,274.66539
Overall Steps per Second: 10,811.60529

Timestep Collection Time: 2.14912
Timestep Consumption Time: 2.47739
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.62651

Cumulative Model Updates: 162,878
Cumulative Timesteps: 1,358,425,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1358425620...
Checkpoint 1358425620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,382.19569
Policy Entropy: 3.05395
Value Function Loss: 0.00395

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.58394
Value Function Update Magnitude: 0.52412

Collected Steps per Second: 23,101.76174
Overall Steps per Second: 10,699.85299

Timestep Collection Time: 2.16434
Timestep Consumption Time: 2.50862
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.67296

Cumulative Model Updates: 162,884
Cumulative Timesteps: 1,358,475,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.49853
Policy Entropy: 3.04306
Value Function Loss: 0.00441

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.53145

Collected Steps per Second: 23,024.20805
Overall Steps per Second: 10,890.72934

Timestep Collection Time: 2.17276
Timestep Consumption Time: 2.42069
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.59345

Cumulative Model Updates: 162,890
Cumulative Timesteps: 1,358,525,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1358525646...
Checkpoint 1358525646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,998.15199
Policy Entropy: 3.04130
Value Function Loss: 0.00444

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.60012
Value Function Update Magnitude: 0.55651

Collected Steps per Second: 22,553.85894
Overall Steps per Second: 10,637.64176

Timestep Collection Time: 2.21700
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.70048

Cumulative Model Updates: 162,896
Cumulative Timesteps: 1,358,575,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.99259
Policy Entropy: 3.02539
Value Function Loss: 0.00479

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.61542
Value Function Update Magnitude: 0.58005

Collected Steps per Second: 22,844.91352
Overall Steps per Second: 10,787.21682

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.44684
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.63586

Cumulative Model Updates: 162,902
Cumulative Timesteps: 1,358,625,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1358625656...
Checkpoint 1358625656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.59229
Policy Entropy: 3.03687
Value Function Loss: 0.00408

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.60887
Value Function Update Magnitude: 0.56284

Collected Steps per Second: 22,667.25566
Overall Steps per Second: 10,794.07785

Timestep Collection Time: 2.20627
Timestep Consumption Time: 2.42683
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.63310

Cumulative Model Updates: 162,908
Cumulative Timesteps: 1,358,675,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.16641
Policy Entropy: 3.04753
Value Function Loss: 0.00376

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.58673
Value Function Update Magnitude: 0.53138

Collected Steps per Second: 23,315.09863
Overall Steps per Second: 10,820.24524

Timestep Collection Time: 2.14531
Timestep Consumption Time: 2.47733
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62263

Cumulative Model Updates: 162,914
Cumulative Timesteps: 1,358,725,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1358725684...
Checkpoint 1358725684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,131.00321
Policy Entropy: 3.05617
Value Function Loss: 0.00360

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11808
Policy Update Magnitude: 0.57333
Value Function Update Magnitude: 0.49666

Collected Steps per Second: 23,094.56236
Overall Steps per Second: 10,684.20444

Timestep Collection Time: 2.16527
Timestep Consumption Time: 2.51510
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.68037

Cumulative Model Updates: 162,920
Cumulative Timesteps: 1,358,775,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.37075
Policy Entropy: 3.05868
Value Function Loss: 0.00372

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.57295
Value Function Update Magnitude: 0.47698

Collected Steps per Second: 23,125.77400
Overall Steps per Second: 10,859.27061

Timestep Collection Time: 2.16313
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.60657

Cumulative Model Updates: 162,926
Cumulative Timesteps: 1,358,825,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1358825714...
Checkpoint 1358825714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,871.98195
Policy Entropy: 3.05664
Value Function Loss: 0.00397

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.57441
Value Function Update Magnitude: 0.48819

Collected Steps per Second: 23,008.53819
Overall Steps per Second: 10,658.94868

Timestep Collection Time: 2.17371
Timestep Consumption Time: 2.51849
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.69221

Cumulative Model Updates: 162,932
Cumulative Timesteps: 1,358,875,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,751.62520
Policy Entropy: 3.05720
Value Function Loss: 0.00417

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.51237

Collected Steps per Second: 23,272.82201
Overall Steps per Second: 10,897.49298

Timestep Collection Time: 2.14946
Timestep Consumption Time: 2.44095
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.59041

Cumulative Model Updates: 162,938
Cumulative Timesteps: 1,358,925,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1358925752...
Checkpoint 1358925752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.91898
Policy Entropy: 3.04763
Value Function Loss: 0.00429

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.57510
Value Function Update Magnitude: 0.50575

Collected Steps per Second: 23,060.28292
Overall Steps per Second: 10,711.20670

Timestep Collection Time: 2.16936
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.67044

Cumulative Model Updates: 162,944
Cumulative Timesteps: 1,358,975,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,684.35466
Policy Entropy: 3.04344
Value Function Loss: 0.00454

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.59596
Value Function Update Magnitude: 0.55279

Collected Steps per Second: 22,965.24275
Overall Steps per Second: 10,822.33068

Timestep Collection Time: 2.17720
Timestep Consumption Time: 2.44287
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.62008

Cumulative Model Updates: 162,950
Cumulative Timesteps: 1,359,025,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1359025778...
Checkpoint 1359025778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,657.89740
Policy Entropy: 3.04429
Value Function Loss: 0.00439

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.59358
Value Function Update Magnitude: 0.59873

Collected Steps per Second: 22,573.07917
Overall Steps per Second: 10,677.70665

Timestep Collection Time: 2.21556
Timestep Consumption Time: 2.46822
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.68378

Cumulative Model Updates: 162,956
Cumulative Timesteps: 1,359,075,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,189.12071
Policy Entropy: 3.05481
Value Function Loss: 0.00434

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.58376
Value Function Update Magnitude: 0.56543

Collected Steps per Second: 22,998.34614
Overall Steps per Second: 10,865.31580

Timestep Collection Time: 2.17424
Timestep Consumption Time: 2.42792
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.60217

Cumulative Model Updates: 162,962
Cumulative Timesteps: 1,359,125,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1359125794...
Checkpoint 1359125794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.62416
Policy Entropy: 3.05940
Value Function Loss: 0.00459

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.60039
Value Function Update Magnitude: 0.55447

Collected Steps per Second: 22,526.20730
Overall Steps per Second: 10,680.31341

Timestep Collection Time: 2.21999
Timestep Consumption Time: 2.46227
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.68226

Cumulative Model Updates: 162,968
Cumulative Timesteps: 1,359,175,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.38914
Policy Entropy: 3.06309
Value Function Loss: 0.00448

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.59588
Value Function Update Magnitude: 0.55136

Collected Steps per Second: 23,465.16820
Overall Steps per Second: 10,828.29864

Timestep Collection Time: 2.13295
Timestep Consumption Time: 2.48920
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62215

Cumulative Model Updates: 162,974
Cumulative Timesteps: 1,359,225,852

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1359225852...
Checkpoint 1359225852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.76612
Policy Entropy: 3.06237
Value Function Loss: 0.00417

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.58351
Value Function Update Magnitude: 0.52792

Collected Steps per Second: 22,691.91404
Overall Steps per Second: 10,658.50123

Timestep Collection Time: 2.20449
Timestep Consumption Time: 2.48886
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.69334

Cumulative Model Updates: 162,980
Cumulative Timesteps: 1,359,275,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,237.72015
Policy Entropy: 3.06309
Value Function Loss: 0.00434

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.58164
Value Function Update Magnitude: 0.51924

Collected Steps per Second: 23,314.28505
Overall Steps per Second: 10,911.55810

Timestep Collection Time: 2.14572
Timestep Consumption Time: 2.43896
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.58468

Cumulative Model Updates: 162,986
Cumulative Timesteps: 1,359,325,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1359325902...
Checkpoint 1359325902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,338.23713
Policy Entropy: 3.05855
Value Function Loss: 0.00437

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.59700
Value Function Update Magnitude: 0.54070

Collected Steps per Second: 22,881.66442
Overall Steps per Second: 10,708.86412

Timestep Collection Time: 2.18620
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.67127

Cumulative Model Updates: 162,992
Cumulative Timesteps: 1,359,375,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415.61161
Policy Entropy: 3.06253
Value Function Loss: 0.00455

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10997
Policy Update Magnitude: 0.59570
Value Function Update Magnitude: 0.52925

Collected Steps per Second: 23,336.37053
Overall Steps per Second: 10,939.32816

Timestep Collection Time: 2.14386
Timestep Consumption Time: 2.42954
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.57341

Cumulative Model Updates: 162,998
Cumulative Timesteps: 1,359,425,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1359425956...
Checkpoint 1359425956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.32047
Policy Entropy: 3.05652
Value Function Loss: 0.00467

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.58578
Value Function Update Magnitude: 0.48869

Collected Steps per Second: 22,717.22890
Overall Steps per Second: 10,714.86911

Timestep Collection Time: 2.20194
Timestep Consumption Time: 2.46652
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.66847

Cumulative Model Updates: 163,004
Cumulative Timesteps: 1,359,475,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,026.90909
Policy Entropy: 3.05742
Value Function Loss: 0.00441

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.58384
Value Function Update Magnitude: 0.46621

Collected Steps per Second: 22,724.42952
Overall Steps per Second: 10,789.67730

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.43505
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.63647

Cumulative Model Updates: 163,010
Cumulative Timesteps: 1,359,526,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1359526004...
Checkpoint 1359526004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,626.84637
Policy Entropy: 3.06257
Value Function Loss: 0.00392

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.56966
Value Function Update Magnitude: 0.45921

Collected Steps per Second: 22,248.79710
Overall Steps per Second: 10,626.47989

Timestep Collection Time: 2.24740
Timestep Consumption Time: 2.45801
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.70542

Cumulative Model Updates: 163,016
Cumulative Timesteps: 1,359,576,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,806.20433
Policy Entropy: 3.06845
Value Function Loss: 0.00403

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.57206
Value Function Update Magnitude: 0.46804

Collected Steps per Second: 22,645.99626
Overall Steps per Second: 10,680.29587

Timestep Collection Time: 2.20957
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.68508

Cumulative Model Updates: 163,022
Cumulative Timesteps: 1,359,626,044

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1359626044...
Checkpoint 1359626044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164.65570
Policy Entropy: 3.06536
Value Function Loss: 0.00395

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.57894
Value Function Update Magnitude: 0.49314

Collected Steps per Second: 23,234.10622
Overall Steps per Second: 10,918.76094

Timestep Collection Time: 2.15313
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58166

Cumulative Model Updates: 163,028
Cumulative Timesteps: 1,359,676,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,743.10249
Policy Entropy: 3.06228
Value Function Loss: 0.00404

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.58730
Value Function Update Magnitude: 0.49715

Collected Steps per Second: 23,259.49338
Overall Steps per Second: 10,866.58377

Timestep Collection Time: 2.15086
Timestep Consumption Time: 2.45298
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.60384

Cumulative Model Updates: 163,034
Cumulative Timesteps: 1,359,726,098

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1359726098...
Checkpoint 1359726098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,963.52977
Policy Entropy: 3.06696
Value Function Loss: 0.00396

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.57896
Value Function Update Magnitude: 0.49070

Collected Steps per Second: 22,819.06230
Overall Steps per Second: 10,661.10167

Timestep Collection Time: 2.19247
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.69276

Cumulative Model Updates: 163,040
Cumulative Timesteps: 1,359,776,128

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.63773
Policy Entropy: 3.06209
Value Function Loss: 0.00386

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.56871
Value Function Update Magnitude: 0.48838

Collected Steps per Second: 22,199.31781
Overall Steps per Second: 10,489.36127

Timestep Collection Time: 2.25313
Timestep Consumption Time: 2.51532
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.76845

Cumulative Model Updates: 163,046
Cumulative Timesteps: 1,359,826,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1359826146...
Checkpoint 1359826146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.53926
Policy Entropy: 3.04801
Value Function Loss: 0.00401

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.56901
Value Function Update Magnitude: 0.48483

Collected Steps per Second: 22,542.11760
Overall Steps per Second: 10,585.77284

Timestep Collection Time: 2.21834
Timestep Consumption Time: 2.50555
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.72389

Cumulative Model Updates: 163,052
Cumulative Timesteps: 1,359,876,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,271.51006
Policy Entropy: 3.05007
Value Function Loss: 0.00382

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.55877
Value Function Update Magnitude: 0.49646

Collected Steps per Second: 22,821.22878
Overall Steps per Second: 10,872.12242

Timestep Collection Time: 2.19164
Timestep Consumption Time: 2.40875
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.60039

Cumulative Model Updates: 163,058
Cumulative Timesteps: 1,359,926,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1359926168...
Checkpoint 1359926168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.99381
Policy Entropy: 3.03865
Value Function Loss: 0.00393

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.56022
Value Function Update Magnitude: 0.49274

Collected Steps per Second: 22,641.48927
Overall Steps per Second: 10,730.27290

Timestep Collection Time: 2.20860
Timestep Consumption Time: 2.45167
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.66027

Cumulative Model Updates: 163,064
Cumulative Timesteps: 1,359,976,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,888.03444
Policy Entropy: 3.04486
Value Function Loss: 0.00388

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.57482
Value Function Update Magnitude: 0.50017

Collected Steps per Second: 23,290.56396
Overall Steps per Second: 10,887.94029

Timestep Collection Time: 2.14756
Timestep Consumption Time: 2.44633
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.59389

Cumulative Model Updates: 163,070
Cumulative Timesteps: 1,360,026,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1360026192...
Checkpoint 1360026192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.23169
Policy Entropy: 3.02533
Value Function Loss: 0.00464

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.59180
Value Function Update Magnitude: 0.52209

Collected Steps per Second: 22,980.31852
Overall Steps per Second: 10,660.78154

Timestep Collection Time: 2.17665
Timestep Consumption Time: 2.51532
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.69196

Cumulative Model Updates: 163,076
Cumulative Timesteps: 1,360,076,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.30778
Policy Entropy: 3.03445
Value Function Loss: 0.00471

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.59621
Value Function Update Magnitude: 0.54847

Collected Steps per Second: 23,236.76870
Overall Steps per Second: 10,885.08647

Timestep Collection Time: 2.15228
Timestep Consumption Time: 2.44226
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.59454

Cumulative Model Updates: 163,082
Cumulative Timesteps: 1,360,126,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1360126224...
Checkpoint 1360126224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.42631
Policy Entropy: 3.04456
Value Function Loss: 0.00449

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.58599
Value Function Update Magnitude: 0.52359

Collected Steps per Second: 22,913.68703
Overall Steps per Second: 10,772.00086

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.45956
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.64166

Cumulative Model Updates: 163,088
Cumulative Timesteps: 1,360,176,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,586.13013
Policy Entropy: 3.05486
Value Function Loss: 0.00454

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.58891
Value Function Update Magnitude: 0.52243

Collected Steps per Second: 23,278.73446
Overall Steps per Second: 10,761.91928

Timestep Collection Time: 2.14909
Timestep Consumption Time: 2.49953
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.64861

Cumulative Model Updates: 163,094
Cumulative Timesteps: 1,360,226,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1360226252...
Checkpoint 1360226252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.02451
Policy Entropy: 3.05287
Value Function Loss: 0.00442

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.58513
Value Function Update Magnitude: 0.54240

Collected Steps per Second: 22,396.63424
Overall Steps per Second: 10,648.00882

Timestep Collection Time: 2.23275
Timestep Consumption Time: 2.46353
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.69628

Cumulative Model Updates: 163,100
Cumulative Timesteps: 1,360,276,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,747.23081
Policy Entropy: 3.03440
Value Function Loss: 0.00490

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.60061
Value Function Update Magnitude: 0.54734

Collected Steps per Second: 22,994.53641
Overall Steps per Second: 10,864.79597

Timestep Collection Time: 2.17547
Timestep Consumption Time: 2.42875
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.60423

Cumulative Model Updates: 163,106
Cumulative Timesteps: 1,360,326,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1360326282...
Checkpoint 1360326282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911.35900
Policy Entropy: 3.04074
Value Function Loss: 0.00461

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.59717
Value Function Update Magnitude: 0.56442

Collected Steps per Second: 22,606.22488
Overall Steps per Second: 10,688.84826

Timestep Collection Time: 2.21293
Timestep Consumption Time: 2.46727
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.68020

Cumulative Model Updates: 163,112
Cumulative Timesteps: 1,360,376,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,346.18095
Policy Entropy: 3.04622
Value Function Loss: 0.00452

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.58440
Value Function Update Magnitude: 0.56610

Collected Steps per Second: 22,643.97036
Overall Steps per Second: 10,798.12021

Timestep Collection Time: 2.20871
Timestep Consumption Time: 2.42302
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.63173

Cumulative Model Updates: 163,118
Cumulative Timesteps: 1,360,426,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1360426322...
Checkpoint 1360426322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,758.27972
Policy Entropy: 3.06471
Value Function Loss: 0.00426

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.58766
Value Function Update Magnitude: 0.53135

Collected Steps per Second: 22,703.67741
Overall Steps per Second: 10,768.18254

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.44102
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.64331

Cumulative Model Updates: 163,124
Cumulative Timesteps: 1,360,476,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,875.16110
Policy Entropy: 3.06024
Value Function Loss: 0.00429

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.57818
Value Function Update Magnitude: 0.53003

Collected Steps per Second: 23,191.04667
Overall Steps per Second: 10,871.63535

Timestep Collection Time: 2.15695
Timestep Consumption Time: 2.44419
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60115

Cumulative Model Updates: 163,130
Cumulative Timesteps: 1,360,526,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1360526344...
Checkpoint 1360526344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,314.38447
Policy Entropy: 3.05624
Value Function Loss: 0.00407

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.57783
Value Function Update Magnitude: 0.53867

Collected Steps per Second: 22,804.58564
Overall Steps per Second: 10,636.05058

Timestep Collection Time: 2.19351
Timestep Consumption Time: 2.50956
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.70306

Cumulative Model Updates: 163,136
Cumulative Timesteps: 1,360,576,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.91073
Policy Entropy: 3.07045
Value Function Loss: 0.00410

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.53779

Collected Steps per Second: 23,279.90148
Overall Steps per Second: 10,897.60004

Timestep Collection Time: 2.14846
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.58963

Cumulative Model Updates: 163,142
Cumulative Timesteps: 1,360,626,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1360626382...
Checkpoint 1360626382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.70998
Policy Entropy: 3.06108
Value Function Loss: 0.00412

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.57169
Value Function Update Magnitude: 0.52721

Collected Steps per Second: 23,099.14161
Overall Steps per Second: 10,809.89834

Timestep Collection Time: 2.16458
Timestep Consumption Time: 2.46081
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.62539

Cumulative Model Updates: 163,148
Cumulative Timesteps: 1,360,676,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.95221
Policy Entropy: 3.04594
Value Function Loss: 0.00450

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.58543
Value Function Update Magnitude: 0.52091

Collected Steps per Second: 23,410.87466
Overall Steps per Second: 10,756.92198

Timestep Collection Time: 2.13636
Timestep Consumption Time: 2.51311
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.64947

Cumulative Model Updates: 163,154
Cumulative Timesteps: 1,360,726,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1360726396...
Checkpoint 1360726396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,016.76808
Policy Entropy: 3.05422
Value Function Loss: 0.00470

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.59926
Value Function Update Magnitude: 0.54512

Collected Steps per Second: 22,811.10110
Overall Steps per Second: 10,655.77769

Timestep Collection Time: 2.19279
Timestep Consumption Time: 2.50138
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.69417

Cumulative Model Updates: 163,160
Cumulative Timesteps: 1,360,776,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041.42693
Policy Entropy: 3.07326
Value Function Loss: 0.00422

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.58127
Value Function Update Magnitude: 0.54467

Collected Steps per Second: 23,068.90412
Overall Steps per Second: 10,840.07974

Timestep Collection Time: 2.16794
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.61362

Cumulative Model Updates: 163,166
Cumulative Timesteps: 1,360,826,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1360826428...
Checkpoint 1360826428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.48665
Policy Entropy: 3.07771
Value Function Loss: 0.00384

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.56046
Value Function Update Magnitude: 0.52340

Collected Steps per Second: 22,645.32493
Overall Steps per Second: 10,707.81537

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.46231
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.67098

Cumulative Model Updates: 163,172
Cumulative Timesteps: 1,360,876,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,193.72898
Policy Entropy: 3.06433
Value Function Loss: 0.00361

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.55345
Value Function Update Magnitude: 0.48929

Collected Steps per Second: 23,051.16522
Overall Steps per Second: 10,850.75443

Timestep Collection Time: 2.16943
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60871

Cumulative Model Updates: 163,178
Cumulative Timesteps: 1,360,926,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1360926452...
Checkpoint 1360926452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,884.55691
Policy Entropy: 3.04852
Value Function Loss: 0.00392

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.56303
Value Function Update Magnitude: 0.48864

Collected Steps per Second: 22,585.24698
Overall Steps per Second: 10,676.68848

Timestep Collection Time: 2.21525
Timestep Consumption Time: 2.47085
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.68610

Cumulative Model Updates: 163,184
Cumulative Timesteps: 1,360,976,484

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,723.71646
Policy Entropy: 3.04615
Value Function Loss: 0.00406

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.57434
Value Function Update Magnitude: 0.49897

Collected Steps per Second: 23,485.43859
Overall Steps per Second: 10,870.74261

Timestep Collection Time: 2.12932
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.60024

Cumulative Model Updates: 163,190
Cumulative Timesteps: 1,361,026,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1361026492...
Checkpoint 1361026492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,675.30576
Policy Entropy: 3.04886
Value Function Loss: 0.00433

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11382
Policy Update Magnitude: 0.58503
Value Function Update Magnitude: 0.50109

Collected Steps per Second: 22,963.66611
Overall Steps per Second: 10,578.08266

Timestep Collection Time: 2.17857
Timestep Consumption Time: 2.55083
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.72940

Cumulative Model Updates: 163,196
Cumulative Timesteps: 1,361,076,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,859.10700
Policy Entropy: 3.03986
Value Function Loss: 0.00451

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.59137
Value Function Update Magnitude: 0.50285

Collected Steps per Second: 23,372.14911
Overall Steps per Second: 10,928.42487

Timestep Collection Time: 2.14067
Timestep Consumption Time: 2.43749
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.57815

Cumulative Model Updates: 163,202
Cumulative Timesteps: 1,361,126,552

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1361126552...
Checkpoint 1361126552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.45313
Policy Entropy: 3.02580
Value Function Loss: 0.00443

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.58695
Value Function Update Magnitude: 0.49765

Collected Steps per Second: 22,942.11334
Overall Steps per Second: 10,754.13963

Timestep Collection Time: 2.18149
Timestep Consumption Time: 2.47235
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.65384

Cumulative Model Updates: 163,208
Cumulative Timesteps: 1,361,176,600

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,095.49077
Policy Entropy: 3.02347
Value Function Loss: 0.00419

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.57416
Value Function Update Magnitude: 0.49539

Collected Steps per Second: 23,155.72326
Overall Steps per Second: 10,851.33425

Timestep Collection Time: 2.16016
Timestep Consumption Time: 2.44941
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.60957

Cumulative Model Updates: 163,214
Cumulative Timesteps: 1,361,226,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1361226620...
Checkpoint 1361226620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,413.46974
Policy Entropy: 3.03728
Value Function Loss: 0.00420

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.57674
Value Function Update Magnitude: 0.49995

Collected Steps per Second: 22,862.06728
Overall Steps per Second: 10,669.00795

Timestep Collection Time: 2.18712
Timestep Consumption Time: 2.49954
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.68666

Cumulative Model Updates: 163,220
Cumulative Timesteps: 1,361,276,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.89764
Policy Entropy: 3.04078
Value Function Loss: 0.00463

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.58949
Value Function Update Magnitude: 0.51375

Collected Steps per Second: 22,625.13450
Overall Steps per Second: 10,654.96820

Timestep Collection Time: 2.21037
Timestep Consumption Time: 2.48321
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.69359

Cumulative Model Updates: 163,226
Cumulative Timesteps: 1,361,326,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1361326632...
Checkpoint 1361326632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,660.76922
Policy Entropy: 3.05682
Value Function Loss: 0.00467

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.59355
Value Function Update Magnitude: 0.53300

Collected Steps per Second: 22,592.32011
Overall Steps per Second: 10,675.52563

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.68473

Cumulative Model Updates: 163,232
Cumulative Timesteps: 1,361,376,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,851.31229
Policy Entropy: 3.04940
Value Function Loss: 0.00468

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.59070
Value Function Update Magnitude: 0.53333

Collected Steps per Second: 22,642.61362
Overall Steps per Second: 10,679.79784

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.68211

Cumulative Model Updates: 163,238
Cumulative Timesteps: 1,361,426,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1361426648...
Checkpoint 1361426648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,200.57670
Policy Entropy: 3.03462
Value Function Loss: 0.00482

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.60307
Value Function Update Magnitude: 0.55215

Collected Steps per Second: 22,580.27959
Overall Steps per Second: 10,658.97154

Timestep Collection Time: 2.21485
Timestep Consumption Time: 2.47716
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.69201

Cumulative Model Updates: 163,244
Cumulative Timesteps: 1,361,476,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.54398
Policy Entropy: 3.00926
Value Function Loss: 0.00476

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.60968
Value Function Update Magnitude: 0.56647

Collected Steps per Second: 23,037.50678
Overall Steps per Second: 10,843.43169

Timestep Collection Time: 2.17124
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61293

Cumulative Model Updates: 163,250
Cumulative Timesteps: 1,361,526,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1361526680...
Checkpoint 1361526680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,982.00822
Policy Entropy: 3.00101
Value Function Loss: 0.00481

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.60707
Value Function Update Magnitude: 0.56111

Collected Steps per Second: 22,969.48144
Overall Steps per Second: 10,709.93329

Timestep Collection Time: 2.17689
Timestep Consumption Time: 2.49186
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.66875

Cumulative Model Updates: 163,256
Cumulative Timesteps: 1,361,576,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,429.72849
Policy Entropy: 3.00770
Value Function Loss: 0.00446

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.59656
Value Function Update Magnitude: 0.54653

Collected Steps per Second: 23,175.01935
Overall Steps per Second: 10,862.47788

Timestep Collection Time: 2.15827
Timestep Consumption Time: 2.44639
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.60466

Cumulative Model Updates: 163,262
Cumulative Timesteps: 1,361,626,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1361626700...
Checkpoint 1361626700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.91465
Policy Entropy: 3.00521
Value Function Loss: 0.00466

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.59714
Value Function Update Magnitude: 0.54968

Collected Steps per Second: 22,886.68779
Overall Steps per Second: 10,652.88231

Timestep Collection Time: 2.18607
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.69657

Cumulative Model Updates: 163,268
Cumulative Timesteps: 1,361,676,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,656.54277
Policy Entropy: 3.00176
Value Function Loss: 0.00450

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.60917
Value Function Update Magnitude: 0.55970

Collected Steps per Second: 22,185.54702
Overall Steps per Second: 10,640.34450

Timestep Collection Time: 2.25390
Timestep Consumption Time: 2.44557
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.69947

Cumulative Model Updates: 163,274
Cumulative Timesteps: 1,361,726,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1361726736...
Checkpoint 1361726736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,894.59406
Policy Entropy: 3.00016
Value Function Loss: 0.00457

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.61018
Value Function Update Magnitude: 0.56686

Collected Steps per Second: 22,489.60513
Overall Steps per Second: 10,897.55734

Timestep Collection Time: 2.22369
Timestep Consumption Time: 2.36541
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.58910

Cumulative Model Updates: 163,280
Cumulative Timesteps: 1,361,776,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.29583
Policy Entropy: 3.00559
Value Function Loss: 0.00451

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.60185
Value Function Update Magnitude: 0.55564

Collected Steps per Second: 22,618.51579
Overall Steps per Second: 10,915.86432

Timestep Collection Time: 2.21137
Timestep Consumption Time: 2.37076
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.58214

Cumulative Model Updates: 163,286
Cumulative Timesteps: 1,361,826,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1361826764...
Checkpoint 1361826764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.49649
Policy Entropy: 3.03173
Value Function Loss: 0.00396

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.57811
Value Function Update Magnitude: 0.54155

Collected Steps per Second: 21,890.87449
Overall Steps per Second: 10,662.62810

Timestep Collection Time: 2.28543
Timestep Consumption Time: 2.40666
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.69209

Cumulative Model Updates: 163,292
Cumulative Timesteps: 1,361,876,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,651.36107
Policy Entropy: 3.03764
Value Function Loss: 0.00358

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.51513

Collected Steps per Second: 21,993.49608
Overall Steps per Second: 10,800.99316

Timestep Collection Time: 2.27349
Timestep Consumption Time: 2.35590
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.62939

Cumulative Model Updates: 163,298
Cumulative Timesteps: 1,361,926,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1361926796...
Checkpoint 1361926796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,788.08880
Policy Entropy: 3.05588
Value Function Loss: 0.00333

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.49127

Collected Steps per Second: 21,680.87539
Overall Steps per Second: 10,752.73532

Timestep Collection Time: 2.30766
Timestep Consumption Time: 2.34530
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.65296

Cumulative Model Updates: 163,304
Cumulative Timesteps: 1,361,976,828

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.34086
Policy Entropy: 3.04699
Value Function Loss: 0.00374

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.55257
Value Function Update Magnitude: 0.48446

Collected Steps per Second: 22,583.63686
Overall Steps per Second: 10,774.34696

Timestep Collection Time: 2.21506
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.64288

Cumulative Model Updates: 163,310
Cumulative Timesteps: 1,362,026,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1362026852...
Checkpoint 1362026852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.43338
Policy Entropy: 3.04671
Value Function Loss: 0.00410

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.56826
Value Function Update Magnitude: 0.48707

Collected Steps per Second: 23,007.61905
Overall Steps per Second: 10,747.43552

Timestep Collection Time: 2.17337
Timestep Consumption Time: 2.47928
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.65264

Cumulative Model Updates: 163,316
Cumulative Timesteps: 1,362,076,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,900.34332
Policy Entropy: 3.05169
Value Function Loss: 0.00436

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.57357
Value Function Update Magnitude: 0.51283

Collected Steps per Second: 23,352.66753
Overall Steps per Second: 10,903.07054

Timestep Collection Time: 2.14203
Timestep Consumption Time: 2.44586
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.58788

Cumulative Model Updates: 163,322
Cumulative Timesteps: 1,362,126,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1362126878...
Checkpoint 1362126878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,216.44541
Policy Entropy: 3.05118
Value Function Loss: 0.00432

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.57926
Value Function Update Magnitude: 0.51107

Collected Steps per Second: 22,973.85001
Overall Steps per Second: 10,749.56337

Timestep Collection Time: 2.17717
Timestep Consumption Time: 2.47586
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.65303

Cumulative Model Updates: 163,328
Cumulative Timesteps: 1,362,176,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.07889
Policy Entropy: 3.06875
Value Function Loss: 0.00398

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.56632
Value Function Update Magnitude: 0.50834

Collected Steps per Second: 23,098.00117
Overall Steps per Second: 10,833.29399

Timestep Collection Time: 2.16590
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.61799

Cumulative Model Updates: 163,334
Cumulative Timesteps: 1,362,226,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1362226924...
Checkpoint 1362226924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.36830
Policy Entropy: 3.06631
Value Function Loss: 0.00380

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.55402
Value Function Update Magnitude: 0.49470

Collected Steps per Second: 22,913.27975
Overall Steps per Second: 10,674.95072

Timestep Collection Time: 2.18266
Timestep Consumption Time: 2.50232
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.68499

Cumulative Model Updates: 163,340
Cumulative Timesteps: 1,362,276,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,641.69302
Policy Entropy: 3.05551
Value Function Loss: 0.00373

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.54952
Value Function Update Magnitude: 0.47300

Collected Steps per Second: 23,440.62894
Overall Steps per Second: 10,877.47692

Timestep Collection Time: 2.13356
Timestep Consumption Time: 2.46420
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.59776

Cumulative Model Updates: 163,346
Cumulative Timesteps: 1,362,326,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1362326948...
Checkpoint 1362326948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.84907
Policy Entropy: 3.02880
Value Function Loss: 0.00420

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.56572
Value Function Update Magnitude: 0.45383

Collected Steps per Second: 22,552.77095
Overall Steps per Second: 10,642.96325

Timestep Collection Time: 2.21782
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.69963

Cumulative Model Updates: 163,352
Cumulative Timesteps: 1,362,376,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.33332
Policy Entropy: 3.01457
Value Function Loss: 0.00434

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.57910
Value Function Update Magnitude: 0.47426

Collected Steps per Second: 22,800.37929
Overall Steps per Second: 10,787.37390

Timestep Collection Time: 2.19356
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.63635

Cumulative Model Updates: 163,358
Cumulative Timesteps: 1,362,426,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1362426980...
Checkpoint 1362426980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,617.84426
Policy Entropy: 3.01801
Value Function Loss: 0.00430

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.57643
Value Function Update Magnitude: 0.49905

Collected Steps per Second: 22,456.52029
Overall Steps per Second: 10,726.06603

Timestep Collection Time: 2.22750
Timestep Consumption Time: 2.43609
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.66359

Cumulative Model Updates: 163,364
Cumulative Timesteps: 1,362,477,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,619.23150
Policy Entropy: 3.02123
Value Function Loss: 0.00390

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.57500
Value Function Update Magnitude: 0.50347

Collected Steps per Second: 22,956.57974
Overall Steps per Second: 10,845.57622

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.43215
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61017

Cumulative Model Updates: 163,370
Cumulative Timesteps: 1,362,527,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1362527002...
Checkpoint 1362527002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,957.23539
Policy Entropy: 3.03523
Value Function Loss: 0.00414

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.58225
Value Function Update Magnitude: 0.51576

Collected Steps per Second: 22,652.76907
Overall Steps per Second: 10,679.36444

Timestep Collection Time: 2.20785
Timestep Consumption Time: 2.47538
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.68324

Cumulative Model Updates: 163,376
Cumulative Timesteps: 1,362,577,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.31655
Policy Entropy: 3.04119
Value Function Loss: 0.00411

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.58421
Value Function Update Magnitude: 0.50798

Collected Steps per Second: 23,326.09756
Overall Steps per Second: 10,928.58123

Timestep Collection Time: 2.14361
Timestep Consumption Time: 2.43173
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.57534

Cumulative Model Updates: 163,382
Cumulative Timesteps: 1,362,627,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1362627018...
Checkpoint 1362627018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,167.70272
Policy Entropy: 3.04942
Value Function Loss: 0.00437

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.58185
Value Function Update Magnitude: 0.50625

Collected Steps per Second: 23,003.70795
Overall Steps per Second: 10,672.49635

Timestep Collection Time: 2.17452
Timestep Consumption Time: 2.51248
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.68700

Cumulative Model Updates: 163,388
Cumulative Timesteps: 1,362,677,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,782.44784
Policy Entropy: 3.04131
Value Function Loss: 0.00471

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.58648
Value Function Update Magnitude: 0.50717

Collected Steps per Second: 23,301.78896
Overall Steps per Second: 10,920.02069

Timestep Collection Time: 2.14662
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.58058

Cumulative Model Updates: 163,394
Cumulative Timesteps: 1,362,727,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1362727060...
Checkpoint 1362727060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159.00917
Policy Entropy: 3.04112
Value Function Loss: 0.00497

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.59779
Value Function Update Magnitude: 0.51192

Collected Steps per Second: 22,987.00341
Overall Steps per Second: 10,786.89304

Timestep Collection Time: 2.17593
Timestep Consumption Time: 2.46100
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.63692

Cumulative Model Updates: 163,400
Cumulative Timesteps: 1,362,777,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.29373
Policy Entropy: 3.03945
Value Function Loss: 0.00507

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.16048
Policy Update Magnitude: 0.60491
Value Function Update Magnitude: 0.53687

Collected Steps per Second: 23,503.27821
Overall Steps per Second: 10,891.53144

Timestep Collection Time: 2.12753
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.59109

Cumulative Model Updates: 163,406
Cumulative Timesteps: 1,362,827,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1362827082...
Checkpoint 1362827082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,816.37646
Policy Entropy: 3.02645
Value Function Loss: 0.00466

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.60352
Value Function Update Magnitude: 0.56624

Collected Steps per Second: 22,582.38246
Overall Steps per Second: 10,631.09099

Timestep Collection Time: 2.21553
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.70620

Cumulative Model Updates: 163,412
Cumulative Timesteps: 1,362,877,114

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,239.85179
Policy Entropy: 3.03065
Value Function Loss: 0.00461

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.61249
Value Function Update Magnitude: 0.56441

Collected Steps per Second: 22,955.89571
Overall Steps per Second: 10,767.29070

Timestep Collection Time: 2.17809
Timestep Consumption Time: 2.46560
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.64369

Cumulative Model Updates: 163,418
Cumulative Timesteps: 1,362,927,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1362927114...
Checkpoint 1362927114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,381.87528
Policy Entropy: 3.00728
Value Function Loss: 0.00445

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.62067
Value Function Update Magnitude: 0.53003

Collected Steps per Second: 22,406.09675
Overall Steps per Second: 10,666.09758

Timestep Collection Time: 2.23243
Timestep Consumption Time: 2.45720
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.68963

Cumulative Model Updates: 163,424
Cumulative Timesteps: 1,362,977,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.76755
Policy Entropy: 2.99546
Value Function Loss: 0.00463

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.60962
Value Function Update Magnitude: 0.51020

Collected Steps per Second: 22,666.73390
Overall Steps per Second: 10,774.25264

Timestep Collection Time: 2.20711
Timestep Consumption Time: 2.43618
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.64329

Cumulative Model Updates: 163,430
Cumulative Timesteps: 1,363,027,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1363027162...
Checkpoint 1363027162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,104.92728
Policy Entropy: 2.99179
Value Function Loss: 0.00457

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.60321
Value Function Update Magnitude: 0.50566

Collected Steps per Second: 22,393.00571
Overall Steps per Second: 10,661.90678

Timestep Collection Time: 2.23382
Timestep Consumption Time: 2.45783
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.69166

Cumulative Model Updates: 163,436
Cumulative Timesteps: 1,363,077,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,711.42595
Policy Entropy: 3.01201
Value Function Loss: 0.00457

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.59794
Value Function Update Magnitude: 0.51613

Collected Steps per Second: 23,446.66655
Overall Steps per Second: 10,975.99446

Timestep Collection Time: 2.13258
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.55558

Cumulative Model Updates: 163,442
Cumulative Timesteps: 1,363,127,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1363127186...
Checkpoint 1363127186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640.76279
Policy Entropy: 3.00684
Value Function Loss: 0.00463

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.61211
Value Function Update Magnitude: 0.53493

Collected Steps per Second: 22,906.88499
Overall Steps per Second: 10,764.51614

Timestep Collection Time: 2.18310
Timestep Consumption Time: 2.46253
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.64563

Cumulative Model Updates: 163,448
Cumulative Timesteps: 1,363,177,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,332.57081
Policy Entropy: 3.00166
Value Function Loss: 0.00427

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.60129
Value Function Update Magnitude: 0.53287

Collected Steps per Second: 23,265.66020
Overall Steps per Second: 10,781.35684

Timestep Collection Time: 2.14909
Timestep Consumption Time: 2.48855
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.63764

Cumulative Model Updates: 163,454
Cumulative Timesteps: 1,363,227,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1363227194...
Checkpoint 1363227194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,471.39646
Policy Entropy: 2.99962
Value Function Loss: 0.00433

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11400
Policy Update Magnitude: 0.59411
Value Function Update Magnitude: 0.51637

Collected Steps per Second: 23,040.55340
Overall Steps per Second: 10,695.41036

Timestep Collection Time: 2.17095
Timestep Consumption Time: 2.50582
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.67677

Cumulative Model Updates: 163,460
Cumulative Timesteps: 1,363,277,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,973.40644
Policy Entropy: 2.99457
Value Function Loss: 0.00452

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.60905
Value Function Update Magnitude: 0.52843

Collected Steps per Second: 23,352.65128
Overall Steps per Second: 10,888.98606

Timestep Collection Time: 2.14126
Timestep Consumption Time: 2.45091
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.59216

Cumulative Model Updates: 163,466
Cumulative Timesteps: 1,363,327,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1363327218...
Checkpoint 1363327218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,039.66957
Policy Entropy: 2.99211
Value Function Loss: 0.00457

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.61525
Value Function Update Magnitude: 0.55368

Collected Steps per Second: 23,010.52498
Overall Steps per Second: 10,651.57627

Timestep Collection Time: 2.17448
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.69752

Cumulative Model Updates: 163,472
Cumulative Timesteps: 1,363,377,254

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.02479
Policy Entropy: 2.99352
Value Function Loss: 0.00442

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.60412
Value Function Update Magnitude: 0.54766

Collected Steps per Second: 22,295.96155
Overall Steps per Second: 10,599.64079

Timestep Collection Time: 2.24310
Timestep Consumption Time: 2.47518
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.71827

Cumulative Model Updates: 163,478
Cumulative Timesteps: 1,363,427,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1363427266...
Checkpoint 1363427266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,965.83387
Policy Entropy: 3.01948
Value Function Loss: 0.00388

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.59211
Value Function Update Magnitude: 0.51280

Collected Steps per Second: 22,589.99542
Overall Steps per Second: 10,616.32359

Timestep Collection Time: 2.21363
Timestep Consumption Time: 2.49666
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.71029

Cumulative Model Updates: 163,484
Cumulative Timesteps: 1,363,477,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.39660
Policy Entropy: 3.02220
Value Function Loss: 0.00364

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.48637

Collected Steps per Second: 22,936.69133
Overall Steps per Second: 10,800.68921

Timestep Collection Time: 2.18157
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.63285

Cumulative Model Updates: 163,490
Cumulative Timesteps: 1,363,527,310

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1363527310...
Checkpoint 1363527310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,878.52485
Policy Entropy: 3.02637
Value Function Loss: 0.00353

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.56784
Value Function Update Magnitude: 0.48070

Collected Steps per Second: 22,330.71501
Overall Steps per Second: 10,643.21374

Timestep Collection Time: 2.23925
Timestep Consumption Time: 2.45896
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.69821

Cumulative Model Updates: 163,496
Cumulative Timesteps: 1,363,577,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,499.17317
Policy Entropy: 3.03292
Value Function Loss: 0.00369

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.56617
Value Function Update Magnitude: 0.48397

Collected Steps per Second: 23,314.77094
Overall Steps per Second: 10,791.99161

Timestep Collection Time: 2.14559
Timestep Consumption Time: 2.48970
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.63529

Cumulative Model Updates: 163,502
Cumulative Timesteps: 1,363,627,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1363627338...
Checkpoint 1363627338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,918.31287
Policy Entropy: 3.03535
Value Function Loss: 0.00426

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.57891
Value Function Update Magnitude: 0.49055

Collected Steps per Second: 21,893.99041
Overall Steps per Second: 10,675.93360

Timestep Collection Time: 2.28410
Timestep Consumption Time: 2.40008
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.68418

Cumulative Model Updates: 163,508
Cumulative Timesteps: 1,363,677,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,973.06643
Policy Entropy: 3.03523
Value Function Loss: 0.00449

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.59170
Value Function Update Magnitude: 0.51271

Collected Steps per Second: 23,022.24175
Overall Steps per Second: 10,761.69382

Timestep Collection Time: 2.17286
Timestep Consumption Time: 2.47548
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.64834

Cumulative Model Updates: 163,514
Cumulative Timesteps: 1,363,727,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1363727370...
Checkpoint 1363727370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.07554
Policy Entropy: 3.02344
Value Function Loss: 0.00479

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.59590
Value Function Update Magnitude: 0.52309

Collected Steps per Second: 22,658.09575
Overall Steps per Second: 10,776.37138

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.43423
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.64201

Cumulative Model Updates: 163,520
Cumulative Timesteps: 1,363,777,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792.76765
Policy Entropy: 3.02125
Value Function Loss: 0.00456

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.60372
Value Function Update Magnitude: 0.53303

Collected Steps per Second: 22,641.33827
Overall Steps per Second: 10,505.26334

Timestep Collection Time: 2.20906
Timestep Consumption Time: 2.55199
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.76104

Cumulative Model Updates: 163,526
Cumulative Timesteps: 1,363,827,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1363827410...
Checkpoint 1363827410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,906.17635
Policy Entropy: 3.03611
Value Function Loss: 0.00437

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.59706
Value Function Update Magnitude: 0.53790

Collected Steps per Second: 23,013.20475
Overall Steps per Second: 10,628.50064

Timestep Collection Time: 2.17301
Timestep Consumption Time: 2.53207
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.70509

Cumulative Model Updates: 163,532
Cumulative Timesteps: 1,363,877,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,102.01424
Policy Entropy: 3.03718
Value Function Loss: 0.00382

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.58335
Value Function Update Magnitude: 0.52957

Collected Steps per Second: 23,375.41584
Overall Steps per Second: 10,949.17224

Timestep Collection Time: 2.14003
Timestep Consumption Time: 2.42872
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.56875

Cumulative Model Updates: 163,538
Cumulative Timesteps: 1,363,927,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1363927442...
Checkpoint 1363927442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,516.31324
Policy Entropy: 3.02871
Value Function Loss: 0.00382

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.58087
Value Function Update Magnitude: 0.51049

Collected Steps per Second: 22,871.54168
Overall Steps per Second: 10,669.81388

Timestep Collection Time: 2.18621
Timestep Consumption Time: 2.50009
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.68630

Cumulative Model Updates: 163,544
Cumulative Timesteps: 1,363,977,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,951.59372
Policy Entropy: 3.01657
Value Function Loss: 0.00403

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.59101
Value Function Update Magnitude: 0.51771

Collected Steps per Second: 23,347.64891
Overall Steps per Second: 10,841.96270

Timestep Collection Time: 2.14189
Timestep Consumption Time: 2.47056
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.61245

Cumulative Model Updates: 163,550
Cumulative Timesteps: 1,364,027,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1364027452...
Checkpoint 1364027452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.83322
Policy Entropy: 3.01125
Value Function Loss: 0.00444

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10686
Policy Update Magnitude: 0.59991
Value Function Update Magnitude: 0.52599

Collected Steps per Second: 23,067.61877
Overall Steps per Second: 10,686.92535

Timestep Collection Time: 2.16806
Timestep Consumption Time: 2.51168
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.67974

Cumulative Model Updates: 163,556
Cumulative Timesteps: 1,364,077,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.24869
Policy Entropy: 3.00861
Value Function Loss: 0.00449

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.60275
Value Function Update Magnitude: 0.52539

Collected Steps per Second: 23,504.06701
Overall Steps per Second: 10,906.03707

Timestep Collection Time: 2.12746
Timestep Consumption Time: 2.45752
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.58498

Cumulative Model Updates: 163,562
Cumulative Timesteps: 1,364,127,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1364127468...
Checkpoint 1364127468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.85856
Policy Entropy: 3.00920
Value Function Loss: 0.00424

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 0.59975
Value Function Update Magnitude: 0.52140

Collected Steps per Second: 20,572.60048
Overall Steps per Second: 10,172.55934

Timestep Collection Time: 2.43158
Timestep Consumption Time: 2.48596
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.91754

Cumulative Model Updates: 163,568
Cumulative Timesteps: 1,364,177,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,607.88975
Policy Entropy: 2.99267
Value Function Loss: 0.00425

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.59743
Value Function Update Magnitude: 0.51707

Collected Steps per Second: 21,872.06838
Overall Steps per Second: 10,467.74817

Timestep Collection Time: 2.28703
Timestep Consumption Time: 2.49165
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.77868

Cumulative Model Updates: 163,574
Cumulative Timesteps: 1,364,227,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1364227514...
Checkpoint 1364227514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,549.02083
Policy Entropy: 2.98521
Value Function Loss: 0.00447

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.61310
Value Function Update Magnitude: 0.49969

Collected Steps per Second: 22,574.46067
Overall Steps per Second: 10,636.08093

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.48698
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.70267

Cumulative Model Updates: 163,580
Cumulative Timesteps: 1,364,277,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.51544
Policy Entropy: 2.98461
Value Function Loss: 0.00482

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.61292
Value Function Update Magnitude: 0.50990

Collected Steps per Second: 22,663.21560
Overall Steps per Second: 10,606.07044

Timestep Collection Time: 2.20666
Timestep Consumption Time: 2.50856
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.71522

Cumulative Model Updates: 163,586
Cumulative Timesteps: 1,364,327,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1364327542...
Checkpoint 1364327542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,214.47082
Policy Entropy: 3.01146
Value Function Loss: 0.00458

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.60796
Value Function Update Magnitude: 0.51744

Collected Steps per Second: 22,538.66721
Overall Steps per Second: 10,578.80135

Timestep Collection Time: 2.21965
Timestep Consumption Time: 2.50943
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.72908

Cumulative Model Updates: 163,592
Cumulative Timesteps: 1,364,377,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.69543
Policy Entropy: 3.02357
Value Function Loss: 0.00431

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.59710
Value Function Update Magnitude: 0.51083

Collected Steps per Second: 23,569.37770
Overall Steps per Second: 10,812.46026

Timestep Collection Time: 2.12216
Timestep Consumption Time: 2.50380
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.62596

Cumulative Model Updates: 163,598
Cumulative Timesteps: 1,364,427,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1364427588...
Checkpoint 1364427588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.36513
Policy Entropy: 3.02573
Value Function Loss: 0.00437

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.59364
Value Function Update Magnitude: 0.51072

Collected Steps per Second: 23,063.84765
Overall Steps per Second: 10,672.40370

Timestep Collection Time: 2.16789
Timestep Consumption Time: 2.51709
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.68498

Cumulative Model Updates: 163,604
Cumulative Timesteps: 1,364,477,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.83913
Policy Entropy: 3.00745
Value Function Loss: 0.00441

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.60258
Value Function Update Magnitude: 0.51445

Collected Steps per Second: 23,385.49350
Overall Steps per Second: 10,964.76803

Timestep Collection Time: 2.13842
Timestep Consumption Time: 2.42237
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.56079

Cumulative Model Updates: 163,610
Cumulative Timesteps: 1,364,527,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1364527596...
Checkpoint 1364527596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.93044
Policy Entropy: 3.01010
Value Function Loss: 0.00442

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.60931
Value Function Update Magnitude: 0.52409

Collected Steps per Second: 23,094.20718
Overall Steps per Second: 10,775.64495

Timestep Collection Time: 2.16522
Timestep Consumption Time: 2.47525
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.64046

Cumulative Model Updates: 163,616
Cumulative Timesteps: 1,364,577,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.39620
Policy Entropy: 3.01989
Value Function Loss: 0.00424

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.60586
Value Function Update Magnitude: 0.52102

Collected Steps per Second: 23,397.24761
Overall Steps per Second: 10,704.79062

Timestep Collection Time: 2.13786
Timestep Consumption Time: 2.53482
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.67267

Cumulative Model Updates: 163,622
Cumulative Timesteps: 1,364,627,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1364627620...
Checkpoint 1364627620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,097.31922
Policy Entropy: 3.04655
Value Function Loss: 0.00436

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.59869
Value Function Update Magnitude: 0.51645

Collected Steps per Second: 23,199.98190
Overall Steps per Second: 10,747.07279

Timestep Collection Time: 2.15647
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.65522

Cumulative Model Updates: 163,628
Cumulative Timesteps: 1,364,677,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.99346
Policy Entropy: 3.05780
Value Function Loss: 0.00434

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.59550
Value Function Update Magnitude: 0.50407

Collected Steps per Second: 22,819.22940
Overall Steps per Second: 10,827.27591

Timestep Collection Time: 2.19236
Timestep Consumption Time: 2.42819
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.62055

Cumulative Model Updates: 163,634
Cumulative Timesteps: 1,364,727,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1364727678...
Checkpoint 1364727678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.04512
Policy Entropy: 3.05325
Value Function Loss: 0.00438

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.59750
Value Function Update Magnitude: 0.49842

Collected Steps per Second: 22,492.98005
Overall Steps per Second: 10,592.41334

Timestep Collection Time: 2.22416
Timestep Consumption Time: 2.49884
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.72300

Cumulative Model Updates: 163,640
Cumulative Timesteps: 1,364,777,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.44254
Policy Entropy: 3.04305
Value Function Loss: 0.00423

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.59778
Value Function Update Magnitude: 0.49382

Collected Steps per Second: 22,597.17204
Overall Steps per Second: 10,592.35524

Timestep Collection Time: 2.21329
Timestep Consumption Time: 2.50842
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.72171

Cumulative Model Updates: 163,646
Cumulative Timesteps: 1,364,827,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1364827720...
Checkpoint 1364827720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,702.27112
Policy Entropy: 3.03035
Value Function Loss: 0.00436

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.59695
Value Function Update Magnitude: 0.50474

Collected Steps per Second: 22,481.46713
Overall Steps per Second: 10,563.66184

Timestep Collection Time: 2.22414
Timestep Consumption Time: 2.50925
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.73340

Cumulative Model Updates: 163,652
Cumulative Timesteps: 1,364,877,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.11140
Policy Entropy: 3.01275
Value Function Loss: 0.00442

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.60182
Value Function Update Magnitude: 0.51417

Collected Steps per Second: 23,277.47088
Overall Steps per Second: 10,841.05918

Timestep Collection Time: 2.14894
Timestep Consumption Time: 2.46518
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.61412

Cumulative Model Updates: 163,658
Cumulative Timesteps: 1,364,927,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1364927744...
Checkpoint 1364927744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,989.84663
Policy Entropy: 3.01351
Value Function Loss: 0.00469

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10800
Policy Update Magnitude: 0.59863
Value Function Update Magnitude: 0.51428

Collected Steps per Second: 22,982.82496
Overall Steps per Second: 10,681.39246

Timestep Collection Time: 2.17632
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.68272

Cumulative Model Updates: 163,664
Cumulative Timesteps: 1,364,977,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,236.60381
Policy Entropy: 3.02553
Value Function Loss: 0.00484

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.59171
Value Function Update Magnitude: 0.51807

Collected Steps per Second: 23,221.35752
Overall Steps per Second: 10,866.91522

Timestep Collection Time: 2.15405
Timestep Consumption Time: 2.44891
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.60296

Cumulative Model Updates: 163,670
Cumulative Timesteps: 1,365,027,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1365027782...
Checkpoint 1365027782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,738.13640
Policy Entropy: 3.03986
Value Function Loss: 0.00476

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11928
Policy Update Magnitude: 0.59515
Value Function Update Magnitude: 0.53959

Collected Steps per Second: 23,055.81544
Overall Steps per Second: 10,687.07743

Timestep Collection Time: 2.16874
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.67873

Cumulative Model Updates: 163,676
Cumulative Timesteps: 1,365,077,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.49387
Policy Entropy: 3.03281
Value Function Loss: 0.00473

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.60359
Value Function Update Magnitude: 0.56028

Collected Steps per Second: 23,191.80912
Overall Steps per Second: 10,850.33904

Timestep Collection Time: 2.15714
Timestep Consumption Time: 2.45359
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.61073

Cumulative Model Updates: 163,682
Cumulative Timesteps: 1,365,127,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1365127812...
Checkpoint 1365127812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,854.90695
Policy Entropy: 3.04312
Value Function Loss: 0.00469

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.61106
Value Function Update Magnitude: 0.58512

Collected Steps per Second: 23,157.79393
Overall Steps per Second: 10,712.52655

Timestep Collection Time: 2.15936
Timestep Consumption Time: 2.50863
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.66799

Cumulative Model Updates: 163,688
Cumulative Timesteps: 1,365,177,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.31824
Policy Entropy: 3.04128
Value Function Loss: 0.00465

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.60848
Value Function Update Magnitude: 0.58233

Collected Steps per Second: 22,941.28541
Overall Steps per Second: 10,924.92071

Timestep Collection Time: 2.18044
Timestep Consumption Time: 2.39827
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.57871

Cumulative Model Updates: 163,694
Cumulative Timesteps: 1,365,227,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1365227840...
Checkpoint 1365227840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.39187
Policy Entropy: 3.03688
Value Function Loss: 0.00470

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.60145
Value Function Update Magnitude: 0.57940

Collected Steps per Second: 22,648.72148
Overall Steps per Second: 10,582.19928

Timestep Collection Time: 2.20878
Timestep Consumption Time: 2.51859
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.72737

Cumulative Model Updates: 163,700
Cumulative Timesteps: 1,365,277,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.58788
Policy Entropy: 3.04118
Value Function Loss: 0.00459

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.59463
Value Function Update Magnitude: 0.57799

Collected Steps per Second: 22,669.15580
Overall Steps per Second: 10,620.07972

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.50382
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71070

Cumulative Model Updates: 163,706
Cumulative Timesteps: 1,365,327,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1365327894...
Checkpoint 1365327894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.33793
Policy Entropy: 3.04039
Value Function Loss: 0.00461

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.59241
Value Function Update Magnitude: 0.55205

Collected Steps per Second: 22,766.94551
Overall Steps per Second: 10,886.15690

Timestep Collection Time: 2.19661
Timestep Consumption Time: 2.39730
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.59391

Cumulative Model Updates: 163,712
Cumulative Timesteps: 1,365,377,904

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.84802
Policy Entropy: 3.04657
Value Function Loss: 0.00470

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.59493
Value Function Update Magnitude: 0.53078

Collected Steps per Second: 23,170.85641
Overall Steps per Second: 10,578.62856

Timestep Collection Time: 2.15831
Timestep Consumption Time: 2.56914
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.72746

Cumulative Model Updates: 163,718
Cumulative Timesteps: 1,365,427,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1365427914...
Checkpoint 1365427914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.82078
Policy Entropy: 3.01595
Value Function Loss: 0.00483

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.60471
Value Function Update Magnitude: 0.56380

Collected Steps per Second: 23,245.19962
Overall Steps per Second: 10,950.03462

Timestep Collection Time: 2.15133
Timestep Consumption Time: 2.41560
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.56693

Cumulative Model Updates: 163,724
Cumulative Timesteps: 1,365,477,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.84513
Policy Entropy: 3.01353
Value Function Loss: 0.00485

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.61626
Value Function Update Magnitude: 0.59387

Collected Steps per Second: 22,989.26004
Overall Steps per Second: 10,912.25358

Timestep Collection Time: 2.17606
Timestep Consumption Time: 2.40833
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.58439

Cumulative Model Updates: 163,730
Cumulative Timesteps: 1,365,527,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1365527948...
Checkpoint 1365527948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,965.98930
Policy Entropy: 3.01214
Value Function Loss: 0.00431

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.60263
Value Function Update Magnitude: 0.59789

Collected Steps per Second: 22,446.97618
Overall Steps per Second: 10,649.06933

Timestep Collection Time: 2.22854
Timestep Consumption Time: 2.46896
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.69750

Cumulative Model Updates: 163,736
Cumulative Timesteps: 1,365,577,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,280.62657
Policy Entropy: 3.02667
Value Function Loss: 0.00417

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.59303
Value Function Update Magnitude: 0.57501

Collected Steps per Second: 22,973.74166
Overall Steps per Second: 10,678.11587

Timestep Collection Time: 2.17692
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.68360

Cumulative Model Updates: 163,742
Cumulative Timesteps: 1,365,627,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1365627984...
Checkpoint 1365627984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.13678
Policy Entropy: 3.01967
Value Function Loss: 0.00423

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.59874
Value Function Update Magnitude: 0.56172

Collected Steps per Second: 23,148.03994
Overall Steps per Second: 10,983.47277

Timestep Collection Time: 2.16061
Timestep Consumption Time: 2.39295
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.55357

Cumulative Model Updates: 163,748
Cumulative Timesteps: 1,365,677,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,811.56704
Policy Entropy: 3.01337
Value Function Loss: 0.00480

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.60926
Value Function Update Magnitude: 0.57332

Collected Steps per Second: 22,569.78938
Overall Steps per Second: 10,645.95638

Timestep Collection Time: 2.21562
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.69718

Cumulative Model Updates: 163,754
Cumulative Timesteps: 1,365,728,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1365728004...
Checkpoint 1365728004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,684.34173
Policy Entropy: 3.01025
Value Function Loss: 0.00458

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.60746
Value Function Update Magnitude: 0.58607

Collected Steps per Second: 22,774.98237
Overall Steps per Second: 10,928.20066

Timestep Collection Time: 2.19662
Timestep Consumption Time: 2.38126
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.57788

Cumulative Model Updates: 163,760
Cumulative Timesteps: 1,365,778,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.57976
Policy Entropy: 3.00809
Value Function Loss: 0.00481

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11554
Policy Update Magnitude: 0.59781
Value Function Update Magnitude: 0.55375

Collected Steps per Second: 23,060.27024
Overall Steps per Second: 10,863.77859

Timestep Collection Time: 2.16849
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.60300

Cumulative Model Updates: 163,766
Cumulative Timesteps: 1,365,828,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1365828038...
Checkpoint 1365828038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.88744
Policy Entropy: 3.00978
Value Function Loss: 0.00515

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.60107
Value Function Update Magnitude: 0.55221

Collected Steps per Second: 23,166.11115
Overall Steps per Second: 10,707.09193

Timestep Collection Time: 2.15902
Timestep Consumption Time: 2.51228
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.67130

Cumulative Model Updates: 163,772
Cumulative Timesteps: 1,365,878,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.84584
Policy Entropy: 3.00003
Value Function Loss: 0.00479

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.59742
Value Function Update Magnitude: 0.55861

Collected Steps per Second: 22,995.21052
Overall Steps per Second: 10,786.40076

Timestep Collection Time: 2.17550
Timestep Consumption Time: 2.46238
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.63788

Cumulative Model Updates: 163,778
Cumulative Timesteps: 1,365,928,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1365928080...
Checkpoint 1365928080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.53252
Policy Entropy: 2.99363
Value Function Loss: 0.00453

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.59639
Value Function Update Magnitude: 0.52371

Collected Steps per Second: 22,946.98173
Overall Steps per Second: 10,768.70506

Timestep Collection Time: 2.17894
Timestep Consumption Time: 2.46415
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.64308

Cumulative Model Updates: 163,784
Cumulative Timesteps: 1,365,978,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,343.21959
Policy Entropy: 2.99795
Value Function Loss: 0.00434

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.60024
Value Function Update Magnitude: 0.52074

Collected Steps per Second: 23,275.11499
Overall Steps per Second: 10,825.98397

Timestep Collection Time: 2.14942
Timestep Consumption Time: 2.47168
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.62110

Cumulative Model Updates: 163,790
Cumulative Timesteps: 1,366,028,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1366028108...
Checkpoint 1366028108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.63733
Policy Entropy: 2.99635
Value Function Loss: 0.00460

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.61366
Value Function Update Magnitude: 0.55245

Collected Steps per Second: 23,083.31517
Overall Steps per Second: 10,692.59264

Timestep Collection Time: 2.16650
Timestep Consumption Time: 2.51057
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.67707

Cumulative Model Updates: 163,796
Cumulative Timesteps: 1,366,078,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.43270
Policy Entropy: 3.01457
Value Function Loss: 0.00438

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.61051
Value Function Update Magnitude: 0.56257

Collected Steps per Second: 23,356.29523
Overall Steps per Second: 10,821.42146

Timestep Collection Time: 2.14084
Timestep Consumption Time: 2.47981
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.62065

Cumulative Model Updates: 163,802
Cumulative Timesteps: 1,366,128,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1366128120...
Checkpoint 1366128120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,859.85371
Policy Entropy: 3.02163
Value Function Loss: 0.00422

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.59362
Value Function Update Magnitude: 0.53855

Collected Steps per Second: 22,648.76573
Overall Steps per Second: 10,679.50233

Timestep Collection Time: 2.20904
Timestep Consumption Time: 2.47582
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.68486

Cumulative Model Updates: 163,808
Cumulative Timesteps: 1,366,178,152

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,972.70973
Policy Entropy: 3.05222
Value Function Loss: 0.00395

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 0.57866
Value Function Update Magnitude: 0.51971

Collected Steps per Second: 22,912.92534
Overall Steps per Second: 10,813.56730

Timestep Collection Time: 2.18244
Timestep Consumption Time: 2.44194
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.62438

Cumulative Model Updates: 163,814
Cumulative Timesteps: 1,366,228,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1366228158...
Checkpoint 1366228158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,180.82093
Policy Entropy: 3.07025
Value Function Loss: 0.00376

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.56389
Value Function Update Magnitude: 0.51126

Collected Steps per Second: 22,598.90070
Overall Steps per Second: 10,680.60387

Timestep Collection Time: 2.21259
Timestep Consumption Time: 2.46898
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.68157

Cumulative Model Updates: 163,820
Cumulative Timesteps: 1,366,278,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,124.73987
Policy Entropy: 3.05228
Value Function Loss: 0.00409

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.56267
Value Function Update Magnitude: 0.48291

Collected Steps per Second: 23,194.43315
Overall Steps per Second: 10,833.35476

Timestep Collection Time: 2.15578
Timestep Consumption Time: 2.45978
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.61556

Cumulative Model Updates: 163,826
Cumulative Timesteps: 1,366,328,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1366328162...
Checkpoint 1366328162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.73146
Policy Entropy: 3.02774
Value Function Loss: 0.00434

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.57570
Value Function Update Magnitude: 0.48655

Collected Steps per Second: 23,052.12325
Overall Steps per Second: 10,741.32224

Timestep Collection Time: 2.16900
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.65492

Cumulative Model Updates: 163,832
Cumulative Timesteps: 1,366,378,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,682.52864
Policy Entropy: 3.01214
Value Function Loss: 0.00460

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.58447
Value Function Update Magnitude: 0.50653

Collected Steps per Second: 23,088.21070
Overall Steps per Second: 10,849.71483

Timestep Collection Time: 2.16595
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.60915

Cumulative Model Updates: 163,838
Cumulative Timesteps: 1,366,428,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1366428170...
Checkpoint 1366428170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.10547
Policy Entropy: 3.01702
Value Function Loss: 0.00457

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.58124
Value Function Update Magnitude: 0.50909

Collected Steps per Second: 23,013.14234
Overall Steps per Second: 10,682.77820

Timestep Collection Time: 2.17311
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.68137

Cumulative Model Updates: 163,844
Cumulative Timesteps: 1,366,478,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.33033
Policy Entropy: 3.04012
Value Function Loss: 0.00445

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.57010
Value Function Update Magnitude: 0.50353

Collected Steps per Second: 23,065.81246
Overall Steps per Second: 10,866.43810

Timestep Collection Time: 2.16840
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60280

Cumulative Model Updates: 163,850
Cumulative Timesteps: 1,366,528,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1366528196...
Checkpoint 1366528196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,587.16480
Policy Entropy: 3.04296
Value Function Loss: 0.00423

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.56811
Value Function Update Magnitude: 0.48358

Collected Steps per Second: 23,028.76948
Overall Steps per Second: 10,702.93852

Timestep Collection Time: 2.17154
Timestep Consumption Time: 2.50082
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.67236

Cumulative Model Updates: 163,856
Cumulative Timesteps: 1,366,578,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,984.40493
Policy Entropy: 3.05301
Value Function Loss: 0.00432

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.58106
Value Function Update Magnitude: 0.48487

Collected Steps per Second: 22,920.37831
Overall Steps per Second: 10,827.25249

Timestep Collection Time: 2.18181
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.61872

Cumulative Model Updates: 163,862
Cumulative Timesteps: 1,366,628,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1366628212...
Checkpoint 1366628212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.26130
Policy Entropy: 3.03964
Value Function Loss: 0.00441

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.58484
Value Function Update Magnitude: 0.50179

Collected Steps per Second: 22,813.22192
Overall Steps per Second: 10,694.06592

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.67586

Cumulative Model Updates: 163,868
Cumulative Timesteps: 1,366,678,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,214.94109
Policy Entropy: 3.04574
Value Function Loss: 0.00437

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.57892
Value Function Update Magnitude: 0.50319

Collected Steps per Second: 22,609.25754
Overall Steps per Second: 10,618.35773

Timestep Collection Time: 2.21148
Timestep Consumption Time: 2.49734
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.70883

Cumulative Model Updates: 163,874
Cumulative Timesteps: 1,366,728,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1366728216...
Checkpoint 1366728216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,442.42409
Policy Entropy: 3.05123
Value Function Loss: 0.00467

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.58836
Value Function Update Magnitude: 0.51565

Collected Steps per Second: 22,708.52664
Overall Steps per Second: 10,880.10561

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.39449
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.59701

Cumulative Model Updates: 163,880
Cumulative Timesteps: 1,366,778,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.60967
Policy Entropy: 3.05399
Value Function Loss: 0.00487

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.60182
Value Function Update Magnitude: 0.54184

Collected Steps per Second: 22,845.99354
Overall Steps per Second: 10,739.93000

Timestep Collection Time: 2.18971
Timestep Consumption Time: 2.46824
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.65794

Cumulative Model Updates: 163,886
Cumulative Timesteps: 1,366,828,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1366828258...
Checkpoint 1366828258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,537.13133
Policy Entropy: 3.07142
Value Function Loss: 0.00484

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11165
Policy Update Magnitude: 0.59650
Value Function Update Magnitude: 0.56516

Collected Steps per Second: 23,318.80663
Overall Steps per Second: 10,836.52369

Timestep Collection Time: 2.14488
Timestep Consumption Time: 2.47062
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61550

Cumulative Model Updates: 163,892
Cumulative Timesteps: 1,366,878,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.85283
Policy Entropy: 3.07618
Value Function Loss: 0.00456

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.58988
Value Function Update Magnitude: 0.57270

Collected Steps per Second: 22,912.78466
Overall Steps per Second: 10,840.73491

Timestep Collection Time: 2.18245
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61279

Cumulative Model Updates: 163,898
Cumulative Timesteps: 1,366,928,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1366928280...
Checkpoint 1366928280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,703.20134
Policy Entropy: 3.08007
Value Function Loss: 0.00427

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.57596
Value Function Update Magnitude: 0.53947

Collected Steps per Second: 23,037.19994
Overall Steps per Second: 10,728.90987

Timestep Collection Time: 2.17170
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.66310

Cumulative Model Updates: 163,904
Cumulative Timesteps: 1,366,978,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.66575
Policy Entropy: 3.07157
Value Function Loss: 0.00414

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.52103

Collected Steps per Second: 23,295.80668
Overall Steps per Second: 10,932.28917

Timestep Collection Time: 2.14743
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.57599

Cumulative Model Updates: 163,910
Cumulative Timesteps: 1,367,028,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1367028336...
Checkpoint 1367028336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.66531
Policy Entropy: 3.06145
Value Function Loss: 0.00423

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.51378

Collected Steps per Second: 23,483.56216
Overall Steps per Second: 10,845.02253

Timestep Collection Time: 2.13034
Timestep Consumption Time: 2.48265
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.61299

Cumulative Model Updates: 163,916
Cumulative Timesteps: 1,367,078,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,634.83897
Policy Entropy: 3.05782
Value Function Loss: 0.00453

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.57334
Value Function Update Magnitude: 0.53235

Collected Steps per Second: 22,963.60897
Overall Steps per Second: 10,710.59851

Timestep Collection Time: 2.17736
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.66827

Cumulative Model Updates: 163,922
Cumulative Timesteps: 1,367,128,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1367128364...
Checkpoint 1367128364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,939.93697
Policy Entropy: 3.06165
Value Function Loss: 0.00434

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.58289
Value Function Update Magnitude: 0.53370

Collected Steps per Second: 22,836.72989
Overall Steps per Second: 10,655.33802

Timestep Collection Time: 2.18998
Timestep Consumption Time: 2.50363
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.69361

Cumulative Model Updates: 163,928
Cumulative Timesteps: 1,367,178,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,011.76271
Policy Entropy: 3.06117
Value Function Loss: 0.00442

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 0.58788
Value Function Update Magnitude: 0.52147

Collected Steps per Second: 22,588.30688
Overall Steps per Second: 10,780.69642

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.42497
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.63903

Cumulative Model Updates: 163,934
Cumulative Timesteps: 1,367,228,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1367228388...
Checkpoint 1367228388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,016.43786
Policy Entropy: 3.06232
Value Function Loss: 0.00443

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.58833
Value Function Update Magnitude: 0.52832

Collected Steps per Second: 22,729.66845
Overall Steps per Second: 10,688.75339

Timestep Collection Time: 2.19994
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.67819

Cumulative Model Updates: 163,940
Cumulative Timesteps: 1,367,278,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.30746
Policy Entropy: 3.06570
Value Function Loss: 0.00443

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.58565
Value Function Update Magnitude: 0.52019

Collected Steps per Second: 22,783.33804
Overall Steps per Second: 10,621.90674

Timestep Collection Time: 2.19529
Timestep Consumption Time: 2.51347
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.70876

Cumulative Model Updates: 163,946
Cumulative Timesteps: 1,367,328,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1367328408...
Checkpoint 1367328408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.34425
Policy Entropy: 3.04538
Value Function Loss: 0.00422

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.58438
Value Function Update Magnitude: 0.50838

Collected Steps per Second: 23,244.90053
Overall Steps per Second: 10,677.72848

Timestep Collection Time: 2.15118
Timestep Consumption Time: 2.53184
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.68302

Cumulative Model Updates: 163,952
Cumulative Timesteps: 1,367,378,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,044.08163
Policy Entropy: 3.04567
Value Function Loss: 0.00446

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.58955
Value Function Update Magnitude: 0.52682

Collected Steps per Second: 23,102.78258
Overall Steps per Second: 10,668.54320

Timestep Collection Time: 2.16528
Timestep Consumption Time: 2.52364
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.68893

Cumulative Model Updates: 163,958
Cumulative Timesteps: 1,367,428,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1367428436...
Checkpoint 1367428436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,733.97265
Policy Entropy: 3.03769
Value Function Loss: 0.00442

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.58892
Value Function Update Magnitude: 0.51159

Collected Steps per Second: 22,979.12427
Overall Steps per Second: 10,634.38857

Timestep Collection Time: 2.17719
Timestep Consumption Time: 2.52736
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.70455

Cumulative Model Updates: 163,964
Cumulative Timesteps: 1,367,478,466

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,655.80281
Policy Entropy: 3.05977
Value Function Loss: 0.00424

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.57642
Value Function Update Magnitude: 0.47865

Collected Steps per Second: 22,172.27747
Overall Steps per Second: 10,479.46651

Timestep Collection Time: 2.25516
Timestep Consumption Time: 2.51627
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.77143

Cumulative Model Updates: 163,970
Cumulative Timesteps: 1,367,528,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1367528468...
Checkpoint 1367528468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.21177
Policy Entropy: 3.05704
Value Function Loss: 0.00441

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.58182
Value Function Update Magnitude: 0.46792

Collected Steps per Second: 22,591.64507
Overall Steps per Second: 10,665.17319

Timestep Collection Time: 2.21454
Timestep Consumption Time: 2.47643
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69097

Cumulative Model Updates: 163,976
Cumulative Timesteps: 1,367,578,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.10765
Policy Entropy: 3.06176
Value Function Loss: 0.00439

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.58446
Value Function Update Magnitude: 0.47899

Collected Steps per Second: 22,950.80147
Overall Steps per Second: 10,839.87206

Timestep Collection Time: 2.17927
Timestep Consumption Time: 2.43481
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.61408

Cumulative Model Updates: 163,982
Cumulative Timesteps: 1,367,628,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1367628514...
Checkpoint 1367628514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,275.29169
Policy Entropy: 3.05518
Value Function Loss: 0.00452

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.58330
Value Function Update Magnitude: 0.50587

Collected Steps per Second: 23,260.97877
Overall Steps per Second: 10,667.73306

Timestep Collection Time: 2.14961
Timestep Consumption Time: 2.53761
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.68722

Cumulative Model Updates: 163,988
Cumulative Timesteps: 1,367,678,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,558.18036
Policy Entropy: 3.05253
Value Function Loss: 0.00420

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.57882
Value Function Update Magnitude: 0.51395

Collected Steps per Second: 23,139.43872
Overall Steps per Second: 10,836.25222

Timestep Collection Time: 2.16081
Timestep Consumption Time: 2.45333
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.61414

Cumulative Model Updates: 163,994
Cumulative Timesteps: 1,367,728,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1367728516...
Checkpoint 1367728516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,931.44899
Policy Entropy: 3.05561
Value Function Loss: 0.00414

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.57369
Value Function Update Magnitude: 0.49401

Collected Steps per Second: 23,013.15154
Overall Steps per Second: 10,769.26150

Timestep Collection Time: 2.17397
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.64563

Cumulative Model Updates: 164,000
Cumulative Timesteps: 1,367,778,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,658.46647
Policy Entropy: 3.06147
Value Function Loss: 0.00407

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.56992
Value Function Update Magnitude: 0.48147

Collected Steps per Second: 23,320.99445
Overall Steps per Second: 10,885.55408

Timestep Collection Time: 2.14528
Timestep Consumption Time: 2.45072
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.59600

Cumulative Model Updates: 164,006
Cumulative Timesteps: 1,367,828,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1367828576...
Checkpoint 1367828576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,141.03308
Policy Entropy: 3.04776
Value Function Loss: 0.00475

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.58731
Value Function Update Magnitude: 0.50226

Collected Steps per Second: 22,976.45524
Overall Steps per Second: 10,817.05888

Timestep Collection Time: 2.17666
Timestep Consumption Time: 2.44677
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.62344

Cumulative Model Updates: 164,012
Cumulative Timesteps: 1,367,878,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.25989
Policy Entropy: 3.03269
Value Function Loss: 0.00501

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.61504
Value Function Update Magnitude: 0.53874

Collected Steps per Second: 23,045.19253
Overall Steps per Second: 10,761.71376

Timestep Collection Time: 2.16974
Timestep Consumption Time: 2.47655
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.64629

Cumulative Model Updates: 164,018
Cumulative Timesteps: 1,367,928,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1367928590...
Checkpoint 1367928590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.29541
Policy Entropy: 3.02291
Value Function Loss: 0.00521

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.61521
Value Function Update Magnitude: 0.55540

Collected Steps per Second: 22,772.33234
Overall Steps per Second: 10,728.90947

Timestep Collection Time: 2.19714
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.66347

Cumulative Model Updates: 164,024
Cumulative Timesteps: 1,367,978,624

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,607.68857
Policy Entropy: 3.04176
Value Function Loss: 0.00492

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.61024
Value Function Update Magnitude: 0.55204

Collected Steps per Second: 22,704.58234
Overall Steps per Second: 10,768.37586

Timestep Collection Time: 2.20237
Timestep Consumption Time: 2.44122
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.64360

Cumulative Model Updates: 164,030
Cumulative Timesteps: 1,368,028,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1368028628...
Checkpoint 1368028628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,926.00201
Policy Entropy: 3.05616
Value Function Loss: 0.00481

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.60459
Value Function Update Magnitude: 0.53791

Collected Steps per Second: 22,436.03754
Overall Steps per Second: 10,688.63682

Timestep Collection Time: 2.23043
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.68179

Cumulative Model Updates: 164,036
Cumulative Timesteps: 1,368,078,670

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,577.79297
Policy Entropy: 3.05316
Value Function Loss: 0.00442

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11472
Policy Update Magnitude: 0.59312
Value Function Update Magnitude: 0.54388

Collected Steps per Second: 22,599.52253
Overall Steps per Second: 10,601.08724

Timestep Collection Time: 2.21323
Timestep Consumption Time: 2.50496
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.71820

Cumulative Model Updates: 164,042
Cumulative Timesteps: 1,368,128,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1368128688...
Checkpoint 1368128688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,251.20401
Policy Entropy: 3.04160
Value Function Loss: 0.00455

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.58892
Value Function Update Magnitude: 0.53319

Collected Steps per Second: 22,535.36308
Overall Steps per Second: 10,555.58468

Timestep Collection Time: 2.21918
Timestep Consumption Time: 2.51860
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.73778

Cumulative Model Updates: 164,048
Cumulative Timesteps: 1,368,178,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.76057
Policy Entropy: 3.02274
Value Function Loss: 0.00433

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.58059
Value Function Update Magnitude: 0.51080

Collected Steps per Second: 23,184.84903
Overall Steps per Second: 10,791.14199

Timestep Collection Time: 2.15796
Timestep Consumption Time: 2.47843
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.63640

Cumulative Model Updates: 164,054
Cumulative Timesteps: 1,368,228,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1368228730...
Checkpoint 1368228730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,373.72908
Policy Entropy: 3.01999
Value Function Loss: 0.00448

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.58487
Value Function Update Magnitude: 0.50545

Collected Steps per Second: 23,280.93958
Overall Steps per Second: 10,766.72442

Timestep Collection Time: 2.14837
Timestep Consumption Time: 2.49706
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.64542

Cumulative Model Updates: 164,060
Cumulative Timesteps: 1,368,278,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,699.75178
Policy Entropy: 3.02359
Value Function Loss: 0.00443

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.58904
Value Function Update Magnitude: 0.50465

Collected Steps per Second: 23,235.71552
Overall Steps per Second: 10,843.70220

Timestep Collection Time: 2.15289
Timestep Consumption Time: 2.46029
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.61318

Cumulative Model Updates: 164,066
Cumulative Timesteps: 1,368,328,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1368328770...
Checkpoint 1368328770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,994.41344
Policy Entropy: 3.03350
Value Function Loss: 0.00448

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.58786
Value Function Update Magnitude: 0.51244

Collected Steps per Second: 23,113.00589
Overall Steps per Second: 10,813.98514

Timestep Collection Time: 2.16389
Timestep Consumption Time: 2.46105
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.62494

Cumulative Model Updates: 164,072
Cumulative Timesteps: 1,368,378,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,704.53690
Policy Entropy: 3.04449
Value Function Loss: 0.00424

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.58119
Value Function Update Magnitude: 0.50360

Collected Steps per Second: 23,378.45005
Overall Steps per Second: 10,735.64166

Timestep Collection Time: 2.14001
Timestep Consumption Time: 2.52017
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.66018

Cumulative Model Updates: 164,078
Cumulative Timesteps: 1,368,428,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1368428814...
Checkpoint 1368428814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.34816
Policy Entropy: 3.04409
Value Function Loss: 0.00405

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.49522

Collected Steps per Second: 23,158.06772
Overall Steps per Second: 10,744.61935

Timestep Collection Time: 2.16020
Timestep Consumption Time: 2.49571
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.65591

Cumulative Model Updates: 164,084
Cumulative Timesteps: 1,368,478,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,492.62483
Policy Entropy: 3.04323
Value Function Loss: 0.00380

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.56226
Value Function Update Magnitude: 0.47456

Collected Steps per Second: 22,663.61198
Overall Steps per Second: 10,811.92933

Timestep Collection Time: 2.20680
Timestep Consumption Time: 2.41902
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.62582

Cumulative Model Updates: 164,090
Cumulative Timesteps: 1,368,528,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1368528854...
Checkpoint 1368528854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.23617
Policy Entropy: 3.03460
Value Function Loss: 0.00419

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.47966

Collected Steps per Second: 22,934.11972
Overall Steps per Second: 10,668.42733

Timestep Collection Time: 2.18016
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.68673

Cumulative Model Updates: 164,096
Cumulative Timesteps: 1,368,578,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.37469
Policy Entropy: 3.04239
Value Function Loss: 0.00427

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.57220
Value Function Update Magnitude: 0.48787

Collected Steps per Second: 22,828.38288
Overall Steps per Second: 10,786.91938

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.63728

Cumulative Model Updates: 164,102
Cumulative Timesteps: 1,368,628,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1368628876...
Checkpoint 1368628876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,436.52861
Policy Entropy: 3.05927
Value Function Loss: 0.00405

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.56410
Value Function Update Magnitude: 0.48422

Collected Steps per Second: 22,836.08487
Overall Steps per Second: 10,675.73305

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.49490
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.68521

Cumulative Model Updates: 164,108
Cumulative Timesteps: 1,368,678,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,582.74450
Policy Entropy: 3.07133
Value Function Loss: 0.00377

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.47046

Collected Steps per Second: 23,121.73257
Overall Steps per Second: 10,682.65635

Timestep Collection Time: 2.16290
Timestep Consumption Time: 2.51852
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.68142

Cumulative Model Updates: 164,114
Cumulative Timesteps: 1,368,728,904

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1368728904...
Checkpoint 1368728904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,167.35905
Policy Entropy: 3.07065
Value Function Loss: 0.00393

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.55717
Value Function Update Magnitude: 0.47670

Collected Steps per Second: 23,284.72209
Overall Steps per Second: 10,885.98768

Timestep Collection Time: 2.14810
Timestep Consumption Time: 2.44661
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.59471

Cumulative Model Updates: 164,120
Cumulative Timesteps: 1,368,778,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,056.43623
Policy Entropy: 3.05716
Value Function Loss: 0.00423

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.57651
Value Function Update Magnitude: 0.49705

Collected Steps per Second: 22,914.43031
Overall Steps per Second: 10,808.47067

Timestep Collection Time: 2.18212
Timestep Consumption Time: 2.44407
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.62619

Cumulative Model Updates: 164,126
Cumulative Timesteps: 1,368,828,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1368828924...
Checkpoint 1368828924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,598.91172
Policy Entropy: 3.05958
Value Function Loss: 0.00401

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.57730
Value Function Update Magnitude: 0.49709

Collected Steps per Second: 22,997.81360
Overall Steps per Second: 10,680.54877

Timestep Collection Time: 2.17490
Timestep Consumption Time: 2.50819
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.68309

Cumulative Model Updates: 164,132
Cumulative Timesteps: 1,368,878,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,777.30046
Policy Entropy: 3.06119
Value Function Loss: 0.00371

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.54997
Value Function Update Magnitude: 0.47823

Collected Steps per Second: 23,169.12549
Overall Steps per Second: 10,875.29463

Timestep Collection Time: 2.15830
Timestep Consumption Time: 2.43983
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59813

Cumulative Model Updates: 164,138
Cumulative Timesteps: 1,368,928,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1368928948...
Checkpoint 1368928948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.04258
Policy Entropy: 3.07414
Value Function Loss: 0.00380

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.54029
Value Function Update Magnitude: 0.46597

Collected Steps per Second: 22,754.78493
Overall Steps per Second: 10,703.50826

Timestep Collection Time: 2.19787
Timestep Consumption Time: 2.47462
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.67249

Cumulative Model Updates: 164,144
Cumulative Timesteps: 1,368,978,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.59556
Policy Entropy: 3.06807
Value Function Loss: 0.00415

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.55242
Value Function Update Magnitude: 0.48374

Collected Steps per Second: 22,826.41745
Overall Steps per Second: 10,826.34467

Timestep Collection Time: 2.19106
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.61966

Cumulative Model Updates: 164,150
Cumulative Timesteps: 1,369,028,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1369028974...
Checkpoint 1369028974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,163.62872
Policy Entropy: 3.04895
Value Function Loss: 0.00462

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.56864
Value Function Update Magnitude: 0.52787

Collected Steps per Second: 22,535.02796
Overall Steps per Second: 10,746.56406

Timestep Collection Time: 2.21903
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.65321

Cumulative Model Updates: 164,156
Cumulative Timesteps: 1,369,078,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.87902
Policy Entropy: 3.04119
Value Function Loss: 0.00434

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.57190
Value Function Update Magnitude: 0.53094

Collected Steps per Second: 22,739.73440
Overall Steps per Second: 10,777.20023

Timestep Collection Time: 2.20020
Timestep Consumption Time: 2.44219
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.64239

Cumulative Model Updates: 164,162
Cumulative Timesteps: 1,369,129,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1369129012...
Checkpoint 1369129012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,748.98532
Policy Entropy: 3.02568
Value Function Loss: 0.00475

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.58396
Value Function Update Magnitude: 0.55206

Collected Steps per Second: 22,859.49290
Overall Steps per Second: 10,773.19314

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.45515
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.64356

Cumulative Model Updates: 164,168
Cumulative Timesteps: 1,369,179,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676.71051
Policy Entropy: 3.01993
Value Function Loss: 0.00469

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.60701
Value Function Update Magnitude: 0.57266

Collected Steps per Second: 23,297.51274
Overall Steps per Second: 10,808.57212

Timestep Collection Time: 2.14718
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.62818

Cumulative Model Updates: 164,174
Cumulative Timesteps: 1,369,229,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1369229062...
Checkpoint 1369229062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.47031
Policy Entropy: 3.01288
Value Function Loss: 0.00479

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.60454
Value Function Update Magnitude: 0.55977

Collected Steps per Second: 23,036.74473
Overall Steps per Second: 10,676.80927

Timestep Collection Time: 2.17071
Timestep Consumption Time: 2.51290
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.68361

Cumulative Model Updates: 164,180
Cumulative Timesteps: 1,369,279,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,855.72417
Policy Entropy: 3.02229
Value Function Loss: 0.00443

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.59822
Value Function Update Magnitude: 0.54980

Collected Steps per Second: 23,243.90594
Overall Steps per Second: 10,885.44286

Timestep Collection Time: 2.15196
Timestep Consumption Time: 2.44317
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.59513

Cumulative Model Updates: 164,186
Cumulative Timesteps: 1,369,329,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1369329088...
Checkpoint 1369329088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.35169
Policy Entropy: 3.02954
Value Function Loss: 0.00439

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.58697
Value Function Update Magnitude: 0.54526

Collected Steps per Second: 22,600.31867
Overall Steps per Second: 10,782.12287

Timestep Collection Time: 2.21369
Timestep Consumption Time: 2.42640
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.64009

Cumulative Model Updates: 164,192
Cumulative Timesteps: 1,369,379,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.28024
Policy Entropy: 3.00376
Value Function Loss: 0.00450

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.58734
Value Function Update Magnitude: 0.55187

Collected Steps per Second: 22,214.52587
Overall Steps per Second: 10,748.73315

Timestep Collection Time: 2.25186
Timestep Consumption Time: 2.40208
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.65394

Cumulative Model Updates: 164,198
Cumulative Timesteps: 1,369,429,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1369429142...
Checkpoint 1369429142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.80810
Policy Entropy: 3.00270
Value Function Loss: 0.00442

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.59908
Value Function Update Magnitude: 0.57285

Collected Steps per Second: 21,590.05459
Overall Steps per Second: 10,673.29485

Timestep Collection Time: 2.31607
Timestep Consumption Time: 2.36890
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.68496

Cumulative Model Updates: 164,204
Cumulative Timesteps: 1,369,479,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.60950
Policy Entropy: 2.98513
Value Function Loss: 0.00463

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.60816
Value Function Update Magnitude: 0.58366

Collected Steps per Second: 21,655.69335
Overall Steps per Second: 10,548.81463

Timestep Collection Time: 2.30979
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.74176

Cumulative Model Updates: 164,210
Cumulative Timesteps: 1,369,529,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1369529166...
Checkpoint 1369529166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,124.94464
Policy Entropy: 3.02053
Value Function Loss: 0.00444

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.60823
Value Function Update Magnitude: 0.61532

Collected Steps per Second: 22,168.92088
Overall Steps per Second: 10,714.54582

Timestep Collection Time: 2.25631
Timestep Consumption Time: 2.41211
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.66842

Cumulative Model Updates: 164,216
Cumulative Timesteps: 1,369,579,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,467.39703
Policy Entropy: 3.03159
Value Function Loss: 0.00415

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.59519
Value Function Update Magnitude: 0.59437

Collected Steps per Second: 22,330.13683
Overall Steps per Second: 10,736.48948

Timestep Collection Time: 2.24002
Timestep Consumption Time: 2.41886
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.65888

Cumulative Model Updates: 164,222
Cumulative Timesteps: 1,369,629,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1369629206...
Checkpoint 1369629206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.31382
Policy Entropy: 3.04315
Value Function Loss: 0.00384

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.57739
Value Function Update Magnitude: 0.54983

Collected Steps per Second: 22,648.57341
Overall Steps per Second: 10,665.83704

Timestep Collection Time: 2.20817
Timestep Consumption Time: 2.48082
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.68899

Cumulative Model Updates: 164,228
Cumulative Timesteps: 1,369,679,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,546.37740
Policy Entropy: 3.01614
Value Function Loss: 0.00380

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.57654
Value Function Update Magnitude: 0.51325

Collected Steps per Second: 23,098.36310
Overall Steps per Second: 10,829.27616

Timestep Collection Time: 2.16500
Timestep Consumption Time: 2.45285
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61785

Cumulative Model Updates: 164,234
Cumulative Timesteps: 1,369,729,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1369729226...
Checkpoint 1369729226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,388.38236
Policy Entropy: 3.00608
Value Function Loss: 0.00377

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.57860
Value Function Update Magnitude: 0.48688

Collected Steps per Second: 23,005.38800
Overall Steps per Second: 10,733.57802

Timestep Collection Time: 2.17340
Timestep Consumption Time: 2.48488
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.65828

Cumulative Model Updates: 164,240
Cumulative Timesteps: 1,369,779,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,472.50232
Policy Entropy: 3.00926
Value Function Loss: 0.00377

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.57009
Value Function Update Magnitude: 0.49037

Collected Steps per Second: 23,189.59790
Overall Steps per Second: 10,910.21172

Timestep Collection Time: 2.15623
Timestep Consumption Time: 2.42682
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.58305

Cumulative Model Updates: 164,246
Cumulative Timesteps: 1,369,829,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1369829228...
Checkpoint 1369829228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,588.81495
Policy Entropy: 3.02106
Value Function Loss: 0.00408

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.57433
Value Function Update Magnitude: 0.47706

Collected Steps per Second: 23,253.14740
Overall Steps per Second: 10,770.62729

Timestep Collection Time: 2.15068
Timestep Consumption Time: 2.49251
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.64318

Cumulative Model Updates: 164,252
Cumulative Timesteps: 1,369,879,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,330.75683
Policy Entropy: 3.02211
Value Function Loss: 0.00434

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.58901
Value Function Update Magnitude: 0.47631

Collected Steps per Second: 23,045.61354
Overall Steps per Second: 10,741.21700

Timestep Collection Time: 2.17004
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.65590

Cumulative Model Updates: 164,258
Cumulative Timesteps: 1,369,929,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1369929248...
Checkpoint 1369929248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,344.44503
Policy Entropy: 3.01825
Value Function Loss: 0.00462

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.59358
Value Function Update Magnitude: 0.50335

Collected Steps per Second: 23,105.07951
Overall Steps per Second: 10,731.38316

Timestep Collection Time: 2.16472
Timestep Consumption Time: 2.49600
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.66072

Cumulative Model Updates: 164,264
Cumulative Timesteps: 1,369,979,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,236.54346
Policy Entropy: 3.01681
Value Function Loss: 0.00448

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.59221
Value Function Update Magnitude: 0.52453

Collected Steps per Second: 22,969.38193
Overall Steps per Second: 10,856.94327

Timestep Collection Time: 2.17794
Timestep Consumption Time: 2.42980
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.60774

Cumulative Model Updates: 164,270
Cumulative Timesteps: 1,370,029,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1370029290...
Checkpoint 1370029290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,048.72536
Policy Entropy: 3.02410
Value Function Loss: 0.00406

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.58322
Value Function Update Magnitude: 0.50623

Collected Steps per Second: 22,872.89631
Overall Steps per Second: 10,776.05682

Timestep Collection Time: 2.18713
Timestep Consumption Time: 2.45520
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.64233

Cumulative Model Updates: 164,276
Cumulative Timesteps: 1,370,079,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.00740
Policy Entropy: 3.04660
Value Function Loss: 0.00409

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.57435
Value Function Update Magnitude: 0.48610

Collected Steps per Second: 22,705.39142
Overall Steps per Second: 10,802.14733

Timestep Collection Time: 2.20300
Timestep Consumption Time: 2.42756
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.63056

Cumulative Model Updates: 164,282
Cumulative Timesteps: 1,370,129,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1370129336...
Checkpoint 1370129336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,057.14127
Policy Entropy: 3.05638
Value Function Loss: 0.00401

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.57929
Value Function Update Magnitude: 0.49082

Collected Steps per Second: 22,808.11902
Overall Steps per Second: 10,650.63022

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.50336
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.69644

Cumulative Model Updates: 164,288
Cumulative Timesteps: 1,370,179,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,410.22071
Policy Entropy: 3.06535
Value Function Loss: 0.00402

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.57411
Value Function Update Magnitude: 0.47987

Collected Steps per Second: 23,288.27826
Overall Steps per Second: 10,813.84286

Timestep Collection Time: 2.14769
Timestep Consumption Time: 2.47749
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.62518

Cumulative Model Updates: 164,294
Cumulative Timesteps: 1,370,229,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1370229372...
Checkpoint 1370229372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,728.49561
Policy Entropy: 3.06041
Value Function Loss: 0.00366

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.56568
Value Function Update Magnitude: 0.48459

Collected Steps per Second: 23,103.00998
Overall Steps per Second: 10,687.94121

Timestep Collection Time: 2.16439
Timestep Consumption Time: 2.51415
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.67854

Cumulative Model Updates: 164,300
Cumulative Timesteps: 1,370,279,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.55557
Policy Entropy: 3.06014
Value Function Loss: 0.00381

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.56526
Value Function Update Magnitude: 0.48616

Collected Steps per Second: 22,832.21790
Overall Steps per Second: 10,813.08074

Timestep Collection Time: 2.18989
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.62403

Cumulative Model Updates: 164,306
Cumulative Timesteps: 1,370,329,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1370329376...
Checkpoint 1370329376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.19013
Policy Entropy: 3.05102
Value Function Loss: 0.00430

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.57504
Value Function Update Magnitude: 0.52149

Collected Steps per Second: 22,780.49573
Overall Steps per Second: 10,685.11593

Timestep Collection Time: 2.19565
Timestep Consumption Time: 2.48544
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.68109

Cumulative Model Updates: 164,312
Cumulative Timesteps: 1,370,379,394

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,461.35472
Policy Entropy: 3.03634
Value Function Loss: 0.00449

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.54697

Collected Steps per Second: 23,214.85108
Overall Steps per Second: 10,922.45817

Timestep Collection Time: 2.15379
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.57772

Cumulative Model Updates: 164,318
Cumulative Timesteps: 1,370,429,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1370429394...
Checkpoint 1370429394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,542.08833
Policy Entropy: 3.04384
Value Function Loss: 0.00435

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.57639
Value Function Update Magnitude: 0.52540

Collected Steps per Second: 23,132.90306
Overall Steps per Second: 10,724.32206

Timestep Collection Time: 2.16220
Timestep Consumption Time: 2.50178
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.66398

Cumulative Model Updates: 164,324
Cumulative Timesteps: 1,370,479,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.51386
Policy Entropy: 3.06194
Value Function Loss: 0.00424

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.50016

Collected Steps per Second: 22,712.51328
Overall Steps per Second: 10,798.45460

Timestep Collection Time: 2.20152
Timestep Consumption Time: 2.42896
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.63048

Cumulative Model Updates: 164,330
Cumulative Timesteps: 1,370,529,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1370529414...
Checkpoint 1370529414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,375.26065
Policy Entropy: 3.07042
Value Function Loss: 0.00397

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.54234
Value Function Update Magnitude: 0.49035

Collected Steps per Second: 22,788.69919
Overall Steps per Second: 10,663.57929

Timestep Collection Time: 2.19512
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.69111

Cumulative Model Updates: 164,336
Cumulative Timesteps: 1,370,579,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,664.69435
Policy Entropy: 3.04916
Value Function Loss: 0.00405

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.55503
Value Function Update Magnitude: 0.50279

Collected Steps per Second: 22,930.04543
Overall Steps per Second: 10,833.51930

Timestep Collection Time: 2.18063
Timestep Consumption Time: 2.43486
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61549

Cumulative Model Updates: 164,342
Cumulative Timesteps: 1,370,629,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1370629440...
Checkpoint 1370629440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.91771
Policy Entropy: 3.02561
Value Function Loss: 0.00431

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.51708

Collected Steps per Second: 22,823.11239
Overall Steps per Second: 10,692.76333

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.48570
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.67681

Cumulative Model Updates: 164,348
Cumulative Timesteps: 1,370,679,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,682.29812
Policy Entropy: 3.01393
Value Function Loss: 0.00429

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.57304
Value Function Update Magnitude: 0.53098

Collected Steps per Second: 23,264.80933
Overall Steps per Second: 10,932.44406

Timestep Collection Time: 2.14994
Timestep Consumption Time: 2.42525
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.57519

Cumulative Model Updates: 164,354
Cumulative Timesteps: 1,370,729,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1370729466...
Checkpoint 1370729466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,458.93524
Policy Entropy: 3.01328
Value Function Loss: 0.00432

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.51969

Collected Steps per Second: 22,974.23275
Overall Steps per Second: 10,694.46835

Timestep Collection Time: 2.17757
Timestep Consumption Time: 2.50036
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.67793

Cumulative Model Updates: 164,360
Cumulative Timesteps: 1,370,779,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,552.98157
Policy Entropy: 3.00299
Value Function Loss: 0.00416

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.58208
Value Function Update Magnitude: 0.49745

Collected Steps per Second: 23,269.23982
Overall Steps per Second: 10,860.76042

Timestep Collection Time: 2.14996
Timestep Consumption Time: 2.45634
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.60631

Cumulative Model Updates: 164,366
Cumulative Timesteps: 1,370,829,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1370829522...
Checkpoint 1370829522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,725.03850
Policy Entropy: 3.00687
Value Function Loss: 0.00403

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.58315
Value Function Update Magnitude: 0.49354

Collected Steps per Second: 23,263.46942
Overall Steps per Second: 10,799.76205

Timestep Collection Time: 2.14955
Timestep Consumption Time: 2.48074
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.63029

Cumulative Model Updates: 164,372
Cumulative Timesteps: 1,370,879,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,798.22951
Policy Entropy: 2.98973
Value Function Loss: 0.00396

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.51562

Collected Steps per Second: 23,160.27359
Overall Steps per Second: 10,698.70907

Timestep Collection Time: 2.15991
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.67570

Cumulative Model Updates: 164,378
Cumulative Timesteps: 1,370,929,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1370929552...
Checkpoint 1370929552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.39988
Policy Entropy: 2.97658
Value Function Loss: 0.00382

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.59399
Value Function Update Magnitude: 0.52745

Collected Steps per Second: 22,712.43547
Overall Steps per Second: 10,656.40619

Timestep Collection Time: 2.20161
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.69239

Cumulative Model Updates: 164,384
Cumulative Timesteps: 1,370,979,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,580.45757
Policy Entropy: 2.95561
Value Function Loss: 0.00445

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.60511
Value Function Update Magnitude: 0.52498

Collected Steps per Second: 22,756.04660
Overall Steps per Second: 10,697.17962

Timestep Collection Time: 2.19731
Timestep Consumption Time: 2.47701
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.67432

Cumulative Model Updates: 164,390
Cumulative Timesteps: 1,371,029,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1371029558...
Checkpoint 1371029558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.56955
Policy Entropy: 2.95351
Value Function Loss: 0.00461

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12032
Policy Update Magnitude: 0.61597
Value Function Update Magnitude: 0.51634

Collected Steps per Second: 22,555.80733
Overall Steps per Second: 10,773.42195

Timestep Collection Time: 2.21708
Timestep Consumption Time: 2.42471
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.64179

Cumulative Model Updates: 164,396
Cumulative Timesteps: 1,371,079,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.46566
Policy Entropy: 2.96174
Value Function Loss: 0.00466

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.60539
Value Function Update Magnitude: 0.49787

Collected Steps per Second: 22,689.75456
Overall Steps per Second: 10,591.76190

Timestep Collection Time: 2.20390
Timestep Consumption Time: 2.51731
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.72122

Cumulative Model Updates: 164,402
Cumulative Timesteps: 1,371,129,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1371129572...
Checkpoint 1371129572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.69570
Policy Entropy: 2.96972
Value Function Loss: 0.00452

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.59863
Value Function Update Magnitude: 0.48106

Collected Steps per Second: 22,648.97070
Overall Steps per Second: 10,581.23506

Timestep Collection Time: 2.20884
Timestep Consumption Time: 2.51915
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.72799

Cumulative Model Updates: 164,408
Cumulative Timesteps: 1,371,179,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,607.49796
Policy Entropy: 2.98350
Value Function Loss: 0.00433

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.59985
Value Function Update Magnitude: 0.49809

Collected Steps per Second: 23,278.69771
Overall Steps per Second: 10,873.09052

Timestep Collection Time: 2.14857
Timestep Consumption Time: 2.45141
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.59998

Cumulative Model Updates: 164,414
Cumulative Timesteps: 1,371,229,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1371229616...
Checkpoint 1371229616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758.57509
Policy Entropy: 2.97616
Value Function Loss: 0.00448

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.60134
Value Function Update Magnitude: 0.51336

Collected Steps per Second: 23,082.11131
Overall Steps per Second: 10,691.53784

Timestep Collection Time: 2.16644
Timestep Consumption Time: 2.51072
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.67716

Cumulative Model Updates: 164,420
Cumulative Timesteps: 1,371,279,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.45455
Policy Entropy: 2.97503
Value Function Loss: 0.00453

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.60344
Value Function Update Magnitude: 0.54212

Collected Steps per Second: 23,082.98542
Overall Steps per Second: 10,933.08550

Timestep Collection Time: 2.16722
Timestep Consumption Time: 2.40843
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.57565

Cumulative Model Updates: 164,426
Cumulative Timesteps: 1,371,329,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1371329648...
Checkpoint 1371329648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,848.21866
Policy Entropy: 2.96972
Value Function Loss: 0.00454

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.61113
Value Function Update Magnitude: 0.54422

Collected Steps per Second: 22,378.08628
Overall Steps per Second: 10,591.26613

Timestep Collection Time: 2.23460
Timestep Consumption Time: 2.48684
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.72144

Cumulative Model Updates: 164,432
Cumulative Timesteps: 1,371,379,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,237.40110
Policy Entropy: 2.97846
Value Function Loss: 0.00422

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.61132
Value Function Update Magnitude: 0.54273

Collected Steps per Second: 22,504.22680
Overall Steps per Second: 10,614.16428

Timestep Collection Time: 2.22225
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.71163

Cumulative Model Updates: 164,438
Cumulative Timesteps: 1,371,429,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1371429664...
Checkpoint 1371429664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.38077
Policy Entropy: 2.96823
Value Function Loss: 0.00398

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.59476
Value Function Update Magnitude: 0.52648

Collected Steps per Second: 22,795.60394
Overall Steps per Second: 10,714.72603

Timestep Collection Time: 2.19446
Timestep Consumption Time: 2.47426
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.66871

Cumulative Model Updates: 164,444
Cumulative Timesteps: 1,371,479,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.75891
Policy Entropy: 2.97534
Value Function Loss: 0.00407

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.59069
Value Function Update Magnitude: 0.51553

Collected Steps per Second: 23,006.18930
Overall Steps per Second: 10,677.74582

Timestep Collection Time: 2.17359
Timestep Consumption Time: 2.50961
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.68320

Cumulative Model Updates: 164,450
Cumulative Timesteps: 1,371,529,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1371529694...
Checkpoint 1371529694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.35178
Policy Entropy: 2.98516
Value Function Loss: 0.00394

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.59438
Value Function Update Magnitude: 0.51686

Collected Steps per Second: 22,889.60271
Overall Steps per Second: 10,621.75995

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.52332
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.70807

Cumulative Model Updates: 164,456
Cumulative Timesteps: 1,371,579,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,783.12440
Policy Entropy: 2.99461
Value Function Loss: 0.00410

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.59272
Value Function Update Magnitude: 0.51772

Collected Steps per Second: 23,181.73696
Overall Steps per Second: 10,964.09974

Timestep Collection Time: 2.15791
Timestep Consumption Time: 2.40462
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.56253

Cumulative Model Updates: 164,462
Cumulative Timesteps: 1,371,629,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1371629726...
Checkpoint 1371629726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,416.83828
Policy Entropy: 2.97776
Value Function Loss: 0.00454

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.60180
Value Function Update Magnitude: 0.53300

Collected Steps per Second: 23,126.27027
Overall Steps per Second: 10,968.77637

Timestep Collection Time: 2.16204
Timestep Consumption Time: 2.39635
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.55839

Cumulative Model Updates: 164,468
Cumulative Timesteps: 1,371,679,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.75211
Policy Entropy: 2.94766
Value Function Loss: 0.00506

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.62106
Value Function Update Magnitude: 0.56675

Collected Steps per Second: 23,243.93917
Overall Steps per Second: 10,900.85400

Timestep Collection Time: 2.15230
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.58937

Cumulative Model Updates: 164,474
Cumulative Timesteps: 1,371,729,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1371729754...
Checkpoint 1371729754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.17234
Policy Entropy: 2.92949
Value Function Loss: 0.00515

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.62922
Value Function Update Magnitude: 0.58338

Collected Steps per Second: 22,936.25413
Overall Steps per Second: 10,727.26572

Timestep Collection Time: 2.18083
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.66288

Cumulative Model Updates: 164,480
Cumulative Timesteps: 1,371,779,774

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.91233
Policy Entropy: 2.93583
Value Function Loss: 0.00485

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.62711
Value Function Update Magnitude: 0.56163

Collected Steps per Second: 23,026.88383
Overall Steps per Second: 10,836.88399

Timestep Collection Time: 2.17216
Timestep Consumption Time: 2.44338
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.61553

Cumulative Model Updates: 164,486
Cumulative Timesteps: 1,371,829,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1371829792...
Checkpoint 1371829792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.68278
Policy Entropy: 2.95932
Value Function Loss: 0.00464

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.59955
Value Function Update Magnitude: 0.53504

Collected Steps per Second: 22,666.24652
Overall Steps per Second: 10,728.91724

Timestep Collection Time: 2.20654
Timestep Consumption Time: 2.45507
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.66161

Cumulative Model Updates: 164,492
Cumulative Timesteps: 1,371,879,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.07301
Policy Entropy: 2.97233
Value Function Loss: 0.00464

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.59664
Value Function Update Magnitude: 0.55515

Collected Steps per Second: 22,606.84810
Overall Steps per Second: 10,630.34072

Timestep Collection Time: 2.21172
Timestep Consumption Time: 2.49180
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.70352

Cumulative Model Updates: 164,498
Cumulative Timesteps: 1,371,929,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1371929806...
Checkpoint 1371929806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,986.28215
Policy Entropy: 2.98963
Value Function Loss: 0.00451

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.60197
Value Function Update Magnitude: 0.56042

Collected Steps per Second: 22,602.79597
Overall Steps per Second: 10,660.93672

Timestep Collection Time: 2.21274
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.69133

Cumulative Model Updates: 164,504
Cumulative Timesteps: 1,371,979,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.81563
Policy Entropy: 2.98388
Value Function Loss: 0.00479

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.60433
Value Function Update Magnitude: 0.55487

Collected Steps per Second: 23,185.02321
Overall Steps per Second: 10,668.01145

Timestep Collection Time: 2.15769
Timestep Consumption Time: 2.53166
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.68935

Cumulative Model Updates: 164,510
Cumulative Timesteps: 1,372,029,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1372029846...
Checkpoint 1372029846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.59529
Policy Entropy: 2.99539
Value Function Loss: 0.00451

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.60152
Value Function Update Magnitude: 0.56043

Collected Steps per Second: 22,695.54808
Overall Steps per Second: 10,738.78707

Timestep Collection Time: 2.20369
Timestep Consumption Time: 2.45363
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.65732

Cumulative Model Updates: 164,516
Cumulative Timesteps: 1,372,079,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,379.22662
Policy Entropy: 2.99586
Value Function Loss: 0.00417

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.59699
Value Function Update Magnitude: 0.53568

Collected Steps per Second: 23,092.88595
Overall Steps per Second: 10,832.68002

Timestep Collection Time: 2.16560
Timestep Consumption Time: 2.45098
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.61659

Cumulative Model Updates: 164,522
Cumulative Timesteps: 1,372,129,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1372129870...
Checkpoint 1372129870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,711.42922
Policy Entropy: 3.00604
Value Function Loss: 0.00413

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.59307
Value Function Update Magnitude: 0.52357

Collected Steps per Second: 23,122.54835
Overall Steps per Second: 10,670.16925

Timestep Collection Time: 2.16265
Timestep Consumption Time: 2.52387
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.68652

Cumulative Model Updates: 164,528
Cumulative Timesteps: 1,372,179,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.40396
Policy Entropy: 3.01698
Value Function Loss: 0.00410

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.59193
Value Function Update Magnitude: 0.52930

Collected Steps per Second: 23,349.34951
Overall Steps per Second: 10,907.46235

Timestep Collection Time: 2.14173
Timestep Consumption Time: 2.44302
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.58475

Cumulative Model Updates: 164,534
Cumulative Timesteps: 1,372,229,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1372229884...
Checkpoint 1372229884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,635.11968
Policy Entropy: 3.01718
Value Function Loss: 0.00435

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.58705
Value Function Update Magnitude: 0.49796

Collected Steps per Second: 22,965.36264
Overall Steps per Second: 10,685.19547

Timestep Collection Time: 2.17885
Timestep Consumption Time: 2.50408
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.68293

Cumulative Model Updates: 164,540
Cumulative Timesteps: 1,372,279,922

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,648.71972
Policy Entropy: 3.02173
Value Function Loss: 0.00415

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.49781

Collected Steps per Second: 23,193.57468
Overall Steps per Second: 10,892.58153

Timestep Collection Time: 2.15672
Timestep Consumption Time: 2.43558
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.59230

Cumulative Model Updates: 164,546
Cumulative Timesteps: 1,372,329,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1372329944...
Checkpoint 1372329944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.07346
Policy Entropy: 3.00031
Value Function Loss: 0.00499

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.62184
Value Function Update Magnitude: 0.53342

Collected Steps per Second: 22,028.34902
Overall Steps per Second: 10,641.91093

Timestep Collection Time: 2.27007
Timestep Consumption Time: 2.42889
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.69897

Cumulative Model Updates: 164,552
Cumulative Timesteps: 1,372,379,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.79581
Policy Entropy: 2.99293
Value Function Loss: 0.00474

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.61803
Value Function Update Magnitude: 0.57237

Collected Steps per Second: 22,996.30844
Overall Steps per Second: 10,848.35654

Timestep Collection Time: 2.17461
Timestep Consumption Time: 2.43512
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.60973

Cumulative Model Updates: 164,558
Cumulative Timesteps: 1,372,429,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1372429958...
Checkpoint 1372429958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.80861
Policy Entropy: 2.99177
Value Function Loss: 0.00447

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.60286
Value Function Update Magnitude: 0.56992

Collected Steps per Second: 22,580.78333
Overall Steps per Second: 10,689.84658

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.46464
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.68033

Cumulative Model Updates: 164,564
Cumulative Timesteps: 1,372,479,990

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.09333
Policy Entropy: 2.99894
Value Function Loss: 0.00407

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11617
Policy Update Magnitude: 0.58828
Value Function Update Magnitude: 0.55737

Collected Steps per Second: 22,989.96695
Overall Steps per Second: 10,799.24005

Timestep Collection Time: 2.17582
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.63199

Cumulative Model Updates: 164,570
Cumulative Timesteps: 1,372,530,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1372530012...
Checkpoint 1372530012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,973.29502
Policy Entropy: 3.00366
Value Function Loss: 0.00412

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.59384
Value Function Update Magnitude: 0.54578

Collected Steps per Second: 23,113.00455
Overall Steps per Second: 10,735.58163

Timestep Collection Time: 2.16354
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.65797

Cumulative Model Updates: 164,576
Cumulative Timesteps: 1,372,580,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.54820
Policy Entropy: 3.00130
Value Function Loss: 0.00419

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.58843
Value Function Update Magnitude: 0.53560

Collected Steps per Second: 23,295.70956
Overall Steps per Second: 10,893.09414

Timestep Collection Time: 2.14735
Timestep Consumption Time: 2.44492
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.59227

Cumulative Model Updates: 164,582
Cumulative Timesteps: 1,372,630,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1372630042...
Checkpoint 1372630042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,402.10846
Policy Entropy: 3.00932
Value Function Loss: 0.00410

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.58772
Value Function Update Magnitude: 0.51137

Collected Steps per Second: 22,958.79602
Overall Steps per Second: 10,771.98230

Timestep Collection Time: 2.17886
Timestep Consumption Time: 2.46504
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.64390

Cumulative Model Updates: 164,588
Cumulative Timesteps: 1,372,680,066

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,596.11611
Policy Entropy: 3.00428
Value Function Loss: 0.00403

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.59405
Value Function Update Magnitude: 0.50587

Collected Steps per Second: 23,053.66290
Overall Steps per Second: 10,813.42842

Timestep Collection Time: 2.17007
Timestep Consumption Time: 2.45640
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.62647

Cumulative Model Updates: 164,594
Cumulative Timesteps: 1,372,730,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1372730094...
Checkpoint 1372730094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,425.57225
Policy Entropy: 2.99115
Value Function Loss: 0.00396

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.59688
Value Function Update Magnitude: 0.52917

Collected Steps per Second: 22,839.61492
Overall Steps per Second: 10,645.59337

Timestep Collection Time: 2.18935
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.69715

Cumulative Model Updates: 164,600
Cumulative Timesteps: 1,372,780,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,789.11585
Policy Entropy: 2.98267
Value Function Loss: 0.00388

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.59524
Value Function Update Magnitude: 0.54445

Collected Steps per Second: 23,276.64742
Overall Steps per Second: 10,940.20905

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.42319
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.57212

Cumulative Model Updates: 164,606
Cumulative Timesteps: 1,372,830,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1372830118...
Checkpoint 1372830118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903.23889
Policy Entropy: 2.97167
Value Function Loss: 0.00420

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.61011
Value Function Update Magnitude: 0.54321

Collected Steps per Second: 22,465.41264
Overall Steps per Second: 10,611.04265

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.48752
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.71415

Cumulative Model Updates: 164,612
Cumulative Timesteps: 1,372,880,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,922.42008
Policy Entropy: 2.98137
Value Function Loss: 0.00441

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.61378
Value Function Update Magnitude: 0.53387

Collected Steps per Second: 22,817.42958
Overall Steps per Second: 10,711.68729

Timestep Collection Time: 2.19131
Timestep Consumption Time: 2.47649
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.66780

Cumulative Model Updates: 164,618
Cumulative Timesteps: 1,372,930,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1372930140...
Checkpoint 1372930140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,206.67115
Policy Entropy: 2.99375
Value Function Loss: 0.00461

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.61217
Value Function Update Magnitude: 0.53175

Collected Steps per Second: 22,788.08403
Overall Steps per Second: 10,839.59948

Timestep Collection Time: 2.19457
Timestep Consumption Time: 2.41907
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.61364

Cumulative Model Updates: 164,624
Cumulative Timesteps: 1,372,980,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.81404
Policy Entropy: 3.02899
Value Function Loss: 0.00447

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.59641
Value Function Update Magnitude: 0.52776

Collected Steps per Second: 22,648.05120
Overall Steps per Second: 10,654.92801

Timestep Collection Time: 2.20805
Timestep Consumption Time: 2.48537
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.69342

Cumulative Model Updates: 164,630
Cumulative Timesteps: 1,373,030,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1373030158...
Checkpoint 1373030158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.90536
Policy Entropy: 3.03396
Value Function Loss: 0.00442

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.58338
Value Function Update Magnitude: 0.52023

Collected Steps per Second: 22,756.91020
Overall Steps per Second: 10,783.94590

Timestep Collection Time: 2.19731
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.63689

Cumulative Model Updates: 164,636
Cumulative Timesteps: 1,373,080,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,169.01888
Policy Entropy: 3.02898
Value Function Loss: 0.00443

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10410
Policy Update Magnitude: 0.58145
Value Function Update Magnitude: 0.51571

Collected Steps per Second: 23,178.53478
Overall Steps per Second: 10,723.30346

Timestep Collection Time: 2.15769
Timestep Consumption Time: 2.50618
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.66386

Cumulative Model Updates: 164,642
Cumulative Timesteps: 1,373,130,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1373130174...
Checkpoint 1373130174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.04014
Policy Entropy: 3.01450
Value Function Loss: 0.00437

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10538
Policy Update Magnitude: 0.59019
Value Function Update Magnitude: 0.50537

Collected Steps per Second: 23,060.92724
Overall Steps per Second: 10,964.27045

Timestep Collection Time: 2.16869
Timestep Consumption Time: 2.39267
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.56136

Cumulative Model Updates: 164,648
Cumulative Timesteps: 1,373,180,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.98310
Policy Entropy: 3.00651
Value Function Loss: 0.00441

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.58399
Value Function Update Magnitude: 0.50250

Collected Steps per Second: 23,318.47594
Overall Steps per Second: 10,896.48518

Timestep Collection Time: 2.14551
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.59139

Cumulative Model Updates: 164,654
Cumulative Timesteps: 1,373,230,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1373230216...
Checkpoint 1373230216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.85385
Policy Entropy: 2.99641
Value Function Loss: 0.00427

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.58074
Value Function Update Magnitude: 0.51344

Collected Steps per Second: 22,574.06460
Overall Steps per Second: 10,529.49015

Timestep Collection Time: 2.21493
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.74857

Cumulative Model Updates: 164,660
Cumulative Timesteps: 1,373,280,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.61465
Policy Entropy: 2.99049
Value Function Loss: 0.00467

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.59336
Value Function Update Magnitude: 0.51841

Collected Steps per Second: 23,329.97426
Overall Steps per Second: 10,921.07383

Timestep Collection Time: 2.14325
Timestep Consumption Time: 2.43524
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.57849

Cumulative Model Updates: 164,666
Cumulative Timesteps: 1,373,330,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1373330218...
Checkpoint 1373330218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,810.89946
Policy Entropy: 2.98821
Value Function Loss: 0.00440

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.59451
Value Function Update Magnitude: 0.54589

Collected Steps per Second: 22,931.65332
Overall Steps per Second: 10,719.33921

Timestep Collection Time: 2.18214
Timestep Consumption Time: 2.48606
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.66820

Cumulative Model Updates: 164,672
Cumulative Timesteps: 1,373,380,258

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,035.43895
Policy Entropy: 3.00214
Value Function Loss: 0.00421

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.58764
Value Function Update Magnitude: 0.54699

Collected Steps per Second: 23,077.62979
Overall Steps per Second: 10,854.57629

Timestep Collection Time: 2.16712
Timestep Consumption Time: 2.44034
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.60746

Cumulative Model Updates: 164,678
Cumulative Timesteps: 1,373,430,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1373430270...
Checkpoint 1373430270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,330.75437
Policy Entropy: 3.00877
Value Function Loss: 0.00392

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.58372
Value Function Update Magnitude: 0.52410

Collected Steps per Second: 22,404.16594
Overall Steps per Second: 10,729.12036

Timestep Collection Time: 2.23289
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.66264

Cumulative Model Updates: 164,684
Cumulative Timesteps: 1,373,480,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,920.11547
Policy Entropy: 3.02708
Value Function Loss: 0.00424

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.57765
Value Function Update Magnitude: 0.50416

Collected Steps per Second: 22,894.39980
Overall Steps per Second: 10,909.02516

Timestep Collection Time: 2.18455
Timestep Consumption Time: 2.40009
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.58464

Cumulative Model Updates: 164,690
Cumulative Timesteps: 1,373,530,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1373530310...
Checkpoint 1373530310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.65934
Policy Entropy: 3.03904
Value Function Loss: 0.00394

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.55884
Value Function Update Magnitude: 0.49105

Collected Steps per Second: 22,518.01565
Overall Steps per Second: 10,593.65715

Timestep Collection Time: 2.22133
Timestep Consumption Time: 2.50036
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.72169

Cumulative Model Updates: 164,696
Cumulative Timesteps: 1,373,580,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,752.23408
Policy Entropy: 3.05499
Value Function Loss: 0.00391

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.45671

Collected Steps per Second: 23,390.52664
Overall Steps per Second: 10,947.55191

Timestep Collection Time: 2.13873
Timestep Consumption Time: 2.43088
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.56961

Cumulative Model Updates: 164,702
Cumulative Timesteps: 1,373,630,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1373630356...
Checkpoint 1373630356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,018.64571
Policy Entropy: 3.03624
Value Function Loss: 0.00378

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.54911
Value Function Update Magnitude: 0.44908

Collected Steps per Second: 22,737.20952
Overall Steps per Second: 10,620.08266

Timestep Collection Time: 2.20027
Timestep Consumption Time: 2.51043
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.71070

Cumulative Model Updates: 164,708
Cumulative Timesteps: 1,373,680,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,543.08100
Policy Entropy: 3.01985
Value Function Loss: 0.00379

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.44571

Collected Steps per Second: 23,554.65963
Overall Steps per Second: 10,902.95628

Timestep Collection Time: 2.12323
Timestep Consumption Time: 2.46378
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.58701

Cumulative Model Updates: 164,714
Cumulative Timesteps: 1,373,730,396

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1373730396...
Checkpoint 1373730396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.37892
Policy Entropy: 3.00746
Value Function Loss: 0.00371

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.56382
Value Function Update Magnitude: 0.46915

Collected Steps per Second: 23,159.70149
Overall Steps per Second: 10,777.62964

Timestep Collection Time: 2.15927
Timestep Consumption Time: 2.48071
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.63998

Cumulative Model Updates: 164,720
Cumulative Timesteps: 1,373,780,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,689.48550
Policy Entropy: 3.02114
Value Function Loss: 0.00393

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.56961
Value Function Update Magnitude: 0.51409

Collected Steps per Second: 23,456.17099
Overall Steps per Second: 10,735.84819

Timestep Collection Time: 2.13240
Timestep Consumption Time: 2.52657
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.65897

Cumulative Model Updates: 164,726
Cumulative Timesteps: 1,373,830,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1373830422...
Checkpoint 1373830422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,227.27530
Policy Entropy: 3.02303
Value Function Loss: 0.00435

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.52995

Collected Steps per Second: 22,991.91660
Overall Steps per Second: 10,663.76715

Timestep Collection Time: 2.17494
Timestep Consumption Time: 2.51440
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.68934

Cumulative Model Updates: 164,732
Cumulative Timesteps: 1,373,880,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,907.87272
Policy Entropy: 3.03438
Value Function Loss: 0.00431

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.57712
Value Function Update Magnitude: 0.53115

Collected Steps per Second: 22,921.85909
Overall Steps per Second: 10,831.41050

Timestep Collection Time: 2.18159
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61676

Cumulative Model Updates: 164,738
Cumulative Timesteps: 1,373,930,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1373930434...
Checkpoint 1373930434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.56203
Policy Entropy: 3.02045
Value Function Loss: 0.00441

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.57908
Value Function Update Magnitude: 0.52048

Collected Steps per Second: 22,460.26207
Overall Steps per Second: 10,723.66325

Timestep Collection Time: 2.22615
Timestep Consumption Time: 2.43643
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.66259

Cumulative Model Updates: 164,744
Cumulative Timesteps: 1,373,980,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,483.79214
Policy Entropy: 3.01876
Value Function Loss: 0.00429

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.58838
Value Function Update Magnitude: 0.50444

Collected Steps per Second: 22,830.45755
Overall Steps per Second: 10,796.47370

Timestep Collection Time: 2.19190
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.63503

Cumulative Model Updates: 164,750
Cumulative Timesteps: 1,374,030,476

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1374030476...
Checkpoint 1374030476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.93281
Policy Entropy: 3.00116
Value Function Loss: 0.00490

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.60371
Value Function Update Magnitude: 0.53785

Collected Steps per Second: 22,506.51094
Overall Steps per Second: 10,716.09244

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.44577
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.66868

Cumulative Model Updates: 164,756
Cumulative Timesteps: 1,374,080,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,743.44242
Policy Entropy: 3.00217
Value Function Loss: 0.00520

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.62810
Value Function Update Magnitude: 0.56729

Collected Steps per Second: 23,277.90198
Overall Steps per Second: 10,703.59275

Timestep Collection Time: 2.14796
Timestep Consumption Time: 2.52337
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.67133

Cumulative Model Updates: 164,762
Cumulative Timesteps: 1,374,130,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1374130506...
Checkpoint 1374130506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,631.92126
Policy Entropy: 3.00612
Value Function Loss: 0.00517

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.63124
Value Function Update Magnitude: 0.59143

Collected Steps per Second: 23,015.45007
Overall Steps per Second: 10,836.50068

Timestep Collection Time: 2.17315
Timestep Consumption Time: 2.44236
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.61551

Cumulative Model Updates: 164,768
Cumulative Timesteps: 1,374,180,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494.54036
Policy Entropy: 3.01201
Value Function Loss: 0.00455

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.61522
Value Function Update Magnitude: 0.58344

Collected Steps per Second: 23,485.25703
Overall Steps per Second: 10,947.24845

Timestep Collection Time: 2.12968
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.56882

Cumulative Model Updates: 164,774
Cumulative Timesteps: 1,374,230,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1374230538...
Checkpoint 1374230538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.46669
Policy Entropy: 3.01897
Value Function Loss: 0.00477

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.61949
Value Function Update Magnitude: 0.57926

Collected Steps per Second: 22,932.45438
Overall Steps per Second: 10,673.05736

Timestep Collection Time: 2.18223
Timestep Consumption Time: 2.50658
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.68882

Cumulative Model Updates: 164,780
Cumulative Timesteps: 1,374,280,582

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,302.43343
Policy Entropy: 2.99894
Value Function Loss: 0.00474

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.63363
Value Function Update Magnitude: 0.57683

Collected Steps per Second: 23,020.40621
Overall Steps per Second: 10,847.26160

Timestep Collection Time: 2.17199
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.60946

Cumulative Model Updates: 164,786
Cumulative Timesteps: 1,374,330,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1374330582...
Checkpoint 1374330582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.39392
Policy Entropy: 2.99309
Value Function Loss: 0.00503

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.63640
Value Function Update Magnitude: 0.58017

Collected Steps per Second: 22,590.27881
Overall Steps per Second: 10,684.26568

Timestep Collection Time: 2.21432
Timestep Consumption Time: 2.46752
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.68184

Cumulative Model Updates: 164,792
Cumulative Timesteps: 1,374,380,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,396.39443
Policy Entropy: 2.98046
Value Function Loss: 0.00486

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.15336
Policy Update Magnitude: 0.64140
Value Function Update Magnitude: 0.59593

Collected Steps per Second: 22,490.38157
Overall Steps per Second: 10,586.10993

Timestep Collection Time: 2.22451
Timestep Consumption Time: 2.50150
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.72600

Cumulative Model Updates: 164,798
Cumulative Timesteps: 1,374,430,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1374430634...
Checkpoint 1374430634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,555.57958
Policy Entropy: 2.99721
Value Function Loss: 0.00512

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.14737
Policy Update Magnitude: 0.64145
Value Function Update Magnitude: 0.61793

Collected Steps per Second: 22,555.63306
Overall Steps per Second: 10,629.90871

Timestep Collection Time: 2.21718
Timestep Consumption Time: 2.48747
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.70465

Cumulative Model Updates: 164,804
Cumulative Timesteps: 1,374,480,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.49731
Policy Entropy: 2.98565
Value Function Loss: 0.00530

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.64094
Value Function Update Magnitude: 0.62419

Collected Steps per Second: 22,941.05773
Overall Steps per Second: 10,781.69301

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.45829
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.63805

Cumulative Model Updates: 164,810
Cumulative Timesteps: 1,374,530,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1374530650...
Checkpoint 1374530650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494.98704
Policy Entropy: 2.97063
Value Function Loss: 0.00530

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.64407
Value Function Update Magnitude: 0.61309

Collected Steps per Second: 22,979.15897
Overall Steps per Second: 10,606.54181

Timestep Collection Time: 2.17667
Timestep Consumption Time: 2.53910
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.71577

Cumulative Model Updates: 164,816
Cumulative Timesteps: 1,374,580,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,569.07850
Policy Entropy: 2.95945
Value Function Loss: 0.00506

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.64119
Value Function Update Magnitude: 0.58775

Collected Steps per Second: 23,385.62315
Overall Steps per Second: 10,885.11265

Timestep Collection Time: 2.13824
Timestep Consumption Time: 2.45556
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.59380

Cumulative Model Updates: 164,822
Cumulative Timesteps: 1,374,630,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1374630672...
Checkpoint 1374630672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,382.46715
Policy Entropy: 2.96889
Value Function Loss: 0.00455

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.62435
Value Function Update Magnitude: 0.55740

Collected Steps per Second: 23,011.44214
Overall Steps per Second: 10,662.74153

Timestep Collection Time: 2.17353
Timestep Consumption Time: 2.51720
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.69073

Cumulative Model Updates: 164,828
Cumulative Timesteps: 1,374,680,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.47928
Policy Entropy: 2.98671
Value Function Loss: 0.00419

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.60764
Value Function Update Magnitude: 0.54287

Collected Steps per Second: 23,190.76516
Overall Steps per Second: 10,880.88791

Timestep Collection Time: 2.15681
Timestep Consumption Time: 2.44006
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.59687

Cumulative Model Updates: 164,834
Cumulative Timesteps: 1,374,730,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1374730706...
Checkpoint 1374730706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,473.20871
Policy Entropy: 2.98497
Value Function Loss: 0.00420

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.59774
Value Function Update Magnitude: 0.53511

Collected Steps per Second: 23,086.10265
Overall Steps per Second: 10,816.58773

Timestep Collection Time: 2.16702
Timestep Consumption Time: 2.45810
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.62512

Cumulative Model Updates: 164,840
Cumulative Timesteps: 1,374,780,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,399.37036
Policy Entropy: 2.99390
Value Function Loss: 0.00426

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.59424
Value Function Update Magnitude: 0.51849

Collected Steps per Second: 23,306.55575
Overall Steps per Second: 10,779.82322

Timestep Collection Time: 2.14643
Timestep Consumption Time: 2.49427
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.64071

Cumulative Model Updates: 164,846
Cumulative Timesteps: 1,374,830,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1374830760...
Checkpoint 1374830760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,904.70450
Policy Entropy: 2.98626
Value Function Loss: 0.00455

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.60977
Value Function Update Magnitude: 0.53175

Collected Steps per Second: 22,996.44835
Overall Steps per Second: 10,787.81605

Timestep Collection Time: 2.17451
Timestep Consumption Time: 2.46090
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.63541

Cumulative Model Updates: 164,852
Cumulative Timesteps: 1,374,880,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.80336
Policy Entropy: 2.97679
Value Function Loss: 0.00448

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.62317
Value Function Update Magnitude: 0.55414

Collected Steps per Second: 22,830.63538
Overall Steps per Second: 10,844.98969

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.42077
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.61116

Cumulative Model Updates: 164,858
Cumulative Timesteps: 1,374,930,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1374930774...
Checkpoint 1374930774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,957.65046
Policy Entropy: 2.97871
Value Function Loss: 0.00450

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.62413
Value Function Update Magnitude: 0.54971

Collected Steps per Second: 22,690.57909
Overall Steps per Second: 10,604.52156

Timestep Collection Time: 2.20400
Timestep Consumption Time: 2.51191
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.71591

Cumulative Model Updates: 164,864
Cumulative Timesteps: 1,374,980,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.03319
Policy Entropy: 2.97397
Value Function Loss: 0.00453

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.62409
Value Function Update Magnitude: 0.52771

Collected Steps per Second: 22,807.47111
Overall Steps per Second: 10,825.40534

Timestep Collection Time: 2.19314
Timestep Consumption Time: 2.42747
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.62061

Cumulative Model Updates: 164,870
Cumulative Timesteps: 1,375,030,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1375030804...
Checkpoint 1375030804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.39627
Policy Entropy: 2.99603
Value Function Loss: 0.00452

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.61476
Value Function Update Magnitude: 0.53192

Collected Steps per Second: 22,415.45585
Overall Steps per Second: 10,693.59437

Timestep Collection Time: 2.23114
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.67682

Cumulative Model Updates: 164,876
Cumulative Timesteps: 1,375,080,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.77371
Policy Entropy: 2.99296
Value Function Loss: 0.00464

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.62033
Value Function Update Magnitude: 0.53956

Collected Steps per Second: 23,320.78614
Overall Steps per Second: 10,864.08059

Timestep Collection Time: 2.14478
Timestep Consumption Time: 2.45920
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60398

Cumulative Model Updates: 164,882
Cumulative Timesteps: 1,375,130,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1375130834...
Checkpoint 1375130834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.85738
Policy Entropy: 3.00186
Value Function Loss: 0.00515

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.63597
Value Function Update Magnitude: 0.56719

Collected Steps per Second: 23,166.19408
Overall Steps per Second: 10,726.08959

Timestep Collection Time: 2.15961
Timestep Consumption Time: 2.50472
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.66433

Cumulative Model Updates: 164,888
Cumulative Timesteps: 1,375,180,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.59733
Policy Entropy: 2.99676
Value Function Loss: 0.00523

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.63386
Value Function Update Magnitude: 0.60614

Collected Steps per Second: 22,457.33130
Overall Steps per Second: 10,577.54182

Timestep Collection Time: 2.22733
Timestep Consumption Time: 2.50155
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.72889

Cumulative Model Updates: 164,894
Cumulative Timesteps: 1,375,230,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1375230884...
Checkpoint 1375230884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,982.79640
Policy Entropy: 2.98512
Value Function Loss: 0.00502

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.62349
Value Function Update Magnitude: 0.61736

Collected Steps per Second: 22,485.60877
Overall Steps per Second: 10,685.60055

Timestep Collection Time: 2.22444
Timestep Consumption Time: 2.45643
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.68088

Cumulative Model Updates: 164,900
Cumulative Timesteps: 1,375,280,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.98534
Policy Entropy: 2.98507
Value Function Loss: 0.00462

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.61306
Value Function Update Magnitude: 0.58211

Collected Steps per Second: 22,921.09179
Overall Steps per Second: 10,706.18790

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.67300

Cumulative Model Updates: 164,906
Cumulative Timesteps: 1,375,330,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1375330932...
Checkpoint 1375330932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.10616
Policy Entropy: 2.97114
Value Function Loss: 0.00469

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.59797
Value Function Update Magnitude: 0.55887

Collected Steps per Second: 22,953.23938
Overall Steps per Second: 10,634.52503

Timestep Collection Time: 2.17869
Timestep Consumption Time: 2.52373
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.70242

Cumulative Model Updates: 164,912
Cumulative Timesteps: 1,375,380,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.92875
Policy Entropy: 2.96965
Value Function Loss: 0.00484

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.60617
Value Function Update Magnitude: 0.54842

Collected Steps per Second: 23,515.61609
Overall Steps per Second: 10,895.05064

Timestep Collection Time: 2.12820
Timestep Consumption Time: 2.46526
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.59346

Cumulative Model Updates: 164,918
Cumulative Timesteps: 1,375,430,986

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1375430986...
Checkpoint 1375430986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.55674
Policy Entropy: 2.97447
Value Function Loss: 0.00446

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.60487
Value Function Update Magnitude: 0.53891

Collected Steps per Second: 22,829.42969
Overall Steps per Second: 10,700.16759

Timestep Collection Time: 2.19077
Timestep Consumption Time: 2.48336
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.67413

Cumulative Model Updates: 164,924
Cumulative Timesteps: 1,375,481,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,395.63958
Policy Entropy: 2.99330
Value Function Loss: 0.00412

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.59921
Value Function Update Magnitude: 0.52552

Collected Steps per Second: 23,133.80920
Overall Steps per Second: 10,866.66132

Timestep Collection Time: 2.16194
Timestep Consumption Time: 2.44057
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.60252

Cumulative Model Updates: 164,930
Cumulative Timesteps: 1,375,531,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1375531014...
Checkpoint 1375531014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,235.58100
Policy Entropy: 2.99987
Value Function Loss: 0.00430

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.60176
Value Function Update Magnitude: 0.53706

Collected Steps per Second: 22,971.44263
Overall Steps per Second: 10,681.76739

Timestep Collection Time: 2.17731
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.68237

Cumulative Model Updates: 164,936
Cumulative Timesteps: 1,375,581,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.02685
Policy Entropy: 3.00641
Value Function Loss: 0.00438

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.60426
Value Function Update Magnitude: 0.54986

Collected Steps per Second: 23,022.02617
Overall Steps per Second: 10,824.03659

Timestep Collection Time: 2.17270
Timestep Consumption Time: 2.44849
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.62120

Cumulative Model Updates: 164,942
Cumulative Timesteps: 1,375,631,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1375631050...
Checkpoint 1375631050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490.84723
Policy Entropy: 2.99647
Value Function Loss: 0.00459

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.59863
Value Function Update Magnitude: 0.54943

Collected Steps per Second: 22,956.55517
Overall Steps per Second: 10,735.57445

Timestep Collection Time: 2.17872
Timestep Consumption Time: 2.48018
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.65890

Cumulative Model Updates: 164,948
Cumulative Timesteps: 1,375,681,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,160.49789
Policy Entropy: 3.01338
Value Function Loss: 0.00401

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.58658
Value Function Update Magnitude: 0.52240

Collected Steps per Second: 23,053.46122
Overall Steps per Second: 10,902.06275

Timestep Collection Time: 2.16948
Timestep Consumption Time: 2.41809
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.58757

Cumulative Model Updates: 164,954
Cumulative Timesteps: 1,375,731,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1375731080...
Checkpoint 1375731080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,827.90945
Policy Entropy: 3.00954
Value Function Loss: 0.00411

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.58150
Value Function Update Magnitude: 0.49125

Collected Steps per Second: 22,672.02514
Overall Steps per Second: 10,629.98484

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.70499

Cumulative Model Updates: 164,960
Cumulative Timesteps: 1,375,781,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.53071
Policy Entropy: 3.00354
Value Function Loss: 0.00420

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.59418
Value Function Update Magnitude: 0.51802

Collected Steps per Second: 22,515.16286
Overall Steps per Second: 10,581.20063

Timestep Collection Time: 2.22206
Timestep Consumption Time: 2.50614
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.72820

Cumulative Model Updates: 164,966
Cumulative Timesteps: 1,375,831,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1375831124...
Checkpoint 1375831124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,757.78593
Policy Entropy: 2.97447
Value Function Loss: 0.00470

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.62364
Value Function Update Magnitude: 0.58752

Collected Steps per Second: 22,635.45479
Overall Steps per Second: 10,588.60655

Timestep Collection Time: 2.20919
Timestep Consumption Time: 2.51343
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.72262

Cumulative Model Updates: 164,972
Cumulative Timesteps: 1,375,881,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,457.66020
Policy Entropy: 2.96978
Value Function Loss: 0.00477

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.64313
Value Function Update Magnitude: 0.61838

Collected Steps per Second: 23,265.91881
Overall Steps per Second: 10,795.41315

Timestep Collection Time: 2.14932
Timestep Consumption Time: 2.48283
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.63215

Cumulative Model Updates: 164,978
Cumulative Timesteps: 1,375,931,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1375931136...
Checkpoint 1375931136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.17667
Policy Entropy: 2.97506
Value Function Loss: 0.00479

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.63405
Value Function Update Magnitude: 0.59639

Collected Steps per Second: 23,107.82406
Overall Steps per Second: 10,811.22990

Timestep Collection Time: 2.16515
Timestep Consumption Time: 2.46263
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.62778

Cumulative Model Updates: 164,984
Cumulative Timesteps: 1,375,981,168

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.06837
Policy Entropy: 2.99223
Value Function Loss: 0.00467

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.61887
Value Function Update Magnitude: 0.59285

Collected Steps per Second: 23,673.95777
Overall Steps per Second: 10,842.15161

Timestep Collection Time: 2.11245
Timestep Consumption Time: 2.50011
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.61255

Cumulative Model Updates: 164,990
Cumulative Timesteps: 1,376,031,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1376031178...
Checkpoint 1376031178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677.70389
Policy Entropy: 3.00150
Value Function Loss: 0.00434

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.60293
Value Function Update Magnitude: 0.57627

Collected Steps per Second: 23,210.99512
Overall Steps per Second: 10,915.14209

Timestep Collection Time: 2.15441
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.58134

Cumulative Model Updates: 164,996
Cumulative Timesteps: 1,376,081,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.23072
Policy Entropy: 2.99817
Value Function Loss: 0.00442

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.60135
Value Function Update Magnitude: 0.53268

Collected Steps per Second: 23,263.73254
Overall Steps per Second: 10,977.90329

Timestep Collection Time: 2.14978
Timestep Consumption Time: 2.40591
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.55570

Cumulative Model Updates: 165,002
Cumulative Timesteps: 1,376,131,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1376131196...
Checkpoint 1376131196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.03683
Policy Entropy: 2.98321
Value Function Loss: 0.00477

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.60331
Value Function Update Magnitude: 0.53275

Collected Steps per Second: 23,042.31661
Overall Steps per Second: 10,820.83075

Timestep Collection Time: 2.17018
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.62127

Cumulative Model Updates: 165,008
Cumulative Timesteps: 1,376,181,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.99589
Policy Entropy: 2.96835
Value Function Loss: 0.00498

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.61892
Value Function Update Magnitude: 0.56932

Collected Steps per Second: 22,996.61821
Overall Steps per Second: 10,757.26781

Timestep Collection Time: 2.17432
Timestep Consumption Time: 2.47389
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.64821

Cumulative Model Updates: 165,014
Cumulative Timesteps: 1,376,231,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1376231204...
Checkpoint 1376231204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.76467
Policy Entropy: 2.98440
Value Function Loss: 0.00487

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.62466
Value Function Update Magnitude: 0.58674

Collected Steps per Second: 21,553.74044
Overall Steps per Second: 10,533.01797

Timestep Collection Time: 2.32053
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.74850

Cumulative Model Updates: 165,020
Cumulative Timesteps: 1,376,281,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,915.36839
Policy Entropy: 2.98509
Value Function Loss: 0.00441

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.60812
Value Function Update Magnitude: 0.56733

Collected Steps per Second: 22,627.68353
Overall Steps per Second: 10,597.98960

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.50869
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.71882

Cumulative Model Updates: 165,026
Cumulative Timesteps: 1,376,331,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1376331230...
Checkpoint 1376331230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.05055
Policy Entropy: 3.00713
Value Function Loss: 0.00423

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.58988
Value Function Update Magnitude: 0.52367

Collected Steps per Second: 22,883.42918
Overall Steps per Second: 10,681.02977

Timestep Collection Time: 2.18612
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.68363

Cumulative Model Updates: 165,032
Cumulative Timesteps: 1,376,381,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.09150
Policy Entropy: 3.01500
Value Function Loss: 0.00440

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.59271
Value Function Update Magnitude: 0.52374

Collected Steps per Second: 23,281.50271
Overall Steps per Second: 10,798.72256

Timestep Collection Time: 2.14771
Timestep Consumption Time: 2.48265
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.63036

Cumulative Model Updates: 165,038
Cumulative Timesteps: 1,376,431,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1376431258...
Checkpoint 1376431258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.73047
Policy Entropy: 3.02268
Value Function Loss: 0.00444

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.60280
Value Function Update Magnitude: 0.54587

Collected Steps per Second: 22,877.43956
Overall Steps per Second: 10,632.83685

Timestep Collection Time: 2.18608
Timestep Consumption Time: 2.51746
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.70354

Cumulative Model Updates: 165,044
Cumulative Timesteps: 1,376,481,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,518.88077
Policy Entropy: 3.02993
Value Function Loss: 0.00443

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.60773
Value Function Update Magnitude: 0.53879

Collected Steps per Second: 23,159.82921
Overall Steps per Second: 10,869.58293

Timestep Collection Time: 2.16003
Timestep Consumption Time: 2.44235
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.60238

Cumulative Model Updates: 165,050
Cumulative Timesteps: 1,376,531,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1376531296...
Checkpoint 1376531296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,615.15045
Policy Entropy: 3.01619
Value Function Loss: 0.00465

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.60592
Value Function Update Magnitude: 0.52962

Collected Steps per Second: 22,857.12301
Overall Steps per Second: 10,707.91787

Timestep Collection Time: 2.18855
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.67168

Cumulative Model Updates: 165,056
Cumulative Timesteps: 1,376,581,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,520.19933
Policy Entropy: 3.02846
Value Function Loss: 0.00452

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.15924
Policy Update Magnitude: 0.61261
Value Function Update Magnitude: 0.54927

Collected Steps per Second: 23,525.80754
Overall Steps per Second: 10,862.23738

Timestep Collection Time: 2.12626
Timestep Consumption Time: 2.47887
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.60513

Cumulative Model Updates: 165,062
Cumulative Timesteps: 1,376,631,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1376631342...
Checkpoint 1376631342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,975.10899
Policy Entropy: 3.01423
Value Function Loss: 0.00459

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.16092
Policy Update Magnitude: 0.60835
Value Function Update Magnitude: 0.56524

Collected Steps per Second: 22,901.19724
Overall Steps per Second: 10,635.28052

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.51814
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.70152

Cumulative Model Updates: 165,068
Cumulative Timesteps: 1,376,681,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,502.54646
Policy Entropy: 3.02303
Value Function Loss: 0.00469

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.60905
Value Function Update Magnitude: 0.56045

Collected Steps per Second: 23,265.66088
Overall Steps per Second: 10,919.45719

Timestep Collection Time: 2.15012
Timestep Consumption Time: 2.43106
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.58118

Cumulative Model Updates: 165,074
Cumulative Timesteps: 1,376,731,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1376731368...
Checkpoint 1376731368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.40306
Policy Entropy: 3.01428
Value Function Loss: 0.00492

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.61335
Value Function Update Magnitude: 0.55606

Collected Steps per Second: 22,593.25080
Overall Steps per Second: 10,671.54824

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.47329
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.68723

Cumulative Model Updates: 165,080
Cumulative Timesteps: 1,376,781,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.99844
Policy Entropy: 3.01878
Value Function Loss: 0.00457

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.60513
Value Function Update Magnitude: 0.53403

Collected Steps per Second: 23,123.21660
Overall Steps per Second: 10,863.53219

Timestep Collection Time: 2.16259
Timestep Consumption Time: 2.44052
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60311

Cumulative Model Updates: 165,086
Cumulative Timesteps: 1,376,831,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1376831394...
Checkpoint 1376831394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,285.91723
Policy Entropy: 3.01776
Value Function Loss: 0.00420

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.60349
Value Function Update Magnitude: 0.51066

Collected Steps per Second: 22,329.72712
Overall Steps per Second: 10,736.06439

Timestep Collection Time: 2.23979
Timestep Consumption Time: 2.41871
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.65850

Cumulative Model Updates: 165,092
Cumulative Timesteps: 1,376,881,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,256.99014
Policy Entropy: 3.01265
Value Function Loss: 0.00415

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.59832
Value Function Update Magnitude: 0.51344

Collected Steps per Second: 22,972.97974
Overall Steps per Second: 10,825.30200

Timestep Collection Time: 2.17699
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.61992

Cumulative Model Updates: 165,098
Cumulative Timesteps: 1,376,931,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1376931420...
Checkpoint 1376931420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.11464
Policy Entropy: 2.99065
Value Function Loss: 0.00453

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.61413
Value Function Update Magnitude: 0.52590

Collected Steps per Second: 22,880.16565
Overall Steps per Second: 10,681.63785

Timestep Collection Time: 2.18556
Timestep Consumption Time: 2.49593
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.68149

Cumulative Model Updates: 165,104
Cumulative Timesteps: 1,376,981,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.44487
Policy Entropy: 2.98895
Value Function Loss: 0.00479

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.62377
Value Function Update Magnitude: 0.54184

Collected Steps per Second: 23,480.45278
Overall Steps per Second: 10,897.52371

Timestep Collection Time: 2.13028
Timestep Consumption Time: 2.45975
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.59003

Cumulative Model Updates: 165,110
Cumulative Timesteps: 1,377,031,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1377031446...
Checkpoint 1377031446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,587.95642
Policy Entropy: 2.99363
Value Function Loss: 0.00499

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.62308
Value Function Update Magnitude: 0.55876

Collected Steps per Second: 22,806.05209
Overall Steps per Second: 10,631.01359

Timestep Collection Time: 2.19240
Timestep Consumption Time: 2.51082
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.70322

Cumulative Model Updates: 165,116
Cumulative Timesteps: 1,377,081,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.63847
Policy Entropy: 3.00661
Value Function Loss: 0.00454

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.61004
Value Function Update Magnitude: 0.57734

Collected Steps per Second: 22,984.97575
Overall Steps per Second: 10,680.07885

Timestep Collection Time: 2.17577
Timestep Consumption Time: 2.50678
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.68255

Cumulative Model Updates: 165,122
Cumulative Timesteps: 1,377,131,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1377131456...
Checkpoint 1377131456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.98696
Policy Entropy: 2.99394
Value Function Loss: 0.00478

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.60746
Value Function Update Magnitude: 0.53788

Collected Steps per Second: 23,074.18438
Overall Steps per Second: 10,883.37685

Timestep Collection Time: 2.16779
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.59600

Cumulative Model Updates: 165,128
Cumulative Timesteps: 1,377,181,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.35080
Policy Entropy: 3.00237
Value Function Loss: 0.00449

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.59657
Value Function Update Magnitude: 0.52615

Collected Steps per Second: 23,145.73547
Overall Steps per Second: 10,856.48860

Timestep Collection Time: 2.16066
Timestep Consumption Time: 2.44580
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.60646

Cumulative Model Updates: 165,134
Cumulative Timesteps: 1,377,231,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1377231486...
Checkpoint 1377231486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,052.27447
Policy Entropy: 3.02107
Value Function Loss: 0.00425

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.59471
Value Function Update Magnitude: 0.52719

Collected Steps per Second: 22,230.71222
Overall Steps per Second: 10,685.85527

Timestep Collection Time: 2.25049
Timestep Consumption Time: 2.43140
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.68189

Cumulative Model Updates: 165,140
Cumulative Timesteps: 1,377,281,516

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.12920
Policy Entropy: 3.04760
Value Function Loss: 0.00415

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.59216
Value Function Update Magnitude: 0.53985

Collected Steps per Second: 22,797.33993
Overall Steps per Second: 10,693.30095

Timestep Collection Time: 2.19341
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.67620

Cumulative Model Updates: 165,146
Cumulative Timesteps: 1,377,331,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1377331520...
Checkpoint 1377331520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,054.17405
Policy Entropy: 3.03623
Value Function Loss: 0.00438

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.59623
Value Function Update Magnitude: 0.54501

Collected Steps per Second: 22,396.14584
Overall Steps per Second: 10,800.87690

Timestep Collection Time: 2.23360
Timestep Consumption Time: 2.39788
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.63148

Cumulative Model Updates: 165,152
Cumulative Timesteps: 1,377,381,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.77974
Policy Entropy: 3.02223
Value Function Loss: 0.00445

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.60216
Value Function Update Magnitude: 0.53335

Collected Steps per Second: 22,852.98328
Overall Steps per Second: 10,639.33019

Timestep Collection Time: 2.18869
Timestep Consumption Time: 2.51255
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.70124

Cumulative Model Updates: 165,158
Cumulative Timesteps: 1,377,431,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1377431562...
Checkpoint 1377431562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,369.50939
Policy Entropy: 3.00431
Value Function Loss: 0.00470

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.60519
Value Function Update Magnitude: 0.52758

Collected Steps per Second: 23,078.32936
Overall Steps per Second: 10,679.70535

Timestep Collection Time: 2.16775
Timestep Consumption Time: 2.51665
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.68440

Cumulative Model Updates: 165,164
Cumulative Timesteps: 1,377,481,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,381.33240
Policy Entropy: 3.00237
Value Function Loss: 0.00470

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.61000
Value Function Update Magnitude: 0.55609

Collected Steps per Second: 23,332.04354
Overall Steps per Second: 10,721.07001

Timestep Collection Time: 2.14298
Timestep Consumption Time: 2.52074
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.66371

Cumulative Model Updates: 165,170
Cumulative Timesteps: 1,377,531,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1377531590...
Checkpoint 1377531590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.88775
Policy Entropy: 2.99997
Value Function Loss: 0.00538

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.62193
Value Function Update Magnitude: 0.59684

Collected Steps per Second: 23,043.79547
Overall Steps per Second: 10,807.92223

Timestep Collection Time: 2.17030
Timestep Consumption Time: 2.45704
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.62735

Cumulative Model Updates: 165,176
Cumulative Timesteps: 1,377,581,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.84114
Policy Entropy: 2.99680
Value Function Loss: 0.00516

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.63241
Value Function Update Magnitude: 0.61654

Collected Steps per Second: 23,469.75842
Overall Steps per Second: 10,884.38928

Timestep Collection Time: 2.13074
Timestep Consumption Time: 2.46373
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.59447

Cumulative Model Updates: 165,182
Cumulative Timesteps: 1,377,631,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1377631610...
Checkpoint 1377631610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,548.37434
Policy Entropy: 3.00280
Value Function Loss: 0.00512

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.62504
Value Function Update Magnitude: 0.59785

Collected Steps per Second: 23,043.50202
Overall Steps per Second: 10,900.31142

Timestep Collection Time: 2.17076
Timestep Consumption Time: 2.41828
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.58904

Cumulative Model Updates: 165,188
Cumulative Timesteps: 1,377,681,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.74513
Policy Entropy: 3.01976
Value Function Loss: 0.00448

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.62063
Value Function Update Magnitude: 0.58261

Collected Steps per Second: 23,235.65806
Overall Steps per Second: 10,912.22996

Timestep Collection Time: 2.15264
Timestep Consumption Time: 2.43102
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.58366

Cumulative Model Updates: 165,194
Cumulative Timesteps: 1,377,731,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1377731650...
Checkpoint 1377731650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.05449
Policy Entropy: 3.02104
Value Function Loss: 0.00471

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.60588
Value Function Update Magnitude: 0.56830

Collected Steps per Second: 22,596.65730
Overall Steps per Second: 10,741.77809

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.65565

Cumulative Model Updates: 165,200
Cumulative Timesteps: 1,377,781,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.73521
Policy Entropy: 3.00936
Value Function Loss: 0.00473

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.60446
Value Function Update Magnitude: 0.57897

Collected Steps per Second: 23,074.83475
Overall Steps per Second: 10,856.71153

Timestep Collection Time: 2.16773
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.60729

Cumulative Model Updates: 165,206
Cumulative Timesteps: 1,377,831,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1377831680...
Checkpoint 1377831680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.79828
Policy Entropy: 3.00944
Value Function Loss: 0.00473

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.60458
Value Function Update Magnitude: 0.60814

Collected Steps per Second: 22,252.66965
Overall Steps per Second: 10,655.51737

Timestep Collection Time: 2.24737
Timestep Consumption Time: 2.44597
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.69334

Cumulative Model Updates: 165,212
Cumulative Timesteps: 1,377,881,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,184.83892
Policy Entropy: 3.02237
Value Function Loss: 0.00460

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.60209
Value Function Update Magnitude: 0.61785

Collected Steps per Second: 23,102.14280
Overall Steps per Second: 10,662.27688

Timestep Collection Time: 2.16430
Timestep Consumption Time: 2.52513
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.68943

Cumulative Model Updates: 165,218
Cumulative Timesteps: 1,377,931,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1377931690...
Checkpoint 1377931690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.09772
Policy Entropy: 3.03338
Value Function Loss: 0.00459

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.60136
Value Function Update Magnitude: 0.59124

Collected Steps per Second: 23,110.06404
Overall Steps per Second: 10,852.69821

Timestep Collection Time: 2.16425
Timestep Consumption Time: 2.44437
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60862

Cumulative Model Updates: 165,224
Cumulative Timesteps: 1,377,981,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.29425
Policy Entropy: 3.02034
Value Function Loss: 0.00461

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.59861
Value Function Update Magnitude: 0.55349

Collected Steps per Second: 23,030.13303
Overall Steps per Second: 10,826.73753

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.44723
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.61838

Cumulative Model Updates: 165,230
Cumulative Timesteps: 1,378,031,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1378031708...
Checkpoint 1378031708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.31273
Policy Entropy: 2.99535
Value Function Loss: 0.00461

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.61312
Value Function Update Magnitude: 0.53703

Collected Steps per Second: 23,025.85279
Overall Steps per Second: 10,778.56111

Timestep Collection Time: 2.17260
Timestep Consumption Time: 2.46865
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.64125

Cumulative Model Updates: 165,236
Cumulative Timesteps: 1,378,081,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,266.76489
Policy Entropy: 2.99146
Value Function Loss: 0.00431

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.60465
Value Function Update Magnitude: 0.51866

Collected Steps per Second: 23,164.82029
Overall Steps per Second: 10,876.63372

Timestep Collection Time: 2.15957
Timestep Consumption Time: 2.43983
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.59940

Cumulative Model Updates: 165,242
Cumulative Timesteps: 1,378,131,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1378131760...
Checkpoint 1378131760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.53849
Policy Entropy: 2.99555
Value Function Loss: 0.00408

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.58658
Value Function Update Magnitude: 0.49121

Collected Steps per Second: 23,182.95426
Overall Steps per Second: 10,714.51067

Timestep Collection Time: 2.15719
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.66750

Cumulative Model Updates: 165,248
Cumulative Timesteps: 1,378,181,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,141.63197
Policy Entropy: 3.00889
Value Function Loss: 0.00437

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.59127
Value Function Update Magnitude: 0.49776

Collected Steps per Second: 23,006.45180
Overall Steps per Second: 10,826.11300

Timestep Collection Time: 2.17356
Timestep Consumption Time: 2.44545
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61902

Cumulative Model Updates: 165,254
Cumulative Timesteps: 1,378,231,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1378231776...
Checkpoint 1378231776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.26959
Policy Entropy: 3.00745
Value Function Loss: 0.00471

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.59168
Value Function Update Magnitude: 0.52421

Collected Steps per Second: 22,445.14850
Overall Steps per Second: 10,689.02093

Timestep Collection Time: 2.22774
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.67788

Cumulative Model Updates: 165,260
Cumulative Timesteps: 1,378,281,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.78271
Policy Entropy: 3.01133
Value Function Loss: 0.00464

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.58869
Value Function Update Magnitude: 0.53430

Collected Steps per Second: 23,106.53844
Overall Steps per Second: 10,949.58866

Timestep Collection Time: 2.16501
Timestep Consumption Time: 2.40374
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.56876

Cumulative Model Updates: 165,266
Cumulative Timesteps: 1,378,331,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1378331804...
Checkpoint 1378331804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 815.80990
Policy Entropy: 3.02694
Value Function Loss: 0.00452

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.58682
Value Function Update Magnitude: 0.54153

Collected Steps per Second: 22,848.08013
Overall Steps per Second: 10,606.62897

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.52748
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.71743

Cumulative Model Updates: 165,272
Cumulative Timesteps: 1,378,381,840

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,863.43789
Policy Entropy: 3.03226
Value Function Loss: 0.00413

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.57661
Value Function Update Magnitude: 0.54183

Collected Steps per Second: 23,425.62094
Overall Steps per Second: 10,818.38467

Timestep Collection Time: 2.13493
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.62287

Cumulative Model Updates: 165,278
Cumulative Timesteps: 1,378,431,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1378431852...
Checkpoint 1378431852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.37859
Policy Entropy: 3.03289
Value Function Loss: 0.00437

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.57923
Value Function Update Magnitude: 0.53413

Collected Steps per Second: 22,702.17216
Overall Steps per Second: 10,695.40741

Timestep Collection Time: 2.20314
Timestep Consumption Time: 2.47326
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.67640

Cumulative Model Updates: 165,284
Cumulative Timesteps: 1,378,481,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.63177
Policy Entropy: 3.00701
Value Function Loss: 0.00440

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.58763
Value Function Update Magnitude: 0.53838

Collected Steps per Second: 23,106.36280
Overall Steps per Second: 10,861.33510

Timestep Collection Time: 2.16494
Timestep Consumption Time: 2.44075
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60570

Cumulative Model Updates: 165,290
Cumulative Timesteps: 1,378,531,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1378531892...
Checkpoint 1378531892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164.46547
Policy Entropy: 2.99851
Value Function Loss: 0.00441

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.58727
Value Function Update Magnitude: 0.54802

Collected Steps per Second: 22,860.68609
Overall Steps per Second: 10,707.84995

Timestep Collection Time: 2.18751
Timestep Consumption Time: 2.48271
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.67022

Cumulative Model Updates: 165,296
Cumulative Timesteps: 1,378,581,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,281.52796
Policy Entropy: 3.00772
Value Function Loss: 0.00411

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.57672
Value Function Update Magnitude: 0.54906

Collected Steps per Second: 23,332.44958
Overall Steps per Second: 10,925.00589

Timestep Collection Time: 2.14388
Timestep Consumption Time: 2.43479
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.57867

Cumulative Model Updates: 165,302
Cumulative Timesteps: 1,378,631,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1378631922...
Checkpoint 1378631922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,961.37897
Policy Entropy: 3.01546
Value Function Loss: 0.00416

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.57489
Value Function Update Magnitude: 0.52114

Collected Steps per Second: 22,549.93927
Overall Steps per Second: 10,622.69807

Timestep Collection Time: 2.21810
Timestep Consumption Time: 2.49050
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.70860

Cumulative Model Updates: 165,308
Cumulative Timesteps: 1,378,681,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,790.80484
Policy Entropy: 3.00714
Value Function Loss: 0.00442

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.58179
Value Function Update Magnitude: 0.51499

Collected Steps per Second: 22,918.78164
Overall Steps per Second: 10,838.93716

Timestep Collection Time: 2.18197
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.61374

Cumulative Model Updates: 165,314
Cumulative Timesteps: 1,378,731,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1378731948...
Checkpoint 1378731948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171.86079
Policy Entropy: 3.00639
Value Function Loss: 0.00438

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.58904
Value Function Update Magnitude: 0.52032

Collected Steps per Second: 22,733.99166
Overall Steps per Second: 10,733.88494

Timestep Collection Time: 2.19935
Timestep Consumption Time: 2.45880
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.65815

Cumulative Model Updates: 165,320
Cumulative Timesteps: 1,378,781,948

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,503.74065
Policy Entropy: 3.01022
Value Function Loss: 0.00449

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.59606
Value Function Update Magnitude: 0.52288

Collected Steps per Second: 23,218.79856
Overall Steps per Second: 10,783.58528

Timestep Collection Time: 2.15429
Timestep Consumption Time: 2.48424
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.63853

Cumulative Model Updates: 165,326
Cumulative Timesteps: 1,378,831,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1378831968...
Checkpoint 1378831968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,443.20174
Policy Entropy: 3.00274
Value Function Loss: 0.00447

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.59266
Value Function Update Magnitude: 0.52267

Collected Steps per Second: 22,858.00469
Overall Steps per Second: 10,709.01614

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.48224
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.67027

Cumulative Model Updates: 165,332
Cumulative Timesteps: 1,378,881,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.02507
Policy Entropy: 2.99086
Value Function Loss: 0.00417

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.58664
Value Function Update Magnitude: 0.54356

Collected Steps per Second: 23,417.96245
Overall Steps per Second: 10,961.07626

Timestep Collection Time: 2.13571
Timestep Consumption Time: 2.42716
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.56287

Cumulative Model Updates: 165,338
Cumulative Timesteps: 1,378,931,996

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1378931996...
Checkpoint 1378931996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817.84832
Policy Entropy: 2.98204
Value Function Loss: 0.00466

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.59280
Value Function Update Magnitude: 0.55128

Collected Steps per Second: 23,110.88162
Overall Steps per Second: 10,737.23172

Timestep Collection Time: 2.16366
Timestep Consumption Time: 2.49341
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.65707

Cumulative Model Updates: 165,344
Cumulative Timesteps: 1,378,982,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.46198
Policy Entropy: 2.98832
Value Function Loss: 0.00447

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.60075
Value Function Update Magnitude: 0.54710

Collected Steps per Second: 23,325.28724
Overall Steps per Second: 10,763.92229

Timestep Collection Time: 2.14394
Timestep Consumption Time: 2.50195
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.64589

Cumulative Model Updates: 165,350
Cumulative Timesteps: 1,379,032,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1379032008...
Checkpoint 1379032008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,432.40550
Policy Entropy: 2.99651
Value Function Loss: 0.00433

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.59018
Value Function Update Magnitude: 0.53138

Collected Steps per Second: 21,716.34706
Overall Steps per Second: 10,345.87061

Timestep Collection Time: 2.30269
Timestep Consumption Time: 2.53074
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.83343

Cumulative Model Updates: 165,356
Cumulative Timesteps: 1,379,082,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015.15877
Policy Entropy: 2.99329
Value Function Loss: 0.00394

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.58714
Value Function Update Magnitude: 0.51781

Collected Steps per Second: 22,790.98133
Overall Steps per Second: 10,798.59033

Timestep Collection Time: 2.19394
Timestep Consumption Time: 2.43648
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.63042

Cumulative Model Updates: 165,362
Cumulative Timesteps: 1,379,132,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1379132016...
Checkpoint 1379132016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,333.73717
Policy Entropy: 3.00373
Value Function Loss: 0.00420

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.59944
Value Function Update Magnitude: 0.51389

Collected Steps per Second: 22,327.70548
Overall Steps per Second: 10,599.74634

Timestep Collection Time: 2.24000
Timestep Consumption Time: 2.47842
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.71841

Cumulative Model Updates: 165,368
Cumulative Timesteps: 1,379,182,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,670.86032
Policy Entropy: 3.00006
Value Function Loss: 0.00443

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.60755
Value Function Update Magnitude: 0.53026

Collected Steps per Second: 23,265.69522
Overall Steps per Second: 10,912.30514

Timestep Collection Time: 2.14995
Timestep Consumption Time: 2.43387
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.58382

Cumulative Model Updates: 165,374
Cumulative Timesteps: 1,379,232,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1379232050...
Checkpoint 1379232050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,699.42556
Policy Entropy: 2.99743
Value Function Loss: 0.00443

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.59812
Value Function Update Magnitude: 0.52102

Collected Steps per Second: 22,914.65674
Overall Steps per Second: 10,647.72466

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.51463
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.69734

Cumulative Model Updates: 165,380
Cumulative Timesteps: 1,379,282,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.24714
Policy Entropy: 2.98890
Value Function Loss: 0.00452

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.60032
Value Function Update Magnitude: 0.52148

Collected Steps per Second: 23,314.42231
Overall Steps per Second: 10,920.59345

Timestep Collection Time: 2.14554
Timestep Consumption Time: 2.43498
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.58052

Cumulative Model Updates: 165,386
Cumulative Timesteps: 1,379,332,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1379332088...
Checkpoint 1379332088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,083.22833
Policy Entropy: 2.97542
Value Function Loss: 0.00440

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.60152
Value Function Update Magnitude: 0.53444

Collected Steps per Second: 23,215.20036
Overall Steps per Second: 10,757.64303

Timestep Collection Time: 2.15462
Timestep Consumption Time: 2.49509
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.64972

Cumulative Model Updates: 165,392
Cumulative Timesteps: 1,379,382,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,116.22096
Policy Entropy: 2.97565
Value Function Loss: 0.00436

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.59783
Value Function Update Magnitude: 0.53781

Collected Steps per Second: 23,116.19574
Overall Steps per Second: 10,796.70784

Timestep Collection Time: 2.16359
Timestep Consumption Time: 2.46875
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.63234

Cumulative Model Updates: 165,398
Cumulative Timesteps: 1,379,432,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1379432122...
Checkpoint 1379432122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748.01354
Policy Entropy: 2.97639
Value Function Loss: 0.00420

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.59693
Value Function Update Magnitude: 0.53784

Collected Steps per Second: 23,069.30027
Overall Steps per Second: 10,668.90765

Timestep Collection Time: 2.16738
Timestep Consumption Time: 2.51913
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.68652

Cumulative Model Updates: 165,404
Cumulative Timesteps: 1,379,482,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,118.19165
Policy Entropy: 2.98280
Value Function Loss: 0.00410

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.58785
Value Function Update Magnitude: 0.51659

Collected Steps per Second: 22,971.74535
Overall Steps per Second: 10,845.27792

Timestep Collection Time: 2.17659
Timestep Consumption Time: 2.43371
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.61030

Cumulative Model Updates: 165,410
Cumulative Timesteps: 1,379,532,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1379532122...
Checkpoint 1379532122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210.08557
Policy Entropy: 2.98379
Value Function Loss: 0.00394

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.58244
Value Function Update Magnitude: 0.49059

Collected Steps per Second: 22,781.61402
Overall Steps per Second: 10,682.31794

Timestep Collection Time: 2.19484
Timestep Consumption Time: 2.48598
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.68082

Cumulative Model Updates: 165,416
Cumulative Timesteps: 1,379,582,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,589.83403
Policy Entropy: 2.98016
Value Function Loss: 0.00406

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.58506
Value Function Update Magnitude: 0.48329

Collected Steps per Second: 22,649.81151
Overall Steps per Second: 10,641.65712

Timestep Collection Time: 2.20850
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.70058

Cumulative Model Updates: 165,422
Cumulative Timesteps: 1,379,632,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1379632146...
Checkpoint 1379632146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.27004
Policy Entropy: 2.96737
Value Function Loss: 0.00436

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11254
Policy Update Magnitude: 0.60605
Value Function Update Magnitude: 0.52050

Collected Steps per Second: 22,758.95503
Overall Steps per Second: 10,810.89589

Timestep Collection Time: 2.19703
Timestep Consumption Time: 2.42812
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.62515

Cumulative Model Updates: 165,428
Cumulative Timesteps: 1,379,682,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.18417
Policy Entropy: 2.96513
Value Function Loss: 0.00457

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.61459
Value Function Update Magnitude: 0.56132

Collected Steps per Second: 22,563.94030
Overall Steps per Second: 10,522.25785

Timestep Collection Time: 2.21610
Timestep Consumption Time: 2.53611
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.75221

Cumulative Model Updates: 165,434
Cumulative Timesteps: 1,379,732,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1379732152...
Checkpoint 1379732152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,131.06651
Policy Entropy: 2.96581
Value Function Loss: 0.00458

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.61660
Value Function Update Magnitude: 0.57575

Collected Steps per Second: 22,990.89815
Overall Steps per Second: 10,678.59007

Timestep Collection Time: 2.17547
Timestep Consumption Time: 2.50829
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.68376

Cumulative Model Updates: 165,440
Cumulative Timesteps: 1,379,782,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,614.22163
Policy Entropy: 2.96807
Value Function Loss: 0.00439

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.60267
Value Function Update Magnitude: 0.57114

Collected Steps per Second: 22,888.50959
Overall Steps per Second: 10,767.56789

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.64376

Cumulative Model Updates: 165,446
Cumulative Timesteps: 1,379,832,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1379832170...
Checkpoint 1379832170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.84544
Policy Entropy: 2.96542
Value Function Loss: 0.00459

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.61186
Value Function Update Magnitude: 0.57305

Collected Steps per Second: 23,177.74903
Overall Steps per Second: 10,776.55857

Timestep Collection Time: 2.15733
Timestep Consumption Time: 2.48256
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.63989

Cumulative Model Updates: 165,452
Cumulative Timesteps: 1,379,882,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,107.79606
Policy Entropy: 2.97055
Value Function Loss: 0.00438

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.61525
Value Function Update Magnitude: 0.56309

Collected Steps per Second: 23,492.99004
Overall Steps per Second: 10,865.31958

Timestep Collection Time: 2.12846
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.60217

Cumulative Model Updates: 165,458
Cumulative Timesteps: 1,379,932,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1379932176...
Checkpoint 1379932176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.48822
Policy Entropy: 2.97760
Value Function Loss: 0.00429

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.60506
Value Function Update Magnitude: 0.55833

Collected Steps per Second: 23,183.86994
Overall Steps per Second: 10,767.70917

Timestep Collection Time: 2.15788
Timestep Consumption Time: 2.48823
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.64611

Cumulative Model Updates: 165,464
Cumulative Timesteps: 1,379,982,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.42876
Policy Entropy: 2.98050
Value Function Loss: 0.00440

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.60978
Value Function Update Magnitude: 0.54002

Collected Steps per Second: 23,242.23726
Overall Steps per Second: 10,778.92100

Timestep Collection Time: 2.15194
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.64017

Cumulative Model Updates: 165,470
Cumulative Timesteps: 1,380,032,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1380032220...
Checkpoint 1380032220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.87874
Policy Entropy: 2.98257
Value Function Loss: 0.00456

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.61261
Value Function Update Magnitude: 0.54772

Collected Steps per Second: 22,551.75981
Overall Steps per Second: 10,662.49463

Timestep Collection Time: 2.21757
Timestep Consumption Time: 2.47271
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.69027

Cumulative Model Updates: 165,476
Cumulative Timesteps: 1,380,082,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,436.52737
Policy Entropy: 2.98995
Value Function Loss: 0.00447

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.60594
Value Function Update Magnitude: 0.54253

Collected Steps per Second: 22,403.84817
Overall Steps per Second: 10,530.33689

Timestep Collection Time: 2.23283
Timestep Consumption Time: 2.51763
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.75047

Cumulative Model Updates: 165,482
Cumulative Timesteps: 1,380,132,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1380132254...
Checkpoint 1380132254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885.08042
Policy Entropy: 2.99389
Value Function Loss: 0.00446

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.60294
Value Function Update Magnitude: 0.52314

Collected Steps per Second: 22,662.85254
Overall Steps per Second: 10,610.83713

Timestep Collection Time: 2.20661
Timestep Consumption Time: 2.50631
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.71292

Cumulative Model Updates: 165,488
Cumulative Timesteps: 1,380,182,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.39334
Policy Entropy: 2.99473
Value Function Loss: 0.00457

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.60948
Value Function Update Magnitude: 0.52352

Collected Steps per Second: 22,839.88819
Overall Steps per Second: 10,889.52309

Timestep Collection Time: 2.19012
Timestep Consumption Time: 2.40347
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.59359

Cumulative Model Updates: 165,494
Cumulative Timesteps: 1,380,232,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1380232284...
Checkpoint 1380232284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.19139
Policy Entropy: 2.98983
Value Function Loss: 0.00463

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.60183
Value Function Update Magnitude: 0.53070

Collected Steps per Second: 22,666.73349
Overall Steps per Second: 10,593.80860

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.72163

Cumulative Model Updates: 165,500
Cumulative Timesteps: 1,380,282,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,105.58539
Policy Entropy: 2.99900
Value Function Loss: 0.00493

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.61249
Value Function Update Magnitude: 0.55027

Collected Steps per Second: 23,227.36961
Overall Steps per Second: 10,839.20531

Timestep Collection Time: 2.15263
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61288

Cumulative Model Updates: 165,506
Cumulative Timesteps: 1,380,332,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1380332304...
Checkpoint 1380332304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.61859
Policy Entropy: 2.99183
Value Function Loss: 0.00478

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.62048
Value Function Update Magnitude: 0.57074

Collected Steps per Second: 23,244.82888
Overall Steps per Second: 10,723.40917

Timestep Collection Time: 2.15239
Timestep Consumption Time: 2.51329
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.66568

Cumulative Model Updates: 165,512
Cumulative Timesteps: 1,380,382,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.35265
Policy Entropy: 2.97822
Value Function Loss: 0.00482

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.62303
Value Function Update Magnitude: 0.55434

Collected Steps per Second: 23,076.77405
Overall Steps per Second: 10,930.85537

Timestep Collection Time: 2.16789
Timestep Consumption Time: 2.40888
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.57677

Cumulative Model Updates: 165,518
Cumulative Timesteps: 1,380,432,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1380432364...
Checkpoint 1380432364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.62318
Policy Entropy: 2.97298
Value Function Loss: 0.00454

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.61466
Value Function Update Magnitude: 0.52715

Collected Steps per Second: 22,842.40363
Overall Steps per Second: 10,645.51485

Timestep Collection Time: 2.18891
Timestep Consumption Time: 2.50790
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.69681

Cumulative Model Updates: 165,524
Cumulative Timesteps: 1,380,482,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,852.31361
Policy Entropy: 2.96328
Value Function Loss: 0.00449

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.61587
Value Function Update Magnitude: 0.51808

Collected Steps per Second: 23,548.67143
Overall Steps per Second: 10,894.42905

Timestep Collection Time: 2.12428
Timestep Consumption Time: 2.46742
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.59170

Cumulative Model Updates: 165,530
Cumulative Timesteps: 1,380,532,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1380532388...
Checkpoint 1380532388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.77685
Policy Entropy: 2.94752
Value Function Loss: 0.00435

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.61297
Value Function Update Magnitude: 0.50902

Collected Steps per Second: 23,160.73979
Overall Steps per Second: 10,849.87514

Timestep Collection Time: 2.15917
Timestep Consumption Time: 2.44991
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.60909

Cumulative Model Updates: 165,536
Cumulative Timesteps: 1,380,582,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,492.91332
Policy Entropy: 2.95038
Value Function Loss: 0.00426

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.60588
Value Function Update Magnitude: 0.51668

Collected Steps per Second: 22,534.55735
Overall Steps per Second: 10,666.78429

Timestep Collection Time: 2.21935
Timestep Consumption Time: 2.46923
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.68857

Cumulative Model Updates: 165,542
Cumulative Timesteps: 1,380,632,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1380632408...
Checkpoint 1380632408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,060.81114
Policy Entropy: 2.95377
Value Function Loss: 0.00426

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.60287
Value Function Update Magnitude: 0.51911

Collected Steps per Second: 22,705.94848
Overall Steps per Second: 10,678.38413

Timestep Collection Time: 2.20321
Timestep Consumption Time: 2.48158
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.68479

Cumulative Model Updates: 165,548
Cumulative Timesteps: 1,380,682,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.01142
Policy Entropy: 2.95097
Value Function Loss: 0.00443

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.61165
Value Function Update Magnitude: 0.51000

Collected Steps per Second: 22,937.40214
Overall Steps per Second: 10,867.12881

Timestep Collection Time: 2.18002
Timestep Consumption Time: 2.42138
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60140

Cumulative Model Updates: 165,554
Cumulative Timesteps: 1,380,732,438

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1380732438...
Checkpoint 1380732438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,495.40215
Policy Entropy: 2.95005
Value Function Loss: 0.00455

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.61474
Value Function Update Magnitude: 0.52132

Collected Steps per Second: 22,609.87302
Overall Steps per Second: 10,688.61121

Timestep Collection Time: 2.21142
Timestep Consumption Time: 2.46645
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.67788

Cumulative Model Updates: 165,560
Cumulative Timesteps: 1,380,782,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.93687
Policy Entropy: 2.95206
Value Function Loss: 0.00453

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.61120
Value Function Update Magnitude: 0.51420

Collected Steps per Second: 23,184.46915
Overall Steps per Second: 10,846.78917

Timestep Collection Time: 2.15765
Timestep Consumption Time: 2.45422
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.61187

Cumulative Model Updates: 165,566
Cumulative Timesteps: 1,380,832,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1380832462...
Checkpoint 1380832462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.28256
Policy Entropy: 2.96297
Value Function Loss: 0.00422

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.60212
Value Function Update Magnitude: 0.52389

Collected Steps per Second: 23,125.76597
Overall Steps per Second: 10,705.32873

Timestep Collection Time: 2.16287
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.67225

Cumulative Model Updates: 165,572
Cumulative Timesteps: 1,380,882,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.47851
Policy Entropy: 2.95960
Value Function Loss: 0.00435

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.60806
Value Function Update Magnitude: 0.54336

Collected Steps per Second: 22,970.59996
Overall Steps per Second: 10,915.71835

Timestep Collection Time: 2.17678
Timestep Consumption Time: 2.40395
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.58073

Cumulative Model Updates: 165,578
Cumulative Timesteps: 1,380,932,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1380932482...
Checkpoint 1380932482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.03649
Policy Entropy: 2.95597
Value Function Loss: 0.00439

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.61896
Value Function Update Magnitude: 0.54716

Collected Steps per Second: 23,168.31557
Overall Steps per Second: 10,934.42835

Timestep Collection Time: 2.15855
Timestep Consumption Time: 2.41508
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.57363

Cumulative Model Updates: 165,584
Cumulative Timesteps: 1,380,982,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,275.69970
Policy Entropy: 2.95800
Value Function Loss: 0.00432

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.60934
Value Function Update Magnitude: 0.54028

Collected Steps per Second: 22,814.59505
Overall Steps per Second: 10,623.56144

Timestep Collection Time: 2.19289
Timestep Consumption Time: 2.51645
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.70934

Cumulative Model Updates: 165,590
Cumulative Timesteps: 1,381,032,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1381032522...
Checkpoint 1381032522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,363.69649
Policy Entropy: 2.95874
Value Function Loss: 0.00440

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.60486
Value Function Update Magnitude: 0.53925

Collected Steps per Second: 23,073.35246
Overall Steps per Second: 10,738.79777

Timestep Collection Time: 2.16770
Timestep Consumption Time: 2.48981
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.65750

Cumulative Model Updates: 165,596
Cumulative Timesteps: 1,381,082,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.86221
Policy Entropy: 2.94204
Value Function Loss: 0.00520

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.62458
Value Function Update Magnitude: 0.55157

Collected Steps per Second: 22,794.77380
Overall Steps per Second: 10,776.28252

Timestep Collection Time: 2.19427
Timestep Consumption Time: 2.44721
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.64149

Cumulative Model Updates: 165,602
Cumulative Timesteps: 1,381,132,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1381132556...
Checkpoint 1381132556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,583.52012
Policy Entropy: 2.95467
Value Function Loss: 0.00517

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.63319
Value Function Update Magnitude: 0.56007

Collected Steps per Second: 22,569.87546
Overall Steps per Second: 10,636.52619

Timestep Collection Time: 2.21658
Timestep Consumption Time: 2.48683
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.70342

Cumulative Model Updates: 165,608
Cumulative Timesteps: 1,381,182,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.57165
Policy Entropy: 2.95242
Value Function Loss: 0.00506

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.62875
Value Function Update Magnitude: 0.53477

Collected Steps per Second: 22,539.24049
Overall Steps per Second: 10,617.43094

Timestep Collection Time: 2.21844
Timestep Consumption Time: 2.49098
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.70943

Cumulative Model Updates: 165,614
Cumulative Timesteps: 1,381,232,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1381232586...
Checkpoint 1381232586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,553.55945
Policy Entropy: 2.97042
Value Function Loss: 0.00472

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.61592
Value Function Update Magnitude: 0.53937

Collected Steps per Second: 22,871.82409
Overall Steps per Second: 10,862.17340

Timestep Collection Time: 2.18697
Timestep Consumption Time: 2.41800
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60497

Cumulative Model Updates: 165,620
Cumulative Timesteps: 1,381,282,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.97405
Policy Entropy: 2.97524
Value Function Loss: 0.00442

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.60192
Value Function Update Magnitude: 0.54360

Collected Steps per Second: 23,110.76454
Overall Steps per Second: 10,571.14022

Timestep Collection Time: 2.16419
Timestep Consumption Time: 2.56719
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.73137

Cumulative Model Updates: 165,626
Cumulative Timesteps: 1,381,332,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1381332622...
Checkpoint 1381332622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,097.88839
Policy Entropy: 2.99039
Value Function Loss: 0.00426

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.58958
Value Function Update Magnitude: 0.53147

Collected Steps per Second: 22,907.53417
Overall Steps per Second: 10,736.00294

Timestep Collection Time: 2.18382
Timestep Consumption Time: 2.47583
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.65965

Cumulative Model Updates: 165,632
Cumulative Timesteps: 1,381,382,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.01007
Policy Entropy: 2.98694
Value Function Loss: 0.00461

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.59710
Value Function Update Magnitude: 0.53260

Collected Steps per Second: 23,373.26640
Overall Steps per Second: 10,811.54775

Timestep Collection Time: 2.14022
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.62690

Cumulative Model Updates: 165,638
Cumulative Timesteps: 1,381,432,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1381432672...
Checkpoint 1381432672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.00386
Policy Entropy: 2.98191
Value Function Loss: 0.00451

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.60599
Value Function Update Magnitude: 0.54122

Collected Steps per Second: 23,139.87911
Overall Steps per Second: 10,784.19804

Timestep Collection Time: 2.16112
Timestep Consumption Time: 2.47604
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.63716

Cumulative Model Updates: 165,644
Cumulative Timesteps: 1,381,482,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,270.80229
Policy Entropy: 2.97252
Value Function Loss: 0.00451

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.60805
Value Function Update Magnitude: 0.53403

Collected Steps per Second: 23,354.90978
Overall Steps per Second: 10,778.57279

Timestep Collection Time: 2.14268
Timestep Consumption Time: 2.50005
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.64273

Cumulative Model Updates: 165,650
Cumulative Timesteps: 1,381,532,722

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1381532722...
Checkpoint 1381532722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,380.45156
Policy Entropy: 2.98026
Value Function Loss: 0.00418

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.59996
Value Function Update Magnitude: 0.52464

Collected Steps per Second: 22,618.11487
Overall Steps per Second: 10,691.39376

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.46614
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.67685

Cumulative Model Updates: 165,656
Cumulative Timesteps: 1,381,582,724

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,230.13999
Policy Entropy: 2.99645
Value Function Loss: 0.00420

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.58982
Value Function Update Magnitude: 0.51747

Collected Steps per Second: 23,045.77321
Overall Steps per Second: 10,767.80884

Timestep Collection Time: 2.17038
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.64514

Cumulative Model Updates: 165,662
Cumulative Timesteps: 1,381,632,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1381632742...
Checkpoint 1381632742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.34666
Policy Entropy: 2.99648
Value Function Loss: 0.00422

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.58782
Value Function Update Magnitude: 0.51434

Collected Steps per Second: 22,777.37062
Overall Steps per Second: 10,642.31635

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70142

Cumulative Model Updates: 165,668
Cumulative Timesteps: 1,381,682,776

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.34255
Policy Entropy: 2.99684
Value Function Loss: 0.00424

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.58414
Value Function Update Magnitude: 0.50119

Collected Steps per Second: 22,579.21153
Overall Steps per Second: 10,621.81942

Timestep Collection Time: 2.21522
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.70899

Cumulative Model Updates: 165,674
Cumulative Timesteps: 1,381,732,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1381732794...
Checkpoint 1381732794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.85065
Policy Entropy: 3.00667
Value Function Loss: 0.00400

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.57958
Value Function Update Magnitude: 0.50104

Collected Steps per Second: 22,872.80596
Overall Steps per Second: 10,699.47085

Timestep Collection Time: 2.18705
Timestep Consumption Time: 2.48832
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.67537

Cumulative Model Updates: 165,680
Cumulative Timesteps: 1,381,782,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.26912
Policy Entropy: 3.00477
Value Function Loss: 0.00386

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.57121
Value Function Update Magnitude: 0.48330

Collected Steps per Second: 23,408.09815
Overall Steps per Second: 10,834.76076

Timestep Collection Time: 2.13661
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.61607

Cumulative Model Updates: 165,686
Cumulative Timesteps: 1,381,832,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1381832832...
Checkpoint 1381832832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.81030
Policy Entropy: 3.00383
Value Function Loss: 0.00391

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.57176
Value Function Update Magnitude: 0.47329

Collected Steps per Second: 23,390.22351
Overall Steps per Second: 10,954.92183

Timestep Collection Time: 2.13850
Timestep Consumption Time: 2.42748
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.56598

Cumulative Model Updates: 165,692
Cumulative Timesteps: 1,381,882,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.91522
Policy Entropy: 2.99650
Value Function Loss: 0.00399

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.57754
Value Function Update Magnitude: 0.47477

Collected Steps per Second: 23,067.30064
Overall Steps per Second: 10,855.40279

Timestep Collection Time: 2.16809
Timestep Consumption Time: 2.43902
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60711

Cumulative Model Updates: 165,698
Cumulative Timesteps: 1,381,932,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1381932864...
Checkpoint 1381932864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,545.13964
Policy Entropy: 2.99346
Value Function Loss: 0.00414

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.58977
Value Function Update Magnitude: 0.50665

Collected Steps per Second: 23,019.54880
Overall Steps per Second: 10,662.33963

Timestep Collection Time: 2.17207
Timestep Consumption Time: 2.51734
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.68940

Cumulative Model Updates: 165,704
Cumulative Timesteps: 1,381,982,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.19846
Policy Entropy: 2.99473
Value Function Loss: 0.00416

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.59683
Value Function Update Magnitude: 0.52176

Collected Steps per Second: 23,217.42898
Overall Steps per Second: 10,963.35319

Timestep Collection Time: 2.15364
Timestep Consumption Time: 2.40719
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.56083

Cumulative Model Updates: 165,710
Cumulative Timesteps: 1,382,032,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1382032866...
Checkpoint 1382032866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,382.42795
Policy Entropy: 2.98289
Value Function Loss: 0.00453

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.13599
Policy Update Magnitude: 0.60671
Value Function Update Magnitude: 0.52964

Collected Steps per Second: 22,802.26644
Overall Steps per Second: 10,611.79607

Timestep Collection Time: 2.19373
Timestep Consumption Time: 2.52008
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.71381

Cumulative Model Updates: 165,716
Cumulative Timesteps: 1,382,082,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.90067
Policy Entropy: 2.99507
Value Function Loss: 0.00486

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.60778
Value Function Update Magnitude: 0.54729

Collected Steps per Second: 22,979.02861
Overall Steps per Second: 10,832.31600

Timestep Collection Time: 2.17729
Timestep Consumption Time: 2.44148
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.61877

Cumulative Model Updates: 165,722
Cumulative Timesteps: 1,382,132,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1382132920...
Checkpoint 1382132920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,581.34255
Policy Entropy: 3.00046
Value Function Loss: 0.00493

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.60005
Value Function Update Magnitude: 0.55539

Collected Steps per Second: 22,671.59296
Overall Steps per Second: 10,749.50066

Timestep Collection Time: 2.20629
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.65324

Cumulative Model Updates: 165,728
Cumulative Timesteps: 1,382,182,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,819.74753
Policy Entropy: 3.01352
Value Function Loss: 0.00469

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.59792
Value Function Update Magnitude: 0.53954

Collected Steps per Second: 22,402.16531
Overall Steps per Second: 10,655.42495

Timestep Collection Time: 2.23273
Timestep Consumption Time: 2.46140
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.69413

Cumulative Model Updates: 165,734
Cumulative Timesteps: 1,382,232,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1382232958...
Checkpoint 1382232958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.79121
Policy Entropy: 3.00484
Value Function Loss: 0.00470

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.60212
Value Function Update Magnitude: 0.54477

Collected Steps per Second: 23,149.18557
Overall Steps per Second: 10,855.58723

Timestep Collection Time: 2.15990
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.60592

Cumulative Model Updates: 165,740
Cumulative Timesteps: 1,382,282,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.96718
Policy Entropy: 3.00959
Value Function Loss: 0.00428

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.59507
Value Function Update Magnitude: 0.53930

Collected Steps per Second: 22,971.34853
Overall Steps per Second: 10,653.59280

Timestep Collection Time: 2.17662
Timestep Consumption Time: 2.51663
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69325

Cumulative Model Updates: 165,746
Cumulative Timesteps: 1,382,332,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1382332958...
Checkpoint 1382332958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.90972
Policy Entropy: 3.01403
Value Function Loss: 0.00407

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.58142
Value Function Update Magnitude: 0.49988

Collected Steps per Second: 23,451.55021
Overall Steps per Second: 10,917.17835

Timestep Collection Time: 2.13214
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.58012

Cumulative Model Updates: 165,752
Cumulative Timesteps: 1,382,382,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,615.63054
Policy Entropy: 3.02111
Value Function Loss: 0.00391

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.57376
Value Function Update Magnitude: 0.48713

Collected Steps per Second: 23,109.14184
Overall Steps per Second: 10,935.32527

Timestep Collection Time: 2.16365
Timestep Consumption Time: 2.40869
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.57234

Cumulative Model Updates: 165,758
Cumulative Timesteps: 1,382,432,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1382432960...
Checkpoint 1382432960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,572.50484
Policy Entropy: 3.01877
Value Function Loss: 0.00427

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.57927
Value Function Update Magnitude: 0.49999

Collected Steps per Second: 23,137.67639
Overall Steps per Second: 10,757.68122

Timestep Collection Time: 2.16124
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.64840

Cumulative Model Updates: 165,764
Cumulative Timesteps: 1,382,482,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,671.73660
Policy Entropy: 3.00728
Value Function Loss: 0.00478

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.59788
Value Function Update Magnitude: 0.52849

Collected Steps per Second: 22,974.17360
Overall Steps per Second: 10,735.12367

Timestep Collection Time: 2.17644
Timestep Consumption Time: 2.48135
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.65779

Cumulative Model Updates: 165,770
Cumulative Timesteps: 1,382,532,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1382532968...
Checkpoint 1382532968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.49223
Policy Entropy: 3.00434
Value Function Loss: 0.00468

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.59804
Value Function Update Magnitude: 0.53291

Collected Steps per Second: 23,004.48258
Overall Steps per Second: 10,778.17575

Timestep Collection Time: 2.17384
Timestep Consumption Time: 2.46591
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.63975

Cumulative Model Updates: 165,776
Cumulative Timesteps: 1,382,582,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,884.55951
Policy Entropy: 3.01007
Value Function Loss: 0.00456

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10573
Policy Update Magnitude: 0.59226
Value Function Update Magnitude: 0.51674

Collected Steps per Second: 22,766.14382
Overall Steps per Second: 10,773.08678

Timestep Collection Time: 2.19730
Timestep Consumption Time: 2.44613
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.64342

Cumulative Model Updates: 165,782
Cumulative Timesteps: 1,382,633,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1382633000...
Checkpoint 1382633000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,950.18536
Policy Entropy: 3.00683
Value Function Loss: 0.00457

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.59542
Value Function Update Magnitude: 0.51045

Collected Steps per Second: 22,503.31064
Overall Steps per Second: 10,630.30034

Timestep Collection Time: 2.22261
Timestep Consumption Time: 2.48243
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.70504

Cumulative Model Updates: 165,788
Cumulative Timesteps: 1,382,683,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.60119
Policy Entropy: 3.00781
Value Function Loss: 0.00450

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.59149
Value Function Update Magnitude: 0.51070

Collected Steps per Second: 22,352.29527
Overall Steps per Second: 10,641.17347

Timestep Collection Time: 2.23744
Timestep Consumption Time: 2.46241
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.69986

Cumulative Model Updates: 165,794
Cumulative Timesteps: 1,382,733,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1382733028...
Checkpoint 1382733028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.43801
Policy Entropy: 2.99833
Value Function Loss: 0.00452

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.59542
Value Function Update Magnitude: 0.51657

Collected Steps per Second: 22,780.84931
Overall Steps per Second: 10,832.42735

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.61799

Cumulative Model Updates: 165,800
Cumulative Timesteps: 1,382,783,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,112.99741
Policy Entropy: 3.00691
Value Function Loss: 0.00435

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.59423
Value Function Update Magnitude: 0.51020

Collected Steps per Second: 22,888.82468
Overall Steps per Second: 10,497.34923

Timestep Collection Time: 2.18508
Timestep Consumption Time: 2.57936
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.76444

Cumulative Model Updates: 165,806
Cumulative Timesteps: 1,382,833,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1382833066...
Checkpoint 1382833066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.41152
Policy Entropy: 3.00309
Value Function Loss: 0.00452

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.60213
Value Function Update Magnitude: 0.51296

Collected Steps per Second: 23,240.54682
Overall Steps per Second: 10,787.14166

Timestep Collection Time: 2.15176
Timestep Consumption Time: 2.48413
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.63589

Cumulative Model Updates: 165,812
Cumulative Timesteps: 1,382,883,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,473.95588
Policy Entropy: 3.00411
Value Function Loss: 0.00461

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.60927
Value Function Update Magnitude: 0.51894

Collected Steps per Second: 21,797.17945
Overall Steps per Second: 10,413.68842

Timestep Collection Time: 2.29443
Timestep Consumption Time: 2.50810
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.80253

Cumulative Model Updates: 165,818
Cumulative Timesteps: 1,382,933,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1382933086...
Checkpoint 1382933086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.07617
Policy Entropy: 2.98994
Value Function Loss: 0.00496

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.62440
Value Function Update Magnitude: 0.54651

Collected Steps per Second: 22,701.81456
Overall Steps per Second: 10,712.90367

Timestep Collection Time: 2.20344
Timestep Consumption Time: 2.46589
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.66932

Cumulative Model Updates: 165,824
Cumulative Timesteps: 1,382,983,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.94257
Policy Entropy: 2.98620
Value Function Loss: 0.00488

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.62323
Value Function Update Magnitude: 0.56971

Collected Steps per Second: 22,836.24105
Overall Steps per Second: 10,768.50831

Timestep Collection Time: 2.19038
Timestep Consumption Time: 2.45465
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.64503

Cumulative Model Updates: 165,830
Cumulative Timesteps: 1,383,033,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1383033128...
Checkpoint 1383033128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.64015
Policy Entropy: 2.98598
Value Function Loss: 0.00479

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11896
Policy Update Magnitude: 0.61990
Value Function Update Magnitude: 0.54653

Collected Steps per Second: 23,066.42824
Overall Steps per Second: 10,624.69926

Timestep Collection Time: 2.16817
Timestep Consumption Time: 2.53897
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.70715

Cumulative Model Updates: 165,836
Cumulative Timesteps: 1,383,083,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,916.98414
Policy Entropy: 2.98909
Value Function Loss: 0.00471

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.61355
Value Function Update Magnitude: 0.50577

Collected Steps per Second: 23,423.31265
Overall Steps per Second: 10,872.09247

Timestep Collection Time: 2.13565
Timestep Consumption Time: 2.46549
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.60114

Cumulative Model Updates: 165,842
Cumulative Timesteps: 1,383,133,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1383133164...
Checkpoint 1383133164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.13460
Policy Entropy: 2.99317
Value Function Loss: 0.00460

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.61237
Value Function Update Magnitude: 0.51627

Collected Steps per Second: 22,914.35536
Overall Steps per Second: 10,733.72315

Timestep Collection Time: 2.18230
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.65877

Cumulative Model Updates: 165,848
Cumulative Timesteps: 1,383,183,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.44339
Policy Entropy: 2.98898
Value Function Loss: 0.00466

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.61066
Value Function Update Magnitude: 0.53162

Collected Steps per Second: 23,116.96378
Overall Steps per Second: 10,825.53419

Timestep Collection Time: 2.16395
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.62093

Cumulative Model Updates: 165,854
Cumulative Timesteps: 1,383,233,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1383233194...
Checkpoint 1383233194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.80577
Policy Entropy: 2.96776
Value Function Loss: 0.00484

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.61895
Value Function Update Magnitude: 0.53172

Collected Steps per Second: 23,153.06756
Overall Steps per Second: 10,797.54158

Timestep Collection Time: 2.16075
Timestep Consumption Time: 2.47253
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.63328

Cumulative Model Updates: 165,860
Cumulative Timesteps: 1,383,283,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.15139
Policy Entropy: 2.96002
Value Function Loss: 0.00509

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.62405
Value Function Update Magnitude: 0.53330

Collected Steps per Second: 23,222.91707
Overall Steps per Second: 10,797.10043

Timestep Collection Time: 2.15373
Timestep Consumption Time: 2.47862
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.63235

Cumulative Model Updates: 165,866
Cumulative Timesteps: 1,383,333,238

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1383333238...
Checkpoint 1383333238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,068.51981
Policy Entropy: 2.97118
Value Function Loss: 0.00539

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.62928
Value Function Update Magnitude: 0.54984

Collected Steps per Second: 22,852.36754
Overall Steps per Second: 10,659.00031

Timestep Collection Time: 2.18839
Timestep Consumption Time: 2.50341
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.69181

Cumulative Model Updates: 165,872
Cumulative Timesteps: 1,383,383,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.80237
Policy Entropy: 2.99785
Value Function Loss: 0.00527

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.62947
Value Function Update Magnitude: 0.56659

Collected Steps per Second: 22,463.18535
Overall Steps per Second: 10,668.59350

Timestep Collection Time: 2.22613
Timestep Consumption Time: 2.46108
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.68722

Cumulative Model Updates: 165,878
Cumulative Timesteps: 1,383,433,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1383433254...
Checkpoint 1383433254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.53429
Policy Entropy: 2.98917
Value Function Loss: 0.00502

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.61586
Value Function Update Magnitude: 0.56149

Collected Steps per Second: 22,888.58292
Overall Steps per Second: 10,920.35404

Timestep Collection Time: 2.18502
Timestep Consumption Time: 2.39469
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.57971

Cumulative Model Updates: 165,884
Cumulative Timesteps: 1,383,483,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.96449
Policy Entropy: 2.97131
Value Function Loss: 0.00505

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.62214
Value Function Update Magnitude: 0.55565

Collected Steps per Second: 23,035.67536
Overall Steps per Second: 10,845.35978

Timestep Collection Time: 2.17133
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.61193

Cumulative Model Updates: 165,890
Cumulative Timesteps: 1,383,533,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1383533284...
Checkpoint 1383533284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.57608
Policy Entropy: 2.96668
Value Function Loss: 0.00512

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.63345
Value Function Update Magnitude: 0.55007

Collected Steps per Second: 22,686.93821
Overall Steps per Second: 10,660.24063

Timestep Collection Time: 2.20497
Timestep Consumption Time: 2.48761
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.69258

Cumulative Model Updates: 165,896
Cumulative Timesteps: 1,383,583,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.71083
Policy Entropy: 2.99124
Value Function Loss: 0.00517

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12144
Policy Update Magnitude: 0.63043
Value Function Update Magnitude: 0.53616

Collected Steps per Second: 23,299.54927
Overall Steps per Second: 10,929.06608

Timestep Collection Time: 2.14717
Timestep Consumption Time: 2.43035
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.57752

Cumulative Model Updates: 165,902
Cumulative Timesteps: 1,383,633,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1383633336...
Checkpoint 1383633336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.22955
Policy Entropy: 2.99950
Value Function Loss: 0.00581

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.63754
Value Function Update Magnitude: 0.55427

Collected Steps per Second: 23,339.88140
Overall Steps per Second: 10,969.31386

Timestep Collection Time: 2.14277
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.55926

Cumulative Model Updates: 165,908
Cumulative Timesteps: 1,383,683,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.04853
Policy Entropy: 3.01042
Value Function Loss: 0.00521

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.62860
Value Function Update Magnitude: 0.58232

Collected Steps per Second: 23,225.83161
Overall Steps per Second: 10,986.11445

Timestep Collection Time: 2.15398
Timestep Consumption Time: 2.39977
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.55375

Cumulative Model Updates: 165,914
Cumulative Timesteps: 1,383,733,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1383733376...
Checkpoint 1383733376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,349.07791
Policy Entropy: 3.00730
Value Function Loss: 0.00504

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.62013
Value Function Update Magnitude: 0.58624

Collected Steps per Second: 23,078.93243
Overall Steps per Second: 10,784.07254

Timestep Collection Time: 2.16717
Timestep Consumption Time: 2.47078
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.63795

Cumulative Model Updates: 165,920
Cumulative Timesteps: 1,383,783,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.02639
Policy Entropy: 3.01129
Value Function Loss: 0.00437

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.60452
Value Function Update Magnitude: 0.55874

Collected Steps per Second: 22,788.00712
Overall Steps per Second: 10,784.16408

Timestep Collection Time: 2.19510
Timestep Consumption Time: 2.44337
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.63847

Cumulative Model Updates: 165,926
Cumulative Timesteps: 1,383,833,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1383833414...
Checkpoint 1383833414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.22765
Policy Entropy: 3.00525
Value Function Loss: 0.00437

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.59390
Value Function Update Magnitude: 0.53230

Collected Steps per Second: 22,596.79666
Overall Steps per Second: 10,667.45713

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.47554
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.68922

Cumulative Model Updates: 165,932
Cumulative Timesteps: 1,383,883,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,319.27432
Policy Entropy: 2.99115
Value Function Loss: 0.00458

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11118
Policy Update Magnitude: 0.59407
Value Function Update Magnitude: 0.52474

Collected Steps per Second: 22,669.79244
Overall Steps per Second: 10,824.61491

Timestep Collection Time: 2.20673
Timestep Consumption Time: 2.41478
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.62150

Cumulative Model Updates: 165,938
Cumulative Timesteps: 1,383,933,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1383933462...
Checkpoint 1383933462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.32285
Policy Entropy: 2.98750
Value Function Loss: 0.00453

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.59931
Value Function Update Magnitude: 0.52062

Collected Steps per Second: 22,367.39088
Overall Steps per Second: 10,704.60395

Timestep Collection Time: 2.23558
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.67126

Cumulative Model Updates: 165,944
Cumulative Timesteps: 1,383,983,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.75552
Policy Entropy: 2.98854
Value Function Loss: 0.00441

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11689
Policy Update Magnitude: 0.60334
Value Function Update Magnitude: 0.52606

Collected Steps per Second: 22,227.61344
Overall Steps per Second: 10,562.79422

Timestep Collection Time: 2.25098
Timestep Consumption Time: 2.48583
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.73681

Cumulative Model Updates: 165,950
Cumulative Timesteps: 1,384,033,500

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1384033500...
Checkpoint 1384033500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.83447
Policy Entropy: 2.99268
Value Function Loss: 0.00422

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.60584
Value Function Update Magnitude: 0.51134

Collected Steps per Second: 22,661.97328
Overall Steps per Second: 10,584.56297

Timestep Collection Time: 2.20634
Timestep Consumption Time: 2.51752
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.72386

Cumulative Model Updates: 165,956
Cumulative Timesteps: 1,384,083,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.67361
Policy Entropy: 3.00333
Value Function Loss: 0.00441

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.60547
Value Function Update Magnitude: 0.52386

Collected Steps per Second: 23,123.69364
Overall Steps per Second: 10,820.39562

Timestep Collection Time: 2.16341
Timestep Consumption Time: 2.45990
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.62331

Cumulative Model Updates: 165,962
Cumulative Timesteps: 1,384,133,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1384133526...
Checkpoint 1384133526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,122.91600
Policy Entropy: 2.99437
Value Function Loss: 0.00427

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.59330
Value Function Update Magnitude: 0.52559

Collected Steps per Second: 22,913.94409
Overall Steps per Second: 10,685.89881

Timestep Collection Time: 2.18321
Timestep Consumption Time: 2.49828
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.68150

Cumulative Model Updates: 165,968
Cumulative Timesteps: 1,384,183,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,021.50914
Policy Entropy: 2.97745
Value Function Loss: 0.00466

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.59576
Value Function Update Magnitude: 0.51563

Collected Steps per Second: 23,161.13041
Overall Steps per Second: 10,845.70318

Timestep Collection Time: 2.16000
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.61270

Cumulative Model Updates: 165,974
Cumulative Timesteps: 1,384,233,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1384233580...
Checkpoint 1384233580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,208.79804
Policy Entropy: 2.97066
Value Function Loss: 0.00444

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.59979
Value Function Update Magnitude: 0.51516

Collected Steps per Second: 23,123.81005
Overall Steps per Second: 10,707.77617

Timestep Collection Time: 2.16253
Timestep Consumption Time: 2.50753
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.67006

Cumulative Model Updates: 165,980
Cumulative Timesteps: 1,384,283,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,221.51505
Policy Entropy: 2.97135
Value Function Loss: 0.00477

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.59772
Value Function Update Magnitude: 0.52178

Collected Steps per Second: 23,260.56338
Overall Steps per Second: 10,881.94732

Timestep Collection Time: 2.15008
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.59587

Cumulative Model Updates: 165,986
Cumulative Timesteps: 1,384,333,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1384333598...
Checkpoint 1384333598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.73211
Policy Entropy: 2.98940
Value Function Loss: 0.00481

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.60774
Value Function Update Magnitude: 0.53809

Collected Steps per Second: 22,959.62311
Overall Steps per Second: 10,772.62474

Timestep Collection Time: 2.17869
Timestep Consumption Time: 2.46474
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.64344

Cumulative Model Updates: 165,992
Cumulative Timesteps: 1,384,383,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.54210
Policy Entropy: 2.98680
Value Function Loss: 0.00494

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11105
Policy Update Magnitude: 0.60933
Value Function Update Magnitude: 0.54470

Collected Steps per Second: 22,699.85466
Overall Steps per Second: 10,869.21226

Timestep Collection Time: 2.20301
Timestep Consumption Time: 2.39788
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.60089

Cumulative Model Updates: 165,998
Cumulative Timesteps: 1,384,433,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1384433628...
Checkpoint 1384433628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.95209
Policy Entropy: 2.97205
Value Function Loss: 0.00465

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.60147
Value Function Update Magnitude: 0.53283

Collected Steps per Second: 22,720.76429
Overall Steps per Second: 10,618.26562

Timestep Collection Time: 2.20169
Timestep Consumption Time: 2.50944
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.71113

Cumulative Model Updates: 166,004
Cumulative Timesteps: 1,384,483,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.23537
Policy Entropy: 2.95679
Value Function Loss: 0.00446

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.58758
Value Function Update Magnitude: 0.51000

Collected Steps per Second: 22,661.17742
Overall Steps per Second: 10,780.18170

Timestep Collection Time: 2.20659
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.63851

Cumulative Model Updates: 166,010
Cumulative Timesteps: 1,384,533,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1384533656...
Checkpoint 1384533656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.29721
Policy Entropy: 2.94606
Value Function Loss: 0.00464

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.59433
Value Function Update Magnitude: 0.51454

Collected Steps per Second: 22,414.59673
Overall Steps per Second: 10,722.33920

Timestep Collection Time: 2.23149
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.66484

Cumulative Model Updates: 166,016
Cumulative Timesteps: 1,384,583,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.52034
Policy Entropy: 2.96199
Value Function Loss: 0.00461

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.15028
Policy Update Magnitude: 0.60349
Value Function Update Magnitude: 0.52549

Collected Steps per Second: 22,932.39269
Overall Steps per Second: 10,808.35105

Timestep Collection Time: 2.18041
Timestep Consumption Time: 2.44583
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.62624

Cumulative Model Updates: 166,022
Cumulative Timesteps: 1,384,633,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1384633676...
Checkpoint 1384633676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,237.06889
Policy Entropy: 2.97095
Value Function Loss: 0.00440

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.59539
Value Function Update Magnitude: 0.52590

Collected Steps per Second: 23,081.57478
Overall Steps per Second: 10,768.06191

Timestep Collection Time: 2.16744
Timestep Consumption Time: 2.47852
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.64596

Cumulative Model Updates: 166,028
Cumulative Timesteps: 1,384,683,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,748.75817
Policy Entropy: 2.98059
Value Function Loss: 0.00440

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.59175
Value Function Update Magnitude: 0.52861

Collected Steps per Second: 23,117.54233
Overall Steps per Second: 10,879.32177

Timestep Collection Time: 2.16303
Timestep Consumption Time: 2.43321
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.59624

Cumulative Model Updates: 166,034
Cumulative Timesteps: 1,384,733,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1384733708...
Checkpoint 1384733708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.64028
Policy Entropy: 2.98626
Value Function Loss: 0.00459

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.60269
Value Function Update Magnitude: 0.52908

Collected Steps per Second: 23,059.92298
Overall Steps per Second: 10,786.86634

Timestep Collection Time: 2.16922
Timestep Consumption Time: 2.46809
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.63731

Cumulative Model Updates: 166,040
Cumulative Timesteps: 1,384,783,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.73567
Policy Entropy: 2.98228
Value Function Loss: 0.00482

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11873
Policy Update Magnitude: 0.61520
Value Function Update Magnitude: 0.56038

Collected Steps per Second: 23,091.62657
Overall Steps per Second: 10,724.95908

Timestep Collection Time: 2.16641
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.66445

Cumulative Model Updates: 166,046
Cumulative Timesteps: 1,384,833,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1384833756...
Checkpoint 1384833756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.05783
Policy Entropy: 2.98741
Value Function Loss: 0.00457

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.60256
Value Function Update Magnitude: 0.58194

Collected Steps per Second: 22,882.73199
Overall Steps per Second: 10,651.47391

Timestep Collection Time: 2.18593
Timestep Consumption Time: 2.51014
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.69606

Cumulative Model Updates: 166,052
Cumulative Timesteps: 1,384,883,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.21289
Policy Entropy: 2.98093
Value Function Loss: 0.00442

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.59003
Value Function Update Magnitude: 0.53609

Collected Steps per Second: 22,550.68831
Overall Steps per Second: 10,692.33191

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.67662

Cumulative Model Updates: 166,058
Cumulative Timesteps: 1,384,933,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1384933780...
Checkpoint 1384933780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.26304
Policy Entropy: 2.98412
Value Function Loss: 0.00423

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.59284
Value Function Update Magnitude: 0.50238

Collected Steps per Second: 22,891.03624
Overall Steps per Second: 10,837.18277

Timestep Collection Time: 2.18426
Timestep Consumption Time: 2.42948
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61375

Cumulative Model Updates: 166,064
Cumulative Timesteps: 1,384,983,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.56764
Policy Entropy: 2.98043
Value Function Loss: 0.00421

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.59940
Value Function Update Magnitude: 0.48936

Collected Steps per Second: 22,691.38630
Overall Steps per Second: 10,835.98544

Timestep Collection Time: 2.20348
Timestep Consumption Time: 2.41078
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.61426

Cumulative Model Updates: 166,070
Cumulative Timesteps: 1,385,033,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1385033780...
Checkpoint 1385033780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,336.97420
Policy Entropy: 2.98317
Value Function Loss: 0.00419

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.59588
Value Function Update Magnitude: 0.48717

Collected Steps per Second: 23,176.99808
Overall Steps per Second: 10,715.65854

Timestep Collection Time: 2.15852
Timestep Consumption Time: 2.51016
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.66868

Cumulative Model Updates: 166,076
Cumulative Timesteps: 1,385,083,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.93395
Policy Entropy: 2.97880
Value Function Loss: 0.00426

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.58860
Value Function Update Magnitude: 0.48476

Collected Steps per Second: 22,859.60630
Overall Steps per Second: 10,809.80210

Timestep Collection Time: 2.18788
Timestep Consumption Time: 2.43885
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62673

Cumulative Model Updates: 166,082
Cumulative Timesteps: 1,385,133,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1385133822...
Checkpoint 1385133822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.54406
Policy Entropy: 2.99271
Value Function Loss: 0.00433

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.58467
Value Function Update Magnitude: 0.51417

Collected Steps per Second: 23,086.77186
Overall Steps per Second: 10,767.18787

Timestep Collection Time: 2.16583
Timestep Consumption Time: 2.47809
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.64392

Cumulative Model Updates: 166,088
Cumulative Timesteps: 1,385,183,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,655.23927
Policy Entropy: 2.98727
Value Function Loss: 0.00429

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.58128
Value Function Update Magnitude: 0.52523

Collected Steps per Second: 22,679.53319
Overall Steps per Second: 10,654.48570

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.69305

Cumulative Model Updates: 166,094
Cumulative Timesteps: 1,385,233,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1385233826...
Checkpoint 1385233826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.96482
Policy Entropy: 2.98862
Value Function Loss: 0.00425

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.58292
Value Function Update Magnitude: 0.51270

Collected Steps per Second: 23,159.31966
Overall Steps per Second: 10,880.99572

Timestep Collection Time: 2.16034
Timestep Consumption Time: 2.43777
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.59811

Cumulative Model Updates: 166,100
Cumulative Timesteps: 1,385,283,858

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.63527
Policy Entropy: 2.96947
Value Function Loss: 0.00421

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.58604
Value Function Update Magnitude: 0.52629

Collected Steps per Second: 23,134.31804
Overall Steps per Second: 10,875.75296

Timestep Collection Time: 2.16198
Timestep Consumption Time: 2.43687
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.59885

Cumulative Model Updates: 166,106
Cumulative Timesteps: 1,385,333,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1385333874...
Checkpoint 1385333874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,326.37056
Policy Entropy: 2.98657
Value Function Loss: 0.00433

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.59110
Value Function Update Magnitude: 0.54800

Collected Steps per Second: 22,594.19804
Overall Steps per Second: 10,698.27971

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.67365

Cumulative Model Updates: 166,112
Cumulative Timesteps: 1,385,383,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,000.01215
Policy Entropy: 2.99971
Value Function Loss: 0.00419

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.58308
Value Function Update Magnitude: 0.55489

Collected Steps per Second: 22,600.49128
Overall Steps per Second: 10,594.51968

Timestep Collection Time: 2.21358
Timestep Consumption Time: 2.50848
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.72206

Cumulative Model Updates: 166,118
Cumulative Timesteps: 1,385,433,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1385433902...
Checkpoint 1385433902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.71881
Policy Entropy: 3.00418
Value Function Loss: 0.00430

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.57734
Value Function Update Magnitude: 0.52980

Collected Steps per Second: 22,866.80366
Overall Steps per Second: 10,887.28547

Timestep Collection Time: 2.18710
Timestep Consumption Time: 2.40651
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.59362

Cumulative Model Updates: 166,124
Cumulative Timesteps: 1,385,483,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.95017
Policy Entropy: 3.00091
Value Function Loss: 0.00400

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.51886

Collected Steps per Second: 23,258.27392
Overall Steps per Second: 10,929.02243

Timestep Collection Time: 2.14977
Timestep Consumption Time: 2.42520
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.57497

Cumulative Model Updates: 166,130
Cumulative Timesteps: 1,385,533,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1385533914...
Checkpoint 1385533914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,448.12061
Policy Entropy: 2.97691
Value Function Loss: 0.00446

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.58922
Value Function Update Magnitude: 0.54282

Collected Steps per Second: 23,180.71460
Overall Steps per Second: 10,827.42370

Timestep Collection Time: 2.15748
Timestep Consumption Time: 2.46153
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.61901

Cumulative Model Updates: 166,136
Cumulative Timesteps: 1,385,583,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,499.27572
Policy Entropy: 2.98677
Value Function Loss: 0.00443

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.60495
Value Function Update Magnitude: 0.56074

Collected Steps per Second: 22,946.27132
Overall Steps per Second: 10,749.16209

Timestep Collection Time: 2.17935
Timestep Consumption Time: 2.47292
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.65227

Cumulative Model Updates: 166,142
Cumulative Timesteps: 1,385,633,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1385633934...
Checkpoint 1385633934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.48975
Policy Entropy: 2.98709
Value Function Loss: 0.00458

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.61393
Value Function Update Magnitude: 0.57085

Collected Steps per Second: 23,248.34648
Overall Steps per Second: 10,748.88275

Timestep Collection Time: 2.15103
Timestep Consumption Time: 2.50136
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.65239

Cumulative Model Updates: 166,148
Cumulative Timesteps: 1,385,683,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.66197
Policy Entropy: 2.98476
Value Function Loss: 0.00454

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.61086
Value Function Update Magnitude: 0.57479

Collected Steps per Second: 23,498.74114
Overall Steps per Second: 10,825.07492

Timestep Collection Time: 2.12811
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.61964

Cumulative Model Updates: 166,154
Cumulative Timesteps: 1,385,733,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1385733950...
Checkpoint 1385733950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.24530
Policy Entropy: 2.97493
Value Function Loss: 0.00441

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.60363
Value Function Update Magnitude: 0.55068

Collected Steps per Second: 23,280.37451
Overall Steps per Second: 10,983.65861

Timestep Collection Time: 2.14799
Timestep Consumption Time: 2.40477
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.55276

Cumulative Model Updates: 166,160
Cumulative Timesteps: 1,385,783,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,317.35438
Policy Entropy: 2.96463
Value Function Loss: 0.00441

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.60462
Value Function Update Magnitude: 0.52936

Collected Steps per Second: 22,541.42792
Overall Steps per Second: 10,571.67245

Timestep Collection Time: 2.21885
Timestep Consumption Time: 2.51229
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.73113

Cumulative Model Updates: 166,166
Cumulative Timesteps: 1,385,833,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1385833972...
Checkpoint 1385833972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,919.07349
Policy Entropy: 2.98991
Value Function Loss: 0.00439

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.61091
Value Function Update Magnitude: 0.54862

Collected Steps per Second: 22,684.82027
Overall Steps per Second: 10,594.74042

Timestep Collection Time: 2.20509
Timestep Consumption Time: 2.51631
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.72140

Cumulative Model Updates: 166,172
Cumulative Timesteps: 1,385,883,994

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,404.19044
Policy Entropy: 3.01676
Value Function Loss: 0.00450

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.60490
Value Function Update Magnitude: 0.57548

Collected Steps per Second: 22,815.18573
Overall Steps per Second: 10,704.11807

Timestep Collection Time: 2.19222
Timestep Consumption Time: 2.48037
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.67259

Cumulative Model Updates: 166,178
Cumulative Timesteps: 1,385,934,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1385934010...
Checkpoint 1385934010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.72891
Policy Entropy: 3.01483
Value Function Loss: 0.00483

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.59733
Value Function Update Magnitude: 0.57228

Collected Steps per Second: 22,712.67687
Overall Steps per Second: 10,833.00745

Timestep Collection Time: 2.20159
Timestep Consumption Time: 2.41430
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61589

Cumulative Model Updates: 166,184
Cumulative Timesteps: 1,385,984,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,038.58295
Policy Entropy: 3.01032
Value Function Loss: 0.00504

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.60052
Value Function Update Magnitude: 0.57704

Collected Steps per Second: 23,165.95915
Overall Steps per Second: 10,918.77459

Timestep Collection Time: 2.15938
Timestep Consumption Time: 2.42209
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.58147

Cumulative Model Updates: 166,190
Cumulative Timesteps: 1,386,034,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1386034038...
Checkpoint 1386034038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,194.64156
Policy Entropy: 2.99166
Value Function Loss: 0.00507

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.60400
Value Function Update Magnitude: 0.58656

Collected Steps per Second: 23,103.03546
Overall Steps per Second: 10,826.46316

Timestep Collection Time: 2.16526
Timestep Consumption Time: 2.45527
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.62053

Cumulative Model Updates: 166,196
Cumulative Timesteps: 1,386,084,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.72082
Policy Entropy: 2.99427
Value Function Loss: 0.00463

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.60580
Value Function Update Magnitude: 0.58723

Collected Steps per Second: 23,326.95129
Overall Steps per Second: 10,719.43005

Timestep Collection Time: 2.14456
Timestep Consumption Time: 2.52229
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.66685

Cumulative Model Updates: 166,202
Cumulative Timesteps: 1,386,134,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1386134088...
Checkpoint 1386134088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,878.36051
Policy Entropy: 2.99077
Value Function Loss: 0.00438

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.59738
Value Function Update Magnitude: 0.56206

Collected Steps per Second: 23,062.81378
Overall Steps per Second: 10,671.64207

Timestep Collection Time: 2.16895
Timestep Consumption Time: 2.51843
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.68738

Cumulative Model Updates: 166,208
Cumulative Timesteps: 1,386,184,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.02255
Policy Entropy: 2.99305
Value Function Loss: 0.00408

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.53044

Collected Steps per Second: 23,038.17711
Overall Steps per Second: 10,871.99528

Timestep Collection Time: 2.17101
Timestep Consumption Time: 2.42944
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60044

Cumulative Model Updates: 166,214
Cumulative Timesteps: 1,386,234,126

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1386234126...
Checkpoint 1386234126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.14853
Policy Entropy: 2.99260
Value Function Loss: 0.00393

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.57813
Value Function Update Magnitude: 0.50499

Collected Steps per Second: 22,730.17230
Overall Steps per Second: 10,697.63058

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.47560
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.67655

Cumulative Model Updates: 166,220
Cumulative Timesteps: 1,386,284,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.61757
Policy Entropy: 2.99845
Value Function Loss: 0.00419

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.50920

Collected Steps per Second: 22,929.67950
Overall Steps per Second: 10,921.75249

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.39754
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.57820

Cumulative Model Updates: 166,226
Cumulative Timesteps: 1,386,334,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1386334156...
Checkpoint 1386334156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,099.66739
Policy Entropy: 3.01629
Value Function Loss: 0.00386

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11677
Policy Update Magnitude: 0.57340
Value Function Update Magnitude: 0.50902

Collected Steps per Second: 22,526.45653
Overall Steps per Second: 10,620.89655

Timestep Collection Time: 2.21961
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.70770

Cumulative Model Updates: 166,232
Cumulative Timesteps: 1,386,384,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898.10728
Policy Entropy: 3.01626
Value Function Loss: 0.00413

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.56984
Value Function Update Magnitude: 0.50514

Collected Steps per Second: 22,677.22785
Overall Steps per Second: 10,818.41018

Timestep Collection Time: 2.20538
Timestep Consumption Time: 2.41748
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.62286

Cumulative Model Updates: 166,238
Cumulative Timesteps: 1,386,434,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1386434168...
Checkpoint 1386434168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.61673
Policy Entropy: 3.02191
Value Function Loss: 0.00452

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.59175
Value Function Update Magnitude: 0.53600

Collected Steps per Second: 22,781.43067
Overall Steps per Second: 10,766.29403

Timestep Collection Time: 2.19547
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.64561

Cumulative Model Updates: 166,244
Cumulative Timesteps: 1,386,484,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.29797
Policy Entropy: 2.99845
Value Function Loss: 0.00509

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.61955
Value Function Update Magnitude: 0.57480

Collected Steps per Second: 23,185.21925
Overall Steps per Second: 10,845.61015

Timestep Collection Time: 2.15689
Timestep Consumption Time: 2.45401
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.61090

Cumulative Model Updates: 166,250
Cumulative Timesteps: 1,386,534,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1386534192...
Checkpoint 1386534192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.10331
Policy Entropy: 2.99816
Value Function Loss: 0.00525

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.63561
Value Function Update Magnitude: 0.57224

Collected Steps per Second: 23,191.72767
Overall Steps per Second: 10,830.03743

Timestep Collection Time: 2.15629
Timestep Consumption Time: 2.46124
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.61753

Cumulative Model Updates: 166,256
Cumulative Timesteps: 1,386,584,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.70611
Policy Entropy: 2.98513
Value Function Loss: 0.00537

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.63829
Value Function Update Magnitude: 0.57668

Collected Steps per Second: 23,137.70608
Overall Steps per Second: 10,766.14417

Timestep Collection Time: 2.16184
Timestep Consumption Time: 2.48421
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.64605

Cumulative Model Updates: 166,262
Cumulative Timesteps: 1,386,634,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1386634220...
Checkpoint 1386634220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.66868
Policy Entropy: 2.98979
Value Function Loss: 0.00511

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.63517
Value Function Update Magnitude: 0.57809

Collected Steps per Second: 23,186.35526
Overall Steps per Second: 10,982.67211

Timestep Collection Time: 2.15765
Timestep Consumption Time: 2.39753
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.55518

Cumulative Model Updates: 166,268
Cumulative Timesteps: 1,386,684,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,273.19286
Policy Entropy: 2.98353
Value Function Loss: 0.00490

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.63176
Value Function Update Magnitude: 0.59204

Collected Steps per Second: 23,291.45615
Overall Steps per Second: 10,968.92756

Timestep Collection Time: 2.14731
Timestep Consumption Time: 2.41230
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.55961

Cumulative Model Updates: 166,274
Cumulative Timesteps: 1,386,734,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1386734262...
Checkpoint 1386734262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.76222
Policy Entropy: 2.99501
Value Function Loss: 0.00505

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.63052
Value Function Update Magnitude: 0.59250

Collected Steps per Second: 21,472.25687
Overall Steps per Second: 10,301.63359

Timestep Collection Time: 2.32933
Timestep Consumption Time: 2.52582
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.85515

Cumulative Model Updates: 166,280
Cumulative Timesteps: 1,386,784,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.89261
Policy Entropy: 2.98849
Value Function Loss: 0.00501

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11286
Policy Update Magnitude: 0.62144
Value Function Update Magnitude: 0.59288

Collected Steps per Second: 22,783.79508
Overall Steps per Second: 10,763.31376

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.45146
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.64652

Cumulative Model Updates: 166,286
Cumulative Timesteps: 1,386,834,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1386834290...
Checkpoint 1386834290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,015.95218
Policy Entropy: 2.99402
Value Function Loss: 0.00477

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.61491
Value Function Update Magnitude: 0.57596

Collected Steps per Second: 22,557.49540
Overall Steps per Second: 10,765.44599

Timestep Collection Time: 2.21665
Timestep Consumption Time: 2.42803
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.64468

Cumulative Model Updates: 166,292
Cumulative Timesteps: 1,386,884,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.23356
Policy Entropy: 2.98338
Value Function Loss: 0.00472

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.61061
Value Function Update Magnitude: 0.54381

Collected Steps per Second: 23,080.40822
Overall Steps per Second: 10,814.53779

Timestep Collection Time: 2.16634
Timestep Consumption Time: 2.45707
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.62341

Cumulative Model Updates: 166,298
Cumulative Timesteps: 1,386,934,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1386934292...
Checkpoint 1386934292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.51277
Policy Entropy: 2.97628
Value Function Loss: 0.00448

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.61430
Value Function Update Magnitude: 0.52618

Collected Steps per Second: 22,827.11579
Overall Steps per Second: 10,643.23795

Timestep Collection Time: 2.19117
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.69951

Cumulative Model Updates: 166,304
Cumulative Timesteps: 1,386,984,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.74604
Policy Entropy: 2.97663
Value Function Loss: 0.00445

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.60383
Value Function Update Magnitude: 0.50868

Collected Steps per Second: 23,231.74900
Overall Steps per Second: 10,867.90923

Timestep Collection Time: 2.15309
Timestep Consumption Time: 2.44945
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.60254

Cumulative Model Updates: 166,310
Cumulative Timesteps: 1,387,034,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1387034330...
Checkpoint 1387034330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.15757
Policy Entropy: 2.98570
Value Function Loss: 0.00425

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.59626
Value Function Update Magnitude: 0.50767

Collected Steps per Second: 22,939.09400
Overall Steps per Second: 10,684.01215

Timestep Collection Time: 2.18064
Timestep Consumption Time: 2.50130
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.68195

Cumulative Model Updates: 166,316
Cumulative Timesteps: 1,387,084,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.93786
Policy Entropy: 3.00386
Value Function Loss: 0.00435

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10942
Policy Update Magnitude: 0.59410
Value Function Update Magnitude: 0.52210

Collected Steps per Second: 23,174.95922
Overall Steps per Second: 10,895.04837

Timestep Collection Time: 2.15880
Timestep Consumption Time: 2.43320
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.59199

Cumulative Model Updates: 166,322
Cumulative Timesteps: 1,387,134,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1387134382...
Checkpoint 1387134382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.09932
Policy Entropy: 3.00737
Value Function Loss: 0.00465

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.59803
Value Function Update Magnitude: 0.52352

Collected Steps per Second: 23,123.92355
Overall Steps per Second: 10,826.35351

Timestep Collection Time: 2.16330
Timestep Consumption Time: 2.45728
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.62058

Cumulative Model Updates: 166,328
Cumulative Timesteps: 1,387,184,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,330.15665
Policy Entropy: 2.99912
Value Function Loss: 0.00476

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.60379
Value Function Update Magnitude: 0.55051

Collected Steps per Second: 23,160.87392
Overall Steps per Second: 10,748.24478

Timestep Collection Time: 2.15933
Timestep Consumption Time: 2.49371
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.65304

Cumulative Model Updates: 166,334
Cumulative Timesteps: 1,387,234,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1387234418...
Checkpoint 1387234418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.93559
Policy Entropy: 2.98135
Value Function Loss: 0.00500

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.61082
Value Function Update Magnitude: 0.60035

Collected Steps per Second: 22,435.96816
Overall Steps per Second: 10,640.40598

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.47189
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.70170

Cumulative Model Updates: 166,340
Cumulative Timesteps: 1,387,284,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.52501
Policy Entropy: 2.96552
Value Function Loss: 0.00490

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.62058
Value Function Update Magnitude: 0.58825

Collected Steps per Second: 22,783.54850
Overall Steps per Second: 10,670.54398

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.49273
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.68861

Cumulative Model Updates: 166,346
Cumulative Timesteps: 1,387,334,476

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1387334476...
Checkpoint 1387334476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.33730
Policy Entropy: 2.95354
Value Function Loss: 0.00504

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.61869
Value Function Update Magnitude: 0.56713

Collected Steps per Second: 22,847.47989
Overall Steps per Second: 10,863.69881

Timestep Collection Time: 2.18921
Timestep Consumption Time: 2.41493
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.60414

Cumulative Model Updates: 166,352
Cumulative Timesteps: 1,387,384,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.20060
Policy Entropy: 2.94118
Value Function Loss: 0.00490

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.62420
Value Function Update Magnitude: 0.56213

Collected Steps per Second: 23,276.16057
Overall Steps per Second: 10,872.15161

Timestep Collection Time: 2.14812
Timestep Consumption Time: 2.45079
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.59891

Cumulative Model Updates: 166,358
Cumulative Timesteps: 1,387,434,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1387434494...
Checkpoint 1387434494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,221.84509
Policy Entropy: 2.95685
Value Function Loss: 0.00456

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.62041
Value Function Update Magnitude: 0.54428

Collected Steps per Second: 23,019.85450
Overall Steps per Second: 10,682.57410

Timestep Collection Time: 2.17230
Timestep Consumption Time: 2.50878
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.68108

Cumulative Model Updates: 166,364
Cumulative Timesteps: 1,387,484,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.96910
Policy Entropy: 2.96739
Value Function Loss: 0.00490

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11554
Policy Update Magnitude: 0.61581
Value Function Update Magnitude: 0.55390

Collected Steps per Second: 23,440.54544
Overall Steps per Second: 10,935.70106

Timestep Collection Time: 2.13357
Timestep Consumption Time: 2.43971
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.57328

Cumulative Model Updates: 166,370
Cumulative Timesteps: 1,387,534,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1387534512...
Checkpoint 1387534512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,178.44314
Policy Entropy: 2.97757
Value Function Loss: 0.00488

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11808
Policy Update Magnitude: 0.61885
Value Function Update Magnitude: 0.56714

Collected Steps per Second: 22,744.41446
Overall Steps per Second: 10,725.56739

Timestep Collection Time: 2.19905
Timestep Consumption Time: 2.46420
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.66325

Cumulative Model Updates: 166,376
Cumulative Timesteps: 1,387,584,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.73015
Policy Entropy: 2.96506
Value Function Loss: 0.00500

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.61227
Value Function Update Magnitude: 0.59366

Collected Steps per Second: 23,287.24996
Overall Steps per Second: 10,798.81799

Timestep Collection Time: 2.14744
Timestep Consumption Time: 2.48344
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.63088

Cumulative Model Updates: 166,382
Cumulative Timesteps: 1,387,634,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1387634536...
Checkpoint 1387634536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923.39806
Policy Entropy: 2.97498
Value Function Loss: 0.00462

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.60040
Value Function Update Magnitude: 0.59686

Collected Steps per Second: 22,831.89352
Overall Steps per Second: 10,631.05114

Timestep Collection Time: 2.19027
Timestep Consumption Time: 2.51369
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.70396

Cumulative Model Updates: 166,388
Cumulative Timesteps: 1,387,684,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.35663
Policy Entropy: 2.98113
Value Function Loss: 0.00466

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.59682
Value Function Update Magnitude: 0.56603

Collected Steps per Second: 22,631.49080
Overall Steps per Second: 10,666.85909

Timestep Collection Time: 2.21037
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.68967

Cumulative Model Updates: 166,394
Cumulative Timesteps: 1,387,734,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1387734568...
Checkpoint 1387734568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.71011
Policy Entropy: 2.98045
Value Function Loss: 0.00441

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.59907
Value Function Update Magnitude: 0.53217

Collected Steps per Second: 22,625.00139
Overall Steps per Second: 10,796.04223

Timestep Collection Time: 2.21056
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.63262

Cumulative Model Updates: 166,400
Cumulative Timesteps: 1,387,784,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,303.67517
Policy Entropy: 2.96065
Value Function Loss: 0.00437

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.60163
Value Function Update Magnitude: 0.52289

Collected Steps per Second: 22,878.42777
Overall Steps per Second: 10,653.59476

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.50799
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.69363

Cumulative Model Updates: 166,406
Cumulative Timesteps: 1,387,834,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1387834586...
Checkpoint 1387834586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.88332
Policy Entropy: 2.96139
Value Function Loss: 0.00430

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.60428
Value Function Update Magnitude: 0.52606

Collected Steps per Second: 22,737.52284
Overall Steps per Second: 10,605.23020

Timestep Collection Time: 2.19998
Timestep Consumption Time: 2.51675
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.71673

Cumulative Model Updates: 166,412
Cumulative Timesteps: 1,387,884,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,774.16409
Policy Entropy: 2.95826
Value Function Loss: 0.00456

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.61449
Value Function Update Magnitude: 0.52041

Collected Steps per Second: 23,260.26389
Overall Steps per Second: 10,828.62215

Timestep Collection Time: 2.15002
Timestep Consumption Time: 2.46830
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61832

Cumulative Model Updates: 166,418
Cumulative Timesteps: 1,387,934,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1387934618...
Checkpoint 1387934618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,084.55879
Policy Entropy: 2.96851
Value Function Loss: 0.00465

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.62135
Value Function Update Magnitude: 0.54488

Collected Steps per Second: 23,024.49484
Overall Steps per Second: 10,678.75748

Timestep Collection Time: 2.17282
Timestep Consumption Time: 2.51200
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.68481

Cumulative Model Updates: 166,424
Cumulative Timesteps: 1,387,984,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,249.38353
Policy Entropy: 2.96364
Value Function Loss: 0.00460

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.61210
Value Function Update Magnitude: 0.57396

Collected Steps per Second: 23,203.50664
Overall Steps per Second: 10,866.24962

Timestep Collection Time: 2.15502
Timestep Consumption Time: 2.44675
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.60177

Cumulative Model Updates: 166,430
Cumulative Timesteps: 1,388,034,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1388034650...
Checkpoint 1388034650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,874.85636
Policy Entropy: 2.96904
Value Function Loss: 0.00437

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.60119
Value Function Update Magnitude: 0.56123

Collected Steps per Second: 22,922.48794
Overall Steps per Second: 10,634.37953

Timestep Collection Time: 2.18144
Timestep Consumption Time: 2.52067
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.70211

Cumulative Model Updates: 166,436
Cumulative Timesteps: 1,388,084,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,103.99513
Policy Entropy: 2.98868
Value Function Loss: 0.00445

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.59869
Value Function Update Magnitude: 0.54941

Collected Steps per Second: 23,237.11991
Overall Steps per Second: 10,894.49448

Timestep Collection Time: 2.15328
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.59278

Cumulative Model Updates: 166,442
Cumulative Timesteps: 1,388,134,690

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1388134690...
Checkpoint 1388134690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,597.64634
Policy Entropy: 2.98963
Value Function Loss: 0.00428

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.58863
Value Function Update Magnitude: 0.53417

Collected Steps per Second: 22,709.12607
Overall Steps per Second: 10,672.21212

Timestep Collection Time: 2.20176
Timestep Consumption Time: 2.48331
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.68506

Cumulative Model Updates: 166,448
Cumulative Timesteps: 1,388,184,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.13626
Policy Entropy: 2.99322
Value Function Loss: 0.00446

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.58546
Value Function Update Magnitude: 0.53824

Collected Steps per Second: 22,506.25016
Overall Steps per Second: 10,597.28705

Timestep Collection Time: 2.22258
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.72026

Cumulative Model Updates: 166,454
Cumulative Timesteps: 1,388,234,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1388234712...
Checkpoint 1388234712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,886.65653
Policy Entropy: 2.97054
Value Function Loss: 0.00441

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12122
Policy Update Magnitude: 0.59014
Value Function Update Magnitude: 0.52350

Collected Steps per Second: 22,646.76543
Overall Steps per Second: 10,855.28838

Timestep Collection Time: 2.20844
Timestep Consumption Time: 2.39890
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.60734

Cumulative Model Updates: 166,460
Cumulative Timesteps: 1,388,284,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,457.15372
Policy Entropy: 2.95793
Value Function Loss: 0.00465

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.59763
Value Function Update Magnitude: 0.52111

Collected Steps per Second: 23,067.46258
Overall Steps per Second: 10,761.61519

Timestep Collection Time: 2.16886
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.64893

Cumulative Model Updates: 166,466
Cumulative Timesteps: 1,388,334,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1388334756...
Checkpoint 1388334756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.01702
Policy Entropy: 2.96297
Value Function Loss: 0.00447

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.58996
Value Function Update Magnitude: 0.53872

Collected Steps per Second: 23,011.46571
Overall Steps per Second: 10,784.12535

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.63830

Cumulative Model Updates: 166,472
Cumulative Timesteps: 1,388,384,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.04609
Policy Entropy: 2.98376
Value Function Loss: 0.00421

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.58734
Value Function Update Magnitude: 0.54060

Collected Steps per Second: 23,288.39926
Overall Steps per Second: 10,938.87881

Timestep Collection Time: 2.14785
Timestep Consumption Time: 2.42483
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.57268

Cumulative Model Updates: 166,478
Cumulative Timesteps: 1,388,434,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1388434796...
Checkpoint 1388434796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.77806
Policy Entropy: 2.98231
Value Function Loss: 0.00464

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11826
Policy Update Magnitude: 0.60789
Value Function Update Magnitude: 0.53872

Collected Steps per Second: 23,063.93727
Overall Steps per Second: 10,765.94456

Timestep Collection Time: 2.16858
Timestep Consumption Time: 2.47718
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.64576

Cumulative Model Updates: 166,484
Cumulative Timesteps: 1,388,484,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.42088
Policy Entropy: 2.99537
Value Function Loss: 0.00458

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.60556
Value Function Update Magnitude: 0.55285

Collected Steps per Second: 23,589.48060
Overall Steps per Second: 10,831.90940

Timestep Collection Time: 2.12035
Timestep Consumption Time: 2.49730
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.61765

Cumulative Model Updates: 166,490
Cumulative Timesteps: 1,388,534,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1388534830...
Checkpoint 1388534830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.49856
Policy Entropy: 3.00127
Value Function Loss: 0.00470

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.59843
Value Function Update Magnitude: 0.55254

Collected Steps per Second: 22,857.55659
Overall Steps per Second: 10,655.48379

Timestep Collection Time: 2.18772
Timestep Consumption Time: 2.50526
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.69298

Cumulative Model Updates: 166,496
Cumulative Timesteps: 1,388,584,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,985.04266
Policy Entropy: 2.99865
Value Function Loss: 0.00440

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.58999
Value Function Update Magnitude: 0.52999

Collected Steps per Second: 23,322.91028
Overall Steps per Second: 10,892.75360

Timestep Collection Time: 2.14416
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.59094

Cumulative Model Updates: 166,502
Cumulative Timesteps: 1,388,634,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1388634844...
Checkpoint 1388634844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,177.07066
Policy Entropy: 2.97609
Value Function Loss: 0.00467

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.59800
Value Function Update Magnitude: 0.53336

Collected Steps per Second: 22,700.27869
Overall Steps per Second: 10,620.89998

Timestep Collection Time: 2.20394
Timestep Consumption Time: 2.50659
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.71052

Cumulative Model Updates: 166,508
Cumulative Timesteps: 1,388,684,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,912.18730
Policy Entropy: 2.97426
Value Function Loss: 0.00438

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.59858
Value Function Update Magnitude: 0.52963

Collected Steps per Second: 22,409.81073
Overall Steps per Second: 10,659.67602

Timestep Collection Time: 2.23125
Timestep Consumption Time: 2.45951
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.69076

Cumulative Model Updates: 166,514
Cumulative Timesteps: 1,388,734,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1388734876...
Checkpoint 1388734876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.18898
Policy Entropy: 2.99683
Value Function Loss: 0.00457

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.60034
Value Function Update Magnitude: 0.53385

Collected Steps per Second: 22,538.92022
Overall Steps per Second: 10,601.67382

Timestep Collection Time: 2.21892
Timestep Consumption Time: 2.49845
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.71737

Cumulative Model Updates: 166,520
Cumulative Timesteps: 1,388,784,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.25426
Policy Entropy: 3.01342
Value Function Loss: 0.00426

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.59419
Value Function Update Magnitude: 0.53852

Collected Steps per Second: 22,936.08376
Overall Steps per Second: 10,722.27973

Timestep Collection Time: 2.18084
Timestep Consumption Time: 2.48421
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.66505

Cumulative Model Updates: 166,526
Cumulative Timesteps: 1,388,834,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1388834908...
Checkpoint 1388834908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.96605
Policy Entropy: 3.02013
Value Function Loss: 0.00427

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.58754
Value Function Update Magnitude: 0.52867

Collected Steps per Second: 22,651.93898
Overall Steps per Second: 10,622.27670

Timestep Collection Time: 2.20802
Timestep Consumption Time: 2.50057
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.70860

Cumulative Model Updates: 166,532
Cumulative Timesteps: 1,388,884,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,930.61476
Policy Entropy: 3.02131
Value Function Loss: 0.00419

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.58046
Value Function Update Magnitude: 0.51944

Collected Steps per Second: 23,482.66922
Overall Steps per Second: 10,902.41752

Timestep Collection Time: 2.13017
Timestep Consumption Time: 2.45799
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.58816

Cumulative Model Updates: 166,538
Cumulative Timesteps: 1,388,934,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1388934946...
Checkpoint 1388934946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,721.09896
Policy Entropy: 3.01774
Value Function Loss: 0.00402

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.57475
Value Function Update Magnitude: 0.50228

Collected Steps per Second: 22,881.34965
Overall Steps per Second: 10,677.11175

Timestep Collection Time: 2.18536
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.68329

Cumulative Model Updates: 166,544
Cumulative Timesteps: 1,388,984,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,317.85570
Policy Entropy: 3.01246
Value Function Loss: 0.00396

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.57186
Value Function Update Magnitude: 0.49508

Collected Steps per Second: 23,114.87583
Overall Steps per Second: 10,842.46909

Timestep Collection Time: 2.16320
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.61168

Cumulative Model Updates: 166,550
Cumulative Timesteps: 1,389,034,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1389034952...
Checkpoint 1389034952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.84898
Policy Entropy: 2.99540
Value Function Loss: 0.00408

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.57475
Value Function Update Magnitude: 0.50964

Collected Steps per Second: 22,869.84034
Overall Steps per Second: 10,706.72726

Timestep Collection Time: 2.18716
Timestep Consumption Time: 2.48467
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.67183

Cumulative Model Updates: 166,556
Cumulative Timesteps: 1,389,084,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.49284
Policy Entropy: 2.96816
Value Function Loss: 0.00480

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.60041
Value Function Update Magnitude: 0.53537

Collected Steps per Second: 23,257.21725
Overall Steps per Second: 10,925.41793

Timestep Collection Time: 2.15107
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.57905

Cumulative Model Updates: 166,562
Cumulative Timesteps: 1,389,135,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1389135000...
Checkpoint 1389135000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.98846
Policy Entropy: 2.96165
Value Function Loss: 0.00484

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.61576
Value Function Update Magnitude: 0.56019

Collected Steps per Second: 22,797.93757
Overall Steps per Second: 10,625.18327

Timestep Collection Time: 2.19432
Timestep Consumption Time: 2.51393
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.70825

Cumulative Model Updates: 166,568
Cumulative Timesteps: 1,389,185,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,762.55998
Policy Entropy: 2.96936
Value Function Loss: 0.00470

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.15529
Policy Update Magnitude: 0.61280
Value Function Update Magnitude: 0.55127

Collected Steps per Second: 22,908.33505
Overall Steps per Second: 10,819.58707

Timestep Collection Time: 2.18270
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.62143

Cumulative Model Updates: 166,574
Cumulative Timesteps: 1,389,235,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1389235028...
Checkpoint 1389235028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,008.76454
Policy Entropy: 3.00891
Value Function Loss: 0.00446

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.59510
Value Function Update Magnitude: 0.52216

Collected Steps per Second: 22,431.71208
Overall Steps per Second: 10,708.20416

Timestep Collection Time: 2.22908
Timestep Consumption Time: 2.44043
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.66950

Cumulative Model Updates: 166,580
Cumulative Timesteps: 1,389,285,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,389.79383
Policy Entropy: 3.00438
Value Function Loss: 0.00469

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.60167
Value Function Update Magnitude: 0.50188

Collected Steps per Second: 22,780.94898
Overall Steps per Second: 10,884.18571

Timestep Collection Time: 2.19578
Timestep Consumption Time: 2.40006
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.59584

Cumulative Model Updates: 166,586
Cumulative Timesteps: 1,389,335,052

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1389335052...
Checkpoint 1389335052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.80060
Policy Entropy: 2.99026
Value Function Loss: 0.00492

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.60415
Value Function Update Magnitude: 0.51528

Collected Steps per Second: 22,282.23800
Overall Steps per Second: 10,676.23104

Timestep Collection Time: 2.24430
Timestep Consumption Time: 2.43975
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.68405

Cumulative Model Updates: 166,592
Cumulative Timesteps: 1,389,385,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.45393
Policy Entropy: 2.98430
Value Function Loss: 0.00506

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.60815
Value Function Update Magnitude: 0.53324

Collected Steps per Second: 23,066.70783
Overall Steps per Second: 10,667.08603

Timestep Collection Time: 2.16780
Timestep Consumption Time: 2.51989
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.68769

Cumulative Model Updates: 166,598
Cumulative Timesteps: 1,389,435,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1389435064...
Checkpoint 1389435064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.13573
Policy Entropy: 2.99619
Value Function Loss: 0.00458

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.60638
Value Function Update Magnitude: 0.52626

Collected Steps per Second: 23,083.69862
Overall Steps per Second: 10,840.19156

Timestep Collection Time: 2.16707
Timestep Consumption Time: 2.44761
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61468

Cumulative Model Updates: 166,604
Cumulative Timesteps: 1,389,485,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.92429
Policy Entropy: 3.00084
Value Function Loss: 0.00439

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.59328
Value Function Update Magnitude: 0.52700

Collected Steps per Second: 22,957.29266
Overall Steps per Second: 10,670.56171

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.50803
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.68616

Cumulative Model Updates: 166,610
Cumulative Timesteps: 1,389,535,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1389535092...
Checkpoint 1389535092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.21348
Policy Entropy: 2.99519
Value Function Loss: 0.00406

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.58329
Value Function Update Magnitude: 0.51811

Collected Steps per Second: 23,041.79844
Overall Steps per Second: 10,863.91875

Timestep Collection Time: 2.17049
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.60350

Cumulative Model Updates: 166,616
Cumulative Timesteps: 1,389,585,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.82203
Policy Entropy: 2.99391
Value Function Loss: 0.00427

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.58582
Value Function Update Magnitude: 0.49308

Collected Steps per Second: 23,400.09718
Overall Steps per Second: 10,983.52114

Timestep Collection Time: 2.13777
Timestep Consumption Time: 2.41669
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.55446

Cumulative Model Updates: 166,622
Cumulative Timesteps: 1,389,635,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1389635128...
Checkpoint 1389635128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758.62007
Policy Entropy: 2.98206
Value Function Loss: 0.00430

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11254
Policy Update Magnitude: 0.59635
Value Function Update Magnitude: 0.49067

Collected Steps per Second: 22,970.39615
Overall Steps per Second: 10,666.41670

Timestep Collection Time: 2.17767
Timestep Consumption Time: 2.51200
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.68967

Cumulative Model Updates: 166,628
Cumulative Timesteps: 1,389,685,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.47297
Policy Entropy: 3.00268
Value Function Loss: 0.00417

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.59214
Value Function Update Magnitude: 0.50707

Collected Steps per Second: 22,765.56026
Overall Steps per Second: 10,783.49325

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.44042
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.63672

Cumulative Model Updates: 166,634
Cumulative Timesteps: 1,389,735,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1389735150...
Checkpoint 1389735150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,227.82938
Policy Entropy: 3.00644
Value Function Loss: 0.00401

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.58060
Value Function Update Magnitude: 0.50248

Collected Steps per Second: 22,642.41295
Overall Steps per Second: 10,815.15122

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.41615
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.62555

Cumulative Model Updates: 166,640
Cumulative Timesteps: 1,389,785,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,547.07022
Policy Entropy: 3.02854
Value Function Loss: 0.00433

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.58111
Value Function Update Magnitude: 0.49012

Collected Steps per Second: 22,558.98475
Overall Steps per Second: 10,742.75401

Timestep Collection Time: 2.21641
Timestep Consumption Time: 2.43789
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.65430

Cumulative Model Updates: 166,646
Cumulative Timesteps: 1,389,835,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1389835176...
Checkpoint 1389835176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,197.29460
Policy Entropy: 3.03164
Value Function Loss: 0.00456

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.58389
Value Function Update Magnitude: 0.51506

Collected Steps per Second: 22,520.93084
Overall Steps per Second: 10,709.17528

Timestep Collection Time: 2.22158
Timestep Consumption Time: 2.45030
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.67188

Cumulative Model Updates: 166,652
Cumulative Timesteps: 1,389,885,208

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,333.11865
Policy Entropy: 3.01956
Value Function Loss: 0.00472

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.58684
Value Function Update Magnitude: 0.52829

Collected Steps per Second: 22,993.66141
Overall Steps per Second: 10,632.17783

Timestep Collection Time: 2.17460
Timestep Consumption Time: 2.52829
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.70289

Cumulative Model Updates: 166,658
Cumulative Timesteps: 1,389,935,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1389935210...
Checkpoint 1389935210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,344.59754
Policy Entropy: 3.00591
Value Function Loss: 0.00414

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.59219
Value Function Update Magnitude: 0.53020

Collected Steps per Second: 23,119.19616
Overall Steps per Second: 10,833.49645

Timestep Collection Time: 2.16322
Timestep Consumption Time: 2.45320
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.61642

Cumulative Model Updates: 166,664
Cumulative Timesteps: 1,389,985,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.33697
Policy Entropy: 3.00630
Value Function Loss: 0.00412

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.59089
Value Function Update Magnitude: 0.52669

Collected Steps per Second: 23,273.68457
Overall Steps per Second: 10,978.20023

Timestep Collection Time: 2.14878
Timestep Consumption Time: 2.40661
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.55539

Cumulative Model Updates: 166,670
Cumulative Timesteps: 1,390,035,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1390035232...
Checkpoint 1390035232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,651.00253
Policy Entropy: 3.01797
Value Function Loss: 0.00417

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.58902
Value Function Update Magnitude: 0.53292

Collected Steps per Second: 22,816.18532
Overall Steps per Second: 10,729.98918

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.46910
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.66114

Cumulative Model Updates: 166,676
Cumulative Timesteps: 1,390,085,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.46453
Policy Entropy: 3.02230
Value Function Loss: 0.00455

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.58997
Value Function Update Magnitude: 0.53373

Collected Steps per Second: 23,174.62859
Overall Steps per Second: 10,892.80149

Timestep Collection Time: 2.15883
Timestep Consumption Time: 2.43412
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.59294

Cumulative Model Updates: 166,682
Cumulative Timesteps: 1,390,135,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1390135276...
Checkpoint 1390135276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.56472
Policy Entropy: 3.01836
Value Function Loss: 0.00467

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.58782
Value Function Update Magnitude: 0.52095

Collected Steps per Second: 22,836.73814
Overall Steps per Second: 10,774.69850

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.45212
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.64254

Cumulative Model Updates: 166,688
Cumulative Timesteps: 1,390,185,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990.34987
Policy Entropy: 3.01823
Value Function Loss: 0.00499

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.59703
Value Function Update Magnitude: 0.52008

Collected Steps per Second: 22,761.63317
Overall Steps per Second: 10,723.92773

Timestep Collection Time: 2.19729
Timestep Consumption Time: 2.46648
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.66378

Cumulative Model Updates: 166,694
Cumulative Timesteps: 1,390,235,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1390235312...
Checkpoint 1390235312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.69396
Policy Entropy: 3.01590
Value Function Loss: 0.00491

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.60033
Value Function Update Magnitude: 0.52034

Collected Steps per Second: 22,675.33404
Overall Steps per Second: 10,653.65670

Timestep Collection Time: 2.20610
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.69548

Cumulative Model Updates: 166,700
Cumulative Timesteps: 1,390,285,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.91668
Policy Entropy: 3.02265
Value Function Loss: 0.00485

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.59054
Value Function Update Magnitude: 0.53056

Collected Steps per Second: 22,950.25606
Overall Steps per Second: 10,839.44327

Timestep Collection Time: 2.17915
Timestep Consumption Time: 2.43474
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61389

Cumulative Model Updates: 166,706
Cumulative Timesteps: 1,390,335,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1390335348...
Checkpoint 1390335348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.95236
Policy Entropy: 3.02421
Value Function Loss: 0.00449

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.57540
Value Function Update Magnitude: 0.52148

Collected Steps per Second: 22,555.22700
Overall Steps per Second: 10,702.18170

Timestep Collection Time: 2.21758
Timestep Consumption Time: 2.45605
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.67363

Cumulative Model Updates: 166,712
Cumulative Timesteps: 1,390,385,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,691.49671
Policy Entropy: 3.01827
Value Function Loss: 0.00463

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.58448
Value Function Update Magnitude: 0.52653

Collected Steps per Second: 23,457.04663
Overall Steps per Second: 10,866.80681

Timestep Collection Time: 2.13164
Timestep Consumption Time: 2.46971
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.60135

Cumulative Model Updates: 166,718
Cumulative Timesteps: 1,390,435,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1390435368...
Checkpoint 1390435368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.09308
Policy Entropy: 3.01552
Value Function Loss: 0.00499

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.60631
Value Function Update Magnitude: 0.53979

Collected Steps per Second: 22,933.91579
Overall Steps per Second: 10,627.92645

Timestep Collection Time: 2.18157
Timestep Consumption Time: 2.52602
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.70760

Cumulative Model Updates: 166,724
Cumulative Timesteps: 1,390,485,400

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,840.69270
Policy Entropy: 3.00232
Value Function Loss: 0.00498

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11049
Policy Update Magnitude: 0.60802
Value Function Update Magnitude: 0.55082

Collected Steps per Second: 23,379.81527
Overall Steps per Second: 10,964.21249

Timestep Collection Time: 2.13902
Timestep Consumption Time: 2.42218
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.56120

Cumulative Model Updates: 166,730
Cumulative Timesteps: 1,390,535,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1390535410...
Checkpoint 1390535410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,714.89626
Policy Entropy: 3.00792
Value Function Loss: 0.00491

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10942
Policy Update Magnitude: 0.60659
Value Function Update Magnitude: 0.56386

Collected Steps per Second: 22,845.65413
Overall Steps per Second: 10,669.57013

Timestep Collection Time: 2.18948
Timestep Consumption Time: 2.49862
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.68810

Cumulative Model Updates: 166,736
Cumulative Timesteps: 1,390,585,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.67250
Policy Entropy: 3.01653
Value Function Loss: 0.00454

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.60071
Value Function Update Magnitude: 0.57444

Collected Steps per Second: 22,661.91512
Overall Steps per Second: 10,498.00659

Timestep Collection Time: 2.20723
Timestep Consumption Time: 2.55749
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.76471

Cumulative Model Updates: 166,742
Cumulative Timesteps: 1,390,635,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1390635450...
Checkpoint 1390635450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.88468
Policy Entropy: 3.01157
Value Function Loss: 0.00437

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.59727
Value Function Update Magnitude: 0.56729

Collected Steps per Second: 22,953.34685
Overall Steps per Second: 10,906.57401

Timestep Collection Time: 2.17842
Timestep Consumption Time: 2.40616
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.58457

Cumulative Model Updates: 166,748
Cumulative Timesteps: 1,390,685,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.25269
Policy Entropy: 3.00770
Value Function Loss: 0.00437

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.59120
Value Function Update Magnitude: 0.55383

Collected Steps per Second: 23,108.17737
Overall Steps per Second: 10,961.06656

Timestep Collection Time: 2.16443
Timestep Consumption Time: 2.39863
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.56306

Cumulative Model Updates: 166,754
Cumulative Timesteps: 1,390,735,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1390735468...
Checkpoint 1390735468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,416.16719
Policy Entropy: 2.99305
Value Function Loss: 0.00487

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.59995
Value Function Update Magnitude: 0.55135

Collected Steps per Second: 22,612.15143
Overall Steps per Second: 10,700.31401

Timestep Collection Time: 2.21235
Timestep Consumption Time: 2.46284
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.67519

Cumulative Model Updates: 166,760
Cumulative Timesteps: 1,390,785,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.25982
Policy Entropy: 2.99596
Value Function Loss: 0.00503

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.61416
Value Function Update Magnitude: 0.58116

Collected Steps per Second: 23,087.03500
Overall Steps per Second: 10,949.91306

Timestep Collection Time: 2.16606
Timestep Consumption Time: 2.40091
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.56698

Cumulative Model Updates: 166,766
Cumulative Timesteps: 1,390,835,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1390835502...
Checkpoint 1390835502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,890.64416
Policy Entropy: 3.00159
Value Function Loss: 0.00497

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.60488
Value Function Update Magnitude: 0.58771

Collected Steps per Second: 22,622.74501
Overall Steps per Second: 10,674.10106

Timestep Collection Time: 2.21105
Timestep Consumption Time: 2.47506
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.68611

Cumulative Model Updates: 166,772
Cumulative Timesteps: 1,390,885,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.89660
Policy Entropy: 3.00997
Value Function Loss: 0.00489

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.59868
Value Function Update Magnitude: 0.55506

Collected Steps per Second: 23,221.07246
Overall Steps per Second: 10,834.24604

Timestep Collection Time: 2.15425
Timestep Consumption Time: 2.46296
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.61721

Cumulative Model Updates: 166,778
Cumulative Timesteps: 1,390,935,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1390935546...
Checkpoint 1390935546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.87212
Policy Entropy: 3.01176
Value Function Loss: 0.00486

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.60536
Value Function Update Magnitude: 0.54274

Collected Steps per Second: 22,828.07147
Overall Steps per Second: 10,673.62857

Timestep Collection Time: 2.19055
Timestep Consumption Time: 2.49446
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.68500

Cumulative Model Updates: 166,784
Cumulative Timesteps: 1,390,985,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.84544
Policy Entropy: 3.00900
Value Function Loss: 0.00485

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.59887
Value Function Update Magnitude: 0.54195

Collected Steps per Second: 23,241.58362
Overall Steps per Second: 10,850.01514

Timestep Collection Time: 2.15132
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.60829

Cumulative Model Updates: 166,790
Cumulative Timesteps: 1,391,035,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1391035552...
Checkpoint 1391035552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.25460
Policy Entropy: 2.99685
Value Function Loss: 0.00484

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.60181
Value Function Update Magnitude: 0.53657

Collected Steps per Second: 23,188.97414
Overall Steps per Second: 10,747.25467

Timestep Collection Time: 2.15628
Timestep Consumption Time: 2.49625
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.65254

Cumulative Model Updates: 166,796
Cumulative Timesteps: 1,391,085,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,090.43238
Policy Entropy: 2.97843
Value Function Loss: 0.00496

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.61862
Value Function Update Magnitude: 0.53485

Collected Steps per Second: 23,305.36081
Overall Steps per Second: 10,794.24168

Timestep Collection Time: 2.14577
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.63284

Cumulative Model Updates: 166,802
Cumulative Timesteps: 1,391,135,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1391135562...
Checkpoint 1391135562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,994.69142
Policy Entropy: 2.99191
Value Function Loss: 0.00475

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.61125
Value Function Update Magnitude: 0.54709

Collected Steps per Second: 22,999.22006
Overall Steps per Second: 10,787.95278

Timestep Collection Time: 2.17477
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.63647

Cumulative Model Updates: 166,808
Cumulative Timesteps: 1,391,185,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,950.20922
Policy Entropy: 3.01701
Value Function Loss: 0.00432

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.59572
Value Function Update Magnitude: 0.53777

Collected Steps per Second: 23,394.90323
Overall Steps per Second: 10,749.51237

Timestep Collection Time: 2.13756
Timestep Consumption Time: 2.51456
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.65212

Cumulative Model Updates: 166,814
Cumulative Timesteps: 1,391,235,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1391235588...
Checkpoint 1391235588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,009.41170
Policy Entropy: 3.02879
Value Function Loss: 0.00456

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.59767
Value Function Update Magnitude: 0.51785

Collected Steps per Second: 22,519.96418
Overall Steps per Second: 10,649.40189

Timestep Collection Time: 2.22114
Timestep Consumption Time: 2.47584
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.69698

Cumulative Model Updates: 166,820
Cumulative Timesteps: 1,391,285,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.58743
Policy Entropy: 3.01586
Value Function Loss: 0.00454

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.59703
Value Function Update Magnitude: 0.51976

Collected Steps per Second: 22,791.44885
Overall Steps per Second: 10,816.67918

Timestep Collection Time: 2.19407
Timestep Consumption Time: 2.42898
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62305

Cumulative Model Updates: 166,826
Cumulative Timesteps: 1,391,335,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1391335614...
Checkpoint 1391335614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.01494
Policy Entropy: 2.99684
Value Function Loss: 0.00465

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.59673
Value Function Update Magnitude: 0.54090

Collected Steps per Second: 22,621.46058
Overall Steps per Second: 10,723.05773

Timestep Collection Time: 2.21162
Timestep Consumption Time: 2.45403
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.66565

Cumulative Model Updates: 166,832
Cumulative Timesteps: 1,391,385,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,319.18490
Policy Entropy: 2.98824
Value Function Loss: 0.00438

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.59724
Value Function Update Magnitude: 0.55241

Collected Steps per Second: 22,974.22159
Overall Steps per Second: 10,806.42048

Timestep Collection Time: 2.17635
Timestep Consumption Time: 2.45053
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62688

Cumulative Model Updates: 166,838
Cumulative Timesteps: 1,391,435,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1391435644...
Checkpoint 1391435644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,364.96168
Policy Entropy: 2.98680
Value Function Loss: 0.00434

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.59074
Value Function Update Magnitude: 0.54406

Collected Steps per Second: 22,988.61986
Overall Steps per Second: 10,739.67360

Timestep Collection Time: 2.17577
Timestep Consumption Time: 2.48154
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.65731

Cumulative Model Updates: 166,844
Cumulative Timesteps: 1,391,485,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.42232
Policy Entropy: 3.00081
Value Function Loss: 0.00451

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.59559
Value Function Update Magnitude: 0.52704

Collected Steps per Second: 23,328.20625
Overall Steps per Second: 10,877.24720

Timestep Collection Time: 2.14384
Timestep Consumption Time: 2.45401
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.59785

Cumulative Model Updates: 166,850
Cumulative Timesteps: 1,391,535,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1391535674...
Checkpoint 1391535674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.46845
Policy Entropy: 2.99916
Value Function Loss: 0.00420

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.58573
Value Function Update Magnitude: 0.52377

Collected Steps per Second: 22,942.90122
Overall Steps per Second: 10,636.99906

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.52175
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.70151

Cumulative Model Updates: 166,856
Cumulative Timesteps: 1,391,585,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.62177
Policy Entropy: 3.01181
Value Function Loss: 0.00437

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.58643
Value Function Update Magnitude: 0.52670

Collected Steps per Second: 23,206.88171
Overall Steps per Second: 10,971.40683

Timestep Collection Time: 2.15557
Timestep Consumption Time: 2.40392
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.55949

Cumulative Model Updates: 166,862
Cumulative Timesteps: 1,391,635,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1391635708...
Checkpoint 1391635708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.60063
Policy Entropy: 2.99079
Value Function Loss: 0.00467

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.60052
Value Function Update Magnitude: 0.55198

Collected Steps per Second: 23,065.81769
Overall Steps per Second: 10,831.89513

Timestep Collection Time: 2.16832
Timestep Consumption Time: 2.44897
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.61729

Cumulative Model Updates: 166,868
Cumulative Timesteps: 1,391,685,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,355.99605
Policy Entropy: 2.98975
Value Function Loss: 0.00554

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.62471
Value Function Update Magnitude: 0.57438

Collected Steps per Second: 23,179.41086
Overall Steps per Second: 10,736.84329

Timestep Collection Time: 2.15786
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.65854

Cumulative Model Updates: 166,874
Cumulative Timesteps: 1,391,735,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1391735740...
Checkpoint 1391735740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,211.52886
Policy Entropy: 2.99246
Value Function Loss: 0.00514

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.61814
Value Function Update Magnitude: 0.60553

Collected Steps per Second: 22,227.19596
Overall Steps per Second: 10,612.05925

Timestep Collection Time: 2.25049
Timestep Consumption Time: 2.46321
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.71369

Cumulative Model Updates: 166,880
Cumulative Timesteps: 1,391,785,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,432.58367
Policy Entropy: 3.00222
Value Function Loss: 0.00472

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.61137
Value Function Update Magnitude: 0.61505

Collected Steps per Second: 22,909.32171
Overall Steps per Second: 10,803.18865

Timestep Collection Time: 2.18322
Timestep Consumption Time: 2.44653
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.62974

Cumulative Model Updates: 166,886
Cumulative Timesteps: 1,391,835,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1391835778...
Checkpoint 1391835778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,259.64721
Policy Entropy: 2.99757
Value Function Loss: 0.00426

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.61031
Value Function Update Magnitude: 0.59020

Collected Steps per Second: 22,663.52400
Overall Steps per Second: 10,715.50499

Timestep Collection Time: 2.20742
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.66875

Cumulative Model Updates: 166,892
Cumulative Timesteps: 1,391,885,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.50302
Policy Entropy: 3.00432
Value Function Loss: 0.00414

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11882
Policy Update Magnitude: 0.58877
Value Function Update Magnitude: 0.56163

Collected Steps per Second: 22,643.86070
Overall Steps per Second: 10,824.85640

Timestep Collection Time: 2.20837
Timestep Consumption Time: 2.41118
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.61955

Cumulative Model Updates: 166,898
Cumulative Timesteps: 1,391,935,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1391935812...
Checkpoint 1391935812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.31200
Policy Entropy: 2.99778
Value Function Loss: 0.00428

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.57888
Value Function Update Magnitude: 0.52787

Collected Steps per Second: 22,922.24473
Overall Steps per Second: 10,797.02326

Timestep Collection Time: 2.18172
Timestep Consumption Time: 2.45011
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.63183

Cumulative Model Updates: 166,904
Cumulative Timesteps: 1,391,985,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.81712
Policy Entropy: 3.00601
Value Function Loss: 0.00427

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.58195
Value Function Update Magnitude: 0.52567

Collected Steps per Second: 23,330.97031
Overall Steps per Second: 10,802.45997

Timestep Collection Time: 2.14316
Timestep Consumption Time: 2.48560
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.62876

Cumulative Model Updates: 166,910
Cumulative Timesteps: 1,392,035,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1392035824...
Checkpoint 1392035824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,591.40763
Policy Entropy: 3.00250
Value Function Loss: 0.00429

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11419
Policy Update Magnitude: 0.58465
Value Function Update Magnitude: 0.52637

Collected Steps per Second: 23,069.16119
Overall Steps per Second: 10,682.53549

Timestep Collection Time: 2.16878
Timestep Consumption Time: 2.51475
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.68353

Cumulative Model Updates: 166,916
Cumulative Timesteps: 1,392,085,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,263.35522
Policy Entropy: 3.01047
Value Function Loss: 0.00431

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.57742
Value Function Update Magnitude: 0.50694

Collected Steps per Second: 23,522.72658
Overall Steps per Second: 10,915.26884

Timestep Collection Time: 2.12586
Timestep Consumption Time: 2.45543
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.58129

Cumulative Model Updates: 166,922
Cumulative Timesteps: 1,392,135,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1392135862...
Checkpoint 1392135862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,647.97271
Policy Entropy: 3.01436
Value Function Loss: 0.00445

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.57641
Value Function Update Magnitude: 0.51232

Collected Steps per Second: 22,820.76249
Overall Steps per Second: 10,612.57888

Timestep Collection Time: 2.19195
Timestep Consumption Time: 2.52151
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.71346

Cumulative Model Updates: 166,928
Cumulative Timesteps: 1,392,185,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974.95501
Policy Entropy: 3.01851
Value Function Loss: 0.00443

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.59553
Value Function Update Magnitude: 0.52003

Collected Steps per Second: 23,122.41125
Overall Steps per Second: 10,844.34305

Timestep Collection Time: 2.16318
Timestep Consumption Time: 2.44918
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.61236

Cumulative Model Updates: 166,934
Cumulative Timesteps: 1,392,235,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1392235902...
Checkpoint 1392235902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,080.35694
Policy Entropy: 3.00812
Value Function Loss: 0.00419

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.58699
Value Function Update Magnitude: 0.51608

Collected Steps per Second: 22,397.12772
Overall Steps per Second: 10,737.90192

Timestep Collection Time: 2.23288
Timestep Consumption Time: 2.42446
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.65733

Cumulative Model Updates: 166,940
Cumulative Timesteps: 1,392,285,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,764.99924
Policy Entropy: 3.00378
Value Function Loss: 0.00417

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.57887
Value Function Update Magnitude: 0.51247

Collected Steps per Second: 22,936.05331
Overall Steps per Second: 10,845.34392

Timestep Collection Time: 2.18041
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.61120

Cumulative Model Updates: 166,946
Cumulative Timesteps: 1,392,335,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1392335922...
Checkpoint 1392335922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,574.65171
Policy Entropy: 2.99739
Value Function Loss: 0.00415

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.56691
Value Function Update Magnitude: 0.50500

Collected Steps per Second: 22,214.35619
Overall Steps per Second: 10,692.21878

Timestep Collection Time: 2.25188
Timestep Consumption Time: 2.42667
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.67854

Cumulative Model Updates: 166,952
Cumulative Timesteps: 1,392,385,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.27808
Policy Entropy: 2.98934
Value Function Loss: 0.00422

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.49218

Collected Steps per Second: 22,599.65515
Overall Steps per Second: 10,604.81018

Timestep Collection Time: 2.21357
Timestep Consumption Time: 2.50372
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.71729

Cumulative Model Updates: 166,958
Cumulative Timesteps: 1,392,435,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1392435972...
Checkpoint 1392435972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.91609
Policy Entropy: 2.98534
Value Function Loss: 0.00477

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.59047
Value Function Update Magnitude: 0.49946

Collected Steps per Second: 22,861.03676
Overall Steps per Second: 10,699.19246

Timestep Collection Time: 2.18774
Timestep Consumption Time: 2.48682
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.67456

Cumulative Model Updates: 166,964
Cumulative Timesteps: 1,392,485,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,091.10517
Policy Entropy: 2.99559
Value Function Loss: 0.00446

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.59595
Value Function Update Magnitude: 0.51426

Collected Steps per Second: 23,356.24180
Overall Steps per Second: 10,719.64126

Timestep Collection Time: 2.14170
Timestep Consumption Time: 2.52469
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.66639

Cumulative Model Updates: 166,970
Cumulative Timesteps: 1,392,536,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1392536008...
Checkpoint 1392536008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,939.58881
Policy Entropy: 3.02197
Value Function Loss: 0.00402

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.57082
Value Function Update Magnitude: 0.48133

Collected Steps per Second: 21,993.74533
Overall Steps per Second: 10,617.93065

Timestep Collection Time: 2.27337
Timestep Consumption Time: 2.43564
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.70902

Cumulative Model Updates: 166,976
Cumulative Timesteps: 1,392,586,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,251.89423
Policy Entropy: 3.03821
Value Function Loss: 0.00385

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.56306
Value Function Update Magnitude: 0.45803

Collected Steps per Second: 22,836.84506
Overall Steps per Second: 10,665.60282

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69041

Cumulative Model Updates: 166,982
Cumulative Timesteps: 1,392,636,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1392636034...
Checkpoint 1392636034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,088.90204
Policy Entropy: 3.05381
Value Function Loss: 0.00385

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.56651
Value Function Update Magnitude: 0.47188

Collected Steps per Second: 22,768.46430
Overall Steps per Second: 10,812.76731

Timestep Collection Time: 2.19716
Timestep Consumption Time: 2.42941
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.62657

Cumulative Model Updates: 166,988
Cumulative Timesteps: 1,392,686,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,831.10948
Policy Entropy: 3.03532
Value Function Loss: 0.00412

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.57532
Value Function Update Magnitude: 0.48003

Collected Steps per Second: 23,305.14724
Overall Steps per Second: 10,702.37767

Timestep Collection Time: 2.14596
Timestep Consumption Time: 2.52702
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.67298

Cumulative Model Updates: 166,994
Cumulative Timesteps: 1,392,736,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1392736072...
Checkpoint 1392736072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,094.86412
Policy Entropy: 3.01178
Value Function Loss: 0.00447

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.58710
Value Function Update Magnitude: 0.52489

Collected Steps per Second: 22,938.13781
Overall Steps per Second: 10,702.08641

Timestep Collection Time: 2.17978
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.67199

Cumulative Model Updates: 167,000
Cumulative Timesteps: 1,392,786,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,064.89296
Policy Entropy: 3.00150
Value Function Loss: 0.00428

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.58643
Value Function Update Magnitude: 0.52721

Collected Steps per Second: 23,532.51805
Overall Steps per Second: 11,033.32159

Timestep Collection Time: 2.12548
Timestep Consumption Time: 2.40787
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.53336

Cumulative Model Updates: 167,006
Cumulative Timesteps: 1,392,836,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1392836090...
Checkpoint 1392836090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.59858
Policy Entropy: 3.01103
Value Function Loss: 0.00484

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.58787
Value Function Update Magnitude: 0.51444

Collected Steps per Second: 23,038.51067
Overall Steps per Second: 10,747.78965

Timestep Collection Time: 2.17045
Timestep Consumption Time: 2.48204
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.65249

Cumulative Model Updates: 167,012
Cumulative Timesteps: 1,392,886,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,331.51710
Policy Entropy: 3.01867
Value Function Loss: 0.00488

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.59185
Value Function Update Magnitude: 0.48800

Collected Steps per Second: 23,178.73124
Overall Steps per Second: 10,904.55707

Timestep Collection Time: 2.15836
Timestep Consumption Time: 2.42945
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.58781

Cumulative Model Updates: 167,018
Cumulative Timesteps: 1,392,936,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1392936122...
Checkpoint 1392936122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,909.82769
Policy Entropy: 3.02648
Value Function Loss: 0.00469

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.58622
Value Function Update Magnitude: 0.48019

Collected Steps per Second: 22,990.48787
Overall Steps per Second: 10,682.28886

Timestep Collection Time: 2.17577
Timestep Consumption Time: 2.50693
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.68270

Cumulative Model Updates: 167,024
Cumulative Timesteps: 1,392,986,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,214.82251
Policy Entropy: 3.03681
Value Function Loss: 0.00430

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.57907
Value Function Update Magnitude: 0.47952

Collected Steps per Second: 22,903.49185
Overall Steps per Second: 10,929.95329

Timestep Collection Time: 2.18447
Timestep Consumption Time: 2.39304
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.57751

Cumulative Model Updates: 167,030
Cumulative Timesteps: 1,393,036,176

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1393036176...
Checkpoint 1393036176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,561.19861
Policy Entropy: 3.02404
Value Function Loss: 0.00427

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.58439
Value Function Update Magnitude: 0.50608

Collected Steps per Second: 22,486.43324
Overall Steps per Second: 10,564.49412

Timestep Collection Time: 2.22365
Timestep Consumption Time: 2.50937
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.73302

Cumulative Model Updates: 167,036
Cumulative Timesteps: 1,393,086,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,443.92913
Policy Entropy: 3.00544
Value Function Loss: 0.00447

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.59163
Value Function Update Magnitude: 0.54725

Collected Steps per Second: 22,812.94100
Overall Steps per Second: 10,699.72958

Timestep Collection Time: 2.19218
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.67395

Cumulative Model Updates: 167,042
Cumulative Timesteps: 1,393,136,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1393136188...
Checkpoint 1393136188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,822.17320
Policy Entropy: 2.99973
Value Function Loss: 0.00432

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.58601
Value Function Update Magnitude: 0.52801

Collected Steps per Second: 22,376.17871
Overall Steps per Second: 10,595.12544

Timestep Collection Time: 2.23479
Timestep Consumption Time: 2.48493
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.71972

Cumulative Model Updates: 167,048
Cumulative Timesteps: 1,393,186,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,857.31197
Policy Entropy: 3.01186
Value Function Loss: 0.00426

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.57698
Value Function Update Magnitude: 0.49932

Collected Steps per Second: 22,643.82810
Overall Steps per Second: 10,754.76977

Timestep Collection Time: 2.20881
Timestep Consumption Time: 2.44177
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.65059

Cumulative Model Updates: 167,054
Cumulative Timesteps: 1,393,236,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1393236210...
Checkpoint 1393236210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,590.86789
Policy Entropy: 3.03376
Value Function Loss: 0.00425

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.58088
Value Function Update Magnitude: 0.50093

Collected Steps per Second: 22,887.23473
Overall Steps per Second: 10,582.71923

Timestep Collection Time: 2.18462
Timestep Consumption Time: 2.54006
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.72468

Cumulative Model Updates: 167,060
Cumulative Timesteps: 1,393,286,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,202.12643
Policy Entropy: 3.03658
Value Function Loss: 0.00417

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.49405

Collected Steps per Second: 22,900.83920
Overall Steps per Second: 10,805.95607

Timestep Collection Time: 2.18411
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.62874

Cumulative Model Updates: 167,066
Cumulative Timesteps: 1,393,336,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1393336228...
Checkpoint 1393336228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,046.24644
Policy Entropy: 3.03493
Value Function Loss: 0.00428

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.57996
Value Function Update Magnitude: 0.49529

Collected Steps per Second: 22,534.29053
Overall Steps per Second: 10,753.39594

Timestep Collection Time: 2.21991
Timestep Consumption Time: 2.43202
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.65193

Cumulative Model Updates: 167,072
Cumulative Timesteps: 1,393,386,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,606.54460
Policy Entropy: 3.04019
Value Function Loss: 0.00405

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.56941
Value Function Update Magnitude: 0.46908

Collected Steps per Second: 23,449.27248
Overall Steps per Second: 10,934.22605

Timestep Collection Time: 2.13329
Timestep Consumption Time: 2.44171
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.57499

Cumulative Model Updates: 167,078
Cumulative Timesteps: 1,393,436,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1393436276...
Checkpoint 1393436276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,247.23301
Policy Entropy: 3.04316
Value Function Loss: 0.00446

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.56004
Value Function Update Magnitude: 0.45811

Collected Steps per Second: 23,036.97294
Overall Steps per Second: 10,727.11554

Timestep Collection Time: 2.17173
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.66388

Cumulative Model Updates: 167,084
Cumulative Timesteps: 1,393,486,306

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,947.01891
Policy Entropy: 3.05245
Value Function Loss: 0.00445

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.57418
Value Function Update Magnitude: 0.47967

Collected Steps per Second: 23,163.04971
Overall Steps per Second: 10,811.14706

Timestep Collection Time: 2.15939
Timestep Consumption Time: 2.46713
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.62652

Cumulative Model Updates: 167,090
Cumulative Timesteps: 1,393,536,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1393536324...
Checkpoint 1393536324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,885.13531
Policy Entropy: 3.05168
Value Function Loss: 0.00443

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.57840
Value Function Update Magnitude: 0.49876

Collected Steps per Second: 22,311.77629
Overall Steps per Second: 10,632.14556

Timestep Collection Time: 2.24133
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.70347

Cumulative Model Updates: 167,096
Cumulative Timesteps: 1,393,586,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,471.38560
Policy Entropy: 3.04436
Value Function Loss: 0.00431

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 0.57787
Value Function Update Magnitude: 0.49644

Collected Steps per Second: 22,837.32646
Overall Steps per Second: 10,831.87023

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61859

Cumulative Model Updates: 167,102
Cumulative Timesteps: 1,393,636,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1393636360...
Checkpoint 1393636360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,869.38263
Policy Entropy: 3.03889
Value Function Loss: 0.00429

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.57954
Value Function Update Magnitude: 0.49158

Collected Steps per Second: 22,588.89170
Overall Steps per Second: 10,707.53149

Timestep Collection Time: 2.21383
Timestep Consumption Time: 2.45653
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.67036

Cumulative Model Updates: 167,108
Cumulative Timesteps: 1,393,686,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,687.58306
Policy Entropy: 3.03243
Value Function Loss: 0.00417

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.47390

Collected Steps per Second: 22,918.31039
Overall Steps per Second: 10,841.04596

Timestep Collection Time: 2.18166
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.61210

Cumulative Model Updates: 167,114
Cumulative Timesteps: 1,393,736,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1393736368...
Checkpoint 1393736368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.06628
Policy Entropy: 3.03182
Value Function Loss: 0.00394

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.56456
Value Function Update Magnitude: 0.46592

Collected Steps per Second: 22,906.43449
Overall Steps per Second: 10,709.45044

Timestep Collection Time: 2.18288
Timestep Consumption Time: 2.48608
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.66896

Cumulative Model Updates: 167,120
Cumulative Timesteps: 1,393,786,370

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,584.99608
Policy Entropy: 3.02960
Value Function Loss: 0.00371

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.44958

Collected Steps per Second: 23,351.21327
Overall Steps per Second: 10,880.23711

Timestep Collection Time: 2.14216
Timestep Consumption Time: 2.45535
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.59751

Cumulative Model Updates: 167,126
Cumulative Timesteps: 1,393,836,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1393836392...
Checkpoint 1393836392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,837.45949
Policy Entropy: 3.02959
Value Function Loss: 0.00376

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.43700

Collected Steps per Second: 23,199.03883
Overall Steps per Second: 10,765.62820

Timestep Collection Time: 2.15604
Timestep Consumption Time: 2.49005
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.64608

Cumulative Model Updates: 167,132
Cumulative Timesteps: 1,393,886,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,004.21439
Policy Entropy: 3.02869
Value Function Loss: 0.00398

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.47049

Collected Steps per Second: 23,519.44505
Overall Steps per Second: 10,788.06770

Timestep Collection Time: 2.12590
Timestep Consumption Time: 2.50885
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.63475

Cumulative Model Updates: 167,138
Cumulative Timesteps: 1,393,936,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1393936410...
Checkpoint 1393936410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,714.73985
Policy Entropy: 3.02253
Value Function Loss: 0.00367

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.49212

Collected Steps per Second: 22,562.52233
Overall Steps per Second: 10,832.19935

Timestep Collection Time: 2.21713
Timestep Consumption Time: 2.40096
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.61808

Cumulative Model Updates: 167,144
Cumulative Timesteps: 1,393,986,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.33569
Policy Entropy: 3.01270
Value Function Loss: 0.00391

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.50121

Collected Steps per Second: 22,394.69919
Overall Steps per Second: 10,720.99184

Timestep Collection Time: 2.23392
Timestep Consumption Time: 2.43244
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.66636

Cumulative Model Updates: 167,150
Cumulative Timesteps: 1,394,036,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1394036462...
Checkpoint 1394036462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,926.26396
Policy Entropy: 3.00744
Value Function Loss: 0.00412

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.58284
Value Function Update Magnitude: 0.51448

Collected Steps per Second: 22,043.55052
Overall Steps per Second: 10,644.62118

Timestep Collection Time: 2.26842
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.69758

Cumulative Model Updates: 167,156
Cumulative Timesteps: 1,394,086,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.51135
Policy Entropy: 3.01286
Value Function Loss: 0.00475

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11113
Policy Update Magnitude: 0.59826
Value Function Update Magnitude: 0.53035

Collected Steps per Second: 21,796.75468
Overall Steps per Second: 10,618.42539

Timestep Collection Time: 2.29429
Timestep Consumption Time: 2.41526
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.70955

Cumulative Model Updates: 167,162
Cumulative Timesteps: 1,394,136,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1394136474...
Checkpoint 1394136474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.36646
Policy Entropy: 3.03424
Value Function Loss: 0.00458

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.59617
Value Function Update Magnitude: 0.53832

Collected Steps per Second: 22,199.54943
Overall Steps per Second: 10,862.90225

Timestep Collection Time: 2.25302
Timestep Consumption Time: 2.35128
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60429

Cumulative Model Updates: 167,168
Cumulative Timesteps: 1,394,186,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040.22093
Policy Entropy: 3.03610
Value Function Loss: 0.00457

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.58528
Value Function Update Magnitude: 0.52690

Collected Steps per Second: 22,028.11613
Overall Steps per Second: 10,671.91127

Timestep Collection Time: 2.27010
Timestep Consumption Time: 2.41566
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.68576

Cumulative Model Updates: 167,174
Cumulative Timesteps: 1,394,236,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1394236496...
Checkpoint 1394236496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.23411
Policy Entropy: 3.03234
Value Function Loss: 0.00438

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.59000
Value Function Update Magnitude: 0.53938

Collected Steps per Second: 22,140.43895
Overall Steps per Second: 10,702.72086

Timestep Collection Time: 2.25930
Timestep Consumption Time: 2.41446
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.67376

Cumulative Model Updates: 167,180
Cumulative Timesteps: 1,394,286,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,913.23954
Policy Entropy: 3.00619
Value Function Loss: 0.00451

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.59956
Value Function Update Magnitude: 0.53375

Collected Steps per Second: 23,028.62731
Overall Steps per Second: 10,866.00703

Timestep Collection Time: 2.17191
Timestep Consumption Time: 2.43107
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.60298

Cumulative Model Updates: 167,186
Cumulative Timesteps: 1,394,336,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1394336534...
Checkpoint 1394336534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.52693
Policy Entropy: 2.98077
Value Function Loss: 0.00449

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.60344
Value Function Update Magnitude: 0.57345

Collected Steps per Second: 22,396.28823
Overall Steps per Second: 10,634.33084

Timestep Collection Time: 2.23367
Timestep Consumption Time: 2.47052
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70420

Cumulative Model Updates: 167,192
Cumulative Timesteps: 1,394,386,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,972.18761
Policy Entropy: 2.99033
Value Function Loss: 0.00431

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11689
Policy Update Magnitude: 0.60232
Value Function Update Magnitude: 0.54651

Collected Steps per Second: 23,225.20314
Overall Steps per Second: 10,773.75247

Timestep Collection Time: 2.15413
Timestep Consumption Time: 2.48957
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.64369

Cumulative Model Updates: 167,198
Cumulative Timesteps: 1,394,436,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1394436590...
Checkpoint 1394436590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,379.46953
Policy Entropy: 3.00989
Value Function Loss: 0.00402

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.59322
Value Function Update Magnitude: 0.52827

Collected Steps per Second: 22,594.59028
Overall Steps per Second: 10,598.47311

Timestep Collection Time: 2.21301
Timestep Consumption Time: 2.50484
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.71785

Cumulative Model Updates: 167,204
Cumulative Timesteps: 1,394,486,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,650.06126
Policy Entropy: 3.03512
Value Function Loss: 0.00406

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.58816
Value Function Update Magnitude: 0.51914

Collected Steps per Second: 23,094.09414
Overall Steps per Second: 10,937.78575

Timestep Collection Time: 2.16532
Timestep Consumption Time: 2.40654
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.57186

Cumulative Model Updates: 167,210
Cumulative Timesteps: 1,394,536,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1394536598...
Checkpoint 1394536598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.29637
Policy Entropy: 3.04149
Value Function Loss: 0.00435

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11876
Policy Update Magnitude: 0.59669
Value Function Update Magnitude: 0.53286

Collected Steps per Second: 22,953.65971
Overall Steps per Second: 10,789.33450

Timestep Collection Time: 2.17891
Timestep Consumption Time: 2.45659
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.63550

Cumulative Model Updates: 167,216
Cumulative Timesteps: 1,394,586,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,855.42878
Policy Entropy: 3.05132
Value Function Loss: 0.00464

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.59445
Value Function Update Magnitude: 0.53163

Collected Steps per Second: 23,118.76044
Overall Steps per Second: 10,720.04827

Timestep Collection Time: 2.16352
Timestep Consumption Time: 2.50231
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.66584

Cumulative Model Updates: 167,222
Cumulative Timesteps: 1,394,636,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1394636630...
Checkpoint 1394636630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,985.49164
Policy Entropy: 3.05356
Value Function Loss: 0.00453

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.57953
Value Function Update Magnitude: 0.52249

Collected Steps per Second: 22,246.82034
Overall Steps per Second: 10,656.94992

Timestep Collection Time: 2.24859
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.69403

Cumulative Model Updates: 167,228
Cumulative Timesteps: 1,394,686,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,894.60426
Policy Entropy: 3.04174
Value Function Loss: 0.00411

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.57148
Value Function Update Magnitude: 0.50314

Collected Steps per Second: 22,451.71085
Overall Steps per Second: 10,559.31618

Timestep Collection Time: 2.22825
Timestep Consumption Time: 2.50956
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.73781

Cumulative Model Updates: 167,234
Cumulative Timesteps: 1,394,736,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1394736682...
Checkpoint 1394736682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.92678
Policy Entropy: 3.02102
Value Function Loss: 0.00371

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.56388
Value Function Update Magnitude: 0.49097

Collected Steps per Second: 22,560.02070
Overall Steps per Second: 10,606.89992

Timestep Collection Time: 2.21729
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.71599

Cumulative Model Updates: 167,240
Cumulative Timesteps: 1,394,786,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,120.13513
Policy Entropy: 3.02159
Value Function Loss: 0.00387

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.48790

Collected Steps per Second: 23,062.48242
Overall Steps per Second: 10,794.60099

Timestep Collection Time: 2.16872
Timestep Consumption Time: 2.46471
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.63343

Cumulative Model Updates: 167,246
Cumulative Timesteps: 1,394,836,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1394836720...
Checkpoint 1394836720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.60360
Policy Entropy: 3.03212
Value Function Loss: 0.00424

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.56574
Value Function Update Magnitude: 0.47988

Collected Steps per Second: 23,200.77210
Overall Steps per Second: 10,704.96511

Timestep Collection Time: 2.15527
Timestep Consumption Time: 2.51583
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.67110

Cumulative Model Updates: 167,252
Cumulative Timesteps: 1,394,886,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,047.39255
Policy Entropy: 3.02619
Value Function Loss: 0.00473

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.56798
Value Function Update Magnitude: 0.47468

Collected Steps per Second: 23,526.91434
Overall Steps per Second: 10,886.04566

Timestep Collection Time: 2.12548
Timestep Consumption Time: 2.46811
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.59359

Cumulative Model Updates: 167,258
Cumulative Timesteps: 1,394,936,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1394936730...
Checkpoint 1394936730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.40967
Policy Entropy: 3.00896
Value Function Loss: 0.00511

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.58271
Value Function Update Magnitude: 0.47437

Collected Steps per Second: 22,920.63678
Overall Steps per Second: 10,656.30432

Timestep Collection Time: 2.18240
Timestep Consumption Time: 2.51172
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.69412

Cumulative Model Updates: 167,264
Cumulative Timesteps: 1,394,986,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,295.73342
Policy Entropy: 2.98896
Value Function Loss: 0.00491

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.59512
Value Function Update Magnitude: 0.51331

Collected Steps per Second: 23,120.25961
Overall Steps per Second: 10,849.54765

Timestep Collection Time: 2.16312
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60959

Cumulative Model Updates: 167,270
Cumulative Timesteps: 1,395,036,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1395036764...
Checkpoint 1395036764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,323.61415
Policy Entropy: 2.99387
Value Function Loss: 0.00432

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10912
Policy Update Magnitude: 0.57490
Value Function Update Magnitude: 0.51990

Collected Steps per Second: 23,260.84574
Overall Steps per Second: 10,769.03419

Timestep Collection Time: 2.15005
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.64406

Cumulative Model Updates: 167,276
Cumulative Timesteps: 1,395,086,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.95532
Policy Entropy: 3.00382
Value Function Loss: 0.00429

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.57797
Value Function Update Magnitude: 0.52255

Collected Steps per Second: 22,740.99071
Overall Steps per Second: 10,799.67209

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62977

Cumulative Model Updates: 167,282
Cumulative Timesteps: 1,395,136,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1395136776...
Checkpoint 1395136776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.04678
Policy Entropy: 3.00573
Value Function Loss: 0.00437

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.59336
Value Function Update Magnitude: 0.51510

Collected Steps per Second: 22,733.29853
Overall Steps per Second: 10,718.48245

Timestep Collection Time: 2.20038
Timestep Consumption Time: 2.46651
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.66689

Cumulative Model Updates: 167,288
Cumulative Timesteps: 1,395,186,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.36482
Policy Entropy: 3.00038
Value Function Loss: 0.00476

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.59964
Value Function Update Magnitude: 0.52498

Collected Steps per Second: 22,839.24113
Overall Steps per Second: 10,874.50780

Timestep Collection Time: 2.18948
Timestep Consumption Time: 2.40898
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.59846

Cumulative Model Updates: 167,294
Cumulative Timesteps: 1,395,236,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1395236804...
Checkpoint 1395236804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,449.99199
Policy Entropy: 3.00394
Value Function Loss: 0.00444

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.59264
Value Function Update Magnitude: 0.52216

Collected Steps per Second: 22,982.91389
Overall Steps per Second: 10,823.72063

Timestep Collection Time: 2.17640
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.62133

Cumulative Model Updates: 167,300
Cumulative Timesteps: 1,395,286,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,711.77181
Policy Entropy: 2.99803
Value Function Loss: 0.00460

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.60177
Value Function Update Magnitude: 0.50631

Collected Steps per Second: 22,621.24490
Overall Steps per Second: 10,706.70460

Timestep Collection Time: 2.21031
Timestep Consumption Time: 2.45966
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.66997

Cumulative Model Updates: 167,306
Cumulative Timesteps: 1,395,336,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1395336824...
Checkpoint 1395336824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.92479
Policy Entropy: 2.99892
Value Function Loss: 0.00498

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.60741
Value Function Update Magnitude: 0.53538

Collected Steps per Second: 23,119.50648
Overall Steps per Second: 10,767.34036

Timestep Collection Time: 2.16363
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.64572

Cumulative Model Updates: 167,312
Cumulative Timesteps: 1,395,386,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.49735
Policy Entropy: 2.98695
Value Function Loss: 0.00506

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.61183
Value Function Update Magnitude: 0.55428

Collected Steps per Second: 23,340.48677
Overall Steps per Second: 10,755.14442

Timestep Collection Time: 2.14289
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.65043

Cumulative Model Updates: 167,318
Cumulative Timesteps: 1,395,436,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1395436862...
Checkpoint 1395436862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,636.85062
Policy Entropy: 2.98705
Value Function Loss: 0.00489

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.61437
Value Function Update Magnitude: 0.55351

Collected Steps per Second: 23,096.51851
Overall Steps per Second: 10,804.28306

Timestep Collection Time: 2.16526
Timestep Consumption Time: 2.46346
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.62872

Cumulative Model Updates: 167,324
Cumulative Timesteps: 1,395,486,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,297.54963
Policy Entropy: 3.00171
Value Function Loss: 0.00466

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.61145
Value Function Update Magnitude: 0.55570

Collected Steps per Second: 23,323.95663
Overall Steps per Second: 10,747.02894

Timestep Collection Time: 2.14475
Timestep Consumption Time: 2.50993
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.65468

Cumulative Model Updates: 167,330
Cumulative Timesteps: 1,395,536,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1395536896...
Checkpoint 1395536896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.68922
Policy Entropy: 3.02082
Value Function Loss: 0.00446

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.60273
Value Function Update Magnitude: 0.53440

Collected Steps per Second: 23,075.34320
Overall Steps per Second: 10,777.45567

Timestep Collection Time: 2.16716
Timestep Consumption Time: 2.47289
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.64006

Cumulative Model Updates: 167,336
Cumulative Timesteps: 1,395,586,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.52581
Policy Entropy: 3.03208
Value Function Loss: 0.00477

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.59693
Value Function Update Magnitude: 0.53056

Collected Steps per Second: 23,256.46719
Overall Steps per Second: 10,725.01330

Timestep Collection Time: 2.15028
Timestep Consumption Time: 2.51246
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.66274

Cumulative Model Updates: 167,342
Cumulative Timesteps: 1,395,636,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1395636912...
Checkpoint 1395636912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.47548
Policy Entropy: 3.02207
Value Function Loss: 0.00465

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.59500
Value Function Update Magnitude: 0.53461

Collected Steps per Second: 22,718.68437
Overall Steps per Second: 10,679.59092

Timestep Collection Time: 2.20171
Timestep Consumption Time: 2.48199
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.68370

Cumulative Model Updates: 167,348
Cumulative Timesteps: 1,395,686,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,038.93961
Policy Entropy: 3.02406
Value Function Loss: 0.00461

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.15323
Policy Update Magnitude: 0.59593
Value Function Update Magnitude: 0.54598

Collected Steps per Second: 22,800.08514
Overall Steps per Second: 10,806.76589

Timestep Collection Time: 2.19359
Timestep Consumption Time: 2.43444
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.62803

Cumulative Model Updates: 167,354
Cumulative Timesteps: 1,395,736,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1395736946...
Checkpoint 1395736946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,684.15441
Policy Entropy: 3.03538
Value Function Loss: 0.00437

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.14908
Policy Update Magnitude: 0.59565
Value Function Update Magnitude: 0.53184

Collected Steps per Second: 22,461.78343
Overall Steps per Second: 10,761.01306

Timestep Collection Time: 2.22618
Timestep Consumption Time: 2.42059
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.64677

Cumulative Model Updates: 167,360
Cumulative Timesteps: 1,395,786,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.65475
Policy Entropy: 3.05396
Value Function Loss: 0.00412

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.58277
Value Function Update Magnitude: 0.50792

Collected Steps per Second: 22,728.73310
Overall Steps per Second: 10,814.24174

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.42445
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.62501

Cumulative Model Updates: 167,366
Cumulative Timesteps: 1,395,836,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1395836966...
Checkpoint 1395836966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.90327
Policy Entropy: 3.05491
Value Function Loss: 0.00402

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.56907
Value Function Update Magnitude: 0.47420

Collected Steps per Second: 23,081.06889
Overall Steps per Second: 10,706.70160

Timestep Collection Time: 2.16697
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.67147

Cumulative Model Updates: 167,372
Cumulative Timesteps: 1,395,886,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,200.67530
Policy Entropy: 3.04673
Value Function Loss: 0.00373

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12274
Policy Update Magnitude: 0.56696
Value Function Update Magnitude: 0.47497

Collected Steps per Second: 23,272.54726
Overall Steps per Second: 10,891.00411

Timestep Collection Time: 2.14931
Timestep Consumption Time: 2.44347
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.59278

Cumulative Model Updates: 167,378
Cumulative Timesteps: 1,395,937,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1395937002...
Checkpoint 1395937002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.11966
Policy Entropy: 3.03716
Value Function Loss: 0.00455

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.58467
Value Function Update Magnitude: 0.51143

Collected Steps per Second: 22,798.08053
Overall Steps per Second: 10,655.47674

Timestep Collection Time: 2.19352
Timestep Consumption Time: 2.49966
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.69317

Cumulative Model Updates: 167,384
Cumulative Timesteps: 1,395,987,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,923.56787
Policy Entropy: 3.03004
Value Function Loss: 0.00487

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.61078
Value Function Update Magnitude: 0.57408

Collected Steps per Second: 23,090.44507
Overall Steps per Second: 10,866.34800

Timestep Collection Time: 2.16678
Timestep Consumption Time: 2.43752
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60431

Cumulative Model Updates: 167,390
Cumulative Timesteps: 1,396,037,042

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1396037042...
Checkpoint 1396037042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.54126
Policy Entropy: 3.02844
Value Function Loss: 0.00470

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.59978
Value Function Update Magnitude: 0.58490

Collected Steps per Second: 22,999.22980
Overall Steps per Second: 10,650.34800

Timestep Collection Time: 2.17451
Timestep Consumption Time: 2.52130
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.69581

Cumulative Model Updates: 167,396
Cumulative Timesteps: 1,396,087,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.77607
Policy Entropy: 3.00761
Value Function Loss: 0.00439

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.59434
Value Function Update Magnitude: 0.55434

Collected Steps per Second: 23,217.48299
Overall Steps per Second: 10,999.62804

Timestep Collection Time: 2.15407
Timestep Consumption Time: 2.39263
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.54670

Cumulative Model Updates: 167,402
Cumulative Timesteps: 1,396,137,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1396137066...
Checkpoint 1396137066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.80333
Policy Entropy: 3.00770
Value Function Loss: 0.00423

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.58748
Value Function Update Magnitude: 0.52972

Collected Steps per Second: 22,379.06650
Overall Steps per Second: 10,644.77148

Timestep Collection Time: 2.23486
Timestep Consumption Time: 2.46360
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.69846

Cumulative Model Updates: 167,408
Cumulative Timesteps: 1,396,187,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.97434
Policy Entropy: 2.99767
Value Function Loss: 0.00446

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.59360
Value Function Update Magnitude: 0.52752

Collected Steps per Second: 23,059.14697
Overall Steps per Second: 10,864.09831

Timestep Collection Time: 2.16903
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.60379

Cumulative Model Updates: 167,414
Cumulative Timesteps: 1,396,237,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1396237096...
Checkpoint 1396237096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.36261
Policy Entropy: 2.99791
Value Function Loss: 0.00466

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.60295
Value Function Update Magnitude: 0.54990

Collected Steps per Second: 22,837.42133
Overall Steps per Second: 10,730.02751

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.66243

Cumulative Model Updates: 167,420
Cumulative Timesteps: 1,396,287,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.65889
Policy Entropy: 2.98453
Value Function Loss: 0.00521

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.62018
Value Function Update Magnitude: 0.56292

Collected Steps per Second: 22,869.53815
Overall Steps per Second: 10,753.86646

Timestep Collection Time: 2.18719
Timestep Consumption Time: 2.46416
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.65135

Cumulative Model Updates: 167,426
Cumulative Timesteps: 1,396,337,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1396337144...
Checkpoint 1396337144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.87753
Policy Entropy: 2.98779
Value Function Loss: 0.00503

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.61596
Value Function Update Magnitude: 0.57622

Collected Steps per Second: 23,194.77207
Overall Steps per Second: 10,670.16498

Timestep Collection Time: 2.15574
Timestep Consumption Time: 2.53041
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.68615

Cumulative Model Updates: 167,432
Cumulative Timesteps: 1,396,387,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.09716
Policy Entropy: 2.98729
Value Function Loss: 0.00496

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.61007
Value Function Update Magnitude: 0.59886

Collected Steps per Second: 22,553.72640
Overall Steps per Second: 10,690.21903

Timestep Collection Time: 2.21790
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.67923

Cumulative Model Updates: 167,438
Cumulative Timesteps: 1,396,437,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1396437168...
Checkpoint 1396437168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,330.18164
Policy Entropy: 2.98548
Value Function Loss: 0.00489

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.61078
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 22,918.36774
Overall Steps per Second: 10,849.21191

Timestep Collection Time: 2.18305
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61158

Cumulative Model Updates: 167,444
Cumulative Timesteps: 1,396,487,200

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,396.87276
Policy Entropy: 2.97567
Value Function Loss: 0.00505

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.62091
Value Function Update Magnitude: 0.63769

Collected Steps per Second: 22,659.74486
Overall Steps per Second: 10,631.63721

Timestep Collection Time: 2.20744
Timestep Consumption Time: 2.49739
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.70483

Cumulative Model Updates: 167,450
Cumulative Timesteps: 1,396,537,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1396537220...
Checkpoint 1396537220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.61799
Policy Entropy: 2.97689
Value Function Loss: 0.00510

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.63187
Value Function Update Magnitude: 0.62690

Collected Steps per Second: 23,007.75081
Overall Steps per Second: 10,908.76991

Timestep Collection Time: 2.17318
Timestep Consumption Time: 2.41029
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.58347

Cumulative Model Updates: 167,456
Cumulative Timesteps: 1,396,587,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.33648
Policy Entropy: 2.99399
Value Function Loss: 0.00469

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.62427
Value Function Update Magnitude: 0.61051

Collected Steps per Second: 22,923.28017
Overall Steps per Second: 10,683.10935

Timestep Collection Time: 2.18171
Timestep Consumption Time: 2.49970
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.68141

Cumulative Model Updates: 167,462
Cumulative Timesteps: 1,396,637,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1396637232...
Checkpoint 1396637232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,120.55322
Policy Entropy: 3.01553
Value Function Loss: 0.00439

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.59884
Value Function Update Magnitude: 0.57445

Collected Steps per Second: 23,343.56361
Overall Steps per Second: 10,907.14126

Timestep Collection Time: 2.14243
Timestep Consumption Time: 2.44282
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.58525

Cumulative Model Updates: 167,468
Cumulative Timesteps: 1,396,687,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.11250
Policy Entropy: 3.02500
Value Function Loss: 0.00449

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.59272
Value Function Update Magnitude: 0.59181

Collected Steps per Second: 23,093.44600
Overall Steps per Second: 10,961.94737

Timestep Collection Time: 2.16590
Timestep Consumption Time: 2.39698
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.56288

Cumulative Model Updates: 167,474
Cumulative Timesteps: 1,396,737,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1396737262...
Checkpoint 1396737262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.60050
Policy Entropy: 3.01881
Value Function Loss: 0.00452

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.61304
Value Function Update Magnitude: 0.61556

Collected Steps per Second: 23,147.13682
Overall Steps per Second: 10,736.04895

Timestep Collection Time: 2.16070
Timestep Consumption Time: 2.49781
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.65851

Cumulative Model Updates: 167,480
Cumulative Timesteps: 1,396,787,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,047.42602
Policy Entropy: 3.01778
Value Function Loss: 0.00460

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.62337
Value Function Update Magnitude: 0.61032

Collected Steps per Second: 23,136.95307
Overall Steps per Second: 10,836.39993

Timestep Collection Time: 2.16200
Timestep Consumption Time: 2.45411
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.61611

Cumulative Model Updates: 167,486
Cumulative Timesteps: 1,396,837,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1396837298...
Checkpoint 1396837298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.80553
Policy Entropy: 3.02565
Value Function Loss: 0.00411

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.61385
Value Function Update Magnitude: 0.61287

Collected Steps per Second: 22,507.68587
Overall Steps per Second: 10,614.62148

Timestep Collection Time: 2.22164
Timestep Consumption Time: 2.48922
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.71086

Cumulative Model Updates: 167,492
Cumulative Timesteps: 1,396,887,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.87061
Policy Entropy: 3.00810
Value Function Loss: 0.00453

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.60873
Value Function Update Magnitude: 0.59748

Collected Steps per Second: 22,541.13764
Overall Steps per Second: 10,607.75740

Timestep Collection Time: 2.21897
Timestep Consumption Time: 2.49626
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.71523

Cumulative Model Updates: 167,498
Cumulative Timesteps: 1,396,937,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1396937320...
Checkpoint 1396937320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,157.08432
Policy Entropy: 3.00187
Value Function Loss: 0.00477

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.61130
Value Function Update Magnitude: 0.59119

Collected Steps per Second: 22,608.70053
Overall Steps per Second: 10,617.87386

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.49850
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.71092

Cumulative Model Updates: 167,504
Cumulative Timesteps: 1,396,987,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,656.97219
Policy Entropy: 3.00295
Value Function Loss: 0.00495

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.61443
Value Function Update Magnitude: 0.57898

Collected Steps per Second: 22,706.39100
Overall Steps per Second: 10,759.15470

Timestep Collection Time: 2.20299
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.64925

Cumulative Model Updates: 167,510
Cumulative Timesteps: 1,397,037,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1397037362...
Checkpoint 1397037362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.40173
Policy Entropy: 3.02318
Value Function Loss: 0.00462

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.60417
Value Function Update Magnitude: 0.56153

Collected Steps per Second: 22,557.70089
Overall Steps per Second: 10,625.21345

Timestep Collection Time: 2.21734
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.70748

Cumulative Model Updates: 167,516
Cumulative Timesteps: 1,397,087,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.31979
Policy Entropy: 3.02715
Value Function Loss: 0.00438

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.59127
Value Function Update Magnitude: 0.53675

Collected Steps per Second: 23,031.09262
Overall Steps per Second: 10,704.72777

Timestep Collection Time: 2.17098
Timestep Consumption Time: 2.49986
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.67083

Cumulative Model Updates: 167,522
Cumulative Timesteps: 1,397,137,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1397137380...
Checkpoint 1397137380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,598.13109
Policy Entropy: 3.02151
Value Function Loss: 0.00474

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.59157
Value Function Update Magnitude: 0.54070

Collected Steps per Second: 23,066.09321
Overall Steps per Second: 10,868.24179

Timestep Collection Time: 2.16829
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.60185

Cumulative Model Updates: 167,528
Cumulative Timesteps: 1,397,187,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.67381
Policy Entropy: 3.01709
Value Function Loss: 0.00490

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.59883
Value Function Update Magnitude: 0.54947

Collected Steps per Second: 22,996.22759
Overall Steps per Second: 10,802.16215

Timestep Collection Time: 2.17505
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.63037

Cumulative Model Updates: 167,534
Cumulative Timesteps: 1,397,237,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1397237412...
Checkpoint 1397237412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.20378
Policy Entropy: 3.02449
Value Function Loss: 0.00492

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.59804
Value Function Update Magnitude: 0.54317

Collected Steps per Second: 22,971.95709
Overall Steps per Second: 10,720.58143

Timestep Collection Time: 2.17665
Timestep Consumption Time: 2.48746
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.66411

Cumulative Model Updates: 167,540
Cumulative Timesteps: 1,397,287,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,397.99405
Policy Entropy: 3.02802
Value Function Loss: 0.00497

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.59366
Value Function Update Magnitude: 0.54374

Collected Steps per Second: 23,130.39587
Overall Steps per Second: 10,975.14039

Timestep Collection Time: 2.16287
Timestep Consumption Time: 2.39543
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.55830

Cumulative Model Updates: 167,546
Cumulative Timesteps: 1,397,337,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1397337442...
Checkpoint 1397337442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,489.28749
Policy Entropy: 3.03603
Value Function Loss: 0.00481

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.59619
Value Function Update Magnitude: 0.55657

Collected Steps per Second: 22,906.09751
Overall Steps per Second: 10,697.04788

Timestep Collection Time: 2.18282
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.67419

Cumulative Model Updates: 167,552
Cumulative Timesteps: 1,397,387,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.93669
Policy Entropy: 3.03256
Value Function Loss: 0.00477

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.61515
Value Function Update Magnitude: 0.56362

Collected Steps per Second: 22,633.43481
Overall Steps per Second: 10,773.49836

Timestep Collection Time: 2.20930
Timestep Consumption Time: 2.43209
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.64139

Cumulative Model Updates: 167,558
Cumulative Timesteps: 1,397,437,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1397437446...
Checkpoint 1397437446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.98755
Policy Entropy: 3.03872
Value Function Loss: 0.00436

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.61595
Value Function Update Magnitude: 0.58260

Collected Steps per Second: 22,819.78821
Overall Steps per Second: 10,649.94486

Timestep Collection Time: 2.19248
Timestep Consumption Time: 2.50538
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.69786

Cumulative Model Updates: 167,564
Cumulative Timesteps: 1,397,487,478

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,830.73671
Policy Entropy: 3.01916
Value Function Loss: 0.00434

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.60968
Value Function Update Magnitude: 0.57510

Collected Steps per Second: 22,522.48804
Overall Steps per Second: 10,612.74005

Timestep Collection Time: 2.22045
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.71226

Cumulative Model Updates: 167,570
Cumulative Timesteps: 1,397,537,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1397537488...
Checkpoint 1397537488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,483.74293
Policy Entropy: 3.00675
Value Function Loss: 0.00457

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.61022
Value Function Update Magnitude: 0.55323

Collected Steps per Second: 22,508.63006
Overall Steps per Second: 10,629.36364

Timestep Collection Time: 2.22235
Timestep Consumption Time: 2.48367
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70602

Cumulative Model Updates: 167,576
Cumulative Timesteps: 1,397,587,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.62858
Policy Entropy: 3.01029
Value Function Loss: 0.00493

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.61707
Value Function Update Magnitude: 0.56967

Collected Steps per Second: 23,150.40236
Overall Steps per Second: 10,785.12627

Timestep Collection Time: 2.16057
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.63768

Cumulative Model Updates: 167,582
Cumulative Timesteps: 1,397,637,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1397637528...
Checkpoint 1397637528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880.66312
Policy Entropy: 3.02311
Value Function Loss: 0.00481

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.60754
Value Function Update Magnitude: 0.57027

Collected Steps per Second: 22,977.69437
Overall Steps per Second: 10,653.60629

Timestep Collection Time: 2.17672
Timestep Consumption Time: 2.51803
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.69475

Cumulative Model Updates: 167,588
Cumulative Timesteps: 1,397,687,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.84459
Policy Entropy: 3.03237
Value Function Loss: 0.00469

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.59527
Value Function Update Magnitude: 0.55551

Collected Steps per Second: 23,091.70119
Overall Steps per Second: 10,875.58692

Timestep Collection Time: 2.16641
Timestep Consumption Time: 2.43344
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.59984

Cumulative Model Updates: 167,594
Cumulative Timesteps: 1,397,737,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1397737570...
Checkpoint 1397737570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,106.95355
Policy Entropy: 3.02203
Value Function Loss: 0.00435

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.59594
Value Function Update Magnitude: 0.54274

Collected Steps per Second: 23,091.43058
Overall Steps per Second: 10,736.87203

Timestep Collection Time: 2.16652
Timestep Consumption Time: 2.49294
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.65946

Cumulative Model Updates: 167,600
Cumulative Timesteps: 1,397,787,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.24008
Policy Entropy: 3.01317
Value Function Loss: 0.00433

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.58739
Value Function Update Magnitude: 0.55226

Collected Steps per Second: 23,341.50638
Overall Steps per Second: 10,833.52835

Timestep Collection Time: 2.14331
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.61789

Cumulative Model Updates: 167,606
Cumulative Timesteps: 1,397,837,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1397837626...
Checkpoint 1397837626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,365.72509
Policy Entropy: 3.01334
Value Function Loss: 0.00420

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.57913
Value Function Update Magnitude: 0.53445

Collected Steps per Second: 22,833.43432
Overall Steps per Second: 10,639.76253

Timestep Collection Time: 2.19012
Timestep Consumption Time: 2.50998
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.70010

Cumulative Model Updates: 167,612
Cumulative Timesteps: 1,397,887,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274.11479
Policy Entropy: 3.01618
Value Function Loss: 0.00412

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.57430
Value Function Update Magnitude: 0.50961

Collected Steps per Second: 22,993.75383
Overall Steps per Second: 10,850.24223

Timestep Collection Time: 2.17529
Timestep Consumption Time: 2.43456
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60985

Cumulative Model Updates: 167,618
Cumulative Timesteps: 1,397,937,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1397937652...
Checkpoint 1397937652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817.47948
Policy Entropy: 3.01114
Value Function Loss: 0.00439

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.57846
Value Function Update Magnitude: 0.51634

Collected Steps per Second: 22,498.18784
Overall Steps per Second: 10,745.52240

Timestep Collection Time: 2.22276
Timestep Consumption Time: 2.43109
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.65385

Cumulative Model Updates: 167,624
Cumulative Timesteps: 1,397,987,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.87579
Policy Entropy: 3.00919
Value Function Loss: 0.00468

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.59053
Value Function Update Magnitude: 0.53471

Collected Steps per Second: 23,112.01482
Overall Steps per Second: 10,864.78838

Timestep Collection Time: 2.16450
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.60442

Cumulative Model Updates: 167,630
Cumulative Timesteps: 1,398,037,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1398037686...
Checkpoint 1398037686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.05242
Policy Entropy: 3.01981
Value Function Loss: 0.00499

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.60026
Value Function Update Magnitude: 0.55727

Collected Steps per Second: 22,845.76904
Overall Steps per Second: 10,601.32304

Timestep Collection Time: 2.18929
Timestep Consumption Time: 2.52861
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.71790

Cumulative Model Updates: 167,636
Cumulative Timesteps: 1,398,087,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,384.53698
Policy Entropy: 3.03831
Value Function Loss: 0.00505

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.60880
Value Function Update Magnitude: 0.57954

Collected Steps per Second: 22,551.97931
Overall Steps per Second: 10,571.50201

Timestep Collection Time: 2.21763
Timestep Consumption Time: 2.51320
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.73083

Cumulative Model Updates: 167,642
Cumulative Timesteps: 1,398,137,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1398137714...
Checkpoint 1398137714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.52411
Policy Entropy: 3.04971
Value Function Loss: 0.00461

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11629
Policy Update Magnitude: 0.60044
Value Function Update Magnitude: 0.59653

Collected Steps per Second: 22,971.00549
Overall Steps per Second: 10,650.16008

Timestep Collection Time: 2.17770
Timestep Consumption Time: 2.51932
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.69702

Cumulative Model Updates: 167,648
Cumulative Timesteps: 1,398,187,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.07966
Policy Entropy: 3.03597
Value Function Loss: 0.00442

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.58814
Value Function Update Magnitude: 0.57316

Collected Steps per Second: 23,372.77302
Overall Steps per Second: 10,783.99115

Timestep Collection Time: 2.13993
Timestep Consumption Time: 2.49806
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.63799

Cumulative Model Updates: 167,654
Cumulative Timesteps: 1,398,237,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1398237754...
Checkpoint 1398237754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,490.41820
Policy Entropy: 3.02484
Value Function Loss: 0.00424

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.54163

Collected Steps per Second: 23,247.55317
Overall Steps per Second: 10,848.69402

Timestep Collection Time: 2.15223
Timestep Consumption Time: 2.45976
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.61198

Cumulative Model Updates: 167,660
Cumulative Timesteps: 1,398,287,788

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.28966
Policy Entropy: 3.02530
Value Function Loss: 0.00438

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.52302

Collected Steps per Second: 22,709.88353
Overall Steps per Second: 10,682.76907

Timestep Collection Time: 2.20212
Timestep Consumption Time: 2.47925
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.68137

Cumulative Model Updates: 167,666
Cumulative Timesteps: 1,398,337,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1398337798...
Checkpoint 1398337798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,833.08722
Policy Entropy: 3.04035
Value Function Loss: 0.00428

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.58947
Value Function Update Magnitude: 0.52697

Collected Steps per Second: 23,249.06955
Overall Steps per Second: 10,763.12316

Timestep Collection Time: 2.15166
Timestep Consumption Time: 2.49607
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.64772

Cumulative Model Updates: 167,672
Cumulative Timesteps: 1,398,387,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,220.76068
Policy Entropy: 3.03518
Value Function Loss: 0.00410

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.58334
Value Function Update Magnitude: 0.51791

Collected Steps per Second: 23,290.97076
Overall Steps per Second: 10,809.42498

Timestep Collection Time: 2.14693
Timestep Consumption Time: 2.47904
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.62596

Cumulative Model Updates: 167,678
Cumulative Timesteps: 1,398,437,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1398437826...
Checkpoint 1398437826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,365.44138
Policy Entropy: 3.04020
Value Function Loss: 0.00413

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.58877
Value Function Update Magnitude: 0.52309

Collected Steps per Second: 22,562.21163
Overall Steps per Second: 10,650.45518

Timestep Collection Time: 2.21689
Timestep Consumption Time: 2.47943
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.69633

Cumulative Model Updates: 167,684
Cumulative Timesteps: 1,398,487,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,148.51656
Policy Entropy: 3.03830
Value Function Loss: 0.00411

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.58898
Value Function Update Magnitude: 0.51287

Collected Steps per Second: 22,382.29624
Overall Steps per Second: 10,585.40552

Timestep Collection Time: 2.23436
Timestep Consumption Time: 2.49007
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.72443

Cumulative Model Updates: 167,690
Cumulative Timesteps: 1,398,537,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1398537854...
Checkpoint 1398537854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,146.97925
Policy Entropy: 3.03708
Value Function Loss: 0.00398

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.58780
Value Function Update Magnitude: 0.50478

Collected Steps per Second: 22,553.87277
Overall Steps per Second: 10,649.70459

Timestep Collection Time: 2.21753
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.69628

Cumulative Model Updates: 167,696
Cumulative Timesteps: 1,398,587,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954.57660
Policy Entropy: 3.02322
Value Function Loss: 0.00433

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.59520
Value Function Update Magnitude: 0.52943

Collected Steps per Second: 22,869.04948
Overall Steps per Second: 10,736.83200

Timestep Collection Time: 2.18750
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.65929

Cumulative Model Updates: 167,702
Cumulative Timesteps: 1,398,637,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1398637894...
Checkpoint 1398637894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,964.89560
Policy Entropy: 3.02723
Value Function Loss: 0.00427

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.59124
Value Function Update Magnitude: 0.55130

Collected Steps per Second: 22,586.78777
Overall Steps per Second: 10,658.47718

Timestep Collection Time: 2.21457
Timestep Consumption Time: 2.47841
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.69298

Cumulative Model Updates: 167,708
Cumulative Timesteps: 1,398,687,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.04973
Policy Entropy: 3.03801
Value Function Loss: 0.00433

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.58056
Value Function Update Magnitude: 0.56877

Collected Steps per Second: 23,216.16294
Overall Steps per Second: 10,860.43377

Timestep Collection Time: 2.15496
Timestep Consumption Time: 2.45167
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60663

Cumulative Model Updates: 167,714
Cumulative Timesteps: 1,398,737,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1398737944...
Checkpoint 1398737944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.70458
Policy Entropy: 3.04914
Value Function Loss: 0.00390

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.57420
Value Function Update Magnitude: 0.55121

Collected Steps per Second: 22,907.31783
Overall Steps per Second: 10,683.90011

Timestep Collection Time: 2.18358
Timestep Consumption Time: 2.49823
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.68181

Cumulative Model Updates: 167,720
Cumulative Timesteps: 1,398,787,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,829.63142
Policy Entropy: 3.05040
Value Function Loss: 0.00419

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.53255

Collected Steps per Second: 23,524.86728
Overall Steps per Second: 10,965.94393

Timestep Collection Time: 2.12643
Timestep Consumption Time: 2.43533
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.56176

Cumulative Model Updates: 167,726
Cumulative Timesteps: 1,398,837,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1398837988...
Checkpoint 1398837988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,576.25125
Policy Entropy: 3.04720
Value Function Loss: 0.00418

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.57056
Value Function Update Magnitude: 0.53129

Collected Steps per Second: 23,224.98920
Overall Steps per Second: 10,810.01744

Timestep Collection Time: 2.15389
Timestep Consumption Time: 2.47367
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.62756

Cumulative Model Updates: 167,732
Cumulative Timesteps: 1,398,888,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.99445
Policy Entropy: 3.03267
Value Function Loss: 0.00429

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.56940
Value Function Update Magnitude: 0.53482

Collected Steps per Second: 23,337.00399
Overall Steps per Second: 10,765.46846

Timestep Collection Time: 2.14303
Timestep Consumption Time: 2.50256
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.64559

Cumulative Model Updates: 167,738
Cumulative Timesteps: 1,398,938,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1398938024...
Checkpoint 1398938024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,177.37635
Policy Entropy: 3.03920
Value Function Loss: 0.00444

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.57583
Value Function Update Magnitude: 0.52348

Collected Steps per Second: 23,269.41679
Overall Steps per Second: 10,806.28491

Timestep Collection Time: 2.14969
Timestep Consumption Time: 2.47928
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.62897

Cumulative Model Updates: 167,744
Cumulative Timesteps: 1,398,988,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,244.92133
Policy Entropy: 3.03467
Value Function Loss: 0.00442

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.58077
Value Function Update Magnitude: 0.52507

Collected Steps per Second: 22,321.96459
Overall Steps per Second: 10,673.62049

Timestep Collection Time: 2.24039
Timestep Consumption Time: 2.44499
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.68538

Cumulative Model Updates: 167,750
Cumulative Timesteps: 1,399,038,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1399038056...
Checkpoint 1399038056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.55196
Policy Entropy: 3.03370
Value Function Loss: 0.00483

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.59319
Value Function Update Magnitude: 0.55994

Collected Steps per Second: 22,108.03836
Overall Steps per Second: 10,639.98816

Timestep Collection Time: 2.26298
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.70207

Cumulative Model Updates: 167,756
Cumulative Timesteps: 1,399,088,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.93716
Policy Entropy: 3.02552
Value Function Loss: 0.00445

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.59303
Value Function Update Magnitude: 0.56945

Collected Steps per Second: 21,871.88501
Overall Steps per Second: 10,627.31779

Timestep Collection Time: 2.28622
Timestep Consumption Time: 2.41901
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.70523

Cumulative Model Updates: 167,762
Cumulative Timesteps: 1,399,138,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1399138090...
Checkpoint 1399138090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.26830
Policy Entropy: 3.00997
Value Function Loss: 0.00447

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.59257
Value Function Update Magnitude: 0.56291

Collected Steps per Second: 22,243.39751
Overall Steps per Second: 10,839.42536

Timestep Collection Time: 2.24822
Timestep Consumption Time: 2.36531
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.61353

Cumulative Model Updates: 167,768
Cumulative Timesteps: 1,399,188,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,266.05141
Policy Entropy: 3.01324
Value Function Loss: 0.00417

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.59122
Value Function Update Magnitude: 0.53286

Collected Steps per Second: 22,367.45423
Overall Steps per Second: 10,605.45128

Timestep Collection Time: 2.23575
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.71531

Cumulative Model Updates: 167,774
Cumulative Timesteps: 1,399,238,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1399238106...
Checkpoint 1399238106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.22972
Policy Entropy: 3.01338
Value Function Loss: 0.00428

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.59141
Value Function Update Magnitude: 0.54178

Collected Steps per Second: 22,361.94114
Overall Steps per Second: 10,766.82992

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.40911
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.64612

Cumulative Model Updates: 167,780
Cumulative Timesteps: 1,399,288,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,783.29481
Policy Entropy: 3.02779
Value Function Loss: 0.00446

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.58454
Value Function Update Magnitude: 0.55695

Collected Steps per Second: 22,466.76407
Overall Steps per Second: 10,720.41461

Timestep Collection Time: 2.22578
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.66456

Cumulative Model Updates: 167,786
Cumulative Timesteps: 1,399,338,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1399338136...
Checkpoint 1399338136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.86467
Policy Entropy: 3.02812
Value Function Loss: 0.00425

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.57728
Value Function Update Magnitude: 0.56866

Collected Steps per Second: 22,255.50943
Overall Steps per Second: 10,719.46403

Timestep Collection Time: 2.24744
Timestep Consumption Time: 2.41865
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.66609

Cumulative Model Updates: 167,792
Cumulative Timesteps: 1,399,388,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,842.28904
Policy Entropy: 3.01388
Value Function Loss: 0.00436

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.57352
Value Function Update Magnitude: 0.54650

Collected Steps per Second: 22,574.42395
Overall Steps per Second: 10,828.14459

Timestep Collection Time: 2.21578
Timestep Consumption Time: 2.40366
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.61944

Cumulative Model Updates: 167,798
Cumulative Timesteps: 1,399,438,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1399438174...
Checkpoint 1399438174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,403.68446
Policy Entropy: 3.02242
Value Function Loss: 0.00422

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.57414
Value Function Update Magnitude: 0.51614

Collected Steps per Second: 22,373.33339
Overall Steps per Second: 10,778.30422

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.40453
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.63969

Cumulative Model Updates: 167,804
Cumulative Timesteps: 1,399,488,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,444.98989
Policy Entropy: 3.02088
Value Function Loss: 0.00423

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.49729

Collected Steps per Second: 21,797.57745
Overall Steps per Second: 10,727.82275

Timestep Collection Time: 2.29420
Timestep Consumption Time: 2.36732
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.66152

Cumulative Model Updates: 167,810
Cumulative Timesteps: 1,399,538,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1399538190...
Checkpoint 1399538190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.23391
Policy Entropy: 3.03765
Value Function Loss: 0.00418

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.57025
Value Function Update Magnitude: 0.51551

Collected Steps per Second: 21,750.57142
Overall Steps per Second: 10,682.63977

Timestep Collection Time: 2.29989
Timestep Consumption Time: 2.38284
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.68274

Cumulative Model Updates: 167,816
Cumulative Timesteps: 1,399,588,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,679.11778
Policy Entropy: 3.03963
Value Function Loss: 0.00404

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.57400
Value Function Update Magnitude: 0.52058

Collected Steps per Second: 22,195.25656
Overall Steps per Second: 10,586.12724

Timestep Collection Time: 2.25282
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.72335

Cumulative Model Updates: 167,822
Cumulative Timesteps: 1,399,638,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1399638216...
Checkpoint 1399638216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.60584
Policy Entropy: 3.03413
Value Function Loss: 0.00433

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.58068
Value Function Update Magnitude: 0.49291

Collected Steps per Second: 23,036.67507
Overall Steps per Second: 10,825.28759

Timestep Collection Time: 2.17089
Timestep Consumption Time: 2.44885
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.61974

Cumulative Model Updates: 167,828
Cumulative Timesteps: 1,399,688,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,516.37597
Policy Entropy: 3.03311
Value Function Loss: 0.00425

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.56891
Value Function Update Magnitude: 0.47235

Collected Steps per Second: 22,971.90436
Overall Steps per Second: 10,885.93935

Timestep Collection Time: 2.17736
Timestep Consumption Time: 2.41738
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.59473

Cumulative Model Updates: 167,834
Cumulative Timesteps: 1,399,738,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1399738244...
Checkpoint 1399738244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.51468
Policy Entropy: 3.02989
Value Function Loss: 0.00438

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.46547

Collected Steps per Second: 22,975.27305
Overall Steps per Second: 10,736.76763

Timestep Collection Time: 2.17677
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.65801

Cumulative Model Updates: 167,840
Cumulative Timesteps: 1,399,788,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.24922
Policy Entropy: 3.03944
Value Function Loss: 0.00393

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.56417
Value Function Update Magnitude: 0.46273

Collected Steps per Second: 23,350.50027
Overall Steps per Second: 10,886.24023

Timestep Collection Time: 2.14154
Timestep Consumption Time: 2.45197
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.59351

Cumulative Model Updates: 167,846
Cumulative Timesteps: 1,399,838,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1399838262...
Checkpoint 1399838262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,915.93495
Policy Entropy: 3.05062
Value Function Loss: 0.00446

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.49478

Collected Steps per Second: 22,894.42778
Overall Steps per Second: 10,713.52078

Timestep Collection Time: 2.18420
Timestep Consumption Time: 2.48336
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.66756

Cumulative Model Updates: 167,852
Cumulative Timesteps: 1,399,888,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.92736
Policy Entropy: 3.04691
Value Function Loss: 0.00443

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.56542
Value Function Update Magnitude: 0.51866

Collected Steps per Second: 23,113.87400
Overall Steps per Second: 10,947.46678

Timestep Collection Time: 2.16372
Timestep Consumption Time: 2.40464
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.56836

Cumulative Model Updates: 167,858
Cumulative Timesteps: 1,399,938,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1399938280...
Checkpoint 1399938280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.98946
Policy Entropy: 3.04697
Value Function Loss: 0.00423

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.56287
Value Function Update Magnitude: 0.50017

Collected Steps per Second: 22,712.81718
Overall Steps per Second: 10,627.02237

Timestep Collection Time: 2.20158
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.70536

Cumulative Model Updates: 167,864
Cumulative Timesteps: 1,399,988,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,690.96302
Policy Entropy: 3.03234
Value Function Loss: 0.00423

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.56303
Value Function Update Magnitude: 0.49344

Collected Steps per Second: 22,892.64990
Overall Steps per Second: 10,888.31391

Timestep Collection Time: 2.18419
Timestep Consumption Time: 2.40807
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.59226

Cumulative Model Updates: 167,870
Cumulative Timesteps: 1,400,038,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1400038286...
Checkpoint 1400038286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.81160
Policy Entropy: 3.01363
Value Function Loss: 0.00415

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.56893
Value Function Update Magnitude: 0.50643

Collected Steps per Second: 22,662.70220
Overall Steps per Second: 10,599.93564

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.51265
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.72059

Cumulative Model Updates: 167,876
Cumulative Timesteps: 1,400,088,324

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,812.07651
Policy Entropy: 2.99947
Value Function Loss: 0.00450

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.58289
Value Function Update Magnitude: 0.52531

Collected Steps per Second: 22,621.87668
Overall Steps per Second: 10,832.83440

Timestep Collection Time: 2.21140
Timestep Consumption Time: 2.40660
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61800

Cumulative Model Updates: 167,882
Cumulative Timesteps: 1,400,138,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1400138350...
Checkpoint 1400138350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,126.78328
Policy Entropy: 3.00325
Value Function Loss: 0.00489

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.59999
Value Function Update Magnitude: 0.54621

Collected Steps per Second: 22,615.94334
Overall Steps per Second: 10,728.78217

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.45032
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.66185

Cumulative Model Updates: 167,888
Cumulative Timesteps: 1,400,188,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 873.59658
Policy Entropy: 3.02141
Value Function Loss: 0.00476

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.58497
Value Function Update Magnitude: 0.53480

Collected Steps per Second: 23,127.68216
Overall Steps per Second: 10,887.52814

Timestep Collection Time: 2.16269
Timestep Consumption Time: 2.43137
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.59406

Cumulative Model Updates: 167,894
Cumulative Timesteps: 1,400,238,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1400238384...
Checkpoint 1400238384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,408.61350
Policy Entropy: 3.03494
Value Function Loss: 0.00467

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.57117
Value Function Update Magnitude: 0.52853

Collected Steps per Second: 22,236.32161
Overall Steps per Second: 10,682.11973

Timestep Collection Time: 2.24974
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.68315

Cumulative Model Updates: 167,900
Cumulative Timesteps: 1,400,288,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,389.66309
Policy Entropy: 3.02642
Value Function Loss: 0.00437

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.50662

Collected Steps per Second: 22,717.60058
Overall Steps per Second: 10,799.09317

Timestep Collection Time: 2.20173
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.63169

Cumulative Model Updates: 167,906
Cumulative Timesteps: 1,400,338,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1400338428...
Checkpoint 1400338428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,070.15498
Policy Entropy: 3.01169
Value Function Loss: 0.00486

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.58962
Value Function Update Magnitude: 0.50306

Collected Steps per Second: 22,790.57989
Overall Steps per Second: 10,755.00274

Timestep Collection Time: 2.19406
Timestep Consumption Time: 2.45531
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.64937

Cumulative Model Updates: 167,912
Cumulative Timesteps: 1,400,388,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,947.34503
Policy Entropy: 3.01230
Value Function Loss: 0.00448

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.59282
Value Function Update Magnitude: 0.52050

Collected Steps per Second: 23,192.77388
Overall Steps per Second: 10,801.31771

Timestep Collection Time: 2.15662
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.63073

Cumulative Model Updates: 167,918
Cumulative Timesteps: 1,400,438,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1400438450...
Checkpoint 1400438450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,657.68460
Policy Entropy: 3.00638
Value Function Loss: 0.00438

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.58313
Value Function Update Magnitude: 0.54371

Collected Steps per Second: 22,656.67341
Overall Steps per Second: 10,768.84341

Timestep Collection Time: 2.20791
Timestep Consumption Time: 2.43734
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.64525

Cumulative Model Updates: 167,924
Cumulative Timesteps: 1,400,488,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,402.28293
Policy Entropy: 3.01007
Value Function Loss: 0.00422

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.59524
Value Function Update Magnitude: 0.54303

Collected Steps per Second: 22,973.65987
Overall Steps per Second: 10,823.88670

Timestep Collection Time: 2.17762
Timestep Consumption Time: 2.44438
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.62200

Cumulative Model Updates: 167,930
Cumulative Timesteps: 1,400,538,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1400538502...
Checkpoint 1400538502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,049.90063
Policy Entropy: 3.01412
Value Function Loss: 0.00420

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.59084
Value Function Update Magnitude: 0.54168

Collected Steps per Second: 23,021.89801
Overall Steps per Second: 10,762.43706

Timestep Collection Time: 2.17237
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.64690

Cumulative Model Updates: 167,936
Cumulative Timesteps: 1,400,588,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,460.85265
Policy Entropy: 3.02464
Value Function Loss: 0.00410

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.57608
Value Function Update Magnitude: 0.53718

Collected Steps per Second: 23,362.44341
Overall Steps per Second: 10,826.13125

Timestep Collection Time: 2.14019
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.61845

Cumulative Model Updates: 167,942
Cumulative Timesteps: 1,400,638,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1400638514...
Checkpoint 1400638514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,106.08055
Policy Entropy: 3.03240
Value Function Loss: 0.00401

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.53800

Collected Steps per Second: 23,262.11503
Overall Steps per Second: 11,016.95565

Timestep Collection Time: 2.14950
Timestep Consumption Time: 2.38914
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.53864

Cumulative Model Updates: 167,948
Cumulative Timesteps: 1,400,688,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.55555
Policy Entropy: 3.03450
Value Function Loss: 0.00446

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.58060
Value Function Update Magnitude: 0.55933

Collected Steps per Second: 22,634.11890
Overall Steps per Second: 10,598.44244

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.50942
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.71918

Cumulative Model Updates: 167,954
Cumulative Timesteps: 1,400,738,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1400738532...
Checkpoint 1400738532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.14991
Policy Entropy: 3.03038
Value Function Loss: 0.00449

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.58634
Value Function Update Magnitude: 0.56950

Collected Steps per Second: 22,643.70714
Overall Steps per Second: 10,606.97759

Timestep Collection Time: 2.20883
Timestep Consumption Time: 2.50656
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.71539

Cumulative Model Updates: 167,960
Cumulative Timesteps: 1,400,788,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,894.12010
Policy Entropy: 3.03088
Value Function Loss: 0.00442

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.59163
Value Function Update Magnitude: 0.55953

Collected Steps per Second: 22,874.96228
Overall Steps per Second: 10,879.88800

Timestep Collection Time: 2.18702
Timestep Consumption Time: 2.41119
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.59821

Cumulative Model Updates: 167,966
Cumulative Timesteps: 1,400,838,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1400838576...
Checkpoint 1400838576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,284.70276
Policy Entropy: 3.03673
Value Function Loss: 0.00424

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.58181
Value Function Update Magnitude: 0.56367

Collected Steps per Second: 22,853.29862
Overall Steps per Second: 10,622.72717

Timestep Collection Time: 2.18866
Timestep Consumption Time: 2.51993
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.70858

Cumulative Model Updates: 167,972
Cumulative Timesteps: 1,400,888,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,917.84869
Policy Entropy: 3.03101
Value Function Loss: 0.00443

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.58057
Value Function Update Magnitude: 0.55274

Collected Steps per Second: 22,941.14446
Overall Steps per Second: 10,670.65409

Timestep Collection Time: 2.17958
Timestep Consumption Time: 2.50636
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.68594

Cumulative Model Updates: 167,978
Cumulative Timesteps: 1,400,938,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1400938596...
Checkpoint 1400938596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,245.24182
Policy Entropy: 3.01550
Value Function Loss: 0.00462

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.58116
Value Function Update Magnitude: 0.55673

Collected Steps per Second: 20,719.61036
Overall Steps per Second: 9,879.83401

Timestep Collection Time: 2.41356
Timestep Consumption Time: 2.64806
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 5.06162

Cumulative Model Updates: 167,984
Cumulative Timesteps: 1,400,988,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,340.30496
Policy Entropy: 3.00798
Value Function Loss: 0.00451

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.58054
Value Function Update Magnitude: 0.56909

Collected Steps per Second: 22,174.43916
Overall Steps per Second: 10,519.76847

Timestep Collection Time: 2.25575
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.75486

Cumulative Model Updates: 167,990
Cumulative Timesteps: 1,401,038,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1401038624...
Checkpoint 1401038624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,404.62639
Policy Entropy: 3.02131
Value Function Loss: 0.00406

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.58460
Value Function Update Magnitude: 0.56030

Collected Steps per Second: 22,915.71286
Overall Steps per Second: 10,741.99040

Timestep Collection Time: 2.18226
Timestep Consumption Time: 2.47312
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.65538

Cumulative Model Updates: 167,996
Cumulative Timesteps: 1,401,088,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.90645
Policy Entropy: 3.03534
Value Function Loss: 0.00425

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.58878
Value Function Update Magnitude: 0.54020

Collected Steps per Second: 22,986.25733
Overall Steps per Second: 10,900.08500

Timestep Collection Time: 2.17573
Timestep Consumption Time: 2.41249
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.58822

Cumulative Model Updates: 168,002
Cumulative Timesteps: 1,401,138,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1401138644...
Checkpoint 1401138644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,923.27427
Policy Entropy: 3.04378
Value Function Loss: 0.00418

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.57632
Value Function Update Magnitude: 0.52361

Collected Steps per Second: 23,275.81666
Overall Steps per Second: 10,741.86493

Timestep Collection Time: 2.14901
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.65655

Cumulative Model Updates: 168,008
Cumulative Timesteps: 1,401,188,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.81940
Policy Entropy: 3.05390
Value Function Loss: 0.00444

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.56532
Value Function Update Magnitude: 0.52625

Collected Steps per Second: 23,342.28076
Overall Steps per Second: 10,806.60293

Timestep Collection Time: 2.14229
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.62736

Cumulative Model Updates: 168,014
Cumulative Timesteps: 1,401,238,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1401238670...
Checkpoint 1401238670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,067.15326
Policy Entropy: 3.06185
Value Function Loss: 0.00412

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.56788
Value Function Update Magnitude: 0.50806

Collected Steps per Second: 23,223.52736
Overall Steps per Second: 10,735.77093

Timestep Collection Time: 2.15411
Timestep Consumption Time: 2.50564
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.65975

Cumulative Model Updates: 168,020
Cumulative Timesteps: 1,401,288,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,764.83144
Policy Entropy: 3.05134
Value Function Loss: 0.00450

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.57160
Value Function Update Magnitude: 0.51561

Collected Steps per Second: 23,121.75070
Overall Steps per Second: 10,873.27607

Timestep Collection Time: 2.16316
Timestep Consumption Time: 2.43674
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.59990

Cumulative Model Updates: 168,026
Cumulative Timesteps: 1,401,338,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1401338712...
Checkpoint 1401338712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,589.12207
Policy Entropy: 3.04449
Value Function Loss: 0.00421

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.57810
Value Function Update Magnitude: 0.52667

Collected Steps per Second: 22,781.82796
Overall Steps per Second: 10,653.26843

Timestep Collection Time: 2.19473
Timestep Consumption Time: 2.49866
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.69340

Cumulative Model Updates: 168,032
Cumulative Timesteps: 1,401,388,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,825.85644
Policy Entropy: 3.02446
Value Function Loss: 0.00440

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.57540
Value Function Update Magnitude: 0.52933

Collected Steps per Second: 23,067.76343
Overall Steps per Second: 10,864.39698

Timestep Collection Time: 2.16779
Timestep Consumption Time: 2.43495
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.60274

Cumulative Model Updates: 168,038
Cumulative Timesteps: 1,401,438,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1401438718...
Checkpoint 1401438718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,084.45852
Policy Entropy: 3.01992
Value Function Loss: 0.00421

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.58054
Value Function Update Magnitude: 0.54702

Collected Steps per Second: 22,677.90018
Overall Steps per Second: 10,593.63699

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.51583
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.72132

Cumulative Model Updates: 168,044
Cumulative Timesteps: 1,401,488,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,126.06324
Policy Entropy: 3.00163
Value Function Loss: 0.00414

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.53467

Collected Steps per Second: 23,097.74358
Overall Steps per Second: 10,649.94289

Timestep Collection Time: 2.16558
Timestep Consumption Time: 2.53116
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.69674

Cumulative Model Updates: 168,050
Cumulative Timesteps: 1,401,538,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1401538754...
Checkpoint 1401538754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,601.69625
Policy Entropy: 3.02014
Value Function Loss: 0.00455

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.59843
Value Function Update Magnitude: 0.52598

Collected Steps per Second: 23,250.60407
Overall Steps per Second: 10,877.08683

Timestep Collection Time: 2.15065
Timestep Consumption Time: 2.44653
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.59719

Cumulative Model Updates: 168,056
Cumulative Timesteps: 1,401,588,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,726.75799
Policy Entropy: 3.01983
Value Function Loss: 0.00430

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.53554

Collected Steps per Second: 23,127.32630
Overall Steps per Second: 10,853.61668

Timestep Collection Time: 2.16264
Timestep Consumption Time: 2.44560
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.60823

Cumulative Model Updates: 168,062
Cumulative Timesteps: 1,401,638,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1401638774...
Checkpoint 1401638774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,336.11056
Policy Entropy: 3.02626
Value Function Loss: 0.00427

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.57423
Value Function Update Magnitude: 0.53069

Collected Steps per Second: 22,810.88043
Overall Steps per Second: 10,729.20162

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.46972
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.66298

Cumulative Model Updates: 168,068
Cumulative Timesteps: 1,401,688,804

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,281.93293
Policy Entropy: 3.02055
Value Function Loss: 0.00431

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.57266
Value Function Update Magnitude: 0.50800

Collected Steps per Second: 23,391.11732
Overall Steps per Second: 10,952.55125

Timestep Collection Time: 2.13893
Timestep Consumption Time: 2.42914
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.56807

Cumulative Model Updates: 168,074
Cumulative Timesteps: 1,401,738,836

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1401738836...
Checkpoint 1401738836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,029.62959
Policy Entropy: 3.01504
Value Function Loss: 0.00418

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.57119
Value Function Update Magnitude: 0.51764

Collected Steps per Second: 22,693.32537
Overall Steps per Second: 10,634.37160

Timestep Collection Time: 2.20435
Timestep Consumption Time: 2.49964
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.70399

Cumulative Model Updates: 168,080
Cumulative Timesteps: 1,401,788,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,416.03354
Policy Entropy: 3.01397
Value Function Loss: 0.00417

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.51513

Collected Steps per Second: 22,780.37003
Overall Steps per Second: 10,781.86032

Timestep Collection Time: 2.19593
Timestep Consumption Time: 2.44372
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.63964

Cumulative Model Updates: 168,086
Cumulative Timesteps: 1,401,838,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1401838884...
Checkpoint 1401838884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.63775
Policy Entropy: 3.02712
Value Function Loss: 0.00382

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.51645

Collected Steps per Second: 22,406.81533
Overall Steps per Second: 10,721.19643

Timestep Collection Time: 2.23280
Timestep Consumption Time: 2.43365
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.66646

Cumulative Model Updates: 168,092
Cumulative Timesteps: 1,401,888,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,990.26611
Policy Entropy: 3.03197
Value Function Loss: 0.00394

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.55373
Value Function Update Magnitude: 0.50838

Collected Steps per Second: 22,905.61174
Overall Steps per Second: 10,824.09325

Timestep Collection Time: 2.18409
Timestep Consumption Time: 2.43782
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.62191

Cumulative Model Updates: 168,098
Cumulative Timesteps: 1,401,938,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1401938942...
Checkpoint 1401938942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.86683
Policy Entropy: 3.03652
Value Function Loss: 0.00375

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.50773

Collected Steps per Second: 22,577.31498
Overall Steps per Second: 10,807.97968

Timestep Collection Time: 2.21532
Timestep Consumption Time: 2.41237
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.62769

Cumulative Model Updates: 168,104
Cumulative Timesteps: 1,401,988,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.29912
Policy Entropy: 3.01494
Value Function Loss: 0.00393

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.49139

Collected Steps per Second: 23,289.13817
Overall Steps per Second: 10,835.87079

Timestep Collection Time: 2.14761
Timestep Consumption Time: 2.46817
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.61578

Cumulative Model Updates: 168,110
Cumulative Timesteps: 1,402,038,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1402038974...
Checkpoint 1402038974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.92893
Policy Entropy: 3.00136
Value Function Loss: 0.00451

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.58169
Value Function Update Magnitude: 0.48965

Collected Steps per Second: 22,575.52423
Overall Steps per Second: 10,562.06923

Timestep Collection Time: 2.21576
Timestep Consumption Time: 2.52024
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.73600

Cumulative Model Updates: 168,116
Cumulative Timesteps: 1,402,088,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.65153
Policy Entropy: 2.99461
Value Function Loss: 0.00460

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.58332
Value Function Update Magnitude: 0.50133

Collected Steps per Second: 23,440.64370
Overall Steps per Second: 10,917.48762

Timestep Collection Time: 2.13373
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.58127

Cumulative Model Updates: 168,122
Cumulative Timesteps: 1,402,139,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1402139012...
Checkpoint 1402139012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,500.08352
Policy Entropy: 2.98856
Value Function Loss: 0.00468

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.58741
Value Function Update Magnitude: 0.51095

Collected Steps per Second: 22,517.36710
Overall Steps per Second: 10,687.71637

Timestep Collection Time: 2.22149
Timestep Consumption Time: 2.45884
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.68033

Cumulative Model Updates: 168,128
Cumulative Timesteps: 1,402,189,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.50816
Policy Entropy: 3.00660
Value Function Loss: 0.00435

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.59299
Value Function Update Magnitude: 0.51939

Collected Steps per Second: 23,388.17893
Overall Steps per Second: 11,000.26606

Timestep Collection Time: 2.13903
Timestep Consumption Time: 2.40886
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.54789

Cumulative Model Updates: 168,134
Cumulative Timesteps: 1,402,239,062

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1402239062...
Checkpoint 1402239062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,177.13297
Policy Entropy: 3.02007
Value Function Loss: 0.00442

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.58332
Value Function Update Magnitude: 0.50125

Collected Steps per Second: 22,682.67569
Overall Steps per Second: 10,599.33870

Timestep Collection Time: 2.20459
Timestep Consumption Time: 2.51325
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.71784

Cumulative Model Updates: 168,140
Cumulative Timesteps: 1,402,289,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.65053
Policy Entropy: 3.03613
Value Function Loss: 0.00445

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.58602
Value Function Update Magnitude: 0.51848

Collected Steps per Second: 22,536.68836
Overall Steps per Second: 10,601.31503

Timestep Collection Time: 2.21905
Timestep Consumption Time: 2.49829
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.71734

Cumulative Model Updates: 168,146
Cumulative Timesteps: 1,402,339,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1402339078...
Checkpoint 1402339078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.05076
Policy Entropy: 3.02921
Value Function Loss: 0.00407

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.57394
Value Function Update Magnitude: 0.51115

Collected Steps per Second: 22,507.38173
Overall Steps per Second: 10,606.80107

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.71490

Cumulative Model Updates: 168,152
Cumulative Timesteps: 1,402,389,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.18817
Policy Entropy: 3.02564
Value Function Loss: 0.00421

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.57216
Value Function Update Magnitude: 0.50333

Collected Steps per Second: 22,516.69579
Overall Steps per Second: 10,723.88909

Timestep Collection Time: 2.22182
Timestep Consumption Time: 2.44328
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.66510

Cumulative Model Updates: 168,158
Cumulative Timesteps: 1,402,439,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1402439116...
Checkpoint 1402439116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,607.92125
Policy Entropy: 3.03408
Value Function Loss: 0.00391

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.57516
Value Function Update Magnitude: 0.49741

Collected Steps per Second: 22,054.96025
Overall Steps per Second: 10,617.25148

Timestep Collection Time: 2.26815
Timestep Consumption Time: 2.44343
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.71158

Cumulative Model Updates: 168,164
Cumulative Timesteps: 1,402,489,140

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.41998
Policy Entropy: 3.02805
Value Function Loss: 0.00420

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.57393
Value Function Update Magnitude: 0.48906

Collected Steps per Second: 23,367.19036
Overall Steps per Second: 10,925.44189

Timestep Collection Time: 2.14086
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.57885

Cumulative Model Updates: 168,170
Cumulative Timesteps: 1,402,539,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1402539166...
Checkpoint 1402539166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,234.96902
Policy Entropy: 3.01325
Value Function Loss: 0.00460

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.58866
Value Function Update Magnitude: 0.49749

Collected Steps per Second: 22,731.95391
Overall Steps per Second: 10,723.12794

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.46357
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.66338

Cumulative Model Updates: 168,176
Cumulative Timesteps: 1,402,589,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.05451
Policy Entropy: 3.01735
Value Function Loss: 0.00490

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.59906
Value Function Update Magnitude: 0.52359

Collected Steps per Second: 23,098.96933
Overall Steps per Second: 10,837.76969

Timestep Collection Time: 2.16538
Timestep Consumption Time: 2.44978
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.61516

Cumulative Model Updates: 168,182
Cumulative Timesteps: 1,402,639,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1402639190...
Checkpoint 1402639190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.86622
Policy Entropy: 3.03235
Value Function Loss: 0.00470

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.59596
Value Function Update Magnitude: 0.53035

Collected Steps per Second: 22,766.02259
Overall Steps per Second: 10,675.86558

Timestep Collection Time: 2.19696
Timestep Consumption Time: 2.48800
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.68496

Cumulative Model Updates: 168,188
Cumulative Timesteps: 1,402,689,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,108.86006
Policy Entropy: 3.05487
Value Function Loss: 0.00434

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.57649
Value Function Update Magnitude: 0.50833

Collected Steps per Second: 23,148.02712
Overall Steps per Second: 10,881.50263

Timestep Collection Time: 2.16131
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.59771

Cumulative Model Updates: 168,194
Cumulative Timesteps: 1,402,739,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1402739236...
Checkpoint 1402739236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,280.87823
Policy Entropy: 3.04946
Value Function Loss: 0.00398

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.56539
Value Function Update Magnitude: 0.49144

Collected Steps per Second: 22,665.38595
Overall Steps per Second: 10,718.91061

Timestep Collection Time: 2.20689
Timestep Consumption Time: 2.45963
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.66652

Cumulative Model Updates: 168,200
Cumulative Timesteps: 1,402,789,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,410.30873
Policy Entropy: 3.03268
Value Function Loss: 0.00409

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.56876
Value Function Update Magnitude: 0.51212

Collected Steps per Second: 22,901.43841
Overall Steps per Second: 10,829.30477

Timestep Collection Time: 2.18362
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.61784

Cumulative Model Updates: 168,206
Cumulative Timesteps: 1,402,839,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1402839264...
Checkpoint 1402839264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,591.43921
Policy Entropy: 3.02111
Value Function Loss: 0.00411

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.57893
Value Function Update Magnitude: 0.51023

Collected Steps per Second: 22,195.76487
Overall Steps per Second: 10,672.87959

Timestep Collection Time: 2.25268
Timestep Consumption Time: 2.43209
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.68477

Cumulative Model Updates: 168,212
Cumulative Timesteps: 1,402,889,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.69337
Policy Entropy: 3.00627
Value Function Loss: 0.00458

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.58007
Value Function Update Magnitude: 0.49489

Collected Steps per Second: 23,027.92216
Overall Steps per Second: 10,852.68781

Timestep Collection Time: 2.17145
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.60752

Cumulative Model Updates: 168,218
Cumulative Timesteps: 1,402,939,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1402939268...
Checkpoint 1402939268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,892.64033
Policy Entropy: 2.98715
Value Function Loss: 0.00495

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.59640
Value Function Update Magnitude: 0.51142

Collected Steps per Second: 22,604.22087
Overall Steps per Second: 10,785.05290

Timestep Collection Time: 2.21224
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.63660

Cumulative Model Updates: 168,224
Cumulative Timesteps: 1,402,989,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.76717
Policy Entropy: 2.98136
Value Function Loss: 0.00483

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.59824
Value Function Update Magnitude: 0.54946

Collected Steps per Second: 23,287.36166
Overall Steps per Second: 10,893.37954

Timestep Collection Time: 2.14743
Timestep Consumption Time: 2.44325
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.59068

Cumulative Model Updates: 168,230
Cumulative Timesteps: 1,403,039,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1403039282...
Checkpoint 1403039282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.46902
Policy Entropy: 2.99737
Value Function Loss: 0.00443

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.59216
Value Function Update Magnitude: 0.55603

Collected Steps per Second: 22,597.84056
Overall Steps per Second: 10,609.44923

Timestep Collection Time: 2.21269
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.71297

Cumulative Model Updates: 168,236
Cumulative Timesteps: 1,403,089,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,026.19267
Policy Entropy: 3.01257
Value Function Loss: 0.00447

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.59365
Value Function Update Magnitude: 0.55952

Collected Steps per Second: 23,252.86256
Overall Steps per Second: 10,955.28653

Timestep Collection Time: 2.15113
Timestep Consumption Time: 2.41470
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.56583

Cumulative Model Updates: 168,242
Cumulative Timesteps: 1,403,139,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1403139304...
Checkpoint 1403139304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,028.94140
Policy Entropy: 3.01916
Value Function Loss: 0.00428

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.58603
Value Function Update Magnitude: 0.52824

Collected Steps per Second: 23,086.02678
Overall Steps per Second: 10,793.61453

Timestep Collection Time: 2.16590
Timestep Consumption Time: 2.46665
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.63255

Cumulative Model Updates: 168,248
Cumulative Timesteps: 1,403,189,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,062.60070
Policy Entropy: 2.99249
Value Function Loss: 0.00458

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.58283
Value Function Update Magnitude: 0.52933

Collected Steps per Second: 23,536.18196
Overall Steps per Second: 10,877.76270

Timestep Collection Time: 2.12558
Timestep Consumption Time: 2.47353
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.59911

Cumulative Model Updates: 168,254
Cumulative Timesteps: 1,403,239,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1403239334...
Checkpoint 1403239334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,149.88563
Policy Entropy: 2.99404
Value Function Loss: 0.00440

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.59182
Value Function Update Magnitude: 0.53077

Collected Steps per Second: 22,325.48503
Overall Steps per Second: 10,862.01612

Timestep Collection Time: 2.23959
Timestep Consumption Time: 2.36360
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.60320

Cumulative Model Updates: 168,260
Cumulative Timesteps: 1,403,289,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,598.14186
Policy Entropy: 2.98742
Value Function Loss: 0.00466

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.59463
Value Function Update Magnitude: 0.52942

Collected Steps per Second: 22,291.10073
Overall Steps per Second: 10,881.02057

Timestep Collection Time: 2.24305
Timestep Consumption Time: 2.35211
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.59516

Cumulative Model Updates: 168,266
Cumulative Timesteps: 1,403,339,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1403339334...
Checkpoint 1403339334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.80647
Policy Entropy: 3.00666
Value Function Loss: 0.00468

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.59658
Value Function Update Magnitude: 0.55519

Collected Steps per Second: 21,939.62765
Overall Steps per Second: 10,737.64500

Timestep Collection Time: 2.27998
Timestep Consumption Time: 2.37858
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.65856

Cumulative Model Updates: 168,272
Cumulative Timesteps: 1,403,389,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,826.95846
Policy Entropy: 2.99713
Value Function Loss: 0.00449

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.59813
Value Function Update Magnitude: 0.56225

Collected Steps per Second: 22,416.86675
Overall Steps per Second: 10,871.05420

Timestep Collection Time: 2.23064
Timestep Consumption Time: 2.36910
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.59974

Cumulative Model Updates: 168,278
Cumulative Timesteps: 1,403,439,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1403439360...
Checkpoint 1403439360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,449.01648
Policy Entropy: 3.00352
Value Function Loss: 0.00462

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.60597
Value Function Update Magnitude: 0.54591

Collected Steps per Second: 22,025.83719
Overall Steps per Second: 10,633.66951

Timestep Collection Time: 2.27106
Timestep Consumption Time: 2.43305
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.70411

Cumulative Model Updates: 168,284
Cumulative Timesteps: 1,403,489,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623.35619
Policy Entropy: 2.99505
Value Function Loss: 0.00459

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.60105
Value Function Update Magnitude: 0.52424

Collected Steps per Second: 22,832.59190
Overall Steps per Second: 10,984.32102

Timestep Collection Time: 2.19029
Timestep Consumption Time: 2.36256
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.55285

Cumulative Model Updates: 168,290
Cumulative Timesteps: 1,403,539,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1403539392...
Checkpoint 1403539392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,974.98130
Policy Entropy: 3.00635
Value Function Loss: 0.00455

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.49869

Collected Steps per Second: 22,389.28823
Overall Steps per Second: 10,801.55754

Timestep Collection Time: 2.23419
Timestep Consumption Time: 2.39681
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.63100

Cumulative Model Updates: 168,296
Cumulative Timesteps: 1,403,589,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.09664
Policy Entropy: 3.01579
Value Function Loss: 0.00436

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.58411
Value Function Update Magnitude: 0.47733

Collected Steps per Second: 22,646.39056
Overall Steps per Second: 10,781.21834

Timestep Collection Time: 2.20812
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.63825

Cumulative Model Updates: 168,302
Cumulative Timesteps: 1,403,639,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1403639420...
Checkpoint 1403639420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758.20271
Policy Entropy: 2.99700
Value Function Loss: 0.00428

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.58035
Value Function Update Magnitude: 0.46738

Collected Steps per Second: 22,251.93161
Overall Steps per Second: 10,755.28444

Timestep Collection Time: 2.24763
Timestep Consumption Time: 2.40255
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.65018

Cumulative Model Updates: 168,308
Cumulative Timesteps: 1,403,689,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,332.01091
Policy Entropy: 2.99303
Value Function Loss: 0.00410

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.57169
Value Function Update Magnitude: 0.47399

Collected Steps per Second: 22,453.57405
Overall Steps per Second: 10,709.63577

Timestep Collection Time: 2.22708
Timestep Consumption Time: 2.44217
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.66925

Cumulative Model Updates: 168,314
Cumulative Timesteps: 1,403,739,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1403739440...
Checkpoint 1403739440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,597.94711
Policy Entropy: 2.98407
Value Function Loss: 0.00443

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.58391
Value Function Update Magnitude: 0.47793

Collected Steps per Second: 22,911.12783
Overall Steps per Second: 10,790.47186

Timestep Collection Time: 2.18296
Timestep Consumption Time: 2.45206
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.63502

Cumulative Model Updates: 168,320
Cumulative Timesteps: 1,403,789,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.21272
Policy Entropy: 2.99148
Value Function Loss: 0.00447

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.59374
Value Function Update Magnitude: 0.50641

Collected Steps per Second: 23,154.93383
Overall Steps per Second: 10,776.76787

Timestep Collection Time: 2.15937
Timestep Consumption Time: 2.48024
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.63961

Cumulative Model Updates: 168,326
Cumulative Timesteps: 1,403,839,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1403839454...
Checkpoint 1403839454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.52609
Policy Entropy: 2.98710
Value Function Loss: 0.00473

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.59527
Value Function Update Magnitude: 0.51842

Collected Steps per Second: 22,584.62314
Overall Steps per Second: 10,668.57619

Timestep Collection Time: 2.21469
Timestep Consumption Time: 2.47366
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.68835

Cumulative Model Updates: 168,332
Cumulative Timesteps: 1,403,889,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,796.88009
Policy Entropy: 3.00110
Value Function Loss: 0.00458

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.59479
Value Function Update Magnitude: 0.49646

Collected Steps per Second: 23,007.87157
Overall Steps per Second: 10,844.71123

Timestep Collection Time: 2.17352
Timestep Consumption Time: 2.43776
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.61128

Cumulative Model Updates: 168,338
Cumulative Timesteps: 1,403,939,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1403939480...
Checkpoint 1403939480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,901.02448
Policy Entropy: 2.99686
Value Function Loss: 0.00485

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.58783
Value Function Update Magnitude: 0.48560

Collected Steps per Second: 22,521.82593
Overall Steps per Second: 10,628.45132

Timestep Collection Time: 2.22122
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.70680

Cumulative Model Updates: 168,344
Cumulative Timesteps: 1,403,989,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.14853
Policy Entropy: 3.00084
Value Function Loss: 0.00463

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.59040
Value Function Update Magnitude: 0.49924

Collected Steps per Second: 23,386.01211
Overall Steps per Second: 10,820.37411

Timestep Collection Time: 2.13846
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.62184

Cumulative Model Updates: 168,350
Cumulative Timesteps: 1,404,039,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1404039516...
Checkpoint 1404039516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.02610
Policy Entropy: 2.98196
Value Function Loss: 0.00470

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.59444
Value Function Update Magnitude: 0.52100

Collected Steps per Second: 22,967.78389
Overall Steps per Second: 10,686.48031

Timestep Collection Time: 2.17783
Timestep Consumption Time: 2.50285
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.68068

Cumulative Model Updates: 168,356
Cumulative Timesteps: 1,404,089,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298.76828
Policy Entropy: 2.98659
Value Function Loss: 0.00423

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11898
Policy Update Magnitude: 0.59013
Value Function Update Magnitude: 0.53988

Collected Steps per Second: 22,114.53660
Overall Steps per Second: 10,547.89125

Timestep Collection Time: 2.26105
Timestep Consumption Time: 2.47943
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.74047

Cumulative Model Updates: 168,362
Cumulative Timesteps: 1,404,139,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1404139538...
Checkpoint 1404139538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.97046
Policy Entropy: 2.97201
Value Function Loss: 0.00432

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.59700
Value Function Update Magnitude: 0.54496

Collected Steps per Second: 22,507.38680
Overall Steps per Second: 10,603.45849

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.49445
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.71639

Cumulative Model Updates: 168,368
Cumulative Timesteps: 1,404,189,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,526.94759
Policy Entropy: 2.98349
Value Function Loss: 0.00442

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.60395
Value Function Update Magnitude: 0.54060

Collected Steps per Second: 22,845.20347
Overall Steps per Second: 10,811.50673

Timestep Collection Time: 2.18934
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.62618

Cumulative Model Updates: 168,374
Cumulative Timesteps: 1,404,239,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1404239564...
Checkpoint 1404239564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,535.57168
Policy Entropy: 2.98329
Value Function Loss: 0.00462

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.60778
Value Function Update Magnitude: 0.55299

Collected Steps per Second: 22,397.94482
Overall Steps per Second: 10,669.93016

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.45490
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.68832

Cumulative Model Updates: 168,380
Cumulative Timesteps: 1,404,289,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,967.39721
Policy Entropy: 2.99422
Value Function Loss: 0.00458

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.59731
Value Function Update Magnitude: 0.54492

Collected Steps per Second: 22,961.36076
Overall Steps per Second: 10,709.56558

Timestep Collection Time: 2.17783
Timestep Consumption Time: 2.49145
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.66928

Cumulative Model Updates: 168,386
Cumulative Timesteps: 1,404,339,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1404339594...
Checkpoint 1404339594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.57916
Policy Entropy: 2.99379
Value Function Loss: 0.00404

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.58325
Value Function Update Magnitude: 0.51251

Collected Steps per Second: 23,297.77640
Overall Steps per Second: 10,861.78035

Timestep Collection Time: 2.14716
Timestep Consumption Time: 2.45835
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.60551

Cumulative Model Updates: 168,392
Cumulative Timesteps: 1,404,389,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.80438
Policy Entropy: 3.00244
Value Function Loss: 0.00425

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.57398
Value Function Update Magnitude: 0.47673

Collected Steps per Second: 23,234.00495
Overall Steps per Second: 10,889.26335

Timestep Collection Time: 2.15262
Timestep Consumption Time: 2.44034
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.59296

Cumulative Model Updates: 168,398
Cumulative Timesteps: 1,404,439,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1404439632...
Checkpoint 1404439632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,361.24507
Policy Entropy: 3.00368
Value Function Loss: 0.00449

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.58018
Value Function Update Magnitude: 0.47741

Collected Steps per Second: 22,917.44627
Overall Steps per Second: 10,670.58562

Timestep Collection Time: 2.18192
Timestep Consumption Time: 2.50423
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.68615

Cumulative Model Updates: 168,404
Cumulative Timesteps: 1,404,489,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,176.36977
Policy Entropy: 3.01253
Value Function Loss: 0.00473

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.59169
Value Function Update Magnitude: 0.50874

Collected Steps per Second: 23,053.50519
Overall Steps per Second: 10,837.60005

Timestep Collection Time: 2.17017
Timestep Consumption Time: 2.44617
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61634

Cumulative Model Updates: 168,410
Cumulative Timesteps: 1,404,539,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1404539666...
Checkpoint 1404539666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,287.49693
Policy Entropy: 3.00752
Value Function Loss: 0.00448

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10614
Policy Update Magnitude: 0.58646
Value Function Update Magnitude: 0.51148

Collected Steps per Second: 22,572.74696
Overall Steps per Second: 10,792.70574

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.41799
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.63331

Cumulative Model Updates: 168,416
Cumulative Timesteps: 1,404,589,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,234.13446
Policy Entropy: 3.01210
Value Function Loss: 0.00433

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.58235
Value Function Update Magnitude: 0.51958

Collected Steps per Second: 22,803.30024
Overall Steps per Second: 10,761.46674

Timestep Collection Time: 2.19302
Timestep Consumption Time: 2.45393
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.64695

Cumulative Model Updates: 168,422
Cumulative Timesteps: 1,404,639,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1404639680...
Checkpoint 1404639680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,390.30860
Policy Entropy: 3.01583
Value Function Loss: 0.00416

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.56793
Value Function Update Magnitude: 0.52292

Collected Steps per Second: 22,415.55297
Overall Steps per Second: 10,686.78772

Timestep Collection Time: 2.23175
Timestep Consumption Time: 2.44935
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.68111

Cumulative Model Updates: 168,428
Cumulative Timesteps: 1,404,689,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,048.68624
Policy Entropy: 3.02963
Value Function Loss: 0.00409

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.56550
Value Function Update Magnitude: 0.51245

Collected Steps per Second: 22,315.14075
Overall Steps per Second: 10,525.45301

Timestep Collection Time: 2.24144
Timestep Consumption Time: 2.51066
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.75210

Cumulative Model Updates: 168,434
Cumulative Timesteps: 1,404,739,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1404739724...
Checkpoint 1404739724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,631.77703
Policy Entropy: 3.03320
Value Function Loss: 0.00400

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.56772
Value Function Update Magnitude: 0.49520

Collected Steps per Second: 22,631.61846
Overall Steps per Second: 10,592.63743

Timestep Collection Time: 2.20983
Timestep Consumption Time: 2.51156
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.72139

Cumulative Model Updates: 168,440
Cumulative Timesteps: 1,404,789,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.14416
Policy Entropy: 3.02847
Value Function Loss: 0.00423

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.49668

Collected Steps per Second: 23,149.98326
Overall Steps per Second: 10,660.77201

Timestep Collection Time: 2.16078
Timestep Consumption Time: 2.53138
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.69216

Cumulative Model Updates: 168,446
Cumulative Timesteps: 1,404,839,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1404839758...
Checkpoint 1404839758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,031.13917
Policy Entropy: 3.01658
Value Function Loss: 0.00441

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.50892

Collected Steps per Second: 22,602.63530
Overall Steps per Second: 10,610.35461

Timestep Collection Time: 2.21293
Timestep Consumption Time: 2.50115
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.71407

Cumulative Model Updates: 168,452
Cumulative Timesteps: 1,404,889,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,752.88711
Policy Entropy: 3.01267
Value Function Loss: 0.00460

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.58382
Value Function Update Magnitude: 0.51102

Collected Steps per Second: 23,341.80514
Overall Steps per Second: 10,743.50907

Timestep Collection Time: 2.14311
Timestep Consumption Time: 2.51310
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.65621

Cumulative Model Updates: 168,458
Cumulative Timesteps: 1,404,939,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1404939800...
Checkpoint 1404939800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.33261
Policy Entropy: 3.00781
Value Function Loss: 0.00459

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.58812
Value Function Update Magnitude: 0.52193

Collected Steps per Second: 22,982.78506
Overall Steps per Second: 10,680.91860

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.68312

Cumulative Model Updates: 168,464
Cumulative Timesteps: 1,404,989,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.96875
Policy Entropy: 3.01653
Value Function Loss: 0.00446

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.59584
Value Function Update Magnitude: 0.51830

Collected Steps per Second: 23,160.95320
Overall Steps per Second: 10,872.91806

Timestep Collection Time: 2.15898
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59895

Cumulative Model Updates: 168,470
Cumulative Timesteps: 1,405,039,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1405039824...
Checkpoint 1405039824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,747.95878
Policy Entropy: 3.00610
Value Function Loss: 0.00446

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.59108
Value Function Update Magnitude: 0.51372

Collected Steps per Second: 22,908.51834
Overall Steps per Second: 10,690.84055

Timestep Collection Time: 2.18417
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.68027

Cumulative Model Updates: 168,476
Cumulative Timesteps: 1,405,089,860

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,702.42584
Policy Entropy: 3.01639
Value Function Loss: 0.00421

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.58571
Value Function Update Magnitude: 0.50708

Collected Steps per Second: 22,755.93279
Overall Steps per Second: 10,795.15212

Timestep Collection Time: 2.19723
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.63171

Cumulative Model Updates: 168,482
Cumulative Timesteps: 1,405,139,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1405139860...
Checkpoint 1405139860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,009.51628
Policy Entropy: 3.01415
Value Function Loss: 0.00424

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.57554
Value Function Update Magnitude: 0.49462

Collected Steps per Second: 22,316.56852
Overall Steps per Second: 10,733.76515

Timestep Collection Time: 2.24085
Timestep Consumption Time: 2.41810
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.65894

Cumulative Model Updates: 168,488
Cumulative Timesteps: 1,405,189,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.10515
Policy Entropy: 3.02540
Value Function Loss: 0.00414

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.57661
Value Function Update Magnitude: 0.49192

Collected Steps per Second: 23,066.48995
Overall Steps per Second: 10,842.98577

Timestep Collection Time: 2.16817
Timestep Consumption Time: 2.44422
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61238

Cumulative Model Updates: 168,494
Cumulative Timesteps: 1,405,239,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1405239880...
Checkpoint 1405239880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,759.07270
Policy Entropy: 3.01323
Value Function Loss: 0.00426

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.59277
Value Function Update Magnitude: 0.50299

Collected Steps per Second: 22,387.87094
Overall Steps per Second: 10,728.22872

Timestep Collection Time: 2.23371
Timestep Consumption Time: 2.42764
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.66135

Cumulative Model Updates: 168,500
Cumulative Timesteps: 1,405,289,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.26074
Policy Entropy: 3.00781
Value Function Loss: 0.00418

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.58264
Value Function Update Magnitude: 0.52115

Collected Steps per Second: 22,649.40957
Overall Steps per Second: 10,751.07942

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.44450
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.65330

Cumulative Model Updates: 168,506
Cumulative Timesteps: 1,405,339,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1405339916...
Checkpoint 1405339916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,447.46000
Policy Entropy: 3.01332
Value Function Loss: 0.00425

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.57404
Value Function Update Magnitude: 0.50456

Collected Steps per Second: 22,773.75853
Overall Steps per Second: 10,748.99659

Timestep Collection Time: 2.19568
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.65197

Cumulative Model Updates: 168,512
Cumulative Timesteps: 1,405,389,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,940.89970
Policy Entropy: 3.02647
Value Function Loss: 0.00470

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.58518
Value Function Update Magnitude: 0.51605

Collected Steps per Second: 23,210.03659
Overall Steps per Second: 10,878.77323

Timestep Collection Time: 2.15527
Timestep Consumption Time: 2.44304
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.59831

Cumulative Model Updates: 168,518
Cumulative Timesteps: 1,405,439,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1405439944...
Checkpoint 1405439944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.60570
Policy Entropy: 3.02450
Value Function Loss: 0.00491

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.59500
Value Function Update Magnitude: 0.54784

Collected Steps per Second: 23,057.50460
Overall Steps per Second: 10,782.67734

Timestep Collection Time: 2.16875
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.63762

Cumulative Model Updates: 168,524
Cumulative Timesteps: 1,405,489,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.22094
Policy Entropy: 3.01209
Value Function Loss: 0.00500

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.59852
Value Function Update Magnitude: 0.56401

Collected Steps per Second: 23,218.06309
Overall Steps per Second: 10,795.66288

Timestep Collection Time: 2.15470
Timestep Consumption Time: 2.47938
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.63408

Cumulative Model Updates: 168,530
Cumulative Timesteps: 1,405,539,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1405539978...
Checkpoint 1405539978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,656.48581
Policy Entropy: 3.00260
Value Function Loss: 0.00490

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11766
Policy Update Magnitude: 0.59406
Value Function Update Magnitude: 0.54792

Collected Steps per Second: 22,983.93662
Overall Steps per Second: 10,664.60117

Timestep Collection Time: 2.17552
Timestep Consumption Time: 2.51308
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.68860

Cumulative Model Updates: 168,536
Cumulative Timesteps: 1,405,589,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,578.17707
Policy Entropy: 3.01269
Value Function Loss: 0.00509

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.58644
Value Function Update Magnitude: 0.53864

Collected Steps per Second: 23,463.10297
Overall Steps per Second: 10,850.59767

Timestep Collection Time: 2.13220
Timestep Consumption Time: 2.47842
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.61062

Cumulative Model Updates: 168,542
Cumulative Timesteps: 1,405,640,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1405640008...
Checkpoint 1405640008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.28372
Policy Entropy: 3.02445
Value Function Loss: 0.00484

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.57845
Value Function Update Magnitude: 0.52873

Collected Steps per Second: 22,281.46287
Overall Steps per Second: 10,647.79832

Timestep Collection Time: 2.24501
Timestep Consumption Time: 2.45287
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.69787

Cumulative Model Updates: 168,548
Cumulative Timesteps: 1,405,690,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.99469
Policy Entropy: 3.01248
Value Function Loss: 0.00434

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11872
Policy Update Magnitude: 0.57408
Value Function Update Magnitude: 0.52846

Collected Steps per Second: 22,827.07453
Overall Steps per Second: 10,814.50852

Timestep Collection Time: 2.19082
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.62434

Cumulative Model Updates: 168,554
Cumulative Timesteps: 1,405,740,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1405740040...
Checkpoint 1405740040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,341.18020
Policy Entropy: 2.99283
Value Function Loss: 0.00470

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.57249
Value Function Update Magnitude: 0.54116

Collected Steps per Second: 22,142.76043
Overall Steps per Second: 10,668.42657

Timestep Collection Time: 2.25934
Timestep Consumption Time: 2.43001
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.68935

Cumulative Model Updates: 168,560
Cumulative Timesteps: 1,405,790,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,760.27659
Policy Entropy: 3.00266
Value Function Loss: 0.00433

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.54837

Collected Steps per Second: 22,939.54499
Overall Steps per Second: 10,705.69825

Timestep Collection Time: 2.18078
Timestep Consumption Time: 2.49206
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.67284

Cumulative Model Updates: 168,566
Cumulative Timesteps: 1,405,840,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1405840094...
Checkpoint 1405840094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,378.29143
Policy Entropy: 3.01349
Value Function Loss: 0.00432

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.56925
Value Function Update Magnitude: 0.53904

Collected Steps per Second: 22,879.34629
Overall Steps per Second: 10,592.70427

Timestep Collection Time: 2.18581
Timestep Consumption Time: 2.53536
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.72117

Cumulative Model Updates: 168,572
Cumulative Timesteps: 1,405,890,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820.01264
Policy Entropy: 3.01543
Value Function Loss: 0.00416

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.56250
Value Function Update Magnitude: 0.52780

Collected Steps per Second: 23,137.52007
Overall Steps per Second: 10,780.54941

Timestep Collection Time: 2.16168
Timestep Consumption Time: 2.47778
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.63947

Cumulative Model Updates: 168,578
Cumulative Timesteps: 1,405,940,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1405940120...
Checkpoint 1405940120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,157.03333
Policy Entropy: 2.98876
Value Function Loss: 0.00439

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.57131
Value Function Update Magnitude: 0.51841

Collected Steps per Second: 22,802.02238
Overall Steps per Second: 10,739.91526

Timestep Collection Time: 2.19314
Timestep Consumption Time: 2.46314
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.65628

Cumulative Model Updates: 168,584
Cumulative Timesteps: 1,405,990,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.98566
Policy Entropy: 2.97869
Value Function Loss: 0.00479

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.59472
Value Function Update Magnitude: 0.54155

Collected Steps per Second: 23,224.57016
Overall Steps per Second: 10,772.15313

Timestep Collection Time: 2.15358
Timestep Consumption Time: 2.48950
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.64308

Cumulative Model Updates: 168,590
Cumulative Timesteps: 1,406,040,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1406040144...
Checkpoint 1406040144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,288.46081
Policy Entropy: 2.98656
Value Function Loss: 0.00462

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11672
Policy Update Magnitude: 0.59983
Value Function Update Magnitude: 0.53465

Collected Steps per Second: 22,693.19051
Overall Steps per Second: 10,667.46688

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.68940

Cumulative Model Updates: 168,596
Cumulative Timesteps: 1,406,090,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,327.31022
Policy Entropy: 3.00398
Value Function Loss: 0.00408

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.51791

Collected Steps per Second: 23,036.66706
Overall Steps per Second: 10,857.50279

Timestep Collection Time: 2.17063
Timestep Consumption Time: 2.43485
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60548

Cumulative Model Updates: 168,602
Cumulative Timesteps: 1,406,140,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1406140172...
Checkpoint 1406140172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,206.05722
Policy Entropy: 3.00370
Value Function Loss: 0.00389

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.57019
Value Function Update Magnitude: 0.50117

Collected Steps per Second: 22,854.11266
Overall Steps per Second: 10,734.95426

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.47127
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.66029

Cumulative Model Updates: 168,608
Cumulative Timesteps: 1,406,190,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.29368
Policy Entropy: 3.01930
Value Function Loss: 0.00421

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.57565
Value Function Update Magnitude: 0.49519

Collected Steps per Second: 22,911.53675
Overall Steps per Second: 10,802.54318

Timestep Collection Time: 2.18335
Timestep Consumption Time: 2.44741
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.63076

Cumulative Model Updates: 168,614
Cumulative Timesteps: 1,406,240,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1406240224...
Checkpoint 1406240224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,824.10766
Policy Entropy: 3.01511
Value Function Loss: 0.00472

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.58399
Value Function Update Magnitude: 0.53357

Collected Steps per Second: 22,420.78146
Overall Steps per Second: 10,707.22489

Timestep Collection Time: 2.23248
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.67479

Cumulative Model Updates: 168,620
Cumulative Timesteps: 1,406,290,278

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,769.55498
Policy Entropy: 3.04021
Value Function Loss: 0.00483

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.58269
Value Function Update Magnitude: 0.55012

Collected Steps per Second: 23,080.14410
Overall Steps per Second: 10,912.77278

Timestep Collection Time: 2.16654
Timestep Consumption Time: 2.41562
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.58215

Cumulative Model Updates: 168,626
Cumulative Timesteps: 1,406,340,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1406340282...
Checkpoint 1406340282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,425.23235
Policy Entropy: 3.03177
Value Function Loss: 0.00466

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.58578
Value Function Update Magnitude: 0.53418

Collected Steps per Second: 22,693.48636
Overall Steps per Second: 10,669.80046

Timestep Collection Time: 2.20416
Timestep Consumption Time: 2.48384
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.68800

Cumulative Model Updates: 168,632
Cumulative Timesteps: 1,406,390,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.74576
Policy Entropy: 3.03950
Value Function Loss: 0.00456

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.58974
Value Function Update Magnitude: 0.53696

Collected Steps per Second: 23,089.73666
Overall Steps per Second: 10,773.19860

Timestep Collection Time: 2.16555
Timestep Consumption Time: 2.47578
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.64133

Cumulative Model Updates: 168,638
Cumulative Timesteps: 1,406,440,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1406440304...
Checkpoint 1406440304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,064.83171
Policy Entropy: 3.03858
Value Function Loss: 0.00446

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.58640
Value Function Update Magnitude: 0.55941

Collected Steps per Second: 22,885.35651
Overall Steps per Second: 10,718.36370

Timestep Collection Time: 2.18585
Timestep Consumption Time: 2.48128
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.66713

Cumulative Model Updates: 168,644
Cumulative Timesteps: 1,406,490,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.78970
Policy Entropy: 3.04507
Value Function Loss: 0.00454

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.58726
Value Function Update Magnitude: 0.54810

Collected Steps per Second: 23,208.18783
Overall Steps per Second: 10,860.38363

Timestep Collection Time: 2.15467
Timestep Consumption Time: 2.44977
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60444

Cumulative Model Updates: 168,650
Cumulative Timesteps: 1,406,540,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1406540334...
Checkpoint 1406540334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,546.57809
Policy Entropy: 3.06317
Value Function Loss: 0.00450

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.58075
Value Function Update Magnitude: 0.52829

Collected Steps per Second: 22,744.50548
Overall Steps per Second: 10,700.15745

Timestep Collection Time: 2.19877
Timestep Consumption Time: 2.47499
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.67376

Cumulative Model Updates: 168,656
Cumulative Timesteps: 1,406,590,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,494.12032
Policy Entropy: 3.06615
Value Function Loss: 0.00437

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.57080
Value Function Update Magnitude: 0.51933

Collected Steps per Second: 22,958.72818
Overall Steps per Second: 10,819.84944

Timestep Collection Time: 2.17860
Timestep Consumption Time: 2.44420
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.62280

Cumulative Model Updates: 168,662
Cumulative Timesteps: 1,406,640,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1406640362...
Checkpoint 1406640362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,469.38030
Policy Entropy: 3.04314
Value Function Loss: 0.00450

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.57561
Value Function Update Magnitude: 0.50707

Collected Steps per Second: 22,628.78978
Overall Steps per Second: 10,785.74664

Timestep Collection Time: 2.21081
Timestep Consumption Time: 2.42753
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.63834

Cumulative Model Updates: 168,668
Cumulative Timesteps: 1,406,690,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.10149
Policy Entropy: 3.00329
Value Function Loss: 0.00457

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.59131
Value Function Update Magnitude: 0.54005

Collected Steps per Second: 22,901.52263
Overall Steps per Second: 10,834.43288

Timestep Collection Time: 2.18370
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.61584

Cumulative Model Updates: 168,674
Cumulative Timesteps: 1,406,740,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1406740400...
Checkpoint 1406740400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.26007
Policy Entropy: 2.98816
Value Function Loss: 0.00477

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.60521
Value Function Update Magnitude: 0.56935

Collected Steps per Second: 22,217.76321
Overall Steps per Second: 10,707.52888

Timestep Collection Time: 2.25162
Timestep Consumption Time: 2.42042
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.67204

Cumulative Model Updates: 168,680
Cumulative Timesteps: 1,406,790,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,644.91245
Policy Entropy: 2.99752
Value Function Loss: 0.00484

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.60918
Value Function Update Magnitude: 0.54827

Collected Steps per Second: 22,781.78168
Overall Steps per Second: 10,814.89113

Timestep Collection Time: 2.19605
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.62603

Cumulative Model Updates: 168,686
Cumulative Timesteps: 1,406,840,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1406840456...
Checkpoint 1406840456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.90159
Policy Entropy: 2.99489
Value Function Loss: 0.00546

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.62042
Value Function Update Magnitude: 0.54923

Collected Steps per Second: 22,377.25247
Overall Steps per Second: 10,680.73181

Timestep Collection Time: 2.23531
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.68320

Cumulative Model Updates: 168,692
Cumulative Timesteps: 1,406,890,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.17110
Policy Entropy: 3.00469
Value Function Loss: 0.00523

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13823
Policy Update Magnitude: 0.60823
Value Function Update Magnitude: 0.54853

Collected Steps per Second: 23,133.01739
Overall Steps per Second: 10,643.62567

Timestep Collection Time: 2.16202
Timestep Consumption Time: 2.53694
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.69896

Cumulative Model Updates: 168,698
Cumulative Timesteps: 1,406,940,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1406940490...
Checkpoint 1406940490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,521.57173
Policy Entropy: 3.00201
Value Function Loss: 0.00521

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.59460
Value Function Update Magnitude: 0.54084

Collected Steps per Second: 23,211.51197
Overall Steps per Second: 10,876.63806

Timestep Collection Time: 2.15419
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.59719

Cumulative Model Updates: 168,704
Cumulative Timesteps: 1,406,990,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,636.45650
Policy Entropy: 3.01120
Value Function Loss: 0.00457

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.58973
Value Function Update Magnitude: 0.53188

Collected Steps per Second: 23,353.10889
Overall Steps per Second: 10,916.91478

Timestep Collection Time: 2.14216
Timestep Consumption Time: 2.44027
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.58243

Cumulative Model Updates: 168,710
Cumulative Timesteps: 1,407,040,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1407040518...
Checkpoint 1407040518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.05986
Policy Entropy: 2.99820
Value Function Loss: 0.00464

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.58743
Value Function Update Magnitude: 0.52179

Collected Steps per Second: 22,654.47099
Overall Steps per Second: 10,696.11162

Timestep Collection Time: 2.20786
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.67628

Cumulative Model Updates: 168,716
Cumulative Timesteps: 1,407,090,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,069.29045
Policy Entropy: 2.99737
Value Function Loss: 0.00472

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.59026
Value Function Update Magnitude: 0.51537

Collected Steps per Second: 23,400.45200
Overall Steps per Second: 10,959.16134

Timestep Collection Time: 2.13688
Timestep Consumption Time: 2.42588
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.56276

Cumulative Model Updates: 168,722
Cumulative Timesteps: 1,407,140,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1407140540...
Checkpoint 1407140540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,665.31002
Policy Entropy: 2.99942
Value Function Loss: 0.00446

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.58471
Value Function Update Magnitude: 0.49747

Collected Steps per Second: 22,956.24165
Overall Steps per Second: 10,712.58225

Timestep Collection Time: 2.17893
Timestep Consumption Time: 2.49035
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.66928

Cumulative Model Updates: 168,728
Cumulative Timesteps: 1,407,190,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.85960
Policy Entropy: 3.01307
Value Function Loss: 0.00437

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.58038
Value Function Update Magnitude: 0.50601

Collected Steps per Second: 22,999.83073
Overall Steps per Second: 10,808.40989

Timestep Collection Time: 2.17462
Timestep Consumption Time: 2.45288
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.62751

Cumulative Model Updates: 168,734
Cumulative Timesteps: 1,407,240,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1407240576...
Checkpoint 1407240576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.52783
Policy Entropy: 3.01290
Value Function Loss: 0.00417

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.57598
Value Function Update Magnitude: 0.51462

Collected Steps per Second: 22,364.03669
Overall Steps per Second: 10,623.19622

Timestep Collection Time: 2.23654
Timestep Consumption Time: 2.47184
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.70838

Cumulative Model Updates: 168,740
Cumulative Timesteps: 1,407,290,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.82947
Policy Entropy: 3.01465
Value Function Loss: 0.00453

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.57838
Value Function Update Magnitude: 0.51043

Collected Steps per Second: 22,194.18139
Overall Steps per Second: 10,819.69355

Timestep Collection Time: 2.25401
Timestep Consumption Time: 2.36959
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.62361

Cumulative Model Updates: 168,746
Cumulative Timesteps: 1,407,340,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1407340620...
Checkpoint 1407340620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.48039
Policy Entropy: 3.00614
Value Function Loss: 0.00486

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.58645
Value Function Update Magnitude: 0.49358

Collected Steps per Second: 21,895.92018
Overall Steps per Second: 10,788.13031

Timestep Collection Time: 2.28435
Timestep Consumption Time: 2.35204
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.63639

Cumulative Model Updates: 168,752
Cumulative Timesteps: 1,407,390,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.45651
Policy Entropy: 3.01079
Value Function Loss: 0.00477

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11051
Policy Update Magnitude: 0.59439
Value Function Update Magnitude: 0.51189

Collected Steps per Second: 22,453.09764
Overall Steps per Second: 10,840.48918

Timestep Collection Time: 2.22802
Timestep Consumption Time: 2.38671
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61474

Cumulative Model Updates: 168,758
Cumulative Timesteps: 1,407,440,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1407440664...
Checkpoint 1407440664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,570.54013
Policy Entropy: 3.01416
Value Function Loss: 0.00472

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.59270
Value Function Update Magnitude: 0.52509

Collected Steps per Second: 22,307.87029
Overall Steps per Second: 10,694.29314

Timestep Collection Time: 2.24181
Timestep Consumption Time: 2.43452
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.67633

Cumulative Model Updates: 168,764
Cumulative Timesteps: 1,407,490,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.38160
Policy Entropy: 3.02268
Value Function Loss: 0.00438

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.58485
Value Function Update Magnitude: 0.52626

Collected Steps per Second: 22,432.38098
Overall Steps per Second: 10,925.67570

Timestep Collection Time: 2.22990
Timestep Consumption Time: 2.34849
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.57839

Cumulative Model Updates: 168,770
Cumulative Timesteps: 1,407,540,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1407540696...
Checkpoint 1407540696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.29133
Policy Entropy: 3.01159
Value Function Loss: 0.00429

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.56933
Value Function Update Magnitude: 0.52750

Collected Steps per Second: 22,297.77382
Overall Steps per Second: 10,747.24054

Timestep Collection Time: 2.24274
Timestep Consumption Time: 2.41037
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.65310

Cumulative Model Updates: 168,776
Cumulative Timesteps: 1,407,590,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,071.17196
Policy Entropy: 3.02113
Value Function Loss: 0.00406

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.56485
Value Function Update Magnitude: 0.50907

Collected Steps per Second: 22,557.84349
Overall Steps per Second: 10,753.06086

Timestep Collection Time: 2.21706
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.65095

Cumulative Model Updates: 168,782
Cumulative Timesteps: 1,407,640,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1407640716...
Checkpoint 1407640716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.58876
Policy Entropy: 3.03196
Value Function Loss: 0.00395

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.56502
Value Function Update Magnitude: 0.48901

Collected Steps per Second: 22,185.23746
Overall Steps per Second: 10,624.49404

Timestep Collection Time: 2.25384
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.70629

Cumulative Model Updates: 168,788
Cumulative Timesteps: 1,407,690,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,551.16633
Policy Entropy: 3.04945
Value Function Loss: 0.00427

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.57131
Value Function Update Magnitude: 0.48681

Collected Steps per Second: 22,740.95804
Overall Steps per Second: 10,850.01725

Timestep Collection Time: 2.19894
Timestep Consumption Time: 2.40990
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.60884

Cumulative Model Updates: 168,794
Cumulative Timesteps: 1,407,740,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1407740724...
Checkpoint 1407740724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.38778
Policy Entropy: 3.04464
Value Function Loss: 0.00460

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11383
Policy Update Magnitude: 0.58139
Value Function Update Magnitude: 0.52105

Collected Steps per Second: 22,404.58092
Overall Steps per Second: 10,724.11404

Timestep Collection Time: 2.23187
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.66276

Cumulative Model Updates: 168,800
Cumulative Timesteps: 1,407,790,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,208.01707
Policy Entropy: 3.04026
Value Function Loss: 0.00460

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.58608
Value Function Update Magnitude: 0.57083

Collected Steps per Second: 22,799.94340
Overall Steps per Second: 10,847.01992

Timestep Collection Time: 2.19299
Timestep Consumption Time: 2.41657
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60956

Cumulative Model Updates: 168,806
Cumulative Timesteps: 1,407,840,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1407840728...
Checkpoint 1407840728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.22800
Policy Entropy: 3.03548
Value Function Loss: 0.00446

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.58508
Value Function Update Magnitude: 0.55825

Collected Steps per Second: 22,883.75895
Overall Steps per Second: 10,654.19396

Timestep Collection Time: 2.18592
Timestep Consumption Time: 2.50914
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69505

Cumulative Model Updates: 168,812
Cumulative Timesteps: 1,407,890,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,925.03715
Policy Entropy: 3.03297
Value Function Loss: 0.00424

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.53851

Collected Steps per Second: 23,351.14959
Overall Steps per Second: 10,880.37219

Timestep Collection Time: 2.14156
Timestep Consumption Time: 2.45460
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.59617

Cumulative Model Updates: 168,818
Cumulative Timesteps: 1,407,940,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1407940758...
Checkpoint 1407940758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,883.29427
Policy Entropy: 3.02328
Value Function Loss: 0.00430

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.58348
Value Function Update Magnitude: 0.53514

Collected Steps per Second: 21,413.27440
Overall Steps per Second: 10,365.25151

Timestep Collection Time: 2.33603
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.82593

Cumulative Model Updates: 168,824
Cumulative Timesteps: 1,407,990,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,750.26562
Policy Entropy: 3.02039
Value Function Loss: 0.00417

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.57769
Value Function Update Magnitude: 0.52959

Collected Steps per Second: 22,876.96673
Overall Steps per Second: 10,793.56848

Timestep Collection Time: 2.18692
Timestep Consumption Time: 2.44825
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.63517

Cumulative Model Updates: 168,830
Cumulative Timesteps: 1,408,040,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1408040810...
Checkpoint 1408040810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,470.20996
Policy Entropy: 3.00766
Value Function Loss: 0.00474

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.59030
Value Function Update Magnitude: 0.54429

Collected Steps per Second: 22,589.80015
Overall Steps per Second: 10,637.24351

Timestep Collection Time: 2.21357
Timestep Consumption Time: 2.48728
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.70084

Cumulative Model Updates: 168,836
Cumulative Timesteps: 1,408,090,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,394.65512
Policy Entropy: 3.01776
Value Function Loss: 0.00502

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.61636
Value Function Update Magnitude: 0.56993

Collected Steps per Second: 23,205.70505
Overall Steps per Second: 10,837.65821

Timestep Collection Time: 2.15568
Timestep Consumption Time: 2.46008
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.61576

Cumulative Model Updates: 168,842
Cumulative Timesteps: 1,408,140,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1408140838...
Checkpoint 1408140838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,279.39789
Policy Entropy: 3.02878
Value Function Loss: 0.00477

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11594
Policy Update Magnitude: 0.60993
Value Function Update Magnitude: 0.57669

Collected Steps per Second: 23,018.46060
Overall Steps per Second: 10,720.07797

Timestep Collection Time: 2.17339
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.66676

Cumulative Model Updates: 168,848
Cumulative Timesteps: 1,408,190,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,518.57174
Policy Entropy: 3.04219
Value Function Loss: 0.00402

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.58435
Value Function Update Magnitude: 0.53654

Collected Steps per Second: 23,128.73848
Overall Steps per Second: 10,839.74781

Timestep Collection Time: 2.16268
Timestep Consumption Time: 2.45182
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.61450

Cumulative Model Updates: 168,854
Cumulative Timesteps: 1,408,240,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1408240886...
Checkpoint 1408240886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,249.95324
Policy Entropy: 3.03268
Value Function Loss: 0.00410

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.56965
Value Function Update Magnitude: 0.50150

Collected Steps per Second: 22,881.74747
Overall Steps per Second: 10,696.50936

Timestep Collection Time: 2.18524
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.67461

Cumulative Model Updates: 168,860
Cumulative Timesteps: 1,408,290,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,061.39536
Policy Entropy: 3.02311
Value Function Loss: 0.00397

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.56938
Value Function Update Magnitude: 0.49326

Collected Steps per Second: 23,026.07590
Overall Steps per Second: 10,861.08721

Timestep Collection Time: 2.17206
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.60488

Cumulative Model Updates: 168,866
Cumulative Timesteps: 1,408,340,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1408340902...
Checkpoint 1408340902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,634.38959
Policy Entropy: 3.01592
Value Function Loss: 0.00426

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.56531
Value Function Update Magnitude: 0.48833

Collected Steps per Second: 23,059.51188
Overall Steps per Second: 10,669.04577

Timestep Collection Time: 2.16960
Timestep Consumption Time: 2.51966
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.68927

Cumulative Model Updates: 168,872
Cumulative Timesteps: 1,408,390,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,515.67990
Policy Entropy: 3.01601
Value Function Loss: 0.00429

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.57407
Value Function Update Magnitude: 0.46319

Collected Steps per Second: 23,046.46157
Overall Steps per Second: 10,841.51724

Timestep Collection Time: 2.17066
Timestep Consumption Time: 2.44364
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.61430

Cumulative Model Updates: 168,878
Cumulative Timesteps: 1,408,440,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1408440958...
Checkpoint 1408440958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,288.19375
Policy Entropy: 2.99841
Value Function Loss: 0.00468

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.58817
Value Function Update Magnitude: 0.47836

Collected Steps per Second: 22,531.82262
Overall Steps per Second: 10,700.89173

Timestep Collection Time: 2.22050
Timestep Consumption Time: 2.45499
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.67550

Cumulative Model Updates: 168,884
Cumulative Timesteps: 1,408,490,990

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.86116
Policy Entropy: 3.00092
Value Function Loss: 0.00421

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.58162
Value Function Update Magnitude: 0.49864

Collected Steps per Second: 22,567.95206
Overall Steps per Second: 10,631.25184

Timestep Collection Time: 2.21589
Timestep Consumption Time: 2.48798
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.70387

Cumulative Model Updates: 168,890
Cumulative Timesteps: 1,408,540,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1408540998...
Checkpoint 1408540998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,957.53154
Policy Entropy: 3.01669
Value Function Loss: 0.00419

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.56633
Value Function Update Magnitude: 0.50397

Collected Steps per Second: 22,649.21477
Overall Steps per Second: 10,691.93214

Timestep Collection Time: 2.20891
Timestep Consumption Time: 2.47032
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.67923

Cumulative Model Updates: 168,896
Cumulative Timesteps: 1,408,591,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,401.95290
Policy Entropy: 3.03457
Value Function Loss: 0.00395

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.51529

Collected Steps per Second: 22,925.73712
Overall Steps per Second: 10,728.03249

Timestep Collection Time: 2.18174
Timestep Consumption Time: 2.48062
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.66236

Cumulative Model Updates: 168,902
Cumulative Timesteps: 1,408,641,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1408641046...
Checkpoint 1408641046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,923.88795
Policy Entropy: 3.04721
Value Function Loss: 0.00415

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.55825
Value Function Update Magnitude: 0.51543

Collected Steps per Second: 23,000.59410
Overall Steps per Second: 10,604.08101

Timestep Collection Time: 2.17403
Timestep Consumption Time: 2.54151
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.71554

Cumulative Model Updates: 168,908
Cumulative Timesteps: 1,408,691,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,562.91983
Policy Entropy: 3.03300
Value Function Loss: 0.00402

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.49783

Collected Steps per Second: 23,012.50302
Overall Steps per Second: 10,844.39824

Timestep Collection Time: 2.17343
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.61215

Cumulative Model Updates: 168,914
Cumulative Timesteps: 1,408,741,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1408741066...
Checkpoint 1408741066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.67799
Policy Entropy: 3.02215
Value Function Loss: 0.00388

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.49102

Collected Steps per Second: 22,422.35520
Overall Steps per Second: 10,722.87489

Timestep Collection Time: 2.22992
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.66293

Cumulative Model Updates: 168,920
Cumulative Timesteps: 1,408,791,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,690.38922
Policy Entropy: 3.00349
Value Function Loss: 0.00406

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.47266

Collected Steps per Second: 22,363.18775
Overall Steps per Second: 10,844.03106

Timestep Collection Time: 2.23689
Timestep Consumption Time: 2.37615
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.61304

Cumulative Model Updates: 168,926
Cumulative Timesteps: 1,408,841,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1408841090...
Checkpoint 1408841090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,113.72347
Policy Entropy: 3.01036
Value Function Loss: 0.00408

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.56882
Value Function Update Magnitude: 0.47084

Collected Steps per Second: 22,078.46827
Overall Steps per Second: 10,675.62775

Timestep Collection Time: 2.26501
Timestep Consumption Time: 2.41930
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.68431

Cumulative Model Updates: 168,932
Cumulative Timesteps: 1,408,891,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,513.96887
Policy Entropy: 2.99878
Value Function Loss: 0.00453

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.58548
Value Function Update Magnitude: 0.49298

Collected Steps per Second: 22,323.63883
Overall Steps per Second: 10,880.22888

Timestep Collection Time: 2.23996
Timestep Consumption Time: 2.35590
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59586

Cumulative Model Updates: 168,938
Cumulative Timesteps: 1,408,941,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1408941102...
Checkpoint 1408941102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928.66830
Policy Entropy: 3.00357
Value Function Loss: 0.00432

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.58866
Value Function Update Magnitude: 0.51573

Collected Steps per Second: 21,757.05799
Overall Steps per Second: 10,711.58710

Timestep Collection Time: 2.29838
Timestep Consumption Time: 2.37002
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.66840

Cumulative Model Updates: 168,944
Cumulative Timesteps: 1,408,991,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.94115
Policy Entropy: 3.00712
Value Function Loss: 0.00429

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.58483
Value Function Update Magnitude: 0.51219

Collected Steps per Second: 22,036.84728
Overall Steps per Second: 10,788.36984

Timestep Collection Time: 2.26893
Timestep Consumption Time: 2.36569
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.63462

Cumulative Model Updates: 168,950
Cumulative Timesteps: 1,409,041,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1409041108...
Checkpoint 1409041108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,667.59389
Policy Entropy: 3.00444
Value Function Loss: 0.00425

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.58814
Value Function Update Magnitude: 0.51987

Collected Steps per Second: 21,946.14684
Overall Steps per Second: 10,663.44786

Timestep Collection Time: 2.27840
Timestep Consumption Time: 2.41071
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.68910

Cumulative Model Updates: 168,956
Cumulative Timesteps: 1,409,091,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.48707
Policy Entropy: 2.98728
Value Function Loss: 0.00428

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.51323

Collected Steps per Second: 22,939.31548
Overall Steps per Second: 10,748.41450

Timestep Collection Time: 2.18027
Timestep Consumption Time: 2.47288
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.65315

Cumulative Model Updates: 168,962
Cumulative Timesteps: 1,409,141,124

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1409141124...
Checkpoint 1409141124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.57648
Policy Entropy: 2.96252
Value Function Loss: 0.00439

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.59567
Value Function Update Magnitude: 0.52071

Collected Steps per Second: 22,915.52957
Overall Steps per Second: 10,868.22546

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.60094

Cumulative Model Updates: 168,968
Cumulative Timesteps: 1,409,191,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.06727
Policy Entropy: 2.97038
Value Function Loss: 0.00426

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.59910
Value Function Update Magnitude: 0.51971

Collected Steps per Second: 23,025.26095
Overall Steps per Second: 10,925.82508

Timestep Collection Time: 2.17231
Timestep Consumption Time: 2.40565
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.57796

Cumulative Model Updates: 168,974
Cumulative Timesteps: 1,409,241,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1409241146...
Checkpoint 1409241146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,147.92398
Policy Entropy: 2.97511
Value Function Loss: 0.00435

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11791
Policy Update Magnitude: 0.60156
Value Function Update Magnitude: 0.53005

Collected Steps per Second: 23,166.42374
Overall Steps per Second: 10,922.50559

Timestep Collection Time: 2.15907
Timestep Consumption Time: 2.42028
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.57935

Cumulative Model Updates: 168,980
Cumulative Timesteps: 1,409,291,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,856.69164
Policy Entropy: 2.97537
Value Function Loss: 0.00437

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.61310
Value Function Update Magnitude: 0.54232

Collected Steps per Second: 22,851.54388
Overall Steps per Second: 10,737.86839

Timestep Collection Time: 2.18856
Timestep Consumption Time: 2.46897
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.65754

Cumulative Model Updates: 168,986
Cumulative Timesteps: 1,409,341,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1409341176...
Checkpoint 1409341176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.79927
Policy Entropy: 2.98292
Value Function Loss: 0.00453

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.62250
Value Function Update Magnitude: 0.54737

Collected Steps per Second: 23,101.17504
Overall Steps per Second: 11,004.76942

Timestep Collection Time: 2.16534
Timestep Consumption Time: 2.38014
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.54548

Cumulative Model Updates: 168,992
Cumulative Timesteps: 1,409,391,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.99682
Policy Entropy: 2.99240
Value Function Loss: 0.00457

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.61138
Value Function Update Magnitude: 0.55130

Collected Steps per Second: 22,201.71734
Overall Steps per Second: 10,491.00407

Timestep Collection Time: 2.25334
Timestep Consumption Time: 2.51532
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.76866

Cumulative Model Updates: 168,998
Cumulative Timesteps: 1,409,441,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1409441226...
Checkpoint 1409441226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.29823
Policy Entropy: 2.99637
Value Function Loss: 0.00444

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.59824
Value Function Update Magnitude: 0.52449

Collected Steps per Second: 22,698.58368
Overall Steps per Second: 10,620.00275

Timestep Collection Time: 2.20349
Timestep Consumption Time: 2.50612
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.70960

Cumulative Model Updates: 169,004
Cumulative Timesteps: 1,409,491,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,077.72560
Policy Entropy: 2.98992
Value Function Loss: 0.00438

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.59656
Value Function Update Magnitude: 0.52953

Collected Steps per Second: 22,634.65133
Overall Steps per Second: 10,761.85139

Timestep Collection Time: 2.20997
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.64809

Cumulative Model Updates: 169,010
Cumulative Timesteps: 1,409,541,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1409541264...
Checkpoint 1409541264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,977.66392
Policy Entropy: 2.98983
Value Function Loss: 0.00408

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.59416
Value Function Update Magnitude: 0.52498

Collected Steps per Second: 22,754.85271
Overall Steps per Second: 10,759.90345

Timestep Collection Time: 2.19856
Timestep Consumption Time: 2.45092
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.64948

Cumulative Model Updates: 169,016
Cumulative Timesteps: 1,409,591,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,440.24527
Policy Entropy: 2.97701
Value Function Loss: 0.00450

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.60039
Value Function Update Magnitude: 0.50490

Collected Steps per Second: 23,012.66308
Overall Steps per Second: 10,796.37559

Timestep Collection Time: 2.17359
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.63304

Cumulative Model Updates: 169,022
Cumulative Timesteps: 1,409,641,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1409641312...
Checkpoint 1409641312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,602.18993
Policy Entropy: 2.97299
Value Function Loss: 0.00423

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.59236
Value Function Update Magnitude: 0.50443

Collected Steps per Second: 22,983.57867
Overall Steps per Second: 10,699.76058

Timestep Collection Time: 2.17564
Timestep Consumption Time: 2.49774
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.67338

Cumulative Model Updates: 169,028
Cumulative Timesteps: 1,409,691,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,332.31101
Policy Entropy: 2.96610
Value Function Loss: 0.00437

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.58067
Value Function Update Magnitude: 0.49512

Collected Steps per Second: 22,984.20352
Overall Steps per Second: 10,843.78909

Timestep Collection Time: 2.17636
Timestep Consumption Time: 2.43660
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.61296

Cumulative Model Updates: 169,034
Cumulative Timesteps: 1,409,741,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1409741338...
Checkpoint 1409741338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.74740
Policy Entropy: 2.98131
Value Function Loss: 0.00414

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.58161
Value Function Update Magnitude: 0.49026

Collected Steps per Second: 23,177.78369
Overall Steps per Second: 10,826.92244

Timestep Collection Time: 2.15793
Timestep Consumption Time: 2.46167
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.61960

Cumulative Model Updates: 169,040
Cumulative Timesteps: 1,409,791,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,730.28937
Policy Entropy: 2.97549
Value Function Loss: 0.00481

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.60501
Value Function Update Magnitude: 0.51605

Collected Steps per Second: 22,805.57671
Overall Steps per Second: 10,815.48357

Timestep Collection Time: 2.19245
Timestep Consumption Time: 2.43056
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.62300

Cumulative Model Updates: 169,046
Cumulative Timesteps: 1,409,841,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1409841354...
Checkpoint 1409841354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,677.83025
Policy Entropy: 2.96298
Value Function Loss: 0.00470

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.61967
Value Function Update Magnitude: 0.53516

Collected Steps per Second: 22,480.24387
Overall Steps per Second: 10,590.70123

Timestep Collection Time: 2.22595
Timestep Consumption Time: 2.49895
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.72490

Cumulative Model Updates: 169,052
Cumulative Timesteps: 1,409,891,394

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,041.34970
Policy Entropy: 2.96098
Value Function Loss: 0.00479

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.61905
Value Function Update Magnitude: 0.54556

Collected Steps per Second: 22,459.03680
Overall Steps per Second: 10,542.90300

Timestep Collection Time: 2.22636
Timestep Consumption Time: 2.51635
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.74272

Cumulative Model Updates: 169,058
Cumulative Timesteps: 1,409,941,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1409941396...
Checkpoint 1409941396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.08005
Policy Entropy: 2.97449
Value Function Loss: 0.00478

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.61706
Value Function Update Magnitude: 0.56747

Collected Steps per Second: 22,712.95988
Overall Steps per Second: 10,756.66663

Timestep Collection Time: 2.20209
Timestep Consumption Time: 2.44768
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.64977

Cumulative Model Updates: 169,064
Cumulative Timesteps: 1,409,991,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,476.39397
Policy Entropy: 2.96895
Value Function Loss: 0.00446

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.14790
Policy Update Magnitude: 0.60670
Value Function Update Magnitude: 0.54522

Collected Steps per Second: 22,591.41574
Overall Steps per Second: 10,772.38268

Timestep Collection Time: 2.21341
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.64187

Cumulative Model Updates: 169,070
Cumulative Timesteps: 1,410,041,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1410041416...
Checkpoint 1410041416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,618.09132
Policy Entropy: 2.96909
Value Function Loss: 0.00454

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.59605
Value Function Update Magnitude: 0.52358

Collected Steps per Second: 22,587.07625
Overall Steps per Second: 10,566.36748

Timestep Collection Time: 2.21489
Timestep Consumption Time: 2.51975
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.73465

Cumulative Model Updates: 169,076
Cumulative Timesteps: 1,410,091,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.19147
Policy Entropy: 2.96951
Value Function Loss: 0.00480

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.60934
Value Function Update Magnitude: 0.53100

Collected Steps per Second: 23,131.25331
Overall Steps per Second: 10,851.59181

Timestep Collection Time: 2.16262
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.60983

Cumulative Model Updates: 169,082
Cumulative Timesteps: 1,410,141,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1410141468...
Checkpoint 1410141468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,165.80225
Policy Entropy: 2.97704
Value Function Loss: 0.00475

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.60892
Value Function Update Magnitude: 0.54326

Collected Steps per Second: 22,949.94198
Overall Steps per Second: 10,705.58984

Timestep Collection Time: 2.17970
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.67270

Cumulative Model Updates: 169,088
Cumulative Timesteps: 1,410,191,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,104.08963
Policy Entropy: 2.99301
Value Function Loss: 0.00476

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.60081
Value Function Update Magnitude: 0.54327

Collected Steps per Second: 23,249.86450
Overall Steps per Second: 10,880.88098

Timestep Collection Time: 2.15107
Timestep Consumption Time: 2.44525
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.59632

Cumulative Model Updates: 169,094
Cumulative Timesteps: 1,410,241,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1410241504...
Checkpoint 1410241504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,799.43715
Policy Entropy: 2.99016
Value Function Loss: 0.00454

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.60243
Value Function Update Magnitude: 0.52851

Collected Steps per Second: 22,948.04657
Overall Steps per Second: 10,655.07442

Timestep Collection Time: 2.17901
Timestep Consumption Time: 2.51397
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.69298

Cumulative Model Updates: 169,100
Cumulative Timesteps: 1,410,291,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,931.73831
Policy Entropy: 2.98487
Value Function Loss: 0.00497

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.61873
Value Function Update Magnitude: 0.55753

Collected Steps per Second: 23,229.98109
Overall Steps per Second: 10,971.03729

Timestep Collection Time: 2.15248
Timestep Consumption Time: 2.40516
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.55764

Cumulative Model Updates: 169,106
Cumulative Timesteps: 1,410,341,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1410341510...
Checkpoint 1410341510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.91264
Policy Entropy: 2.99186
Value Function Loss: 0.00479

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.61928
Value Function Update Magnitude: 0.57046

Collected Steps per Second: 23,080.42792
Overall Steps per Second: 10,717.51409

Timestep Collection Time: 2.16755
Timestep Consumption Time: 2.50032
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.66787

Cumulative Model Updates: 169,112
Cumulative Timesteps: 1,410,391,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.14083
Policy Entropy: 2.99002
Value Function Loss: 0.00472

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.60930
Value Function Update Magnitude: 0.56523

Collected Steps per Second: 22,437.59756
Overall Steps per Second: 10,705.54654

Timestep Collection Time: 2.22947
Timestep Consumption Time: 2.44325
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.67272

Cumulative Model Updates: 169,118
Cumulative Timesteps: 1,410,441,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1410441562...
Checkpoint 1410441562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252.71780
Policy Entropy: 3.01306
Value Function Loss: 0.00444

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.60675
Value Function Update Magnitude: 0.56340

Collected Steps per Second: 22,555.08359
Overall Steps per Second: 10,740.87723

Timestep Collection Time: 2.21759
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.65679

Cumulative Model Updates: 169,124
Cumulative Timesteps: 1,410,491,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.02107
Policy Entropy: 3.00557
Value Function Loss: 0.00428

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.58972
Value Function Update Magnitude: 0.53413

Collected Steps per Second: 22,810.75492
Overall Steps per Second: 10,835.98152

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.61592

Cumulative Model Updates: 169,130
Cumulative Timesteps: 1,410,541,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1410541598...
Checkpoint 1410541598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.30261
Policy Entropy: 3.00830
Value Function Loss: 0.00438

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.58617
Value Function Update Magnitude: 0.52554

Collected Steps per Second: 22,809.50858
Overall Steps per Second: 10,736.04189

Timestep Collection Time: 2.19242
Timestep Consumption Time: 2.46554
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.65795

Cumulative Model Updates: 169,136
Cumulative Timesteps: 1,410,591,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,083.44990
Policy Entropy: 2.99805
Value Function Loss: 0.00447

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.59650
Value Function Update Magnitude: 0.53056

Collected Steps per Second: 22,754.92588
Overall Steps per Second: 10,533.55484

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.54982
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.74750

Cumulative Model Updates: 169,142
Cumulative Timesteps: 1,410,641,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1410641614...
Checkpoint 1410641614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.35999
Policy Entropy: 2.99799
Value Function Loss: 0.00458

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.61274
Value Function Update Magnitude: 0.56477

Collected Steps per Second: 22,885.45300
Overall Steps per Second: 10,644.00236

Timestep Collection Time: 2.18567
Timestep Consumption Time: 2.51369
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.69936

Cumulative Model Updates: 169,148
Cumulative Timesteps: 1,410,691,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,882.53720
Policy Entropy: 2.99779
Value Function Loss: 0.00457

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.61889
Value Function Update Magnitude: 0.56862

Collected Steps per Second: 23,217.64980
Overall Steps per Second: 10,820.13138

Timestep Collection Time: 2.15379
Timestep Consumption Time: 2.46778
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.62157

Cumulative Model Updates: 169,154
Cumulative Timesteps: 1,410,741,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1410741640...
Checkpoint 1410741640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,219.21309
Policy Entropy: 3.00323
Value Function Loss: 0.00486

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.61594
Value Function Update Magnitude: 0.55233

Collected Steps per Second: 22,923.63005
Overall Steps per Second: 10,688.18723

Timestep Collection Time: 2.18168
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.67918

Cumulative Model Updates: 169,160
Cumulative Timesteps: 1,410,791,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.05689
Policy Entropy: 3.01691
Value Function Loss: 0.00467

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.60456
Value Function Update Magnitude: 0.53682

Collected Steps per Second: 22,979.11794
Overall Steps per Second: 10,825.27734

Timestep Collection Time: 2.17719
Timestep Consumption Time: 2.44440
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.62159

Cumulative Model Updates: 169,166
Cumulative Timesteps: 1,410,841,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1410841682...
Checkpoint 1410841682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.18614
Policy Entropy: 3.02801
Value Function Loss: 0.00447

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.58874
Value Function Update Magnitude: 0.51181

Collected Steps per Second: 22,862.71354
Overall Steps per Second: 10,638.90689

Timestep Collection Time: 2.18819
Timestep Consumption Time: 2.51417
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.70236

Cumulative Model Updates: 169,172
Cumulative Timesteps: 1,410,891,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.57421
Policy Entropy: 3.02147
Value Function Loss: 0.00438

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.58815
Value Function Update Magnitude: 0.49120

Collected Steps per Second: 22,955.03033
Overall Steps per Second: 10,844.06264

Timestep Collection Time: 2.17878
Timestep Consumption Time: 2.43333
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.61211

Cumulative Model Updates: 169,178
Cumulative Timesteps: 1,410,941,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1410941724...
Checkpoint 1410941724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.30683
Policy Entropy: 2.99763
Value Function Loss: 0.00439

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.58666
Value Function Update Magnitude: 0.49192

Collected Steps per Second: 22,555.69113
Overall Steps per Second: 10,758.43319

Timestep Collection Time: 2.21744
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.64900

Cumulative Model Updates: 169,184
Cumulative Timesteps: 1,410,991,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.03355
Policy Entropy: 3.00489
Value Function Loss: 0.00487

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.58748
Value Function Update Magnitude: 0.51701

Collected Steps per Second: 22,448.97337
Overall Steps per Second: 10,586.10170

Timestep Collection Time: 2.22870
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.72620

Cumulative Model Updates: 169,190
Cumulative Timesteps: 1,411,041,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1411041772...
Checkpoint 1411041772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,510.39091
Policy Entropy: 3.01626
Value Function Loss: 0.00448

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.58359
Value Function Update Magnitude: 0.54383

Collected Steps per Second: 22,798.04194
Overall Steps per Second: 10,822.97961

Timestep Collection Time: 2.19414
Timestep Consumption Time: 2.42770
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.62183

Cumulative Model Updates: 169,196
Cumulative Timesteps: 1,411,091,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,786.69220
Policy Entropy: 3.01868
Value Function Loss: 0.00444

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.58510
Value Function Update Magnitude: 0.52250

Collected Steps per Second: 22,752.59671
Overall Steps per Second: 10,618.42702

Timestep Collection Time: 2.19896
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.71181

Cumulative Model Updates: 169,202
Cumulative Timesteps: 1,411,141,826

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1411141826...
Checkpoint 1411141826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.29682
Policy Entropy: 3.00854
Value Function Loss: 0.00482

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.60435
Value Function Update Magnitude: 0.52865

Collected Steps per Second: 23,246.26594
Overall Steps per Second: 10,694.61599

Timestep Collection Time: 2.15192
Timestep Consumption Time: 2.52558
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.67749

Cumulative Model Updates: 169,208
Cumulative Timesteps: 1,411,191,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.93821
Policy Entropy: 3.00510
Value Function Loss: 0.00475

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.60425
Value Function Update Magnitude: 0.56718

Collected Steps per Second: 23,191.33276
Overall Steps per Second: 10,665.96200

Timestep Collection Time: 2.15606
Timestep Consumption Time: 2.53193
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.68800

Cumulative Model Updates: 169,214
Cumulative Timesteps: 1,411,241,852

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1411241852...
Checkpoint 1411241852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,693.33378
Policy Entropy: 3.00319
Value Function Loss: 0.00458

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.59310
Value Function Update Magnitude: 0.55641

Collected Steps per Second: 22,918.23791
Overall Steps per Second: 10,732.74246

Timestep Collection Time: 2.18272
Timestep Consumption Time: 2.47816
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.66088

Cumulative Model Updates: 169,220
Cumulative Timesteps: 1,411,291,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,448.66341
Policy Entropy: 3.00500
Value Function Loss: 0.00449

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.59343
Value Function Update Magnitude: 0.54022

Collected Steps per Second: 22,973.38572
Overall Steps per Second: 10,846.69400

Timestep Collection Time: 2.17721
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61136

Cumulative Model Updates: 169,226
Cumulative Timesteps: 1,411,341,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1411341894...
Checkpoint 1411341894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,505.59300
Policy Entropy: 3.00330
Value Function Loss: 0.00432

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.59351
Value Function Update Magnitude: 0.53686

Collected Steps per Second: 23,176.98039
Overall Steps per Second: 10,716.88743

Timestep Collection Time: 2.15792
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.66684

Cumulative Model Updates: 169,232
Cumulative Timesteps: 1,411,391,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,545.11542
Policy Entropy: 3.00235
Value Function Loss: 0.00441

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.59004
Value Function Update Magnitude: 0.52550

Collected Steps per Second: 22,736.10699
Overall Steps per Second: 10,682.79715

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.48237
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.68248

Cumulative Model Updates: 169,238
Cumulative Timesteps: 1,411,441,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1411441930...
Checkpoint 1411441930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 882.27262
Policy Entropy: 2.99406
Value Function Loss: 0.00459

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.59350
Value Function Update Magnitude: 0.50104

Collected Steps per Second: 22,975.64921
Overall Steps per Second: 10,913.75698

Timestep Collection Time: 2.17752
Timestep Consumption Time: 2.40660
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.58412

Cumulative Model Updates: 169,244
Cumulative Timesteps: 1,411,491,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,980.49478
Policy Entropy: 3.00166
Value Function Loss: 0.00443

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.58743
Value Function Update Magnitude: 0.48057

Collected Steps per Second: 22,401.34258
Overall Steps per Second: 10,660.68899

Timestep Collection Time: 2.23237
Timestep Consumption Time: 2.45851
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.69088

Cumulative Model Updates: 169,250
Cumulative Timesteps: 1,411,541,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1411541968...
Checkpoint 1411541968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.47087
Policy Entropy: 3.01636
Value Function Loss: 0.00429

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.48316

Collected Steps per Second: 22,847.00824
Overall Steps per Second: 10,823.94559

Timestep Collection Time: 2.18882
Timestep Consumption Time: 2.43131
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.62013

Cumulative Model Updates: 169,256
Cumulative Timesteps: 1,411,591,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,134.68847
Policy Entropy: 3.02758
Value Function Loss: 0.00391

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.57380
Value Function Update Magnitude: 0.48809

Collected Steps per Second: 22,694.09941
Overall Steps per Second: 10,647.04468

Timestep Collection Time: 2.20392
Timestep Consumption Time: 2.49372
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.69764

Cumulative Model Updates: 169,262
Cumulative Timesteps: 1,411,641,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1411641992...
Checkpoint 1411641992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,682.48088
Policy Entropy: 3.01580
Value Function Loss: 0.00430

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.58334
Value Function Update Magnitude: 0.50957

Collected Steps per Second: 22,898.07080
Overall Steps per Second: 10,718.14325

Timestep Collection Time: 2.18385
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.66555

Cumulative Model Updates: 169,268
Cumulative Timesteps: 1,411,691,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,302.06196
Policy Entropy: 2.99704
Value Function Loss: 0.00421

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.59247
Value Function Update Magnitude: 0.53027

Collected Steps per Second: 23,423.11507
Overall Steps per Second: 10,829.00854

Timestep Collection Time: 2.13516
Timestep Consumption Time: 2.48318
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.61834

Cumulative Model Updates: 169,274
Cumulative Timesteps: 1,411,742,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1411742010...
Checkpoint 1411742010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,651.28020
Policy Entropy: 3.00450
Value Function Loss: 0.00459

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.58784
Value Function Update Magnitude: 0.52547

Collected Steps per Second: 22,993.59634
Overall Steps per Second: 10,886.71580

Timestep Collection Time: 2.17530
Timestep Consumption Time: 2.41911
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.59441

Cumulative Model Updates: 169,280
Cumulative Timesteps: 1,411,792,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.56882
Policy Entropy: 3.01799
Value Function Loss: 0.00462

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.58748
Value Function Update Magnitude: 0.53312

Collected Steps per Second: 22,011.50559
Overall Steps per Second: 10,502.27751

Timestep Collection Time: 2.27154
Timestep Consumption Time: 2.48933
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.76087

Cumulative Model Updates: 169,286
Cumulative Timesteps: 1,411,842,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1411842028...
Checkpoint 1411842028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,760.85162
Policy Entropy: 3.02611
Value Function Loss: 0.00443

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.58972
Value Function Update Magnitude: 0.54426

Collected Steps per Second: 22,522.79029
Overall Steps per Second: 10,646.74948

Timestep Collection Time: 2.22060
Timestep Consumption Time: 2.47699
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.69758

Cumulative Model Updates: 169,292
Cumulative Timesteps: 1,411,892,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,707.23372
Policy Entropy: 3.02573
Value Function Loss: 0.00417

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.57437
Value Function Update Magnitude: 0.51813

Collected Steps per Second: 22,679.87269
Overall Steps per Second: 10,671.33366

Timestep Collection Time: 2.20522
Timestep Consumption Time: 2.48155
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.68676

Cumulative Model Updates: 169,298
Cumulative Timesteps: 1,411,942,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1411942056...
Checkpoint 1411942056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,512.70245
Policy Entropy: 3.02090
Value Function Loss: 0.00403

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.51533

Collected Steps per Second: 22,496.95810
Overall Steps per Second: 10,625.41734

Timestep Collection Time: 2.22279
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.70626

Cumulative Model Updates: 169,304
Cumulative Timesteps: 1,411,992,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,200.57962
Policy Entropy: 3.00989
Value Function Loss: 0.00378

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.56616
Value Function Update Magnitude: 0.51095

Collected Steps per Second: 23,094.29147
Overall Steps per Second: 10,672.99431

Timestep Collection Time: 2.16538
Timestep Consumption Time: 2.52009
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.68547

Cumulative Model Updates: 169,310
Cumulative Timesteps: 1,412,042,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1412042070...
Checkpoint 1412042070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,362.59075
Policy Entropy: 3.00441
Value Function Loss: 0.00364

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.56002
Value Function Update Magnitude: 0.48326

Collected Steps per Second: 23,053.31152
Overall Steps per Second: 10,683.14092

Timestep Collection Time: 2.16889
Timestep Consumption Time: 2.51139
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.68027

Cumulative Model Updates: 169,316
Cumulative Timesteps: 1,412,092,070

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,124.17930
Policy Entropy: 2.98563
Value Function Loss: 0.00390

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.56780
Value Function Update Magnitude: 0.47880

Collected Steps per Second: 23,161.86881
Overall Steps per Second: 10,891.30014

Timestep Collection Time: 2.15915
Timestep Consumption Time: 2.43259
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.59174

Cumulative Model Updates: 169,322
Cumulative Timesteps: 1,412,142,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1412142080...
Checkpoint 1412142080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,161.96959
Policy Entropy: 2.98115
Value Function Loss: 0.00412

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.58577
Value Function Update Magnitude: 0.49747

Collected Steps per Second: 23,275.79580
Overall Steps per Second: 10,802.47104

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.48131
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.63024

Cumulative Model Updates: 169,328
Cumulative Timesteps: 1,412,192,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,243.79107
Policy Entropy: 2.96692
Value Function Loss: 0.00429

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.59449
Value Function Update Magnitude: 0.50519

Collected Steps per Second: 23,212.36197
Overall Steps per Second: 10,751.42757

Timestep Collection Time: 2.15437
Timestep Consumption Time: 2.49692
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.65129

Cumulative Model Updates: 169,334
Cumulative Timesteps: 1,412,242,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1412242106...
Checkpoint 1412242106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,440.45148
Policy Entropy: 2.97630
Value Function Loss: 0.00433

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.59234
Value Function Update Magnitude: 0.51113

Collected Steps per Second: 22,974.85993
Overall Steps per Second: 10,776.33379

Timestep Collection Time: 2.17725
Timestep Consumption Time: 2.46459
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.64184

Cumulative Model Updates: 169,340
Cumulative Timesteps: 1,412,292,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.28886
Policy Entropy: 2.97553
Value Function Loss: 0.00442

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.59410
Value Function Update Magnitude: 0.53723

Collected Steps per Second: 22,805.92923
Overall Steps per Second: 10,756.87938

Timestep Collection Time: 2.19268
Timestep Consumption Time: 2.45607
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.64875

Cumulative Model Updates: 169,346
Cumulative Timesteps: 1,412,342,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1412342134...
Checkpoint 1412342134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.71255
Policy Entropy: 2.97044
Value Function Loss: 0.00450

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.59928
Value Function Update Magnitude: 0.51650

Collected Steps per Second: 22,823.98396
Overall Steps per Second: 10,648.03945

Timestep Collection Time: 2.19190
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.69833

Cumulative Model Updates: 169,352
Cumulative Timesteps: 1,412,392,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,678.04490
Policy Entropy: 2.97143
Value Function Loss: 0.00448

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.60242
Value Function Update Magnitude: 0.52766

Collected Steps per Second: 22,362.02838
Overall Steps per Second: 10,567.61071

Timestep Collection Time: 2.23611
Timestep Consumption Time: 2.49571
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.73182

Cumulative Model Updates: 169,358
Cumulative Timesteps: 1,412,442,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1412442166...
Checkpoint 1412442166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,539.41294
Policy Entropy: 2.98614
Value Function Loss: 0.00440

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.59518
Value Function Update Magnitude: 0.53950

Collected Steps per Second: 22,818.00855
Overall Steps per Second: 10,706.71969

Timestep Collection Time: 2.19248
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.67258

Cumulative Model Updates: 169,364
Cumulative Timesteps: 1,412,492,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,239.58108
Policy Entropy: 2.99189
Value Function Loss: 0.00407

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11759
Policy Update Magnitude: 0.59050
Value Function Update Magnitude: 0.52405

Collected Steps per Second: 23,346.10702
Overall Steps per Second: 10,733.79537

Timestep Collection Time: 2.14271
Timestep Consumption Time: 2.51771
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.66042

Cumulative Model Updates: 169,370
Cumulative Timesteps: 1,412,542,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1412542218...
Checkpoint 1412542218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.84501
Policy Entropy: 2.98076
Value Function Loss: 0.00436

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.59588
Value Function Update Magnitude: 0.51616

Collected Steps per Second: 23,156.37873
Overall Steps per Second: 10,745.29176

Timestep Collection Time: 2.16053
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.65599

Cumulative Model Updates: 169,376
Cumulative Timesteps: 1,412,592,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,530.34088
Policy Entropy: 2.98113
Value Function Loss: 0.00422

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.59956
Value Function Update Magnitude: 0.51966

Collected Steps per Second: 22,588.54891
Overall Steps per Second: 10,745.10822

Timestep Collection Time: 2.21475
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.65589

Cumulative Model Updates: 169,382
Cumulative Timesteps: 1,412,642,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1412642276...
Checkpoint 1412642276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,633.60213
Policy Entropy: 2.97808
Value Function Loss: 0.00438

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.60587
Value Function Update Magnitude: 0.50584

Collected Steps per Second: 22,869.95216
Overall Steps per Second: 10,657.28635

Timestep Collection Time: 2.18662
Timestep Consumption Time: 2.50575
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.69238

Cumulative Model Updates: 169,388
Cumulative Timesteps: 1,412,692,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.75312
Policy Entropy: 2.99124
Value Function Loss: 0.00402

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.59916
Value Function Update Magnitude: 0.50306

Collected Steps per Second: 23,272.90225
Overall Steps per Second: 10,894.65334

Timestep Collection Time: 2.14971
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.59216

Cumulative Model Updates: 169,394
Cumulative Timesteps: 1,412,742,314

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1412742314...
Checkpoint 1412742314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,202.15847
Policy Entropy: 2.97989
Value Function Loss: 0.00416

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11632
Policy Update Magnitude: 0.59528
Value Function Update Magnitude: 0.49492

Collected Steps per Second: 23,015.80073
Overall Steps per Second: 10,674.76899

Timestep Collection Time: 2.17286
Timestep Consumption Time: 2.51202
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.68488

Cumulative Model Updates: 169,400
Cumulative Timesteps: 1,412,792,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,748.72638
Policy Entropy: 2.98786
Value Function Loss: 0.00395

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.59087
Value Function Update Magnitude: 0.48519

Collected Steps per Second: 22,936.45410
Overall Steps per Second: 10,830.67392

Timestep Collection Time: 2.18037
Timestep Consumption Time: 2.43707
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61744

Cumulative Model Updates: 169,406
Cumulative Timesteps: 1,412,842,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1412842334...
Checkpoint 1412842334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.11383
Policy Entropy: 2.98604
Value Function Loss: 0.00429

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.58672
Value Function Update Magnitude: 0.48422

Collected Steps per Second: 22,667.48388
Overall Steps per Second: 10,713.36766

Timestep Collection Time: 2.20766
Timestep Consumption Time: 2.46333
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.67099

Cumulative Model Updates: 169,412
Cumulative Timesteps: 1,412,892,376

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.95915
Policy Entropy: 2.98408
Value Function Loss: 0.00451

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.59688
Value Function Update Magnitude: 0.49646

Collected Steps per Second: 22,880.72164
Overall Steps per Second: 10,813.94265

Timestep Collection Time: 2.18647
Timestep Consumption Time: 2.43978
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.62625

Cumulative Model Updates: 169,418
Cumulative Timesteps: 1,412,942,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1412942404...
Checkpoint 1412942404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.25208
Policy Entropy: 2.98215
Value Function Loss: 0.00479

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.61091
Value Function Update Magnitude: 0.53557

Collected Steps per Second: 22,462.31129
Overall Steps per Second: 10,753.30411

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.42427
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.65066

Cumulative Model Updates: 169,424
Cumulative Timesteps: 1,412,992,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293.19011
Policy Entropy: 2.96906
Value Function Loss: 0.00482

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.61684
Value Function Update Magnitude: 0.53918

Collected Steps per Second: 22,749.83244
Overall Steps per Second: 10,791.07899

Timestep Collection Time: 2.19861
Timestep Consumption Time: 2.43652
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.63513

Cumulative Model Updates: 169,430
Cumulative Timesteps: 1,413,042,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1413042432...
Checkpoint 1413042432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,529.63595
Policy Entropy: 2.98522
Value Function Loss: 0.00482

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.61457
Value Function Update Magnitude: 0.53885

Collected Steps per Second: 22,817.27032
Overall Steps per Second: 10,750.09241

Timestep Collection Time: 2.19150
Timestep Consumption Time: 2.46000
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.65149

Cumulative Model Updates: 169,436
Cumulative Timesteps: 1,413,092,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,966.43267
Policy Entropy: 2.99210
Value Function Loss: 0.00487

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.60826
Value Function Update Magnitude: 0.52823

Collected Steps per Second: 22,971.58190
Overall Steps per Second: 10,822.48249

Timestep Collection Time: 2.17730
Timestep Consumption Time: 2.44419
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.62149

Cumulative Model Updates: 169,442
Cumulative Timesteps: 1,413,142,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1413142452...
Checkpoint 1413142452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.85582
Policy Entropy: 3.01290
Value Function Loss: 0.00477

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.60603
Value Function Update Magnitude: 0.51679

Collected Steps per Second: 22,823.20999
Overall Steps per Second: 10,721.03150

Timestep Collection Time: 2.19102
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.66429

Cumulative Model Updates: 169,448
Cumulative Timesteps: 1,413,192,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,338.07333
Policy Entropy: 3.02548
Value Function Loss: 0.00460

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.60052
Value Function Update Magnitude: 0.52830

Collected Steps per Second: 23,289.60070
Overall Steps per Second: 10,912.07550

Timestep Collection Time: 2.14808
Timestep Consumption Time: 2.43656
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.58465

Cumulative Model Updates: 169,454
Cumulative Timesteps: 1,413,242,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1413242486...
Checkpoint 1413242486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,914.43435
Policy Entropy: 3.03361
Value Function Loss: 0.00403

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.57913
Value Function Update Magnitude: 0.53234

Collected Steps per Second: 23,208.73770
Overall Steps per Second: 10,790.00321

Timestep Collection Time: 2.15479
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.63485

Cumulative Model Updates: 169,460
Cumulative Timesteps: 1,413,292,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958.99478
Policy Entropy: 3.02846
Value Function Loss: 0.00421

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.57792
Value Function Update Magnitude: 0.53984

Collected Steps per Second: 23,217.01851
Overall Steps per Second: 10,765.89233

Timestep Collection Time: 2.15471
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.64671

Cumulative Model Updates: 169,466
Cumulative Timesteps: 1,413,342,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1413342522...
Checkpoint 1413342522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,824.94729
Policy Entropy: 3.01836
Value Function Loss: 0.00453

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.59089
Value Function Update Magnitude: 0.58056

Collected Steps per Second: 22,651.71494
Overall Steps per Second: 10,635.60699

Timestep Collection Time: 2.20857
Timestep Consumption Time: 2.49525
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.70382

Cumulative Model Updates: 169,472
Cumulative Timesteps: 1,413,392,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.17049
Policy Entropy: 3.01419
Value Function Loss: 0.00451

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.59399
Value Function Update Magnitude: 0.58755

Collected Steps per Second: 22,731.43071
Overall Steps per Second: 10,815.16547

Timestep Collection Time: 2.20004
Timestep Consumption Time: 2.42402
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.62406

Cumulative Model Updates: 169,478
Cumulative Timesteps: 1,413,442,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1413442560...
Checkpoint 1413442560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,066.42484
Policy Entropy: 3.01786
Value Function Loss: 0.00426

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.58616
Value Function Update Magnitude: 0.54369

Collected Steps per Second: 22,699.07953
Overall Steps per Second: 10,734.37145

Timestep Collection Time: 2.20282
Timestep Consumption Time: 2.45530
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.65812

Cumulative Model Updates: 169,484
Cumulative Timesteps: 1,413,492,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,313.24834
Policy Entropy: 3.01455
Value Function Loss: 0.00452

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.58845
Value Function Update Magnitude: 0.52850

Collected Steps per Second: 22,957.56863
Overall Steps per Second: 10,842.55819

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.43362
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61164

Cumulative Model Updates: 169,490
Cumulative Timesteps: 1,413,542,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1413542564...
Checkpoint 1413542564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.40114
Policy Entropy: 3.02087
Value Function Loss: 0.00485

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.59606
Value Function Update Magnitude: 0.56540

Collected Steps per Second: 23,139.77772
Overall Steps per Second: 10,658.90581

Timestep Collection Time: 2.16121
Timestep Consumption Time: 2.53064
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.69185

Cumulative Model Updates: 169,496
Cumulative Timesteps: 1,413,592,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.94874
Policy Entropy: 3.02192
Value Function Loss: 0.00499

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.59569
Value Function Update Magnitude: 0.55869

Collected Steps per Second: 23,281.09664
Overall Steps per Second: 10,850.42500

Timestep Collection Time: 2.14827
Timestep Consumption Time: 2.46114
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.60940

Cumulative Model Updates: 169,502
Cumulative Timesteps: 1,413,642,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1413642588...
Checkpoint 1413642588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,856.52383
Policy Entropy: 3.01716
Value Function Loss: 0.00471

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.59181
Value Function Update Magnitude: 0.54523

Collected Steps per Second: 23,000.02165
Overall Steps per Second: 10,687.05740

Timestep Collection Time: 2.17530
Timestep Consumption Time: 2.50625
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.68155

Cumulative Model Updates: 169,508
Cumulative Timesteps: 1,413,692,620

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,793.23676
Policy Entropy: 3.01448
Value Function Loss: 0.00423

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.58432
Value Function Update Magnitude: 0.52839

Collected Steps per Second: 22,721.58589
Overall Steps per Second: 10,603.52425

Timestep Collection Time: 2.20125
Timestep Consumption Time: 2.51567
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.71692

Cumulative Model Updates: 169,514
Cumulative Timesteps: 1,413,742,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1413742636...
Checkpoint 1413742636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.07038
Policy Entropy: 3.02405
Value Function Loss: 0.00392

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.57680
Value Function Update Magnitude: 0.50933

Collected Steps per Second: 22,471.81822
Overall Steps per Second: 10,928.60922

Timestep Collection Time: 2.22537
Timestep Consumption Time: 2.35051
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.57588

Cumulative Model Updates: 169,520
Cumulative Timesteps: 1,413,792,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.29427
Policy Entropy: 3.04212
Value Function Loss: 0.00383

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.56395
Value Function Update Magnitude: 0.48702

Collected Steps per Second: 22,430.94139
Overall Steps per Second: 10,873.42265

Timestep Collection Time: 2.23031
Timestep Consumption Time: 2.37063
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.60094

Cumulative Model Updates: 169,526
Cumulative Timesteps: 1,413,842,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1413842672...
Checkpoint 1413842672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,109.14306
Policy Entropy: 3.04090
Value Function Loss: 0.00424

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.57350
Value Function Update Magnitude: 0.50330

Collected Steps per Second: 21,883.96188
Overall Steps per Second: 10,753.13278

Timestep Collection Time: 2.28524
Timestep Consumption Time: 2.36550
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.65074

Cumulative Model Updates: 169,532
Cumulative Timesteps: 1,413,892,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,567.41840
Policy Entropy: 3.03819
Value Function Loss: 0.00414

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.57946
Value Function Update Magnitude: 0.52825

Collected Steps per Second: 21,981.21852
Overall Steps per Second: 10,798.01311

Timestep Collection Time: 2.27512
Timestep Consumption Time: 2.35628
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.63141

Cumulative Model Updates: 169,538
Cumulative Timesteps: 1,413,942,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1413942692...
Checkpoint 1413942692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,451.19403
Policy Entropy: 3.02783
Value Function Loss: 0.00412

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.58216
Value Function Update Magnitude: 0.54378

Collected Steps per Second: 21,794.20292
Overall Steps per Second: 10,622.12807

Timestep Collection Time: 2.29547
Timestep Consumption Time: 2.41432
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.70979

Cumulative Model Updates: 169,544
Cumulative Timesteps: 1,413,992,720

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,451.41311
Policy Entropy: 3.03099
Value Function Loss: 0.00386

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.52887

Collected Steps per Second: 22,904.33845
Overall Steps per Second: 10,676.99256

Timestep Collection Time: 2.18325
Timestep Consumption Time: 2.50027
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.68353

Cumulative Model Updates: 169,550
Cumulative Timesteps: 1,414,042,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1414042726...
Checkpoint 1414042726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,399.60512
Policy Entropy: 3.02906
Value Function Loss: 0.00407

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.53133

Collected Steps per Second: 23,314.38810
Overall Steps per Second: 10,917.89875

Timestep Collection Time: 2.14580
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.58220

Cumulative Model Updates: 169,556
Cumulative Timesteps: 1,414,092,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.70054
Policy Entropy: 3.01995
Value Function Loss: 0.00415

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.54896

Collected Steps per Second: 23,158.31259
Overall Steps per Second: 10,959.85521

Timestep Collection Time: 2.15940
Timestep Consumption Time: 2.40344
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.56283

Cumulative Model Updates: 169,562
Cumulative Timesteps: 1,414,142,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1414142762...
Checkpoint 1414142762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.27421
Policy Entropy: 3.01588
Value Function Loss: 0.00422

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.58104
Value Function Update Magnitude: 0.55722

Collected Steps per Second: 23,094.93676
Overall Steps per Second: 10,742.42968

Timestep Collection Time: 2.16506
Timestep Consumption Time: 2.48956
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.65463

Cumulative Model Updates: 169,568
Cumulative Timesteps: 1,414,192,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.66412
Policy Entropy: 3.01997
Value Function Loss: 0.00429

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.57761
Value Function Update Magnitude: 0.54266

Collected Steps per Second: 23,284.85999
Overall Steps per Second: 10,775.72949

Timestep Collection Time: 2.14783
Timestep Consumption Time: 2.49334
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.64117

Cumulative Model Updates: 169,574
Cumulative Timesteps: 1,414,242,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1414242776...
Checkpoint 1414242776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,648.69811
Policy Entropy: 3.02822
Value Function Loss: 0.00422

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11679
Policy Update Magnitude: 0.56663
Value Function Update Magnitude: 0.52021

Collected Steps per Second: 23,274.01603
Overall Steps per Second: 10,760.43067

Timestep Collection Time: 2.14849
Timestep Consumption Time: 2.49854
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.64703

Cumulative Model Updates: 169,580
Cumulative Timesteps: 1,414,292,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,338.66305
Policy Entropy: 3.02613
Value Function Loss: 0.00415

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.56155
Value Function Update Magnitude: 0.51425

Collected Steps per Second: 23,194.27328
Overall Steps per Second: 10,819.05658

Timestep Collection Time: 2.15622
Timestep Consumption Time: 2.46636
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.62258

Cumulative Model Updates: 169,586
Cumulative Timesteps: 1,414,342,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1414342792...
Checkpoint 1414342792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,698.26831
Policy Entropy: 3.01345
Value Function Loss: 0.00446

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.57433
Value Function Update Magnitude: 0.51504

Collected Steps per Second: 22,461.71626
Overall Steps per Second: 10,621.96945

Timestep Collection Time: 2.22672
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.70873

Cumulative Model Updates: 169,592
Cumulative Timesteps: 1,414,392,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,242.39259
Policy Entropy: 3.00725
Value Function Loss: 0.00465

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11165
Policy Update Magnitude: 0.58920
Value Function Update Magnitude: 0.51938

Collected Steps per Second: 23,038.67436
Overall Steps per Second: 10,892.17850

Timestep Collection Time: 2.17061
Timestep Consumption Time: 2.42057
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.59118

Cumulative Model Updates: 169,598
Cumulative Timesteps: 1,414,442,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1414442816...
Checkpoint 1414442816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.99329
Policy Entropy: 3.00664
Value Function Loss: 0.00449

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.58217
Value Function Update Magnitude: 0.50256

Collected Steps per Second: 23,123.42536
Overall Steps per Second: 10,636.06229

Timestep Collection Time: 2.16343
Timestep Consumption Time: 2.54000
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.70343

Cumulative Model Updates: 169,604
Cumulative Timesteps: 1,414,492,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.21481
Policy Entropy: 3.01460
Value Function Loss: 0.00405

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.57575
Value Function Update Magnitude: 0.49075

Collected Steps per Second: 23,159.24506
Overall Steps per Second: 10,888.63895

Timestep Collection Time: 2.16026
Timestep Consumption Time: 2.43444
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.59470

Cumulative Model Updates: 169,610
Cumulative Timesteps: 1,414,542,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1414542872...
Checkpoint 1414542872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,232.34954
Policy Entropy: 3.01776
Value Function Loss: 0.00382

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.56241
Value Function Update Magnitude: 0.47533

Collected Steps per Second: 22,875.41193
Overall Steps per Second: 10,680.70271

Timestep Collection Time: 2.18637
Timestep Consumption Time: 2.49629
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.68265

Cumulative Model Updates: 169,616
Cumulative Timesteps: 1,414,592,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,218.20687
Policy Entropy: 3.02600
Value Function Loss: 0.00401

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.56332
Value Function Update Magnitude: 0.47034

Collected Steps per Second: 23,231.46943
Overall Steps per Second: 10,918.27420

Timestep Collection Time: 2.15234
Timestep Consumption Time: 2.42732
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.57966

Cumulative Model Updates: 169,622
Cumulative Timesteps: 1,414,642,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1414642888...
Checkpoint 1414642888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,854.57816
Policy Entropy: 3.01985
Value Function Loss: 0.00419

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.56393
Value Function Update Magnitude: 0.48159

Collected Steps per Second: 23,067.15829
Overall Steps per Second: 10,653.85455

Timestep Collection Time: 2.16862
Timestep Consumption Time: 2.52677
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.69539

Cumulative Model Updates: 169,628
Cumulative Timesteps: 1,414,692,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,871.24260
Policy Entropy: 3.01716
Value Function Loss: 0.00416

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.56079
Value Function Update Magnitude: 0.48844

Collected Steps per Second: 23,039.49835
Overall Steps per Second: 10,854.45098

Timestep Collection Time: 2.17088
Timestep Consumption Time: 2.43700
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60788

Cumulative Model Updates: 169,634
Cumulative Timesteps: 1,414,742,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1414742928...
Checkpoint 1414742928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,251.44110
Policy Entropy: 3.00940
Value Function Loss: 0.00438

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.57017
Value Function Update Magnitude: 0.50222

Collected Steps per Second: 22,651.61443
Overall Steps per Second: 10,706.08272

Timestep Collection Time: 2.20858
Timestep Consumption Time: 2.46427
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.67286

Cumulative Model Updates: 169,640
Cumulative Timesteps: 1,414,792,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,729.83496
Policy Entropy: 3.00281
Value Function Loss: 0.00475

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.59049
Value Function Update Magnitude: 0.54066

Collected Steps per Second: 23,091.11922
Overall Steps per Second: 10,827.76237

Timestep Collection Time: 2.16646
Timestep Consumption Time: 2.45370
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.62016

Cumulative Model Updates: 169,646
Cumulative Timesteps: 1,414,842,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1414842982...
Checkpoint 1414842982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.00997
Policy Entropy: 3.00796
Value Function Loss: 0.00461

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.60099
Value Function Update Magnitude: 0.57138

Collected Steps per Second: 22,585.70401
Overall Steps per Second: 10,755.79312

Timestep Collection Time: 2.21388
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.64884

Cumulative Model Updates: 169,652
Cumulative Timesteps: 1,414,892,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,866.08684
Policy Entropy: 3.01220
Value Function Loss: 0.00453

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.60286
Value Function Update Magnitude: 0.55920

Collected Steps per Second: 22,767.18502
Overall Steps per Second: 10,802.61699

Timestep Collection Time: 2.19641
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.62906

Cumulative Model Updates: 169,658
Cumulative Timesteps: 1,414,942,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1414942990...
Checkpoint 1414942990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,484.95294
Policy Entropy: 3.02738
Value Function Loss: 0.00400

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.58870
Value Function Update Magnitude: 0.55752

Collected Steps per Second: 22,523.18289
Overall Steps per Second: 10,736.74400

Timestep Collection Time: 2.22029
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.65765

Cumulative Model Updates: 169,664
Cumulative Timesteps: 1,414,992,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,353.49720
Policy Entropy: 3.01701
Value Function Loss: 0.00412

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.58761
Value Function Update Magnitude: 0.55119

Collected Steps per Second: 23,571.25649
Overall Steps per Second: 10,898.75720

Timestep Collection Time: 2.12191
Timestep Consumption Time: 2.46724
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.58915

Cumulative Model Updates: 169,670
Cumulative Timesteps: 1,415,043,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1415043014...
Checkpoint 1415043014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.98904
Policy Entropy: 3.01740
Value Function Loss: 0.00431

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.59288
Value Function Update Magnitude: 0.55180

Collected Steps per Second: 22,941.58527
Overall Steps per Second: 10,678.66523

Timestep Collection Time: 2.18041
Timestep Consumption Time: 2.50389
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.68429

Cumulative Model Updates: 169,676
Cumulative Timesteps: 1,415,093,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,610.07962
Policy Entropy: 3.00163
Value Function Loss: 0.00442

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.59136
Value Function Update Magnitude: 0.54793

Collected Steps per Second: 23,387.10379
Overall Steps per Second: 10,890.44947

Timestep Collection Time: 2.13896
Timestep Consumption Time: 2.45443
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.59338

Cumulative Model Updates: 169,682
Cumulative Timesteps: 1,415,143,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1415143060...
Checkpoint 1415143060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,532.83909
Policy Entropy: 3.00575
Value Function Loss: 0.00456

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.60079
Value Function Update Magnitude: 0.53225

Collected Steps per Second: 22,915.74606
Overall Steps per Second: 10,711.89340

Timestep Collection Time: 2.18313
Timestep Consumption Time: 2.48720
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.67032

Cumulative Model Updates: 169,688
Cumulative Timesteps: 1,415,193,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,927.62344
Policy Entropy: 3.03051
Value Function Loss: 0.00405

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.58683
Value Function Update Magnitude: 0.51794

Collected Steps per Second: 23,168.82525
Overall Steps per Second: 10,815.81111

Timestep Collection Time: 2.15807
Timestep Consumption Time: 2.46479
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.62286

Cumulative Model Updates: 169,694
Cumulative Timesteps: 1,415,243,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1415243088...
Checkpoint 1415243088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,944.80007
Policy Entropy: 3.02962
Value Function Loss: 0.00421

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.49307

Collected Steps per Second: 22,874.78797
Overall Steps per Second: 10,664.48727

Timestep Collection Time: 2.18686
Timestep Consumption Time: 2.50385
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.69071

Cumulative Model Updates: 169,700
Cumulative Timesteps: 1,415,293,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.52246
Policy Entropy: 3.03916
Value Function Loss: 0.00409

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.58339
Value Function Update Magnitude: 0.49450

Collected Steps per Second: 22,861.87771
Overall Steps per Second: 10,804.67859

Timestep Collection Time: 2.18827
Timestep Consumption Time: 2.44194
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.63022

Cumulative Model Updates: 169,706
Cumulative Timesteps: 1,415,343,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1415343140...
Checkpoint 1415343140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.36047
Policy Entropy: 3.01604
Value Function Loss: 0.00449

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10883
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.49740

Collected Steps per Second: 21,613.23917
Overall Steps per Second: 10,742.22416

Timestep Collection Time: 2.31423
Timestep Consumption Time: 2.34198
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.65621

Cumulative Model Updates: 169,712
Cumulative Timesteps: 1,415,393,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,113.98624
Policy Entropy: 3.01671
Value Function Loss: 0.00417

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.58281
Value Function Update Magnitude: 0.49081

Collected Steps per Second: 22,131.09177
Overall Steps per Second: 10,821.52143

Timestep Collection Time: 2.26035
Timestep Consumption Time: 2.36229
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62264

Cumulative Model Updates: 169,718
Cumulative Timesteps: 1,415,443,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1415443182...
Checkpoint 1415443182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,704.06133
Policy Entropy: 3.00848
Value Function Loss: 0.00452

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.58182
Value Function Update Magnitude: 0.49527

Collected Steps per Second: 21,962.39419
Overall Steps per Second: 10,686.77597

Timestep Collection Time: 2.27771
Timestep Consumption Time: 2.40321
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.68093

Cumulative Model Updates: 169,724
Cumulative Timesteps: 1,415,493,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,772.10593
Policy Entropy: 3.01434
Value Function Loss: 0.00452

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.59183
Value Function Update Magnitude: 0.51196

Collected Steps per Second: 22,493.67646
Overall Steps per Second: 10,835.52779

Timestep Collection Time: 2.22320
Timestep Consumption Time: 2.39199
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61519

Cumulative Model Updates: 169,730
Cumulative Timesteps: 1,415,543,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1415543214...
Checkpoint 1415543214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,194.26530
Policy Entropy: 3.00418
Value Function Loss: 0.00473

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.60133
Value Function Update Magnitude: 0.54436

Collected Steps per Second: 22,021.36527
Overall Steps per Second: 10,670.21925

Timestep Collection Time: 2.27070
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.68631

Cumulative Model Updates: 169,736
Cumulative Timesteps: 1,415,593,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,097.93318
Policy Entropy: 3.02008
Value Function Loss: 0.00423

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.59011
Value Function Update Magnitude: 0.54457

Collected Steps per Second: 22,680.46164
Overall Steps per Second: 10,930.19361

Timestep Collection Time: 2.20533
Timestep Consumption Time: 2.37080
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.57613

Cumulative Model Updates: 169,742
Cumulative Timesteps: 1,415,643,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1415643236...
Checkpoint 1415643236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.25569
Policy Entropy: 3.02231
Value Function Loss: 0.00443

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.59768
Value Function Update Magnitude: 0.54878

Collected Steps per Second: 21,182.10512
Overall Steps per Second: 10,319.03214

Timestep Collection Time: 2.36124
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.84697

Cumulative Model Updates: 169,748
Cumulative Timesteps: 1,415,693,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.43572
Policy Entropy: 3.02224
Value Function Loss: 0.00409

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.59841
Value Function Update Magnitude: 0.54263

Collected Steps per Second: 22,935.88082
Overall Steps per Second: 10,851.22264

Timestep Collection Time: 2.17999
Timestep Consumption Time: 2.42779
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.60778

Cumulative Model Updates: 169,754
Cumulative Timesteps: 1,415,743,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1415743252...
Checkpoint 1415743252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,364.04200
Policy Entropy: 3.01087
Value Function Loss: 0.00407

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.52443

Collected Steps per Second: 22,501.84606
Overall Steps per Second: 10,649.19029

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.47375
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.69632

Cumulative Model Updates: 169,760
Cumulative Timesteps: 1,415,793,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,241.75764
Policy Entropy: 3.00875
Value Function Loss: 0.00416

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.49316

Collected Steps per Second: 23,441.30442
Overall Steps per Second: 10,858.02073

Timestep Collection Time: 2.13341
Timestep Consumption Time: 2.47240
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.60581

Cumulative Model Updates: 169,766
Cumulative Timesteps: 1,415,843,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1415843274...
Checkpoint 1415843274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.97188
Policy Entropy: 3.00650
Value Function Loss: 0.00460

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.59268
Value Function Update Magnitude: 0.49273

Collected Steps per Second: 23,020.17224
Overall Steps per Second: 10,652.51260

Timestep Collection Time: 2.17322
Timestep Consumption Time: 2.52313
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.69636

Cumulative Model Updates: 169,772
Cumulative Timesteps: 1,415,893,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,609.84992
Policy Entropy: 3.00559
Value Function Loss: 0.00456

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.59323
Value Function Update Magnitude: 0.50381

Collected Steps per Second: 23,254.16129
Overall Steps per Second: 10,888.37323

Timestep Collection Time: 2.15015
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.59205

Cumulative Model Updates: 169,778
Cumulative Timesteps: 1,415,943,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1415943302...
Checkpoint 1415943302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.04249
Policy Entropy: 3.00679
Value Function Loss: 0.00460

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.59125
Value Function Update Magnitude: 0.51555

Collected Steps per Second: 22,484.91695
Overall Steps per Second: 10,651.80878

Timestep Collection Time: 2.22407
Timestep Consumption Time: 2.47072
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.69479

Cumulative Model Updates: 169,784
Cumulative Timesteps: 1,415,993,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,169.91824
Policy Entropy: 3.01308
Value Function Loss: 0.00449

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.59827
Value Function Update Magnitude: 0.52237

Collected Steps per Second: 23,204.65834
Overall Steps per Second: 10,869.95432

Timestep Collection Time: 2.15526
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.60094

Cumulative Model Updates: 169,790
Cumulative Timesteps: 1,416,043,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1416043322...
Checkpoint 1416043322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.63985
Policy Entropy: 3.00243
Value Function Loss: 0.00443

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.60710
Value Function Update Magnitude: 0.52865

Collected Steps per Second: 23,109.65781
Overall Steps per Second: 10,668.05068

Timestep Collection Time: 2.16420
Timestep Consumption Time: 2.52400
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.68820

Cumulative Model Updates: 169,796
Cumulative Timesteps: 1,416,093,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,590.24090
Policy Entropy: 3.00028
Value Function Loss: 0.00459

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.61151
Value Function Update Magnitude: 0.53266

Collected Steps per Second: 23,095.88269
Overall Steps per Second: 10,871.13778

Timestep Collection Time: 2.16549
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60062

Cumulative Model Updates: 169,802
Cumulative Timesteps: 1,416,143,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1416143350...
Checkpoint 1416143350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.00345
Policy Entropy: 2.98945
Value Function Loss: 0.00485

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14877
Policy Update Magnitude: 0.61193
Value Function Update Magnitude: 0.54279

Collected Steps per Second: 22,205.34149
Overall Steps per Second: 10,782.30295

Timestep Collection Time: 2.25306
Timestep Consumption Time: 2.38695
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.64001

Cumulative Model Updates: 169,808
Cumulative Timesteps: 1,416,193,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,975.81055
Policy Entropy: 2.99451
Value Function Loss: 0.00476

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.61262
Value Function Update Magnitude: 0.55953

Collected Steps per Second: 22,599.92689
Overall Steps per Second: 10,757.15067

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.64974

Cumulative Model Updates: 169,814
Cumulative Timesteps: 1,416,243,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1416243398...
Checkpoint 1416243398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,045.14543
Policy Entropy: 3.00991
Value Function Loss: 0.00496

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.62933
Value Function Update Magnitude: 0.59839

Collected Steps per Second: 22,357.57653
Overall Steps per Second: 10,676.23698

Timestep Collection Time: 2.23647
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.68349

Cumulative Model Updates: 169,820
Cumulative Timesteps: 1,416,293,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.65600
Policy Entropy: 3.02287
Value Function Loss: 0.00486

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.62663
Value Function Update Magnitude: 0.61884

Collected Steps per Second: 22,910.57188
Overall Steps per Second: 10,700.00297

Timestep Collection Time: 2.18240
Timestep Consumption Time: 2.49050
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.67290

Cumulative Model Updates: 169,826
Cumulative Timesteps: 1,416,343,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1416343400...
Checkpoint 1416343400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,667.70575
Policy Entropy: 3.03142
Value Function Loss: 0.00474

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.60440
Value Function Update Magnitude: 0.60661

Collected Steps per Second: 22,736.90181
Overall Steps per Second: 10,608.22356

Timestep Collection Time: 2.19907
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.71332

Cumulative Model Updates: 169,832
Cumulative Timesteps: 1,416,393,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,271.62263
Policy Entropy: 3.02243
Value Function Loss: 0.00452

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.59942
Value Function Update Magnitude: 0.57444

Collected Steps per Second: 23,304.29179
Overall Steps per Second: 10,684.70382

Timestep Collection Time: 2.14656
Timestep Consumption Time: 2.53528
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.68183

Cumulative Model Updates: 169,838
Cumulative Timesteps: 1,416,443,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1416443424...
Checkpoint 1416443424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,232.21919
Policy Entropy: 3.00627
Value Function Loss: 0.00474

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.61256
Value Function Update Magnitude: 0.58106

Collected Steps per Second: 22,859.67435
Overall Steps per Second: 10,728.37846

Timestep Collection Time: 2.18866
Timestep Consumption Time: 2.47486
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.66352

Cumulative Model Updates: 169,844
Cumulative Timesteps: 1,416,493,456

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.86616
Policy Entropy: 3.00306
Value Function Loss: 0.00491

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.62333
Value Function Update Magnitude: 0.58590

Collected Steps per Second: 23,351.04218
Overall Steps per Second: 10,870.14784

Timestep Collection Time: 2.14166
Timestep Consumption Time: 2.45901
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.60067

Cumulative Model Updates: 169,850
Cumulative Timesteps: 1,416,543,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1416543466...
Checkpoint 1416543466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,614.81253
Policy Entropy: 3.00143
Value Function Loss: 0.00498

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11843
Policy Update Magnitude: 0.62678
Value Function Update Magnitude: 0.60212

Collected Steps per Second: 22,678.79866
Overall Steps per Second: 10,687.71401

Timestep Collection Time: 2.20558
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.68014

Cumulative Model Updates: 169,856
Cumulative Timesteps: 1,416,593,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.58338
Policy Entropy: 3.00315
Value Function Loss: 0.00470

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.62878
Value Function Update Magnitude: 0.59829

Collected Steps per Second: 23,209.66249
Overall Steps per Second: 10,840.38945

Timestep Collection Time: 2.15453
Timestep Consumption Time: 2.45840
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.61293

Cumulative Model Updates: 169,862
Cumulative Timesteps: 1,416,643,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1416643492...
Checkpoint 1416643492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.67712
Policy Entropy: 2.99827
Value Function Loss: 0.00456

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.61920
Value Function Update Magnitude: 0.56865

Collected Steps per Second: 22,683.01173
Overall Steps per Second: 10,621.27766

Timestep Collection Time: 2.20562
Timestep Consumption Time: 2.50474
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.71036

Cumulative Model Updates: 169,868
Cumulative Timesteps: 1,416,693,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.70914
Policy Entropy: 3.02089
Value Function Loss: 0.00433

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.61658
Value Function Update Magnitude: 0.53966

Collected Steps per Second: 22,813.25315
Overall Steps per Second: 10,712.40102

Timestep Collection Time: 2.19188
Timestep Consumption Time: 2.47598
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.66786

Cumulative Model Updates: 169,874
Cumulative Timesteps: 1,416,743,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1416743526...
Checkpoint 1416743526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,786.37509
Policy Entropy: 3.02660
Value Function Loss: 0.00448

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.60745
Value Function Update Magnitude: 0.53515

Collected Steps per Second: 22,301.28933
Overall Steps per Second: 10,584.10304

Timestep Collection Time: 2.24220
Timestep Consumption Time: 2.48224
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.72444

Cumulative Model Updates: 169,880
Cumulative Timesteps: 1,416,793,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,885.58974
Policy Entropy: 3.02462
Value Function Loss: 0.00492

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.61786
Value Function Update Magnitude: 0.56276

Collected Steps per Second: 22,844.27121
Overall Steps per Second: 10,658.70803

Timestep Collection Time: 2.18882
Timestep Consumption Time: 2.50237
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.69119

Cumulative Model Updates: 169,886
Cumulative Timesteps: 1,416,843,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1416843532...
Checkpoint 1416843532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,082.79919
Policy Entropy: 3.00885
Value Function Loss: 0.00507

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.61976
Value Function Update Magnitude: 0.57362

Collected Steps per Second: 22,724.32273
Overall Steps per Second: 10,671.43323

Timestep Collection Time: 2.20108
Timestep Consumption Time: 2.48602
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.68709

Cumulative Model Updates: 169,892
Cumulative Timesteps: 1,416,893,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,228.16000
Policy Entropy: 3.00069
Value Function Loss: 0.00510

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.61047
Value Function Update Magnitude: 0.55634

Collected Steps per Second: 23,106.38808
Overall Steps per Second: 10,854.28188

Timestep Collection Time: 2.16520
Timestep Consumption Time: 2.44404
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60924

Cumulative Model Updates: 169,898
Cumulative Timesteps: 1,416,943,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1416943580...
Checkpoint 1416943580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,351.94219
Policy Entropy: 3.01163
Value Function Loss: 0.00456

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.60186
Value Function Update Magnitude: 0.53910

Collected Steps per Second: 22,793.61083
Overall Steps per Second: 10,738.45698

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.46355
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.65802

Cumulative Model Updates: 169,904
Cumulative Timesteps: 1,416,993,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.26185
Policy Entropy: 3.03120
Value Function Loss: 0.00435

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.59562
Value Function Update Magnitude: 0.54134

Collected Steps per Second: 23,153.27045
Overall Steps per Second: 10,864.39521

Timestep Collection Time: 2.16013
Timestep Consumption Time: 2.44335
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.60348

Cumulative Model Updates: 169,910
Cumulative Timesteps: 1,417,043,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1417043614...
Checkpoint 1417043614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,698.57576
Policy Entropy: 3.02248
Value Function Loss: 0.00440

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.60082
Value Function Update Magnitude: 0.52436

Collected Steps per Second: 22,842.07484
Overall Steps per Second: 10,653.88950

Timestep Collection Time: 2.18999
Timestep Consumption Time: 2.50538
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.69537

Cumulative Model Updates: 169,916
Cumulative Timesteps: 1,417,093,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,165.72451
Policy Entropy: 3.01705
Value Function Loss: 0.00426

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.59416
Value Function Update Magnitude: 0.52367

Collected Steps per Second: 23,155.13049
Overall Steps per Second: 10,874.35416

Timestep Collection Time: 2.16021
Timestep Consumption Time: 2.43960
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.59981

Cumulative Model Updates: 169,922
Cumulative Timesteps: 1,417,143,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1417143658...
Checkpoint 1417143658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,064.37231
Policy Entropy: 3.01127
Value Function Loss: 0.00446

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.59162
Value Function Update Magnitude: 0.51588

Collected Steps per Second: 22,476.23666
Overall Steps per Second: 10,755.63892

Timestep Collection Time: 2.22457
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.64872

Cumulative Model Updates: 169,928
Cumulative Timesteps: 1,417,193,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,762.30491
Policy Entropy: 3.03294
Value Function Loss: 0.00421

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.58356
Value Function Update Magnitude: 0.51713

Collected Steps per Second: 22,867.69093
Overall Steps per Second: 10,806.87027

Timestep Collection Time: 2.18710
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62798

Cumulative Model Updates: 169,934
Cumulative Timesteps: 1,417,243,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1417243672...
Checkpoint 1417243672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,670.89369
Policy Entropy: 3.02292
Value Function Loss: 0.00448

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.58560
Value Function Update Magnitude: 0.53883

Collected Steps per Second: 22,264.69050
Overall Steps per Second: 10,697.91205

Timestep Collection Time: 2.24670
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.67587

Cumulative Model Updates: 169,940
Cumulative Timesteps: 1,417,293,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.43397
Policy Entropy: 3.00924
Value Function Loss: 0.00452

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.58802
Value Function Update Magnitude: 0.53910

Collected Steps per Second: 23,098.71357
Overall Steps per Second: 10,858.59827

Timestep Collection Time: 2.16583
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.60722

Cumulative Model Updates: 169,946
Cumulative Timesteps: 1,417,343,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1417343722...
Checkpoint 1417343722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.65736
Policy Entropy: 2.98699
Value Function Loss: 0.00456

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.58729
Value Function Update Magnitude: 0.55537

Collected Steps per Second: 22,881.92090
Overall Steps per Second: 10,667.43933

Timestep Collection Time: 2.18627
Timestep Consumption Time: 2.50333
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.68960

Cumulative Model Updates: 169,952
Cumulative Timesteps: 1,417,393,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,724.38806
Policy Entropy: 2.97301
Value Function Loss: 0.00470

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.59987
Value Function Update Magnitude: 0.59024

Collected Steps per Second: 23,319.63056
Overall Steps per Second: 10,898.34229

Timestep Collection Time: 2.14412
Timestep Consumption Time: 2.44374
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.58785

Cumulative Model Updates: 169,958
Cumulative Timesteps: 1,417,443,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1417443748...
Checkpoint 1417443748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.25906
Policy Entropy: 2.99183
Value Function Loss: 0.00435

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.61045
Value Function Update Magnitude: 0.60904

Collected Steps per Second: 23,082.86673
Overall Steps per Second: 10,700.88072

Timestep Collection Time: 2.16637
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.67307

Cumulative Model Updates: 169,964
Cumulative Timesteps: 1,417,493,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.03369
Policy Entropy: 3.00402
Value Function Loss: 0.00487

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.61030
Value Function Update Magnitude: 0.59384

Collected Steps per Second: 23,392.22190
Overall Steps per Second: 10,846.62914

Timestep Collection Time: 2.13883
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.61268

Cumulative Model Updates: 169,970
Cumulative Timesteps: 1,417,543,786

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1417543786...
Checkpoint 1417543786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,345.51272
Policy Entropy: 3.03032
Value Function Loss: 0.00498

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.61367
Value Function Update Magnitude: 0.59812

Collected Steps per Second: 22,593.15713
Overall Steps per Second: 10,640.44073

Timestep Collection Time: 2.21324
Timestep Consumption Time: 2.48619
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.69943

Cumulative Model Updates: 169,976
Cumulative Timesteps: 1,417,593,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,514.18854
Policy Entropy: 3.01737
Value Function Loss: 0.00496

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.61188
Value Function Update Magnitude: 0.61106

Collected Steps per Second: 23,344.70298
Overall Steps per Second: 10,918.50814

Timestep Collection Time: 2.14181
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.57938

Cumulative Model Updates: 169,982
Cumulative Timesteps: 1,417,643,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1417643790...
Checkpoint 1417643790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.96569
Policy Entropy: 3.01414
Value Function Loss: 0.00504

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.62815
Value Function Update Magnitude: 0.60752

Collected Steps per Second: 22,534.21611
Overall Steps per Second: 10,605.95466

Timestep Collection Time: 2.21920
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.71509

Cumulative Model Updates: 169,988
Cumulative Timesteps: 1,417,693,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.79621
Policy Entropy: 3.00173
Value Function Loss: 0.00490

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.62442
Value Function Update Magnitude: 0.59253

Collected Steps per Second: 22,657.02883
Overall Steps per Second: 10,618.54771

Timestep Collection Time: 2.20744
Timestep Consumption Time: 2.50262
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.71006

Cumulative Model Updates: 169,994
Cumulative Timesteps: 1,417,743,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1417743812...
Checkpoint 1417743812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.89411
Policy Entropy: 2.99809
Value Function Loss: 0.00477

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.60667
Value Function Update Magnitude: 0.54387

Collected Steps per Second: 22,601.08893
Overall Steps per Second: 10,631.28019

Timestep Collection Time: 2.21317
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.70498

Cumulative Model Updates: 170,000
Cumulative Timesteps: 1,417,793,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,857.84261
Policy Entropy: 3.00156
Value Function Loss: 0.00520

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.60193
Value Function Update Magnitude: 0.51470

Collected Steps per Second: 22,913.96037
Overall Steps per Second: 10,779.17139

Timestep Collection Time: 2.18295
Timestep Consumption Time: 2.45748
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.64043

Cumulative Model Updates: 170,006
Cumulative Timesteps: 1,417,843,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1417843852...
Checkpoint 1417843852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.80603
Policy Entropy: 3.01381
Value Function Loss: 0.00506

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.61068
Value Function Update Magnitude: 0.54191

Collected Steps per Second: 22,514.81435
Overall Steps per Second: 10,596.50701

Timestep Collection Time: 2.22094
Timestep Consumption Time: 2.49798
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.71891

Cumulative Model Updates: 170,012
Cumulative Timesteps: 1,417,893,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,014.83147
Policy Entropy: 3.00873
Value Function Loss: 0.00494

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.61537
Value Function Update Magnitude: 0.57996

Collected Steps per Second: 23,469.85604
Overall Steps per Second: 10,908.43257

Timestep Collection Time: 2.13107
Timestep Consumption Time: 2.45400
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.58508

Cumulative Model Updates: 170,018
Cumulative Timesteps: 1,417,943,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1417943872...
Checkpoint 1417943872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,231.38092
Policy Entropy: 3.02050
Value Function Loss: 0.00426

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.59227
Value Function Update Magnitude: 0.57305

Collected Steps per Second: 22,953.04909
Overall Steps per Second: 10,662.67379

Timestep Collection Time: 2.17906
Timestep Consumption Time: 2.51170
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.69076

Cumulative Model Updates: 170,024
Cumulative Timesteps: 1,417,993,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,012.36025
Policy Entropy: 3.00794
Value Function Loss: 0.00443

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.58786
Value Function Update Magnitude: 0.56338

Collected Steps per Second: 23,378.70919
Overall Steps per Second: 10,927.23523

Timestep Collection Time: 2.13913
Timestep Consumption Time: 2.43751
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.57664

Cumulative Model Updates: 170,030
Cumulative Timesteps: 1,418,043,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1418043898...
Checkpoint 1418043898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,755.11892
Policy Entropy: 3.01637
Value Function Loss: 0.00450

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.59949
Value Function Update Magnitude: 0.57809

Collected Steps per Second: 22,911.55735
Overall Steps per Second: 10,766.21231

Timestep Collection Time: 2.18265
Timestep Consumption Time: 2.46225
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.64490

Cumulative Model Updates: 170,036
Cumulative Timesteps: 1,418,093,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,090.42108
Policy Entropy: 3.00662
Value Function Loss: 0.00459

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.59810
Value Function Update Magnitude: 0.57306

Collected Steps per Second: 23,602.79623
Overall Steps per Second: 10,915.72584

Timestep Collection Time: 2.11941
Timestep Consumption Time: 2.46334
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.58275

Cumulative Model Updates: 170,042
Cumulative Timesteps: 1,418,143,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1418143930...
Checkpoint 1418143930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.64652
Policy Entropy: 3.00483
Value Function Loss: 0.00461

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.58886
Value Function Update Magnitude: 0.54222

Collected Steps per Second: 22,937.06650
Overall Steps per Second: 10,936.88755

Timestep Collection Time: 2.18005
Timestep Consumption Time: 2.39200
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.57205

Cumulative Model Updates: 170,048
Cumulative Timesteps: 1,418,193,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,893.01891
Policy Entropy: 3.00254
Value Function Loss: 0.00457

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.58095
Value Function Update Magnitude: 0.53020

Collected Steps per Second: 22,951.05915
Overall Steps per Second: 10,680.83102

Timestep Collection Time: 2.17959
Timestep Consumption Time: 2.50394
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.68353

Cumulative Model Updates: 170,054
Cumulative Timesteps: 1,418,243,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1418243958...
Checkpoint 1418243958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,181.70433
Policy Entropy: 2.99683
Value Function Loss: 0.00445

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.58695
Value Function Update Magnitude: 0.53020

Collected Steps per Second: 22,710.19976
Overall Steps per Second: 10,815.35248

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.62528

Cumulative Model Updates: 170,060
Cumulative Timesteps: 1,418,293,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,447.33885
Policy Entropy: 3.00447
Value Function Loss: 0.00433

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.59158
Value Function Update Magnitude: 0.54615

Collected Steps per Second: 22,851.79763
Overall Steps per Second: 10,665.36874

Timestep Collection Time: 2.18897
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.69013

Cumulative Model Updates: 170,066
Cumulative Timesteps: 1,418,344,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1418344004...
Checkpoint 1418344004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,781.40149
Policy Entropy: 3.00111
Value Function Loss: 0.00456

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.59597
Value Function Update Magnitude: 0.56387

Collected Steps per Second: 22,114.67489
Overall Steps per Second: 10,527.66811

Timestep Collection Time: 2.26185
Timestep Consumption Time: 2.48944
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.75129

Cumulative Model Updates: 170,072
Cumulative Timesteps: 1,418,394,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.87292
Policy Entropy: 3.00881
Value Function Loss: 0.00485

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.61479
Value Function Update Magnitude: 0.56124

Collected Steps per Second: 23,417.90888
Overall Steps per Second: 10,852.04170

Timestep Collection Time: 2.13597
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.60927

Cumulative Model Updates: 170,078
Cumulative Timesteps: 1,418,444,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1418444044...
Checkpoint 1418444044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.90784
Policy Entropy: 3.01727
Value Function Loss: 0.00476

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.61081
Value Function Update Magnitude: 0.57216

Collected Steps per Second: 23,125.64493
Overall Steps per Second: 10,709.79000

Timestep Collection Time: 2.16245
Timestep Consumption Time: 2.50692
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.66937

Cumulative Model Updates: 170,084
Cumulative Timesteps: 1,418,494,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.42537
Policy Entropy: 3.03186
Value Function Loss: 0.00443

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.59614
Value Function Update Magnitude: 0.55979

Collected Steps per Second: 23,042.91488
Overall Steps per Second: 10,845.27500

Timestep Collection Time: 2.17099
Timestep Consumption Time: 2.44171
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61270

Cumulative Model Updates: 170,090
Cumulative Timesteps: 1,418,544,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1418544078...
Checkpoint 1418544078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,598.75858
Policy Entropy: 3.02434
Value Function Loss: 0.00456

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.59057
Value Function Update Magnitude: 0.53162

Collected Steps per Second: 22,927.81219
Overall Steps per Second: 10,675.73253

Timestep Collection Time: 2.18084
Timestep Consumption Time: 2.50286
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.68371

Cumulative Model Updates: 170,096
Cumulative Timesteps: 1,418,594,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.17781
Policy Entropy: 3.00487
Value Function Loss: 0.00483

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.59574
Value Function Update Magnitude: 0.53216

Collected Steps per Second: 23,152.76181
Overall Steps per Second: 10,890.37833

Timestep Collection Time: 2.16095
Timestep Consumption Time: 2.43320
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.59415

Cumulative Model Updates: 170,102
Cumulative Timesteps: 1,418,644,112

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1418644112...
Checkpoint 1418644112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.27150
Policy Entropy: 3.00909
Value Function Loss: 0.00526

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.60309
Value Function Update Magnitude: 0.54752

Collected Steps per Second: 22,914.14314
Overall Steps per Second: 10,641.62014

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.51798
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.70135

Cumulative Model Updates: 170,108
Cumulative Timesteps: 1,418,694,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,766.52337
Policy Entropy: 3.03008
Value Function Loss: 0.00536

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12237
Policy Update Magnitude: 0.61374
Value Function Update Magnitude: 0.57671

Collected Steps per Second: 22,650.14790
Overall Steps per Second: 10,679.27029

Timestep Collection Time: 2.20846
Timestep Consumption Time: 2.47557
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68403

Cumulative Model Updates: 170,114
Cumulative Timesteps: 1,418,744,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1418744164...
Checkpoint 1418744164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.39701
Policy Entropy: 3.03905
Value Function Loss: 0.00521

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.62379
Value Function Update Magnitude: 0.61651

Collected Steps per Second: 22,669.09353
Overall Steps per Second: 10,785.52464

Timestep Collection Time: 2.20565
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.63584

Cumulative Model Updates: 170,120
Cumulative Timesteps: 1,418,794,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.15549
Policy Entropy: 3.03600
Value Function Loss: 0.00485

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.62240
Value Function Update Magnitude: 0.61968

Collected Steps per Second: 22,820.09844
Overall Steps per Second: 10,687.08185

Timestep Collection Time: 2.19184
Timestep Consumption Time: 2.48839
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.68023

Cumulative Model Updates: 170,126
Cumulative Timesteps: 1,418,844,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1418844182...
Checkpoint 1418844182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.11470
Policy Entropy: 3.01412
Value Function Loss: 0.00498

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.62486
Value Function Update Magnitude: 0.58978

Collected Steps per Second: 22,418.23243
Overall Steps per Second: 10,562.24154

Timestep Collection Time: 2.23042
Timestep Consumption Time: 2.50362
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.73403

Cumulative Model Updates: 170,132
Cumulative Timesteps: 1,418,894,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,069.76826
Policy Entropy: 3.00193
Value Function Loss: 0.00521

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.62682
Value Function Update Magnitude: 0.59313

Collected Steps per Second: 23,428.42473
Overall Steps per Second: 10,805.54157

Timestep Collection Time: 2.13544
Timestep Consumption Time: 2.49459
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.63003

Cumulative Model Updates: 170,138
Cumulative Timesteps: 1,418,944,214

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1418944214...
Checkpoint 1418944214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,526.79382
Policy Entropy: 2.98894
Value Function Loss: 0.00470

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.62028
Value Function Update Magnitude: 0.58458

Collected Steps per Second: 22,794.47235
Overall Steps per Second: 10,651.68455

Timestep Collection Time: 2.19448
Timestep Consumption Time: 2.50168
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.69616

Cumulative Model Updates: 170,144
Cumulative Timesteps: 1,418,994,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.30960
Policy Entropy: 3.01276
Value Function Loss: 0.00419

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.59177
Value Function Update Magnitude: 0.55337

Collected Steps per Second: 23,193.19552
Overall Steps per Second: 10,890.21722

Timestep Collection Time: 2.15606
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.59183

Cumulative Model Updates: 170,150
Cumulative Timesteps: 1,419,044,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1419044242...
Checkpoint 1419044242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,046.45225
Policy Entropy: 3.01078
Value Function Loss: 0.00411

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.58617
Value Function Update Magnitude: 0.52648

Collected Steps per Second: 22,815.83377
Overall Steps per Second: 10,633.99790

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.51084
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.70265

Cumulative Model Updates: 170,156
Cumulative Timesteps: 1,419,094,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,984.22052
Policy Entropy: 3.01017
Value Function Loss: 0.00413

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.59467
Value Function Update Magnitude: 0.52765

Collected Steps per Second: 22,370.23104
Overall Steps per Second: 10,867.65485

Timestep Collection Time: 2.23592
Timestep Consumption Time: 2.36655
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60246

Cumulative Model Updates: 170,162
Cumulative Timesteps: 1,419,144,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1419144268...
Checkpoint 1419144268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,650.55815
Policy Entropy: 2.97511
Value Function Loss: 0.00454

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.59417
Value Function Update Magnitude: 0.52805

Collected Steps per Second: 22,236.58138
Overall Steps per Second: 10,715.23107

Timestep Collection Time: 2.24882
Timestep Consumption Time: 2.41800
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.66681

Cumulative Model Updates: 170,168
Cumulative Timesteps: 1,419,194,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.40776
Policy Entropy: 2.97214
Value Function Loss: 0.00461

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11672
Policy Update Magnitude: 0.60141
Value Function Update Magnitude: 0.53971

Collected Steps per Second: 22,393.05437
Overall Steps per Second: 10,869.37701

Timestep Collection Time: 2.23417
Timestep Consumption Time: 2.36866
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.60284

Cumulative Model Updates: 170,174
Cumulative Timesteps: 1,419,244,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1419244304...
Checkpoint 1419244304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,144.20413
Policy Entropy: 2.96167
Value Function Loss: 0.00463

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.60434
Value Function Update Magnitude: 0.56120

Collected Steps per Second: 21,867.35664
Overall Steps per Second: 10,675.11351

Timestep Collection Time: 2.28679
Timestep Consumption Time: 2.39757
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.68435

Cumulative Model Updates: 170,180
Cumulative Timesteps: 1,419,294,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.87714
Policy Entropy: 2.99424
Value Function Loss: 0.00433

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.59992
Value Function Update Magnitude: 0.57164

Collected Steps per Second: 22,273.24367
Overall Steps per Second: 10,855.12693

Timestep Collection Time: 2.24503
Timestep Consumption Time: 2.36146
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60649

Cumulative Model Updates: 170,186
Cumulative Timesteps: 1,419,344,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1419344314...
Checkpoint 1419344314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.00702
Policy Entropy: 3.01183
Value Function Loss: 0.00420

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.58262
Value Function Update Magnitude: 0.55852

Collected Steps per Second: 21,727.93528
Overall Steps per Second: 10,605.03162

Timestep Collection Time: 2.30146
Timestep Consumption Time: 2.41385
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.71531

Cumulative Model Updates: 170,192
Cumulative Timesteps: 1,419,394,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.83945
Policy Entropy: 3.02091
Value Function Loss: 0.00416

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.57521
Value Function Update Magnitude: 0.53840

Collected Steps per Second: 22,842.29971
Overall Steps per Second: 10,732.18930

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.66000

Cumulative Model Updates: 170,198
Cumulative Timesteps: 1,419,444,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1419444332...
Checkpoint 1419444332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,129.83938
Policy Entropy: 3.00726
Value Function Loss: 0.00450

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.58271
Value Function Update Magnitude: 0.51210

Collected Steps per Second: 23,007.11559
Overall Steps per Second: 10,828.95335

Timestep Collection Time: 2.17324
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61725

Cumulative Model Updates: 170,204
Cumulative Timesteps: 1,419,494,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,755.52513
Policy Entropy: 2.99584
Value Function Loss: 0.00482

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.59274
Value Function Update Magnitude: 0.52196

Collected Steps per Second: 21,949.05695
Overall Steps per Second: 10,529.39845

Timestep Collection Time: 2.27891
Timestep Consumption Time: 2.47160
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.75051

Cumulative Model Updates: 170,210
Cumulative Timesteps: 1,419,544,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1419544352...
Checkpoint 1419544352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,316.12748
Policy Entropy: 2.97889
Value Function Loss: 0.00504

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.60817
Value Function Update Magnitude: 0.55517

Collected Steps per Second: 22,552.43396
Overall Steps per Second: 10,636.13647

Timestep Collection Time: 2.21706
Timestep Consumption Time: 2.48390
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.70096

Cumulative Model Updates: 170,216
Cumulative Timesteps: 1,419,594,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.21254
Policy Entropy: 2.99147
Value Function Loss: 0.00448

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.60572
Value Function Update Magnitude: 0.56227

Collected Steps per Second: 22,808.66934
Overall Steps per Second: 10,855.81608

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.41455
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60748

Cumulative Model Updates: 170,222
Cumulative Timesteps: 1,419,644,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1419644370...
Checkpoint 1419644370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,419.24669
Policy Entropy: 2.97962
Value Function Loss: 0.00483

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.60276
Value Function Update Magnitude: 0.54471

Collected Steps per Second: 22,978.32687
Overall Steps per Second: 10,653.71449

Timestep Collection Time: 2.17692
Timestep Consumption Time: 2.51834
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69526

Cumulative Model Updates: 170,228
Cumulative Timesteps: 1,419,694,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.59508
Policy Entropy: 2.98422
Value Function Loss: 0.00483

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.60919
Value Function Update Magnitude: 0.56346

Collected Steps per Second: 23,239.57350
Overall Steps per Second: 10,885.27909

Timestep Collection Time: 2.15254
Timestep Consumption Time: 2.44303
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59556

Cumulative Model Updates: 170,234
Cumulative Timesteps: 1,419,744,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1419744416...
Checkpoint 1419744416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.17680
Policy Entropy: 2.95992
Value Function Loss: 0.00501

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.60829
Value Function Update Magnitude: 0.56728

Collected Steps per Second: 22,676.36910
Overall Steps per Second: 10,682.05837

Timestep Collection Time: 2.20609
Timestep Consumption Time: 2.47709
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.68318

Cumulative Model Updates: 170,240
Cumulative Timesteps: 1,419,794,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,101.96286
Policy Entropy: 2.95360
Value Function Loss: 0.00513

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.61149
Value Function Update Magnitude: 0.56182

Collected Steps per Second: 23,407.86480
Overall Steps per Second: 10,923.03870

Timestep Collection Time: 2.13663
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.57876

Cumulative Model Updates: 170,246
Cumulative Timesteps: 1,419,844,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1419844456...
Checkpoint 1419844456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.31989
Policy Entropy: 2.94856
Value Function Loss: 0.00500

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.61784
Value Function Update Magnitude: 0.56631

Collected Steps per Second: 23,056.14276
Overall Steps per Second: 10,698.92413

Timestep Collection Time: 2.16888
Timestep Consumption Time: 2.50505
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.67393

Cumulative Model Updates: 170,252
Cumulative Timesteps: 1,419,894,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.68492
Policy Entropy: 2.95826
Value Function Loss: 0.00471

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.60767
Value Function Update Magnitude: 0.55224

Collected Steps per Second: 23,001.04096
Overall Steps per Second: 10,800.96919

Timestep Collection Time: 2.17521
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.63218

Cumulative Model Updates: 170,258
Cumulative Timesteps: 1,419,944,494

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1419944494...
Checkpoint 1419944494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,967.73632
Policy Entropy: 2.95643
Value Function Loss: 0.00472

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12114
Policy Update Magnitude: 0.59701
Value Function Update Magnitude: 0.52536

Collected Steps per Second: 22,580.12973
Overall Steps per Second: 10,707.82578

Timestep Collection Time: 2.21487
Timestep Consumption Time: 2.45573
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.67060

Cumulative Model Updates: 170,264
Cumulative Timesteps: 1,419,994,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,190.15762
Policy Entropy: 2.95357
Value Function Loss: 0.00481

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.60956
Value Function Update Magnitude: 0.51963

Collected Steps per Second: 22,804.48879
Overall Steps per Second: 10,793.88453

Timestep Collection Time: 2.19281
Timestep Consumption Time: 2.43999
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.63281

Cumulative Model Updates: 170,270
Cumulative Timesteps: 1,420,044,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1420044512...
Checkpoint 1420044512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,885.54554
Policy Entropy: 2.94653
Value Function Loss: 0.00489

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.61170
Value Function Update Magnitude: 0.51359

Collected Steps per Second: 22,503.40761
Overall Steps per Second: 10,743.60842

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.43331
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.65635

Cumulative Model Updates: 170,276
Cumulative Timesteps: 1,420,094,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853.39698
Policy Entropy: 2.96956
Value Function Loss: 0.00482

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.60062
Value Function Update Magnitude: 0.50627

Collected Steps per Second: 22,825.18413
Overall Steps per Second: 10,802.59435

Timestep Collection Time: 2.19083
Timestep Consumption Time: 2.43825
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62907

Cumulative Model Updates: 170,282
Cumulative Timesteps: 1,420,144,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1420144544...
Checkpoint 1420144544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,455.21128
Policy Entropy: 2.97720
Value Function Loss: 0.00470

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.59819
Value Function Update Magnitude: 0.50842

Collected Steps per Second: 22,204.79886
Overall Steps per Second: 10,662.77953

Timestep Collection Time: 2.25330
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.69240

Cumulative Model Updates: 170,288
Cumulative Timesteps: 1,420,194,578

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.65470
Policy Entropy: 2.97969
Value Function Loss: 0.00422

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.59281
Value Function Update Magnitude: 0.51572

Collected Steps per Second: 23,085.97977
Overall Steps per Second: 10,694.63574

Timestep Collection Time: 2.16720
Timestep Consumption Time: 2.51103
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.67823

Cumulative Model Updates: 170,294
Cumulative Timesteps: 1,420,244,610

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1420244610...
Checkpoint 1420244610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.32938
Policy Entropy: 2.96369
Value Function Loss: 0.00419

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.58896
Value Function Update Magnitude: 0.51211

Collected Steps per Second: 23,038.29252
Overall Steps per Second: 10,842.11556

Timestep Collection Time: 2.17082
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.61275

Cumulative Model Updates: 170,300
Cumulative Timesteps: 1,420,294,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.06308
Policy Entropy: 2.94150
Value Function Loss: 0.00419

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.14762
Policy Update Magnitude: 0.59164
Value Function Update Magnitude: 0.50688

Collected Steps per Second: 23,186.99945
Overall Steps per Second: 10,945.26207

Timestep Collection Time: 2.15750
Timestep Consumption Time: 2.41306
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.57056

Cumulative Model Updates: 170,306
Cumulative Timesteps: 1,420,344,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1420344648...
Checkpoint 1420344648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,151.61572
Policy Entropy: 2.94279
Value Function Loss: 0.00442

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.60178
Value Function Update Magnitude: 0.50631

Collected Steps per Second: 22,903.97084
Overall Steps per Second: 10,729.84490

Timestep Collection Time: 2.18311
Timestep Consumption Time: 2.47697
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.66009

Cumulative Model Updates: 170,312
Cumulative Timesteps: 1,420,394,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,768.12497
Policy Entropy: 2.94486
Value Function Loss: 0.00461

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14759
Policy Update Magnitude: 0.61665
Value Function Update Magnitude: 0.51177

Collected Steps per Second: 23,321.58625
Overall Steps per Second: 10,915.70066

Timestep Collection Time: 2.14394
Timestep Consumption Time: 2.43662
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.58056

Cumulative Model Updates: 170,318
Cumulative Timesteps: 1,420,444,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1420444650...
Checkpoint 1420444650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293.58450
Policy Entropy: 2.96317
Value Function Loss: 0.00451

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.61001
Value Function Update Magnitude: 0.53509

Collected Steps per Second: 22,944.52576
Overall Steps per Second: 10,722.17354

Timestep Collection Time: 2.18004
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.66510

Cumulative Model Updates: 170,324
Cumulative Timesteps: 1,420,494,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,185.59676
Policy Entropy: 2.96689
Value Function Loss: 0.00411

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.58935
Value Function Update Magnitude: 0.53779

Collected Steps per Second: 22,890.31670
Overall Steps per Second: 10,798.01502

Timestep Collection Time: 2.18485
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.63159

Cumulative Model Updates: 170,330
Cumulative Timesteps: 1,420,544,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1420544682...
Checkpoint 1420544682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,883.64911
Policy Entropy: 2.97809
Value Function Loss: 0.00399

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.58148
Value Function Update Magnitude: 0.51788

Collected Steps per Second: 22,474.47815
Overall Steps per Second: 10,760.68017

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.42238
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.64766

Cumulative Model Updates: 170,336
Cumulative Timesteps: 1,420,594,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,161.41096
Policy Entropy: 2.98279
Value Function Loss: 0.00379

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.57271
Value Function Update Magnitude: 0.50597

Collected Steps per Second: 22,931.08124
Overall Steps per Second: 10,797.81007

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.45022
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.63075

Cumulative Model Updates: 170,342
Cumulative Timesteps: 1,420,644,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1420644696...
Checkpoint 1420644696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,433.02658
Policy Entropy: 2.99828
Value Function Loss: 0.00378

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.48471

Collected Steps per Second: 22,506.16350
Overall Steps per Second: 10,579.57315

Timestep Collection Time: 2.22224
Timestep Consumption Time: 2.50518
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.72741

Cumulative Model Updates: 170,348
Cumulative Timesteps: 1,420,694,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.22547
Policy Entropy: 2.98264
Value Function Loss: 0.00437

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.48783

Collected Steps per Second: 23,050.38711
Overall Steps per Second: 10,614.85515

Timestep Collection Time: 2.16933
Timestep Consumption Time: 2.54142
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.71076

Cumulative Model Updates: 170,354
Cumulative Timesteps: 1,420,744,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1420744714...
Checkpoint 1420744714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,185.22638
Policy Entropy: 2.97806
Value Function Loss: 0.00471

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.58595
Value Function Update Magnitude: 0.53147

Collected Steps per Second: 22,945.71606
Overall Steps per Second: 10,689.76608

Timestep Collection Time: 2.17949
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.67831

Cumulative Model Updates: 170,360
Cumulative Timesteps: 1,420,794,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.20435
Policy Entropy: 2.96951
Value Function Loss: 0.00475

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.55204

Collected Steps per Second: 23,133.81868
Overall Steps per Second: 10,775.58830

Timestep Collection Time: 2.16160
Timestep Consumption Time: 2.47908
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.64067

Cumulative Model Updates: 170,366
Cumulative Timesteps: 1,420,844,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1420844730...
Checkpoint 1420844730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,930.25204
Policy Entropy: 2.98030
Value Function Loss: 0.00481

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.59864
Value Function Update Magnitude: 0.54390

Collected Steps per Second: 23,074.75520
Overall Steps per Second: 10,789.62387

Timestep Collection Time: 2.16696
Timestep Consumption Time: 2.46731
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.63427

Cumulative Model Updates: 170,372
Cumulative Timesteps: 1,420,894,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.93284
Policy Entropy: 2.99261
Value Function Loss: 0.00472

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.59636
Value Function Update Magnitude: 0.55807

Collected Steps per Second: 23,094.53040
Overall Steps per Second: 10,782.88794

Timestep Collection Time: 2.16579
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.63865

Cumulative Model Updates: 170,378
Cumulative Timesteps: 1,420,944,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1420944750...
Checkpoint 1420944750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.09502
Policy Entropy: 3.00036
Value Function Loss: 0.00481

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.59243
Value Function Update Magnitude: 0.55091

Collected Steps per Second: 22,912.73625
Overall Steps per Second: 10,664.25196

Timestep Collection Time: 2.18324
Timestep Consumption Time: 2.50757
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.69081

Cumulative Model Updates: 170,384
Cumulative Timesteps: 1,420,994,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,736.25857
Policy Entropy: 3.00371
Value Function Loss: 0.00466

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.58282
Value Function Update Magnitude: 0.52191

Collected Steps per Second: 22,581.31991
Overall Steps per Second: 10,601.31697

Timestep Collection Time: 2.21493
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.71790

Cumulative Model Updates: 170,390
Cumulative Timesteps: 1,421,044,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1421044790...
Checkpoint 1421044790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.35326
Policy Entropy: 2.98763
Value Function Loss: 0.00479

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.58170
Value Function Update Magnitude: 0.51932

Collected Steps per Second: 22,479.02207
Overall Steps per Second: 10,578.90159

Timestep Collection Time: 2.22572
Timestep Consumption Time: 2.50369
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.72941

Cumulative Model Updates: 170,396
Cumulative Timesteps: 1,421,094,822

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,661.70613
Policy Entropy: 2.97431
Value Function Loss: 0.00428

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.59362
Value Function Update Magnitude: 0.53928

Collected Steps per Second: 22,813.15180
Overall Steps per Second: 10,790.02165

Timestep Collection Time: 2.19312
Timestep Consumption Time: 2.44376
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.63688

Cumulative Model Updates: 170,402
Cumulative Timesteps: 1,421,144,854

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1421144854...
Checkpoint 1421144854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,799.22500
Policy Entropy: 2.97295
Value Function Loss: 0.00448

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.60418
Value Function Update Magnitude: 0.53859

Collected Steps per Second: 22,995.09477
Overall Steps per Second: 10,642.63570

Timestep Collection Time: 2.17464
Timestep Consumption Time: 2.52401
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.69865

Cumulative Model Updates: 170,408
Cumulative Timesteps: 1,421,194,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.42491
Policy Entropy: 2.95378
Value Function Loss: 0.00461

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.60858
Value Function Update Magnitude: 0.56918

Collected Steps per Second: 23,194.82774
Overall Steps per Second: 10,861.69922

Timestep Collection Time: 2.15565
Timestep Consumption Time: 2.44768
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.60333

Cumulative Model Updates: 170,414
Cumulative Timesteps: 1,421,244,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1421244860...
Checkpoint 1421244860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,666.60480
Policy Entropy: 2.94656
Value Function Loss: 0.00467

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.60892
Value Function Update Magnitude: 0.56865

Collected Steps per Second: 23,065.60958
Overall Steps per Second: 10,693.47833

Timestep Collection Time: 2.16868
Timestep Consumption Time: 2.50912
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.67780

Cumulative Model Updates: 170,420
Cumulative Timesteps: 1,421,294,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,938.51058
Policy Entropy: 2.94001
Value Function Loss: 0.00466

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.60483
Value Function Update Magnitude: 0.53768

Collected Steps per Second: 23,394.28707
Overall Steps per Second: 10,946.93458

Timestep Collection Time: 2.13762
Timestep Consumption Time: 2.43060
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.56822

Cumulative Model Updates: 170,426
Cumulative Timesteps: 1,421,344,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1421344890...
Checkpoint 1421344890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,041.70557
Policy Entropy: 2.95696
Value Function Loss: 0.00453

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.60349
Value Function Update Magnitude: 0.54835

Collected Steps per Second: 23,021.46614
Overall Steps per Second: 10,710.86053

Timestep Collection Time: 2.17189
Timestep Consumption Time: 2.49627
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.66816

Cumulative Model Updates: 170,432
Cumulative Timesteps: 1,421,394,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,445.25447
Policy Entropy: 2.96255
Value Function Loss: 0.00442

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.59662
Value Function Update Magnitude: 0.54061

Collected Steps per Second: 23,108.90190
Overall Steps per Second: 10,792.94126

Timestep Collection Time: 2.16540
Timestep Consumption Time: 2.47096
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.63636

Cumulative Model Updates: 170,438
Cumulative Timesteps: 1,421,444,930

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1421444930...
Checkpoint 1421444930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.91996
Policy Entropy: 2.95778
Value Function Loss: 0.00444

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.59475
Value Function Update Magnitude: 0.53800

Collected Steps per Second: 22,916.27925
Overall Steps per Second: 10,652.00537

Timestep Collection Time: 2.18378
Timestep Consumption Time: 2.51431
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.69808

Cumulative Model Updates: 170,444
Cumulative Timesteps: 1,421,494,974

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,422.86372
Policy Entropy: 2.97000
Value Function Loss: 0.00461

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.59766
Value Function Update Magnitude: 0.54236

Collected Steps per Second: 22,413.17684
Overall Steps per Second: 10,582.13305

Timestep Collection Time: 2.23146
Timestep Consumption Time: 2.49481
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.72627

Cumulative Model Updates: 170,450
Cumulative Timesteps: 1,421,544,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1421544988...
Checkpoint 1421544988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.88009
Policy Entropy: 2.98468
Value Function Loss: 0.00433

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.59366
Value Function Update Magnitude: 0.55181

Collected Steps per Second: 22,791.58976
Overall Steps per Second: 10,648.01326

Timestep Collection Time: 2.19484
Timestep Consumption Time: 2.50312
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.69797

Cumulative Model Updates: 170,456
Cumulative Timesteps: 1,421,595,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,097.01764
Policy Entropy: 2.98001
Value Function Loss: 0.00458

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.60010
Value Function Update Magnitude: 0.55454

Collected Steps per Second: 23,171.90520
Overall Steps per Second: 10,772.66630

Timestep Collection Time: 2.15813
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.64212

Cumulative Model Updates: 170,462
Cumulative Timesteps: 1,421,645,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1421645020...
Checkpoint 1421645020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.74327
Policy Entropy: 2.96541
Value Function Loss: 0.00470

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.60639
Value Function Update Magnitude: 0.56736

Collected Steps per Second: 22,601.41991
Overall Steps per Second: 10,628.16971

Timestep Collection Time: 2.21305
Timestep Consumption Time: 2.49313
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.70617

Cumulative Model Updates: 170,468
Cumulative Timesteps: 1,421,695,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.81293
Policy Entropy: 2.97034
Value Function Loss: 0.00463

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.60178
Value Function Update Magnitude: 0.54906

Collected Steps per Second: 23,005.21669
Overall Steps per Second: 10,844.79520

Timestep Collection Time: 2.17464
Timestep Consumption Time: 2.43845
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.61309

Cumulative Model Updates: 170,474
Cumulative Timesteps: 1,421,745,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1421745066...
Checkpoint 1421745066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.49331
Policy Entropy: 2.98951
Value Function Loss: 0.00448

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.57344
Value Function Update Magnitude: 0.50983

Collected Steps per Second: 22,841.60532
Overall Steps per Second: 10,587.15480

Timestep Collection Time: 2.18943
Timestep Consumption Time: 2.53422
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.72365

Cumulative Model Updates: 170,480
Cumulative Timesteps: 1,421,795,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.99610
Policy Entropy: 2.99222
Value Function Loss: 0.00492

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.57695
Value Function Update Magnitude: 0.49782

Collected Steps per Second: 22,878.95830
Overall Steps per Second: 10,713.94182

Timestep Collection Time: 2.18655
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.66924

Cumulative Model Updates: 170,486
Cumulative Timesteps: 1,421,845,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1421845102...
Checkpoint 1421845102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,228.18156
Policy Entropy: 2.98818
Value Function Loss: 0.00483

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.58105
Value Function Update Magnitude: 0.51166

Collected Steps per Second: 23,257.63749
Overall Steps per Second: 10,882.44371

Timestep Collection Time: 2.15018
Timestep Consumption Time: 2.44512
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.59529

Cumulative Model Updates: 170,492
Cumulative Timesteps: 1,421,895,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,382.12998
Policy Entropy: 2.97887
Value Function Loss: 0.00480

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.58085
Value Function Update Magnitude: 0.50604

Collected Steps per Second: 23,201.97349
Overall Steps per Second: 10,887.88449

Timestep Collection Time: 2.15525
Timestep Consumption Time: 2.43756
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.59281

Cumulative Model Updates: 170,498
Cumulative Timesteps: 1,421,945,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1421945116...
Checkpoint 1421945116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,168.89350
Policy Entropy: 2.96601
Value Function Loss: 0.00471

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.59074
Value Function Update Magnitude: 0.51059

Collected Steps per Second: 23,059.11328
Overall Steps per Second: 10,742.35126

Timestep Collection Time: 2.16834
Timestep Consumption Time: 2.48613
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.65447

Cumulative Model Updates: 170,504
Cumulative Timesteps: 1,421,995,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388.12747
Policy Entropy: 2.95654
Value Function Loss: 0.00448

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.58913
Value Function Update Magnitude: 0.54360

Collected Steps per Second: 22,557.88197
Overall Steps per Second: 10,615.84035

Timestep Collection Time: 2.21732
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.71164

Cumulative Model Updates: 170,510
Cumulative Timesteps: 1,422,045,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1422045134...
Checkpoint 1422045134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.32804
Policy Entropy: 2.96603
Value Function Loss: 0.00460

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.55732

Collected Steps per Second: 22,957.97139
Overall Steps per Second: 10,833.31184

Timestep Collection Time: 2.17859
Timestep Consumption Time: 2.43828
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61687

Cumulative Model Updates: 170,516
Cumulative Timesteps: 1,422,095,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.28703
Policy Entropy: 2.97655
Value Function Loss: 0.00441

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.58775
Value Function Update Magnitude: 0.55344

Collected Steps per Second: 22,661.23470
Overall Steps per Second: 10,605.11005

Timestep Collection Time: 2.20765
Timestep Consumption Time: 2.50970
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.71735

Cumulative Model Updates: 170,522
Cumulative Timesteps: 1,422,145,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1422145178...
Checkpoint 1422145178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,752.54982
Policy Entropy: 2.98865
Value Function Loss: 0.00439

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.58961
Value Function Update Magnitude: 0.54086

Collected Steps per Second: 23,016.37652
Overall Steps per Second: 10,632.47046

Timestep Collection Time: 2.17350
Timestep Consumption Time: 2.53153
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.70502

Cumulative Model Updates: 170,528
Cumulative Timesteps: 1,422,195,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,403.70943
Policy Entropy: 2.98485
Value Function Loss: 0.00413

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.58722
Value Function Update Magnitude: 0.52668

Collected Steps per Second: 23,220.09556
Overall Steps per Second: 10,883.63417

Timestep Collection Time: 2.15425
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.59608

Cumulative Model Updates: 170,534
Cumulative Timesteps: 1,422,245,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1422245226...
Checkpoint 1422245226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.02198
Policy Entropy: 2.98472
Value Function Loss: 0.00398

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.57975
Value Function Update Magnitude: 0.51262

Collected Steps per Second: 22,894.68445
Overall Steps per Second: 10,685.01841

Timestep Collection Time: 2.18400
Timestep Consumption Time: 2.49564
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.67964

Cumulative Model Updates: 170,540
Cumulative Timesteps: 1,422,295,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,658.04266
Policy Entropy: 2.99370
Value Function Loss: 0.00376

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.56406
Value Function Update Magnitude: 0.48673

Collected Steps per Second: 23,009.66004
Overall Steps per Second: 10,869.54420

Timestep Collection Time: 2.17396
Timestep Consumption Time: 2.42808
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.60203

Cumulative Model Updates: 170,546
Cumulative Timesteps: 1,422,345,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1422345250...
Checkpoint 1422345250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,071.57562
Policy Entropy: 2.99901
Value Function Loss: 0.00402

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.48451

Collected Steps per Second: 23,104.38100
Overall Steps per Second: 10,759.96949

Timestep Collection Time: 2.16418
Timestep Consumption Time: 2.48286
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.64704

Cumulative Model Updates: 170,552
Cumulative Timesteps: 1,422,395,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,484.89330
Policy Entropy: 3.00638
Value Function Loss: 0.00426

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.57350
Value Function Update Magnitude: 0.50012

Collected Steps per Second: 23,144.21379
Overall Steps per Second: 10,725.87065

Timestep Collection Time: 2.16045
Timestep Consumption Time: 2.50136
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.66181

Cumulative Model Updates: 170,558
Cumulative Timesteps: 1,422,445,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1422445254...
Checkpoint 1422445254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.87641
Policy Entropy: 3.00087
Value Function Loss: 0.00457

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.57775
Value Function Update Magnitude: 0.53870

Collected Steps per Second: 22,730.10103
Overall Steps per Second: 10,670.26026

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.48669
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.68686

Cumulative Model Updates: 170,564
Cumulative Timesteps: 1,422,495,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.21517
Policy Entropy: 2.98842
Value Function Loss: 0.00450

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.58355
Value Function Update Magnitude: 0.55216

Collected Steps per Second: 22,583.42147
Overall Steps per Second: 10,658.92107

Timestep Collection Time: 2.21401
Timestep Consumption Time: 2.47689
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69091

Cumulative Model Updates: 170,570
Cumulative Timesteps: 1,422,545,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1422545264...
Checkpoint 1422545264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,139.45648
Policy Entropy: 2.97581
Value Function Loss: 0.00437

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.58771
Value Function Update Magnitude: 0.55382

Collected Steps per Second: 22,927.27421
Overall Steps per Second: 10,833.01056

Timestep Collection Time: 2.18151
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.61700

Cumulative Model Updates: 170,576
Cumulative Timesteps: 1,422,595,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.19772
Policy Entropy: 2.98260
Value Function Loss: 0.00420

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.58947
Value Function Update Magnitude: 0.55162

Collected Steps per Second: 22,940.16791
Overall Steps per Second: 10,834.44437

Timestep Collection Time: 2.18011
Timestep Consumption Time: 2.43591
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.61602

Cumulative Model Updates: 170,582
Cumulative Timesteps: 1,422,645,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1422645292...
Checkpoint 1422645292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.51388
Policy Entropy: 2.98306
Value Function Loss: 0.00458

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.59889
Value Function Update Magnitude: 0.54686

Collected Steps per Second: 22,753.48354
Overall Steps per Second: 10,803.28039

Timestep Collection Time: 2.19852
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.63045

Cumulative Model Updates: 170,588
Cumulative Timesteps: 1,422,695,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,789.00511
Policy Entropy: 2.98505
Value Function Loss: 0.00457

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.60046
Value Function Update Magnitude: 0.54533

Collected Steps per Second: 22,958.10279
Overall Steps per Second: 10,768.79396

Timestep Collection Time: 2.17840
Timestep Consumption Time: 2.46576
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.64416

Cumulative Model Updates: 170,594
Cumulative Timesteps: 1,422,745,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1422745328...
Checkpoint 1422745328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.97038
Policy Entropy: 2.98002
Value Function Loss: 0.00462

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.59406
Value Function Update Magnitude: 0.57833

Collected Steps per Second: 23,248.66395
Overall Steps per Second: 10,846.58289

Timestep Collection Time: 2.15092
Timestep Consumption Time: 2.45938
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.61030

Cumulative Model Updates: 170,600
Cumulative Timesteps: 1,422,795,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,671.45913
Policy Entropy: 3.00374
Value Function Loss: 0.00433

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.56703

Collected Steps per Second: 23,362.20771
Overall Steps per Second: 10,778.47333

Timestep Collection Time: 2.14132
Timestep Consumption Time: 2.49997
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.64129

Cumulative Model Updates: 170,606
Cumulative Timesteps: 1,422,845,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1422845360...
Checkpoint 1422845360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.72187
Policy Entropy: 2.98706
Value Function Loss: 0.00466

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.57920
Value Function Update Magnitude: 0.55250

Collected Steps per Second: 23,274.28807
Overall Steps per Second: 10,778.72159

Timestep Collection Time: 2.14958
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.64155

Cumulative Model Updates: 170,612
Cumulative Timesteps: 1,422,895,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,007.07459
Policy Entropy: 2.97814
Value Function Loss: 0.00475

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.60644
Value Function Update Magnitude: 0.58745

Collected Steps per Second: 22,992.70452
Overall Steps per Second: 10,782.38910

Timestep Collection Time: 2.17469
Timestep Consumption Time: 2.46269
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.63738

Cumulative Model Updates: 170,618
Cumulative Timesteps: 1,422,945,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1422945392...
Checkpoint 1422945392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.71283
Policy Entropy: 2.95761
Value Function Loss: 0.00488

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.61338
Value Function Update Magnitude: 0.60299

Collected Steps per Second: 22,933.25606
Overall Steps per Second: 10,702.27897

Timestep Collection Time: 2.18111
Timestep Consumption Time: 2.49266
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.67377

Cumulative Model Updates: 170,624
Cumulative Timesteps: 1,422,995,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.04348
Policy Entropy: 2.98308
Value Function Loss: 0.00430

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.60046
Value Function Update Magnitude: 0.60730

Collected Steps per Second: 22,671.75002
Overall Steps per Second: 10,830.67965

Timestep Collection Time: 2.20618
Timestep Consumption Time: 2.41200
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61818

Cumulative Model Updates: 170,630
Cumulative Timesteps: 1,423,045,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1423045430...
Checkpoint 1423045430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.52670
Policy Entropy: 2.99812
Value Function Loss: 0.00450

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11110
Policy Update Magnitude: 0.59403
Value Function Update Magnitude: 0.58168

Collected Steps per Second: 22,432.09825
Overall Steps per Second: 10,667.73498

Timestep Collection Time: 2.22931
Timestep Consumption Time: 2.45847
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.68778

Cumulative Model Updates: 170,636
Cumulative Timesteps: 1,423,095,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,135.92070
Policy Entropy: 3.00370
Value Function Loss: 0.00434

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.58330
Value Function Update Magnitude: 0.55869

Collected Steps per Second: 22,253.78282
Overall Steps per Second: 10,516.90164

Timestep Collection Time: 2.24753
Timestep Consumption Time: 2.50825
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.75577

Cumulative Model Updates: 170,642
Cumulative Timesteps: 1,423,145,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1423145454...
Checkpoint 1423145454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.80583
Policy Entropy: 3.00672
Value Function Loss: 0.00458

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.57949
Value Function Update Magnitude: 0.58352

Collected Steps per Second: 22,722.82877
Overall Steps per Second: 10,727.62678

Timestep Collection Time: 2.20166
Timestep Consumption Time: 2.46181
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.66347

Cumulative Model Updates: 170,648
Cumulative Timesteps: 1,423,195,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,260.74061
Policy Entropy: 2.99817
Value Function Loss: 0.00432

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.58368
Value Function Update Magnitude: 0.58537

Collected Steps per Second: 23,153.66871
Overall Steps per Second: 10,786.83176

Timestep Collection Time: 2.16069
Timestep Consumption Time: 2.47718
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.63788

Cumulative Model Updates: 170,654
Cumulative Timesteps: 1,423,245,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1423245510...
Checkpoint 1423245510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,771.09538
Policy Entropy: 2.99589
Value Function Loss: 0.00449

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.58616
Value Function Update Magnitude: 0.56568

Collected Steps per Second: 22,925.29875
Overall Steps per Second: 10,750.65673

Timestep Collection Time: 2.18108
Timestep Consumption Time: 2.46998
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.65106

Cumulative Model Updates: 170,660
Cumulative Timesteps: 1,423,295,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,759.28593
Policy Entropy: 2.99167
Value Function Loss: 0.00466

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.58929
Value Function Update Magnitude: 0.55088

Collected Steps per Second: 23,053.88685
Overall Steps per Second: 10,776.18339

Timestep Collection Time: 2.16953
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.64135

Cumulative Model Updates: 170,666
Cumulative Timesteps: 1,423,345,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1423345528...
Checkpoint 1423345528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,298.38169
Policy Entropy: 2.98200
Value Function Loss: 0.00476

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.59836
Value Function Update Magnitude: 0.55064

Collected Steps per Second: 21,938.16283
Overall Steps per Second: 10,672.19284

Timestep Collection Time: 2.28023
Timestep Consumption Time: 2.40709
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.68732

Cumulative Model Updates: 170,672
Cumulative Timesteps: 1,423,395,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.68311
Policy Entropy: 2.97896
Value Function Loss: 0.00486

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.60736
Value Function Update Magnitude: 0.54629

Collected Steps per Second: 22,706.35139
Overall Steps per Second: 10,807.40961

Timestep Collection Time: 2.20273
Timestep Consumption Time: 2.42520
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.62794

Cumulative Model Updates: 170,678
Cumulative Timesteps: 1,423,445,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1423445568...
Checkpoint 1423445568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.09800
Policy Entropy: 2.97474
Value Function Loss: 0.00504

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.60616
Value Function Update Magnitude: 0.56926

Collected Steps per Second: 22,632.72729
Overall Steps per Second: 10,686.11354

Timestep Collection Time: 2.20954
Timestep Consumption Time: 2.47017
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.67972

Cumulative Model Updates: 170,684
Cumulative Timesteps: 1,423,495,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.33168
Policy Entropy: 2.97162
Value Function Loss: 0.00499

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.61309
Value Function Update Magnitude: 0.60015

Collected Steps per Second: 22,997.07020
Overall Steps per Second: 10,673.86346

Timestep Collection Time: 2.17445
Timestep Consumption Time: 2.51045
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.68490

Cumulative Model Updates: 170,690
Cumulative Timesteps: 1,423,545,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1423545582...
Checkpoint 1423545582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,792.54904
Policy Entropy: 2.97774
Value Function Loss: 0.00488

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.61263
Value Function Update Magnitude: 0.61231

Collected Steps per Second: 23,423.70108
Overall Steps per Second: 10,905.63336

Timestep Collection Time: 2.13502
Timestep Consumption Time: 2.45069
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.58570

Cumulative Model Updates: 170,696
Cumulative Timesteps: 1,423,595,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,476.52947
Policy Entropy: 2.99343
Value Function Loss: 0.00452

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.60864
Value Function Update Magnitude: 0.59184

Collected Steps per Second: 22,989.55390
Overall Steps per Second: 10,807.45388

Timestep Collection Time: 2.17568
Timestep Consumption Time: 2.45242
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.62810

Cumulative Model Updates: 170,702
Cumulative Timesteps: 1,423,645,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1423645610...
Checkpoint 1423645610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,088.26013
Policy Entropy: 3.00012
Value Function Loss: 0.00421

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10342
Policy Update Magnitude: 0.59537
Value Function Update Magnitude: 0.56151

Collected Steps per Second: 23,177.35710
Overall Steps per Second: 10,682.76836

Timestep Collection Time: 2.15814
Timestep Consumption Time: 2.52417
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.68231

Cumulative Model Updates: 170,708
Cumulative Timesteps: 1,423,695,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,931.99798
Policy Entropy: 2.98700
Value Function Loss: 0.00473

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.61514
Value Function Update Magnitude: 0.56900

Collected Steps per Second: 22,816.31064
Overall Steps per Second: 10,682.59921

Timestep Collection Time: 2.19255
Timestep Consumption Time: 2.49039
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.68294

Cumulative Model Updates: 170,714
Cumulative Timesteps: 1,423,745,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1423745656...
Checkpoint 1423745656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,257.30811
Policy Entropy: 2.96224
Value Function Loss: 0.00453

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.62135
Value Function Update Magnitude: 0.59125

Collected Steps per Second: 23,139.65522
Overall Steps per Second: 10,922.24278

Timestep Collection Time: 2.16166
Timestep Consumption Time: 2.41799
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.57965

Cumulative Model Updates: 170,720
Cumulative Timesteps: 1,423,795,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.57010
Policy Entropy: 2.96125
Value Function Loss: 0.00493

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.61253
Value Function Update Magnitude: 0.59041

Collected Steps per Second: 23,029.45427
Overall Steps per Second: 10,840.78102

Timestep Collection Time: 2.17200
Timestep Consumption Time: 2.44206
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.61406

Cumulative Model Updates: 170,726
Cumulative Timesteps: 1,423,845,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1423845696...
Checkpoint 1423845696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,807.76017
Policy Entropy: 2.96375
Value Function Loss: 0.00503

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.61287
Value Function Update Magnitude: 0.57363

Collected Steps per Second: 22,489.97790
Overall Steps per Second: 10,761.08622

Timestep Collection Time: 2.22321
Timestep Consumption Time: 2.42316
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.64637

Cumulative Model Updates: 170,732
Cumulative Timesteps: 1,423,895,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.54679
Policy Entropy: 2.97100
Value Function Loss: 0.00526

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.61702
Value Function Update Magnitude: 0.59118

Collected Steps per Second: 22,767.67573
Overall Steps per Second: 10,785.65658

Timestep Collection Time: 2.19724
Timestep Consumption Time: 2.44096
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.63820

Cumulative Model Updates: 170,738
Cumulative Timesteps: 1,423,945,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1423945722...
Checkpoint 1423945722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,185.66056
Policy Entropy: 2.95116
Value Function Loss: 0.00507

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.61598
Value Function Update Magnitude: 0.58603

Collected Steps per Second: 22,515.70196
Overall Steps per Second: 10,763.06095

Timestep Collection Time: 2.22103
Timestep Consumption Time: 2.42523
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.64626

Cumulative Model Updates: 170,744
Cumulative Timesteps: 1,423,995,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,279.57107
Policy Entropy: 2.97320
Value Function Loss: 0.00496

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.60813
Value Function Update Magnitude: 0.56629

Collected Steps per Second: 22,767.22781
Overall Steps per Second: 10,800.45456

Timestep Collection Time: 2.19684
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.63092

Cumulative Model Updates: 170,750
Cumulative Timesteps: 1,424,045,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1424045746...
Checkpoint 1424045746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.12758
Policy Entropy: 2.98902
Value Function Loss: 0.00487

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.60717
Value Function Update Magnitude: 0.57522

Collected Steps per Second: 23,151.00065
Overall Steps per Second: 10,648.22580

Timestep Collection Time: 2.16103
Timestep Consumption Time: 2.53741
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.69844

Cumulative Model Updates: 170,756
Cumulative Timesteps: 1,424,095,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,307.10612
Policy Entropy: 3.00397
Value Function Loss: 0.00487

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.60173
Value Function Update Magnitude: 0.57788

Collected Steps per Second: 23,043.51288
Overall Steps per Second: 10,839.39352

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.44378
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61428

Cumulative Model Updates: 170,762
Cumulative Timesteps: 1,424,145,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1424145792...
Checkpoint 1424145792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,213.84375
Policy Entropy: 3.00288
Value Function Loss: 0.00476

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.59196
Value Function Update Magnitude: 0.56181

Collected Steps per Second: 23,102.36266
Overall Steps per Second: 10,786.79897

Timestep Collection Time: 2.16549
Timestep Consumption Time: 2.47240
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.63789

Cumulative Model Updates: 170,768
Cumulative Timesteps: 1,424,195,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.33095
Policy Entropy: 3.00323
Value Function Loss: 0.00489

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.59437
Value Function Update Magnitude: 0.57599

Collected Steps per Second: 23,263.37977
Overall Steps per Second: 10,893.23575

Timestep Collection Time: 2.14982
Timestep Consumption Time: 2.44129
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.59111

Cumulative Model Updates: 170,774
Cumulative Timesteps: 1,424,245,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1424245832...
Checkpoint 1424245832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.87936
Policy Entropy: 3.00967
Value Function Loss: 0.00466

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.59556
Value Function Update Magnitude: 0.56707

Collected Steps per Second: 23,095.33465
Overall Steps per Second: 10,842.17779

Timestep Collection Time: 2.16503
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.61180

Cumulative Model Updates: 170,780
Cumulative Timesteps: 1,424,295,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,316.93738
Policy Entropy: 3.01899
Value Function Loss: 0.00443

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.58665
Value Function Update Magnitude: 0.54529

Collected Steps per Second: 23,239.11425
Overall Steps per Second: 10,727.46866

Timestep Collection Time: 2.15266
Timestep Consumption Time: 2.51069
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.66336

Cumulative Model Updates: 170,786
Cumulative Timesteps: 1,424,345,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1424345860...
Checkpoint 1424345860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,456.05778
Policy Entropy: 3.02798
Value Function Loss: 0.00438

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.57851
Value Function Update Magnitude: 0.53019

Collected Steps per Second: 22,405.49248
Overall Steps per Second: 10,594.79191

Timestep Collection Time: 2.23276
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.72175

Cumulative Model Updates: 170,792
Cumulative Timesteps: 1,424,395,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,055.36573
Policy Entropy: 3.02639
Value Function Loss: 0.00441

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.58340
Value Function Update Magnitude: 0.53288

Collected Steps per Second: 22,912.90065
Overall Steps per Second: 10,812.89168

Timestep Collection Time: 2.18279
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.62540

Cumulative Model Updates: 170,798
Cumulative Timesteps: 1,424,445,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1424445900...
Checkpoint 1424445900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.45386
Policy Entropy: 3.01330
Value Function Loss: 0.00426

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.57424
Value Function Update Magnitude: 0.53994

Collected Steps per Second: 22,481.47686
Overall Steps per Second: 10,719.40122

Timestep Collection Time: 2.22423
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.66481

Cumulative Model Updates: 170,804
Cumulative Timesteps: 1,424,495,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,560.27711
Policy Entropy: 3.01353
Value Function Loss: 0.00411

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.56475
Value Function Update Magnitude: 0.54042

Collected Steps per Second: 22,787.48324
Overall Steps per Second: 10,649.18043

Timestep Collection Time: 2.19533
Timestep Consumption Time: 2.50231
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69764

Cumulative Model Updates: 170,810
Cumulative Timesteps: 1,424,545,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1424545930...
Checkpoint 1424545930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,482.31836
Policy Entropy: 3.01930
Value Function Loss: 0.00436

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.57402
Value Function Update Magnitude: 0.55998

Collected Steps per Second: 23,367.49755
Overall Steps per Second: 10,829.86247

Timestep Collection Time: 2.13972
Timestep Consumption Time: 2.47714
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61686

Cumulative Model Updates: 170,816
Cumulative Timesteps: 1,424,595,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,087.61975
Policy Entropy: 3.03277
Value Function Loss: 0.00460

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.59042
Value Function Update Magnitude: 0.58356

Collected Steps per Second: 23,370.26703
Overall Steps per Second: 10,948.73328

Timestep Collection Time: 2.14041
Timestep Consumption Time: 2.42834
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.56875

Cumulative Model Updates: 170,822
Cumulative Timesteps: 1,424,645,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1424645952...
Checkpoint 1424645952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,790.93523
Policy Entropy: 3.02356
Value Function Loss: 0.00440

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.58479
Value Function Update Magnitude: 0.58292

Collected Steps per Second: 23,087.92477
Overall Steps per Second: 10,685.37080

Timestep Collection Time: 2.16624
Timestep Consumption Time: 2.51436
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.68060

Cumulative Model Updates: 170,828
Cumulative Timesteps: 1,424,695,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.85643
Policy Entropy: 3.02371
Value Function Loss: 0.00439

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.57204

Collected Steps per Second: 23,086.98872
Overall Steps per Second: 10,861.37818

Timestep Collection Time: 2.16624
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.60457

Cumulative Model Updates: 170,834
Cumulative Timesteps: 1,424,745,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1424745978...
Checkpoint 1424745978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,880.75825
Policy Entropy: 3.04159
Value Function Loss: 0.00415

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10489
Policy Update Magnitude: 0.57654
Value Function Update Magnitude: 0.55250

Collected Steps per Second: 22,971.67245
Overall Steps per Second: 10,656.00527

Timestep Collection Time: 2.17781
Timestep Consumption Time: 2.51700
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.69482

Cumulative Model Updates: 170,840
Cumulative Timesteps: 1,424,796,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,744.75972
Policy Entropy: 3.05285
Value Function Loss: 0.00472

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.57985
Value Function Update Magnitude: 0.54998

Collected Steps per Second: 23,155.15552
Overall Steps per Second: 10,864.33803

Timestep Collection Time: 2.15943
Timestep Consumption Time: 2.44296
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.60240

Cumulative Model Updates: 170,846
Cumulative Timesteps: 1,424,846,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1424846008...
Checkpoint 1424846008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,481.48272
Policy Entropy: 3.03069
Value Function Loss: 0.00485

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.59486
Value Function Update Magnitude: 0.55298

Collected Steps per Second: 22,703.72479
Overall Steps per Second: 10,691.12192

Timestep Collection Time: 2.20334
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.67902

Cumulative Model Updates: 170,852
Cumulative Timesteps: 1,424,896,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.20509
Policy Entropy: 3.02435
Value Function Loss: 0.00481

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.59296
Value Function Update Magnitude: 0.54845

Collected Steps per Second: 22,959.44419
Overall Steps per Second: 10,849.29921

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61283

Cumulative Model Updates: 170,858
Cumulative Timesteps: 1,424,946,078

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1424946078...
Checkpoint 1424946078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,735.60322
Policy Entropy: 3.02665
Value Function Loss: 0.00440

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.57832
Value Function Update Magnitude: 0.55017

Collected Steps per Second: 22,673.78091
Overall Steps per Second: 10,725.52241

Timestep Collection Time: 2.20607
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.66364

Cumulative Model Updates: 170,864
Cumulative Timesteps: 1,424,996,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.34521
Policy Entropy: 3.03715
Value Function Loss: 0.00420

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.56589
Value Function Update Magnitude: 0.52705

Collected Steps per Second: 22,551.62610
Overall Steps per Second: 10,615.75201

Timestep Collection Time: 2.21909
Timestep Consumption Time: 2.49504
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.71413

Cumulative Model Updates: 170,870
Cumulative Timesteps: 1,425,046,142

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1425046142...
Checkpoint 1425046142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,776.89281
Policy Entropy: 3.03939
Value Function Loss: 0.00414

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.56382
Value Function Update Magnitude: 0.51592

Collected Steps per Second: 23,250.87779
Overall Steps per Second: 10,928.46829

Timestep Collection Time: 2.15071
Timestep Consumption Time: 2.42504
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.57576

Cumulative Model Updates: 170,876
Cumulative Timesteps: 1,425,096,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,516.15063
Policy Entropy: 3.03575
Value Function Loss: 0.00426

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11896
Policy Update Magnitude: 0.56763
Value Function Update Magnitude: 0.50183

Collected Steps per Second: 22,848.59943
Overall Steps per Second: 10,791.64445

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.63470

Cumulative Model Updates: 170,882
Cumulative Timesteps: 1,425,146,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1425146164...
Checkpoint 1425146164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.37094
Policy Entropy: 3.03468
Value Function Loss: 0.00418

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11796
Policy Update Magnitude: 0.56226
Value Function Update Magnitude: 0.48766

Collected Steps per Second: 23,146.56023
Overall Steps per Second: 10,747.66765

Timestep Collection Time: 2.16041
Timestep Consumption Time: 2.49232
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.65273

Cumulative Model Updates: 170,888
Cumulative Timesteps: 1,425,196,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,883.10464
Policy Entropy: 3.02429
Value Function Loss: 0.00427

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.56325
Value Function Update Magnitude: 0.47176

Collected Steps per Second: 23,164.33745
Overall Steps per Second: 10,852.54724

Timestep Collection Time: 2.15849
Timestep Consumption Time: 2.44872
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60721

Cumulative Model Updates: 170,894
Cumulative Timesteps: 1,425,246,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1425246170...
Checkpoint 1425246170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,123.84265
Policy Entropy: 3.02493
Value Function Loss: 0.00419

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.56840
Value Function Update Magnitude: 0.46226

Collected Steps per Second: 23,037.33530
Overall Steps per Second: 10,634.40887

Timestep Collection Time: 2.17091
Timestep Consumption Time: 2.53194
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.70285

Cumulative Model Updates: 170,900
Cumulative Timesteps: 1,425,296,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.47936
Policy Entropy: 3.03434
Value Function Loss: 0.00431

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.56525
Value Function Update Magnitude: 0.45044

Collected Steps per Second: 22,942.82143
Overall Steps per Second: 10,873.47085

Timestep Collection Time: 2.18003
Timestep Consumption Time: 2.41979
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.59982

Cumulative Model Updates: 170,906
Cumulative Timesteps: 1,425,346,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1425346198...
Checkpoint 1425346198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,671.35065
Policy Entropy: 3.03918
Value Function Loss: 0.00439

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10614
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.46524

Collected Steps per Second: 22,810.16094
Overall Steps per Second: 10,768.92255

Timestep Collection Time: 2.19323
Timestep Consumption Time: 2.45236
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.64559

Cumulative Model Updates: 170,912
Cumulative Timesteps: 1,425,396,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,230.20506
Policy Entropy: 3.02978
Value Function Loss: 0.00431

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.57390
Value Function Update Magnitude: 0.47081

Collected Steps per Second: 22,751.16979
Overall Steps per Second: 10,785.40181

Timestep Collection Time: 2.19892
Timestep Consumption Time: 2.43957
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.63849

Cumulative Model Updates: 170,918
Cumulative Timesteps: 1,425,446,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1425446254...
Checkpoint 1425446254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,183.01352
Policy Entropy: 3.02221
Value Function Loss: 0.00445

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.57283
Value Function Update Magnitude: 0.47054

Collected Steps per Second: 22,713.63070
Overall Steps per Second: 10,725.19737

Timestep Collection Time: 2.20159
Timestep Consumption Time: 2.46089
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.66248

Cumulative Model Updates: 170,924
Cumulative Timesteps: 1,425,496,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,740.90182
Policy Entropy: 3.00903
Value Function Loss: 0.00443

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.58399
Value Function Update Magnitude: 0.49403

Collected Steps per Second: 22,711.81897
Overall Steps per Second: 10,636.30365

Timestep Collection Time: 2.20247
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.70295

Cumulative Model Updates: 170,930
Cumulative Timesteps: 1,425,546,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1425546282...
Checkpoint 1425546282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.71814
Policy Entropy: 2.99775
Value Function Loss: 0.00471

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.59369
Value Function Update Magnitude: 0.50775

Collected Steps per Second: 22,750.49190
Overall Steps per Second: 10,675.58433

Timestep Collection Time: 2.19881
Timestep Consumption Time: 2.48702
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.68583

Cumulative Model Updates: 170,936
Cumulative Timesteps: 1,425,596,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,279.23137
Policy Entropy: 2.99415
Value Function Loss: 0.00461

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.59837
Value Function Update Magnitude: 0.50965

Collected Steps per Second: 23,314.34150
Overall Steps per Second: 10,684.44265

Timestep Collection Time: 2.14520
Timestep Consumption Time: 2.53581
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.68101

Cumulative Model Updates: 170,942
Cumulative Timesteps: 1,425,646,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1425646320...
Checkpoint 1425646320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,459.98088
Policy Entropy: 2.98816
Value Function Loss: 0.00488

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.59997
Value Function Update Magnitude: 0.51473

Collected Steps per Second: 23,046.54044
Overall Steps per Second: 10,683.83510

Timestep Collection Time: 2.16961
Timestep Consumption Time: 2.51054
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.68015

Cumulative Model Updates: 170,948
Cumulative Timesteps: 1,425,696,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,404.77909
Policy Entropy: 2.98908
Value Function Loss: 0.00441

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.59776
Value Function Update Magnitude: 0.53321

Collected Steps per Second: 23,203.48726
Overall Steps per Second: 10,912.97498

Timestep Collection Time: 2.15502
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.58207

Cumulative Model Updates: 170,954
Cumulative Timesteps: 1,425,746,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1425746326...
Checkpoint 1425746326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,302.10877
Policy Entropy: 2.98175
Value Function Loss: 0.00410

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.58487
Value Function Update Magnitude: 0.52501

Collected Steps per Second: 23,162.41491
Overall Steps per Second: 10,754.45701

Timestep Collection Time: 2.15893
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.64979

Cumulative Model Updates: 170,960
Cumulative Timesteps: 1,425,796,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,712.80818
Policy Entropy: 2.99421
Value Function Loss: 0.00368

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.48145

Collected Steps per Second: 23,098.01730
Overall Steps per Second: 10,748.67557

Timestep Collection Time: 2.16581
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.65415

Cumulative Model Updates: 170,966
Cumulative Timesteps: 1,425,846,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1425846358...
Checkpoint 1425846358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,001.69298
Policy Entropy: 2.99571
Value Function Loss: 0.00389

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.46713

Collected Steps per Second: 22,910.02897
Overall Steps per Second: 10,681.79439

Timestep Collection Time: 2.18324
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.68255

Cumulative Model Updates: 170,972
Cumulative Timesteps: 1,425,896,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,316.22671
Policy Entropy: 2.98905
Value Function Loss: 0.00391

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.47344

Collected Steps per Second: 22,783.80148
Overall Steps per Second: 10,802.52328

Timestep Collection Time: 2.19595
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.63151

Cumulative Model Updates: 170,978
Cumulative Timesteps: 1,425,946,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1425946408...
Checkpoint 1425946408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.29800
Policy Entropy: 2.98030
Value Function Loss: 0.00418

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.57611
Value Function Update Magnitude: 0.46362

Collected Steps per Second: 22,371.53682
Overall Steps per Second: 10,639.72495

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.46439
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.69937

Cumulative Model Updates: 170,984
Cumulative Timesteps: 1,425,996,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.50477
Policy Entropy: 2.98758
Value Function Loss: 0.00451

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.58395
Value Function Update Magnitude: 0.46816

Collected Steps per Second: 22,789.35116
Overall Steps per Second: 10,653.15438

Timestep Collection Time: 2.19506
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.69570

Cumulative Model Updates: 170,990
Cumulative Timesteps: 1,426,046,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1426046432...
Checkpoint 1426046432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.89657
Policy Entropy: 2.98156
Value Function Loss: 0.00496

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.59608
Value Function Update Magnitude: 0.49641

Collected Steps per Second: 22,558.80925
Overall Steps per Second: 10,611.10045

Timestep Collection Time: 2.21652
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.71224

Cumulative Model Updates: 170,996
Cumulative Timesteps: 1,426,096,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.19216
Policy Entropy: 2.99933
Value Function Loss: 0.00473

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.58855
Value Function Update Magnitude: 0.52410

Collected Steps per Second: 23,056.73519
Overall Steps per Second: 10,793.85860

Timestep Collection Time: 2.16908
Timestep Consumption Time: 2.46429
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.63338

Cumulative Model Updates: 171,002
Cumulative Timesteps: 1,426,146,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1426146446...
Checkpoint 1426146446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,406.23198
Policy Entropy: 3.00164
Value Function Loss: 0.00433

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.56835
Value Function Update Magnitude: 0.51567

Collected Steps per Second: 23,140.24896
Overall Steps per Second: 10,683.92664

Timestep Collection Time: 2.16091
Timestep Consumption Time: 2.51939
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.68030

Cumulative Model Updates: 171,008
Cumulative Timesteps: 1,426,196,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,378.91502
Policy Entropy: 3.01559
Value Function Loss: 0.00431

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.56439
Value Function Update Magnitude: 0.48205

Collected Steps per Second: 23,358.86746
Overall Steps per Second: 10,862.53138

Timestep Collection Time: 2.14120
Timestep Consumption Time: 2.46325
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.60445

Cumulative Model Updates: 171,014
Cumulative Timesteps: 1,426,246,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1426246466...
Checkpoint 1426246466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,222.32479
Policy Entropy: 3.00509
Value Function Loss: 0.00439

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.56482
Value Function Update Magnitude: 0.48803

Collected Steps per Second: 23,228.91159
Overall Steps per Second: 10,776.90357

Timestep Collection Time: 2.15335
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.64141

Cumulative Model Updates: 171,020
Cumulative Timesteps: 1,426,296,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,028.25852
Policy Entropy: 3.00204
Value Function Loss: 0.00422

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.49475

Collected Steps per Second: 23,370.17027
Overall Steps per Second: 10,757.26751

Timestep Collection Time: 2.14068
Timestep Consumption Time: 2.50995
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.65062

Cumulative Model Updates: 171,026
Cumulative Timesteps: 1,426,346,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1426346514...
Checkpoint 1426346514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,592.56740
Policy Entropy: 2.98276
Value Function Loss: 0.00433

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.57616
Value Function Update Magnitude: 0.50438

Collected Steps per Second: 22,968.18158
Overall Steps per Second: 10,768.98839

Timestep Collection Time: 2.17814
Timestep Consumption Time: 2.46742
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.64556

Cumulative Model Updates: 171,032
Cumulative Timesteps: 1,426,396,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,802.72227
Policy Entropy: 2.97116
Value Function Loss: 0.00450

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.58560
Value Function Update Magnitude: 0.50881

Collected Steps per Second: 23,022.93016
Overall Steps per Second: 10,825.23086

Timestep Collection Time: 2.17201
Timestep Consumption Time: 2.44738
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.61939

Cumulative Model Updates: 171,038
Cumulative Timesteps: 1,426,446,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1426446548...
Checkpoint 1426446548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,469.31718
Policy Entropy: 2.96386
Value Function Loss: 0.00469

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.59114
Value Function Update Magnitude: 0.51464

Collected Steps per Second: 22,285.66146
Overall Steps per Second: 10,599.54812

Timestep Collection Time: 2.24449
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.71907

Cumulative Model Updates: 171,044
Cumulative Timesteps: 1,426,496,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,414.06231
Policy Entropy: 2.98573
Value Function Loss: 0.00452

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.59792
Value Function Update Magnitude: 0.50915

Collected Steps per Second: 22,988.34936
Overall Steps per Second: 10,882.56440

Timestep Collection Time: 2.17554
Timestep Consumption Time: 2.42007
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.59561

Cumulative Model Updates: 171,050
Cumulative Timesteps: 1,426,546,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1426546580...
Checkpoint 1426546580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,844.49410
Policy Entropy: 2.98887
Value Function Loss: 0.00422

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.58823
Value Function Update Magnitude: 0.49633

Collected Steps per Second: 22,542.38530
Overall Steps per Second: 10,682.07722

Timestep Collection Time: 2.21849
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.68167

Cumulative Model Updates: 171,056
Cumulative Timesteps: 1,426,596,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,144.38385
Policy Entropy: 3.00015
Value Function Loss: 0.00419

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.47742

Collected Steps per Second: 22,678.91037
Overall Steps per Second: 10,600.09834

Timestep Collection Time: 2.20654
Timestep Consumption Time: 2.51436
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.72090

Cumulative Model Updates: 171,062
Cumulative Timesteps: 1,426,646,632

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1426646632...
Checkpoint 1426646632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,308.31679
Policy Entropy: 2.99850
Value Function Loss: 0.00446

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.58490
Value Function Update Magnitude: 0.47870

Collected Steps per Second: 23,175.25669
Overall Steps per Second: 10,858.54149

Timestep Collection Time: 2.15799
Timestep Consumption Time: 2.44778
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60578

Cumulative Model Updates: 171,068
Cumulative Timesteps: 1,426,696,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,290.25434
Policy Entropy: 2.99070
Value Function Loss: 0.00473

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.59316
Value Function Update Magnitude: 0.49206

Collected Steps per Second: 22,821.43480
Overall Steps per Second: 10,621.56946

Timestep Collection Time: 2.19206
Timestep Consumption Time: 2.51779
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.70985

Cumulative Model Updates: 171,074
Cumulative Timesteps: 1,426,746,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1426746670...
Checkpoint 1426746670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.86404
Policy Entropy: 2.99213
Value Function Loss: 0.00469

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.58751
Value Function Update Magnitude: 0.50801

Collected Steps per Second: 23,370.73467
Overall Steps per Second: 10,820.42879

Timestep Collection Time: 2.13951
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.62107

Cumulative Model Updates: 171,080
Cumulative Timesteps: 1,426,796,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,247.30750
Policy Entropy: 3.00326
Value Function Loss: 0.00414

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.57285
Value Function Update Magnitude: 0.49507

Collected Steps per Second: 23,362.83216
Overall Steps per Second: 10,780.78180

Timestep Collection Time: 2.14032
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.63825

Cumulative Model Updates: 171,086
Cumulative Timesteps: 1,426,846,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1426846676...
Checkpoint 1426846676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.81654
Policy Entropy: 3.01130
Value Function Loss: 0.00401

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.56901
Value Function Update Magnitude: 0.48959

Collected Steps per Second: 23,151.03418
Overall Steps per Second: 10,881.07578

Timestep Collection Time: 2.15999
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.59569

Cumulative Model Updates: 171,092
Cumulative Timesteps: 1,426,896,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.16959
Policy Entropy: 3.01251
Value Function Loss: 0.00398

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.57165
Value Function Update Magnitude: 0.48940

Collected Steps per Second: 22,903.80015
Overall Steps per Second: 10,683.91953

Timestep Collection Time: 2.18366
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.68124

Cumulative Model Updates: 171,098
Cumulative Timesteps: 1,426,946,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1426946696...
Checkpoint 1426946696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.43144
Policy Entropy: 3.01871
Value Function Loss: 0.00412

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.56348
Value Function Update Magnitude: 0.47815

Collected Steps per Second: 22,622.18370
Overall Steps per Second: 10,630.89333

Timestep Collection Time: 2.21049
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70384

Cumulative Model Updates: 171,104
Cumulative Timesteps: 1,426,996,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,121.02383
Policy Entropy: 3.03451
Value Function Loss: 0.00407

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.55175
Value Function Update Magnitude: 0.46707

Collected Steps per Second: 22,867.41617
Overall Steps per Second: 10,852.90822

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.42141
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.60872

Cumulative Model Updates: 171,110
Cumulative Timesteps: 1,427,046,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1427046720...
Checkpoint 1427046720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,343.19636
Policy Entropy: 3.02794
Value Function Loss: 0.00476

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.56303
Value Function Update Magnitude: 0.49470

Collected Steps per Second: 22,611.66033
Overall Steps per Second: 10,676.46730

Timestep Collection Time: 2.21178
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.68432

Cumulative Model Updates: 171,116
Cumulative Timesteps: 1,427,096,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,100.30369
Policy Entropy: 3.02256
Value Function Loss: 0.00458

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.56829
Value Function Update Magnitude: 0.52472

Collected Steps per Second: 22,915.59969
Overall Steps per Second: 10,842.60055

Timestep Collection Time: 2.18218
Timestep Consumption Time: 2.42981
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.61199

Cumulative Model Updates: 171,122
Cumulative Timesteps: 1,427,146,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1427146738...
Checkpoint 1427146738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,622.51778
Policy Entropy: 3.02645
Value Function Loss: 0.00479

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.57088
Value Function Update Magnitude: 0.52890

Collected Steps per Second: 22,873.24304
Overall Steps per Second: 10,609.00658

Timestep Collection Time: 2.18631
Timestep Consumption Time: 2.52742
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.71373

Cumulative Model Updates: 171,128
Cumulative Timesteps: 1,427,196,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.07041
Policy Entropy: 3.02969
Value Function Loss: 0.00445

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.56698
Value Function Update Magnitude: 0.53274

Collected Steps per Second: 22,099.02674
Overall Steps per Second: 10,562.49599

Timestep Collection Time: 2.26363
Timestep Consumption Time: 2.47237
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.73600

Cumulative Model Updates: 171,134
Cumulative Timesteps: 1,427,246,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1427246770...
Checkpoint 1427246770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,584.41441
Policy Entropy: 3.02120
Value Function Loss: 0.00437

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.56497
Value Function Update Magnitude: 0.51890

Collected Steps per Second: 22,318.40360
Overall Steps per Second: 10,505.27349

Timestep Collection Time: 2.24102
Timestep Consumption Time: 2.52002
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.76104

Cumulative Model Updates: 171,140
Cumulative Timesteps: 1,427,296,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,232.58157
Policy Entropy: 3.00618
Value Function Loss: 0.00443

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.56219
Value Function Update Magnitude: 0.48960

Collected Steps per Second: 22,872.49258
Overall Steps per Second: 10,809.70776

Timestep Collection Time: 2.18673
Timestep Consumption Time: 2.44022
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.62695

Cumulative Model Updates: 171,146
Cumulative Timesteps: 1,427,346,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1427346802...
Checkpoint 1427346802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.84802
Policy Entropy: 2.99866
Value Function Loss: 0.00445

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.56614
Value Function Update Magnitude: 0.47815

Collected Steps per Second: 22,713.82771
Overall Steps per Second: 10,771.67312

Timestep Collection Time: 2.20139
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.64199

Cumulative Model Updates: 171,152
Cumulative Timesteps: 1,427,396,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,623.48578
Policy Entropy: 3.00140
Value Function Loss: 0.00451

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.57821
Value Function Update Magnitude: 0.49199

Collected Steps per Second: 23,453.62014
Overall Steps per Second: 10,851.54295

Timestep Collection Time: 2.13204
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.60801

Cumulative Model Updates: 171,158
Cumulative Timesteps: 1,427,446,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1427446808...
Checkpoint 1427446808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,428.30469
Policy Entropy: 2.99801
Value Function Loss: 0.00433

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.58623
Value Function Update Magnitude: 0.51377

Collected Steps per Second: 22,823.26113
Overall Steps per Second: 10,658.10314

Timestep Collection Time: 2.19162
Timestep Consumption Time: 2.50152
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.69314

Cumulative Model Updates: 171,164
Cumulative Timesteps: 1,427,496,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.26728
Policy Entropy: 2.99873
Value Function Loss: 0.00428

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.59124
Value Function Update Magnitude: 0.52737

Collected Steps per Second: 23,628.42837
Overall Steps per Second: 10,925.80489

Timestep Collection Time: 2.11660
Timestep Consumption Time: 2.46082
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.57742

Cumulative Model Updates: 171,170
Cumulative Timesteps: 1,427,546,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1427546840...
Checkpoint 1427546840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,609.99040
Policy Entropy: 2.99946
Value Function Loss: 0.00408

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.58700
Value Function Update Magnitude: 0.52850

Collected Steps per Second: 23,118.14308
Overall Steps per Second: 10,684.02995

Timestep Collection Time: 2.16376
Timestep Consumption Time: 2.51819
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.68194

Cumulative Model Updates: 171,176
Cumulative Timesteps: 1,427,596,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,119.31967
Policy Entropy: 3.00522
Value Function Loss: 0.00430

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.58467
Value Function Update Magnitude: 0.50367

Collected Steps per Second: 23,458.02655
Overall Steps per Second: 10,878.71621

Timestep Collection Time: 2.13249
Timestep Consumption Time: 2.46585
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.59834

Cumulative Model Updates: 171,182
Cumulative Timesteps: 1,427,646,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1427646886...
Checkpoint 1427646886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,998.77936
Policy Entropy: 3.01296
Value Function Loss: 0.00440

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.57814
Value Function Update Magnitude: 0.48640

Collected Steps per Second: 22,759.22296
Overall Steps per Second: 10,636.18650

Timestep Collection Time: 2.19788
Timestep Consumption Time: 2.50512
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.70300

Cumulative Model Updates: 171,188
Cumulative Timesteps: 1,427,696,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.01991
Policy Entropy: 3.02399
Value Function Loss: 0.00417

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.56803
Value Function Update Magnitude: 0.49979

Collected Steps per Second: 22,652.83371
Overall Steps per Second: 10,652.37297

Timestep Collection Time: 2.20785
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.69510

Cumulative Model Updates: 171,194
Cumulative Timesteps: 1,427,746,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1427746922...
Checkpoint 1427746922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,073.07846
Policy Entropy: 3.01640
Value Function Loss: 0.00425

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.57388
Value Function Update Magnitude: 0.50171

Collected Steps per Second: 22,704.86495
Overall Steps per Second: 10,791.84476

Timestep Collection Time: 2.20226
Timestep Consumption Time: 2.43105
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.63331

Cumulative Model Updates: 171,200
Cumulative Timesteps: 1,427,796,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,546.18876
Policy Entropy: 3.00966
Value Function Loss: 0.00413

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.56830
Value Function Update Magnitude: 0.50898

Collected Steps per Second: 22,663.10872
Overall Steps per Second: 10,619.56453

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.50336
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.71074

Cumulative Model Updates: 171,206
Cumulative Timesteps: 1,427,846,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1427846950...
Checkpoint 1427846950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.21059
Policy Entropy: 2.98758
Value Function Loss: 0.00457

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.57194
Value Function Update Magnitude: 0.51925

Collected Steps per Second: 22,369.87275
Overall Steps per Second: 10,568.86123

Timestep Collection Time: 2.23577
Timestep Consumption Time: 2.49643
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.73220

Cumulative Model Updates: 171,212
Cumulative Timesteps: 1,427,896,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.71663
Policy Entropy: 2.99269
Value Function Loss: 0.00459

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.57930
Value Function Update Magnitude: 0.52482

Collected Steps per Second: 23,149.69777
Overall Steps per Second: 10,797.77911

Timestep Collection Time: 2.16003
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.63095

Cumulative Model Updates: 171,218
Cumulative Timesteps: 1,427,946,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1427946968...
Checkpoint 1427946968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.92366
Policy Entropy: 2.99147
Value Function Loss: 0.00504

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.58717
Value Function Update Magnitude: 0.54476

Collected Steps per Second: 22,774.31883
Overall Steps per Second: 10,680.33326

Timestep Collection Time: 2.19668
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.68412

Cumulative Model Updates: 171,224
Cumulative Timesteps: 1,427,996,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,169.70523
Policy Entropy: 2.97488
Value Function Loss: 0.00495

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.59969
Value Function Update Magnitude: 0.58220

Collected Steps per Second: 23,282.88383
Overall Steps per Second: 10,924.47006

Timestep Collection Time: 2.14767
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.57725

Cumulative Model Updates: 171,230
Cumulative Timesteps: 1,428,047,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1428047000...
Checkpoint 1428047000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.10085
Policy Entropy: 2.95478
Value Function Loss: 0.00506

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12237
Policy Update Magnitude: 0.60866
Value Function Update Magnitude: 0.59490

Collected Steps per Second: 22,863.31015
Overall Steps per Second: 10,682.51874

Timestep Collection Time: 2.18813
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.68317

Cumulative Model Updates: 171,236
Cumulative Timesteps: 1,428,097,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,729.59321
Policy Entropy: 2.94886
Value Function Loss: 0.00473

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.60452
Value Function Update Magnitude: 0.58625

Collected Steps per Second: 23,534.64515
Overall Steps per Second: 10,898.41517

Timestep Collection Time: 2.12572
Timestep Consumption Time: 2.46467
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.59039

Cumulative Model Updates: 171,242
Cumulative Timesteps: 1,428,147,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1428147056...
Checkpoint 1428147056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.85175
Policy Entropy: 2.96981
Value Function Loss: 0.00465

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.59311
Value Function Update Magnitude: 0.57013

Collected Steps per Second: 23,021.92439
Overall Steps per Second: 10,692.99833

Timestep Collection Time: 2.17306
Timestep Consumption Time: 2.50552
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.67858

Cumulative Model Updates: 171,248
Cumulative Timesteps: 1,428,197,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.13141
Policy Entropy: 2.97887
Value Function Loss: 0.00467

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.59504
Value Function Update Magnitude: 0.56349

Collected Steps per Second: 22,510.90068
Overall Steps per Second: 10,645.52387

Timestep Collection Time: 2.22186
Timestep Consumption Time: 2.47646
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.69831

Cumulative Model Updates: 171,254
Cumulative Timesteps: 1,428,247,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1428247100...
Checkpoint 1428247100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.81913
Policy Entropy: 2.98032
Value Function Loss: 0.00458

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.59588
Value Function Update Magnitude: 0.54099

Collected Steps per Second: 22,501.62715
Overall Steps per Second: 10,653.25497

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.69584

Cumulative Model Updates: 171,260
Cumulative Timesteps: 1,428,297,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,555.91918
Policy Entropy: 2.97885
Value Function Loss: 0.00457

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.57931
Value Function Update Magnitude: 0.51024

Collected Steps per Second: 23,090.44102
Overall Steps per Second: 10,648.18591

Timestep Collection Time: 2.16635
Timestep Consumption Time: 2.53135
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.69770

Cumulative Model Updates: 171,266
Cumulative Timesteps: 1,428,347,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1428347148...
Checkpoint 1428347148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,659.20946
Policy Entropy: 2.97315
Value Function Loss: 0.00439

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.58440
Value Function Update Magnitude: 0.49793

Collected Steps per Second: 22,768.77896
Overall Steps per Second: 10,667.92237

Timestep Collection Time: 2.19617
Timestep Consumption Time: 2.49116
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.68732

Cumulative Model Updates: 171,272
Cumulative Timesteps: 1,428,397,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.00500
Policy Entropy: 2.98326
Value Function Loss: 0.00475

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.59340
Value Function Update Magnitude: 0.51133

Collected Steps per Second: 22,936.53098
Overall Steps per Second: 10,814.54568

Timestep Collection Time: 2.18010
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.62377

Cumulative Model Updates: 171,278
Cumulative Timesteps: 1,428,447,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1428447156...
Checkpoint 1428447156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.64467
Policy Entropy: 2.98370
Value Function Loss: 0.00494

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.59727
Value Function Update Magnitude: 0.54165

Collected Steps per Second: 22,905.79754
Overall Steps per Second: 10,717.44050

Timestep Collection Time: 2.18294
Timestep Consumption Time: 2.48254
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.66548

Cumulative Model Updates: 171,284
Cumulative Timesteps: 1,428,497,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.56625
Policy Entropy: 2.99772
Value Function Loss: 0.00476

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.58666
Value Function Update Magnitude: 0.54182

Collected Steps per Second: 23,238.71419
Overall Steps per Second: 10,875.27214

Timestep Collection Time: 2.15167
Timestep Consumption Time: 2.44610
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.59777

Cumulative Model Updates: 171,290
Cumulative Timesteps: 1,428,547,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1428547160...
Checkpoint 1428547160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.15488
Policy Entropy: 2.98814
Value Function Loss: 0.00417

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.57075
Value Function Update Magnitude: 0.52144

Collected Steps per Second: 22,517.68702
Overall Steps per Second: 10,674.20250

Timestep Collection Time: 2.22128
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.68588

Cumulative Model Updates: 171,296
Cumulative Timesteps: 1,428,597,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,232.67086
Policy Entropy: 2.97843
Value Function Loss: 0.00432

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.51459

Collected Steps per Second: 23,302.25000
Overall Steps per Second: 10,962.48606

Timestep Collection Time: 2.14589
Timestep Consumption Time: 2.41549
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.56137

Cumulative Model Updates: 171,302
Cumulative Timesteps: 1,428,647,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1428647182...
Checkpoint 1428647182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.96334
Policy Entropy: 2.96978
Value Function Loss: 0.00465

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.60502
Value Function Update Magnitude: 0.51817

Collected Steps per Second: 22,659.64812
Overall Steps per Second: 10,609.45815

Timestep Collection Time: 2.20798
Timestep Consumption Time: 2.50781
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.71579

Cumulative Model Updates: 171,308
Cumulative Timesteps: 1,428,697,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,092.60589
Policy Entropy: 2.96015
Value Function Loss: 0.00512

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.62320
Value Function Update Magnitude: 0.52927

Collected Steps per Second: 22,939.43349
Overall Steps per Second: 10,849.57889

Timestep Collection Time: 2.18079
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61087

Cumulative Model Updates: 171,314
Cumulative Timesteps: 1,428,747,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1428747240...
Checkpoint 1428747240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.07576
Policy Entropy: 2.97145
Value Function Loss: 0.00482

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.61397
Value Function Update Magnitude: 0.54785

Collected Steps per Second: 22,682.51150
Overall Steps per Second: 10,708.48403

Timestep Collection Time: 2.20514
Timestep Consumption Time: 2.46574
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.67088

Cumulative Model Updates: 171,320
Cumulative Timesteps: 1,428,797,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,594.62701
Policy Entropy: 2.97356
Value Function Loss: 0.00458

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.60044
Value Function Update Magnitude: 0.53543

Collected Steps per Second: 22,392.77085
Overall Steps per Second: 10,910.62348

Timestep Collection Time: 2.23367
Timestep Consumption Time: 2.35067
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.58434

Cumulative Model Updates: 171,326
Cumulative Timesteps: 1,428,847,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1428847276...
Checkpoint 1428847276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,536.99565
Policy Entropy: 2.97860
Value Function Loss: 0.00485

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.61289
Value Function Update Magnitude: 0.53564

Collected Steps per Second: 21,596.05061
Overall Steps per Second: 10,632.15937

Timestep Collection Time: 2.31681
Timestep Consumption Time: 2.38910
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.70591

Cumulative Model Updates: 171,332
Cumulative Timesteps: 1,428,897,310

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,658.09439
Policy Entropy: 2.97053
Value Function Loss: 0.00477

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.61662
Value Function Update Magnitude: 0.54533

Collected Steps per Second: 22,671.82376
Overall Steps per Second: 10,878.85552

Timestep Collection Time: 2.20662
Timestep Consumption Time: 2.39203
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.59865

Cumulative Model Updates: 171,338
Cumulative Timesteps: 1,428,947,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1428947338...
Checkpoint 1428947338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,022.71899
Policy Entropy: 2.96683
Value Function Loss: 0.00460

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.61194
Value Function Update Magnitude: 0.53612

Collected Steps per Second: 22,373.31769
Overall Steps per Second: 10,714.89501

Timestep Collection Time: 2.23480
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.66640

Cumulative Model Updates: 171,344
Cumulative Timesteps: 1,428,997,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.99323
Policy Entropy: 2.96318
Value Function Loss: 0.00436

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11759
Policy Update Magnitude: 0.60435
Value Function Update Magnitude: 0.52797

Collected Steps per Second: 22,625.09771
Overall Steps per Second: 10,834.78173

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.40512
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.61532

Cumulative Model Updates: 171,350
Cumulative Timesteps: 1,429,047,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1429047344...
Checkpoint 1429047344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.62634
Policy Entropy: 2.97389
Value Function Loss: 0.00450

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.60492
Value Function Update Magnitude: 0.51771

Collected Steps per Second: 22,315.45213
Overall Steps per Second: 10,725.48252

Timestep Collection Time: 2.24132
Timestep Consumption Time: 2.42197
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.66329

Cumulative Model Updates: 171,356
Cumulative Timesteps: 1,429,097,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.41919
Policy Entropy: 2.97662
Value Function Loss: 0.00439

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.60061
Value Function Update Magnitude: 0.52303

Collected Steps per Second: 22,359.61342
Overall Steps per Second: 10,793.70951

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.39673
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.63344

Cumulative Model Updates: 171,362
Cumulative Timesteps: 1,429,147,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1429147372...
Checkpoint 1429147372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.26887
Policy Entropy: 2.96838
Value Function Loss: 0.00501

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.60138
Value Function Update Magnitude: 0.54370

Collected Steps per Second: 22,104.26249
Overall Steps per Second: 10,701.56682

Timestep Collection Time: 2.26228
Timestep Consumption Time: 2.41050
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.67277

Cumulative Model Updates: 171,368
Cumulative Timesteps: 1,429,197,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.06002
Policy Entropy: 2.97043
Value Function Loss: 0.00495

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.59988
Value Function Update Magnitude: 0.57314

Collected Steps per Second: 22,398.27227
Overall Steps per Second: 10,890.32916

Timestep Collection Time: 2.23276
Timestep Consumption Time: 2.35939
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59215

Cumulative Model Updates: 171,374
Cumulative Timesteps: 1,429,247,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1429247388...
Checkpoint 1429247388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.10869
Policy Entropy: 2.98968
Value Function Loss: 0.00448

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.55940

Collected Steps per Second: 21,754.68314
Overall Steps per Second: 10,683.24341

Timestep Collection Time: 2.29836
Timestep Consumption Time: 2.38187
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.68023

Cumulative Model Updates: 171,380
Cumulative Timesteps: 1,429,297,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.45743
Policy Entropy: 2.99441
Value Function Loss: 0.00460

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.57789
Value Function Update Magnitude: 0.52609

Collected Steps per Second: 22,286.45705
Overall Steps per Second: 10,839.35812

Timestep Collection Time: 2.24513
Timestep Consumption Time: 2.37101
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61614

Cumulative Model Updates: 171,386
Cumulative Timesteps: 1,429,347,424

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1429347424...
Checkpoint 1429347424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831.77221
Policy Entropy: 2.98708
Value Function Loss: 0.00452

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.58180
Value Function Update Magnitude: 0.53013

Collected Steps per Second: 21,980.91855
Overall Steps per Second: 10,685.89778

Timestep Collection Time: 2.27552
Timestep Consumption Time: 2.40523
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.68075

Cumulative Model Updates: 171,392
Cumulative Timesteps: 1,429,397,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.48299
Policy Entropy: 2.97380
Value Function Loss: 0.00472

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.58729
Value Function Update Magnitude: 0.52997

Collected Steps per Second: 22,690.13500
Overall Steps per Second: 10,601.51170

Timestep Collection Time: 2.20457
Timestep Consumption Time: 2.51381
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.71838

Cumulative Model Updates: 171,398
Cumulative Timesteps: 1,429,447,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1429447464...
Checkpoint 1429447464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,877.10763
Policy Entropy: 2.98860
Value Function Loss: 0.00455

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.58959
Value Function Update Magnitude: 0.51321

Collected Steps per Second: 23,226.91889
Overall Steps per Second: 10,928.95673

Timestep Collection Time: 2.15302
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.57573

Cumulative Model Updates: 171,404
Cumulative Timesteps: 1,429,497,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,325.12847
Policy Entropy: 2.99785
Value Function Loss: 0.00452

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.58974
Value Function Update Magnitude: 0.49973

Collected Steps per Second: 23,152.46137
Overall Steps per Second: 10,934.38759

Timestep Collection Time: 2.15960
Timestep Consumption Time: 2.41313
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.57273

Cumulative Model Updates: 171,410
Cumulative Timesteps: 1,429,547,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1429547472...
Checkpoint 1429547472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,065.44583
Policy Entropy: 3.00725
Value Function Loss: 0.00415

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.57382
Value Function Update Magnitude: 0.49260

Collected Steps per Second: 23,079.56151
Overall Steps per Second: 10,829.62946

Timestep Collection Time: 2.16737
Timestep Consumption Time: 2.45162
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.61899

Cumulative Model Updates: 171,416
Cumulative Timesteps: 1,429,597,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,804.97053
Policy Entropy: 3.00558
Value Function Loss: 0.00417

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.56812
Value Function Update Magnitude: 0.47973

Collected Steps per Second: 23,454.44144
Overall Steps per Second: 10,766.20891

Timestep Collection Time: 2.13179
Timestep Consumption Time: 2.51237
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.64416

Cumulative Model Updates: 171,422
Cumulative Timesteps: 1,429,647,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1429647494...
Checkpoint 1429647494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.38817
Policy Entropy: 2.99257
Value Function Loss: 0.00440

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.58027
Value Function Update Magnitude: 0.48362

Collected Steps per Second: 22,660.42961
Overall Steps per Second: 10,592.51230

Timestep Collection Time: 2.20649
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.72032

Cumulative Model Updates: 171,428
Cumulative Timesteps: 1,429,697,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.53372
Policy Entropy: 2.97975
Value Function Loss: 0.00432

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.57799
Value Function Update Magnitude: 0.49175

Collected Steps per Second: 22,531.44030
Overall Steps per Second: 10,609.84884

Timestep Collection Time: 2.21948
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.71336

Cumulative Model Updates: 171,434
Cumulative Timesteps: 1,429,747,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1429747502...
Checkpoint 1429747502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,742.20705
Policy Entropy: 3.00174
Value Function Loss: 0.00419

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.57270
Value Function Update Magnitude: 0.49163

Collected Steps per Second: 22,707.14790
Overall Steps per Second: 10,680.49603

Timestep Collection Time: 2.20239
Timestep Consumption Time: 2.47998
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.68237

Cumulative Model Updates: 171,440
Cumulative Timesteps: 1,429,797,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.73484
Policy Entropy: 3.02176
Value Function Loss: 0.00424

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.57164
Value Function Update Magnitude: 0.47961

Collected Steps per Second: 22,874.78449
Overall Steps per Second: 10,730.97592

Timestep Collection Time: 2.18677
Timestep Consumption Time: 2.47468
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.66146

Cumulative Model Updates: 171,446
Cumulative Timesteps: 1,429,847,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1429847534...
Checkpoint 1429847534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,151.52439
Policy Entropy: 3.02357
Value Function Loss: 0.00424

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.57132
Value Function Update Magnitude: 0.46494

Collected Steps per Second: 22,616.92546
Overall Steps per Second: 10,605.26758

Timestep Collection Time: 2.21215
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.71766

Cumulative Model Updates: 171,452
Cumulative Timesteps: 1,429,897,566

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.02893
Policy Entropy: 2.99404
Value Function Loss: 0.00455

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.58721
Value Function Update Magnitude: 0.46529

Collected Steps per Second: 22,889.56298
Overall Steps per Second: 10,838.98991

Timestep Collection Time: 2.18545
Timestep Consumption Time: 2.42974
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61519

Cumulative Model Updates: 171,458
Cumulative Timesteps: 1,429,947,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1429947590...
Checkpoint 1429947590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,423.54872
Policy Entropy: 2.96356
Value Function Loss: 0.00489

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.60072
Value Function Update Magnitude: 0.48210

Collected Steps per Second: 23,043.86632
Overall Steps per Second: 10,683.88323

Timestep Collection Time: 2.17056
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.68163

Cumulative Model Updates: 171,464
Cumulative Timesteps: 1,429,997,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,980.82694
Policy Entropy: 2.97494
Value Function Loss: 0.00498

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.59829
Value Function Update Magnitude: 0.50660

Collected Steps per Second: 23,210.86153
Overall Steps per Second: 10,885.41342

Timestep Collection Time: 2.15442
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.59385

Cumulative Model Updates: 171,470
Cumulative Timesteps: 1,430,047,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1430047614...
Checkpoint 1430047614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,237.26016
Policy Entropy: 3.00168
Value Function Loss: 0.00446

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11480
Policy Update Magnitude: 0.58803
Value Function Update Magnitude: 0.50347

Collected Steps per Second: 23,017.34657
Overall Steps per Second: 10,679.88303

Timestep Collection Time: 2.17340
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.68413

Cumulative Model Updates: 171,476
Cumulative Timesteps: 1,430,097,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085.40391
Policy Entropy: 3.01859
Value Function Loss: 0.00427

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.57985
Value Function Update Magnitude: 0.50659

Collected Steps per Second: 23,352.13175
Overall Steps per Second: 10,892.97741

Timestep Collection Time: 2.14199
Timestep Consumption Time: 2.44996
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.59195

Cumulative Model Updates: 171,482
Cumulative Timesteps: 1,430,147,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1430147660...
Checkpoint 1430147660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,028.00465
Policy Entropy: 3.01436
Value Function Loss: 0.00404

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.57172
Value Function Update Magnitude: 0.52120

Collected Steps per Second: 22,859.77160
Overall Steps per Second: 10,633.60600

Timestep Collection Time: 2.18769
Timestep Consumption Time: 2.51533
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.70301

Cumulative Model Updates: 171,488
Cumulative Timesteps: 1,430,197,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,183.52761
Policy Entropy: 3.01061
Value Function Loss: 0.00431

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.57129
Value Function Update Magnitude: 0.53863

Collected Steps per Second: 23,299.62800
Overall Steps per Second: 10,885.05889

Timestep Collection Time: 2.14639
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.59437

Cumulative Model Updates: 171,494
Cumulative Timesteps: 1,430,247,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1430247680...
Checkpoint 1430247680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,542.22651
Policy Entropy: 3.01429
Value Function Loss: 0.00395

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.50645

Collected Steps per Second: 22,414.43977
Overall Steps per Second: 10,731.16094

Timestep Collection Time: 2.23079
Timestep Consumption Time: 2.42872
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.65951

Cumulative Model Updates: 171,500
Cumulative Timesteps: 1,430,297,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.68195
Policy Entropy: 2.99253
Value Function Loss: 0.00430

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.57503
Value Function Update Magnitude: 0.47815

Collected Steps per Second: 22,803.02453
Overall Steps per Second: 10,864.87858

Timestep Collection Time: 2.19287
Timestep Consumption Time: 2.40949
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60235

Cumulative Model Updates: 171,506
Cumulative Timesteps: 1,430,347,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1430347686...
Checkpoint 1430347686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.38322
Policy Entropy: 2.98117
Value Function Loss: 0.00450

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12234
Policy Update Magnitude: 0.59019
Value Function Update Magnitude: 0.50095

Collected Steps per Second: 22,573.65480
Overall Steps per Second: 10,615.31766

Timestep Collection Time: 2.21577
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.71187

Cumulative Model Updates: 171,512
Cumulative Timesteps: 1,430,397,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,877.81195
Policy Entropy: 2.97543
Value Function Loss: 0.00455

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.60314
Value Function Update Magnitude: 0.52742

Collected Steps per Second: 22,823.65509
Overall Steps per Second: 10,681.28270

Timestep Collection Time: 2.19106
Timestep Consumption Time: 2.49077
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.68183

Cumulative Model Updates: 171,518
Cumulative Timesteps: 1,430,447,712

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1430447712...
Checkpoint 1430447712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.91518
Policy Entropy: 2.99217
Value Function Loss: 0.00432

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.59817
Value Function Update Magnitude: 0.52022

Collected Steps per Second: 23,190.39989
Overall Steps per Second: 10,793.04011

Timestep Collection Time: 2.15710
Timestep Consumption Time: 2.47774
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.63484

Cumulative Model Updates: 171,524
Cumulative Timesteps: 1,430,497,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.98901
Policy Entropy: 2.99453
Value Function Loss: 0.00438

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.59035
Value Function Update Magnitude: 0.51952

Collected Steps per Second: 23,296.66645
Overall Steps per Second: 10,943.70798

Timestep Collection Time: 2.14726
Timestep Consumption Time: 2.42377
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.57103

Cumulative Model Updates: 171,530
Cumulative Timesteps: 1,430,547,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1430547760...
Checkpoint 1430547760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.24421
Policy Entropy: 3.00841
Value Function Loss: 0.00440

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.58148
Value Function Update Magnitude: 0.50671

Collected Steps per Second: 22,998.59391
Overall Steps per Second: 10,748.36386

Timestep Collection Time: 2.17439
Timestep Consumption Time: 2.47822
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.65262

Cumulative Model Updates: 171,536
Cumulative Timesteps: 1,430,597,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,568.33504
Policy Entropy: 2.99266
Value Function Loss: 0.00455

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.58355
Value Function Update Magnitude: 0.50639

Collected Steps per Second: 23,325.45185
Overall Steps per Second: 10,868.04766

Timestep Collection Time: 2.14418
Timestep Consumption Time: 2.45775
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.60193

Cumulative Model Updates: 171,542
Cumulative Timesteps: 1,430,647,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1430647782...
Checkpoint 1430647782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,995.58502
Policy Entropy: 3.00670
Value Function Loss: 0.00442

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.59853
Value Function Update Magnitude: 0.51807

Collected Steps per Second: 22,985.98215
Overall Steps per Second: 10,684.38894

Timestep Collection Time: 2.17533
Timestep Consumption Time: 2.50459
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.67991

Cumulative Model Updates: 171,548
Cumulative Timesteps: 1,430,697,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,533.88082
Policy Entropy: 3.00146
Value Function Loss: 0.00440

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.59176
Value Function Update Magnitude: 0.51758

Collected Steps per Second: 23,431.85425
Overall Steps per Second: 10,871.63855

Timestep Collection Time: 2.13393
Timestep Consumption Time: 2.46537
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.59931

Cumulative Model Updates: 171,554
Cumulative Timesteps: 1,430,747,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1430747786...
Checkpoint 1430747786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,143.67810
Policy Entropy: 3.01777
Value Function Loss: 0.00451

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.58688
Value Function Update Magnitude: 0.50942

Collected Steps per Second: 22,610.51352
Overall Steps per Second: 10,627.94090

Timestep Collection Time: 2.21225
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.70646

Cumulative Model Updates: 171,560
Cumulative Timesteps: 1,430,797,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.39096
Policy Entropy: 2.99146
Value Function Loss: 0.00450

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.58932
Value Function Update Magnitude: 0.51591

Collected Steps per Second: 22,535.36764
Overall Steps per Second: 10,644.11632

Timestep Collection Time: 2.21927
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.69856

Cumulative Model Updates: 171,566
Cumulative Timesteps: 1,430,847,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1430847818...
Checkpoint 1430847818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.19849
Policy Entropy: 2.97811
Value Function Loss: 0.00436

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.58742
Value Function Update Magnitude: 0.51408

Collected Steps per Second: 22,554.94741
Overall Steps per Second: 10,661.02285

Timestep Collection Time: 2.21725
Timestep Consumption Time: 2.47367
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69092

Cumulative Model Updates: 171,572
Cumulative Timesteps: 1,430,897,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.68625
Policy Entropy: 2.98034
Value Function Loss: 0.00450

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.59263
Value Function Update Magnitude: 0.50383

Collected Steps per Second: 23,117.57286
Overall Steps per Second: 10,708.16876

Timestep Collection Time: 2.16338
Timestep Consumption Time: 2.50708
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.67045

Cumulative Model Updates: 171,578
Cumulative Timesteps: 1,430,947,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1430947840...
Checkpoint 1430947840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,278.71102
Policy Entropy: 2.99231
Value Function Loss: 0.00423

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.59328
Value Function Update Magnitude: 0.49330

Collected Steps per Second: 22,415.58823
Overall Steps per Second: 10,607.16800

Timestep Collection Time: 2.23104
Timestep Consumption Time: 2.48370
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.71474

Cumulative Model Updates: 171,584
Cumulative Timesteps: 1,430,997,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,631.91327
Policy Entropy: 3.00480
Value Function Loss: 0.00391

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.58114
Value Function Update Magnitude: 0.48487

Collected Steps per Second: 23,256.06377
Overall Steps per Second: 10,859.61437

Timestep Collection Time: 2.15041
Timestep Consumption Time: 2.45473
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.60514

Cumulative Model Updates: 171,590
Cumulative Timesteps: 1,431,047,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1431047860...
Checkpoint 1431047860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,583.83763
Policy Entropy: 3.00196
Value Function Loss: 0.00388

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.57093
Value Function Update Magnitude: 0.50009

Collected Steps per Second: 21,891.34380
Overall Steps per Second: 10,586.51472

Timestep Collection Time: 2.28401
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.72299

Cumulative Model Updates: 171,596
Cumulative Timesteps: 1,431,097,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,252.98219
Policy Entropy: 3.00936
Value Function Loss: 0.00383

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.57083
Value Function Update Magnitude: 0.49164

Collected Steps per Second: 21,843.03896
Overall Steps per Second: 10,558.08909

Timestep Collection Time: 2.28924
Timestep Consumption Time: 2.44684
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.73608

Cumulative Model Updates: 171,602
Cumulative Timesteps: 1,431,147,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1431147864...
Checkpoint 1431147864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,890.08325
Policy Entropy: 3.01475
Value Function Loss: 0.00377

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.55877
Value Function Update Magnitude: 0.48470

Collected Steps per Second: 21,893.37558
Overall Steps per Second: 10,598.02336

Timestep Collection Time: 2.28444
Timestep Consumption Time: 2.43475
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.71918

Cumulative Model Updates: 171,608
Cumulative Timesteps: 1,431,197,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,150.88555
Policy Entropy: 3.01041
Value Function Loss: 0.00354

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.54788
Value Function Update Magnitude: 0.46579

Collected Steps per Second: 22,043.11542
Overall Steps per Second: 10,657.88531

Timestep Collection Time: 2.26883
Timestep Consumption Time: 2.42366
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.69249

Cumulative Model Updates: 171,614
Cumulative Timesteps: 1,431,247,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1431247890...
Checkpoint 1431247890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,608.06047
Policy Entropy: 3.00722
Value Function Loss: 0.00378

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.56007
Value Function Update Magnitude: 0.46866

Collected Steps per Second: 22,235.75575
Overall Steps per Second: 10,823.91729

Timestep Collection Time: 2.24890
Timestep Consumption Time: 2.37105
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61995

Cumulative Model Updates: 171,620
Cumulative Timesteps: 1,431,297,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,149.62890
Policy Entropy: 2.99284
Value Function Loss: 0.00406

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.57425
Value Function Update Magnitude: 0.46950

Collected Steps per Second: 22,531.58046
Overall Steps per Second: 10,929.25247

Timestep Collection Time: 2.21920
Timestep Consumption Time: 2.35586
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.57506

Cumulative Model Updates: 171,626
Cumulative Timesteps: 1,431,347,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1431347898...
Checkpoint 1431347898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,310.96212
Policy Entropy: 3.01098
Value Function Loss: 0.00414

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.46563

Collected Steps per Second: 22,359.77937
Overall Steps per Second: 10,719.23030

Timestep Collection Time: 2.23669
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.66563

Cumulative Model Updates: 171,632
Cumulative Timesteps: 1,431,397,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,574.31445
Policy Entropy: 3.00627
Value Function Loss: 0.00428

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.57239
Value Function Update Magnitude: 0.47044

Collected Steps per Second: 22,687.01995
Overall Steps per Second: 10,911.76331

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.37935
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.58423

Cumulative Model Updates: 171,638
Cumulative Timesteps: 1,431,447,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1431447932...
Checkpoint 1431447932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,925.02029
Policy Entropy: 3.01819
Value Function Loss: 0.00436

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.48553

Collected Steps per Second: 22,288.13503
Overall Steps per Second: 10,632.78599

Timestep Collection Time: 2.24370
Timestep Consumption Time: 2.45948
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.70319

Cumulative Model Updates: 171,644
Cumulative Timesteps: 1,431,497,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,744.50409
Policy Entropy: 3.01354
Value Function Loss: 0.00432

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.50302

Collected Steps per Second: 23,031.44629
Overall Steps per Second: 10,895.72481

Timestep Collection Time: 2.17103
Timestep Consumption Time: 2.41811
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.58914

Cumulative Model Updates: 171,650
Cumulative Timesteps: 1,431,547,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1431547942...
Checkpoint 1431547942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,775.39944
Policy Entropy: 3.01057
Value Function Loss: 0.00418

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.57181
Value Function Update Magnitude: 0.49208

Collected Steps per Second: 22,733.08801
Overall Steps per Second: 10,691.33091

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.67856

Cumulative Model Updates: 171,656
Cumulative Timesteps: 1,431,597,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.16993
Policy Entropy: 3.01779
Value Function Loss: 0.00443

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.57387
Value Function Update Magnitude: 0.48878

Collected Steps per Second: 23,036.01651
Overall Steps per Second: 10,900.89425

Timestep Collection Time: 2.17069
Timestep Consumption Time: 2.41646
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.58715

Cumulative Model Updates: 171,662
Cumulative Timesteps: 1,431,647,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1431647966...
Checkpoint 1431647966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.59727
Policy Entropy: 3.02104
Value Function Loss: 0.00465

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.57771
Value Function Update Magnitude: 0.51147

Collected Steps per Second: 22,549.51020
Overall Steps per Second: 10,641.44852

Timestep Collection Time: 2.21823
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.70049

Cumulative Model Updates: 171,668
Cumulative Timesteps: 1,431,697,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,044.56160
Policy Entropy: 3.02468
Value Function Loss: 0.00458

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.51353

Collected Steps per Second: 22,895.05341
Overall Steps per Second: 10,829.61028

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.61882

Cumulative Model Updates: 171,674
Cumulative Timesteps: 1,431,748,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1431748006...
Checkpoint 1431748006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,446.80713
Policy Entropy: 3.01794
Value Function Loss: 0.00446

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.57681
Value Function Update Magnitude: 0.50127

Collected Steps per Second: 23,004.36998
Overall Steps per Second: 10,673.25158

Timestep Collection Time: 2.17420
Timestep Consumption Time: 2.51191
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.68611

Cumulative Model Updates: 171,680
Cumulative Timesteps: 1,431,798,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.06632
Policy Entropy: 3.01249
Value Function Loss: 0.00438

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.58494
Value Function Update Magnitude: 0.51822

Collected Steps per Second: 23,177.72181
Overall Steps per Second: 10,849.08771

Timestep Collection Time: 2.15845
Timestep Consumption Time: 2.45281
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.61126

Cumulative Model Updates: 171,686
Cumulative Timesteps: 1,431,848,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1431848050...
Checkpoint 1431848050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.07941
Policy Entropy: 3.01685
Value Function Loss: 0.00416

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.57618
Value Function Update Magnitude: 0.51843

Collected Steps per Second: 23,062.79338
Overall Steps per Second: 10,686.21642

Timestep Collection Time: 2.16843
Timestep Consumption Time: 2.51143
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.67986

Cumulative Model Updates: 171,692
Cumulative Timesteps: 1,431,898,060

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.93546
Policy Entropy: 3.02198
Value Function Loss: 0.00402

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.57179
Value Function Update Magnitude: 0.50463

Collected Steps per Second: 23,545.44553
Overall Steps per Second: 10,929.06419

Timestep Collection Time: 2.12449
Timestep Consumption Time: 2.45248
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.57697

Cumulative Model Updates: 171,698
Cumulative Timesteps: 1,431,948,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1431948082...
Checkpoint 1431948082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.26494
Policy Entropy: 3.04070
Value Function Loss: 0.00385

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.48445

Collected Steps per Second: 23,191.86303
Overall Steps per Second: 10,749.51647

Timestep Collection Time: 2.15670
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.65305

Cumulative Model Updates: 171,704
Cumulative Timesteps: 1,431,998,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,919.29409
Policy Entropy: 3.03888
Value Function Loss: 0.00396

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.55388
Value Function Update Magnitude: 0.48936

Collected Steps per Second: 23,407.49607
Overall Steps per Second: 10,810.28975

Timestep Collection Time: 2.13675
Timestep Consumption Time: 2.48995
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.62670

Cumulative Model Updates: 171,710
Cumulative Timesteps: 1,432,048,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1432048116...
Checkpoint 1432048116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.74011
Policy Entropy: 3.03745
Value Function Loss: 0.00411

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.50465

Collected Steps per Second: 22,423.01052
Overall Steps per Second: 10,638.89557

Timestep Collection Time: 2.23030
Timestep Consumption Time: 2.47038
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.70068

Cumulative Model Updates: 171,716
Cumulative Timesteps: 1,432,098,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007.58134
Policy Entropy: 3.02372
Value Function Loss: 0.00407

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.56158
Value Function Update Magnitude: 0.49617

Collected Steps per Second: 22,760.59806
Overall Steps per Second: 10,793.51102

Timestep Collection Time: 2.19748
Timestep Consumption Time: 2.43641
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.63390

Cumulative Model Updates: 171,722
Cumulative Timesteps: 1,432,148,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1432148142...
Checkpoint 1432148142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,988.48011
Policy Entropy: 3.03422
Value Function Loss: 0.00440

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.50576

Collected Steps per Second: 22,481.73387
Overall Steps per Second: 10,709.63734

Timestep Collection Time: 2.22483
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.67037

Cumulative Model Updates: 171,728
Cumulative Timesteps: 1,432,198,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999.34675
Policy Entropy: 3.01671
Value Function Loss: 0.00459

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.58096
Value Function Update Magnitude: 0.51303

Collected Steps per Second: 22,858.61549
Overall Steps per Second: 10,652.85911

Timestep Collection Time: 2.18850
Timestep Consumption Time: 2.50752
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.69602

Cumulative Model Updates: 171,734
Cumulative Timesteps: 1,432,248,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1432248186...
Checkpoint 1432248186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,489.69109
Policy Entropy: 2.99935
Value Function Loss: 0.00457

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.58599
Value Function Update Magnitude: 0.50649

Collected Steps per Second: 22,883.76858
Overall Steps per Second: 10,651.31015

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.50930
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.69426

Cumulative Model Updates: 171,740
Cumulative Timesteps: 1,432,298,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,014.84698
Policy Entropy: 2.98673
Value Function Loss: 0.00452

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.59242
Value Function Update Magnitude: 0.50587

Collected Steps per Second: 23,557.95722
Overall Steps per Second: 10,794.35934

Timestep Collection Time: 2.12276
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.63279

Cumulative Model Updates: 171,746
Cumulative Timesteps: 1,432,348,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1432348194...
Checkpoint 1432348194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,679.97392
Policy Entropy: 2.99755
Value Function Loss: 0.00447

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.59227
Value Function Update Magnitude: 0.51029

Collected Steps per Second: 22,950.52976
Overall Steps per Second: 10,724.70358

Timestep Collection Time: 2.17930
Timestep Consumption Time: 2.48433
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.66363

Cumulative Model Updates: 171,752
Cumulative Timesteps: 1,432,398,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,357.56681
Policy Entropy: 3.00514
Value Function Loss: 0.00447

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.60166
Value Function Update Magnitude: 0.52021

Collected Steps per Second: 23,289.71049
Overall Steps per Second: 10,747.80202

Timestep Collection Time: 2.14730
Timestep Consumption Time: 2.50574
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.65304

Cumulative Model Updates: 171,758
Cumulative Timesteps: 1,432,448,220

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1432448220...
Checkpoint 1432448220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,350.90424
Policy Entropy: 2.98605
Value Function Loss: 0.00461

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.60234
Value Function Update Magnitude: 0.53627

Collected Steps per Second: 22,886.19132
Overall Steps per Second: 10,644.70508

Timestep Collection Time: 2.18472
Timestep Consumption Time: 2.51245
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.69717

Cumulative Model Updates: 171,764
Cumulative Timesteps: 1,432,498,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,347.58630
Policy Entropy: 2.97524
Value Function Loss: 0.00503

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.61517
Value Function Update Magnitude: 0.53494

Collected Steps per Second: 22,939.13373
Overall Steps per Second: 10,812.29197

Timestep Collection Time: 2.18012
Timestep Consumption Time: 2.44517
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.62529

Cumulative Model Updates: 171,770
Cumulative Timesteps: 1,432,548,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1432548230...
Checkpoint 1432548230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.21322
Policy Entropy: 2.97438
Value Function Loss: 0.00490

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.61378
Value Function Update Magnitude: 0.52626

Collected Steps per Second: 22,880.30431
Overall Steps per Second: 10,716.03048

Timestep Collection Time: 2.18590
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.66721

Cumulative Model Updates: 171,776
Cumulative Timesteps: 1,432,598,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,615.06429
Policy Entropy: 2.98374
Value Function Loss: 0.00472

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.59773
Value Function Update Magnitude: 0.53188

Collected Steps per Second: 22,741.00203
Overall Steps per Second: 10,685.27477

Timestep Collection Time: 2.19885
Timestep Consumption Time: 2.48086
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.67971

Cumulative Model Updates: 171,782
Cumulative Timesteps: 1,432,648,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1432648248...
Checkpoint 1432648248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.16688
Policy Entropy: 2.97608
Value Function Loss: 0.00489

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.59896
Value Function Update Magnitude: 0.53191

Collected Steps per Second: 22,510.76669
Overall Steps per Second: 10,649.32855

Timestep Collection Time: 2.22125
Timestep Consumption Time: 2.47407
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.69532

Cumulative Model Updates: 171,788
Cumulative Timesteps: 1,432,698,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,299.86018
Policy Entropy: 2.96904
Value Function Loss: 0.00486

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.61136
Value Function Update Magnitude: 0.54962

Collected Steps per Second: 22,463.19430
Overall Steps per Second: 10,662.94472

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.46524
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.69289

Cumulative Model Updates: 171,794
Cumulative Timesteps: 1,432,748,290

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1432748290...
Checkpoint 1432748290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.62494
Policy Entropy: 2.98040
Value Function Loss: 0.00472

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.61835
Value Function Update Magnitude: 0.56486

Collected Steps per Second: 22,623.01303
Overall Steps per Second: 10,645.71798

Timestep Collection Time: 2.21093
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.69841

Cumulative Model Updates: 171,800
Cumulative Timesteps: 1,432,798,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.81975
Policy Entropy: 3.00050
Value Function Loss: 0.00448

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.61692
Value Function Update Magnitude: 0.57184

Collected Steps per Second: 22,963.15860
Overall Steps per Second: 10,824.71035

Timestep Collection Time: 2.17749
Timestep Consumption Time: 2.44176
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.61925

Cumulative Model Updates: 171,806
Cumulative Timesteps: 1,432,848,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1432848310...
Checkpoint 1432848310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.71976
Policy Entropy: 2.99922
Value Function Loss: 0.00425

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.59482
Value Function Update Magnitude: 0.54601

Collected Steps per Second: 23,055.11904
Overall Steps per Second: 10,720.75572

Timestep Collection Time: 2.16932
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.66516

Cumulative Model Updates: 171,812
Cumulative Timesteps: 1,432,898,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,378.95670
Policy Entropy: 3.00247
Value Function Loss: 0.00436

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.58457
Value Function Update Magnitude: 0.51901

Collected Steps per Second: 23,409.56400
Overall Steps per Second: 10,929.01048

Timestep Collection Time: 2.13596
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.57516

Cumulative Model Updates: 171,818
Cumulative Timesteps: 1,432,948,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1432948326...
Checkpoint 1432948326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,346.43963
Policy Entropy: 2.99597
Value Function Loss: 0.00463

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.59375
Value Function Update Magnitude: 0.50135

Collected Steps per Second: 22,833.05075
Overall Steps per Second: 10,637.28685

Timestep Collection Time: 2.19121
Timestep Consumption Time: 2.51225
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.70346

Cumulative Model Updates: 171,824
Cumulative Timesteps: 1,432,998,358

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,074.95633
Policy Entropy: 3.00341
Value Function Loss: 0.00470

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.59672
Value Function Update Magnitude: 0.50371

Collected Steps per Second: 23,273.28550
Overall Steps per Second: 10,876.84361

Timestep Collection Time: 2.14967
Timestep Consumption Time: 2.45001
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.59968

Cumulative Model Updates: 171,830
Cumulative Timesteps: 1,433,048,388

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1433048388...
Checkpoint 1433048388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.05634
Policy Entropy: 2.99131
Value Function Loss: 0.00459

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.59919
Value Function Update Magnitude: 0.52428

Collected Steps per Second: 22,738.64449
Overall Steps per Second: 10,649.74995

Timestep Collection Time: 2.19943
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69607

Cumulative Model Updates: 171,836
Cumulative Timesteps: 1,433,098,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.29660
Policy Entropy: 2.99903
Value Function Loss: 0.00426

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.59107
Value Function Update Magnitude: 0.53517

Collected Steps per Second: 23,147.56417
Overall Steps per Second: 10,858.23459

Timestep Collection Time: 2.16031
Timestep Consumption Time: 2.44504
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60535

Cumulative Model Updates: 171,842
Cumulative Timesteps: 1,433,148,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1433148406...
Checkpoint 1433148406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,294.67717
Policy Entropy: 3.00618
Value Function Loss: 0.00429

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.58401
Value Function Update Magnitude: 0.53604

Collected Steps per Second: 22,516.27880
Overall Steps per Second: 10,753.40819

Timestep Collection Time: 2.22097
Timestep Consumption Time: 2.42946
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.65043

Cumulative Model Updates: 171,848
Cumulative Timesteps: 1,433,198,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,777.75941
Policy Entropy: 3.00982
Value Function Loss: 0.00437

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.58385
Value Function Update Magnitude: 0.53563

Collected Steps per Second: 22,696.29930
Overall Steps per Second: 10,778.11119

Timestep Collection Time: 2.20380
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.64070

Cumulative Model Updates: 171,854
Cumulative Timesteps: 1,433,248,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1433248432...
Checkpoint 1433248432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,222.47860
Policy Entropy: 3.00219
Value Function Loss: 0.00474

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.54311

Collected Steps per Second: 22,790.74516
Overall Steps per Second: 10,743.47706

Timestep Collection Time: 2.19422
Timestep Consumption Time: 2.46051
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.65473

Cumulative Model Updates: 171,860
Cumulative Timesteps: 1,433,298,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,107.21466
Policy Entropy: 3.00346
Value Function Loss: 0.00490

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.59621
Value Function Update Magnitude: 0.55490

Collected Steps per Second: 23,296.89545
Overall Steps per Second: 10,824.62681

Timestep Collection Time: 2.14690
Timestep Consumption Time: 2.47368
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.62058

Cumulative Model Updates: 171,866
Cumulative Timesteps: 1,433,348,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1433348456...
Checkpoint 1433348456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.84914
Policy Entropy: 3.02373
Value Function Loss: 0.00504

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.59800
Value Function Update Magnitude: 0.55246

Collected Steps per Second: 23,206.03166
Overall Steps per Second: 10,829.19271

Timestep Collection Time: 2.15487
Timestep Consumption Time: 2.46283
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.61770

Cumulative Model Updates: 171,872
Cumulative Timesteps: 1,433,398,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,038.79519
Policy Entropy: 3.03513
Value Function Loss: 0.00478

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.58837
Value Function Update Magnitude: 0.53280

Collected Steps per Second: 23,347.49672
Overall Steps per Second: 10,738.30334

Timestep Collection Time: 2.14181
Timestep Consumption Time: 2.51497
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.65679

Cumulative Model Updates: 171,878
Cumulative Timesteps: 1,433,448,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1433448468...
Checkpoint 1433448468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,866.34495
Policy Entropy: 3.04531
Value Function Loss: 0.00442

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.57250
Value Function Update Magnitude: 0.51319

Collected Steps per Second: 23,088.14141
Overall Steps per Second: 10,712.56532

Timestep Collection Time: 2.16596
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.66816

Cumulative Model Updates: 171,884
Cumulative Timesteps: 1,433,498,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,045.25227
Policy Entropy: 3.03816
Value Function Loss: 0.00415

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.56598
Value Function Update Magnitude: 0.51259

Collected Steps per Second: 23,165.63690
Overall Steps per Second: 10,877.75591

Timestep Collection Time: 2.15906
Timestep Consumption Time: 2.43895
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.59801

Cumulative Model Updates: 171,890
Cumulative Timesteps: 1,433,548,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1433548492...
Checkpoint 1433548492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,553.11595
Policy Entropy: 3.02447
Value Function Loss: 0.00407

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.56727
Value Function Update Magnitude: 0.51784

Collected Steps per Second: 22,752.33367
Overall Steps per Second: 10,644.10271

Timestep Collection Time: 2.19837
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.69913

Cumulative Model Updates: 171,896
Cumulative Timesteps: 1,433,598,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.46700
Policy Entropy: 3.01889
Value Function Loss: 0.00434

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.57772
Value Function Update Magnitude: 0.52404

Collected Steps per Second: 22,533.04014
Overall Steps per Second: 10,619.73989

Timestep Collection Time: 2.21914
Timestep Consumption Time: 2.48945
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.70859

Cumulative Model Updates: 171,902
Cumulative Timesteps: 1,433,648,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1433648514...
Checkpoint 1433648514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,281.52772
Policy Entropy: 3.02523
Value Function Loss: 0.00466

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.59072
Value Function Update Magnitude: 0.56049

Collected Steps per Second: 23,037.44469
Overall Steps per Second: 10,967.69606

Timestep Collection Time: 2.17038
Timestep Consumption Time: 2.38846
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.55884

Cumulative Model Updates: 171,908
Cumulative Timesteps: 1,433,698,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,844.93368
Policy Entropy: 3.01900
Value Function Loss: 0.00483

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.58624
Value Function Update Magnitude: 0.56962

Collected Steps per Second: 23,020.23812
Overall Steps per Second: 10,741.50772

Timestep Collection Time: 2.17226
Timestep Consumption Time: 2.48314
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.65540

Cumulative Model Updates: 171,914
Cumulative Timesteps: 1,433,748,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1433748520...
Checkpoint 1433748520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.52240
Policy Entropy: 3.01356
Value Function Loss: 0.00520

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.59699
Value Function Update Magnitude: 0.56939

Collected Steps per Second: 23,175.34250
Overall Steps per Second: 10,704.80298

Timestep Collection Time: 2.15859
Timestep Consumption Time: 2.51464
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.67323

Cumulative Model Updates: 171,920
Cumulative Timesteps: 1,433,798,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.10578
Policy Entropy: 2.98851
Value Function Loss: 0.00540

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.62454
Value Function Update Magnitude: 0.61282

Collected Steps per Second: 23,220.38316
Overall Steps per Second: 10,999.88100

Timestep Collection Time: 2.15363
Timestep Consumption Time: 2.39261
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.54623

Cumulative Model Updates: 171,926
Cumulative Timesteps: 1,433,848,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1433848554...
Checkpoint 1433848554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.64484
Policy Entropy: 2.98547
Value Function Loss: 0.00520

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.63887
Value Function Update Magnitude: 0.63813

Collected Steps per Second: 23,354.38777
Overall Steps per Second: 10,951.49338

Timestep Collection Time: 2.14135
Timestep Consumption Time: 2.42515
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.56650

Cumulative Model Updates: 171,932
Cumulative Timesteps: 1,433,898,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.39943
Policy Entropy: 3.00199
Value Function Loss: 0.00449

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.61871
Value Function Update Magnitude: 0.61358

Collected Steps per Second: 23,151.97925
Overall Steps per Second: 10,933.31196

Timestep Collection Time: 2.16068
Timestep Consumption Time: 2.41470
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.57537

Cumulative Model Updates: 171,938
Cumulative Timesteps: 1,433,948,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1433948588...
Checkpoint 1433948588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,555.22907
Policy Entropy: 3.02114
Value Function Loss: 0.00423

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.60303
Value Function Update Magnitude: 0.56527

Collected Steps per Second: 23,098.66302
Overall Steps per Second: 10,757.52157

Timestep Collection Time: 2.16549
Timestep Consumption Time: 2.48428
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.64977

Cumulative Model Updates: 171,944
Cumulative Timesteps: 1,433,998,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,666.44151
Policy Entropy: 3.02866
Value Function Loss: 0.00432

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.60072
Value Function Update Magnitude: 0.55260

Collected Steps per Second: 22,695.02336
Overall Steps per Second: 10,781.92643

Timestep Collection Time: 2.20321
Timestep Consumption Time: 2.43436
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.63758

Cumulative Model Updates: 171,950
Cumulative Timesteps: 1,434,048,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1434048610...
Checkpoint 1434048610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,019.66511
Policy Entropy: 3.00492
Value Function Loss: 0.00444

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.61018
Value Function Update Magnitude: 0.57373

Collected Steps per Second: 22,587.74734
Overall Steps per Second: 10,764.01907

Timestep Collection Time: 2.21545
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.64901

Cumulative Model Updates: 171,956
Cumulative Timesteps: 1,434,098,652

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.14377
Policy Entropy: 3.00601
Value Function Loss: 0.00493

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.62586
Value Function Update Magnitude: 0.58704

Collected Steps per Second: 22,767.01799
Overall Steps per Second: 10,858.76707

Timestep Collection Time: 2.19677
Timestep Consumption Time: 2.40909
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.60586

Cumulative Model Updates: 171,962
Cumulative Timesteps: 1,434,148,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1434148666...
Checkpoint 1434148666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.84858
Policy Entropy: 3.00007
Value Function Loss: 0.00492

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.62067
Value Function Update Magnitude: 0.59132

Collected Steps per Second: 22,904.03864
Overall Steps per Second: 10,727.86648

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.47813
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.66150

Cumulative Model Updates: 171,968
Cumulative Timesteps: 1,434,198,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.40127
Policy Entropy: 3.01250
Value Function Loss: 0.00467

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.60768
Value Function Update Magnitude: 0.58743

Collected Steps per Second: 23,412.07433
Overall Steps per Second: 10,824.44079

Timestep Collection Time: 2.13582
Timestep Consumption Time: 2.48372
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61955

Cumulative Model Updates: 171,974
Cumulative Timesteps: 1,434,248,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1434248678...
Checkpoint 1434248678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,221.52362
Policy Entropy: 3.01358
Value Function Loss: 0.00459

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.59655
Value Function Update Magnitude: 0.56997

Collected Steps per Second: 23,087.85554
Overall Steps per Second: 10,688.68617

Timestep Collection Time: 2.16694
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.68065

Cumulative Model Updates: 171,980
Cumulative Timesteps: 1,434,298,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,042.52669
Policy Entropy: 3.01478
Value Function Loss: 0.00442

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.59688
Value Function Update Magnitude: 0.56200

Collected Steps per Second: 23,391.75817
Overall Steps per Second: 10,891.75925

Timestep Collection Time: 2.13845
Timestep Consumption Time: 2.45420
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.59265

Cumulative Model Updates: 171,986
Cumulative Timesteps: 1,434,348,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1434348730...
Checkpoint 1434348730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.76617
Policy Entropy: 3.00140
Value Function Loss: 0.00476

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.58983
Value Function Update Magnitude: 0.54862

Collected Steps per Second: 22,928.99246
Overall Steps per Second: 10,739.77402

Timestep Collection Time: 2.18160
Timestep Consumption Time: 2.47604
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.65764

Cumulative Model Updates: 171,992
Cumulative Timesteps: 1,434,398,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,087.91766
Policy Entropy: 3.02057
Value Function Loss: 0.00444

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.58881
Value Function Update Magnitude: 0.52575

Collected Steps per Second: 23,159.82707
Overall Steps per Second: 10,812.79419

Timestep Collection Time: 2.16003
Timestep Consumption Time: 2.46652
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.62656

Cumulative Model Updates: 171,998
Cumulative Timesteps: 1,434,448,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1434448778...
Checkpoint 1434448778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.54921
Policy Entropy: 3.02655
Value Function Loss: 0.00442

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.58620
Value Function Update Magnitude: 0.53699

Collected Steps per Second: 22,951.93066
Overall Steps per Second: 10,684.71162

Timestep Collection Time: 2.17942
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.68164

Cumulative Model Updates: 172,004
Cumulative Timesteps: 1,434,498,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,865.78957
Policy Entropy: 3.03212
Value Function Loss: 0.00432

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.59747
Value Function Update Magnitude: 0.54202

Collected Steps per Second: 22,549.74953
Overall Steps per Second: 10,609.98053

Timestep Collection Time: 2.21767
Timestep Consumption Time: 2.49562
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.71330

Cumulative Model Updates: 172,010
Cumulative Timesteps: 1,434,548,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1434548808...
Checkpoint 1434548808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.32035
Policy Entropy: 3.02474
Value Function Loss: 0.00495

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.60836
Value Function Update Magnitude: 0.56967

Collected Steps per Second: 22,943.16978
Overall Steps per Second: 10,912.76785

Timestep Collection Time: 2.18000
Timestep Consumption Time: 2.40326
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.58326

Cumulative Model Updates: 172,016
Cumulative Timesteps: 1,434,598,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.02690
Policy Entropy: 3.02253
Value Function Loss: 0.00469

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11162
Policy Update Magnitude: 0.61124
Value Function Update Magnitude: 0.57628

Collected Steps per Second: 22,780.58233
Overall Steps per Second: 10,805.56290

Timestep Collection Time: 2.19494
Timestep Consumption Time: 2.43249
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.62743

Cumulative Model Updates: 172,022
Cumulative Timesteps: 1,434,648,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1434648826...
Checkpoint 1434648826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,993.78840
Policy Entropy: 3.02030
Value Function Loss: 0.00465

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.60456
Value Function Update Magnitude: 0.55825

Collected Steps per Second: 22,936.14895
Overall Steps per Second: 10,719.00613

Timestep Collection Time: 2.18092
Timestep Consumption Time: 2.48574
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.66666

Cumulative Model Updates: 172,028
Cumulative Timesteps: 1,434,698,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.06414
Policy Entropy: 3.02012
Value Function Loss: 0.00446

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.59807
Value Function Update Magnitude: 0.52683

Collected Steps per Second: 22,923.88749
Overall Steps per Second: 10,770.00960

Timestep Collection Time: 2.18165
Timestep Consumption Time: 2.46198
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.64364

Cumulative Model Updates: 172,034
Cumulative Timesteps: 1,434,748,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1434748860...
Checkpoint 1434748860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,333.40440
Policy Entropy: 3.01026
Value Function Loss: 0.00491

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.60215
Value Function Update Magnitude: 0.52801

Collected Steps per Second: 22,938.17886
Overall Steps per Second: 10,761.67892

Timestep Collection Time: 2.17977
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.64612

Cumulative Model Updates: 172,040
Cumulative Timesteps: 1,434,798,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.90697
Policy Entropy: 3.01911
Value Function Loss: 0.00475

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.59482
Value Function Update Magnitude: 0.53453

Collected Steps per Second: 22,835.36845
Overall Steps per Second: 10,872.94086

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.40995
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60041

Cumulative Model Updates: 172,046
Cumulative Timesteps: 1,434,848,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1434848880...
Checkpoint 1434848880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,735.83541
Policy Entropy: 3.03135
Value Function Loss: 0.00461

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.58543
Value Function Update Magnitude: 0.53647

Collected Steps per Second: 23,201.45029
Overall Steps per Second: 10,727.98878

Timestep Collection Time: 2.15521
Timestep Consumption Time: 2.50587
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.66108

Cumulative Model Updates: 172,052
Cumulative Timesteps: 1,434,898,884

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.49595
Policy Entropy: 3.03372
Value Function Loss: 0.00415

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10252
Policy Update Magnitude: 0.57247
Value Function Update Magnitude: 0.52466

Collected Steps per Second: 21,742.23241
Overall Steps per Second: 10,443.69765

Timestep Collection Time: 2.30078
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.78987

Cumulative Model Updates: 172,058
Cumulative Timesteps: 1,434,948,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1434948908...
Checkpoint 1434948908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,301.36359
Policy Entropy: 3.02872
Value Function Loss: 0.00408

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.50108

Collected Steps per Second: 22,887.76113
Overall Steps per Second: 10,648.15781

Timestep Collection Time: 2.18588
Timestep Consumption Time: 2.51258
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.69847

Cumulative Model Updates: 172,064
Cumulative Timesteps: 1,434,998,938

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.65937
Policy Entropy: 3.02373
Value Function Loss: 0.00419

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.56666
Value Function Update Magnitude: 0.46844

Collected Steps per Second: 22,583.30461
Overall Steps per Second: 10,639.67424

Timestep Collection Time: 2.21438
Timestep Consumption Time: 2.48576
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.70014

Cumulative Model Updates: 172,070
Cumulative Timesteps: 1,435,048,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1435048946...
Checkpoint 1435048946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,570.78255
Policy Entropy: 3.04576
Value Function Loss: 0.00392

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.55736
Value Function Update Magnitude: 0.48007

Collected Steps per Second: 22,767.72339
Overall Steps per Second: 10,780.00557

Timestep Collection Time: 2.19723
Timestep Consumption Time: 2.44340
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.64063

Cumulative Model Updates: 172,076
Cumulative Timesteps: 1,435,098,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,225.08005
Policy Entropy: 3.05553
Value Function Loss: 0.00408

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.55103
Value Function Update Magnitude: 0.47550

Collected Steps per Second: 23,230.44787
Overall Steps per Second: 10,925.74894

Timestep Collection Time: 2.15312
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.57799

Cumulative Model Updates: 172,082
Cumulative Timesteps: 1,435,148,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1435148990...
Checkpoint 1435148990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.83604
Policy Entropy: 3.06061
Value Function Loss: 0.00421

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.56096
Value Function Update Magnitude: 0.47513

Collected Steps per Second: 23,184.07845
Overall Steps per Second: 10,689.80771

Timestep Collection Time: 2.15682
Timestep Consumption Time: 2.52090
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.67773

Cumulative Model Updates: 172,088
Cumulative Timesteps: 1,435,198,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,232.08140
Policy Entropy: 3.04846
Value Function Loss: 0.00426

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.48055

Collected Steps per Second: 23,143.39985
Overall Steps per Second: 10,892.75048

Timestep Collection Time: 2.16062
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.59058

Cumulative Model Updates: 172,094
Cumulative Timesteps: 1,435,248,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1435248998...
Checkpoint 1435248998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.46744
Policy Entropy: 3.05041
Value Function Loss: 0.00427

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.55577
Value Function Update Magnitude: 0.47270

Collected Steps per Second: 23,281.81525
Overall Steps per Second: 10,771.17945

Timestep Collection Time: 2.14837
Timestep Consumption Time: 2.49532
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.64369

Cumulative Model Updates: 172,100
Cumulative Timesteps: 1,435,299,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,813.77978
Policy Entropy: 3.04580
Value Function Loss: 0.00425

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.48149

Collected Steps per Second: 23,456.56571
Overall Steps per Second: 10,815.48942

Timestep Collection Time: 2.13288
Timestep Consumption Time: 2.49289
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.62577

Cumulative Model Updates: 172,106
Cumulative Timesteps: 1,435,349,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1435349046...
Checkpoint 1435349046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,478.73184
Policy Entropy: 3.04132
Value Function Loss: 0.00448

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11276
Policy Update Magnitude: 0.56966
Value Function Update Magnitude: 0.48758

Collected Steps per Second: 22,961.18389
Overall Steps per Second: 10,662.58024

Timestep Collection Time: 2.17846
Timestep Consumption Time: 2.51271
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.69117

Cumulative Model Updates: 172,112
Cumulative Timesteps: 1,435,399,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,837.62907
Policy Entropy: 3.03407
Value Function Loss: 0.00453

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.48299

Collected Steps per Second: 22,684.90198
Overall Steps per Second: 10,840.98531

Timestep Collection Time: 2.20473
Timestep Consumption Time: 2.40869
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61342

Cumulative Model Updates: 172,118
Cumulative Timesteps: 1,435,449,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1435449080...
Checkpoint 1435449080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,409.84784
Policy Entropy: 3.04218
Value Function Loss: 0.00479

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.55977
Value Function Update Magnitude: 0.46750

Collected Steps per Second: 22,515.93795
Overall Steps per Second: 10,680.27391

Timestep Collection Time: 2.22127
Timestep Consumption Time: 2.46157
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.68284

Cumulative Model Updates: 172,124
Cumulative Timesteps: 1,435,499,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.05843
Policy Entropy: 3.02579
Value Function Loss: 0.00481

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.57230
Value Function Update Magnitude: 0.47669

Collected Steps per Second: 22,524.11823
Overall Steps per Second: 10,582.89704

Timestep Collection Time: 2.22162
Timestep Consumption Time: 2.50677
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.72838

Cumulative Model Updates: 172,130
Cumulative Timesteps: 1,435,549,134

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1435549134...
Checkpoint 1435549134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,348.38300
Policy Entropy: 3.02477
Value Function Loss: 0.00481

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.58380
Value Function Update Magnitude: 0.48875

Collected Steps per Second: 22,856.24287
Overall Steps per Second: 10,665.94432

Timestep Collection Time: 2.18925
Timestep Consumption Time: 2.50213
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.69138

Cumulative Model Updates: 172,136
Cumulative Timesteps: 1,435,599,172

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.84722
Policy Entropy: 3.02064
Value Function Loss: 0.00518

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.59802
Value Function Update Magnitude: 0.52278

Collected Steps per Second: 23,379.16840
Overall Steps per Second: 10,778.68501

Timestep Collection Time: 2.13985
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.64138

Cumulative Model Updates: 172,142
Cumulative Timesteps: 1,435,649,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1435649200...
Checkpoint 1435649200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,861.01941
Policy Entropy: 3.03543
Value Function Loss: 0.00516

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.61084
Value Function Update Magnitude: 0.54214

Collected Steps per Second: 23,316.14839
Overall Steps per Second: 10,852.76111

Timestep Collection Time: 2.14564
Timestep Consumption Time: 2.46407
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.60970

Cumulative Model Updates: 172,148
Cumulative Timesteps: 1,435,699,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.82567
Policy Entropy: 3.04140
Value Function Loss: 0.00491

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.59640
Value Function Update Magnitude: 0.54502

Collected Steps per Second: 23,680.53983
Overall Steps per Second: 10,831.88115

Timestep Collection Time: 2.11254
Timestep Consumption Time: 2.50587
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.61840

Cumulative Model Updates: 172,154
Cumulative Timesteps: 1,435,749,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1435749254...
Checkpoint 1435749254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,394.27026
Policy Entropy: 3.04470
Value Function Loss: 0.00492

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.58450
Value Function Update Magnitude: 0.53885

Collected Steps per Second: 23,151.70066
Overall Steps per Second: 10,877.28320

Timestep Collection Time: 2.16071
Timestep Consumption Time: 2.43824
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.59894

Cumulative Model Updates: 172,160
Cumulative Timesteps: 1,435,799,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.23553
Policy Entropy: 3.03708
Value Function Loss: 0.00486

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.57714
Value Function Update Magnitude: 0.53194

Collected Steps per Second: 23,089.14287
Overall Steps per Second: 10,749.10463

Timestep Collection Time: 2.16647
Timestep Consumption Time: 2.48712
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.65360

Cumulative Model Updates: 172,166
Cumulative Timesteps: 1,435,849,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1435849300...
Checkpoint 1435849300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.41499
Policy Entropy: 3.02369
Value Function Loss: 0.00492

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.58196
Value Function Update Magnitude: 0.53224

Collected Steps per Second: 23,353.73800
Overall Steps per Second: 10,887.30727

Timestep Collection Time: 2.14124
Timestep Consumption Time: 2.45181
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.59305

Cumulative Model Updates: 172,172
Cumulative Timesteps: 1,435,899,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.66513
Policy Entropy: 3.00920
Value Function Loss: 0.00472

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.60046
Value Function Update Magnitude: 0.53656

Collected Steps per Second: 22,570.73565
Overall Steps per Second: 10,802.36229

Timestep Collection Time: 2.21544
Timestep Consumption Time: 2.41355
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.62899

Cumulative Model Updates: 172,178
Cumulative Timesteps: 1,435,949,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1435949310...
Checkpoint 1435949310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,497.48727
Policy Entropy: 3.00257
Value Function Loss: 0.00479

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.60184
Value Function Update Magnitude: 0.54270

Collected Steps per Second: 22,395.65362
Overall Steps per Second: 10,731.98601

Timestep Collection Time: 2.23392
Timestep Consumption Time: 2.42785
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.66177

Cumulative Model Updates: 172,184
Cumulative Timesteps: 1,435,999,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.28074
Policy Entropy: 3.01628
Value Function Loss: 0.00444

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.59159
Value Function Update Magnitude: 0.57244

Collected Steps per Second: 22,688.40547
Overall Steps per Second: 10,678.63731

Timestep Collection Time: 2.20430
Timestep Consumption Time: 2.47907
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.68337

Cumulative Model Updates: 172,190
Cumulative Timesteps: 1,436,049,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1436049352...
Checkpoint 1436049352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,123.14144
Policy Entropy: 3.01124
Value Function Loss: 0.00436

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.56129

Collected Steps per Second: 22,585.21637
Overall Steps per Second: 10,788.82279

Timestep Collection Time: 2.21393
Timestep Consumption Time: 2.42069
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.63461

Cumulative Model Updates: 172,196
Cumulative Timesteps: 1,436,099,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.75250
Policy Entropy: 3.00389
Value Function Loss: 0.00433

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.59897
Value Function Update Magnitude: 0.54090

Collected Steps per Second: 22,941.84459
Overall Steps per Second: 10,591.24484

Timestep Collection Time: 2.18021
Timestep Consumption Time: 2.54237
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.72258

Cumulative Model Updates: 172,202
Cumulative Timesteps: 1,436,149,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1436149372...
Checkpoint 1436149372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,817.47227
Policy Entropy: 3.00236
Value Function Loss: 0.00444

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.59953
Value Function Update Magnitude: 0.54293

Collected Steps per Second: 23,179.54511
Overall Steps per Second: 10,717.52674

Timestep Collection Time: 2.15837
Timestep Consumption Time: 2.50969
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.66805

Cumulative Model Updates: 172,208
Cumulative Timesteps: 1,436,199,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,094.18126
Policy Entropy: 2.99842
Value Function Loss: 0.00441

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.58757
Value Function Update Magnitude: 0.53390

Collected Steps per Second: 23,359.51668
Overall Steps per Second: 10,778.49552

Timestep Collection Time: 2.14165
Timestep Consumption Time: 2.49981
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.64146

Cumulative Model Updates: 172,214
Cumulative Timesteps: 1,436,249,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1436249430...
Checkpoint 1436249430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,088.97114
Policy Entropy: 3.00834
Value Function Loss: 0.00472

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.60425
Value Function Update Magnitude: 0.53627

Collected Steps per Second: 23,034.13269
Overall Steps per Second: 10,659.51240

Timestep Collection Time: 2.17078
Timestep Consumption Time: 2.52006
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.69083

Cumulative Model Updates: 172,220
Cumulative Timesteps: 1,436,299,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,484.50025
Policy Entropy: 3.01922
Value Function Loss: 0.00446

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.59819
Value Function Update Magnitude: 0.53764

Collected Steps per Second: 23,386.11755
Overall Steps per Second: 10,878.36524

Timestep Collection Time: 2.13862
Timestep Consumption Time: 2.45895
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.59757

Cumulative Model Updates: 172,226
Cumulative Timesteps: 1,436,349,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1436349446...
Checkpoint 1436349446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937.49157
Policy Entropy: 3.04717
Value Function Loss: 0.00416

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.51848

Collected Steps per Second: 23,129.86806
Overall Steps per Second: 10,709.12185

Timestep Collection Time: 2.16171
Timestep Consumption Time: 2.50721
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.66892

Cumulative Model Updates: 172,232
Cumulative Timesteps: 1,436,399,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.21768
Policy Entropy: 3.06731
Value Function Loss: 0.00399

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.55220
Value Function Update Magnitude: 0.46972

Collected Steps per Second: 22,799.14198
Overall Steps per Second: 10,814.58312

Timestep Collection Time: 2.19350
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62431

Cumulative Model Updates: 172,238
Cumulative Timesteps: 1,436,449,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1436449456...
Checkpoint 1436449456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,066.08440
Policy Entropy: 3.05996
Value Function Loss: 0.00398

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.55619
Value Function Update Magnitude: 0.45227

Collected Steps per Second: 22,408.28875
Overall Steps per Second: 10,693.10521

Timestep Collection Time: 2.23150
Timestep Consumption Time: 2.44479
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.67628

Cumulative Model Updates: 172,244
Cumulative Timesteps: 1,436,499,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.16664
Policy Entropy: 3.04176
Value Function Loss: 0.00407

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.55899
Value Function Update Magnitude: 0.47200

Collected Steps per Second: 22,300.46697
Overall Steps per Second: 10,840.67386

Timestep Collection Time: 2.24220
Timestep Consumption Time: 2.37025
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.61244

Cumulative Model Updates: 172,250
Cumulative Timesteps: 1,436,549,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1436549462...
Checkpoint 1436549462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.06153
Policy Entropy: 3.02842
Value Function Loss: 0.00421

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.55888
Value Function Update Magnitude: 0.48777

Collected Steps per Second: 22,213.32063
Overall Steps per Second: 10,663.08646

Timestep Collection Time: 2.25153
Timestep Consumption Time: 2.43885
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.69039

Cumulative Model Updates: 172,256
Cumulative Timesteps: 1,436,599,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,114.25258
Policy Entropy: 3.03318
Value Function Loss: 0.00453

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.57340
Value Function Update Magnitude: 0.49543

Collected Steps per Second: 22,081.22863
Overall Steps per Second: 10,801.69368

Timestep Collection Time: 2.26563
Timestep Consumption Time: 2.36586
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.63150

Cumulative Model Updates: 172,262
Cumulative Timesteps: 1,436,649,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1436649504...
Checkpoint 1436649504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.74989
Policy Entropy: 3.04248
Value Function Loss: 0.00486

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.58211
Value Function Update Magnitude: 0.50121

Collected Steps per Second: 22,132.93799
Overall Steps per Second: 10,756.62546

Timestep Collection Time: 2.25980
Timestep Consumption Time: 2.38999
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.64979

Cumulative Model Updates: 172,268
Cumulative Timesteps: 1,436,699,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,564.45441
Policy Entropy: 3.03867
Value Function Loss: 0.00449

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.57277
Value Function Update Magnitude: 0.52074

Collected Steps per Second: 22,609.07435
Overall Steps per Second: 10,928.59422

Timestep Collection Time: 2.21354
Timestep Consumption Time: 2.36583
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.57936

Cumulative Model Updates: 172,274
Cumulative Timesteps: 1,436,749,566

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1436749566...
Checkpoint 1436749566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.89541
Policy Entropy: 3.03407
Value Function Loss: 0.00418

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.56626
Value Function Update Magnitude: 0.49594

Collected Steps per Second: 22,395.73247
Overall Steps per Second: 10,788.69447

Timestep Collection Time: 2.23275
Timestep Consumption Time: 2.40211
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.63485

Cumulative Model Updates: 172,280
Cumulative Timesteps: 1,436,799,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,559.07952
Policy Entropy: 3.01200
Value Function Loss: 0.00441

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.57644
Value Function Update Magnitude: 0.49110

Collected Steps per Second: 22,422.18399
Overall Steps per Second: 10,738.29976

Timestep Collection Time: 2.23083
Timestep Consumption Time: 2.42727
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.65809

Cumulative Model Updates: 172,286
Cumulative Timesteps: 1,436,849,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1436849590...
Checkpoint 1436849590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.21146
Policy Entropy: 3.02860
Value Function Loss: 0.00504

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.59088
Value Function Update Magnitude: 0.51067

Collected Steps per Second: 22,147.04672
Overall Steps per Second: 10,642.91406

Timestep Collection Time: 2.25836
Timestep Consumption Time: 2.44111
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69946

Cumulative Model Updates: 172,292
Cumulative Timesteps: 1,436,899,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.66217
Policy Entropy: 3.03248
Value Function Loss: 0.00477

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.58144
Value Function Update Magnitude: 0.54434

Collected Steps per Second: 21,892.34147
Overall Steps per Second: 10,642.38769

Timestep Collection Time: 2.28518
Timestep Consumption Time: 2.41564
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.70082

Cumulative Model Updates: 172,298
Cumulative Timesteps: 1,436,949,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1436949634...
Checkpoint 1436949634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,942.73694
Policy Entropy: 3.05699
Value Function Loss: 0.00450

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.57180
Value Function Update Magnitude: 0.52280

Collected Steps per Second: 22,018.97877
Overall Steps per Second: 10,806.62919

Timestep Collection Time: 2.27122
Timestep Consumption Time: 2.35649
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62771

Cumulative Model Updates: 172,304
Cumulative Timesteps: 1,436,999,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,341.83289
Policy Entropy: 3.04158
Value Function Loss: 0.00433

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.56848
Value Function Update Magnitude: 0.50652

Collected Steps per Second: 22,051.85635
Overall Steps per Second: 10,658.90397

Timestep Collection Time: 2.26756
Timestep Consumption Time: 2.42372
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.69129

Cumulative Model Updates: 172,310
Cumulative Timesteps: 1,437,049,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1437049648...
Checkpoint 1437049648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801.28405
Policy Entropy: 3.03491
Value Function Loss: 0.00439

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.50497

Collected Steps per Second: 22,366.70559
Overall Steps per Second: 10,581.11574

Timestep Collection Time: 2.23663
Timestep Consumption Time: 2.49123
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.72786

Cumulative Model Updates: 172,316
Cumulative Timesteps: 1,437,099,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,904.07252
Policy Entropy: 3.00821
Value Function Loss: 0.00437

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.50170

Collected Steps per Second: 23,226.44676
Overall Steps per Second: 10,863.19882

Timestep Collection Time: 2.15341
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60417

Cumulative Model Updates: 172,322
Cumulative Timesteps: 1,437,149,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1437149690...
Checkpoint 1437149690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,876.25640
Policy Entropy: 3.00967
Value Function Loss: 0.00444

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.58719
Value Function Update Magnitude: 0.51819

Collected Steps per Second: 23,201.35125
Overall Steps per Second: 10,800.93033

Timestep Collection Time: 2.15522
Timestep Consumption Time: 2.47438
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.62960

Cumulative Model Updates: 172,328
Cumulative Timesteps: 1,437,199,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.00554
Policy Entropy: 3.00914
Value Function Loss: 0.00470

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.59802
Value Function Update Magnitude: 0.54220

Collected Steps per Second: 22,937.55337
Overall Steps per Second: 10,769.03442

Timestep Collection Time: 2.18035
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.64406

Cumulative Model Updates: 172,334
Cumulative Timesteps: 1,437,249,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1437249706...
Checkpoint 1437249706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.47875
Policy Entropy: 3.03048
Value Function Loss: 0.00480

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.58823
Value Function Update Magnitude: 0.54006

Collected Steps per Second: 23,008.82342
Overall Steps per Second: 10,780.67842

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.46574
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.63960

Cumulative Model Updates: 172,340
Cumulative Timesteps: 1,437,299,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.55256
Policy Entropy: 3.02315
Value Function Loss: 0.00478

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.58099
Value Function Update Magnitude: 0.52290

Collected Steps per Second: 23,410.23941
Overall Steps per Second: 10,773.23060

Timestep Collection Time: 2.13701
Timestep Consumption Time: 2.50672
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.64373

Cumulative Model Updates: 172,346
Cumulative Timesteps: 1,437,349,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1437349752...
Checkpoint 1437349752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.37288
Policy Entropy: 3.02556
Value Function Loss: 0.00477

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.58202
Value Function Update Magnitude: 0.50546

Collected Steps per Second: 23,270.50019
Overall Steps per Second: 10,808.30035

Timestep Collection Time: 2.14993
Timestep Consumption Time: 2.47892
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.62885

Cumulative Model Updates: 172,352
Cumulative Timesteps: 1,437,399,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.80393
Policy Entropy: 3.01763
Value Function Loss: 0.00472

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.59742
Value Function Update Magnitude: 0.51130

Collected Steps per Second: 22,893.89135
Overall Steps per Second: 10,741.92753

Timestep Collection Time: 2.18399
Timestep Consumption Time: 2.47067
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.65466

Cumulative Model Updates: 172,358
Cumulative Timesteps: 1,437,449,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1437449782...
Checkpoint 1437449782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.43892
Policy Entropy: 3.01340
Value Function Loss: 0.00448

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.59339
Value Function Update Magnitude: 0.52698

Collected Steps per Second: 22,654.08756
Overall Steps per Second: 10,625.94042

Timestep Collection Time: 2.20773
Timestep Consumption Time: 2.49906
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.70678

Cumulative Model Updates: 172,364
Cumulative Timesteps: 1,437,499,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,082.57399
Policy Entropy: 3.01836
Value Function Loss: 0.00450

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.59409
Value Function Update Magnitude: 0.52795

Collected Steps per Second: 22,469.21604
Overall Steps per Second: 10,568.08218

Timestep Collection Time: 2.22544
Timestep Consumption Time: 2.50616
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.73161

Cumulative Model Updates: 172,370
Cumulative Timesteps: 1,437,549,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1437549800...
Checkpoint 1437549800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,381.01469
Policy Entropy: 3.00719
Value Function Loss: 0.00468

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.60202
Value Function Update Magnitude: 0.53374

Collected Steps per Second: 22,806.91201
Overall Steps per Second: 10,685.99790

Timestep Collection Time: 2.19276
Timestep Consumption Time: 2.48720
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.67996

Cumulative Model Updates: 172,376
Cumulative Timesteps: 1,437,599,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.45446
Policy Entropy: 3.00891
Value Function Loss: 0.00468

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.60640
Value Function Update Magnitude: 0.55381

Collected Steps per Second: 23,121.40973
Overall Steps per Second: 10,745.34226

Timestep Collection Time: 2.16310
Timestep Consumption Time: 2.49138
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.65448

Cumulative Model Updates: 172,382
Cumulative Timesteps: 1,437,649,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1437649824...
Checkpoint 1437649824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,029.80036
Policy Entropy: 3.02325
Value Function Loss: 0.00430

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11872
Policy Update Magnitude: 0.58908
Value Function Update Magnitude: 0.53700

Collected Steps per Second: 23,248.56230
Overall Steps per Second: 10,757.23328

Timestep Collection Time: 2.15187
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.65064

Cumulative Model Updates: 172,388
Cumulative Timesteps: 1,437,699,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465.53011
Policy Entropy: 3.04603
Value Function Loss: 0.00384

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.57210
Value Function Update Magnitude: 0.52956

Collected Steps per Second: 23,350.05157
Overall Steps per Second: 10,756.36470

Timestep Collection Time: 2.14149
Timestep Consumption Time: 2.50729
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.64878

Cumulative Model Updates: 172,394
Cumulative Timesteps: 1,437,749,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1437749856...
Checkpoint 1437749856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.58498
Policy Entropy: 3.04869
Value Function Loss: 0.00404

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.57046
Value Function Update Magnitude: 0.53716

Collected Steps per Second: 22,998.72050
Overall Steps per Second: 10,665.39393

Timestep Collection Time: 2.17490
Timestep Consumption Time: 2.51503
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.68993

Cumulative Model Updates: 172,400
Cumulative Timesteps: 1,437,799,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465.01375
Policy Entropy: 3.03975
Value Function Loss: 0.00409

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.58130
Value Function Update Magnitude: 0.54803

Collected Steps per Second: 23,201.25233
Overall Steps per Second: 10,855.02591

Timestep Collection Time: 2.15566
Timestep Consumption Time: 2.45179
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.60745

Cumulative Model Updates: 172,406
Cumulative Timesteps: 1,437,849,890

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1437849890...
Checkpoint 1437849890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,144.66513
Policy Entropy: 3.03457
Value Function Loss: 0.00406

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.57072
Value Function Update Magnitude: 0.53216

Collected Steps per Second: 23,225.31026
Overall Steps per Second: 10,738.63404

Timestep Collection Time: 2.15368
Timestep Consumption Time: 2.50426
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.65795

Cumulative Model Updates: 172,412
Cumulative Timesteps: 1,437,899,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.92132
Policy Entropy: 3.03190
Value Function Loss: 0.00415

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.56701
Value Function Update Magnitude: 0.51464

Collected Steps per Second: 22,994.44844
Overall Steps per Second: 10,830.91588

Timestep Collection Time: 2.17557
Timestep Consumption Time: 2.44325
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61882

Cumulative Model Updates: 172,418
Cumulative Timesteps: 1,437,949,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1437949936...
Checkpoint 1437949936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,705.65011
Policy Entropy: 3.01335
Value Function Loss: 0.00447

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11346
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.51131

Collected Steps per Second: 22,286.40043
Overall Steps per Second: 10,707.45852

Timestep Collection Time: 2.24469
Timestep Consumption Time: 2.42738
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.67207

Cumulative Model Updates: 172,424
Cumulative Timesteps: 1,437,999,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,031.74480
Policy Entropy: 3.00650
Value Function Loss: 0.00468

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.59108
Value Function Update Magnitude: 0.52934

Collected Steps per Second: 22,707.46838
Overall Steps per Second: 10,781.29748

Timestep Collection Time: 2.20280
Timestep Consumption Time: 2.43672
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.63952

Cumulative Model Updates: 172,430
Cumulative Timesteps: 1,438,049,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1438049982...
Checkpoint 1438049982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.53261
Policy Entropy: 3.01769
Value Function Loss: 0.00456

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.59142
Value Function Update Magnitude: 0.54315

Collected Steps per Second: 22,356.42215
Overall Steps per Second: 10,697.14262

Timestep Collection Time: 2.23676
Timestep Consumption Time: 2.43794
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.67471

Cumulative Model Updates: 172,436
Cumulative Timesteps: 1,438,099,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.89888
Policy Entropy: 3.04145
Value Function Loss: 0.00467

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.58387
Value Function Update Magnitude: 0.52391

Collected Steps per Second: 22,849.64699
Overall Steps per Second: 10,660.28215

Timestep Collection Time: 2.18909
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.69218

Cumulative Model Updates: 172,442
Cumulative Timesteps: 1,438,150,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1438150008...
Checkpoint 1438150008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.89127
Policy Entropy: 3.04709
Value Function Loss: 0.00470

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.58257
Value Function Update Magnitude: 0.52420

Collected Steps per Second: 23,084.92271
Overall Steps per Second: 10,656.62012

Timestep Collection Time: 2.16722
Timestep Consumption Time: 2.52752
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.69473

Cumulative Model Updates: 172,448
Cumulative Timesteps: 1,438,200,038

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,564.33332
Policy Entropy: 3.04927
Value Function Loss: 0.00490

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.58584
Value Function Update Magnitude: 0.54948

Collected Steps per Second: 23,176.60341
Overall Steps per Second: 10,647.61396

Timestep Collection Time: 2.15795
Timestep Consumption Time: 2.53925
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.69720

Cumulative Model Updates: 172,454
Cumulative Timesteps: 1,438,250,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1438250052...
Checkpoint 1438250052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,392.27299
Policy Entropy: 3.03503
Value Function Loss: 0.00471

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.58860
Value Function Update Magnitude: 0.57194

Collected Steps per Second: 22,956.40367
Overall Steps per Second: 10,711.16063

Timestep Collection Time: 2.17883
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.66971

Cumulative Model Updates: 172,460
Cumulative Timesteps: 1,438,300,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948.01420
Policy Entropy: 3.02363
Value Function Loss: 0.00465

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.59289
Value Function Update Magnitude: 0.54539

Collected Steps per Second: 23,240.56573
Overall Steps per Second: 10,863.11114

Timestep Collection Time: 2.15244
Timestep Consumption Time: 2.45250
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.60494

Cumulative Model Updates: 172,466
Cumulative Timesteps: 1,438,350,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1438350094...
Checkpoint 1438350094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.28784
Policy Entropy: 3.00731
Value Function Loss: 0.00477

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.60255
Value Function Update Magnitude: 0.55252

Collected Steps per Second: 23,037.15327
Overall Steps per Second: 10,713.73888

Timestep Collection Time: 2.17171
Timestep Consumption Time: 2.49800
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.66971

Cumulative Model Updates: 172,472
Cumulative Timesteps: 1,438,400,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.87504
Policy Entropy: 3.00875
Value Function Loss: 0.00454

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.60730
Value Function Update Magnitude: 0.57072

Collected Steps per Second: 23,276.10287
Overall Steps per Second: 10,883.66696

Timestep Collection Time: 2.14941
Timestep Consumption Time: 2.44738
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.59680

Cumulative Model Updates: 172,478
Cumulative Timesteps: 1,438,450,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1438450154...
Checkpoint 1438450154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.67672
Policy Entropy: 3.00725
Value Function Loss: 0.00439

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.59863
Value Function Update Magnitude: 0.56144

Collected Steps per Second: 22,674.09721
Overall Steps per Second: 10,661.65854

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.48514
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.69083

Cumulative Model Updates: 172,484
Cumulative Timesteps: 1,438,500,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,355.91387
Policy Entropy: 3.02170
Value Function Loss: 0.00417

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.58779
Value Function Update Magnitude: 0.55426

Collected Steps per Second: 22,950.61790
Overall Steps per Second: 10,852.52379

Timestep Collection Time: 2.17903
Timestep Consumption Time: 2.42912
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60814

Cumulative Model Updates: 172,490
Cumulative Timesteps: 1,438,550,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1438550176...
Checkpoint 1438550176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,034.11234
Policy Entropy: 3.02129
Value Function Loss: 0.00434

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.58571
Value Function Update Magnitude: 0.54503

Collected Steps per Second: 21,796.60619
Overall Steps per Second: 10,686.50812

Timestep Collection Time: 2.29394
Timestep Consumption Time: 2.38486
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.67880

Cumulative Model Updates: 172,496
Cumulative Timesteps: 1,438,600,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,414.42679
Policy Entropy: 3.02918
Value Function Loss: 0.00431

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.58654
Value Function Update Magnitude: 0.54838

Collected Steps per Second: 22,289.26553
Overall Steps per Second: 10,870.75561

Timestep Collection Time: 2.24359
Timestep Consumption Time: 2.35664
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60023

Cumulative Model Updates: 172,502
Cumulative Timesteps: 1,438,650,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1438650184...
Checkpoint 1438650184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910.49167
Policy Entropy: 3.02830
Value Function Loss: 0.00448

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.58878
Value Function Update Magnitude: 0.54164

Collected Steps per Second: 21,963.27146
Overall Steps per Second: 10,667.37481

Timestep Collection Time: 2.27744
Timestep Consumption Time: 2.41163
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.68906

Cumulative Model Updates: 172,508
Cumulative Timesteps: 1,438,700,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,837.65915
Policy Entropy: 3.02522
Value Function Loss: 0.00448

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.59505
Value Function Update Magnitude: 0.54836

Collected Steps per Second: 22,254.83860
Overall Steps per Second: 10,783.79156

Timestep Collection Time: 2.24679
Timestep Consumption Time: 2.38998
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.63677

Cumulative Model Updates: 172,514
Cumulative Timesteps: 1,438,750,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1438750206...
Checkpoint 1438750206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.12963
Policy Entropy: 3.01718
Value Function Loss: 0.00454

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.59948
Value Function Update Magnitude: 0.55712

Collected Steps per Second: 21,341.98599
Overall Steps per Second: 10,518.65152

Timestep Collection Time: 2.34299
Timestep Consumption Time: 2.41085
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.75384

Cumulative Model Updates: 172,520
Cumulative Timesteps: 1,438,800,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,501.87553
Policy Entropy: 3.02084
Value Function Loss: 0.00463

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.60598
Value Function Update Magnitude: 0.55763

Collected Steps per Second: 22,201.07763
Overall Steps per Second: 10,693.03584

Timestep Collection Time: 2.25295
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.67762

Cumulative Model Updates: 172,526
Cumulative Timesteps: 1,438,850,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1438850228...
Checkpoint 1438850228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,228.43943
Policy Entropy: 3.01043
Value Function Loss: 0.00463

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.60328
Value Function Update Magnitude: 0.55863

Collected Steps per Second: 21,673.10233
Overall Steps per Second: 10,628.82550

Timestep Collection Time: 2.30821
Timestep Consumption Time: 2.39843
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.70663

Cumulative Model Updates: 172,532
Cumulative Timesteps: 1,438,900,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.67994
Policy Entropy: 3.01701
Value Function Loss: 0.00500

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.61543
Value Function Update Magnitude: 0.56728

Collected Steps per Second: 22,330.87942
Overall Steps per Second: 10,835.18616

Timestep Collection Time: 2.23950
Timestep Consumption Time: 2.37602
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.61552

Cumulative Model Updates: 172,538
Cumulative Timesteps: 1,438,950,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1438950264...
Checkpoint 1438950264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,912.00641
Policy Entropy: 3.01448
Value Function Loss: 0.00482

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.62206
Value Function Update Magnitude: 0.57872

Collected Steps per Second: 22,282.82413
Overall Steps per Second: 10,696.98464

Timestep Collection Time: 2.24397
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.67440

Cumulative Model Updates: 172,544
Cumulative Timesteps: 1,439,000,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.90592
Policy Entropy: 3.01004
Value Function Loss: 0.00487

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.60491
Value Function Update Magnitude: 0.55291

Collected Steps per Second: 22,638.47246
Overall Steps per Second: 10,960.29751

Timestep Collection Time: 2.20925
Timestep Consumption Time: 2.35395
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.56320

Cumulative Model Updates: 172,550
Cumulative Timesteps: 1,439,050,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1439050280...
Checkpoint 1439050280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,528.26435
Policy Entropy: 2.99428
Value Function Loss: 0.00479

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.59408
Value Function Update Magnitude: 0.51873

Collected Steps per Second: 22,509.31098
Overall Steps per Second: 10,807.21137

Timestep Collection Time: 2.22130
Timestep Consumption Time: 2.40524
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.62654

Cumulative Model Updates: 172,556
Cumulative Timesteps: 1,439,100,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.80316
Policy Entropy: 2.99120
Value Function Loss: 0.00477

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.59222
Value Function Update Magnitude: 0.52423

Collected Steps per Second: 22,964.84077
Overall Steps per Second: 10,923.59782

Timestep Collection Time: 2.17733
Timestep Consumption Time: 2.40010
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.57743

Cumulative Model Updates: 172,562
Cumulative Timesteps: 1,439,150,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1439150282...
Checkpoint 1439150282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,977.46208
Policy Entropy: 3.01598
Value Function Loss: 0.00450

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.60141
Value Function Update Magnitude: 0.53680

Collected Steps per Second: 22,617.99415
Overall Steps per Second: 10,870.66689

Timestep Collection Time: 2.21072
Timestep Consumption Time: 2.38900
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.59972

Cumulative Model Updates: 172,568
Cumulative Timesteps: 1,439,200,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,984.97114
Policy Entropy: 3.01096
Value Function Loss: 0.00465

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.60087
Value Function Update Magnitude: 0.54870

Collected Steps per Second: 21,773.40037
Overall Steps per Second: 10,621.41950

Timestep Collection Time: 2.29730
Timestep Consumption Time: 2.41205
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.70935

Cumulative Model Updates: 172,574
Cumulative Timesteps: 1,439,250,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1439250304...
Checkpoint 1439250304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.04525
Policy Entropy: 3.02460
Value Function Loss: 0.00446

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.59626
Value Function Update Magnitude: 0.54359

Collected Steps per Second: 22,064.19326
Overall Steps per Second: 10,515.63632

Timestep Collection Time: 2.26747
Timestep Consumption Time: 2.49020
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.75768

Cumulative Model Updates: 172,580
Cumulative Timesteps: 1,439,300,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.66716
Policy Entropy: 3.01738
Value Function Loss: 0.00448

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.59057
Value Function Update Magnitude: 0.51925

Collected Steps per Second: 22,974.38966
Overall Steps per Second: 10,890.36888

Timestep Collection Time: 2.17686
Timestep Consumption Time: 2.41546
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59231

Cumulative Model Updates: 172,586
Cumulative Timesteps: 1,439,350,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1439350346...
Checkpoint 1439350346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.62912
Policy Entropy: 3.04874
Value Function Loss: 0.00432

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.58581
Value Function Update Magnitude: 0.51589

Collected Steps per Second: 22,595.87716
Overall Steps per Second: 10,633.89840

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.70270

Cumulative Model Updates: 172,592
Cumulative Timesteps: 1,439,400,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,828.32626
Policy Entropy: 3.05644
Value Function Loss: 0.00429

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.57988
Value Function Update Magnitude: 0.53257

Collected Steps per Second: 23,235.73738
Overall Steps per Second: 10,965.31921

Timestep Collection Time: 2.15280
Timestep Consumption Time: 2.40903
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.56184

Cumulative Model Updates: 172,598
Cumulative Timesteps: 1,439,450,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1439450376...
Checkpoint 1439450376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.77637
Policy Entropy: 3.05349
Value Function Loss: 0.00420

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.55042

Collected Steps per Second: 23,079.68077
Overall Steps per Second: 10,947.59892

Timestep Collection Time: 2.16736
Timestep Consumption Time: 2.40186
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.56922

Cumulative Model Updates: 172,604
Cumulative Timesteps: 1,439,500,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.26982
Policy Entropy: 3.04042
Value Function Loss: 0.00404

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.57426
Value Function Update Magnitude: 0.52206

Collected Steps per Second: 23,203.02592
Overall Steps per Second: 10,780.97317

Timestep Collection Time: 2.15601
Timestep Consumption Time: 2.48420
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.64021

Cumulative Model Updates: 172,610
Cumulative Timesteps: 1,439,550,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1439550424...
Checkpoint 1439550424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,529.15339
Policy Entropy: 3.01696
Value Function Loss: 0.00395

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.57273
Value Function Update Magnitude: 0.51312

Collected Steps per Second: 23,036.13092
Overall Steps per Second: 10,829.37109

Timestep Collection Time: 2.17146
Timestep Consumption Time: 2.44765
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61910

Cumulative Model Updates: 172,616
Cumulative Timesteps: 1,439,600,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,584.50375
Policy Entropy: 3.01259
Value Function Loss: 0.00400

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.58087
Value Function Update Magnitude: 0.52250

Collected Steps per Second: 22,979.20865
Overall Steps per Second: 10,856.47859

Timestep Collection Time: 2.17692
Timestep Consumption Time: 2.43083
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60776

Cumulative Model Updates: 172,622
Cumulative Timesteps: 1,439,650,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1439650470...
Checkpoint 1439650470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.34961
Policy Entropy: 3.02602
Value Function Loss: 0.00429

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.58285
Value Function Update Magnitude: 0.54967

Collected Steps per Second: 22,416.72366
Overall Steps per Second: 10,699.14047

Timestep Collection Time: 2.23048
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.67327

Cumulative Model Updates: 172,628
Cumulative Timesteps: 1,439,700,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,016.00479
Policy Entropy: 3.02235
Value Function Loss: 0.00430

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.57792
Value Function Update Magnitude: 0.56935

Collected Steps per Second: 22,968.46963
Overall Steps per Second: 10,844.90107

Timestep Collection Time: 2.17733
Timestep Consumption Time: 2.43405
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.61138

Cumulative Model Updates: 172,634
Cumulative Timesteps: 1,439,750,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1439750480...
Checkpoint 1439750480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,553.17490
Policy Entropy: 3.05249
Value Function Loss: 0.00429

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.58206
Value Function Update Magnitude: 0.54751

Collected Steps per Second: 22,664.28994
Overall Steps per Second: 10,807.54350

Timestep Collection Time: 2.20735
Timestep Consumption Time: 2.42164
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.62899

Cumulative Model Updates: 172,640
Cumulative Timesteps: 1,439,800,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.15761
Policy Entropy: 3.03835
Value Function Loss: 0.00427

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.57723
Value Function Update Magnitude: 0.54205

Collected Steps per Second: 22,784.65860
Overall Steps per Second: 10,793.18192

Timestep Collection Time: 2.19542
Timestep Consumption Time: 2.43917
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.63459

Cumulative Model Updates: 172,646
Cumulative Timesteps: 1,439,850,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1439850530...
Checkpoint 1439850530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,425.22513
Policy Entropy: 3.02344
Value Function Loss: 0.00468

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.58883
Value Function Update Magnitude: 0.54295

Collected Steps per Second: 22,815.70458
Overall Steps per Second: 10,721.42425

Timestep Collection Time: 2.19270
Timestep Consumption Time: 2.47347
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.66617

Cumulative Model Updates: 172,652
Cumulative Timesteps: 1,439,900,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,611.16011
Policy Entropy: 2.99900
Value Function Loss: 0.00454

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.59999
Value Function Update Magnitude: 0.54041

Collected Steps per Second: 23,224.86194
Overall Steps per Second: 10,863.21717

Timestep Collection Time: 2.15330
Timestep Consumption Time: 2.45031
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.60361

Cumulative Model Updates: 172,658
Cumulative Timesteps: 1,439,950,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1439950568...
Checkpoint 1439950568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,860.11204
Policy Entropy: 2.99710
Value Function Loss: 0.00445

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.59163
Value Function Update Magnitude: 0.54143

Collected Steps per Second: 22,896.82864
Overall Steps per Second: 10,623.63200

Timestep Collection Time: 2.18528
Timestep Consumption Time: 2.52460
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.70988

Cumulative Model Updates: 172,664
Cumulative Timesteps: 1,440,000,604

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,631.69771
Policy Entropy: 3.02874
Value Function Loss: 0.00405

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.58396
Value Function Update Magnitude: 0.53359

Collected Steps per Second: 22,993.37887
Overall Steps per Second: 10,843.24185

Timestep Collection Time: 2.17567
Timestep Consumption Time: 2.43790
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.61356

Cumulative Model Updates: 172,670
Cumulative Timesteps: 1,440,050,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1440050630...
Checkpoint 1440050630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,522.74948
Policy Entropy: 3.04447
Value Function Loss: 0.00401

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.52221

Collected Steps per Second: 22,745.37639
Overall Steps per Second: 10,744.62997

Timestep Collection Time: 2.19895
Timestep Consumption Time: 2.45602
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.65498

Cumulative Model Updates: 172,676
Cumulative Timesteps: 1,440,100,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,055.92877
Policy Entropy: 3.06172
Value Function Loss: 0.00375

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.56118
Value Function Update Magnitude: 0.50059

Collected Steps per Second: 23,161.42583
Overall Steps per Second: 10,903.39926

Timestep Collection Time: 2.16006
Timestep Consumption Time: 2.42842
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58848

Cumulative Model Updates: 172,682
Cumulative Timesteps: 1,440,150,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1440150676...
Checkpoint 1440150676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,626.99905
Policy Entropy: 3.04621
Value Function Loss: 0.00383

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.56140
Value Function Update Magnitude: 0.48884

Collected Steps per Second: 22,382.78218
Overall Steps per Second: 10,640.19514

Timestep Collection Time: 2.23449
Timestep Consumption Time: 2.46599
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.70048

Cumulative Model Updates: 172,688
Cumulative Timesteps: 1,440,200,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.37806
Policy Entropy: 3.03524
Value Function Loss: 0.00397

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.56354
Value Function Update Magnitude: 0.49897

Collected Steps per Second: 22,697.49687
Overall Steps per Second: 10,698.34112

Timestep Collection Time: 2.20412
Timestep Consumption Time: 2.47212
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.67624

Cumulative Model Updates: 172,694
Cumulative Timesteps: 1,440,250,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1440250718...
Checkpoint 1440250718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,767.56610
Policy Entropy: 3.01686
Value Function Loss: 0.00452

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.58509
Value Function Update Magnitude: 0.51214

Collected Steps per Second: 22,655.26580
Overall Steps per Second: 10,805.64283

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.42177
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.63017

Cumulative Model Updates: 172,700
Cumulative Timesteps: 1,440,300,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,894.65028
Policy Entropy: 3.01524
Value Function Loss: 0.00450

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.59334
Value Function Update Magnitude: 0.54364

Collected Steps per Second: 22,493.80935
Overall Steps per Second: 10,557.17770

Timestep Collection Time: 2.22408
Timestep Consumption Time: 2.51469
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.73877

Cumulative Model Updates: 172,706
Cumulative Timesteps: 1,440,350,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1440350778...
Checkpoint 1440350778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,892.89609
Policy Entropy: 3.00073
Value Function Loss: 0.00492

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.60749
Value Function Update Magnitude: 0.55677

Collected Steps per Second: 22,462.41937
Overall Steps per Second: 10,594.39836

Timestep Collection Time: 2.22665
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.72099

Cumulative Model Updates: 172,712
Cumulative Timesteps: 1,440,400,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.53565
Policy Entropy: 2.99457
Value Function Loss: 0.00470

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.60712
Value Function Update Magnitude: 0.54357

Collected Steps per Second: 23,306.01483
Overall Steps per Second: 10,858.48446

Timestep Collection Time: 2.14580
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.60562

Cumulative Model Updates: 172,718
Cumulative Timesteps: 1,440,450,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1440450804...
Checkpoint 1440450804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.11134
Policy Entropy: 2.98887
Value Function Loss: 0.00462

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.59362
Value Function Update Magnitude: 0.51232

Collected Steps per Second: 23,027.32350
Overall Steps per Second: 10,668.70519

Timestep Collection Time: 2.17142
Timestep Consumption Time: 2.51537
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.68679

Cumulative Model Updates: 172,724
Cumulative Timesteps: 1,440,500,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.11316
Policy Entropy: 2.99195
Value Function Loss: 0.00455

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.60308
Value Function Update Magnitude: 0.52197

Collected Steps per Second: 23,365.23474
Overall Steps per Second: 10,963.46033

Timestep Collection Time: 2.14062
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.56206

Cumulative Model Updates: 172,730
Cumulative Timesteps: 1,440,550,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1440550822...
Checkpoint 1440550822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.07189
Policy Entropy: 2.99870
Value Function Loss: 0.00417

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.59802
Value Function Update Magnitude: 0.52010

Collected Steps per Second: 22,928.46281
Overall Steps per Second: 10,691.36564

Timestep Collection Time: 2.18104
Timestep Consumption Time: 2.49637
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.67742

Cumulative Model Updates: 172,736
Cumulative Timesteps: 1,440,600,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,469.12100
Policy Entropy: 2.99382
Value Function Loss: 0.00452

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.59098
Value Function Update Magnitude: 0.51500

Collected Steps per Second: 22,945.41391
Overall Steps per Second: 10,562.60297

Timestep Collection Time: 2.17952
Timestep Consumption Time: 2.55511
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.73463

Cumulative Model Updates: 172,742
Cumulative Timesteps: 1,440,650,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1440650840...
Checkpoint 1440650840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,294.63051
Policy Entropy: 2.99561
Value Function Loss: 0.00462

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.60697
Value Function Update Magnitude: 0.53614

Collected Steps per Second: 22,103.70081
Overall Steps per Second: 10,412.09202

Timestep Collection Time: 2.26279
Timestep Consumption Time: 2.54086
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.80365

Cumulative Model Updates: 172,748
Cumulative Timesteps: 1,440,700,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.85024
Policy Entropy: 2.97422
Value Function Loss: 0.00492

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.62029
Value Function Update Magnitude: 0.56291

Collected Steps per Second: 22,901.62981
Overall Steps per Second: 10,741.82113

Timestep Collection Time: 2.18404
Timestep Consumption Time: 2.47234
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.65638

Cumulative Model Updates: 172,754
Cumulative Timesteps: 1,440,750,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1440750874...
Checkpoint 1440750874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,981.93610
Policy Entropy: 2.97625
Value Function Loss: 0.00468

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.60401
Value Function Update Magnitude: 0.58384

Collected Steps per Second: 22,199.92265
Overall Steps per Second: 10,578.44839

Timestep Collection Time: 2.25226
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.72659

Cumulative Model Updates: 172,760
Cumulative Timesteps: 1,440,800,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.13407
Policy Entropy: 2.98926
Value Function Loss: 0.00466

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.60360
Value Function Update Magnitude: 0.57606

Collected Steps per Second: 22,891.49023
Overall Steps per Second: 10,739.81335

Timestep Collection Time: 2.18500
Timestep Consumption Time: 2.47225
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.65725

Cumulative Model Updates: 172,766
Cumulative Timesteps: 1,440,850,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1440850892...
Checkpoint 1440850892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,945.21186
Policy Entropy: 3.01169
Value Function Loss: 0.00494

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.61103
Value Function Update Magnitude: 0.59032

Collected Steps per Second: 22,948.10278
Overall Steps per Second: 10,612.43968

Timestep Collection Time: 2.18005
Timestep Consumption Time: 2.53404
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.71409

Cumulative Model Updates: 172,772
Cumulative Timesteps: 1,440,900,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.92149
Policy Entropy: 3.00307
Value Function Loss: 0.00513

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.61222
Value Function Update Magnitude: 0.58482

Collected Steps per Second: 23,398.95423
Overall Steps per Second: 10,960.47993

Timestep Collection Time: 2.13762
Timestep Consumption Time: 2.42587
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.56349

Cumulative Model Updates: 172,778
Cumulative Timesteps: 1,440,950,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1440950938...
Checkpoint 1440950938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.64935
Policy Entropy: 2.99075
Value Function Loss: 0.00562

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.61260
Value Function Update Magnitude: 0.58420

Collected Steps per Second: 23,155.72062
Overall Steps per Second: 10,761.05462

Timestep Collection Time: 2.15938
Timestep Consumption Time: 2.48719
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.64657

Cumulative Model Updates: 172,784
Cumulative Timesteps: 1,441,000,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.15551
Policy Entropy: 3.00172
Value Function Loss: 0.00519

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.60286
Value Function Update Magnitude: 0.58387

Collected Steps per Second: 22,583.95674
Overall Steps per Second: 10,740.63262

Timestep Collection Time: 2.21423
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.65578

Cumulative Model Updates: 172,790
Cumulative Timesteps: 1,441,050,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1441050946...
Checkpoint 1441050946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252.39801
Policy Entropy: 3.02239
Value Function Loss: 0.00490

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.58951
Value Function Update Magnitude: 0.55453

Collected Steps per Second: 22,296.27871
Overall Steps per Second: 10,699.95034

Timestep Collection Time: 2.24369
Timestep Consumption Time: 2.43166
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.67535

Cumulative Model Updates: 172,796
Cumulative Timesteps: 1,441,100,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,309.13475
Policy Entropy: 3.04000
Value Function Loss: 0.00452

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.58762
Value Function Update Magnitude: 0.53032

Collected Steps per Second: 22,860.41869
Overall Steps per Second: 10,881.41815

Timestep Collection Time: 2.18745
Timestep Consumption Time: 2.40809
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.59554

Cumulative Model Updates: 172,802
Cumulative Timesteps: 1,441,150,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1441150978...
Checkpoint 1441150978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.38636
Policy Entropy: 3.02855
Value Function Loss: 0.00476

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.59021
Value Function Update Magnitude: 0.53924

Collected Steps per Second: 21,958.51540
Overall Steps per Second: 10,651.97392

Timestep Collection Time: 2.27830
Timestep Consumption Time: 2.41830
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.69659

Cumulative Model Updates: 172,808
Cumulative Timesteps: 1,441,201,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,157.42996
Policy Entropy: 3.02714
Value Function Loss: 0.00469

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.59513
Value Function Update Magnitude: 0.54958

Collected Steps per Second: 22,153.71310
Overall Steps per Second: 10,803.45955

Timestep Collection Time: 2.25696
Timestep Consumption Time: 2.37119
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62815

Cumulative Model Updates: 172,814
Cumulative Timesteps: 1,441,251,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1441251006...
Checkpoint 1441251006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,002.68929
Policy Entropy: 3.04044
Value Function Loss: 0.00476

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.54243

Collected Steps per Second: 21,817.74010
Overall Steps per Second: 10,634.01022

Timestep Collection Time: 2.29190
Timestep Consumption Time: 2.41037
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.70227

Cumulative Model Updates: 172,820
Cumulative Timesteps: 1,441,301,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,002.61790
Policy Entropy: 3.05536
Value Function Loss: 0.00482

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.58456
Value Function Update Magnitude: 0.54311

Collected Steps per Second: 22,757.42201
Overall Steps per Second: 10,699.91144

Timestep Collection Time: 2.19823
Timestep Consumption Time: 2.47714
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.67537

Cumulative Model Updates: 172,826
Cumulative Timesteps: 1,441,351,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1441351036...
Checkpoint 1441351036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,594.00465
Policy Entropy: 3.06072
Value Function Loss: 0.00425

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.57530
Value Function Update Magnitude: 0.54049

Collected Steps per Second: 22,533.08753
Overall Steps per Second: 10,728.56616

Timestep Collection Time: 2.21985
Timestep Consumption Time: 2.44247
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.66232

Cumulative Model Updates: 172,832
Cumulative Timesteps: 1,441,401,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.88956
Policy Entropy: 3.05544
Value Function Loss: 0.00391

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.55367
Value Function Update Magnitude: 0.51474

Collected Steps per Second: 23,213.66300
Overall Steps per Second: 10,776.63678

Timestep Collection Time: 2.15416
Timestep Consumption Time: 2.48606
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.64022

Cumulative Model Updates: 172,838
Cumulative Timesteps: 1,441,451,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1441451062...
Checkpoint 1441451062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.67672
Policy Entropy: 3.05684
Value Function Loss: 0.00395

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10676
Policy Update Magnitude: 0.54635
Value Function Update Magnitude: 0.50179

Collected Steps per Second: 22,736.43768
Overall Steps per Second: 10,644.21549

Timestep Collection Time: 2.20008
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.69945

Cumulative Model Updates: 172,844
Cumulative Timesteps: 1,441,501,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,304.12516
Policy Entropy: 3.05569
Value Function Loss: 0.00401

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.55233
Value Function Update Magnitude: 0.50593

Collected Steps per Second: 23,226.21424
Overall Steps per Second: 10,807.56857

Timestep Collection Time: 2.15291
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.62676

Cumulative Model Updates: 172,850
Cumulative Timesteps: 1,441,551,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1441551088...
Checkpoint 1441551088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,226.43309
Policy Entropy: 3.06632
Value Function Loss: 0.00406

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.50793

Collected Steps per Second: 22,721.19748
Overall Steps per Second: 10,622.03952

Timestep Collection Time: 2.20156
Timestep Consumption Time: 2.50771
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.70927

Cumulative Model Updates: 172,856
Cumulative Timesteps: 1,441,601,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,248.88579
Policy Entropy: 3.05540
Value Function Loss: 0.00446

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.56321
Value Function Update Magnitude: 0.49963

Collected Steps per Second: 22,977.94202
Overall Steps per Second: 10,820.71571

Timestep Collection Time: 2.17617
Timestep Consumption Time: 2.44496
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.62114

Cumulative Model Updates: 172,862
Cumulative Timesteps: 1,441,651,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1441651114...
Checkpoint 1441651114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.89964
Policy Entropy: 3.05312
Value Function Loss: 0.00465

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.56808
Value Function Update Magnitude: 0.50818

Collected Steps per Second: 22,549.69391
Overall Steps per Second: 10,758.51024

Timestep Collection Time: 2.21857
Timestep Consumption Time: 2.43152
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.65009

Cumulative Model Updates: 172,868
Cumulative Timesteps: 1,441,701,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,320.42810
Policy Entropy: 3.04381
Value Function Loss: 0.00459

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11369
Policy Update Magnitude: 0.57283
Value Function Update Magnitude: 0.52588

Collected Steps per Second: 22,615.00783
Overall Steps per Second: 10,665.02326

Timestep Collection Time: 2.21119
Timestep Consumption Time: 2.47760
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.68878

Cumulative Model Updates: 172,874
Cumulative Timesteps: 1,441,751,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1441751148...
Checkpoint 1441751148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,601.61090
Policy Entropy: 3.04091
Value Function Loss: 0.00463

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.57640
Value Function Update Magnitude: 0.51232

Collected Steps per Second: 22,489.79401
Overall Steps per Second: 10,827.52209

Timestep Collection Time: 2.22421
Timestep Consumption Time: 2.39568
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.61989

Cumulative Model Updates: 172,880
Cumulative Timesteps: 1,441,801,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,086.25427
Policy Entropy: 3.03826
Value Function Loss: 0.00463

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.58758
Value Function Update Magnitude: 0.50323

Collected Steps per Second: 22,854.69629
Overall Steps per Second: 10,650.90398

Timestep Collection Time: 2.18896
Timestep Consumption Time: 2.50811
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.69707

Cumulative Model Updates: 172,886
Cumulative Timesteps: 1,441,851,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1441851198...
Checkpoint 1441851198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.90243
Policy Entropy: 3.03228
Value Function Loss: 0.00449

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.58196
Value Function Update Magnitude: 0.50003

Collected Steps per Second: 22,988.01125
Overall Steps per Second: 10,838.92344

Timestep Collection Time: 2.17566
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61430

Cumulative Model Updates: 172,892
Cumulative Timesteps: 1,441,901,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,648.48123
Policy Entropy: 3.03800
Value Function Loss: 0.00425

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.56569
Value Function Update Magnitude: 0.48965

Collected Steps per Second: 23,082.89749
Overall Steps per Second: 10,712.36430

Timestep Collection Time: 2.16732
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.67012

Cumulative Model Updates: 172,898
Cumulative Timesteps: 1,441,951,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1441951240...
Checkpoint 1441951240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,369.28879
Policy Entropy: 3.04206
Value Function Loss: 0.00406

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.55613
Value Function Update Magnitude: 0.47264

Collected Steps per Second: 22,914.13369
Overall Steps per Second: 10,851.33624

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.42712
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61049

Cumulative Model Updates: 172,904
Cumulative Timesteps: 1,442,001,270

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.76315
Policy Entropy: 3.04596
Value Function Loss: 0.00426

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.56687
Value Function Update Magnitude: 0.45934

Collected Steps per Second: 23,392.77110
Overall Steps per Second: 10,912.17722

Timestep Collection Time: 2.13844
Timestep Consumption Time: 2.44580
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.58424

Cumulative Model Updates: 172,910
Cumulative Timesteps: 1,442,051,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1442051294...
Checkpoint 1442051294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171.87080
Policy Entropy: 3.03542
Value Function Loss: 0.00417

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.57321
Value Function Update Magnitude: 0.47274

Collected Steps per Second: 23,138.11735
Overall Steps per Second: 10,684.49490

Timestep Collection Time: 2.16094
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.67968

Cumulative Model Updates: 172,916
Cumulative Timesteps: 1,442,101,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,635.31970
Policy Entropy: 3.03335
Value Function Loss: 0.00475

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.59065
Value Function Update Magnitude: 0.51104

Collected Steps per Second: 23,261.65996
Overall Steps per Second: 10,905.94577

Timestep Collection Time: 2.15015
Timestep Consumption Time: 2.43597
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.58612

Cumulative Model Updates: 172,922
Cumulative Timesteps: 1,442,151,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1442151310...
Checkpoint 1442151310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.79878
Policy Entropy: 3.02251
Value Function Loss: 0.00474

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.60018
Value Function Update Magnitude: 0.55512

Collected Steps per Second: 22,524.66194
Overall Steps per Second: 10,680.62399

Timestep Collection Time: 2.22023
Timestep Consumption Time: 2.46208
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.68231

Cumulative Model Updates: 172,928
Cumulative Timesteps: 1,442,201,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.26183
Policy Entropy: 3.03324
Value Function Loss: 0.00479

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10676
Policy Update Magnitude: 0.59551
Value Function Update Magnitude: 0.55388

Collected Steps per Second: 22,811.08872
Overall Steps per Second: 10,788.24271

Timestep Collection Time: 2.19200
Timestep Consumption Time: 2.44286
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.63486

Cumulative Model Updates: 172,934
Cumulative Timesteps: 1,442,251,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1442251322...
Checkpoint 1442251322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,529.38973
Policy Entropy: 3.02912
Value Function Loss: 0.00432

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.52277

Collected Steps per Second: 22,741.71448
Overall Steps per Second: 10,712.83044

Timestep Collection Time: 2.19975
Timestep Consumption Time: 2.46998
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.66973

Cumulative Model Updates: 172,940
Cumulative Timesteps: 1,442,301,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.30977
Policy Entropy: 3.03626
Value Function Loss: 0.00422

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.49525

Collected Steps per Second: 23,065.78419
Overall Steps per Second: 10,679.72753

Timestep Collection Time: 2.16884
Timestep Consumption Time: 2.51536
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.68420

Cumulative Model Updates: 172,946
Cumulative Timesteps: 1,442,351,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1442351374...
Checkpoint 1442351374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,952.98024
Policy Entropy: 3.03627
Value Function Loss: 0.00409

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.57526
Value Function Update Magnitude: 0.49493

Collected Steps per Second: 22,834.84411
Overall Steps per Second: 10,828.10491

Timestep Collection Time: 2.18990
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61817

Cumulative Model Updates: 172,952
Cumulative Timesteps: 1,442,401,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,662.94242
Policy Entropy: 3.05140
Value Function Loss: 0.00388

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.56376
Value Function Update Magnitude: 0.49661

Collected Steps per Second: 23,276.87501
Overall Steps per Second: 10,877.21511

Timestep Collection Time: 2.14934
Timestep Consumption Time: 2.45018
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59952

Cumulative Model Updates: 172,958
Cumulative Timesteps: 1,442,451,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1442451410...
Checkpoint 1442451410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,363.80643
Policy Entropy: 3.05490
Value Function Loss: 0.00371

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.46114

Collected Steps per Second: 22,874.58505
Overall Steps per Second: 10,699.82976

Timestep Collection Time: 2.18609
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.67353

Cumulative Model Updates: 172,964
Cumulative Timesteps: 1,442,501,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,902.65555
Policy Entropy: 3.04539
Value Function Loss: 0.00410

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.55797
Value Function Update Magnitude: 0.45991

Collected Steps per Second: 23,205.08595
Overall Steps per Second: 10,884.92343

Timestep Collection Time: 2.15582
Timestep Consumption Time: 2.44008
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.59590

Cumulative Model Updates: 172,970
Cumulative Timesteps: 1,442,551,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1442551442...
Checkpoint 1442551442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,493.02625
Policy Entropy: 3.02374
Value Function Loss: 0.00447

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.50073

Collected Steps per Second: 22,864.81911
Overall Steps per Second: 10,705.34902

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.67187

Cumulative Model Updates: 172,976
Cumulative Timesteps: 1,442,601,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.52343
Policy Entropy: 3.03200
Value Function Loss: 0.00455

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.58452
Value Function Update Magnitude: 0.52089

Collected Steps per Second: 21,551.30613
Overall Steps per Second: 10,375.66024

Timestep Collection Time: 2.32014
Timestep Consumption Time: 2.49903
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.81916

Cumulative Model Updates: 172,982
Cumulative Timesteps: 1,442,651,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1442651458...
Checkpoint 1442651458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,088.00680
Policy Entropy: 3.03786
Value Function Loss: 0.00458

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11594
Policy Update Magnitude: 0.58758
Value Function Update Magnitude: 0.51212

Collected Steps per Second: 22,277.75902
Overall Steps per Second: 10,681.52443

Timestep Collection Time: 2.24556
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.68341

Cumulative Model Updates: 172,988
Cumulative Timesteps: 1,442,701,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.53004
Policy Entropy: 3.03861
Value Function Loss: 0.00480

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.59301
Value Function Update Magnitude: 0.52107

Collected Steps per Second: 22,767.81710
Overall Steps per Second: 10,685.82568

Timestep Collection Time: 2.19731
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.68172

Cumulative Model Updates: 172,994
Cumulative Timesteps: 1,442,751,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1442751512...
Checkpoint 1442751512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,208.47388
Policy Entropy: 3.04248
Value Function Loss: 0.00463

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.58653
Value Function Update Magnitude: 0.52735

Collected Steps per Second: 23,084.44773
Overall Steps per Second: 10,696.63675

Timestep Collection Time: 2.16683
Timestep Consumption Time: 2.50941
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.67624

Cumulative Model Updates: 173,000
Cumulative Timesteps: 1,442,801,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,789.38325
Policy Entropy: 3.05323
Value Function Loss: 0.00418

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.55987
Value Function Update Magnitude: 0.50604

Collected Steps per Second: 23,436.82803
Overall Steps per Second: 10,789.87106

Timestep Collection Time: 2.13459
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.63657

Cumulative Model Updates: 173,006
Cumulative Timesteps: 1,442,851,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1442851560...
Checkpoint 1442851560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,069.40529
Policy Entropy: 3.08462
Value Function Loss: 0.00426

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.47615

Collected Steps per Second: 23,085.33909
Overall Steps per Second: 10,895.06921

Timestep Collection Time: 2.16666
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.59088

Cumulative Model Updates: 173,012
Cumulative Timesteps: 1,442,901,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.34691
Policy Entropy: 3.08614
Value Function Loss: 0.00456

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 0.50681

Collected Steps per Second: 23,354.44707
Overall Steps per Second: 10,932.35367

Timestep Collection Time: 2.14143
Timestep Consumption Time: 2.43324
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.57468

Cumulative Model Updates: 173,018
Cumulative Timesteps: 1,442,951,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1442951590...
Checkpoint 1442951590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,030.33139
Policy Entropy: 3.06918
Value Function Loss: 0.00468

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.57803
Value Function Update Magnitude: 0.58021

Collected Steps per Second: 22,796.75649
Overall Steps per Second: 10,702.74656

Timestep Collection Time: 2.19365
Timestep Consumption Time: 2.47880
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.67245

Cumulative Model Updates: 173,024
Cumulative Timesteps: 1,443,001,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,622.11411
Policy Entropy: 3.03201
Value Function Loss: 0.00436

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.58130
Value Function Update Magnitude: 0.59742

Collected Steps per Second: 23,360.90368
Overall Steps per Second: 10,887.77070

Timestep Collection Time: 2.14058
Timestep Consumption Time: 2.45227
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.59286

Cumulative Model Updates: 173,030
Cumulative Timesteps: 1,443,051,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1443051604...
Checkpoint 1443051604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393.36884
Policy Entropy: 3.02204
Value Function Loss: 0.00424

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.58049
Value Function Update Magnitude: 0.56305

Collected Steps per Second: 22,411.74105
Overall Steps per Second: 10,658.91723

Timestep Collection Time: 2.23124
Timestep Consumption Time: 2.46023
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.69147

Cumulative Model Updates: 173,036
Cumulative Timesteps: 1,443,101,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,938.43305
Policy Entropy: 3.02300
Value Function Loss: 0.00402

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.57621
Value Function Update Magnitude: 0.54390

Collected Steps per Second: 22,672.17976
Overall Steps per Second: 10,673.36384

Timestep Collection Time: 2.20561
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.68512

Cumulative Model Updates: 173,042
Cumulative Timesteps: 1,443,151,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1443151616...
Checkpoint 1443151616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,706.42048
Policy Entropy: 3.03833
Value Function Loss: 0.00424

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.56826
Value Function Update Magnitude: 0.52503

Collected Steps per Second: 22,383.70628
Overall Steps per Second: 10,585.14953

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.49043
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.72473

Cumulative Model Updates: 173,048
Cumulative Timesteps: 1,443,201,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,968.73136
Policy Entropy: 3.05000
Value Function Loss: 0.00423

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.56327
Value Function Update Magnitude: 0.51118

Collected Steps per Second: 22,902.29624
Overall Steps per Second: 10,712.48801

Timestep Collection Time: 2.18319
Timestep Consumption Time: 2.48426
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.66745

Cumulative Model Updates: 173,054
Cumulative Timesteps: 1,443,251,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1443251628...
Checkpoint 1443251628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,001.23727
Policy Entropy: 3.06289
Value Function Loss: 0.00444

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.56479
Value Function Update Magnitude: 0.50575

Collected Steps per Second: 22,564.40645
Overall Steps per Second: 10,624.21625

Timestep Collection Time: 2.21677
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.70811

Cumulative Model Updates: 173,060
Cumulative Timesteps: 1,443,301,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.87891
Policy Entropy: 3.06008
Value Function Loss: 0.00427

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.56157
Value Function Update Magnitude: 0.50188

Collected Steps per Second: 23,304.11011
Overall Steps per Second: 10,872.79226

Timestep Collection Time: 2.14683
Timestep Consumption Time: 2.45456
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60139

Cumulative Model Updates: 173,066
Cumulative Timesteps: 1,443,351,678

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1443351678...
Checkpoint 1443351678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,489.10922
Policy Entropy: 3.04808
Value Function Loss: 0.00419

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.50692

Collected Steps per Second: 22,974.67658
Overall Steps per Second: 10,689.92041

Timestep Collection Time: 2.17631
Timestep Consumption Time: 2.50099
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.67730

Cumulative Model Updates: 173,072
Cumulative Timesteps: 1,443,401,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,622.26450
Policy Entropy: 3.03919
Value Function Loss: 0.00424

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10942
Policy Update Magnitude: 0.57235
Value Function Update Magnitude: 0.51760

Collected Steps per Second: 23,332.92089
Overall Steps per Second: 10,925.59233

Timestep Collection Time: 2.14332
Timestep Consumption Time: 2.43400
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.57733

Cumulative Model Updates: 173,078
Cumulative Timesteps: 1,443,451,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1443451688...
Checkpoint 1443451688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,843.11222
Policy Entropy: 3.04601
Value Function Loss: 0.00407

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.51221

Collected Steps per Second: 23,126.80680
Overall Steps per Second: 10,720.26786

Timestep Collection Time: 2.16260
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.66537

Cumulative Model Updates: 173,084
Cumulative Timesteps: 1,443,501,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,061.17024
Policy Entropy: 3.04624
Value Function Loss: 0.00378

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.56366
Value Function Update Magnitude: 0.50614

Collected Steps per Second: 23,346.38343
Overall Steps per Second: 10,799.53230

Timestep Collection Time: 2.14200
Timestep Consumption Time: 2.48857
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.63057

Cumulative Model Updates: 173,090
Cumulative Timesteps: 1,443,551,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1443551710...
Checkpoint 1443551710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.52031
Policy Entropy: 3.04127
Value Function Loss: 0.00422

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.58136
Value Function Update Magnitude: 0.50924

Collected Steps per Second: 22,916.12764
Overall Steps per Second: 10,671.01040

Timestep Collection Time: 2.18257
Timestep Consumption Time: 2.50452
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.68709

Cumulative Model Updates: 173,096
Cumulative Timesteps: 1,443,601,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.58985
Policy Entropy: 3.03769
Value Function Loss: 0.00447

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.59089
Value Function Update Magnitude: 0.53669

Collected Steps per Second: 22,702.02796
Overall Steps per Second: 10,783.94097

Timestep Collection Time: 2.20289
Timestep Consumption Time: 2.43456
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.63745

Cumulative Model Updates: 173,102
Cumulative Timesteps: 1,443,651,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1443651736...
Checkpoint 1443651736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.56858
Policy Entropy: 3.02828
Value Function Loss: 0.00488

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.59307
Value Function Update Magnitude: 0.54349

Collected Steps per Second: 22,651.66039
Overall Steps per Second: 10,787.30615

Timestep Collection Time: 2.20743
Timestep Consumption Time: 2.42783
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.63526

Cumulative Model Updates: 173,108
Cumulative Timesteps: 1,443,701,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,838.05525
Policy Entropy: 3.03095
Value Function Loss: 0.00457

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.58709
Value Function Update Magnitude: 0.54179

Collected Steps per Second: 22,613.04784
Overall Steps per Second: 10,622.92996

Timestep Collection Time: 2.21226
Timestep Consumption Time: 2.49698
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.70925

Cumulative Model Updates: 173,114
Cumulative Timesteps: 1,443,751,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1443751764...
Checkpoint 1443751764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.62915
Policy Entropy: 3.03050
Value Function Loss: 0.00452

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.58379
Value Function Update Magnitude: 0.54249

Collected Steps per Second: 22,551.96406
Overall Steps per Second: 10,608.42607

Timestep Collection Time: 2.21763
Timestep Consumption Time: 2.49673
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.71437

Cumulative Model Updates: 173,120
Cumulative Timesteps: 1,443,801,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,874.75174
Policy Entropy: 3.02596
Value Function Loss: 0.00457

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.58681
Value Function Update Magnitude: 0.56972

Collected Steps per Second: 23,258.81753
Overall Steps per Second: 10,727.00271

Timestep Collection Time: 2.15015
Timestep Consumption Time: 2.51191
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.66207

Cumulative Model Updates: 173,126
Cumulative Timesteps: 1,443,851,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1443851786...
Checkpoint 1443851786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.99326
Policy Entropy: 3.01705
Value Function Loss: 0.00439

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.58920
Value Function Update Magnitude: 0.55501

Collected Steps per Second: 22,996.56821
Overall Steps per Second: 10,720.59636

Timestep Collection Time: 2.17554
Timestep Consumption Time: 2.49118
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.66672

Cumulative Model Updates: 173,132
Cumulative Timesteps: 1,443,901,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.19758
Policy Entropy: 3.00967
Value Function Loss: 0.00440

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.58659
Value Function Update Magnitude: 0.51463

Collected Steps per Second: 23,381.50166
Overall Steps per Second: 10,816.74512

Timestep Collection Time: 2.13973
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.62524

Cumulative Model Updates: 173,138
Cumulative Timesteps: 1,443,951,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1443951846...
Checkpoint 1443951846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,446.75402
Policy Entropy: 3.01334
Value Function Loss: 0.00425

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.58041
Value Function Update Magnitude: 0.51062

Collected Steps per Second: 22,961.20403
Overall Steps per Second: 10,666.12835

Timestep Collection Time: 2.17872
Timestep Consumption Time: 2.51146
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.69017

Cumulative Model Updates: 173,144
Cumulative Timesteps: 1,444,001,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.77726
Policy Entropy: 3.02097
Value Function Loss: 0.00400

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10596
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.50689

Collected Steps per Second: 23,107.67135
Overall Steps per Second: 10,846.66763

Timestep Collection Time: 2.16465
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.61155

Cumulative Model Updates: 173,150
Cumulative Timesteps: 1,444,051,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1444051892...
Checkpoint 1444051892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,212.48279
Policy Entropy: 3.03173
Value Function Loss: 0.00410

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.57823
Value Function Update Magnitude: 0.50469

Collected Steps per Second: 22,899.47007
Overall Steps per Second: 10,658.93160

Timestep Collection Time: 2.18450
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.69315

Cumulative Model Updates: 173,156
Cumulative Timesteps: 1,444,101,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.83557
Policy Entropy: 3.03225
Value Function Loss: 0.00441

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.57603
Value Function Update Magnitude: 0.51697

Collected Steps per Second: 22,831.78293
Overall Steps per Second: 10,689.81472

Timestep Collection Time: 2.19054
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.67866

Cumulative Model Updates: 173,162
Cumulative Timesteps: 1,444,151,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1444151930...
Checkpoint 1444151930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,893.74035
Policy Entropy: 3.01663
Value Function Loss: 0.00471

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.58517
Value Function Update Magnitude: 0.54312

Collected Steps per Second: 22,686.77712
Overall Steps per Second: 10,869.80897

Timestep Collection Time: 2.20490
Timestep Consumption Time: 2.39702
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60192

Cumulative Model Updates: 173,168
Cumulative Timesteps: 1,444,201,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,257.10307
Policy Entropy: 3.01375
Value Function Loss: 0.00462

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.60064
Value Function Update Magnitude: 0.57395

Collected Steps per Second: 23,010.93599
Overall Steps per Second: 10,840.78162

Timestep Collection Time: 2.17410
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.61480

Cumulative Model Updates: 173,174
Cumulative Timesteps: 1,444,251,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1444251980...
Checkpoint 1444251980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,038.69338
Policy Entropy: 3.01929
Value Function Loss: 0.00442

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.59688
Value Function Update Magnitude: 0.59280

Collected Steps per Second: 23,010.56502
Overall Steps per Second: 10,770.33380

Timestep Collection Time: 2.17387
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.64442

Cumulative Model Updates: 173,180
Cumulative Timesteps: 1,444,302,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,760.41308
Policy Entropy: 3.03184
Value Function Loss: 0.00437

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.59154
Value Function Update Magnitude: 0.58021

Collected Steps per Second: 23,314.30541
Overall Steps per Second: 10,824.28732

Timestep Collection Time: 2.14478
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.61961

Cumulative Model Updates: 173,186
Cumulative Timesteps: 1,444,352,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1444352006...
Checkpoint 1444352006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,557.96708
Policy Entropy: 3.04545
Value Function Loss: 0.00427

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.59351
Value Function Update Magnitude: 0.56991

Collected Steps per Second: 22,681.36224
Overall Steps per Second: 10,658.16900

Timestep Collection Time: 2.20498
Timestep Consumption Time: 2.48738
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.69236

Cumulative Model Updates: 173,192
Cumulative Timesteps: 1,444,402,018

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,254.88939
Policy Entropy: 3.03822
Value Function Loss: 0.00443

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.59291
Value Function Update Magnitude: 0.54176

Collected Steps per Second: 23,151.78102
Overall Steps per Second: 10,851.96917

Timestep Collection Time: 2.16070
Timestep Consumption Time: 2.44897
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.60967

Cumulative Model Updates: 173,198
Cumulative Timesteps: 1,444,452,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1444452042...
Checkpoint 1444452042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,444.07967
Policy Entropy: 3.03169
Value Function Loss: 0.00476

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.59447
Value Function Update Magnitude: 0.53285

Collected Steps per Second: 22,929.37903
Overall Steps per Second: 10,703.29217

Timestep Collection Time: 2.18078
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.67183

Cumulative Model Updates: 173,204
Cumulative Timesteps: 1,444,502,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,968.05700
Policy Entropy: 3.01726
Value Function Loss: 0.00490

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.58559
Value Function Update Magnitude: 0.52774

Collected Steps per Second: 22,929.52688
Overall Steps per Second: 10,622.82597

Timestep Collection Time: 2.18173
Timestep Consumption Time: 2.52756
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.70929

Cumulative Model Updates: 173,210
Cumulative Timesteps: 1,444,552,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1444552072...
Checkpoint 1444552072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.75711
Policy Entropy: 3.01136
Value Function Loss: 0.00496

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.59305
Value Function Update Magnitude: 0.54670

Collected Steps per Second: 22,572.45882
Overall Steps per Second: 10,621.88371

Timestep Collection Time: 2.21589
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.70896

Cumulative Model Updates: 173,216
Cumulative Timesteps: 1,444,602,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,212.73701
Policy Entropy: 3.01558
Value Function Loss: 0.00504

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.60908
Value Function Update Magnitude: 0.57798

Collected Steps per Second: 22,607.92908
Overall Steps per Second: 10,718.04448

Timestep Collection Time: 2.21223
Timestep Consumption Time: 2.45410
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.66634

Cumulative Model Updates: 173,222
Cumulative Timesteps: 1,444,652,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1444652104...
Checkpoint 1444652104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040.41137
Policy Entropy: 3.02992
Value Function Loss: 0.00507

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.61051
Value Function Update Magnitude: 0.57827

Collected Steps per Second: 22,599.10589
Overall Steps per Second: 10,683.54575

Timestep Collection Time: 2.21354
Timestep Consumption Time: 2.46880
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.68234

Cumulative Model Updates: 173,228
Cumulative Timesteps: 1,444,702,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,438.47206
Policy Entropy: 3.02380
Value Function Loss: 0.00529

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.61409
Value Function Update Magnitude: 0.56317

Collected Steps per Second: 23,060.95879
Overall Steps per Second: 10,881.00022

Timestep Collection Time: 2.16955
Timestep Consumption Time: 2.42855
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.59811

Cumulative Model Updates: 173,234
Cumulative Timesteps: 1,444,752,160

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1444752160...
Checkpoint 1444752160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.17857
Policy Entropy: 3.01316
Value Function Loss: 0.00544

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.60948
Value Function Update Magnitude: 0.55108

Collected Steps per Second: 22,725.08503
Overall Steps per Second: 10,760.64437

Timestep Collection Time: 2.20136
Timestep Consumption Time: 2.44762
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.64898

Cumulative Model Updates: 173,240
Cumulative Timesteps: 1,444,802,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,454.70825
Policy Entropy: 3.00472
Value Function Loss: 0.00535

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.60340
Value Function Update Magnitude: 0.53422

Collected Steps per Second: 23,444.05428
Overall Steps per Second: 10,870.28500

Timestep Collection Time: 2.13350
Timestep Consumption Time: 2.46785
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.60135

Cumulative Model Updates: 173,246
Cumulative Timesteps: 1,444,852,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1444852204...
Checkpoint 1444852204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.99331
Policy Entropy: 2.99650
Value Function Loss: 0.00545

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.61422
Value Function Update Magnitude: 0.53199

Collected Steps per Second: 23,230.41322
Overall Steps per Second: 10,747.27624

Timestep Collection Time: 2.15330
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.65439

Cumulative Model Updates: 173,252
Cumulative Timesteps: 1,444,902,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.60947
Policy Entropy: 2.99671
Value Function Loss: 0.00504

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.61447
Value Function Update Magnitude: 0.53653

Collected Steps per Second: 23,401.85634
Overall Steps per Second: 10,809.18332

Timestep Collection Time: 2.13761
Timestep Consumption Time: 2.49031
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.62792

Cumulative Model Updates: 173,258
Cumulative Timesteps: 1,444,952,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1444952250...
Checkpoint 1444952250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.88006
Policy Entropy: 2.99517
Value Function Loss: 0.00490

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10863
Policy Update Magnitude: 0.60973
Value Function Update Magnitude: 0.55988

Collected Steps per Second: 22,911.56776
Overall Steps per Second: 10,771.91347

Timestep Collection Time: 2.18274
Timestep Consumption Time: 2.45989
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.64263

Cumulative Model Updates: 173,264
Cumulative Timesteps: 1,445,002,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.74724
Policy Entropy: 3.00033
Value Function Loss: 0.00477

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.61596
Value Function Update Magnitude: 0.56819

Collected Steps per Second: 23,060.07127
Overall Steps per Second: 10,763.05712

Timestep Collection Time: 2.16964
Timestep Consumption Time: 2.47886
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.64849

Cumulative Model Updates: 173,270
Cumulative Timesteps: 1,445,052,292

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1445052292...
Checkpoint 1445052292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.10736
Policy Entropy: 3.00693
Value Function Loss: 0.00489

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.61915
Value Function Update Magnitude: 0.55843

Collected Steps per Second: 22,562.90935
Overall Steps per Second: 10,628.61027

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.48856
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.70485

Cumulative Model Updates: 173,276
Cumulative Timesteps: 1,445,102,298

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.75629
Policy Entropy: 3.01212
Value Function Loss: 0.00491

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.60493
Value Function Update Magnitude: 0.54792

Collected Steps per Second: 22,879.37700
Overall Steps per Second: 10,860.12479

Timestep Collection Time: 2.18660
Timestep Consumption Time: 2.41998
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.60658

Cumulative Model Updates: 173,282
Cumulative Timesteps: 1,445,152,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1445152326...
Checkpoint 1445152326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,766.17747
Policy Entropy: 3.01897
Value Function Loss: 0.00517

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11471
Policy Update Magnitude: 0.59489
Value Function Update Magnitude: 0.55773

Collected Steps per Second: 22,408.99120
Overall Steps per Second: 10,723.28784

Timestep Collection Time: 2.23187
Timestep Consumption Time: 2.43218
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.66405

Cumulative Model Updates: 173,288
Cumulative Timesteps: 1,445,202,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.45651
Policy Entropy: 3.01228
Value Function Loss: 0.00509

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.59617
Value Function Update Magnitude: 0.55284

Collected Steps per Second: 22,918.94861
Overall Steps per Second: 10,853.07805

Timestep Collection Time: 2.18317
Timestep Consumption Time: 2.42713
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61030

Cumulative Model Updates: 173,294
Cumulative Timesteps: 1,445,252,376

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1445252376...
Checkpoint 1445252376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,965.14659
Policy Entropy: 2.99836
Value Function Loss: 0.00554

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.60483
Value Function Update Magnitude: 0.56227

Collected Steps per Second: 23,081.70154
Overall Steps per Second: 10,728.19420

Timestep Collection Time: 2.16726
Timestep Consumption Time: 2.49560
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.66285

Cumulative Model Updates: 173,300
Cumulative Timesteps: 1,445,302,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.21392
Policy Entropy: 2.98320
Value Function Loss: 0.00538

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.61484
Value Function Update Magnitude: 0.58649

Collected Steps per Second: 23,386.07328
Overall Steps per Second: 10,870.71191

Timestep Collection Time: 2.13965
Timestep Consumption Time: 2.46336
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.60301

Cumulative Model Updates: 173,306
Cumulative Timesteps: 1,445,352,438

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1445352438...
Checkpoint 1445352438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,135.53209
Policy Entropy: 2.99450
Value Function Loss: 0.00497

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.60927
Value Function Update Magnitude: 0.59237

Collected Steps per Second: 23,200.96177
Overall Steps per Second: 10,753.14313

Timestep Collection Time: 2.15577
Timestep Consumption Time: 2.49552
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.65129

Cumulative Model Updates: 173,312
Cumulative Timesteps: 1,445,402,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770.54886
Policy Entropy: 2.99118
Value Function Loss: 0.00468

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.60568
Value Function Update Magnitude: 0.58018

Collected Steps per Second: 23,156.00714
Overall Steps per Second: 10,792.03315

Timestep Collection Time: 2.16048
Timestep Consumption Time: 2.47517
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.63564

Cumulative Model Updates: 173,318
Cumulative Timesteps: 1,445,452,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1445452482...
Checkpoint 1445452482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.29125
Policy Entropy: 3.00280
Value Function Loss: 0.00451

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.61106
Value Function Update Magnitude: 0.56722

Collected Steps per Second: 23,253.66557
Overall Steps per Second: 10,869.46223

Timestep Collection Time: 2.15089
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.60152

Cumulative Model Updates: 173,324
Cumulative Timesteps: 1,445,502,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,292.30496
Policy Entropy: 2.99393
Value Function Loss: 0.00462

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.61718
Value Function Update Magnitude: 0.55219

Collected Steps per Second: 23,441.43423
Overall Steps per Second: 10,818.94940

Timestep Collection Time: 2.13391
Timestep Consumption Time: 2.48964
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.62355

Cumulative Model Updates: 173,330
Cumulative Timesteps: 1,445,552,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1445552520...
Checkpoint 1445552520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.09645
Policy Entropy: 2.99447
Value Function Loss: 0.00483

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.61047
Value Function Update Magnitude: 0.55303

Collected Steps per Second: 22,657.46373
Overall Steps per Second: 10,879.24252

Timestep Collection Time: 2.20748
Timestep Consumption Time: 2.38989
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.59738

Cumulative Model Updates: 173,336
Cumulative Timesteps: 1,445,602,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,538.17430
Policy Entropy: 2.98836
Value Function Loss: 0.00481

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.60867
Value Function Update Magnitude: 0.55078

Collected Steps per Second: 22,683.94306
Overall Steps per Second: 10,694.72085

Timestep Collection Time: 2.20482
Timestep Consumption Time: 2.47169
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.67651

Cumulative Model Updates: 173,342
Cumulative Timesteps: 1,445,652,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1445652550...
Checkpoint 1445652550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,852.94325
Policy Entropy: 2.97939
Value Function Loss: 0.00488

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.61756
Value Function Update Magnitude: 0.55469

Collected Steps per Second: 22,339.14292
Overall Steps per Second: 10,647.92511

Timestep Collection Time: 2.23903
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.69744

Cumulative Model Updates: 173,348
Cumulative Timesteps: 1,445,702,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.70595
Policy Entropy: 2.98794
Value Function Loss: 0.00475

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.62539
Value Function Update Magnitude: 0.56367

Collected Steps per Second: 22,731.69449
Overall Steps per Second: 10,719.27492

Timestep Collection Time: 2.20089
Timestep Consumption Time: 2.46640
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.66729

Cumulative Model Updates: 173,354
Cumulative Timesteps: 1,445,752,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1445752598...
Checkpoint 1445752598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,528.32872
Policy Entropy: 3.00150
Value Function Loss: 0.00462

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.61148
Value Function Update Magnitude: 0.55007

Collected Steps per Second: 23,143.63230
Overall Steps per Second: 10,670.94984

Timestep Collection Time: 2.16111
Timestep Consumption Time: 2.52601
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.68712

Cumulative Model Updates: 173,360
Cumulative Timesteps: 1,445,802,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,583.23612
Policy Entropy: 3.00123
Value Function Loss: 0.00482

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.60808
Value Function Update Magnitude: 0.52792

Collected Steps per Second: 23,156.54017
Overall Steps per Second: 10,830.46849

Timestep Collection Time: 2.16034
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.61901

Cumulative Model Updates: 173,366
Cumulative Timesteps: 1,445,852,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1445852640...
Checkpoint 1445852640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.82877
Policy Entropy: 3.01271
Value Function Loss: 0.00451

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12026
Policy Update Magnitude: 0.61300
Value Function Update Magnitude: 0.54025

Collected Steps per Second: 23,269.37836
Overall Steps per Second: 10,717.71453

Timestep Collection Time: 2.14995
Timestep Consumption Time: 2.51784
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.66779

Cumulative Model Updates: 173,372
Cumulative Timesteps: 1,445,902,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.46425
Policy Entropy: 2.99634
Value Function Loss: 0.00436

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.60714
Value Function Update Magnitude: 0.53682

Collected Steps per Second: 23,347.73896
Overall Steps per Second: 10,877.33315

Timestep Collection Time: 2.14196
Timestep Consumption Time: 2.45567
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.59763

Cumulative Model Updates: 173,378
Cumulative Timesteps: 1,445,952,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1445952678...
Checkpoint 1445952678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,458.20043
Policy Entropy: 2.99461
Value Function Loss: 0.00434

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.61201
Value Function Update Magnitude: 0.54176

Collected Steps per Second: 22,893.06891
Overall Steps per Second: 10,705.06608

Timestep Collection Time: 2.18538
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.67349

Cumulative Model Updates: 173,384
Cumulative Timesteps: 1,446,002,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,328.46861
Policy Entropy: 2.97621
Value Function Loss: 0.00440

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.60870
Value Function Update Magnitude: 0.54735

Collected Steps per Second: 23,298.03637
Overall Steps per Second: 10,882.14397

Timestep Collection Time: 2.14628
Timestep Consumption Time: 2.44878
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.59505

Cumulative Model Updates: 173,390
Cumulative Timesteps: 1,446,052,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1446052712...
Checkpoint 1446052712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,235.31085
Policy Entropy: 2.97027
Value Function Loss: 0.00475

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.61313
Value Function Update Magnitude: 0.54714

Collected Steps per Second: 22,463.87016
Overall Steps per Second: 10,608.09859

Timestep Collection Time: 2.22624
Timestep Consumption Time: 2.48808
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.71432

Cumulative Model Updates: 173,396
Cumulative Timesteps: 1,446,102,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.32074
Policy Entropy: 2.97594
Value Function Loss: 0.00524

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.62933
Value Function Update Magnitude: 0.56970

Collected Steps per Second: 22,710.95019
Overall Steps per Second: 10,863.23844

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.40177
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60397

Cumulative Model Updates: 173,402
Cumulative Timesteps: 1,446,152,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1446152736...
Checkpoint 1446152736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465.66448
Policy Entropy: 2.98997
Value Function Loss: 0.00498

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.62254
Value Function Update Magnitude: 0.58944

Collected Steps per Second: 22,530.04524
Overall Steps per Second: 10,773.80965

Timestep Collection Time: 2.21970
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.64181

Cumulative Model Updates: 173,408
Cumulative Timesteps: 1,446,202,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.94930
Policy Entropy: 2.99568
Value Function Loss: 0.00488

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.61004
Value Function Update Magnitude: 0.56850

Collected Steps per Second: 22,834.48731
Overall Steps per Second: 10,790.74662

Timestep Collection Time: 2.19072
Timestep Consumption Time: 2.44510
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.63582

Cumulative Model Updates: 173,414
Cumulative Timesteps: 1,446,252,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1446252770...
Checkpoint 1446252770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.53503
Policy Entropy: 2.99375
Value Function Loss: 0.00447

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.60490
Value Function Update Magnitude: 0.53676

Collected Steps per Second: 22,994.19720
Overall Steps per Second: 10,691.60014

Timestep Collection Time: 2.17507
Timestep Consumption Time: 2.50281
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.67788

Cumulative Model Updates: 173,420
Cumulative Timesteps: 1,446,302,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,206.69548
Policy Entropy: 2.97654
Value Function Loss: 0.00472

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.61186
Value Function Update Magnitude: 0.51720

Collected Steps per Second: 23,285.79387
Overall Steps per Second: 10,914.42164

Timestep Collection Time: 2.14904
Timestep Consumption Time: 2.43591
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.58494

Cumulative Model Updates: 173,426
Cumulative Timesteps: 1,446,352,826

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1446352826...
Checkpoint 1446352826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,944.85021
Policy Entropy: 2.97629
Value Function Loss: 0.00459

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.61366
Value Function Update Magnitude: 0.52179

Collected Steps per Second: 22,731.31109
Overall Steps per Second: 10,630.10218

Timestep Collection Time: 2.20049
Timestep Consumption Time: 2.50502
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.70551

Cumulative Model Updates: 173,432
Cumulative Timesteps: 1,446,402,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,038.09039
Policy Entropy: 2.99389
Value Function Loss: 0.00427

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.59299
Value Function Update Magnitude: 0.51341

Collected Steps per Second: 22,921.37913
Overall Steps per Second: 10,801.37317

Timestep Collection Time: 2.18198
Timestep Consumption Time: 2.44836
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.63034

Cumulative Model Updates: 173,438
Cumulative Timesteps: 1,446,452,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1446452860...
Checkpoint 1446452860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,952.53508
Policy Entropy: 3.00226
Value Function Loss: 0.00409

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.58321
Value Function Update Magnitude: 0.49446

Collected Steps per Second: 21,329.97718
Overall Steps per Second: 10,308.43939

Timestep Collection Time: 2.34459
Timestep Consumption Time: 2.50678
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.85136

Cumulative Model Updates: 173,444
Cumulative Timesteps: 1,446,502,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,429.58026
Policy Entropy: 3.00617
Value Function Loss: 0.00387

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.49199

Collected Steps per Second: 22,254.53528
Overall Steps per Second: 10,459.51793

Timestep Collection Time: 2.24718
Timestep Consumption Time: 2.53411
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.78129

Cumulative Model Updates: 173,450
Cumulative Timesteps: 1,446,552,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1446552880...
Checkpoint 1446552880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,624.55453
Policy Entropy: 2.99442
Value Function Loss: 0.00413

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.58080
Value Function Update Magnitude: 0.48403

Collected Steps per Second: 22,502.28263
Overall Steps per Second: 10,665.05741

Timestep Collection Time: 2.22200
Timestep Consumption Time: 2.46621
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.68821

Cumulative Model Updates: 173,456
Cumulative Timesteps: 1,446,602,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.58285
Policy Entropy: 2.97626
Value Function Loss: 0.00495

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.60009
Value Function Update Magnitude: 0.49784

Collected Steps per Second: 22,734.97577
Overall Steps per Second: 10,620.80901

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.70962

Cumulative Model Updates: 173,462
Cumulative Timesteps: 1,446,652,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1446652900...
Checkpoint 1446652900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.66252
Policy Entropy: 2.97636
Value Function Loss: 0.00536

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.61812
Value Function Update Magnitude: 0.52208

Collected Steps per Second: 23,340.12166
Overall Steps per Second: 10,805.05805

Timestep Collection Time: 2.14309
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.62931

Cumulative Model Updates: 173,468
Cumulative Timesteps: 1,446,702,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.82773
Policy Entropy: 2.98575
Value Function Loss: 0.00528

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.61693
Value Function Update Magnitude: 0.54451

Collected Steps per Second: 22,856.98302
Overall Steps per Second: 10,677.48093

Timestep Collection Time: 2.18795
Timestep Consumption Time: 2.49574
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.68369

Cumulative Model Updates: 173,474
Cumulative Timesteps: 1,446,752,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1446752930...
Checkpoint 1446752930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.71568
Policy Entropy: 3.01116
Value Function Loss: 0.00482

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.61253
Value Function Update Magnitude: 0.54816

Collected Steps per Second: 23,129.45899
Overall Steps per Second: 10,863.61245

Timestep Collection Time: 2.16270
Timestep Consumption Time: 2.44185
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.60455

Cumulative Model Updates: 173,480
Cumulative Timesteps: 1,446,802,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,939.89003
Policy Entropy: 3.02888
Value Function Loss: 0.00451

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.60184
Value Function Update Magnitude: 0.55437

Collected Steps per Second: 23,148.58203
Overall Steps per Second: 10,748.05431

Timestep Collection Time: 2.16074
Timestep Consumption Time: 2.49294
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.65368

Cumulative Model Updates: 173,486
Cumulative Timesteps: 1,446,852,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1446852970...
Checkpoint 1446852970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.45531
Policy Entropy: 3.02157
Value Function Loss: 0.00475

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11592
Policy Update Magnitude: 0.59487
Value Function Update Magnitude: 0.57473

Collected Steps per Second: 23,489.20368
Overall Steps per Second: 10,870.77668

Timestep Collection Time: 2.12974
Timestep Consumption Time: 2.47213
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.60188

Cumulative Model Updates: 173,492
Cumulative Timesteps: 1,446,902,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,651.99107
Policy Entropy: 3.01773
Value Function Loss: 0.00449

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.59729
Value Function Update Magnitude: 0.58718

Collected Steps per Second: 22,865.14525
Overall Steps per Second: 10,696.99565

Timestep Collection Time: 2.18735
Timestep Consumption Time: 2.48817
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.67552

Cumulative Model Updates: 173,498
Cumulative Timesteps: 1,446,953,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1446953010...
Checkpoint 1446953010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.75405
Policy Entropy: 3.00201
Value Function Loss: 0.00465

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.59828
Value Function Update Magnitude: 0.56274

Collected Steps per Second: 22,818.58843
Overall Steps per Second: 10,813.70983

Timestep Collection Time: 2.19172
Timestep Consumption Time: 2.43315
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.62487

Cumulative Model Updates: 173,504
Cumulative Timesteps: 1,447,003,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640.41071
Policy Entropy: 3.00227
Value Function Loss: 0.00481

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.60644
Value Function Update Magnitude: 0.56685

Collected Steps per Second: 22,605.50074
Overall Steps per Second: 10,585.91612

Timestep Collection Time: 2.21194
Timestep Consumption Time: 2.51151
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.72345

Cumulative Model Updates: 173,510
Cumulative Timesteps: 1,447,053,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1447053024...
Checkpoint 1447053024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.41960
Policy Entropy: 2.98410
Value Function Loss: 0.00511

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.61040
Value Function Update Magnitude: 0.59109

Collected Steps per Second: 22,807.55492
Overall Steps per Second: 10,648.16012

Timestep Collection Time: 2.19261
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.69640

Cumulative Model Updates: 173,516
Cumulative Timesteps: 1,447,103,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,078.12792
Policy Entropy: 2.99655
Value Function Loss: 0.00518

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.60822
Value Function Update Magnitude: 0.59161

Collected Steps per Second: 22,780.43272
Overall Steps per Second: 10,873.82353

Timestep Collection Time: 2.19522
Timestep Consumption Time: 2.40372
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.59893

Cumulative Model Updates: 173,522
Cumulative Timesteps: 1,447,153,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1447153040...
Checkpoint 1447153040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.92086
Policy Entropy: 3.00586
Value Function Loss: 0.00505

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.60987
Value Function Update Magnitude: 0.56794

Collected Steps per Second: 23,231.96029
Overall Steps per Second: 10,785.91431

Timestep Collection Time: 2.15247
Timestep Consumption Time: 2.48377
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.63623

Cumulative Model Updates: 173,528
Cumulative Timesteps: 1,447,203,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,553.52066
Policy Entropy: 3.01649
Value Function Loss: 0.00475

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.60520
Value Function Update Magnitude: 0.54757

Collected Steps per Second: 23,098.83762
Overall Steps per Second: 10,667.84565

Timestep Collection Time: 2.16565
Timestep Consumption Time: 2.52358
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.68923

Cumulative Model Updates: 173,534
Cumulative Timesteps: 1,447,253,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1447253070...
Checkpoint 1447253070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.67476
Policy Entropy: 3.02225
Value Function Loss: 0.00471

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.60190
Value Function Update Magnitude: 0.53112

Collected Steps per Second: 22,931.43055
Overall Steps per Second: 10,733.25865

Timestep Collection Time: 2.18111
Timestep Consumption Time: 2.47880
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.65991

Cumulative Model Updates: 173,540
Cumulative Timesteps: 1,447,303,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,709.56597
Policy Entropy: 3.02263
Value Function Loss: 0.00483

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.61269
Value Function Update Magnitude: 0.54255

Collected Steps per Second: 23,125.49340
Overall Steps per Second: 10,871.05177

Timestep Collection Time: 2.16341
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60213

Cumulative Model Updates: 173,546
Cumulative Timesteps: 1,447,353,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1447353116...
Checkpoint 1447353116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,892.70704
Policy Entropy: 3.01940
Value Function Loss: 0.00452

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.60512
Value Function Update Magnitude: 0.53698

Collected Steps per Second: 22,900.06924
Overall Steps per Second: 10,639.18924

Timestep Collection Time: 2.18410
Timestep Consumption Time: 2.51701
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.70111

Cumulative Model Updates: 173,552
Cumulative Timesteps: 1,447,403,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,827.46592
Policy Entropy: 3.01594
Value Function Loss: 0.00437

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.59420
Value Function Update Magnitude: 0.51817

Collected Steps per Second: 23,140.93325
Overall Steps per Second: 10,865.18241

Timestep Collection Time: 2.16085
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.60222

Cumulative Model Updates: 173,558
Cumulative Timesteps: 1,447,453,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1447453136...
Checkpoint 1447453136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,999.26361
Policy Entropy: 3.00478
Value Function Loss: 0.00460

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11480
Policy Update Magnitude: 0.59671
Value Function Update Magnitude: 0.50956

Collected Steps per Second: 22,873.32744
Overall Steps per Second: 10,676.35893

Timestep Collection Time: 2.18691
Timestep Consumption Time: 2.49839
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.68531

Cumulative Model Updates: 173,564
Cumulative Timesteps: 1,447,503,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,811.86819
Policy Entropy: 3.01653
Value Function Loss: 0.00466

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.59132
Value Function Update Magnitude: 0.50398

Collected Steps per Second: 22,447.65035
Overall Steps per Second: 10,585.63914

Timestep Collection Time: 2.22776
Timestep Consumption Time: 2.49638
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.72414

Cumulative Model Updates: 173,570
Cumulative Timesteps: 1,447,553,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1447553166...
Checkpoint 1447553166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,021.44655
Policy Entropy: 3.01373
Value Function Loss: 0.00476

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.58304
Value Function Update Magnitude: 0.47636

Collected Steps per Second: 22,972.85455
Overall Steps per Second: 10,843.81650

Timestep Collection Time: 2.17735
Timestep Consumption Time: 2.43541
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.61277

Cumulative Model Updates: 173,576
Cumulative Timesteps: 1,447,603,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,488.89473
Policy Entropy: 3.02198
Value Function Loss: 0.00473

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.57964
Value Function Update Magnitude: 0.46754

Collected Steps per Second: 22,441.83100
Overall Steps per Second: 10,549.89870

Timestep Collection Time: 2.22798
Timestep Consumption Time: 2.51140
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.73938

Cumulative Model Updates: 173,582
Cumulative Timesteps: 1,447,653,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1447653186...
Checkpoint 1447653186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,784.93115
Policy Entropy: 3.01503
Value Function Loss: 0.00477

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.48164

Collected Steps per Second: 22,957.50154
Overall Steps per Second: 10,650.07522

Timestep Collection Time: 2.17820
Timestep Consumption Time: 2.51717
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.69537

Cumulative Model Updates: 173,588
Cumulative Timesteps: 1,447,703,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,153.53173
Policy Entropy: 3.01029
Value Function Loss: 0.00490

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.59384
Value Function Update Magnitude: 0.51857

Collected Steps per Second: 22,946.09842
Overall Steps per Second: 10,613.03590

Timestep Collection Time: 2.17919
Timestep Consumption Time: 2.53237
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.71156

Cumulative Model Updates: 173,594
Cumulative Timesteps: 1,447,753,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1447753196...
Checkpoint 1447753196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.32729
Policy Entropy: 3.01680
Value Function Loss: 0.00518

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.60766
Value Function Update Magnitude: 0.53024

Collected Steps per Second: 22,988.76042
Overall Steps per Second: 10,841.04037

Timestep Collection Time: 2.17541
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.61303

Cumulative Model Updates: 173,600
Cumulative Timesteps: 1,447,803,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.68975
Policy Entropy: 3.02896
Value Function Loss: 0.00490

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.59754
Value Function Update Magnitude: 0.52784

Collected Steps per Second: 22,808.31764
Overall Steps per Second: 10,669.89229

Timestep Collection Time: 2.19376
Timestep Consumption Time: 2.49570
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.68946

Cumulative Model Updates: 173,606
Cumulative Timesteps: 1,447,853,242

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1447853242...
Checkpoint 1447853242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,960.55714
Policy Entropy: 3.04477
Value Function Loss: 0.00476

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.59690
Value Function Update Magnitude: 0.53597

Collected Steps per Second: 23,004.96940
Overall Steps per Second: 10,862.96205

Timestep Collection Time: 2.17449
Timestep Consumption Time: 2.43052
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.60501

Cumulative Model Updates: 173,612
Cumulative Timesteps: 1,447,903,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.05783
Policy Entropy: 3.06986
Value Function Loss: 0.00433

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.58098
Value Function Update Magnitude: 0.53406

Collected Steps per Second: 22,563.61668
Overall Steps per Second: 10,555.28659

Timestep Collection Time: 2.21640
Timestep Consumption Time: 2.52151
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.73791

Cumulative Model Updates: 173,618
Cumulative Timesteps: 1,447,953,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1447953276...
Checkpoint 1447953276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,121.15404
Policy Entropy: 3.05760
Value Function Loss: 0.00499

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.58385
Value Function Update Magnitude: 0.55759

Collected Steps per Second: 23,119.61618
Overall Steps per Second: 10,715.60885

Timestep Collection Time: 2.16318
Timestep Consumption Time: 2.50403
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.66721

Cumulative Model Updates: 173,624
Cumulative Timesteps: 1,448,003,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,830.34931
Policy Entropy: 3.05330
Value Function Loss: 0.00493

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10570
Policy Update Magnitude: 0.59957
Value Function Update Magnitude: 0.57824

Collected Steps per Second: 23,050.76518
Overall Steps per Second: 10,839.21216

Timestep Collection Time: 2.17034
Timestep Consumption Time: 2.44512
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61546

Cumulative Model Updates: 173,630
Cumulative Timesteps: 1,448,053,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1448053316...
Checkpoint 1448053316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.02342
Policy Entropy: 3.04218
Value Function Loss: 0.00482

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.59951
Value Function Update Magnitude: 0.58458

Collected Steps per Second: 22,816.29860
Overall Steps per Second: 10,638.14924

Timestep Collection Time: 2.19247
Timestep Consumption Time: 2.50985
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70232

Cumulative Model Updates: 173,636
Cumulative Timesteps: 1,448,103,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,957.88492
Policy Entropy: 3.04013
Value Function Loss: 0.00459

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.58991
Value Function Update Magnitude: 0.54592

Collected Steps per Second: 22,774.70139
Overall Steps per Second: 10,693.96689

Timestep Collection Time: 2.19559
Timestep Consumption Time: 2.48031
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.67591

Cumulative Model Updates: 173,642
Cumulative Timesteps: 1,448,153,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1448153344...
Checkpoint 1448153344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,472.86014
Policy Entropy: 3.04575
Value Function Loss: 0.00433

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.58512
Value Function Update Magnitude: 0.52300

Collected Steps per Second: 22,787.39434
Overall Steps per Second: 10,831.62572

Timestep Collection Time: 2.19551
Timestep Consumption Time: 2.42337
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.61888

Cumulative Model Updates: 173,648
Cumulative Timesteps: 1,448,203,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,442.31022
Policy Entropy: 3.04869
Value Function Loss: 0.00386

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.56582
Value Function Update Magnitude: 0.52041

Collected Steps per Second: 22,834.11483
Overall Steps per Second: 10,819.41439

Timestep Collection Time: 2.19102
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.62410

Cumulative Model Updates: 173,654
Cumulative Timesteps: 1,448,253,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1448253404...
Checkpoint 1448253404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,775.77443
Policy Entropy: 3.05964
Value Function Loss: 0.00382

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.55788
Value Function Update Magnitude: 0.50939

Collected Steps per Second: 22,767.33512
Overall Steps per Second: 10,697.60655

Timestep Collection Time: 2.19674
Timestep Consumption Time: 2.47851
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.67525

Cumulative Model Updates: 173,660
Cumulative Timesteps: 1,448,303,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,048.85300
Policy Entropy: 3.05776
Value Function Loss: 0.00404

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.56697
Value Function Update Magnitude: 0.48690

Collected Steps per Second: 23,228.44665
Overall Steps per Second: 10,861.90301

Timestep Collection Time: 2.15331
Timestep Consumption Time: 2.45159
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.60490

Cumulative Model Updates: 173,666
Cumulative Timesteps: 1,448,353,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1448353436...
Checkpoint 1448353436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831.71581
Policy Entropy: 3.04236
Value Function Loss: 0.00453

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12071
Policy Update Magnitude: 0.58241
Value Function Update Magnitude: 0.49178

Collected Steps per Second: 22,555.81631
Overall Steps per Second: 10,638.57594

Timestep Collection Time: 2.21770
Timestep Consumption Time: 2.48425
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.70195

Cumulative Model Updates: 173,672
Cumulative Timesteps: 1,448,403,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,809.06539
Policy Entropy: 3.03284
Value Function Loss: 0.00450

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.58187
Value Function Update Magnitude: 0.51697

Collected Steps per Second: 23,265.67211
Overall Steps per Second: 10,868.93884

Timestep Collection Time: 2.14909
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.60027

Cumulative Model Updates: 173,678
Cumulative Timesteps: 1,448,453,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1448453458...
Checkpoint 1448453458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,128.27373
Policy Entropy: 3.02923
Value Function Loss: 0.00437

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.58008
Value Function Update Magnitude: 0.54302

Collected Steps per Second: 23,130.43689
Overall Steps per Second: 10,783.17241

Timestep Collection Time: 2.16252
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.63871

Cumulative Model Updates: 173,684
Cumulative Timesteps: 1,448,503,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.35843
Policy Entropy: 3.02227
Value Function Loss: 0.00416

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.57748
Value Function Update Magnitude: 0.55237

Collected Steps per Second: 23,005.44283
Overall Steps per Second: 10,850.08237

Timestep Collection Time: 2.17383
Timestep Consumption Time: 2.43535
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60918

Cumulative Model Updates: 173,690
Cumulative Timesteps: 1,448,553,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1448553488...
Checkpoint 1448553488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,123.93851
Policy Entropy: 3.02491
Value Function Loss: 0.00427

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.56868
Value Function Update Magnitude: 0.53947

Collected Steps per Second: 22,235.61951
Overall Steps per Second: 10,662.51774

Timestep Collection Time: 2.24954
Timestep Consumption Time: 2.44166
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.69120

Cumulative Model Updates: 173,696
Cumulative Timesteps: 1,448,603,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,842.38968
Policy Entropy: 3.02063
Value Function Loss: 0.00443

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11632
Policy Update Magnitude: 0.57755
Value Function Update Magnitude: 0.51697

Collected Steps per Second: 22,729.13400
Overall Steps per Second: 10,651.25212

Timestep Collection Time: 2.20035
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.69541

Cumulative Model Updates: 173,702
Cumulative Timesteps: 1,448,653,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1448653520...
Checkpoint 1448653520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,779.22609
Policy Entropy: 3.01232
Value Function Loss: 0.00485

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.59458
Value Function Update Magnitude: 0.54287

Collected Steps per Second: 22,747.06468
Overall Steps per Second: 10,704.21917

Timestep Collection Time: 2.19844
Timestep Consumption Time: 2.47337
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.67180

Cumulative Model Updates: 173,708
Cumulative Timesteps: 1,448,703,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.01751
Policy Entropy: 3.00931
Value Function Loss: 0.00482

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.60337
Value Function Update Magnitude: 0.56508

Collected Steps per Second: 22,757.82408
Overall Steps per Second: 10,699.83127

Timestep Collection Time: 2.19898
Timestep Consumption Time: 2.47810
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.67708

Cumulative Model Updates: 173,714
Cumulative Timesteps: 1,448,753,572

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1448753572...
Checkpoint 1448753572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.18823
Policy Entropy: 3.02414
Value Function Loss: 0.00477

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.59614
Value Function Update Magnitude: 0.55866

Collected Steps per Second: 22,832.38419
Overall Steps per Second: 10,639.43357

Timestep Collection Time: 2.19075
Timestep Consumption Time: 2.51063
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.70138

Cumulative Model Updates: 173,720
Cumulative Timesteps: 1,448,803,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,444.58592
Policy Entropy: 3.02643
Value Function Loss: 0.00460

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.59991
Value Function Update Magnitude: 0.56171

Collected Steps per Second: 22,898.02820
Overall Steps per Second: 10,631.62084

Timestep Collection Time: 2.18473
Timestep Consumption Time: 2.52067
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.70540

Cumulative Model Updates: 173,726
Cumulative Timesteps: 1,448,853,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1448853618...
Checkpoint 1448853618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,043.07183
Policy Entropy: 3.03640
Value Function Loss: 0.00446

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.59157
Value Function Update Magnitude: 0.57443

Collected Steps per Second: 23,077.49782
Overall Steps per Second: 10,816.75756

Timestep Collection Time: 2.16687
Timestep Consumption Time: 2.45614
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.62301

Cumulative Model Updates: 173,732
Cumulative Timesteps: 1,448,903,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,849.66120
Policy Entropy: 3.02901
Value Function Loss: 0.00411

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.57231
Value Function Update Magnitude: 0.55750

Collected Steps per Second: 23,007.35079
Overall Steps per Second: 10,740.09800

Timestep Collection Time: 2.17417
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.65750

Cumulative Model Updates: 173,738
Cumulative Timesteps: 1,448,953,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1448953646...
Checkpoint 1448953646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,638.27459
Policy Entropy: 3.03284
Value Function Loss: 0.00366

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.51770

Collected Steps per Second: 23,112.96226
Overall Steps per Second: 10,914.82979

Timestep Collection Time: 2.16476
Timestep Consumption Time: 2.41928
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.58404

Cumulative Model Updates: 173,744
Cumulative Timesteps: 1,449,003,680

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,558.25570
Policy Entropy: 3.02184
Value Function Loss: 0.00404

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.56712
Value Function Update Magnitude: 0.53453

Collected Steps per Second: 23,246.07210
Overall Steps per Second: 10,919.11288

Timestep Collection Time: 2.15159
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.58059

Cumulative Model Updates: 173,750
Cumulative Timesteps: 1,449,053,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1449053696...
Checkpoint 1449053696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126.30724
Policy Entropy: 3.02747
Value Function Loss: 0.00412

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.57532
Value Function Update Magnitude: 0.57242

Collected Steps per Second: 23,049.94901
Overall Steps per Second: 10,717.83013

Timestep Collection Time: 2.16946
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.66568

Cumulative Model Updates: 173,756
Cumulative Timesteps: 1,449,103,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,054.97098
Policy Entropy: 3.02949
Value Function Loss: 0.00437

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.57879
Value Function Update Magnitude: 0.56466

Collected Steps per Second: 22,732.18716
Overall Steps per Second: 10,802.32283

Timestep Collection Time: 2.20084
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.63141

Cumulative Model Updates: 173,762
Cumulative Timesteps: 1,449,153,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1449153732...
Checkpoint 1449153732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869.39451
Policy Entropy: 3.03701
Value Function Loss: 0.00438

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.59005
Value Function Update Magnitude: 0.55979

Collected Steps per Second: 22,519.72738
Overall Steps per Second: 10,673.10176

Timestep Collection Time: 2.22152
Timestep Consumption Time: 2.46578
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.68730

Cumulative Model Updates: 173,768
Cumulative Timesteps: 1,449,203,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.13542
Policy Entropy: 3.01239
Value Function Loss: 0.00496

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.60702
Value Function Update Magnitude: 0.56125

Collected Steps per Second: 22,814.49830
Overall Steps per Second: 10,835.64330

Timestep Collection Time: 2.19194
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61514

Cumulative Model Updates: 173,774
Cumulative Timesteps: 1,449,253,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1449253768...
Checkpoint 1449253768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,771.51067
Policy Entropy: 3.02017
Value Function Loss: 0.00513

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.61353
Value Function Update Magnitude: 0.59235

Collected Steps per Second: 22,773.91681
Overall Steps per Second: 10,661.20608

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.49441
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.68990

Cumulative Model Updates: 173,780
Cumulative Timesteps: 1,449,303,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,820.12178
Policy Entropy: 3.01925
Value Function Loss: 0.00544

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.61423
Value Function Update Magnitude: 0.61690

Collected Steps per Second: 22,417.03878
Overall Steps per Second: 10,835.80678

Timestep Collection Time: 2.23071
Timestep Consumption Time: 2.38417
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61488

Cumulative Model Updates: 173,786
Cumulative Timesteps: 1,449,353,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1449353774...
Checkpoint 1449353774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,311.94820
Policy Entropy: 3.03997
Value Function Loss: 0.00501

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.61066
Value Function Update Magnitude: 0.62834

Collected Steps per Second: 22,303.53232
Overall Steps per Second: 10,728.01112

Timestep Collection Time: 2.24296
Timestep Consumption Time: 2.42016
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.66312

Cumulative Model Updates: 173,792
Cumulative Timesteps: 1,449,403,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,571.79668
Policy Entropy: 3.04048
Value Function Loss: 0.00481

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.59749
Value Function Update Magnitude: 0.60814

Collected Steps per Second: 22,572.64300
Overall Steps per Second: 10,929.64327

Timestep Collection Time: 2.21525
Timestep Consumption Time: 2.35983
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.57508

Cumulative Model Updates: 173,798
Cumulative Timesteps: 1,449,453,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1449453804...
Checkpoint 1449453804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,761.28120
Policy Entropy: 3.06531
Value Function Loss: 0.00431

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.57894
Value Function Update Magnitude: 0.58167

Collected Steps per Second: 22,369.05296
Overall Steps per Second: 10,749.86465

Timestep Collection Time: 2.23550
Timestep Consumption Time: 2.41628
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.65178

Cumulative Model Updates: 173,804
Cumulative Timesteps: 1,449,503,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,108.85883
Policy Entropy: 3.05907
Value Function Loss: 0.00476

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.58181
Value Function Update Magnitude: 0.57942

Collected Steps per Second: 22,365.42888
Overall Steps per Second: 10,746.08176

Timestep Collection Time: 2.23685
Timestep Consumption Time: 2.41862
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.65546

Cumulative Model Updates: 173,810
Cumulative Timesteps: 1,449,553,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1449553838...
Checkpoint 1449553838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.90571
Policy Entropy: 3.05534
Value Function Loss: 0.00476

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.59380
Value Function Update Magnitude: 0.59278

Collected Steps per Second: 22,609.94574
Overall Steps per Second: 10,820.58810

Timestep Collection Time: 2.21159
Timestep Consumption Time: 2.40960
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.62119

Cumulative Model Updates: 173,816
Cumulative Timesteps: 1,449,603,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,332.25358
Policy Entropy: 3.03711
Value Function Loss: 0.00471

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.59921
Value Function Update Magnitude: 0.58707

Collected Steps per Second: 22,054.76562
Overall Steps per Second: 10,699.02676

Timestep Collection Time: 2.26772
Timestep Consumption Time: 2.40691
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.67463

Cumulative Model Updates: 173,822
Cumulative Timesteps: 1,449,653,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1449653856...
Checkpoint 1449653856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,896.36773
Policy Entropy: 3.04014
Value Function Loss: 0.00462

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.59436
Value Function Update Magnitude: 0.56513

Collected Steps per Second: 22,739.14195
Overall Steps per Second: 10,638.88572

Timestep Collection Time: 2.19973
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.70162

Cumulative Model Updates: 173,828
Cumulative Timesteps: 1,449,703,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,142.64454
Policy Entropy: 3.01650
Value Function Loss: 0.00496

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.60484
Value Function Update Magnitude: 0.56330

Collected Steps per Second: 22,537.05717
Overall Steps per Second: 10,640.66753

Timestep Collection Time: 2.21946
Timestep Consumption Time: 2.48138
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.70083

Cumulative Model Updates: 173,834
Cumulative Timesteps: 1,449,753,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1449753896...
Checkpoint 1449753896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948.96077
Policy Entropy: 3.01697
Value Function Loss: 0.00499

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.61526
Value Function Update Magnitude: 0.57476

Collected Steps per Second: 22,808.61661
Overall Steps per Second: 10,894.05175

Timestep Collection Time: 2.19338
Timestep Consumption Time: 2.39885
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.59223

Cumulative Model Updates: 173,840
Cumulative Timesteps: 1,449,803,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,557.12170
Policy Entropy: 3.03307
Value Function Loss: 0.00492

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.61514
Value Function Update Magnitude: 0.58973

Collected Steps per Second: 23,059.33377
Overall Steps per Second: 10,692.56479

Timestep Collection Time: 2.16841
Timestep Consumption Time: 2.50793
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.67633

Cumulative Model Updates: 173,846
Cumulative Timesteps: 1,449,853,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1449853926...
Checkpoint 1449853926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,750.92684
Policy Entropy: 3.05023
Value Function Loss: 0.00482

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.60595
Value Function Update Magnitude: 0.56566

Collected Steps per Second: 23,265.07887
Overall Steps per Second: 10,824.18365

Timestep Collection Time: 2.14914
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.61929

Cumulative Model Updates: 173,852
Cumulative Timesteps: 1,449,903,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,838.40618
Policy Entropy: 3.05731
Value Function Loss: 0.00511

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.60975
Value Function Update Magnitude: 0.59088

Collected Steps per Second: 23,091.71209
Overall Steps per Second: 10,923.33382

Timestep Collection Time: 2.16736
Timestep Consumption Time: 2.41439
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.58175

Cumulative Model Updates: 173,858
Cumulative Timesteps: 1,449,953,974

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1449953974...
Checkpoint 1449953974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.11679
Policy Entropy: 3.04248
Value Function Loss: 0.00491

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.59968
Value Function Update Magnitude: 0.57592

Collected Steps per Second: 23,069.35455
Overall Steps per Second: 10,705.34751

Timestep Collection Time: 2.16738
Timestep Consumption Time: 2.50319
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.67056

Cumulative Model Updates: 173,864
Cumulative Timesteps: 1,450,003,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.06974
Policy Entropy: 3.05573
Value Function Loss: 0.00473

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10686
Policy Update Magnitude: 0.58366
Value Function Update Magnitude: 0.52504

Collected Steps per Second: 22,878.84247
Overall Steps per Second: 10,858.20842

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.41968
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.60536

Cumulative Model Updates: 173,870
Cumulative Timesteps: 1,450,053,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1450053980...
Checkpoint 1450053980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759.92577
Policy Entropy: 3.06686
Value Function Loss: 0.00441

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.57633
Value Function Update Magnitude: 0.50957

Collected Steps per Second: 23,126.08102
Overall Steps per Second: 10,694.33977

Timestep Collection Time: 2.16301
Timestep Consumption Time: 2.51442
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.67743

Cumulative Model Updates: 173,876
Cumulative Timesteps: 1,450,104,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.11904
Policy Entropy: 3.06779
Value Function Loss: 0.00412

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.56282
Value Function Update Magnitude: 0.50430

Collected Steps per Second: 22,673.85080
Overall Steps per Second: 10,658.68273

Timestep Collection Time: 2.20607
Timestep Consumption Time: 2.48682
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69289

Cumulative Model Updates: 173,882
Cumulative Timesteps: 1,450,154,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1450154022...
Checkpoint 1450154022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.24746
Policy Entropy: 3.05296
Value Function Loss: 0.00481

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.58619
Value Function Update Magnitude: 0.52919

Collected Steps per Second: 22,683.25334
Overall Steps per Second: 10,809.38332

Timestep Collection Time: 2.20471
Timestep Consumption Time: 2.42183
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62654

Cumulative Model Updates: 173,888
Cumulative Timesteps: 1,450,204,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,416.82615
Policy Entropy: 3.06556
Value Function Loss: 0.00461

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.59294
Value Function Update Magnitude: 0.56561

Collected Steps per Second: 22,751.94632
Overall Steps per Second: 10,724.22695

Timestep Collection Time: 2.19788
Timestep Consumption Time: 2.46502
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.66290

Cumulative Model Updates: 173,894
Cumulative Timesteps: 1,450,254,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1450254038...
Checkpoint 1450254038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,784.62041
Policy Entropy: 3.06240
Value Function Loss: 0.00446

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.58051
Value Function Update Magnitude: 0.56575

Collected Steps per Second: 22,727.70452
Overall Steps per Second: 10,665.24407

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.48837
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.68850

Cumulative Model Updates: 173,900
Cumulative Timesteps: 1,450,304,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.53974
Policy Entropy: 3.06731
Value Function Loss: 0.00426

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.57438
Value Function Update Magnitude: 0.53178

Collected Steps per Second: 22,352.59997
Overall Steps per Second: 10,677.98021

Timestep Collection Time: 2.23706
Timestep Consumption Time: 2.44585
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.68291

Cumulative Model Updates: 173,906
Cumulative Timesteps: 1,450,354,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1450354046...
Checkpoint 1450354046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,388.61873
Policy Entropy: 3.05043
Value Function Loss: 0.00428

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.57668
Value Function Update Magnitude: 0.51046

Collected Steps per Second: 22,370.33129
Overall Steps per Second: 10,660.78998

Timestep Collection Time: 2.23635
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.69271

Cumulative Model Updates: 173,912
Cumulative Timesteps: 1,450,404,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,505.10623
Policy Entropy: 3.03981
Value Function Loss: 0.00453

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.58215
Value Function Update Magnitude: 0.51857

Collected Steps per Second: 22,953.47531
Overall Steps per Second: 10,821.08298

Timestep Collection Time: 2.17971
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.62357

Cumulative Model Updates: 173,918
Cumulative Timesteps: 1,450,454,106

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1450454106...
Checkpoint 1450454106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.60342
Policy Entropy: 3.04771
Value Function Loss: 0.00433

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.58475
Value Function Update Magnitude: 0.53030

Collected Steps per Second: 22,843.58917
Overall Steps per Second: 10,732.92182

Timestep Collection Time: 2.18880
Timestep Consumption Time: 2.46977
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.65856

Cumulative Model Updates: 173,924
Cumulative Timesteps: 1,450,504,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,606.02002
Policy Entropy: 3.05027
Value Function Loss: 0.00453

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.58531
Value Function Update Magnitude: 0.54022

Collected Steps per Second: 23,131.05969
Overall Steps per Second: 10,851.25987

Timestep Collection Time: 2.16168
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60794

Cumulative Model Updates: 173,930
Cumulative Timesteps: 1,450,554,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1450554108...
Checkpoint 1450554108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,389.11587
Policy Entropy: 3.04669
Value Function Loss: 0.00459

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.59618
Value Function Update Magnitude: 0.55489

Collected Steps per Second: 22,994.76950
Overall Steps per Second: 10,684.13396

Timestep Collection Time: 2.17563
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.68246

Cumulative Model Updates: 173,936
Cumulative Timesteps: 1,450,604,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.48329
Policy Entropy: 3.01616
Value Function Loss: 0.00462

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.60443
Value Function Update Magnitude: 0.55106

Collected Steps per Second: 23,298.25322
Overall Steps per Second: 10,909.93613

Timestep Collection Time: 2.14720
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.58536

Cumulative Model Updates: 173,942
Cumulative Timesteps: 1,450,654,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1450654162...
Checkpoint 1450654162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.15587
Policy Entropy: 3.02398
Value Function Loss: 0.00471

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11629
Policy Update Magnitude: 0.60625
Value Function Update Magnitude: 0.54745

Collected Steps per Second: 23,123.12844
Overall Steps per Second: 10,695.74427

Timestep Collection Time: 2.16320
Timestep Consumption Time: 2.51342
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.67663

Cumulative Model Updates: 173,948
Cumulative Timesteps: 1,450,704,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.20983
Policy Entropy: 3.02838
Value Function Loss: 0.00486

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.60548
Value Function Update Magnitude: 0.53371

Collected Steps per Second: 22,798.64726
Overall Steps per Second: 10,871.38279

Timestep Collection Time: 2.19320
Timestep Consumption Time: 2.40621
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.59941

Cumulative Model Updates: 173,954
Cumulative Timesteps: 1,450,754,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1450754184...
Checkpoint 1450754184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,448.16607
Policy Entropy: 3.04704
Value Function Loss: 0.00480

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.59510
Value Function Update Magnitude: 0.53107

Collected Steps per Second: 23,098.48625
Overall Steps per Second: 10,690.85337

Timestep Collection Time: 2.16473
Timestep Consumption Time: 2.51235
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.67708

Cumulative Model Updates: 173,960
Cumulative Timesteps: 1,450,804,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.96814
Policy Entropy: 3.04127
Value Function Loss: 0.00478

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.59911
Value Function Update Magnitude: 0.52736

Collected Steps per Second: 22,458.01900
Overall Steps per Second: 10,564.60126

Timestep Collection Time: 2.22647
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.73298

Cumulative Model Updates: 173,966
Cumulative Timesteps: 1,450,854,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1450854188...
Checkpoint 1450854188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,271.63392
Policy Entropy: 3.03735
Value Function Loss: 0.00491

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.61068
Value Function Update Magnitude: 0.53067

Collected Steps per Second: 22,661.45060
Overall Steps per Second: 10,634.32095

Timestep Collection Time: 2.20657
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.70213

Cumulative Model Updates: 173,972
Cumulative Timesteps: 1,450,904,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,423.85391
Policy Entropy: 3.02847
Value Function Loss: 0.00482

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.61233
Value Function Update Magnitude: 0.54562

Collected Steps per Second: 22,700.14994
Overall Steps per Second: 10,772.29728

Timestep Collection Time: 2.20395
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.64432

Cumulative Model Updates: 173,978
Cumulative Timesteps: 1,450,954,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1450954222...
Checkpoint 1450954222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.59229
Policy Entropy: 3.01875
Value Function Loss: 0.00475

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.60436
Value Function Update Magnitude: 0.55331

Collected Steps per Second: 22,877.29257
Overall Steps per Second: 10,654.72029

Timestep Collection Time: 2.18592
Timestep Consumption Time: 2.50758
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.69351

Cumulative Model Updates: 173,984
Cumulative Timesteps: 1,451,004,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,504.53328
Policy Entropy: 3.00865
Value Function Loss: 0.00453

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.60238
Value Function Update Magnitude: 0.57713

Collected Steps per Second: 23,177.51769
Overall Steps per Second: 10,663.68013

Timestep Collection Time: 2.15856
Timestep Consumption Time: 2.53307
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.69163

Cumulative Model Updates: 173,990
Cumulative Timesteps: 1,451,054,260

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1451054260...
Checkpoint 1451054260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,974.25358
Policy Entropy: 3.01237
Value Function Loss: 0.00466

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10723
Policy Update Magnitude: 0.59784
Value Function Update Magnitude: 0.57914

Collected Steps per Second: 23,328.38723
Overall Steps per Second: 10,821.46129

Timestep Collection Time: 2.14391
Timestep Consumption Time: 2.47783
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.62174

Cumulative Model Updates: 173,996
Cumulative Timesteps: 1,451,104,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,225.56665
Policy Entropy: 3.02233
Value Function Loss: 0.00443

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.58999
Value Function Update Magnitude: 0.56390

Collected Steps per Second: 23,512.59579
Overall Steps per Second: 10,948.53161

Timestep Collection Time: 2.12669
Timestep Consumption Time: 2.44050
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.56719

Cumulative Model Updates: 174,002
Cumulative Timesteps: 1,451,154,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1451154278...
Checkpoint 1451154278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,712.59992
Policy Entropy: 3.01450
Value Function Loss: 0.00468

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.59591
Value Function Update Magnitude: 0.56641

Collected Steps per Second: 22,860.27138
Overall Steps per Second: 10,702.47904

Timestep Collection Time: 2.18816
Timestep Consumption Time: 2.48571
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.67387

Cumulative Model Updates: 174,008
Cumulative Timesteps: 1,451,204,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.13605
Policy Entropy: 2.98221
Value Function Loss: 0.00449

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.60208
Value Function Update Magnitude: 0.58273

Collected Steps per Second: 23,355.48754
Overall Steps per Second: 10,934.28214

Timestep Collection Time: 2.14160
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.57442

Cumulative Model Updates: 174,014
Cumulative Timesteps: 1,451,254,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1451254318...
Checkpoint 1451254318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.55979
Policy Entropy: 2.99444
Value Function Loss: 0.00458

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.60224
Value Function Update Magnitude: 0.56813

Collected Steps per Second: 23,150.87041
Overall Steps per Second: 10,778.62445

Timestep Collection Time: 2.15983
Timestep Consumption Time: 2.47916
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.63900

Cumulative Model Updates: 174,020
Cumulative Timesteps: 1,451,304,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,962.02919
Policy Entropy: 3.00884
Value Function Loss: 0.00463

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.59516
Value Function Update Magnitude: 0.54781

Collected Steps per Second: 22,948.03765
Overall Steps per Second: 10,743.53347

Timestep Collection Time: 2.17910
Timestep Consumption Time: 2.47542
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.65452

Cumulative Model Updates: 174,026
Cumulative Timesteps: 1,451,354,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1451354326...
Checkpoint 1451354326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,119.79271
Policy Entropy: 3.05925
Value Function Loss: 0.00432

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.58343
Value Function Update Magnitude: 0.53900

Collected Steps per Second: 22,477.66397
Overall Steps per Second: 10,600.77897

Timestep Collection Time: 2.22577
Timestep Consumption Time: 2.49370
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.71946

Cumulative Model Updates: 174,032
Cumulative Timesteps: 1,451,404,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.07633
Policy Entropy: 3.06751
Value Function Loss: 0.00427

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.56531
Value Function Update Magnitude: 0.52472

Collected Steps per Second: 23,014.39221
Overall Steps per Second: 10,829.47956

Timestep Collection Time: 2.17368
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61943

Cumulative Model Updates: 174,038
Cumulative Timesteps: 1,451,454,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1451454382...
Checkpoint 1451454382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,228.75128
Policy Entropy: 3.07108
Value Function Loss: 0.00446

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.57592
Value Function Update Magnitude: 0.52819

Collected Steps per Second: 22,368.35459
Overall Steps per Second: 10,684.02164

Timestep Collection Time: 2.23709
Timestep Consumption Time: 2.44654
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.68363

Cumulative Model Updates: 174,044
Cumulative Timesteps: 1,451,504,422

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.10271
Policy Entropy: 3.05013
Value Function Loss: 0.00448

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.58365
Value Function Update Magnitude: 0.54583

Collected Steps per Second: 23,147.16336
Overall Steps per Second: 10,656.08625

Timestep Collection Time: 2.16018
Timestep Consumption Time: 2.53216
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.69234

Cumulative Model Updates: 174,050
Cumulative Timesteps: 1,451,554,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1451554424...
Checkpoint 1451554424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,350.33560
Policy Entropy: 3.03618
Value Function Loss: 0.00412

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11962
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.54673

Collected Steps per Second: 23,162.22062
Overall Steps per Second: 10,834.75747

Timestep Collection Time: 2.15929
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.61607

Cumulative Model Updates: 174,056
Cumulative Timesteps: 1,451,604,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,006.30590
Policy Entropy: 3.03345
Value Function Loss: 0.00413

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.51116

Collected Steps per Second: 22,996.85851
Overall Steps per Second: 10,706.47107

Timestep Collection Time: 2.17534
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.67250

Cumulative Model Updates: 174,062
Cumulative Timesteps: 1,451,654,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1451654464...
Checkpoint 1451654464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,721.05661
Policy Entropy: 3.03012
Value Function Loss: 0.00440

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.50075

Collected Steps per Second: 23,117.40846
Overall Steps per Second: 10,965.37361

Timestep Collection Time: 2.16348
Timestep Consumption Time: 2.39761
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.56108

Cumulative Model Updates: 174,068
Cumulative Timesteps: 1,451,704,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,767.68323
Policy Entropy: 3.04437
Value Function Loss: 0.00445

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.49808

Collected Steps per Second: 23,055.71626
Overall Steps per Second: 10,837.31109

Timestep Collection Time: 2.16944
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61535

Cumulative Model Updates: 174,074
Cumulative Timesteps: 1,451,754,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1451754496...
Checkpoint 1451754496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.27557
Policy Entropy: 3.05883
Value Function Loss: 0.00452

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.57378
Value Function Update Magnitude: 0.49850

Collected Steps per Second: 22,917.41907
Overall Steps per Second: 10,700.05123

Timestep Collection Time: 2.18218
Timestep Consumption Time: 2.49163
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.67381

Cumulative Model Updates: 174,080
Cumulative Timesteps: 1,451,804,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,308.92543
Policy Entropy: 3.05020
Value Function Loss: 0.00476

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.58358
Value Function Update Magnitude: 0.52360

Collected Steps per Second: 23,074.23121
Overall Steps per Second: 10,853.87019

Timestep Collection Time: 2.16779
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.60849

Cumulative Model Updates: 174,086
Cumulative Timesteps: 1,451,854,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1451854526...
Checkpoint 1451854526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,864.15216
Policy Entropy: 3.03473
Value Function Loss: 0.00456

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.58968
Value Function Update Magnitude: 0.54096

Collected Steps per Second: 22,722.21470
Overall Steps per Second: 10,687.46725

Timestep Collection Time: 2.20172
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.68100

Cumulative Model Updates: 174,092
Cumulative Timesteps: 1,451,904,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,566.70636
Policy Entropy: 3.03462
Value Function Loss: 0.00441

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.58167
Value Function Update Magnitude: 0.50888

Collected Steps per Second: 22,454.15640
Overall Steps per Second: 10,533.38618

Timestep Collection Time: 2.22685
Timestep Consumption Time: 2.52015
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.74700

Cumulative Model Updates: 174,098
Cumulative Timesteps: 1,451,954,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1451954556...
Checkpoint 1451954556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.20579
Policy Entropy: 3.04109
Value Function Loss: 0.00423

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.56847
Value Function Update Magnitude: 0.48257

Collected Steps per Second: 22,699.91526
Overall Steps per Second: 10,605.77307

Timestep Collection Time: 2.20274
Timestep Consumption Time: 2.51186
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.71460

Cumulative Model Updates: 174,104
Cumulative Timesteps: 1,452,004,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,976.23253
Policy Entropy: 3.05210
Value Function Loss: 0.00430

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.57209
Value Function Update Magnitude: 0.47939

Collected Steps per Second: 23,354.53047
Overall Steps per Second: 10,887.37384

Timestep Collection Time: 2.14271
Timestep Consumption Time: 2.45362
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.59633

Cumulative Model Updates: 174,110
Cumulative Timesteps: 1,452,054,600

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1452054600...
Checkpoint 1452054600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,423.47182
Policy Entropy: 3.05966
Value Function Loss: 0.00414

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.57087
Value Function Update Magnitude: 0.48903

Collected Steps per Second: 22,896.67899
Overall Steps per Second: 10,757.58977

Timestep Collection Time: 2.18390
Timestep Consumption Time: 2.46436
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.64825

Cumulative Model Updates: 174,116
Cumulative Timesteps: 1,452,104,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,036.42528
Policy Entropy: 3.05848
Value Function Loss: 0.00425

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.49469

Collected Steps per Second: 22,981.76259
Overall Steps per Second: 10,761.02127

Timestep Collection Time: 2.17573
Timestep Consumption Time: 2.47086
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.64658

Cumulative Model Updates: 174,122
Cumulative Timesteps: 1,452,154,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1452154606...
Checkpoint 1452154606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,004.91557
Policy Entropy: 3.04357
Value Function Loss: 0.00451

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.58151
Value Function Update Magnitude: 0.50788

Collected Steps per Second: 23,164.49581
Overall Steps per Second: 10,738.31844

Timestep Collection Time: 2.15882
Timestep Consumption Time: 2.49815
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.65697

Cumulative Model Updates: 174,128
Cumulative Timesteps: 1,452,204,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,836.44223
Policy Entropy: 3.03520
Value Function Loss: 0.00455

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.59025
Value Function Update Magnitude: 0.51540

Collected Steps per Second: 23,213.33004
Overall Steps per Second: 10,771.13325

Timestep Collection Time: 2.15480
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.64389

Cumulative Model Updates: 174,134
Cumulative Timesteps: 1,452,254,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1452254634...
Checkpoint 1452254634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,419.67216
Policy Entropy: 3.01962
Value Function Loss: 0.00448

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.59410
Value Function Update Magnitude: 0.53138

Collected Steps per Second: 22,906.72688
Overall Steps per Second: 10,687.13760

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.67983

Cumulative Model Updates: 174,140
Cumulative Timesteps: 1,452,304,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,084.57499
Policy Entropy: 3.01256
Value Function Loss: 0.00449

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.58940
Value Function Update Magnitude: 0.51084

Collected Steps per Second: 22,824.00121
Overall Steps per Second: 10,822.35836

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.42987
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.62099

Cumulative Model Updates: 174,146
Cumulative Timesteps: 1,452,354,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1452354658...
Checkpoint 1452354658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.51323
Policy Entropy: 2.99268
Value Function Loss: 0.00460

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.59057
Value Function Update Magnitude: 0.51602

Collected Steps per Second: 22,599.63689
Overall Steps per Second: 10,767.87954

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.64511

Cumulative Model Updates: 174,152
Cumulative Timesteps: 1,452,404,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,923.58342
Policy Entropy: 3.00813
Value Function Loss: 0.00459

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.59952
Value Function Update Magnitude: 0.52361

Collected Steps per Second: 22,786.51083
Overall Steps per Second: 10,780.89754

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.44443
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.63950

Cumulative Model Updates: 174,158
Cumulative Timesteps: 1,452,454,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1452454694...
Checkpoint 1452454694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,002.13534
Policy Entropy: 3.01441
Value Function Loss: 0.00443

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.58401
Value Function Update Magnitude: 0.52432

Collected Steps per Second: 22,663.09948
Overall Steps per Second: 10,702.81116

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.67410

Cumulative Model Updates: 174,164
Cumulative Timesteps: 1,452,504,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,995.35336
Policy Entropy: 3.03085
Value Function Loss: 0.00469

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.58674
Value Function Update Magnitude: 0.51499

Collected Steps per Second: 23,222.46813
Overall Steps per Second: 10,869.38598

Timestep Collection Time: 2.15438
Timestep Consumption Time: 2.44846
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.60284

Cumulative Model Updates: 174,170
Cumulative Timesteps: 1,452,554,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1452554750...
Checkpoint 1452554750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.05543
Policy Entropy: 3.02604
Value Function Loss: 0.00481

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.58496
Value Function Update Magnitude: 0.51043

Collected Steps per Second: 22,971.60714
Overall Steps per Second: 10,660.19630

Timestep Collection Time: 2.17756
Timestep Consumption Time: 2.51485
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.69241

Cumulative Model Updates: 174,176
Cumulative Timesteps: 1,452,604,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,274.69827
Policy Entropy: 3.01683
Value Function Loss: 0.00479

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.58275
Value Function Update Magnitude: 0.50108

Collected Steps per Second: 23,330.99936
Overall Steps per Second: 10,899.62940

Timestep Collection Time: 2.14341
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.58805

Cumulative Model Updates: 174,182
Cumulative Timesteps: 1,452,654,780

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1452654780...
Checkpoint 1452654780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.13548
Policy Entropy: 2.99905
Value Function Loss: 0.00452

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.58561
Value Function Update Magnitude: 0.48992

Collected Steps per Second: 23,136.77955
Overall Steps per Second: 10,709.91498

Timestep Collection Time: 2.16219
Timestep Consumption Time: 2.50881
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.67100

Cumulative Model Updates: 174,188
Cumulative Timesteps: 1,452,704,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.51723
Policy Entropy: 2.99251
Value Function Loss: 0.00438

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.58175
Value Function Update Magnitude: 0.48876

Collected Steps per Second: 23,257.97307
Overall Steps per Second: 10,934.72741

Timestep Collection Time: 2.14989
Timestep Consumption Time: 2.42288
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.57277

Cumulative Model Updates: 174,194
Cumulative Timesteps: 1,452,754,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1452754808...
Checkpoint 1452754808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,754.09160
Policy Entropy: 2.99639
Value Function Loss: 0.00464

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.48347

Collected Steps per Second: 23,048.87337
Overall Steps per Second: 10,721.98739

Timestep Collection Time: 2.16939
Timestep Consumption Time: 2.49411
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.66350

Cumulative Model Updates: 174,200
Cumulative Timesteps: 1,452,804,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.68104
Policy Entropy: 3.00026
Value Function Loss: 0.00515

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.59212
Value Function Update Magnitude: 0.48769

Collected Steps per Second: 22,825.49602
Overall Steps per Second: 10,815.21547

Timestep Collection Time: 2.19053
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.62312

Cumulative Model Updates: 174,206
Cumulative Timesteps: 1,452,854,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1452854810...
Checkpoint 1452854810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,320.13890
Policy Entropy: 3.01236
Value Function Loss: 0.00530

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.59171
Value Function Update Magnitude: 0.51122

Collected Steps per Second: 22,408.96861
Overall Steps per Second: 10,602.61286

Timestep Collection Time: 2.23125
Timestep Consumption Time: 2.48457
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.71582

Cumulative Model Updates: 174,212
Cumulative Timesteps: 1,452,904,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.29237
Policy Entropy: 2.99214
Value Function Loss: 0.00512

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.58846
Value Function Update Magnitude: 0.53356

Collected Steps per Second: 23,138.24809
Overall Steps per Second: 10,934.03884

Timestep Collection Time: 2.16118
Timestep Consumption Time: 2.41224
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.57342

Cumulative Model Updates: 174,218
Cumulative Timesteps: 1,452,954,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1452954816...
Checkpoint 1452954816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.61438
Policy Entropy: 2.98196
Value Function Loss: 0.00471

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.59492
Value Function Update Magnitude: 0.52907

Collected Steps per Second: 22,843.91428
Overall Steps per Second: 10,650.70704

Timestep Collection Time: 2.18885
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.69471

Cumulative Model Updates: 174,224
Cumulative Timesteps: 1,453,004,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,280.09397
Policy Entropy: 2.96954
Value Function Loss: 0.00445

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.59442
Value Function Update Magnitude: 0.52241

Collected Steps per Second: 23,321.05301
Overall Steps per Second: 10,797.50964

Timestep Collection Time: 2.14424
Timestep Consumption Time: 2.48701
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.63125

Cumulative Model Updates: 174,230
Cumulative Timesteps: 1,453,054,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1453054824...
Checkpoint 1453054824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,101.53664
Policy Entropy: 2.96889
Value Function Loss: 0.00444

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.60651
Value Function Update Magnitude: 0.51367

Collected Steps per Second: 22,850.88471
Overall Steps per Second: 10,673.18058

Timestep Collection Time: 2.18924
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.68708

Cumulative Model Updates: 174,236
Cumulative Timesteps: 1,453,104,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.41310
Policy Entropy: 2.96714
Value Function Loss: 0.00464

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.61008
Value Function Update Magnitude: 0.52266

Collected Steps per Second: 23,372.64032
Overall Steps per Second: 10,915.03758

Timestep Collection Time: 2.14037
Timestep Consumption Time: 2.44285
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.58322

Cumulative Model Updates: 174,242
Cumulative Timesteps: 1,453,154,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1453154876...
Checkpoint 1453154876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.86747
Policy Entropy: 2.97697
Value Function Loss: 0.00477

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.15280
Policy Update Magnitude: 0.60359
Value Function Update Magnitude: 0.54387

Collected Steps per Second: 23,016.71942
Overall Steps per Second: 10,692.39064

Timestep Collection Time: 2.17372
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.67922

Cumulative Model Updates: 174,248
Cumulative Timesteps: 1,453,204,908

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.81305
Policy Entropy: 2.99582
Value Function Loss: 0.00470

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.59792
Value Function Update Magnitude: 0.54659

Collected Steps per Second: 23,336.38468
Overall Steps per Second: 10,930.09756

Timestep Collection Time: 2.14386
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.57727

Cumulative Model Updates: 174,254
Cumulative Timesteps: 1,453,254,938

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1453254938...
Checkpoint 1453254938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.93951
Policy Entropy: 3.00710
Value Function Loss: 0.00492

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.60142
Value Function Update Magnitude: 0.54400

Collected Steps per Second: 22,988.93041
Overall Steps per Second: 10,835.94104

Timestep Collection Time: 2.17618
Timestep Consumption Time: 2.44068
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.61686

Cumulative Model Updates: 174,260
Cumulative Timesteps: 1,453,304,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.95866
Policy Entropy: 2.99856
Value Function Loss: 0.00497

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.60377
Value Function Update Magnitude: 0.55619

Collected Steps per Second: 22,810.85744
Overall Steps per Second: 10,718.82766

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.47384
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.66674

Cumulative Model Updates: 174,266
Cumulative Timesteps: 1,453,354,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1453354988...
Checkpoint 1453354988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,144.72430
Policy Entropy: 2.98545
Value Function Loss: 0.00482

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.60264
Value Function Update Magnitude: 0.57696

Collected Steps per Second: 22,603.05458
Overall Steps per Second: 10,615.93434

Timestep Collection Time: 2.21262
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.71103

Cumulative Model Updates: 174,272
Cumulative Timesteps: 1,453,405,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.03292
Policy Entropy: 2.97654
Value Function Loss: 0.00510

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.61254
Value Function Update Magnitude: 0.57889

Collected Steps per Second: 22,700.13282
Overall Steps per Second: 10,625.90887

Timestep Collection Time: 2.20289
Timestep Consumption Time: 2.50315
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.70604

Cumulative Model Updates: 174,278
Cumulative Timesteps: 1,453,455,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1453455006...
Checkpoint 1453455006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.26066
Policy Entropy: 2.99440
Value Function Loss: 0.00484

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.59658
Value Function Update Magnitude: 0.57393

Collected Steps per Second: 22,500.45142
Overall Steps per Second: 10,545.72670

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.51938
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.74183

Cumulative Model Updates: 174,284
Cumulative Timesteps: 1,453,505,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,389.80298
Policy Entropy: 3.00267
Value Function Loss: 0.00477

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.54307

Collected Steps per Second: 23,358.48748
Overall Steps per Second: 10,791.90607

Timestep Collection Time: 2.14072
Timestep Consumption Time: 2.49275
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.63347

Cumulative Model Updates: 174,290
Cumulative Timesteps: 1,453,555,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1453555016...
Checkpoint 1453555016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,724.51759
Policy Entropy: 3.02345
Value Function Loss: 0.00452

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.53826

Collected Steps per Second: 22,989.57437
Overall Steps per Second: 10,773.59172

Timestep Collection Time: 2.17490
Timestep Consumption Time: 2.46608
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.64098

Cumulative Model Updates: 174,296
Cumulative Timesteps: 1,453,605,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,242.24666
Policy Entropy: 3.02247
Value Function Loss: 0.00418

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.57038
Value Function Update Magnitude: 0.54832

Collected Steps per Second: 23,320.13265
Overall Steps per Second: 10,777.70582

Timestep Collection Time: 2.14416
Timestep Consumption Time: 2.49524
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.63939

Cumulative Model Updates: 174,302
Cumulative Timesteps: 1,453,655,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1453655018...
Checkpoint 1453655018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.21853
Policy Entropy: 3.03171
Value Function Loss: 0.00428

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.57601
Value Function Update Magnitude: 0.53328

Collected Steps per Second: 23,010.50592
Overall Steps per Second: 10,691.70194

Timestep Collection Time: 2.17344
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.67765

Cumulative Model Updates: 174,308
Cumulative Timesteps: 1,453,705,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,526.15858
Policy Entropy: 3.04190
Value Function Loss: 0.00398

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11537
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.52594

Collected Steps per Second: 23,109.50167
Overall Steps per Second: 10,889.12929

Timestep Collection Time: 2.16379
Timestep Consumption Time: 2.42832
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.59210

Cumulative Model Updates: 174,314
Cumulative Timesteps: 1,453,755,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1453755034...
Checkpoint 1453755034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.73513
Policy Entropy: 3.04760
Value Function Loss: 0.00413

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.55019
Value Function Update Magnitude: 0.50990

Collected Steps per Second: 22,842.16095
Overall Steps per Second: 10,655.97983

Timestep Collection Time: 2.18946
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.69333

Cumulative Model Updates: 174,320
Cumulative Timesteps: 1,453,805,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.34074
Policy Entropy: 3.03248
Value Function Loss: 0.00441

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.55577
Value Function Update Magnitude: 0.49221

Collected Steps per Second: 22,936.94107
Overall Steps per Second: 10,829.36023

Timestep Collection Time: 2.18050
Timestep Consumption Time: 2.43787
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61837

Cumulative Model Updates: 174,326
Cumulative Timesteps: 1,453,855,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1453855060...
Checkpoint 1453855060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.03878
Policy Entropy: 3.02482
Value Function Loss: 0.00468

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.57060
Value Function Update Magnitude: 0.50273

Collected Steps per Second: 22,192.30304
Overall Steps per Second: 10,640.95391

Timestep Collection Time: 2.25430
Timestep Consumption Time: 2.44716
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.70146

Cumulative Model Updates: 174,332
Cumulative Timesteps: 1,453,905,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,123.71836
Policy Entropy: 2.99843
Value Function Loss: 0.00484

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.59252
Value Function Update Magnitude: 0.52408

Collected Steps per Second: 22,763.30778
Overall Steps per Second: 10,675.88541

Timestep Collection Time: 2.19792
Timestep Consumption Time: 2.48853
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.68645

Cumulative Model Updates: 174,338
Cumulative Timesteps: 1,453,955,120

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1453955120...
Checkpoint 1453955120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,307.53651
Policy Entropy: 3.00779
Value Function Loss: 0.00471

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11590
Policy Update Magnitude: 0.59512
Value Function Update Magnitude: 0.57218

Collected Steps per Second: 22,700.63669
Overall Steps per Second: 10,816.75078

Timestep Collection Time: 2.20276
Timestep Consumption Time: 2.42007
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.62283

Cumulative Model Updates: 174,344
Cumulative Timesteps: 1,454,005,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,312.54454
Policy Entropy: 3.02420
Value Function Loss: 0.00416

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.57135
Value Function Update Magnitude: 0.55492

Collected Steps per Second: 23,012.83939
Overall Steps per Second: 10,614.35189

Timestep Collection Time: 2.17305
Timestep Consumption Time: 2.53831
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.71136

Cumulative Model Updates: 174,350
Cumulative Timesteps: 1,454,055,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1454055132...
Checkpoint 1454055132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,691.78843
Policy Entropy: 3.03629
Value Function Loss: 0.00421

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.55748
Value Function Update Magnitude: 0.52491

Collected Steps per Second: 22,844.00667
Overall Steps per Second: 10,684.83544

Timestep Collection Time: 2.18946
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.68103

Cumulative Model Updates: 174,356
Cumulative Timesteps: 1,454,105,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,519.87674
Policy Entropy: 3.06706
Value Function Loss: 0.00395

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.55717
Value Function Update Magnitude: 0.52473

Collected Steps per Second: 23,303.15133
Overall Steps per Second: 10,783.82566

Timestep Collection Time: 2.14580
Timestep Consumption Time: 2.49114
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.63694

Cumulative Model Updates: 174,362
Cumulative Timesteps: 1,454,155,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1454155152...
Checkpoint 1454155152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.82816
Policy Entropy: 3.06098
Value Function Loss: 0.00397

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.54855
Value Function Update Magnitude: 0.52835

Collected Steps per Second: 22,180.23644
Overall Steps per Second: 10,683.84718

Timestep Collection Time: 2.25489
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.68127

Cumulative Model Updates: 174,368
Cumulative Timesteps: 1,454,205,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,234.71975
Policy Entropy: 3.06854
Value Function Loss: 0.00369

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.53443
Value Function Update Magnitude: 0.50606

Collected Steps per Second: 22,790.58774
Overall Steps per Second: 10,812.67040

Timestep Collection Time: 2.19494
Timestep Consumption Time: 2.43148
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.62642

Cumulative Model Updates: 174,374
Cumulative Timesteps: 1,454,255,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1454255190...
Checkpoint 1454255190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,904.12048
Policy Entropy: 3.04224
Value Function Loss: 0.00416

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.50944

Collected Steps per Second: 22,748.10689
Overall Steps per Second: 10,685.70420

Timestep Collection Time: 2.19799
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.67915

Cumulative Model Updates: 174,380
Cumulative Timesteps: 1,454,305,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.56546
Policy Entropy: 3.03904
Value Function Loss: 0.00405

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.56238
Value Function Update Magnitude: 0.49911

Collected Steps per Second: 23,564.83788
Overall Steps per Second: 10,885.11299

Timestep Collection Time: 2.12299
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.59600

Cumulative Model Updates: 174,386
Cumulative Timesteps: 1,454,355,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1454355218...
Checkpoint 1454355218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.93415
Policy Entropy: 3.02005
Value Function Loss: 0.00426

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.56891
Value Function Update Magnitude: 0.50439

Collected Steps per Second: 23,079.01543
Overall Steps per Second: 10,702.85077

Timestep Collection Time: 2.16760
Timestep Consumption Time: 2.50649
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.67408

Cumulative Model Updates: 174,392
Cumulative Timesteps: 1,454,405,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,507.37306
Policy Entropy: 3.01485
Value Function Loss: 0.00452

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.57426
Value Function Update Magnitude: 0.51185

Collected Steps per Second: 23,326.67519
Overall Steps per Second: 10,887.68090

Timestep Collection Time: 2.14484
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.59529

Cumulative Model Updates: 174,398
Cumulative Timesteps: 1,454,455,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1454455276...
Checkpoint 1454455276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,807.96805
Policy Entropy: 2.99984
Value Function Loss: 0.00437

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.57986
Value Function Update Magnitude: 0.50962

Collected Steps per Second: 22,372.37246
Overall Steps per Second: 10,731.82299

Timestep Collection Time: 2.23535
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.65997

Cumulative Model Updates: 174,404
Cumulative Timesteps: 1,454,505,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.73132
Policy Entropy: 2.99308
Value Function Loss: 0.00448

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.57638
Value Function Update Magnitude: 0.49185

Collected Steps per Second: 22,655.67227
Overall Steps per Second: 10,832.39074

Timestep Collection Time: 2.20828
Timestep Consumption Time: 2.41028
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.61856

Cumulative Model Updates: 174,410
Cumulative Timesteps: 1,454,555,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1454555316...
Checkpoint 1454555316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,495.64738
Policy Entropy: 2.99380
Value Function Loss: 0.00428

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.57046
Value Function Update Magnitude: 0.48383

Collected Steps per Second: 22,744.04688
Overall Steps per Second: 11,000.21370

Timestep Collection Time: 2.19873
Timestep Consumption Time: 2.34736
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.54609

Cumulative Model Updates: 174,416
Cumulative Timesteps: 1,454,605,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,507.68064
Policy Entropy: 2.99758
Value Function Loss: 0.00455

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.56310
Value Function Update Magnitude: 0.49817

Collected Steps per Second: 22,027.03021
Overall Steps per Second: 10,621.71002

Timestep Collection Time: 2.27076
Timestep Consumption Time: 2.43828
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.70903

Cumulative Model Updates: 174,422
Cumulative Timesteps: 1,454,655,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1454655342...
Checkpoint 1454655342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.82899
Policy Entropy: 3.01170
Value Function Loss: 0.00438

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.49544

Collected Steps per Second: 21,844.63794
Overall Steps per Second: 10,595.37166

Timestep Collection Time: 2.29017
Timestep Consumption Time: 2.43151
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.72168

Cumulative Model Updates: 174,428
Cumulative Timesteps: 1,454,705,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.24172
Policy Entropy: 3.00734
Value Function Loss: 0.00467

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.57455
Value Function Update Magnitude: 0.49673

Collected Steps per Second: 22,080.70842
Overall Steps per Second: 10,793.00007

Timestep Collection Time: 2.26560
Timestep Consumption Time: 2.36944
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.63504

Cumulative Model Updates: 174,434
Cumulative Timesteps: 1,454,755,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1454755396...
Checkpoint 1454755396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,448.81168
Policy Entropy: 3.00324
Value Function Loss: 0.00494

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.58868
Value Function Update Magnitude: 0.53391

Collected Steps per Second: 22,139.55737
Overall Steps per Second: 10,747.46649

Timestep Collection Time: 2.25949
Timestep Consumption Time: 2.39501
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.65449

Cumulative Model Updates: 174,440
Cumulative Timesteps: 1,454,805,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.89593
Policy Entropy: 2.98575
Value Function Loss: 0.00505

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.60256
Value Function Update Magnitude: 0.55798

Collected Steps per Second: 22,699.17734
Overall Steps per Second: 10,763.92826

Timestep Collection Time: 2.20272
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.64514

Cumulative Model Updates: 174,446
Cumulative Timesteps: 1,454,855,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1454855420...
Checkpoint 1454855420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.16550
Policy Entropy: 2.97614
Value Function Loss: 0.00478

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.59305
Value Function Update Magnitude: 0.54398

Collected Steps per Second: 22,222.94887
Overall Steps per Second: 10,698.75443

Timestep Collection Time: 2.25083
Timestep Consumption Time: 2.42448
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.67531

Cumulative Model Updates: 174,452
Cumulative Timesteps: 1,454,905,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,088.53813
Policy Entropy: 2.96490
Value Function Loss: 0.00479

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.58629
Value Function Update Magnitude: 0.51019

Collected Steps per Second: 23,159.99872
Overall Steps per Second: 10,935.87706

Timestep Collection Time: 2.15941
Timestep Consumption Time: 2.41379
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.57320

Cumulative Model Updates: 174,458
Cumulative Timesteps: 1,454,955,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1454955452...
Checkpoint 1454955452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.35899
Policy Entropy: 2.96594
Value Function Loss: 0.00481

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.59383
Value Function Update Magnitude: 0.48839

Collected Steps per Second: 23,009.55119
Overall Steps per Second: 10,743.21665

Timestep Collection Time: 2.17318
Timestep Consumption Time: 2.48129
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.65447

Cumulative Model Updates: 174,464
Cumulative Timesteps: 1,455,005,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.30415
Policy Entropy: 2.96667
Value Function Loss: 0.00474

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.59393
Value Function Update Magnitude: 0.50601

Collected Steps per Second: 22,731.68023
Overall Steps per Second: 10,823.62937

Timestep Collection Time: 2.20028
Timestep Consumption Time: 2.42072
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.62100

Cumulative Model Updates: 174,470
Cumulative Timesteps: 1,455,055,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1455055472...
Checkpoint 1455055472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,666.52122
Policy Entropy: 2.99233
Value Function Loss: 0.00424

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.57826
Value Function Update Magnitude: 0.50273

Collected Steps per Second: 22,536.19237
Overall Steps per Second: 10,650.88508

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.47599
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.69482

Cumulative Model Updates: 174,476
Cumulative Timesteps: 1,455,105,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,034.75409
Policy Entropy: 3.00600
Value Function Loss: 0.00381

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.56038
Value Function Update Magnitude: 0.48622

Collected Steps per Second: 23,051.95838
Overall Steps per Second: 10,906.98303

Timestep Collection Time: 2.17014
Timestep Consumption Time: 2.41646
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.58660

Cumulative Model Updates: 174,482
Cumulative Timesteps: 1,455,155,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1455155502...
Checkpoint 1455155502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.81024
Policy Entropy: 2.99776
Value Function Loss: 0.00406

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.47969

Collected Steps per Second: 22,391.60202
Overall Steps per Second: 10,642.23170

Timestep Collection Time: 2.23334
Timestep Consumption Time: 2.46568
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.69901

Cumulative Model Updates: 174,488
Cumulative Timesteps: 1,455,205,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,942.33598
Policy Entropy: 2.98917
Value Function Loss: 0.00428

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11853
Policy Update Magnitude: 0.57750
Value Function Update Magnitude: 0.50005

Collected Steps per Second: 23,381.81019
Overall Steps per Second: 10,884.29535

Timestep Collection Time: 2.13884
Timestep Consumption Time: 2.45585
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.59469

Cumulative Model Updates: 174,494
Cumulative Timesteps: 1,455,255,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1455255520...
Checkpoint 1455255520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,217.80629
Policy Entropy: 2.98201
Value Function Loss: 0.00429

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.57744
Value Function Update Magnitude: 0.49687

Collected Steps per Second: 22,920.76731
Overall Steps per Second: 10,637.08167

Timestep Collection Time: 2.18152
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.70073

Cumulative Model Updates: 174,500
Cumulative Timesteps: 1,455,305,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,492.76920
Policy Entropy: 2.97979
Value Function Loss: 0.00414

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.57165
Value Function Update Magnitude: 0.47116

Collected Steps per Second: 23,347.92579
Overall Steps per Second: 10,917.49699

Timestep Collection Time: 2.14186
Timestep Consumption Time: 2.43868
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.58054

Cumulative Model Updates: 174,506
Cumulative Timesteps: 1,455,355,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1455355530...
Checkpoint 1455355530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,863.58469
Policy Entropy: 2.96733
Value Function Loss: 0.00441

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.57399
Value Function Update Magnitude: 0.47295

Collected Steps per Second: 22,937.47854
Overall Steps per Second: 10,654.14072

Timestep Collection Time: 2.18054
Timestep Consumption Time: 2.51398
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.69451

Cumulative Model Updates: 174,512
Cumulative Timesteps: 1,455,405,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.70993
Policy Entropy: 2.96949
Value Function Loss: 0.00438

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.48988

Collected Steps per Second: 23,317.68703
Overall Steps per Second: 10,925.59649

Timestep Collection Time: 2.14464
Timestep Consumption Time: 2.43250
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.57714

Cumulative Model Updates: 174,518
Cumulative Timesteps: 1,455,455,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1455455554...
Checkpoint 1455455554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.31130
Policy Entropy: 2.96939
Value Function Loss: 0.00458

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.49363

Collected Steps per Second: 22,894.92708
Overall Steps per Second: 10,636.03909

Timestep Collection Time: 2.18468
Timestep Consumption Time: 2.51801
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.70269

Cumulative Model Updates: 174,524
Cumulative Timesteps: 1,455,505,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,028.17052
Policy Entropy: 2.99137
Value Function Loss: 0.00466

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.57937
Value Function Update Magnitude: 0.50191

Collected Steps per Second: 23,336.22738
Overall Steps per Second: 10,900.47488

Timestep Collection Time: 2.14268
Timestep Consumption Time: 2.44446
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.58714

Cumulative Model Updates: 174,530
Cumulative Timesteps: 1,455,555,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1455555574...
Checkpoint 1455555574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.61569
Policy Entropy: 2.99192
Value Function Loss: 0.00456

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.58767
Value Function Update Magnitude: 0.51403

Collected Steps per Second: 22,639.83438
Overall Steps per Second: 10,661.47760

Timestep Collection Time: 2.20912
Timestep Consumption Time: 2.48198
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.69109

Cumulative Model Updates: 174,536
Cumulative Timesteps: 1,455,605,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.24292
Policy Entropy: 2.99929
Value Function Loss: 0.00470

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.59954
Value Function Update Magnitude: 0.52738

Collected Steps per Second: 22,863.68317
Overall Steps per Second: 10,805.71722

Timestep Collection Time: 2.18775
Timestep Consumption Time: 2.44128
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62903

Cumulative Model Updates: 174,542
Cumulative Timesteps: 1,455,655,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1455655608...
Checkpoint 1455655608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,763.95974
Policy Entropy: 3.00195
Value Function Loss: 0.00465

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.59320
Value Function Update Magnitude: 0.53540

Collected Steps per Second: 22,364.80510
Overall Steps per Second: 10,685.28932

Timestep Collection Time: 2.23592
Timestep Consumption Time: 2.44397
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.67989

Cumulative Model Updates: 174,548
Cumulative Timesteps: 1,455,705,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.01234
Policy Entropy: 3.00653
Value Function Loss: 0.00468

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.57978
Value Function Update Magnitude: 0.53448

Collected Steps per Second: 22,813.82111
Overall Steps per Second: 10,875.95910

Timestep Collection Time: 2.19165
Timestep Consumption Time: 2.40564
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59730

Cumulative Model Updates: 174,554
Cumulative Timesteps: 1,455,755,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1455755614...
Checkpoint 1455755614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.74935
Policy Entropy: 3.00660
Value Function Loss: 0.00447

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.56359
Value Function Update Magnitude: 0.52927

Collected Steps per Second: 22,907.30113
Overall Steps per Second: 10,678.54099

Timestep Collection Time: 2.18367
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.68435

Cumulative Model Updates: 174,560
Cumulative Timesteps: 1,455,805,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.71718
Policy Entropy: 3.00293
Value Function Loss: 0.00456

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.56307
Value Function Update Magnitude: 0.51715

Collected Steps per Second: 23,343.02622
Overall Steps per Second: 10,902.59320

Timestep Collection Time: 2.14257
Timestep Consumption Time: 2.44478
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.58735

Cumulative Model Updates: 174,566
Cumulative Timesteps: 1,455,855,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1455855650...
Checkpoint 1455855650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,381.14053
Policy Entropy: 3.00062
Value Function Loss: 0.00474

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.57550
Value Function Update Magnitude: 0.50391

Collected Steps per Second: 22,959.47800
Overall Steps per Second: 10,646.65761

Timestep Collection Time: 2.17897
Timestep Consumption Time: 2.51997
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.69894

Cumulative Model Updates: 174,572
Cumulative Timesteps: 1,455,905,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,474.26574
Policy Entropy: 2.99688
Value Function Loss: 0.00472

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.58800
Value Function Update Magnitude: 0.50716

Collected Steps per Second: 23,500.31317
Overall Steps per Second: 10,964.33604

Timestep Collection Time: 2.12891
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.56298

Cumulative Model Updates: 174,578
Cumulative Timesteps: 1,455,955,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1455955708...
Checkpoint 1455955708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,055.68372
Policy Entropy: 3.00273
Value Function Loss: 0.00466

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.58047
Value Function Update Magnitude: 0.49892

Collected Steps per Second: 23,055.22041
Overall Steps per Second: 10,723.28732

Timestep Collection Time: 2.16992
Timestep Consumption Time: 2.49544
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.66536

Cumulative Model Updates: 174,584
Cumulative Timesteps: 1,456,005,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,185.52133
Policy Entropy: 3.00105
Value Function Loss: 0.00465

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.57874
Value Function Update Magnitude: 0.51613

Collected Steps per Second: 23,305.18781
Overall Steps per Second: 10,800.81631

Timestep Collection Time: 2.14613
Timestep Consumption Time: 2.48463
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.63076

Cumulative Model Updates: 174,590
Cumulative Timesteps: 1,456,055,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1456055752...
Checkpoint 1456055752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,435.91150
Policy Entropy: 2.99007
Value Function Loss: 0.00468

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.58169
Value Function Update Magnitude: 0.52739

Collected Steps per Second: 22,251.74491
Overall Steps per Second: 10,574.37390

Timestep Collection Time: 2.24791
Timestep Consumption Time: 2.48239
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.73030

Cumulative Model Updates: 174,596
Cumulative Timesteps: 1,456,105,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,371.60357
Policy Entropy: 2.98180
Value Function Loss: 0.00458

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.58526
Value Function Update Magnitude: 0.52072

Collected Steps per Second: 22,489.20789
Overall Steps per Second: 10,581.95619

Timestep Collection Time: 2.22436
Timestep Consumption Time: 2.50294
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.72729

Cumulative Model Updates: 174,602
Cumulative Timesteps: 1,456,155,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1456155796...
Checkpoint 1456155796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,656.46832
Policy Entropy: 2.98047
Value Function Loss: 0.00457

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.57848
Value Function Update Magnitude: 0.50082

Collected Steps per Second: 22,718.27374
Overall Steps per Second: 10,624.25922

Timestep Collection Time: 2.20202
Timestep Consumption Time: 2.50664
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.70866

Cumulative Model Updates: 174,608
Cumulative Timesteps: 1,456,205,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,363.99450
Policy Entropy: 3.00508
Value Function Loss: 0.00437

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.56752
Value Function Update Magnitude: 0.47879

Collected Steps per Second: 22,910.76594
Overall Steps per Second: 10,821.93044

Timestep Collection Time: 2.18264
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.62080

Cumulative Model Updates: 174,614
Cumulative Timesteps: 1,456,255,828

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1456255828...
Checkpoint 1456255828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.87564
Policy Entropy: 3.00690
Value Function Loss: 0.00437

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11654
Policy Update Magnitude: 0.56257
Value Function Update Magnitude: 0.46610

Collected Steps per Second: 22,670.67904
Overall Steps per Second: 10,639.75205

Timestep Collection Time: 2.20664
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.70180

Cumulative Model Updates: 174,620
Cumulative Timesteps: 1,456,305,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.39669
Policy Entropy: 2.99604
Value Function Loss: 0.00471

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.57471
Value Function Update Magnitude: 0.46840

Collected Steps per Second: 23,092.87267
Overall Steps per Second: 10,871.63471

Timestep Collection Time: 2.16630
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60152

Cumulative Model Updates: 174,626
Cumulative Timesteps: 1,456,355,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1456355880...
Checkpoint 1456355880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.61773
Policy Entropy: 2.97197
Value Function Loss: 0.00497

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.59156
Value Function Update Magnitude: 0.48165

Collected Steps per Second: 22,866.58172
Overall Steps per Second: 10,711.67638

Timestep Collection Time: 2.18695
Timestep Consumption Time: 2.48160
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.66855

Cumulative Model Updates: 174,632
Cumulative Timesteps: 1,456,405,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,695.02447
Policy Entropy: 2.95803
Value Function Loss: 0.00525

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.60681
Value Function Update Magnitude: 0.52560

Collected Steps per Second: 23,372.46834
Overall Steps per Second: 10,951.35092

Timestep Collection Time: 2.13935
Timestep Consumption Time: 2.42647
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.56583

Cumulative Model Updates: 174,638
Cumulative Timesteps: 1,456,455,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1456455890...
Checkpoint 1456455890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.65618
Policy Entropy: 2.97060
Value Function Loss: 0.00490

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.60914
Value Function Update Magnitude: 0.56095

Collected Steps per Second: 22,785.07016
Overall Steps per Second: 10,622.68230

Timestep Collection Time: 2.19442
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.70691

Cumulative Model Updates: 174,644
Cumulative Timesteps: 1,456,505,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.63423
Policy Entropy: 2.98248
Value Function Loss: 0.00459

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.60632
Value Function Update Magnitude: 0.56010

Collected Steps per Second: 23,503.02177
Overall Steps per Second: 10,895.55800

Timestep Collection Time: 2.12781
Timestep Consumption Time: 2.46213
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.58994

Cumulative Model Updates: 174,650
Cumulative Timesteps: 1,456,555,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1456555900...
Checkpoint 1456555900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,505.75535
Policy Entropy: 2.98075
Value Function Loss: 0.00477

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.60248
Value Function Update Magnitude: 0.53658

Collected Steps per Second: 22,902.79405
Overall Steps per Second: 10,627.71882

Timestep Collection Time: 2.18366
Timestep Consumption Time: 2.52214
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.70581

Cumulative Model Updates: 174,656
Cumulative Timesteps: 1,456,605,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,787.01078
Policy Entropy: 2.97798
Value Function Loss: 0.00478

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.60099
Value Function Update Magnitude: 0.52581

Collected Steps per Second: 22,711.87116
Overall Steps per Second: 10,664.44635

Timestep Collection Time: 2.20211
Timestep Consumption Time: 2.48768
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.68979

Cumulative Model Updates: 174,662
Cumulative Timesteps: 1,456,655,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1456655926...
Checkpoint 1456655926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,005.22455
Policy Entropy: 2.97597
Value Function Loss: 0.00488

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.60876
Value Function Update Magnitude: 0.53223

Collected Steps per Second: 22,518.03074
Overall Steps per Second: 10,659.15962

Timestep Collection Time: 2.22178
Timestep Consumption Time: 2.47184
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.69362

Cumulative Model Updates: 174,668
Cumulative Timesteps: 1,456,705,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,494.42927
Policy Entropy: 2.97877
Value Function Loss: 0.00482

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.60166
Value Function Update Magnitude: 0.52507

Collected Steps per Second: 23,019.77040
Overall Steps per Second: 10,690.02132

Timestep Collection Time: 2.17248
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.67819

Cumulative Model Updates: 174,674
Cumulative Timesteps: 1,456,755,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1456755966...
Checkpoint 1456755966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,998.27082
Policy Entropy: 2.98031
Value Function Loss: 0.00491

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.59658
Value Function Update Magnitude: 0.52898

Collected Steps per Second: 22,665.48659
Overall Steps per Second: 10,644.80661

Timestep Collection Time: 2.20776
Timestep Consumption Time: 2.49312
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.70088

Cumulative Model Updates: 174,680
Cumulative Timesteps: 1,456,806,006

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.24073
Policy Entropy: 2.99252
Value Function Loss: 0.00447

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.58543
Value Function Update Magnitude: 0.50933

Collected Steps per Second: 23,221.24773
Overall Steps per Second: 10,809.09562

Timestep Collection Time: 2.15380
Timestep Consumption Time: 2.47323
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.62703

Cumulative Model Updates: 174,686
Cumulative Timesteps: 1,456,856,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1456856020...
Checkpoint 1456856020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.89774
Policy Entropy: 2.98282
Value Function Loss: 0.00469

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.10912
Policy Update Magnitude: 0.59070
Value Function Update Magnitude: 0.50089

Collected Steps per Second: 22,213.95569
Overall Steps per Second: 10,669.59754

Timestep Collection Time: 2.25219
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.68902

Cumulative Model Updates: 174,692
Cumulative Timesteps: 1,456,906,050

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.55530
Policy Entropy: 2.97499
Value Function Loss: 0.00451

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11140
Policy Update Magnitude: 0.59557
Value Function Update Magnitude: 0.53233

Collected Steps per Second: 22,581.94045
Overall Steps per Second: 10,908.18085

Timestep Collection Time: 2.21522
Timestep Consumption Time: 2.37069
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.58592

Cumulative Model Updates: 174,698
Cumulative Timesteps: 1,456,956,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1456956074...
Checkpoint 1456956074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,304.83018
Policy Entropy: 2.95580
Value Function Loss: 0.00467

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.59310
Value Function Update Magnitude: 0.53505

Collected Steps per Second: 22,274.77425
Overall Steps per Second: 10,697.78029

Timestep Collection Time: 2.24586
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.67630

Cumulative Model Updates: 174,704
Cumulative Timesteps: 1,457,006,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.69350
Policy Entropy: 2.96994
Value Function Loss: 0.00476

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.59451
Value Function Update Magnitude: 0.53287

Collected Steps per Second: 22,799.54658
Overall Steps per Second: 10,893.80131

Timestep Collection Time: 2.19399
Timestep Consumption Time: 2.39779
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.59179

Cumulative Model Updates: 174,710
Cumulative Timesteps: 1,457,056,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1457056122...
Checkpoint 1457056122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,497.59708
Policy Entropy: 2.98610
Value Function Loss: 0.00468

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.53026

Collected Steps per Second: 22,258.64288
Overall Steps per Second: 10,695.45481

Timestep Collection Time: 2.24659
Timestep Consumption Time: 2.42886
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.67544

Cumulative Model Updates: 174,716
Cumulative Timesteps: 1,457,106,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,617.99459
Policy Entropy: 2.99729
Value Function Loss: 0.00444

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.59027
Value Function Update Magnitude: 0.54006

Collected Steps per Second: 22,001.25579
Overall Steps per Second: 10,536.47077

Timestep Collection Time: 2.27378
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.74789

Cumulative Model Updates: 174,722
Cumulative Timesteps: 1,457,156,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1457156154...
Checkpoint 1457156154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,881.23939
Policy Entropy: 2.97994
Value Function Loss: 0.00445

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.58921
Value Function Update Magnitude: 0.52788

Collected Steps per Second: 22,743.42896
Overall Steps per Second: 10,739.23241

Timestep Collection Time: 2.19940
Timestep Consumption Time: 2.45847
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.65787

Cumulative Model Updates: 174,728
Cumulative Timesteps: 1,457,206,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914.20130
Policy Entropy: 2.98486
Value Function Loss: 0.00481

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.59055
Value Function Update Magnitude: 0.52947

Collected Steps per Second: 23,022.29313
Overall Steps per Second: 10,711.37464

Timestep Collection Time: 2.17207
Timestep Consumption Time: 2.49643
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.66850

Cumulative Model Updates: 174,734
Cumulative Timesteps: 1,457,256,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1457256182...
Checkpoint 1457256182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.44372
Policy Entropy: 2.97094
Value Function Loss: 0.00477

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.58373
Value Function Update Magnitude: 0.52596

Collected Steps per Second: 22,588.35753
Overall Steps per Second: 10,610.92879

Timestep Collection Time: 2.21442
Timestep Consumption Time: 2.49959
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.71401

Cumulative Model Updates: 174,740
Cumulative Timesteps: 1,457,306,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.98071
Policy Entropy: 2.98701
Value Function Loss: 0.00455

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.57140
Value Function Update Magnitude: 0.50935

Collected Steps per Second: 22,868.23910
Overall Steps per Second: 10,845.01344

Timestep Collection Time: 2.18679
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.61115

Cumulative Model Updates: 174,746
Cumulative Timesteps: 1,457,356,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1457356210...
Checkpoint 1457356210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912.54698
Policy Entropy: 2.97395
Value Function Loss: 0.00464

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.58249
Value Function Update Magnitude: 0.50123

Collected Steps per Second: 22,754.89275
Overall Steps per Second: 10,689.58900

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.67820

Cumulative Model Updates: 174,752
Cumulative Timesteps: 1,457,406,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,565.74568
Policy Entropy: 2.98814
Value Function Loss: 0.00475

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.59373
Value Function Update Magnitude: 0.52522

Collected Steps per Second: 23,322.15252
Overall Steps per Second: 10,979.62969

Timestep Collection Time: 2.14397
Timestep Consumption Time: 2.41010
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.55407

Cumulative Model Updates: 174,758
Cumulative Timesteps: 1,457,456,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1457456220...
Checkpoint 1457456220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,651.36905
Policy Entropy: 2.98325
Value Function Loss: 0.00459

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.59227
Value Function Update Magnitude: 0.53784

Collected Steps per Second: 22,719.56873
Overall Steps per Second: 10,621.66525

Timestep Collection Time: 2.20075
Timestep Consumption Time: 2.50661
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.70736

Cumulative Model Updates: 174,764
Cumulative Timesteps: 1,457,506,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,794.16559
Policy Entropy: 2.99056
Value Function Loss: 0.00437

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.58365
Value Function Update Magnitude: 0.50826

Collected Steps per Second: 23,209.75437
Overall Steps per Second: 10,930.42284

Timestep Collection Time: 2.15444
Timestep Consumption Time: 2.42032
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.57475

Cumulative Model Updates: 174,770
Cumulative Timesteps: 1,457,556,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1457556224...
Checkpoint 1457556224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,953.26517
Policy Entropy: 2.98636
Value Function Loss: 0.00464

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.47600

Collected Steps per Second: 22,747.47678
Overall Steps per Second: 10,631.37374

Timestep Collection Time: 2.19972
Timestep Consumption Time: 2.50692
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.70664

Cumulative Model Updates: 174,776
Cumulative Timesteps: 1,457,606,262

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,585.85410
Policy Entropy: 2.99770
Value Function Loss: 0.00462

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.58833
Value Function Update Magnitude: 0.50027

Collected Steps per Second: 22,663.96788
Overall Steps per Second: 10,838.16540

Timestep Collection Time: 2.20667
Timestep Consumption Time: 2.40776
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61443

Cumulative Model Updates: 174,782
Cumulative Timesteps: 1,457,656,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1457656274...
Checkpoint 1457656274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,623.13173
Policy Entropy: 2.99470
Value Function Loss: 0.00469

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.58502
Value Function Update Magnitude: 0.51247

Collected Steps per Second: 22,175.02317
Overall Steps per Second: 10,654.17254

Timestep Collection Time: 2.25560
Timestep Consumption Time: 2.43909
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.69469

Cumulative Model Updates: 174,788
Cumulative Timesteps: 1,457,706,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,670.13332
Policy Entropy: 3.00721
Value Function Loss: 0.00488

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.59000
Value Function Update Magnitude: 0.52216

Collected Steps per Second: 23,371.17251
Overall Steps per Second: 10,851.92115

Timestep Collection Time: 2.14059
Timestep Consumption Time: 2.46947
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61006

Cumulative Model Updates: 174,794
Cumulative Timesteps: 1,457,756,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1457756320...
Checkpoint 1457756320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,287.43144
Policy Entropy: 3.00160
Value Function Loss: 0.00474

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.57786
Value Function Update Magnitude: 0.51464

Collected Steps per Second: 22,908.22400
Overall Steps per Second: 10,697.98708

Timestep Collection Time: 2.18306
Timestep Consumption Time: 2.49165
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.67471

Cumulative Model Updates: 174,800
Cumulative Timesteps: 1,457,806,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,032.30774
Policy Entropy: 2.98999
Value Function Loss: 0.00477

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.57500
Value Function Update Magnitude: 0.50857

Collected Steps per Second: 23,163.74312
Overall Steps per Second: 10,829.84687

Timestep Collection Time: 2.15941
Timestep Consumption Time: 2.45931
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.61872

Cumulative Model Updates: 174,806
Cumulative Timesteps: 1,457,856,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1457856350...
Checkpoint 1457856350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.21467
Policy Entropy: 2.98282
Value Function Loss: 0.00454

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.58576
Value Function Update Magnitude: 0.50790

Collected Steps per Second: 23,260.29383
Overall Steps per Second: 10,721.70587

Timestep Collection Time: 2.15070
Timestep Consumption Time: 2.51516
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.66586

Cumulative Model Updates: 174,812
Cumulative Timesteps: 1,457,906,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,545.61710
Policy Entropy: 2.97855
Value Function Loss: 0.00476

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.59466
Value Function Update Magnitude: 0.49905

Collected Steps per Second: 23,146.18402
Overall Steps per Second: 10,895.57120

Timestep Collection Time: 2.16027
Timestep Consumption Time: 2.42893
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.58920

Cumulative Model Updates: 174,818
Cumulative Timesteps: 1,457,956,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1457956378...
Checkpoint 1457956378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.56708
Policy Entropy: 2.98402
Value Function Loss: 0.00451

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.59191
Value Function Update Magnitude: 0.49918

Collected Steps per Second: 23,079.12368
Overall Steps per Second: 10,791.78469

Timestep Collection Time: 2.16724
Timestep Consumption Time: 2.46758
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.63482

Cumulative Model Updates: 174,824
Cumulative Timesteps: 1,458,006,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,811.13827
Policy Entropy: 2.99272
Value Function Loss: 0.00536

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.60359
Value Function Update Magnitude: 0.51120

Collected Steps per Second: 21,842.63188
Overall Steps per Second: 10,499.27472

Timestep Collection Time: 2.28919
Timestep Consumption Time: 2.47323
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.76242

Cumulative Model Updates: 174,830
Cumulative Timesteps: 1,458,056,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1458056398...
Checkpoint 1458056398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.62319
Policy Entropy: 3.00000
Value Function Loss: 0.00502

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.60381
Value Function Update Magnitude: 0.52947

Collected Steps per Second: 22,543.36339
Overall Steps per Second: 10,628.29442

Timestep Collection Time: 2.21866
Timestep Consumption Time: 2.48727
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.70593

Cumulative Model Updates: 174,836
Cumulative Timesteps: 1,458,106,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.95973
Policy Entropy: 2.99004
Value Function Loss: 0.00509

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.57985
Value Function Update Magnitude: 0.54123

Collected Steps per Second: 22,862.00254
Overall Steps per Second: 10,781.19237

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.45126
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.63882

Cumulative Model Updates: 174,842
Cumulative Timesteps: 1,458,156,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1458156426...
Checkpoint 1458156426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,777.33535
Policy Entropy: 2.98158
Value Function Loss: 0.00449

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.57189
Value Function Update Magnitude: 0.51936

Collected Steps per Second: 23,023.80079
Overall Steps per Second: 10,622.10299

Timestep Collection Time: 2.17236
Timestep Consumption Time: 2.53631
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.70867

Cumulative Model Updates: 174,848
Cumulative Timesteps: 1,458,206,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,659.36866
Policy Entropy: 2.97267
Value Function Loss: 0.00459

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.57782
Value Function Update Magnitude: 0.50833

Collected Steps per Second: 23,154.02662
Overall Steps per Second: 10,840.38134

Timestep Collection Time: 2.16066
Timestep Consumption Time: 2.45431
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.61497

Cumulative Model Updates: 174,854
Cumulative Timesteps: 1,458,256,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1458256470...
Checkpoint 1458256470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.58279
Policy Entropy: 2.98480
Value Function Loss: 0.00438

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.57760
Value Function Update Magnitude: 0.51183

Collected Steps per Second: 23,030.20240
Overall Steps per Second: 10,673.01833

Timestep Collection Time: 2.17184
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.68640

Cumulative Model Updates: 174,860
Cumulative Timesteps: 1,458,306,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,524.04321
Policy Entropy: 2.98792
Value Function Loss: 0.00442

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11482
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.50346

Collected Steps per Second: 23,570.89270
Overall Steps per Second: 10,949.84414

Timestep Collection Time: 2.12219
Timestep Consumption Time: 2.44609
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.56828

Cumulative Model Updates: 174,866
Cumulative Timesteps: 1,458,356,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1458356510...
Checkpoint 1458356510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,392.72328
Policy Entropy: 2.99446
Value Function Loss: 0.00437

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.56570
Value Function Update Magnitude: 0.49059

Collected Steps per Second: 23,330.18095
Overall Steps per Second: 10,730.86218

Timestep Collection Time: 2.14452
Timestep Consumption Time: 2.51792
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.66244

Cumulative Model Updates: 174,872
Cumulative Timesteps: 1,458,406,542

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,873.42900
Policy Entropy: 2.97736
Value Function Loss: 0.00469

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.58096
Value Function Update Magnitude: 0.52111

Collected Steps per Second: 23,247.85441
Overall Steps per Second: 10,816.62092

Timestep Collection Time: 2.15099
Timestep Consumption Time: 2.47208
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.62307

Cumulative Model Updates: 174,878
Cumulative Timesteps: 1,458,456,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1458456548...
Checkpoint 1458456548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,634.92780
Policy Entropy: 2.96389
Value Function Loss: 0.00498

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.59966
Value Function Update Magnitude: 0.54908

Collected Steps per Second: 22,756.72010
Overall Steps per Second: 10,729.49726

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.46349
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.66117

Cumulative Model Updates: 174,884
Cumulative Timesteps: 1,458,506,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.66080
Policy Entropy: 2.96013
Value Function Loss: 0.00478

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.60780
Value Function Update Magnitude: 0.55918

Collected Steps per Second: 23,041.70396
Overall Steps per Second: 10,876.37412

Timestep Collection Time: 2.17041
Timestep Consumption Time: 2.42763
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.59804

Cumulative Model Updates: 174,890
Cumulative Timesteps: 1,458,556,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1458556570...
Checkpoint 1458556570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.00977
Policy Entropy: 2.96931
Value Function Loss: 0.00451

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.59215
Value Function Update Magnitude: 0.54379

Collected Steps per Second: 22,433.04969
Overall Steps per Second: 10,583.44274

Timestep Collection Time: 2.23028
Timestep Consumption Time: 2.49710
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.72738

Cumulative Model Updates: 174,896
Cumulative Timesteps: 1,458,606,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.00393
Policy Entropy: 2.97007
Value Function Loss: 0.00434

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.58200
Value Function Update Magnitude: 0.50909

Collected Steps per Second: 23,415.61099
Overall Steps per Second: 10,854.22852

Timestep Collection Time: 2.13610
Timestep Consumption Time: 2.47206
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60816

Cumulative Model Updates: 174,902
Cumulative Timesteps: 1,458,656,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1458656620...
Checkpoint 1458656620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,905.62154
Policy Entropy: 2.96703
Value Function Loss: 0.00441

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.59153
Value Function Update Magnitude: 0.50597

Collected Steps per Second: 22,954.45778
Overall Steps per Second: 10,722.54294

Timestep Collection Time: 2.17840
Timestep Consumption Time: 2.48505
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.66345

Cumulative Model Updates: 174,908
Cumulative Timesteps: 1,458,706,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,217.96340
Policy Entropy: 2.95123
Value Function Loss: 0.00465

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.59081
Value Function Update Magnitude: 0.50765

Collected Steps per Second: 23,074.04292
Overall Steps per Second: 10,843.75973

Timestep Collection Time: 2.16815
Timestep Consumption Time: 2.44538
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.61353

Cumulative Model Updates: 174,914
Cumulative Timesteps: 1,458,756,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1458756652...
Checkpoint 1458756652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,928.33723
Policy Entropy: 2.95117
Value Function Loss: 0.00484

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.59660
Value Function Update Magnitude: 0.53027

Collected Steps per Second: 23,211.72725
Overall Steps per Second: 10,758.83287

Timestep Collection Time: 2.15469
Timestep Consumption Time: 2.49396
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.64865

Cumulative Model Updates: 174,920
Cumulative Timesteps: 1,458,806,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.13320
Policy Entropy: 2.95961
Value Function Loss: 0.00465

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.60775
Value Function Update Magnitude: 0.54903

Collected Steps per Second: 23,327.38315
Overall Steps per Second: 10,801.24949

Timestep Collection Time: 2.14358
Timestep Consumption Time: 2.48589
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.62946

Cumulative Model Updates: 174,926
Cumulative Timesteps: 1,458,856,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1458856670...
Checkpoint 1458856670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,189.79321
Policy Entropy: 2.96235
Value Function Loss: 0.00475

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.60807
Value Function Update Magnitude: 0.55799

Collected Steps per Second: 23,050.04035
Overall Steps per Second: 10,684.69902

Timestep Collection Time: 2.16919
Timestep Consumption Time: 2.51040
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.67959

Cumulative Model Updates: 174,932
Cumulative Timesteps: 1,458,906,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,259.98985
Policy Entropy: 2.96388
Value Function Loss: 0.00466

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.60511
Value Function Update Magnitude: 0.54283

Collected Steps per Second: 22,796.11320
Overall Steps per Second: 10,784.97361

Timestep Collection Time: 2.19344
Timestep Consumption Time: 2.44282
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.63627

Cumulative Model Updates: 174,938
Cumulative Timesteps: 1,458,956,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1458956672...
Checkpoint 1458956672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.18057
Policy Entropy: 2.95821
Value Function Loss: 0.00437

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.59504
Value Function Update Magnitude: 0.53020

Collected Steps per Second: 22,702.84609
Overall Steps per Second: 10,746.50017

Timestep Collection Time: 2.20307
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.65417

Cumulative Model Updates: 174,944
Cumulative Timesteps: 1,459,006,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,161.32063
Policy Entropy: 2.97103
Value Function Loss: 0.00436

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.58988
Value Function Update Magnitude: 0.53761

Collected Steps per Second: 22,529.10644
Overall Steps per Second: 10,551.52248

Timestep Collection Time: 2.21944
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.73884

Cumulative Model Updates: 174,950
Cumulative Timesteps: 1,459,056,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1459056690...
Checkpoint 1459056690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,035.89643
Policy Entropy: 2.97738
Value Function Loss: 0.00417

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.58380
Value Function Update Magnitude: 0.54924

Collected Steps per Second: 22,730.79619
Overall Steps per Second: 10,662.75077

Timestep Collection Time: 2.20019
Timestep Consumption Time: 2.49016
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.69035

Cumulative Model Updates: 174,956
Cumulative Timesteps: 1,459,106,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,383.83645
Policy Entropy: 2.96928
Value Function Loss: 0.00447

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.59378
Value Function Update Magnitude: 0.57611

Collected Steps per Second: 23,034.86353
Overall Steps per Second: 10,762.14635

Timestep Collection Time: 2.17132
Timestep Consumption Time: 2.47608
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.64740

Cumulative Model Updates: 174,962
Cumulative Timesteps: 1,459,156,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1459156718...
Checkpoint 1459156718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.09300
Policy Entropy: 2.95292
Value Function Loss: 0.00457

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.15134
Policy Update Magnitude: 0.59874
Value Function Update Magnitude: 0.57120

Collected Steps per Second: 23,181.31212
Overall Steps per Second: 10,624.94121

Timestep Collection Time: 2.15812
Timestep Consumption Time: 2.55043
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.70854

Cumulative Model Updates: 174,968
Cumulative Timesteps: 1,459,206,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.91015
Policy Entropy: 2.94878
Value Function Loss: 0.00425

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.58137
Value Function Update Magnitude: 0.53588

Collected Steps per Second: 22,917.22540
Overall Steps per Second: 10,782.00731

Timestep Collection Time: 2.18203
Timestep Consumption Time: 2.45589
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.63791

Cumulative Model Updates: 174,974
Cumulative Timesteps: 1,459,256,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1459256752...
Checkpoint 1459256752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.82661
Policy Entropy: 2.95926
Value Function Loss: 0.00419

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.14838
Policy Update Magnitude: 0.56682
Value Function Update Magnitude: 0.52544

Collected Steps per Second: 23,094.91644
Overall Steps per Second: 10,756.31099

Timestep Collection Time: 2.16558
Timestep Consumption Time: 2.48415
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.64974

Cumulative Model Updates: 174,980
Cumulative Timesteps: 1,459,306,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.37022
Policy Entropy: 2.94939
Value Function Loss: 0.00429

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.57092
Value Function Update Magnitude: 0.53740

Collected Steps per Second: 23,340.81804
Overall Steps per Second: 10,907.85839

Timestep Collection Time: 2.14277
Timestep Consumption Time: 2.44236
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.58513

Cumulative Model Updates: 174,986
Cumulative Timesteps: 1,459,356,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1459356780...
Checkpoint 1459356780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,536.71969
Policy Entropy: 2.94668
Value Function Loss: 0.00463

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.59160
Value Function Update Magnitude: 0.53404

Collected Steps per Second: 22,966.09068
Overall Steps per Second: 10,633.17651

Timestep Collection Time: 2.17721
Timestep Consumption Time: 2.52524
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.70245

Cumulative Model Updates: 174,992
Cumulative Timesteps: 1,459,406,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,537.78094
Policy Entropy: 2.93147
Value Function Loss: 0.00495

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.60233
Value Function Update Magnitude: 0.55686

Collected Steps per Second: 23,124.91426
Overall Steps per Second: 10,900.75047

Timestep Collection Time: 2.16269
Timestep Consumption Time: 2.42525
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.58794

Cumulative Model Updates: 174,998
Cumulative Timesteps: 1,459,456,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1459456794...
Checkpoint 1459456794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,533.91818
Policy Entropy: 2.94844
Value Function Loss: 0.00446

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.58889
Value Function Update Magnitude: 0.54498

Collected Steps per Second: 22,502.55343
Overall Steps per Second: 10,674.73344

Timestep Collection Time: 2.22348
Timestep Consumption Time: 2.46366
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.68714

Cumulative Model Updates: 175,004
Cumulative Timesteps: 1,459,506,828

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,005.62229
Policy Entropy: 2.95118
Value Function Loss: 0.00432

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.58008
Value Function Update Magnitude: 0.50315

Collected Steps per Second: 22,692.15576
Overall Steps per Second: 10,617.59018

Timestep Collection Time: 2.20393
Timestep Consumption Time: 2.50636
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.71030

Cumulative Model Updates: 175,010
Cumulative Timesteps: 1,459,556,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1459556840...
Checkpoint 1459556840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,147.66171
Policy Entropy: 2.95294
Value Function Loss: 0.00430

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.57835
Value Function Update Magnitude: 0.49828

Collected Steps per Second: 22,747.00559
Overall Steps per Second: 10,830.76778

Timestep Collection Time: 2.19915
Timestep Consumption Time: 2.41955
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.61869

Cumulative Model Updates: 175,016
Cumulative Timesteps: 1,459,606,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.35833
Policy Entropy: 2.94099
Value Function Loss: 0.00449

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.58754
Value Function Update Magnitude: 0.50703

Collected Steps per Second: 22,514.63598
Overall Steps per Second: 10,532.32537

Timestep Collection Time: 2.22211
Timestep Consumption Time: 2.52803
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.75014

Cumulative Model Updates: 175,022
Cumulative Timesteps: 1,459,656,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1459656894...
Checkpoint 1459656894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.23750
Policy Entropy: 2.93946
Value Function Loss: 0.00437

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.58967
Value Function Update Magnitude: 0.52582

Collected Steps per Second: 22,731.26969
Overall Steps per Second: 10,644.71040

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.49796
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.69792

Cumulative Model Updates: 175,028
Cumulative Timesteps: 1,459,706,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,954.69449
Policy Entropy: 2.94796
Value Function Loss: 0.00426

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11372
Policy Update Magnitude: 0.58088
Value Function Update Magnitude: 0.51466

Collected Steps per Second: 23,172.86903
Overall Steps per Second: 10,828.49550

Timestep Collection Time: 2.15873
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.61966

Cumulative Model Updates: 175,034
Cumulative Timesteps: 1,459,756,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1459756926...
Checkpoint 1459756926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,281.03874
Policy Entropy: 2.95362
Value Function Loss: 0.00470

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.59098
Value Function Update Magnitude: 0.53002

Collected Steps per Second: 23,212.76905
Overall Steps per Second: 10,798.97351

Timestep Collection Time: 2.15416
Timestep Consumption Time: 2.47628
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.63044

Cumulative Model Updates: 175,040
Cumulative Timesteps: 1,459,806,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,607.40566
Policy Entropy: 2.95289
Value Function Loss: 0.00495

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.60244
Value Function Update Magnitude: 0.54870

Collected Steps per Second: 23,222.02376
Overall Steps per Second: 10,800.03485

Timestep Collection Time: 2.15365
Timestep Consumption Time: 2.47708
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.63073

Cumulative Model Updates: 175,046
Cumulative Timesteps: 1,459,856,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1459856942...
Checkpoint 1459856942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,318.18586
Policy Entropy: 2.95486
Value Function Loss: 0.00534

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.61094
Value Function Update Magnitude: 0.56771

Collected Steps per Second: 23,227.52016
Overall Steps per Second: 10,822.26357

Timestep Collection Time: 2.15357
Timestep Consumption Time: 2.46857
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.62214

Cumulative Model Updates: 175,052
Cumulative Timesteps: 1,459,906,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,914.74119
Policy Entropy: 2.95138
Value Function Loss: 0.00506

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.61012
Value Function Update Magnitude: 0.56933

Collected Steps per Second: 22,620.04569
Overall Steps per Second: 10,674.35962

Timestep Collection Time: 2.21105
Timestep Consumption Time: 2.47439
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.68543

Cumulative Model Updates: 175,058
Cumulative Timesteps: 1,459,956,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1459956978...
Checkpoint 1459956978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,235.25957
Policy Entropy: 2.96589
Value Function Loss: 0.00501

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.60422
Value Function Update Magnitude: 0.55899

Collected Steps per Second: 22,918.48087
Overall Steps per Second: 10,701.54891

Timestep Collection Time: 2.18208
Timestep Consumption Time: 2.49107
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.67316

Cumulative Model Updates: 175,064
Cumulative Timesteps: 1,460,006,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,755.47875
Policy Entropy: 2.98767
Value Function Loss: 0.00438

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.58707
Value Function Update Magnitude: 0.54906

Collected Steps per Second: 22,753.17411
Overall Steps per Second: 10,660.27033

Timestep Collection Time: 2.19767
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.69069

Cumulative Model Updates: 175,070
Cumulative Timesteps: 1,460,056,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1460056992...
Checkpoint 1460056992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,737.56521
Policy Entropy: 2.97989
Value Function Loss: 0.00455

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.58257
Value Function Update Magnitude: 0.52379

Collected Steps per Second: 22,420.93864
Overall Steps per Second: 10,589.95686

Timestep Collection Time: 2.23059
Timestep Consumption Time: 2.49199
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.72259

Cumulative Model Updates: 175,076
Cumulative Timesteps: 1,460,107,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.04713
Policy Entropy: 2.95356
Value Function Loss: 0.00458

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.59346
Value Function Update Magnitude: 0.54078

Collected Steps per Second: 22,823.54914
Overall Steps per Second: 10,759.93915

Timestep Collection Time: 2.19116
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.64780

Cumulative Model Updates: 175,082
Cumulative Timesteps: 1,460,157,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1460157014...
Checkpoint 1460157014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.31595
Policy Entropy: 2.94713
Value Function Loss: 0.00502

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.60734
Value Function Update Magnitude: 0.56403

Collected Steps per Second: 22,335.09022
Overall Steps per Second: 10,650.74143

Timestep Collection Time: 2.23890
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.69507

Cumulative Model Updates: 175,088
Cumulative Timesteps: 1,460,207,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,289.02704
Policy Entropy: 2.94131
Value Function Loss: 0.00525

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.61556
Value Function Update Magnitude: 0.56976

Collected Steps per Second: 22,922.93244
Overall Steps per Second: 10,815.59431

Timestep Collection Time: 2.18140
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62332

Cumulative Model Updates: 175,094
Cumulative Timesteps: 1,460,257,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1460257024...
Checkpoint 1460257024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,440.02947
Policy Entropy: 2.94323
Value Function Loss: 0.00530

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.62233
Value Function Update Magnitude: 0.58892

Collected Steps per Second: 22,912.15118
Overall Steps per Second: 10,692.47055

Timestep Collection Time: 2.18286
Timestep Consumption Time: 2.49464
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.67750

Cumulative Model Updates: 175,100
Cumulative Timesteps: 1,460,307,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.96308
Policy Entropy: 2.94823
Value Function Loss: 0.00497

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.61500
Value Function Update Magnitude: 0.58837

Collected Steps per Second: 23,346.11611
Overall Steps per Second: 10,944.98437

Timestep Collection Time: 2.14288
Timestep Consumption Time: 2.42798
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.57086

Cumulative Model Updates: 175,106
Cumulative Timesteps: 1,460,357,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1460357066...
Checkpoint 1460357066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,807.44330
Policy Entropy: 2.96218
Value Function Loss: 0.00483

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.60428
Value Function Update Magnitude: 0.56246

Collected Steps per Second: 23,270.31341
Overall Steps per Second: 10,686.57699

Timestep Collection Time: 2.14892
Timestep Consumption Time: 2.53041
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.67933

Cumulative Model Updates: 175,112
Cumulative Timesteps: 1,460,407,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.07018
Policy Entropy: 2.96387
Value Function Loss: 0.00514

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.61265
Value Function Update Magnitude: 0.55074

Collected Steps per Second: 22,996.76522
Overall Steps per Second: 10,804.92359

Timestep Collection Time: 2.17431
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.62771

Cumulative Model Updates: 175,118
Cumulative Timesteps: 1,460,457,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1460457074...
Checkpoint 1460457074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.99172
Policy Entropy: 2.93862
Value Function Loss: 0.00528

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.61440
Value Function Update Magnitude: 0.55596

Collected Steps per Second: 23,082.78897
Overall Steps per Second: 10,689.34204

Timestep Collection Time: 2.16716
Timestep Consumption Time: 2.51265
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.67980

Cumulative Model Updates: 175,124
Cumulative Timesteps: 1,460,507,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,503.25822
Policy Entropy: 2.94580
Value Function Loss: 0.00534

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.60641
Value Function Update Magnitude: 0.57265

Collected Steps per Second: 23,137.62160
Overall Steps per Second: 10,859.74258

Timestep Collection Time: 2.16098
Timestep Consumption Time: 2.44318
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.60416

Cumulative Model Updates: 175,130
Cumulative Timesteps: 1,460,557,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1460557098...
Checkpoint 1460557098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.17596
Policy Entropy: 2.95242
Value Function Loss: 0.00508

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.60474
Value Function Update Magnitude: 0.56075

Collected Steps per Second: 22,529.25201
Overall Steps per Second: 10,692.90810

Timestep Collection Time: 2.21996
Timestep Consumption Time: 2.45735
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.67731

Cumulative Model Updates: 175,136
Cumulative Timesteps: 1,460,607,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,968.15246
Policy Entropy: 2.98148
Value Function Loss: 0.00482

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.59631
Value Function Update Magnitude: 0.54929

Collected Steps per Second: 22,729.80143
Overall Steps per Second: 10,856.41695

Timestep Collection Time: 2.20020
Timestep Consumption Time: 2.40630
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.60649

Cumulative Model Updates: 175,142
Cumulative Timesteps: 1,460,657,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1460657122...
Checkpoint 1460657122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937.79932
Policy Entropy: 2.96315
Value Function Loss: 0.00452

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.58776
Value Function Update Magnitude: 0.52387

Collected Steps per Second: 22,684.50070
Overall Steps per Second: 10,668.15285

Timestep Collection Time: 2.20477
Timestep Consumption Time: 2.48339
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.68816

Cumulative Model Updates: 175,148
Cumulative Timesteps: 1,460,707,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,728.47477
Policy Entropy: 2.98077
Value Function Loss: 0.00419

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.50871

Collected Steps per Second: 23,029.37871
Overall Steps per Second: 10,836.74312

Timestep Collection Time: 2.17253
Timestep Consumption Time: 2.44436
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61689

Cumulative Model Updates: 175,154
Cumulative Timesteps: 1,460,757,168

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1460757168...
Checkpoint 1460757168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,079.39747
Policy Entropy: 3.01092
Value Function Loss: 0.00419

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.57450
Value Function Update Magnitude: 0.50462

Collected Steps per Second: 23,015.08572
Overall Steps per Second: 10,692.30403

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.67888

Cumulative Model Updates: 175,160
Cumulative Timesteps: 1,460,807,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,149.65769
Policy Entropy: 3.01294
Value Function Loss: 0.00423

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.57280
Value Function Update Magnitude: 0.50203

Collected Steps per Second: 22,924.00133
Overall Steps per Second: 10,674.80551

Timestep Collection Time: 2.18191
Timestep Consumption Time: 2.50371
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.68561

Cumulative Model Updates: 175,166
Cumulative Timesteps: 1,460,857,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1460857214...
Checkpoint 1460857214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,823.47144
Policy Entropy: 2.98729
Value Function Loss: 0.00450

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11866
Policy Update Magnitude: 0.58869
Value Function Update Magnitude: 0.50768

Collected Steps per Second: 23,084.05356
Overall Steps per Second: 10,869.14330

Timestep Collection Time: 2.16643
Timestep Consumption Time: 2.43467
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.60110

Cumulative Model Updates: 175,172
Cumulative Timesteps: 1,460,907,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800.16257
Policy Entropy: 2.94690
Value Function Loss: 0.00501

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.60440
Value Function Update Magnitude: 0.54704

Collected Steps per Second: 23,249.46560
Overall Steps per Second: 10,992.17305

Timestep Collection Time: 2.15145
Timestep Consumption Time: 2.39906
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.55051

Cumulative Model Updates: 175,178
Cumulative Timesteps: 1,460,957,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1460957244...
Checkpoint 1460957244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.19718
Policy Entropy: 2.94401
Value Function Loss: 0.00491

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.61374
Value Function Update Magnitude: 0.58786

Collected Steps per Second: 23,107.90350
Overall Steps per Second: 10,768.40260

Timestep Collection Time: 2.16402
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.64377

Cumulative Model Updates: 175,184
Cumulative Timesteps: 1,461,007,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,502.88282
Policy Entropy: 2.97210
Value Function Loss: 0.00445

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.59562
Value Function Update Magnitude: 0.58118

Collected Steps per Second: 22,784.38715
Overall Steps per Second: 10,730.11677

Timestep Collection Time: 2.19484
Timestep Consumption Time: 2.46569
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.66053

Cumulative Model Updates: 175,190
Cumulative Timesteps: 1,461,057,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1461057258...
Checkpoint 1461057258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,665.90866
Policy Entropy: 2.97838
Value Function Loss: 0.00427

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.57505
Value Function Update Magnitude: 0.53188

Collected Steps per Second: 22,442.91729
Overall Steps per Second: 10,644.11150

Timestep Collection Time: 2.22930
Timestep Consumption Time: 2.47114
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.70044

Cumulative Model Updates: 175,196
Cumulative Timesteps: 1,461,107,290

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,309.34048
Policy Entropy: 2.97769
Value Function Loss: 0.00439

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.58079
Value Function Update Magnitude: 0.52024

Collected Steps per Second: 23,070.91840
Overall Steps per Second: 10,847.34729

Timestep Collection Time: 2.16792
Timestep Consumption Time: 2.44297
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61090

Cumulative Model Updates: 175,202
Cumulative Timesteps: 1,461,157,306

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1461157306...
Checkpoint 1461157306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,237.48829
Policy Entropy: 2.95128
Value Function Loss: 0.00482

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.59884
Value Function Update Magnitude: 0.54865

Collected Steps per Second: 22,383.03301
Overall Steps per Second: 10,688.33036

Timestep Collection Time: 2.23419
Timestep Consumption Time: 2.44456
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.67875

Cumulative Model Updates: 175,208
Cumulative Timesteps: 1,461,207,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,324.82580
Policy Entropy: 2.95367
Value Function Loss: 0.00466

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.60938
Value Function Update Magnitude: 0.56987

Collected Steps per Second: 21,878.18959
Overall Steps per Second: 10,434.81106

Timestep Collection Time: 2.28566
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.79223

Cumulative Model Updates: 175,214
Cumulative Timesteps: 1,461,257,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1461257320...
Checkpoint 1461257320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,866.64670
Policy Entropy: 2.94837
Value Function Loss: 0.00452

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.60082
Value Function Update Magnitude: 0.56657

Collected Steps per Second: 23,043.74714
Overall Steps per Second: 10,647.76667

Timestep Collection Time: 2.17083
Timestep Consumption Time: 2.52725
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.69807

Cumulative Model Updates: 175,220
Cumulative Timesteps: 1,461,307,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,291.71559
Policy Entropy: 2.97097
Value Function Loss: 0.00494

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.60939
Value Function Update Magnitude: 0.57201

Collected Steps per Second: 23,357.31001
Overall Steps per Second: 10,935.11618

Timestep Collection Time: 2.14143
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.57407

Cumulative Model Updates: 175,226
Cumulative Timesteps: 1,461,357,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1461357362...
Checkpoint 1461357362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,797.91856
Policy Entropy: 2.96586
Value Function Loss: 0.00489

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.60165
Value Function Update Magnitude: 0.56677

Collected Steps per Second: 23,177.99337
Overall Steps per Second: 10,791.28715

Timestep Collection Time: 2.15851
Timestep Consumption Time: 2.47763
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.63615

Cumulative Model Updates: 175,232
Cumulative Timesteps: 1,461,407,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,103.72353
Policy Entropy: 2.97388
Value Function Loss: 0.00473

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.59906
Value Function Update Magnitude: 0.53229

Collected Steps per Second: 23,361.55023
Overall Steps per Second: 10,746.50362

Timestep Collection Time: 2.14087
Timestep Consumption Time: 2.51311
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.65398

Cumulative Model Updates: 175,238
Cumulative Timesteps: 1,461,457,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1461457406...
Checkpoint 1461457406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,511.47762
Policy Entropy: 2.95201
Value Function Loss: 0.00463

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11416
Policy Update Magnitude: 0.59394
Value Function Update Magnitude: 0.50457

Collected Steps per Second: 23,007.35622
Overall Steps per Second: 10,758.73804

Timestep Collection Time: 2.17330
Timestep Consumption Time: 2.47427
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.64757

Cumulative Model Updates: 175,244
Cumulative Timesteps: 1,461,507,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.60147
Policy Entropy: 2.95662
Value Function Loss: 0.00472

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.59707
Value Function Update Magnitude: 0.51589

Collected Steps per Second: 23,395.51177
Overall Steps per Second: 10,768.52672

Timestep Collection Time: 2.13750
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.64390

Cumulative Model Updates: 175,250
Cumulative Timesteps: 1,461,557,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1461557416...
Checkpoint 1461557416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.38716
Policy Entropy: 2.95498
Value Function Loss: 0.00481

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.60053
Value Function Update Magnitude: 0.52790

Collected Steps per Second: 22,707.86267
Overall Steps per Second: 10,706.92649

Timestep Collection Time: 2.20223
Timestep Consumption Time: 2.46839
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.67062

Cumulative Model Updates: 175,256
Cumulative Timesteps: 1,461,607,424

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,603.65749
Policy Entropy: 2.94568
Value Function Loss: 0.00520

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.60906
Value Function Update Magnitude: 0.53987

Collected Steps per Second: 22,296.12572
Overall Steps per Second: 10,536.44803

Timestep Collection Time: 2.24398
Timestep Consumption Time: 2.50449
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.74847

Cumulative Model Updates: 175,262
Cumulative Timesteps: 1,461,657,456

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1461657456...
Checkpoint 1461657456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,209.67641
Policy Entropy: 2.95509
Value Function Loss: 0.00502

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.60195
Value Function Update Magnitude: 0.53924

Collected Steps per Second: 22,461.10959
Overall Steps per Second: 10,570.22015

Timestep Collection Time: 2.22732
Timestep Consumption Time: 2.50560
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.73292

Cumulative Model Updates: 175,268
Cumulative Timesteps: 1,461,707,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,103.92790
Policy Entropy: 2.94652
Value Function Loss: 0.00478

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.59189
Value Function Update Magnitude: 0.52312

Collected Steps per Second: 22,668.07195
Overall Steps per Second: 10,697.05217

Timestep Collection Time: 2.20663
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.67605

Cumulative Model Updates: 175,274
Cumulative Timesteps: 1,461,757,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1461757504...
Checkpoint 1461757504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,178.91558
Policy Entropy: 2.96221
Value Function Loss: 0.00428

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.58187
Value Function Update Magnitude: 0.50769

Collected Steps per Second: 22,598.64955
Overall Steps per Second: 10,764.04400

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.43384
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.64751

Cumulative Model Updates: 175,280
Cumulative Timesteps: 1,461,807,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,156.98811
Policy Entropy: 2.95488
Value Function Loss: 0.00407

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.58114
Value Function Update Magnitude: 0.51081

Collected Steps per Second: 23,123.45505
Overall Steps per Second: 10,644.53799

Timestep Collection Time: 2.16257
Timestep Consumption Time: 2.53524
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.69781

Cumulative Model Updates: 175,286
Cumulative Timesteps: 1,461,857,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1461857536...
Checkpoint 1461857536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.45397
Policy Entropy: 2.95277
Value Function Loss: 0.00437

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.59689
Value Function Update Magnitude: 0.51706

Collected Steps per Second: 22,615.81004
Overall Steps per Second: 10,587.88418

Timestep Collection Time: 2.21120
Timestep Consumption Time: 2.51194
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.72313

Cumulative Model Updates: 175,292
Cumulative Timesteps: 1,461,907,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,005.14603
Policy Entropy: 2.95593
Value Function Loss: 0.00433

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.59771
Value Function Update Magnitude: 0.51541

Collected Steps per Second: 23,035.24221
Overall Steps per Second: 10,825.94067

Timestep Collection Time: 2.17163
Timestep Consumption Time: 2.44912
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.62075

Cumulative Model Updates: 175,298
Cumulative Timesteps: 1,461,957,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1461957568...
Checkpoint 1461957568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,270.76386
Policy Entropy: 2.96153
Value Function Loss: 0.00413

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.58003
Value Function Update Magnitude: 0.48870

Collected Steps per Second: 22,510.93843
Overall Steps per Second: 10,787.38016

Timestep Collection Time: 2.22132
Timestep Consumption Time: 2.41410
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.63542

Cumulative Model Updates: 175,304
Cumulative Timesteps: 1,462,007,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,812.58942
Policy Entropy: 2.96983
Value Function Loss: 0.00446

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.58768
Value Function Update Magnitude: 0.48506

Collected Steps per Second: 22,617.17336
Overall Steps per Second: 10,778.86296

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.42800
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.63871

Cumulative Model Updates: 175,310
Cumulative Timesteps: 1,462,057,572

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1462057572...
Checkpoint 1462057572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.92788
Policy Entropy: 2.96177
Value Function Loss: 0.00479

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.59261
Value Function Update Magnitude: 0.51646

Collected Steps per Second: 22,418.39890
Overall Steps per Second: 10,748.87358

Timestep Collection Time: 2.23085
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.65277

Cumulative Model Updates: 175,316
Cumulative Timesteps: 1,462,107,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,433.68395
Policy Entropy: 2.97102
Value Function Loss: 0.00522

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.60329
Value Function Update Magnitude: 0.55046

Collected Steps per Second: 21,916.36672
Overall Steps per Second: 10,766.74064

Timestep Collection Time: 2.28149
Timestep Consumption Time: 2.36263
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.64412

Cumulative Model Updates: 175,322
Cumulative Timesteps: 1,462,157,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1462157586...
Checkpoint 1462157586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.42814
Policy Entropy: 2.97395
Value Function Loss: 0.00472

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.59529
Value Function Update Magnitude: 0.55248

Collected Steps per Second: 21,890.19658
Overall Steps per Second: 10,670.53651

Timestep Collection Time: 2.28413
Timestep Consumption Time: 2.40167
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.68580

Cumulative Model Updates: 175,328
Cumulative Timesteps: 1,462,207,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,685.16331
Policy Entropy: 2.98918
Value Function Loss: 0.00454

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.57708
Value Function Update Magnitude: 0.51511

Collected Steps per Second: 21,828.33632
Overall Steps per Second: 10,629.34854

Timestep Collection Time: 2.29179
Timestep Consumption Time: 2.41461
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.70640

Cumulative Model Updates: 175,334
Cumulative Timesteps: 1,462,257,612

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1462257612...
Checkpoint 1462257612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,042.40076
Policy Entropy: 2.98497
Value Function Loss: 0.00437

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.47612

Collected Steps per Second: 22,161.33841
Overall Steps per Second: 10,529.66869

Timestep Collection Time: 2.25690
Timestep Consumption Time: 2.49310
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.75001

Cumulative Model Updates: 175,340
Cumulative Timesteps: 1,462,307,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,734.97995
Policy Entropy: 2.98402
Value Function Loss: 0.00479

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.48354

Collected Steps per Second: 23,288.75274
Overall Steps per Second: 10,870.13307

Timestep Collection Time: 2.14782
Timestep Consumption Time: 2.45378
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.60160

Cumulative Model Updates: 175,346
Cumulative Timesteps: 1,462,357,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1462357648...
Checkpoint 1462357648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,641.32989
Policy Entropy: 2.97183
Value Function Loss: 0.00506

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.57215
Value Function Update Magnitude: 0.50026

Collected Steps per Second: 23,106.03133
Overall Steps per Second: 10,851.84935

Timestep Collection Time: 2.16489
Timestep Consumption Time: 2.44465
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.60954

Cumulative Model Updates: 175,352
Cumulative Timesteps: 1,462,407,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,262.13886
Policy Entropy: 2.97181
Value Function Loss: 0.00517

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.57863
Value Function Update Magnitude: 0.50771

Collected Steps per Second: 22,887.20027
Overall Steps per Second: 10,663.13475

Timestep Collection Time: 2.18515
Timestep Consumption Time: 2.50503
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.69018

Cumulative Model Updates: 175,358
Cumulative Timesteps: 1,462,457,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1462457682...
Checkpoint 1462457682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,005.83397
Policy Entropy: 2.97103
Value Function Loss: 0.00503

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.58756
Value Function Update Magnitude: 0.51154

Collected Steps per Second: 23,039.37474
Overall Steps per Second: 10,763.75590

Timestep Collection Time: 2.17037
Timestep Consumption Time: 2.47522
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.64559

Cumulative Model Updates: 175,364
Cumulative Timesteps: 1,462,507,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.70856
Policy Entropy: 2.97690
Value Function Loss: 0.00454

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.58712
Value Function Update Magnitude: 0.49739

Collected Steps per Second: 23,398.27552
Overall Steps per Second: 10,812.32961

Timestep Collection Time: 2.13734
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.62528

Cumulative Model Updates: 175,370
Cumulative Timesteps: 1,462,557,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1462557696...
Checkpoint 1462557696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,201.72738
Policy Entropy: 2.99239
Value Function Loss: 0.00417

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.57346
Value Function Update Magnitude: 0.47370

Collected Steps per Second: 23,233.56256
Overall Steps per Second: 10,793.34588

Timestep Collection Time: 2.15309
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.63471

Cumulative Model Updates: 175,376
Cumulative Timesteps: 1,462,607,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,345.23580
Policy Entropy: 3.00223
Value Function Loss: 0.00406

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.46433

Collected Steps per Second: 22,874.07056
Overall Steps per Second: 10,715.72317

Timestep Collection Time: 2.18597
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.66623

Cumulative Model Updates: 175,382
Cumulative Timesteps: 1,462,657,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1462657722...
Checkpoint 1462657722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,499.43397
Policy Entropy: 3.00120
Value Function Loss: 0.00398

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.55555
Value Function Update Magnitude: 0.46026

Collected Steps per Second: 22,804.53041
Overall Steps per Second: 10,649.33947

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.69588

Cumulative Model Updates: 175,388
Cumulative Timesteps: 1,462,707,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,490.64406
Policy Entropy: 2.98029
Value Function Loss: 0.00415

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.55482
Value Function Update Magnitude: 0.45371

Collected Steps per Second: 22,690.38406
Overall Steps per Second: 10,640.03237

Timestep Collection Time: 2.20393
Timestep Consumption Time: 2.49606
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.69999

Cumulative Model Updates: 175,394
Cumulative Timesteps: 1,462,757,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1462757738...
Checkpoint 1462757738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,148.68425
Policy Entropy: 2.97474
Value Function Loss: 0.00425

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.55921
Value Function Update Magnitude: 0.45783

Collected Steps per Second: 22,850.50819
Overall Steps per Second: 10,908.73566

Timestep Collection Time: 2.18971
Timestep Consumption Time: 2.39707
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.58678

Cumulative Model Updates: 175,400
Cumulative Timesteps: 1,462,807,774

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,238.12727
Policy Entropy: 2.96018
Value Function Loss: 0.00456

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10705
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.47463

Collected Steps per Second: 23,284.38697
Overall Steps per Second: 10,841.42637

Timestep Collection Time: 2.14839
Timestep Consumption Time: 2.46576
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.61415

Cumulative Model Updates: 175,406
Cumulative Timesteps: 1,462,857,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1462857798...
Checkpoint 1462857798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,235.67391
Policy Entropy: 2.95804
Value Function Loss: 0.00437

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.47185

Collected Steps per Second: 23,093.80010
Overall Steps per Second: 10,666.13697

Timestep Collection Time: 2.16612
Timestep Consumption Time: 2.52386
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.68998

Cumulative Model Updates: 175,412
Cumulative Timesteps: 1,462,907,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,381.73144
Policy Entropy: 2.95906
Value Function Loss: 0.00413

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.46493

Collected Steps per Second: 23,060.50237
Overall Steps per Second: 10,878.40913

Timestep Collection Time: 2.16856
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.59700

Cumulative Model Updates: 175,418
Cumulative Timesteps: 1,462,957,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1462957830...
Checkpoint 1462957830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,782.31733
Policy Entropy: 2.97850
Value Function Loss: 0.00388

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.56908
Value Function Update Magnitude: 0.46666

Collected Steps per Second: 22,988.67478
Overall Steps per Second: 10,728.78066

Timestep Collection Time: 2.17594
Timestep Consumption Time: 2.48647
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.66241

Cumulative Model Updates: 175,424
Cumulative Timesteps: 1,463,007,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,394.98604
Policy Entropy: 2.97240
Value Function Loss: 0.00415

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.56790
Value Function Update Magnitude: 0.46234

Collected Steps per Second: 23,045.64831
Overall Steps per Second: 10,859.86013

Timestep Collection Time: 2.17074
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60650

Cumulative Model Updates: 175,430
Cumulative Timesteps: 1,463,057,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1463057878...
Checkpoint 1463057878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,856.21057
Policy Entropy: 2.97051
Value Function Loss: 0.00433

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.57234
Value Function Update Magnitude: 0.47107

Collected Steps per Second: 22,836.06887
Overall Steps per Second: 10,703.09484

Timestep Collection Time: 2.19092
Timestep Consumption Time: 2.48362
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.67454

Cumulative Model Updates: 175,436
Cumulative Timesteps: 1,463,107,910

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,919.50899
Policy Entropy: 2.96577
Value Function Loss: 0.00465

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.57619
Value Function Update Magnitude: 0.48297

Collected Steps per Second: 22,556.87867
Overall Steps per Second: 10,635.39827

Timestep Collection Time: 2.21697
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.70203

Cumulative Model Updates: 175,442
Cumulative Timesteps: 1,463,157,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1463157918...
Checkpoint 1463157918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,798.44204
Policy Entropy: 2.96225
Value Function Loss: 0.00466

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.58080
Value Function Update Magnitude: 0.49478

Collected Steps per Second: 22,633.16364
Overall Steps per Second: 10,790.90210

Timestep Collection Time: 2.20977
Timestep Consumption Time: 2.42506
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.63483

Cumulative Model Updates: 175,448
Cumulative Timesteps: 1,463,207,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,305.92524
Policy Entropy: 2.96428
Value Function Loss: 0.00441

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.57277
Value Function Update Magnitude: 0.49756

Collected Steps per Second: 22,553.50415
Overall Steps per Second: 10,561.25853

Timestep Collection Time: 2.21775
Timestep Consumption Time: 2.51824
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.73599

Cumulative Model Updates: 175,454
Cumulative Timesteps: 1,463,257,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1463257950...
Checkpoint 1463257950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,131.29834
Policy Entropy: 2.96689
Value Function Loss: 0.00442

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.57273
Value Function Update Magnitude: 0.48900

Collected Steps per Second: 22,728.56913
Overall Steps per Second: 10,604.20313

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.51554
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.71568

Cumulative Model Updates: 175,460
Cumulative Timesteps: 1,463,307,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,362.84303
Policy Entropy: 2.97356
Value Function Loss: 0.00429

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.58222
Value Function Update Magnitude: 0.48848

Collected Steps per Second: 22,782.61051
Overall Steps per Second: 10,661.14402

Timestep Collection Time: 2.19474
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.69012

Cumulative Model Updates: 175,466
Cumulative Timesteps: 1,463,357,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1463357958...
Checkpoint 1463357958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.47765
Policy Entropy: 2.98315
Value Function Loss: 0.00440

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.51135

Collected Steps per Second: 23,593.51435
Overall Steps per Second: 10,922.69815

Timestep Collection Time: 2.12050
Timestep Consumption Time: 2.45987
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.58037

Cumulative Model Updates: 175,472
Cumulative Timesteps: 1,463,407,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.73500
Policy Entropy: 2.99081
Value Function Loss: 0.00412

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.51894

Collected Steps per Second: 22,969.43197
Overall Steps per Second: 10,838.50867

Timestep Collection Time: 2.17811
Timestep Consumption Time: 2.43784
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61595

Cumulative Model Updates: 175,478
Cumulative Timesteps: 1,463,458,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1463458018...
Checkpoint 1463458018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.34827
Policy Entropy: 2.98945
Value Function Loss: 0.00417

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.57195
Value Function Update Magnitude: 0.47853

Collected Steps per Second: 22,825.64733
Overall Steps per Second: 10,710.35471

Timestep Collection Time: 2.19061
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.66857

Cumulative Model Updates: 175,484
Cumulative Timesteps: 1,463,508,020

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,715.16149
Policy Entropy: 2.99262
Value Function Loss: 0.00431

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11654
Policy Update Magnitude: 0.57800
Value Function Update Magnitude: 0.48097

Collected Steps per Second: 23,357.15215
Overall Steps per Second: 10,924.30854

Timestep Collection Time: 2.14153
Timestep Consumption Time: 2.43725
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.57878

Cumulative Model Updates: 175,490
Cumulative Timesteps: 1,463,558,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1463558040...
Checkpoint 1463558040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,776.40080
Policy Entropy: 2.99737
Value Function Loss: 0.00464

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.11928
Policy Update Magnitude: 0.57541
Value Function Update Magnitude: 0.51732

Collected Steps per Second: 23,088.74819
Overall Steps per Second: 10,936.11696

Timestep Collection Time: 2.16599
Timestep Consumption Time: 2.40693
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.57292

Cumulative Model Updates: 175,496
Cumulative Timesteps: 1,463,608,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,870.58451
Policy Entropy: 2.99455
Value Function Loss: 0.00427

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.53917

Collected Steps per Second: 22,619.90776
Overall Steps per Second: 10,562.41279

Timestep Collection Time: 2.21115
Timestep Consumption Time: 2.52413
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.73528

Cumulative Model Updates: 175,502
Cumulative Timesteps: 1,463,658,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1463658066...
Checkpoint 1463658066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,863.91902
Policy Entropy: 2.99336
Value Function Loss: 0.00441

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.57295
Value Function Update Magnitude: 0.52338

Collected Steps per Second: 22,812.14985
Overall Steps per Second: 10,628.36454

Timestep Collection Time: 2.19234
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.70552

Cumulative Model Updates: 175,508
Cumulative Timesteps: 1,463,708,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,516.65001
Policy Entropy: 2.97951
Value Function Loss: 0.00419

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11488
Policy Update Magnitude: 0.57353
Value Function Update Magnitude: 0.50412

Collected Steps per Second: 22,604.93025
Overall Steps per Second: 10,608.13166

Timestep Collection Time: 2.21208
Timestep Consumption Time: 2.50166
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.71374

Cumulative Model Updates: 175,514
Cumulative Timesteps: 1,463,758,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1463758082...
Checkpoint 1463758082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,341.82679
Policy Entropy: 2.98213
Value Function Loss: 0.00447

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.57892
Value Function Update Magnitude: 0.49616

Collected Steps per Second: 21,501.84926
Overall Steps per Second: 10,467.97952

Timestep Collection Time: 2.32547
Timestep Consumption Time: 2.45119
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.77666

Cumulative Model Updates: 175,520
Cumulative Timesteps: 1,463,808,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,926.44864
Policy Entropy: 2.97485
Value Function Loss: 0.00431

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.48356

Collected Steps per Second: 23,045.80611
Overall Steps per Second: 10,706.34264

Timestep Collection Time: 2.16985
Timestep Consumption Time: 2.50084
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.67069

Cumulative Model Updates: 175,526
Cumulative Timesteps: 1,463,858,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1463858090...
Checkpoint 1463858090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,088.35828
Policy Entropy: 2.97490
Value Function Loss: 0.00427

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.56589
Value Function Update Magnitude: 0.47227

Collected Steps per Second: 23,161.89241
Overall Steps per Second: 10,901.99240

Timestep Collection Time: 2.15915
Timestep Consumption Time: 2.42808
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.58723

Cumulative Model Updates: 175,532
Cumulative Timesteps: 1,463,908,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,254.45093
Policy Entropy: 2.97587
Value Function Loss: 0.00453

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.57941
Value Function Update Magnitude: 0.47720

Collected Steps per Second: 23,390.87749
Overall Steps per Second: 10,922.51748

Timestep Collection Time: 2.13818
Timestep Consumption Time: 2.44080
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.57898

Cumulative Model Updates: 175,538
Cumulative Timesteps: 1,463,958,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1463958114...
Checkpoint 1463958114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,381.93192
Policy Entropy: 2.97987
Value Function Loss: 0.00447

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.58442
Value Function Update Magnitude: 0.50012

Collected Steps per Second: 22,996.65595
Overall Steps per Second: 10,706.54280

Timestep Collection Time: 2.17553
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.67284

Cumulative Model Updates: 175,544
Cumulative Timesteps: 1,464,008,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,904.23017
Policy Entropy: 2.98247
Value Function Loss: 0.00480

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.59040
Value Function Update Magnitude: 0.52878

Collected Steps per Second: 23,040.72610
Overall Steps per Second: 10,798.73001

Timestep Collection Time: 2.17007
Timestep Consumption Time: 2.46010
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.63017

Cumulative Model Updates: 175,550
Cumulative Timesteps: 1,464,058,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1464058144...
Checkpoint 1464058144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.88120
Policy Entropy: 2.97818
Value Function Loss: 0.00439

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.58966
Value Function Update Magnitude: 0.55076

Collected Steps per Second: 22,780.73921
Overall Steps per Second: 10,695.85988

Timestep Collection Time: 2.19607
Timestep Consumption Time: 2.48126
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.67732

Cumulative Model Updates: 175,556
Cumulative Timesteps: 1,464,108,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,849.96780
Policy Entropy: 2.96959
Value Function Loss: 0.00459

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.59164
Value Function Update Magnitude: 0.57453

Collected Steps per Second: 22,826.37615
Overall Steps per Second: 10,832.22514

Timestep Collection Time: 2.19124
Timestep Consumption Time: 2.42628
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.61752

Cumulative Model Updates: 175,562
Cumulative Timesteps: 1,464,158,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1464158190...
Checkpoint 1464158190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928.23325
Policy Entropy: 2.95978
Value Function Loss: 0.00439

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.58975
Value Function Update Magnitude: 0.56850

Collected Steps per Second: 22,766.57281
Overall Steps per Second: 10,697.88950

Timestep Collection Time: 2.19708
Timestep Consumption Time: 2.47861
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.67569

Cumulative Model Updates: 175,568
Cumulative Timesteps: 1,464,208,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,047.66143
Policy Entropy: 2.97022
Value Function Loss: 0.00459

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.59179
Value Function Update Magnitude: 0.56391

Collected Steps per Second: 22,647.63247
Overall Steps per Second: 10,826.32023

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.41180
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.62059

Cumulative Model Updates: 175,574
Cumulative Timesteps: 1,464,258,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1464258234...
Checkpoint 1464258234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,309.85586
Policy Entropy: 2.97268
Value Function Loss: 0.00464

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.59150
Value Function Update Magnitude: 0.54809

Collected Steps per Second: 22,448.19401
Overall Steps per Second: 10,716.65166

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.43946
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.66788

Cumulative Model Updates: 175,580
Cumulative Timesteps: 1,464,308,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.78183
Policy Entropy: 2.96813
Value Function Loss: 0.00487

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.59469
Value Function Update Magnitude: 0.53683

Collected Steps per Second: 23,216.98901
Overall Steps per Second: 10,860.93276

Timestep Collection Time: 2.15385
Timestep Consumption Time: 2.45035
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60421

Cumulative Model Updates: 175,586
Cumulative Timesteps: 1,464,358,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1464358264...
Checkpoint 1464358264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.78926
Policy Entropy: 2.95627
Value Function Loss: 0.00506

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.59500
Value Function Update Magnitude: 0.54580

Collected Steps per Second: 22,845.81955
Overall Steps per Second: 10,673.53543

Timestep Collection Time: 2.18876
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.68486

Cumulative Model Updates: 175,592
Cumulative Timesteps: 1,464,408,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,019.77860
Policy Entropy: 2.95493
Value Function Loss: 0.00452

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.57942
Value Function Update Magnitude: 0.53240

Collected Steps per Second: 23,069.75955
Overall Steps per Second: 10,861.34251

Timestep Collection Time: 2.16803
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.60496

Cumulative Model Updates: 175,598
Cumulative Timesteps: 1,464,458,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1464458284...
Checkpoint 1464458284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.78652
Policy Entropy: 2.95961
Value Function Loss: 0.00516

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.60330
Value Function Update Magnitude: 0.53376

Collected Steps per Second: 22,999.87243
Overall Steps per Second: 10,655.02225

Timestep Collection Time: 2.17453
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.69394

Cumulative Model Updates: 175,604
Cumulative Timesteps: 1,464,508,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.05576
Policy Entropy: 2.95389
Value Function Loss: 0.00480

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.60138
Value Function Update Magnitude: 0.55580

Collected Steps per Second: 23,064.14378
Overall Steps per Second: 10,867.81969

Timestep Collection Time: 2.16925
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.60368

Cumulative Model Updates: 175,610
Cumulative Timesteps: 1,464,558,330

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1464558330...
Checkpoint 1464558330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974.50868
Policy Entropy: 2.95815
Value Function Loss: 0.00462

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.57714
Value Function Update Magnitude: 0.55019

Collected Steps per Second: 22,803.09617
Overall Steps per Second: 10,726.48547

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.47006
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.66397

Cumulative Model Updates: 175,616
Cumulative Timesteps: 1,464,608,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,775.62402
Policy Entropy: 2.95856
Value Function Loss: 0.00437

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.58519
Value Function Update Magnitude: 0.54207

Collected Steps per Second: 22,568.08022
Overall Steps per Second: 10,640.02825

Timestep Collection Time: 2.21623
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.70074

Cumulative Model Updates: 175,622
Cumulative Timesteps: 1,464,658,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1464658374...
Checkpoint 1464658374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,165.85083
Policy Entropy: 2.96686
Value Function Loss: 0.00449

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.59893
Value Function Update Magnitude: 0.54620

Collected Steps per Second: 22,703.41312
Overall Steps per Second: 10,730.45703

Timestep Collection Time: 2.20275
Timestep Consumption Time: 2.45781
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.66057

Cumulative Model Updates: 175,628
Cumulative Timesteps: 1,464,708,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.98478
Policy Entropy: 2.96496
Value Function Loss: 0.00445

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.59705
Value Function Update Magnitude: 0.54473

Collected Steps per Second: 23,040.23264
Overall Steps per Second: 10,725.92531

Timestep Collection Time: 2.17055
Timestep Consumption Time: 2.49198
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.66253

Cumulative Model Updates: 175,634
Cumulative Timesteps: 1,464,758,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1464758394...
Checkpoint 1464758394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,501.30235
Policy Entropy: 2.95907
Value Function Loss: 0.00476

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.59990
Value Function Update Magnitude: 0.53921

Collected Steps per Second: 22,652.54272
Overall Steps per Second: 10,710.75931

Timestep Collection Time: 2.20752
Timestep Consumption Time: 2.46124
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.66876

Cumulative Model Updates: 175,640
Cumulative Timesteps: 1,464,808,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.20502
Policy Entropy: 2.95661
Value Function Loss: 0.00499

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.60676
Value Function Update Magnitude: 0.55211

Collected Steps per Second: 23,349.55923
Overall Steps per Second: 10,696.38671

Timestep Collection Time: 2.14145
Timestep Consumption Time: 2.53321
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.67466

Cumulative Model Updates: 175,646
Cumulative Timesteps: 1,464,858,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1464858402...
Checkpoint 1464858402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.58262
Policy Entropy: 2.95247
Value Function Loss: 0.00509

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.60617
Value Function Update Magnitude: 0.56533

Collected Steps per Second: 23,089.36476
Overall Steps per Second: 10,711.37660

Timestep Collection Time: 2.16654
Timestep Consumption Time: 2.50364
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.67017

Cumulative Model Updates: 175,652
Cumulative Timesteps: 1,464,908,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,656.23846
Policy Entropy: 2.95586
Value Function Loss: 0.00479

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.60285
Value Function Update Magnitude: 0.56046

Collected Steps per Second: 23,395.65218
Overall Steps per Second: 10,836.83494

Timestep Collection Time: 2.13732
Timestep Consumption Time: 2.47694
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.61426

Cumulative Model Updates: 175,658
Cumulative Timesteps: 1,464,958,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1464958430...
Checkpoint 1464958430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.41755
Policy Entropy: 2.94824
Value Function Loss: 0.00476

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.59625
Value Function Update Magnitude: 0.53831

Collected Steps per Second: 23,170.03409
Overall Steps per Second: 10,820.96247

Timestep Collection Time: 2.15839
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.62159

Cumulative Model Updates: 175,664
Cumulative Timesteps: 1,465,008,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,193.25390
Policy Entropy: 2.94137
Value Function Loss: 0.00479

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.60064
Value Function Update Magnitude: 0.54076

Collected Steps per Second: 23,336.52937
Overall Steps per Second: 10,842.85652

Timestep Collection Time: 2.14359
Timestep Consumption Time: 2.46995
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.61354

Cumulative Model Updates: 175,670
Cumulative Timesteps: 1,465,058,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1465058464...
Checkpoint 1465058464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.48817
Policy Entropy: 2.91752
Value Function Loss: 0.00474

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.60886
Value Function Update Magnitude: 0.55844

Collected Steps per Second: 23,251.43164
Overall Steps per Second: 10,997.36604

Timestep Collection Time: 2.15135
Timestep Consumption Time: 2.39719
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.54854

Cumulative Model Updates: 175,676
Cumulative Timesteps: 1,465,108,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.10590
Policy Entropy: 2.92037
Value Function Loss: 0.00476

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.61492
Value Function Update Magnitude: 0.55337

Collected Steps per Second: 22,596.82365
Overall Steps per Second: 10,816.83944

Timestep Collection Time: 2.21305
Timestep Consumption Time: 2.41011
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62316

Cumulative Model Updates: 175,682
Cumulative Timesteps: 1,465,158,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1465158494...
Checkpoint 1465158494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,993.61352
Policy Entropy: 2.93140
Value Function Loss: 0.00500

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.61697
Value Function Update Magnitude: 0.56400

Collected Steps per Second: 22,363.40711
Overall Steps per Second: 10,730.44753

Timestep Collection Time: 2.23642
Timestep Consumption Time: 2.42452
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.66094

Cumulative Model Updates: 175,688
Cumulative Timesteps: 1,465,208,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.11672
Policy Entropy: 2.96235
Value Function Loss: 0.00489

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.60952
Value Function Update Magnitude: 0.58839

Collected Steps per Second: 22,704.58304
Overall Steps per Second: 10,787.48256

Timestep Collection Time: 2.20334
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.63741

Cumulative Model Updates: 175,694
Cumulative Timesteps: 1,465,258,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1465258534...
Checkpoint 1465258534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.79981
Policy Entropy: 2.96224
Value Function Loss: 0.00482

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.59762
Value Function Update Magnitude: 0.58382

Collected Steps per Second: 22,784.32900
Overall Steps per Second: 10,734.77056

Timestep Collection Time: 2.19528
Timestep Consumption Time: 2.46416
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.65944

Cumulative Model Updates: 175,700
Cumulative Timesteps: 1,465,308,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.08745
Policy Entropy: 2.96035
Value Function Loss: 0.00471

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.58980
Value Function Update Magnitude: 0.54897

Collected Steps per Second: 23,135.39670
Overall Steps per Second: 10,821.76103

Timestep Collection Time: 2.16188
Timestep Consumption Time: 2.45992
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.62180

Cumulative Model Updates: 175,706
Cumulative Timesteps: 1,465,358,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1465358568...
Checkpoint 1465358568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.23079
Policy Entropy: 2.94064
Value Function Loss: 0.00501

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.60248
Value Function Update Magnitude: 0.53672

Collected Steps per Second: 23,206.66109
Overall Steps per Second: 10,722.70615

Timestep Collection Time: 2.15507
Timestep Consumption Time: 2.50905
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.66412

Cumulative Model Updates: 175,712
Cumulative Timesteps: 1,465,408,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.35125
Policy Entropy: 2.93362
Value Function Loss: 0.00526

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.61333
Value Function Update Magnitude: 0.52751

Collected Steps per Second: 23,183.45286
Overall Steps per Second: 10,875.62163

Timestep Collection Time: 2.15852
Timestep Consumption Time: 2.44278
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.60130

Cumulative Model Updates: 175,718
Cumulative Timesteps: 1,465,458,622

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1465458622...
Checkpoint 1465458622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,742.55829
Policy Entropy: 2.93614
Value Function Loss: 0.00538

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.61343
Value Function Update Magnitude: 0.54253

Collected Steps per Second: 22,962.57536
Overall Steps per Second: 10,648.35425

Timestep Collection Time: 2.17789
Timestep Consumption Time: 2.51861
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.69650

Cumulative Model Updates: 175,724
Cumulative Timesteps: 1,465,508,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.29478
Policy Entropy: 2.92588
Value Function Loss: 0.00511

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.60341
Value Function Update Magnitude: 0.54539

Collected Steps per Second: 23,248.60292
Overall Steps per Second: 10,876.96646

Timestep Collection Time: 2.15110
Timestep Consumption Time: 2.44669
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.59779

Cumulative Model Updates: 175,730
Cumulative Timesteps: 1,465,558,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1465558642...
Checkpoint 1465558642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.84197
Policy Entropy: 2.92401
Value Function Loss: 0.00460

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.52776

Collected Steps per Second: 22,528.68571
Overall Steps per Second: 10,688.51856

Timestep Collection Time: 2.21966
Timestep Consumption Time: 2.45882
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.67848

Cumulative Model Updates: 175,736
Cumulative Timesteps: 1,465,608,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.11162
Policy Entropy: 2.91349
Value Function Loss: 0.00421

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12101
Policy Update Magnitude: 0.59636
Value Function Update Magnitude: 0.50853

Collected Steps per Second: 22,777.19235
Overall Steps per Second: 10,868.48350

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.40566
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.60119

Cumulative Model Updates: 175,742
Cumulative Timesteps: 1,465,658,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1465658656...
Checkpoint 1465658656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,135.31343
Policy Entropy: 2.90472
Value Function Loss: 0.00454

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.60050
Value Function Update Magnitude: 0.50201

Collected Steps per Second: 22,469.70793
Overall Steps per Second: 10,763.60442

Timestep Collection Time: 2.22557
Timestep Consumption Time: 2.42045
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.64603

Cumulative Model Updates: 175,748
Cumulative Timesteps: 1,465,708,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,317.50089
Policy Entropy: 2.90614
Value Function Loss: 0.00474

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.60959
Value Function Update Magnitude: 0.52739

Collected Steps per Second: 21,951.61287
Overall Steps per Second: 10,437.82009

Timestep Collection Time: 2.27810
Timestep Consumption Time: 2.51294
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.79104

Cumulative Model Updates: 175,754
Cumulative Timesteps: 1,465,758,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1465758672...
Checkpoint 1465758672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.15939
Policy Entropy: 2.90449
Value Function Loss: 0.00489

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.61699
Value Function Update Magnitude: 0.55291

Collected Steps per Second: 22,704.40500
Overall Steps per Second: 10,608.10469

Timestep Collection Time: 2.20318
Timestep Consumption Time: 2.51227
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.71545

Cumulative Model Updates: 175,760
Cumulative Timesteps: 1,465,808,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.21889
Policy Entropy: 2.90801
Value Function Loss: 0.00481

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.61990
Value Function Update Magnitude: 0.54771

Collected Steps per Second: 23,327.18646
Overall Steps per Second: 10,920.35388

Timestep Collection Time: 2.14342
Timestep Consumption Time: 2.43518
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.57861

Cumulative Model Updates: 175,766
Cumulative Timesteps: 1,465,858,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1465858694...
Checkpoint 1465858694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.60831
Policy Entropy: 2.90712
Value Function Loss: 0.00469

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.60710
Value Function Update Magnitude: 0.53836

Collected Steps per Second: 23,038.02896
Overall Steps per Second: 10,737.80980

Timestep Collection Time: 2.17128
Timestep Consumption Time: 2.48721
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.65849

Cumulative Model Updates: 175,772
Cumulative Timesteps: 1,465,908,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,260.39021
Policy Entropy: 2.89655
Value Function Loss: 0.00462

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.59531
Value Function Update Magnitude: 0.54190

Collected Steps per Second: 23,498.01997
Overall Steps per Second: 10,863.53054

Timestep Collection Time: 2.12809
Timestep Consumption Time: 2.47501
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.60311

Cumulative Model Updates: 175,778
Cumulative Timesteps: 1,465,958,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1465958722...
Checkpoint 1465958722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.16974
Policy Entropy: 2.91939
Value Function Loss: 0.00444

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.58830
Value Function Update Magnitude: 0.52875

Collected Steps per Second: 23,224.63247
Overall Steps per Second: 10,769.53709

Timestep Collection Time: 2.15401
Timestep Consumption Time: 2.49113
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.64514

Cumulative Model Updates: 175,784
Cumulative Timesteps: 1,466,008,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.14503
Policy Entropy: 2.91131
Value Function Loss: 0.00505

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.60038
Value Function Update Magnitude: 0.53198

Collected Steps per Second: 23,198.58075
Overall Steps per Second: 10,731.99314

Timestep Collection Time: 2.15556
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.65953

Cumulative Model Updates: 175,790
Cumulative Timesteps: 1,466,058,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1466058754...
Checkpoint 1466058754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,679.80495
Policy Entropy: 2.91227
Value Function Loss: 0.00479

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.60002
Value Function Update Magnitude: 0.55784

Collected Steps per Second: 23,268.13101
Overall Steps per Second: 10,981.55258

Timestep Collection Time: 2.14903
Timestep Consumption Time: 2.40442
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.55345

Cumulative Model Updates: 175,796
Cumulative Timesteps: 1,466,108,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,663.30368
Policy Entropy: 2.90127
Value Function Loss: 0.00477

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.60307
Value Function Update Magnitude: 0.55328

Collected Steps per Second: 22,990.06180
Overall Steps per Second: 10,723.17403

Timestep Collection Time: 2.17616
Timestep Consumption Time: 2.48944
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.66560

Cumulative Model Updates: 175,802
Cumulative Timesteps: 1,466,158,788

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1466158788...
Checkpoint 1466158788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.62060
Policy Entropy: 2.90546
Value Function Loss: 0.00502

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.61683
Value Function Update Magnitude: 0.54501

Collected Steps per Second: 22,738.44038
Overall Steps per Second: 10,855.22900

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.40783
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.60736

Cumulative Model Updates: 175,808
Cumulative Timesteps: 1,466,208,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,118.82435
Policy Entropy: 2.90190
Value Function Loss: 0.00502

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.60461
Value Function Update Magnitude: 0.53520

Collected Steps per Second: 22,770.45896
Overall Steps per Second: 10,872.12003

Timestep Collection Time: 2.19635
Timestep Consumption Time: 2.40367
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.60002

Cumulative Model Updates: 175,814
Cumulative Timesteps: 1,466,258,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1466258814...
Checkpoint 1466258814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,027.92578
Policy Entropy: 2.90379
Value Function Loss: 0.00516

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.59522
Value Function Update Magnitude: 0.51692

Collected Steps per Second: 22,567.35071
Overall Steps per Second: 10,745.12075

Timestep Collection Time: 2.21577
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.65365

Cumulative Model Updates: 175,820
Cumulative Timesteps: 1,466,308,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.70524
Policy Entropy: 2.90386
Value Function Loss: 0.00493

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11259
Policy Update Magnitude: 0.58824
Value Function Update Magnitude: 0.50506

Collected Steps per Second: 23,130.44110
Overall Steps per Second: 10,881.33154

Timestep Collection Time: 2.16356
Timestep Consumption Time: 2.43551
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.59907

Cumulative Model Updates: 175,826
Cumulative Timesteps: 1,466,358,862

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1466358862...
Checkpoint 1466358862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.45064
Policy Entropy: 2.91942
Value Function Loss: 0.00492

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.58536
Value Function Update Magnitude: 0.48499

Collected Steps per Second: 22,835.10375
Overall Steps per Second: 10,627.23489

Timestep Collection Time: 2.18987
Timestep Consumption Time: 2.51558
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.70546

Cumulative Model Updates: 175,832
Cumulative Timesteps: 1,466,408,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.23121
Policy Entropy: 2.92592
Value Function Loss: 0.00488

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.59606
Value Function Update Magnitude: 0.50142

Collected Steps per Second: 23,129.67584
Overall Steps per Second: 10,889.22575

Timestep Collection Time: 2.16302
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.59445

Cumulative Model Updates: 175,838
Cumulative Timesteps: 1,466,458,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1466458898...
Checkpoint 1466458898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274.10999
Policy Entropy: 2.92516
Value Function Loss: 0.00454

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.59853
Value Function Update Magnitude: 0.52112

Collected Steps per Second: 22,941.98368
Overall Steps per Second: 10,675.13505

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.68453

Cumulative Model Updates: 175,844
Cumulative Timesteps: 1,466,508,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.85897
Policy Entropy: 2.93293
Value Function Loss: 0.00464

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.60416
Value Function Update Magnitude: 0.51741

Collected Steps per Second: 23,155.90964
Overall Steps per Second: 10,871.94692

Timestep Collection Time: 2.15988
Timestep Consumption Time: 2.44040
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60028

Cumulative Model Updates: 175,850
Cumulative Timesteps: 1,466,558,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1466558920...
Checkpoint 1466558920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.22618
Policy Entropy: 2.92097
Value Function Loss: 0.00493

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.60643
Value Function Update Magnitude: 0.53385

Collected Steps per Second: 23,003.18560
Overall Steps per Second: 10,755.70887

Timestep Collection Time: 2.17422
Timestep Consumption Time: 2.47578
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.65000

Cumulative Model Updates: 175,856
Cumulative Timesteps: 1,466,608,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 972.84126
Policy Entropy: 2.92001
Value Function Loss: 0.00534

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11935
Policy Update Magnitude: 0.60817
Value Function Update Magnitude: 0.53543

Collected Steps per Second: 22,992.68944
Overall Steps per Second: 10,822.39631

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.44633
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.62171

Cumulative Model Updates: 175,862
Cumulative Timesteps: 1,466,658,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1466658952...
Checkpoint 1466658952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.45559
Policy Entropy: 2.90546
Value Function Loss: 0.00581

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.62006
Value Function Update Magnitude: 0.54444

Collected Steps per Second: 22,774.43402
Overall Steps per Second: 10,722.56400

Timestep Collection Time: 2.19623
Timestep Consumption Time: 2.46851
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.66474

Cumulative Model Updates: 175,868
Cumulative Timesteps: 1,466,708,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,345.89927
Policy Entropy: 2.90883
Value Function Loss: 0.00545

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.61839
Value Function Update Magnitude: 0.55656

Collected Steps per Second: 23,061.62589
Overall Steps per Second: 10,842.62940

Timestep Collection Time: 2.16862
Timestep Consumption Time: 2.44391
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61253

Cumulative Model Updates: 175,874
Cumulative Timesteps: 1,466,758,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1466758982...
Checkpoint 1466758982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.74411
Policy Entropy: 2.90605
Value Function Loss: 0.00509

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.60893
Value Function Update Magnitude: 0.55760

Collected Steps per Second: 22,599.75939
Overall Steps per Second: 10,630.77588

Timestep Collection Time: 2.21330
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.70521

Cumulative Model Updates: 175,880
Cumulative Timesteps: 1,466,809,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041.21857
Policy Entropy: 2.92851
Value Function Loss: 0.00473

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.60057
Value Function Update Magnitude: 0.53677

Collected Steps per Second: 23,279.00758
Overall Steps per Second: 10,884.86278

Timestep Collection Time: 2.14855
Timestep Consumption Time: 2.44646
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.59501

Cumulative Model Updates: 175,886
Cumulative Timesteps: 1,466,859,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1466859018...
Checkpoint 1466859018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.02277
Policy Entropy: 2.92025
Value Function Loss: 0.00481

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.59095
Value Function Update Magnitude: 0.50817

Collected Steps per Second: 23,042.60302
Overall Steps per Second: 10,776.71159

Timestep Collection Time: 2.17067
Timestep Consumption Time: 2.47063
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.64130

Cumulative Model Updates: 175,892
Cumulative Timesteps: 1,466,909,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.79766
Policy Entropy: 2.92394
Value Function Loss: 0.00510

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.60227
Value Function Update Magnitude: 0.50249

Collected Steps per Second: 23,383.26334
Overall Steps per Second: 10,780.60581

Timestep Collection Time: 2.13931
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.64018

Cumulative Model Updates: 175,898
Cumulative Timesteps: 1,466,959,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1466959060...
Checkpoint 1466959060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,731.50411
Policy Entropy: 2.91895
Value Function Loss: 0.00497

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.60730
Value Function Update Magnitude: 0.52166

Collected Steps per Second: 23,034.41176
Overall Steps per Second: 10,623.99990

Timestep Collection Time: 2.17075
Timestep Consumption Time: 2.53576
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.70651

Cumulative Model Updates: 175,904
Cumulative Timesteps: 1,467,009,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.38072
Policy Entropy: 2.95051
Value Function Loss: 0.00506

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.60232
Value Function Update Magnitude: 0.53277

Collected Steps per Second: 23,316.61698
Overall Steps per Second: 10,999.12437

Timestep Collection Time: 2.14517
Timestep Consumption Time: 2.40229
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.54745

Cumulative Model Updates: 175,910
Cumulative Timesteps: 1,467,059,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1467059080...
Checkpoint 1467059080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.02085
Policy Entropy: 2.95553
Value Function Loss: 0.00471

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.60082
Value Function Update Magnitude: 0.52119

Collected Steps per Second: 22,809.40089
Overall Steps per Second: 10,766.59370

Timestep Collection Time: 2.19322
Timestep Consumption Time: 2.45319
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.64641

Cumulative Model Updates: 175,916
Cumulative Timesteps: 1,467,109,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.18437
Policy Entropy: 2.94544
Value Function Loss: 0.00502

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.60232
Value Function Update Magnitude: 0.52101

Collected Steps per Second: 22,909.30077
Overall Steps per Second: 10,706.07720

Timestep Collection Time: 2.18365
Timestep Consumption Time: 2.48902
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.67267

Cumulative Model Updates: 175,922
Cumulative Timesteps: 1,467,159,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1467159132...
Checkpoint 1467159132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157.80727
Policy Entropy: 2.94751
Value Function Loss: 0.00454

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.59081
Value Function Update Magnitude: 0.53928

Collected Steps per Second: 22,491.63500
Overall Steps per Second: 10,655.26787

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.47035
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.69420

Cumulative Model Updates: 175,928
Cumulative Timesteps: 1,467,209,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,188.04703
Policy Entropy: 2.93480
Value Function Loss: 0.00485

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.59277
Value Function Update Magnitude: 0.54330

Collected Steps per Second: 22,667.48235
Overall Steps per Second: 10,644.93936

Timestep Collection Time: 2.20642
Timestep Consumption Time: 2.49196
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.69838

Cumulative Model Updates: 175,934
Cumulative Timesteps: 1,467,259,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1467259164...
Checkpoint 1467259164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.02955
Policy Entropy: 2.93500
Value Function Loss: 0.00476

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.59205
Value Function Update Magnitude: 0.52426

Collected Steps per Second: 22,767.61828
Overall Steps per Second: 10,808.01469

Timestep Collection Time: 2.19716
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.62842

Cumulative Model Updates: 175,940
Cumulative Timesteps: 1,467,309,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,344.90419
Policy Entropy: 2.92246
Value Function Loss: 0.00504

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.58545
Value Function Update Magnitude: 0.50028

Collected Steps per Second: 23,239.93291
Overall Steps per Second: 10,683.29897

Timestep Collection Time: 2.15190
Timestep Consumption Time: 2.52924
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.68114

Cumulative Model Updates: 175,946
Cumulative Timesteps: 1,467,359,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1467359198...
Checkpoint 1467359198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739.70815
Policy Entropy: 2.93411
Value Function Loss: 0.00487

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.58476
Value Function Update Magnitude: 0.49309

Collected Steps per Second: 23,158.77590
Overall Steps per Second: 10,863.76773

Timestep Collection Time: 2.15935
Timestep Consumption Time: 2.44384
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.60319

Cumulative Model Updates: 175,952
Cumulative Timesteps: 1,467,409,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,932.66754
Policy Entropy: 2.93478
Value Function Loss: 0.00501

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.59651
Value Function Update Magnitude: 0.50529

Collected Steps per Second: 23,344.69119
Overall Steps per Second: 10,905.17321

Timestep Collection Time: 2.14207
Timestep Consumption Time: 2.44346
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.58553

Cumulative Model Updates: 175,958
Cumulative Timesteps: 1,467,459,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1467459212...
Checkpoint 1467459212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639.36274
Policy Entropy: 2.92857
Value Function Loss: 0.00540

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.59861
Value Function Update Magnitude: 0.52287

Collected Steps per Second: 23,008.55481
Overall Steps per Second: 10,713.86191

Timestep Collection Time: 2.17432
Timestep Consumption Time: 2.49514
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.66946

Cumulative Model Updates: 175,964
Cumulative Timesteps: 1,467,509,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.57337
Policy Entropy: 2.91283
Value Function Loss: 0.00563

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.60839
Value Function Update Magnitude: 0.53490

Collected Steps per Second: 23,442.21421
Overall Steps per Second: 10,930.11541

Timestep Collection Time: 2.13384
Timestep Consumption Time: 2.44269
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.57653

Cumulative Model Updates: 175,970
Cumulative Timesteps: 1,467,559,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1467559262...
Checkpoint 1467559262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.70658
Policy Entropy: 2.88868
Value Function Loss: 0.00568

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.61984
Value Function Update Magnitude: 0.53979

Collected Steps per Second: 23,031.25111
Overall Steps per Second: 10,811.24442

Timestep Collection Time: 2.17218
Timestep Consumption Time: 2.45523
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.62740

Cumulative Model Updates: 175,976
Cumulative Timesteps: 1,467,609,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,711.43546
Policy Entropy: 2.88629
Value Function Loss: 0.00537

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.61989
Value Function Update Magnitude: 0.55650

Collected Steps per Second: 22,650.12845
Overall Steps per Second: 10,586.91059

Timestep Collection Time: 2.20749
Timestep Consumption Time: 2.51532
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.72281

Cumulative Model Updates: 175,982
Cumulative Timesteps: 1,467,659,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1467659290...
Checkpoint 1467659290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.85581
Policy Entropy: 2.89738
Value Function Loss: 0.00536

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.61874
Value Function Update Magnitude: 0.55579

Collected Steps per Second: 22,618.90389
Overall Steps per Second: 10,783.54638

Timestep Collection Time: 2.21151
Timestep Consumption Time: 2.42722
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.63873

Cumulative Model Updates: 175,988
Cumulative Timesteps: 1,467,709,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.32103
Policy Entropy: 2.91051
Value Function Loss: 0.00508

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.62028
Value Function Update Magnitude: 0.55196

Collected Steps per Second: 22,983.24379
Overall Steps per Second: 10,832.48400

Timestep Collection Time: 2.17611
Timestep Consumption Time: 2.44093
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.61704

Cumulative Model Updates: 175,994
Cumulative Timesteps: 1,467,759,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1467759326...
Checkpoint 1467759326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.54269
Policy Entropy: 2.92808
Value Function Loss: 0.00504

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.61408
Value Function Update Magnitude: 0.55636

Collected Steps per Second: 22,637.21879
Overall Steps per Second: 10,663.62447

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.48048
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.68959

Cumulative Model Updates: 176,000
Cumulative Timesteps: 1,467,809,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.21553
Policy Entropy: 2.92193
Value Function Loss: 0.00507

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.60467
Value Function Update Magnitude: 0.56018

Collected Steps per Second: 23,359.46323
Overall Steps per Second: 10,966.46692

Timestep Collection Time: 2.14166
Timestep Consumption Time: 2.42025
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.56191

Cumulative Model Updates: 176,006
Cumulative Timesteps: 1,467,859,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1467859362...
Checkpoint 1467859362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.93318
Policy Entropy: 2.92612
Value Function Loss: 0.00539

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.60400
Value Function Update Magnitude: 0.54972

Collected Steps per Second: 22,904.90084
Overall Steps per Second: 10,763.42343

Timestep Collection Time: 2.18372
Timestep Consumption Time: 2.46331
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.64703

Cumulative Model Updates: 176,012
Cumulative Timesteps: 1,467,909,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.95580
Policy Entropy: 2.93560
Value Function Loss: 0.00514

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.59405
Value Function Update Magnitude: 0.53507

Collected Steps per Second: 23,220.43948
Overall Steps per Second: 10,778.77094

Timestep Collection Time: 2.15396
Timestep Consumption Time: 2.48627
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.64023

Cumulative Model Updates: 176,018
Cumulative Timesteps: 1,467,959,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1467959396...
Checkpoint 1467959396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.92489
Policy Entropy: 2.95681
Value Function Loss: 0.00510

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.58911
Value Function Update Magnitude: 0.52492

Collected Steps per Second: 22,983.83247
Overall Steps per Second: 10,668.73025

Timestep Collection Time: 2.17623
Timestep Consumption Time: 2.51206
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.68828

Cumulative Model Updates: 176,024
Cumulative Timesteps: 1,468,009,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,225.96892
Policy Entropy: 2.94698
Value Function Loss: 0.00512

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.59990
Value Function Update Magnitude: 0.53709

Collected Steps per Second: 23,129.77409
Overall Steps per Second: 10,874.40755

Timestep Collection Time: 2.16249
Timestep Consumption Time: 2.43711
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.59961

Cumulative Model Updates: 176,030
Cumulative Timesteps: 1,468,059,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1468059432...
Checkpoint 1468059432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.89459
Policy Entropy: 2.93294
Value Function Loss: 0.00508

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.60107
Value Function Update Magnitude: 0.55871

Collected Steps per Second: 22,679.86566
Overall Steps per Second: 10,661.56399

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.48574
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.69087

Cumulative Model Updates: 176,036
Cumulative Timesteps: 1,468,109,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.86446
Policy Entropy: 2.92082
Value Function Loss: 0.00479

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.59320
Value Function Update Magnitude: 0.54158

Collected Steps per Second: 22,926.83913
Overall Steps per Second: 10,807.64189

Timestep Collection Time: 2.18181
Timestep Consumption Time: 2.44658
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62839

Cumulative Model Updates: 176,042
Cumulative Timesteps: 1,468,159,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1468159466...
Checkpoint 1468159466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.27211
Policy Entropy: 2.92015
Value Function Loss: 0.00492

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.60559
Value Function Update Magnitude: 0.53189

Collected Steps per Second: 22,371.06243
Overall Steps per Second: 10,694.31898

Timestep Collection Time: 2.23548
Timestep Consumption Time: 2.44084
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.67631

Cumulative Model Updates: 176,048
Cumulative Timesteps: 1,468,209,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.02895
Policy Entropy: 2.92972
Value Function Loss: 0.00486

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.60996
Value Function Update Magnitude: 0.55805

Collected Steps per Second: 23,181.21602
Overall Steps per Second: 10,698.96909

Timestep Collection Time: 2.15830
Timestep Consumption Time: 2.51804
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.67634

Cumulative Model Updates: 176,054
Cumulative Timesteps: 1,468,259,508

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1468259508...
Checkpoint 1468259508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.05580
Policy Entropy: 2.93683
Value Function Loss: 0.00497

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.60810
Value Function Update Magnitude: 0.55994

Collected Steps per Second: 23,350.27471
Overall Steps per Second: 10,884.50118

Timestep Collection Time: 2.14207
Timestep Consumption Time: 2.45327
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.59534

Cumulative Model Updates: 176,060
Cumulative Timesteps: 1,468,309,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.25021
Policy Entropy: 2.92663
Value Function Loss: 0.00508

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.61482
Value Function Update Magnitude: 0.55087

Collected Steps per Second: 23,313.55926
Overall Steps per Second: 10,916.97220

Timestep Collection Time: 2.14579
Timestep Consumption Time: 2.43662
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.58241

Cumulative Model Updates: 176,066
Cumulative Timesteps: 1,468,359,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1468359552...
Checkpoint 1468359552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,484.12425
Policy Entropy: 2.92138
Value Function Loss: 0.00509

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.14984
Policy Update Magnitude: 0.61583
Value Function Update Magnitude: 0.54332

Collected Steps per Second: 22,967.97068
Overall Steps per Second: 10,663.63914

Timestep Collection Time: 2.17738
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.68977

Cumulative Model Updates: 176,072
Cumulative Timesteps: 1,468,409,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.50000
Policy Entropy: 2.89531
Value Function Loss: 0.00513

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.16022
Policy Update Magnitude: 0.60461
Value Function Update Magnitude: 0.54898

Collected Steps per Second: 23,314.76064
Overall Steps per Second: 10,942.51076

Timestep Collection Time: 2.14534
Timestep Consumption Time: 2.42564
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.57098

Cumulative Model Updates: 176,078
Cumulative Timesteps: 1,468,459,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1468459580...
Checkpoint 1468459580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.25778
Policy Entropy: 2.90412
Value Function Loss: 0.00519

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.61161
Value Function Update Magnitude: 0.54242

Collected Steps per Second: 23,082.14309
Overall Steps per Second: 10,768.43429

Timestep Collection Time: 2.16696
Timestep Consumption Time: 2.47792
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.64487

Cumulative Model Updates: 176,084
Cumulative Timesteps: 1,468,509,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.54828
Policy Entropy: 2.90253
Value Function Loss: 0.00511

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.61618
Value Function Update Magnitude: 0.53335

Collected Steps per Second: 23,295.33928
Overall Steps per Second: 10,861.69458

Timestep Collection Time: 2.14670
Timestep Consumption Time: 2.45737
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.60407

Cumulative Model Updates: 176,090
Cumulative Timesteps: 1,468,559,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1468559606...
Checkpoint 1468559606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.64664
Policy Entropy: 2.90129
Value Function Loss: 0.00509

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.61587
Value Function Update Magnitude: 0.53398

Collected Steps per Second: 22,360.96454
Overall Steps per Second: 10,532.01232

Timestep Collection Time: 2.23711
Timestep Consumption Time: 2.51260
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.74971

Cumulative Model Updates: 176,096
Cumulative Timesteps: 1,468,609,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,504.20197
Policy Entropy: 2.89521
Value Function Loss: 0.00527

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.62071
Value Function Update Magnitude: 0.55179

Collected Steps per Second: 22,774.10970
Overall Steps per Second: 10,779.95810

Timestep Collection Time: 2.19591
Timestep Consumption Time: 2.44325
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.63916

Cumulative Model Updates: 176,102
Cumulative Timesteps: 1,468,659,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1468659640...
Checkpoint 1468659640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,108.02149
Policy Entropy: 2.88482
Value Function Loss: 0.00541

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.62573
Value Function Update Magnitude: 0.56807

Collected Steps per Second: 22,541.78051
Overall Steps per Second: 10,744.43806

Timestep Collection Time: 2.21810
Timestep Consumption Time: 2.43547
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.65357

Cumulative Model Updates: 176,108
Cumulative Timesteps: 1,468,709,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.03667
Policy Entropy: 2.91986
Value Function Loss: 0.00495

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.60952
Value Function Update Magnitude: 0.57141

Collected Steps per Second: 23,390.79569
Overall Steps per Second: 10,934.09966

Timestep Collection Time: 2.13870
Timestep Consumption Time: 2.43652
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.57523

Cumulative Model Updates: 176,114
Cumulative Timesteps: 1,468,759,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1468759666...
Checkpoint 1468759666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.44942
Policy Entropy: 2.91729
Value Function Loss: 0.00533

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.60379
Value Function Update Magnitude: 0.54594

Collected Steps per Second: 22,817.07723
Overall Steps per Second: 10,669.54909

Timestep Collection Time: 2.19160
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.68680

Cumulative Model Updates: 176,120
Cumulative Timesteps: 1,468,809,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.86076
Policy Entropy: 2.94339
Value Function Loss: 0.00484

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.59618
Value Function Update Magnitude: 0.54630

Collected Steps per Second: 23,297.94748
Overall Steps per Second: 10,845.81595

Timestep Collection Time: 2.14611
Timestep Consumption Time: 2.46396
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.61007

Cumulative Model Updates: 176,126
Cumulative Timesteps: 1,468,859,672

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1468859672...
Checkpoint 1468859672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.57103
Policy Entropy: 2.91141
Value Function Loss: 0.00536

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.60491
Value Function Update Magnitude: 0.60168

Collected Steps per Second: 23,010.26291
Overall Steps per Second: 10,689.25814

Timestep Collection Time: 2.17320
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.67815

Cumulative Model Updates: 176,132
Cumulative Timesteps: 1,468,909,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,103.99856
Policy Entropy: 2.92687
Value Function Loss: 0.00469

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.60190
Value Function Update Magnitude: 0.58819

Collected Steps per Second: 23,236.31706
Overall Steps per Second: 10,797.88323

Timestep Collection Time: 2.15180
Timestep Consumption Time: 2.47873
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.63054

Cumulative Model Updates: 176,138
Cumulative Timesteps: 1,468,959,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1468959678...
Checkpoint 1468959678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.00798
Policy Entropy: 2.92023
Value Function Loss: 0.00490

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.58737
Value Function Update Magnitude: 0.54469

Collected Steps per Second: 22,840.80412
Overall Steps per Second: 10,696.49889

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.48665
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.67686

Cumulative Model Updates: 176,144
Cumulative Timesteps: 1,469,009,704

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,873.24259
Policy Entropy: 2.94087
Value Function Loss: 0.00487

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.58438
Value Function Update Magnitude: 0.52980

Collected Steps per Second: 22,690.18981
Overall Steps per Second: 10,682.04473

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.47785
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.68206

Cumulative Model Updates: 176,150
Cumulative Timesteps: 1,469,059,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1469059718...
Checkpoint 1469059718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742.61930
Policy Entropy: 2.95237
Value Function Loss: 0.00492

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.58664
Value Function Update Magnitude: 0.52648

Collected Steps per Second: 22,540.10818
Overall Steps per Second: 10,780.32341

Timestep Collection Time: 2.21836
Timestep Consumption Time: 2.41991
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.63827

Cumulative Model Updates: 176,156
Cumulative Timesteps: 1,469,109,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,260.52046
Policy Entropy: 2.95793
Value Function Loss: 0.00507

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.60662
Value Function Update Magnitude: 0.55304

Collected Steps per Second: 22,823.34247
Overall Steps per Second: 10,704.87311

Timestep Collection Time: 2.19135
Timestep Consumption Time: 2.48072
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.67208

Cumulative Model Updates: 176,162
Cumulative Timesteps: 1,469,159,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1469159734...
Checkpoint 1469159734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.88826
Policy Entropy: 2.96598
Value Function Loss: 0.00480

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.59240
Value Function Update Magnitude: 0.57603

Collected Steps per Second: 22,863.55964
Overall Steps per Second: 10,855.52648

Timestep Collection Time: 2.18855
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60945

Cumulative Model Updates: 176,168
Cumulative Timesteps: 1,469,209,772

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.54489
Policy Entropy: 2.94709
Value Function Loss: 0.00521

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.11765
Policy Update Magnitude: 0.59974
Value Function Update Magnitude: 0.58299

Collected Steps per Second: 23,057.10792
Overall Steps per Second: 10,692.57008

Timestep Collection Time: 2.16940
Timestep Consumption Time: 2.50862
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.67801

Cumulative Model Updates: 176,174
Cumulative Timesteps: 1,469,259,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1469259792...
Checkpoint 1469259792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.28904
Policy Entropy: 2.94876
Value Function Loss: 0.00542

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.60856
Value Function Update Magnitude: 0.57459

Collected Steps per Second: 23,290.08615
Overall Steps per Second: 10,878.27325

Timestep Collection Time: 2.14812
Timestep Consumption Time: 2.45095
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.59908

Cumulative Model Updates: 176,180
Cumulative Timesteps: 1,469,309,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,950.94397
Policy Entropy: 2.94820
Value Function Loss: 0.00500

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.59722
Value Function Update Magnitude: 0.54199

Collected Steps per Second: 23,324.48051
Overall Steps per Second: 10,945.39569

Timestep Collection Time: 2.14410
Timestep Consumption Time: 2.42495
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.56904

Cumulative Model Updates: 176,186
Cumulative Timesteps: 1,469,359,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1469359832...
Checkpoint 1469359832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.68901
Policy Entropy: 2.95822
Value Function Loss: 0.00550

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.60254
Value Function Update Magnitude: 0.52448

Collected Steps per Second: 22,667.95269
Overall Steps per Second: 10,619.66192

Timestep Collection Time: 2.20690
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.71070

Cumulative Model Updates: 176,192
Cumulative Timesteps: 1,469,409,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.65141
Policy Entropy: 2.93650
Value Function Loss: 0.00519

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.60178
Value Function Update Magnitude: 0.53159

Collected Steps per Second: 23,264.28959
Overall Steps per Second: 10,907.41065

Timestep Collection Time: 2.15008
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.58587

Cumulative Model Updates: 176,198
Cumulative Timesteps: 1,469,459,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1469459878...
Checkpoint 1469459878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.15513
Policy Entropy: 2.91679
Value Function Loss: 0.00552

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.59800
Value Function Update Magnitude: 0.53662

Collected Steps per Second: 22,914.59077
Overall Steps per Second: 10,665.97909

Timestep Collection Time: 2.18219
Timestep Consumption Time: 2.50599
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.68818

Cumulative Model Updates: 176,204
Cumulative Timesteps: 1,469,509,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,202.77506
Policy Entropy: 2.92193
Value Function Loss: 0.00480

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.60182
Value Function Update Magnitude: 0.51549

Collected Steps per Second: 22,633.68825
Overall Steps per Second: 10,684.88092

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.47160
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.68176

Cumulative Model Updates: 176,210
Cumulative Timesteps: 1,469,559,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1469559906...
Checkpoint 1469559906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,574.13344
Policy Entropy: 2.94679
Value Function Loss: 0.00498

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.60218
Value Function Update Magnitude: 0.51697

Collected Steps per Second: 21,267.90521
Overall Steps per Second: 10,481.01617

Timestep Collection Time: 2.35228
Timestep Consumption Time: 2.42092
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.77320

Cumulative Model Updates: 176,216
Cumulative Timesteps: 1,469,609,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.66091
Policy Entropy: 2.97045
Value Function Loss: 0.00452

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.58851
Value Function Update Magnitude: 0.53344

Collected Steps per Second: 22,874.52402
Overall Steps per Second: 10,809.82130

Timestep Collection Time: 2.18654
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.62690

Cumulative Model Updates: 176,222
Cumulative Timesteps: 1,469,659,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1469659950...
Checkpoint 1469659950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.99475
Policy Entropy: 2.97196
Value Function Loss: 0.00465

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11826
Policy Update Magnitude: 0.57856
Value Function Update Magnitude: 0.53052

Collected Steps per Second: 22,958.08941
Overall Steps per Second: 10,666.95626

Timestep Collection Time: 2.17858
Timestep Consumption Time: 2.51029
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.68887

Cumulative Model Updates: 176,228
Cumulative Timesteps: 1,469,709,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,763.93099
Policy Entropy: 2.97859
Value Function Loss: 0.00415

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.51517

Collected Steps per Second: 23,408.17614
Overall Steps per Second: 10,934.52390

Timestep Collection Time: 2.13601
Timestep Consumption Time: 2.43667
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.57267

Cumulative Model Updates: 176,234
Cumulative Timesteps: 1,469,759,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1469759966...
Checkpoint 1469759966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.17300
Policy Entropy: 2.98258
Value Function Loss: 0.00433

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.50467

Collected Steps per Second: 21,887.13696
Overall Steps per Second: 10,613.65905

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.71091

Cumulative Model Updates: 176,240
Cumulative Timesteps: 1,469,809,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.98040
Policy Entropy: 2.97758
Value Function Loss: 0.00459

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.56542
Value Function Update Magnitude: 0.49483

Collected Steps per Second: 22,529.61022
Overall Steps per Second: 10,909.31616

Timestep Collection Time: 2.21930
Timestep Consumption Time: 2.36394
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.58324

Cumulative Model Updates: 176,246
Cumulative Timesteps: 1,469,859,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1469859966...
Checkpoint 1469859966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,412.31740
Policy Entropy: 2.96971
Value Function Loss: 0.00522

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.12600
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.50329

Collected Steps per Second: 22,078.51924
Overall Steps per Second: 10,631.47844

Timestep Collection Time: 2.26483
Timestep Consumption Time: 2.43857
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.70339

Cumulative Model Updates: 176,252
Cumulative Timesteps: 1,469,909,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,742.43942
Policy Entropy: 2.96266
Value Function Loss: 0.00504

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.51916

Collected Steps per Second: 22,713.72051
Overall Steps per Second: 10,937.62883

Timestep Collection Time: 2.20175
Timestep Consumption Time: 2.37054
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.57229

Cumulative Model Updates: 176,258
Cumulative Timesteps: 1,469,959,980

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1469959980...
Checkpoint 1469959980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,962.77497
Policy Entropy: 2.95547
Value Function Loss: 0.00508

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.57733
Value Function Update Magnitude: 0.52367

Collected Steps per Second: 21,972.10832
Overall Steps per Second: 10,629.25541

Timestep Collection Time: 2.27598
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70475

Cumulative Model Updates: 176,264
Cumulative Timesteps: 1,470,009,988

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,195.55190
Policy Entropy: 2.95259
Value Function Loss: 0.00524

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.59383
Value Function Update Magnitude: 0.53477

Collected Steps per Second: 22,143.66800
Overall Steps per Second: 10,823.33664

Timestep Collection Time: 2.25925
Timestep Consumption Time: 2.36299
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.62223

Cumulative Model Updates: 176,270
Cumulative Timesteps: 1,470,060,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1470060016...
Checkpoint 1470060016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.80163
Policy Entropy: 2.96098
Value Function Loss: 0.00528

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.60589
Value Function Update Magnitude: 0.56301

Collected Steps per Second: 21,630.42801
Overall Steps per Second: 10,678.47638

Timestep Collection Time: 2.31184
Timestep Consumption Time: 2.37104
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.68288

Cumulative Model Updates: 176,276
Cumulative Timesteps: 1,470,110,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.03660
Policy Entropy: 2.97276
Value Function Loss: 0.00511

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.60648
Value Function Update Magnitude: 0.58326

Collected Steps per Second: 22,240.60287
Overall Steps per Second: 10,848.28052

Timestep Collection Time: 2.24850
Timestep Consumption Time: 2.36126
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60976

Cumulative Model Updates: 176,282
Cumulative Timesteps: 1,470,160,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1470160030...
Checkpoint 1470160030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120.45603
Policy Entropy: 2.97102
Value Function Loss: 0.00480

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.59965
Value Function Update Magnitude: 0.58401

Collected Steps per Second: 21,865.75252
Overall Steps per Second: 10,749.59744

Timestep Collection Time: 2.28741
Timestep Consumption Time: 2.36541
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.65283

Cumulative Model Updates: 176,288
Cumulative Timesteps: 1,470,210,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,861.52836
Policy Entropy: 2.95442
Value Function Loss: 0.00477

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.58797
Value Function Update Magnitude: 0.57913

Collected Steps per Second: 22,493.80442
Overall Steps per Second: 10,883.57285

Timestep Collection Time: 2.22283
Timestep Consumption Time: 2.37125
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59408

Cumulative Model Updates: 176,294
Cumulative Timesteps: 1,470,260,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1470260046...
Checkpoint 1470260046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.46912
Policy Entropy: 2.95433
Value Function Loss: 0.00485

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10973
Policy Update Magnitude: 0.58483
Value Function Update Magnitude: 0.55945

Collected Steps per Second: 22,493.00906
Overall Steps per Second: 10,620.64794

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.48490
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.70781

Cumulative Model Updates: 176,300
Cumulative Timesteps: 1,470,310,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,372.89936
Policy Entropy: 2.95765
Value Function Loss: 0.00492

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11645
Policy Update Magnitude: 0.57871
Value Function Update Magnitude: 0.55292

Collected Steps per Second: 23,245.38215
Overall Steps per Second: 10,952.20989

Timestep Collection Time: 2.15174
Timestep Consumption Time: 2.41519
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.56693

Cumulative Model Updates: 176,306
Cumulative Timesteps: 1,470,360,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1470360064...
Checkpoint 1470360064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,307.79256
Policy Entropy: 2.97145
Value Function Loss: 0.00462

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.57452
Value Function Update Magnitude: 0.54006

Collected Steps per Second: 22,803.59196
Overall Steps per Second: 10,724.99330

Timestep Collection Time: 2.19386
Timestep Consumption Time: 2.47075
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.66462

Cumulative Model Updates: 176,312
Cumulative Timesteps: 1,470,410,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.36313
Policy Entropy: 2.96894
Value Function Loss: 0.00439

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.57188
Value Function Update Magnitude: 0.54031

Collected Steps per Second: 23,522.84676
Overall Steps per Second: 10,843.22222

Timestep Collection Time: 2.12678
Timestep Consumption Time: 2.48697
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.61376

Cumulative Model Updates: 176,318
Cumulative Timesteps: 1,470,460,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1470460120...
Checkpoint 1470460120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,226.26261
Policy Entropy: 2.96754
Value Function Loss: 0.00465

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.57827
Value Function Update Magnitude: 0.53355

Collected Steps per Second: 23,266.17328
Overall Steps per Second: 11,010.07366

Timestep Collection Time: 2.14973
Timestep Consumption Time: 2.39302
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.54275

Cumulative Model Updates: 176,324
Cumulative Timesteps: 1,470,510,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,444.26239
Policy Entropy: 2.93210
Value Function Loss: 0.00481

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.57284
Value Function Update Magnitude: 0.53492

Collected Steps per Second: 22,776.43453
Overall Steps per Second: 10,642.42270

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.50383
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.69987

Cumulative Model Updates: 176,330
Cumulative Timesteps: 1,470,560,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1470560154...
Checkpoint 1470560154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,087.59462
Policy Entropy: 2.91689
Value Function Loss: 0.00534

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.57944
Value Function Update Magnitude: 0.53317

Collected Steps per Second: 22,182.04396
Overall Steps per Second: 10,535.32255

Timestep Collection Time: 2.25534
Timestep Consumption Time: 2.49326
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.74860

Cumulative Model Updates: 176,336
Cumulative Timesteps: 1,470,610,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,947.39489
Policy Entropy: 2.92307
Value Function Loss: 0.00515

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12629
Policy Update Magnitude: 0.58432
Value Function Update Magnitude: 0.52985

Collected Steps per Second: 22,983.56454
Overall Steps per Second: 10,846.03639

Timestep Collection Time: 2.17547
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.60998

Cumulative Model Updates: 176,342
Cumulative Timesteps: 1,470,660,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1470660182...
Checkpoint 1470660182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.39073
Policy Entropy: 2.94307
Value Function Loss: 0.00503

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.57987
Value Function Update Magnitude: 0.53615

Collected Steps per Second: 22,540.69823
Overall Steps per Second: 10,689.26457

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.46007
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.67890

Cumulative Model Updates: 176,348
Cumulative Timesteps: 1,470,710,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,719.91385
Policy Entropy: 2.93981
Value Function Loss: 0.00516

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.58935
Value Function Update Magnitude: 0.54854

Collected Steps per Second: 23,277.17237
Overall Steps per Second: 10,818.43144

Timestep Collection Time: 2.14914
Timestep Consumption Time: 2.47500
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62415

Cumulative Model Updates: 176,354
Cumulative Timesteps: 1,470,760,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1470760222...
Checkpoint 1470760222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,457.76029
Policy Entropy: 2.94458
Value Function Loss: 0.00498

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.59273
Value Function Update Magnitude: 0.55864

Collected Steps per Second: 22,966.89584
Overall Steps per Second: 10,678.51990

Timestep Collection Time: 2.17748
Timestep Consumption Time: 2.50575
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68323

Cumulative Model Updates: 176,360
Cumulative Timesteps: 1,470,810,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.60367
Policy Entropy: 2.93423
Value Function Loss: 0.00502

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.58818
Value Function Update Magnitude: 0.53587

Collected Steps per Second: 23,213.84176
Overall Steps per Second: 10,871.23872

Timestep Collection Time: 2.15475
Timestep Consumption Time: 2.44638
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.60113

Cumulative Model Updates: 176,366
Cumulative Timesteps: 1,470,860,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1470860252...
Checkpoint 1470860252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,341.76760
Policy Entropy: 2.96333
Value Function Loss: 0.00485

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.58092
Value Function Update Magnitude: 0.52721

Collected Steps per Second: 23,024.63173
Overall Steps per Second: 10,730.71176

Timestep Collection Time: 2.17324
Timestep Consumption Time: 2.48983
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.66306

Cumulative Model Updates: 176,372
Cumulative Timesteps: 1,470,910,290

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532.06534
Policy Entropy: 2.96727
Value Function Loss: 0.00476

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.53588

Collected Steps per Second: 23,342.07175
Overall Steps per Second: 10,916.19714

Timestep Collection Time: 2.14223
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58072

Cumulative Model Updates: 176,378
Cumulative Timesteps: 1,470,960,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1470960294...
Checkpoint 1470960294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.53344
Policy Entropy: 2.97272
Value Function Loss: 0.00494

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.57648
Value Function Update Magnitude: 0.54007

Collected Steps per Second: 22,880.77940
Overall Steps per Second: 10,649.18389

Timestep Collection Time: 2.18664
Timestep Consumption Time: 2.51156
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.69820

Cumulative Model Updates: 176,384
Cumulative Timesteps: 1,471,010,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,754.67352
Policy Entropy: 2.96281
Value Function Loss: 0.00491

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.58761
Value Function Update Magnitude: 0.55357

Collected Steps per Second: 22,645.45914
Overall Steps per Second: 10,654.70870

Timestep Collection Time: 2.20910
Timestep Consumption Time: 2.48610
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.69520

Cumulative Model Updates: 176,390
Cumulative Timesteps: 1,471,060,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1471060352...
Checkpoint 1471060352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,336.76908
Policy Entropy: 2.96798
Value Function Loss: 0.00499

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.59451
Value Function Update Magnitude: 0.56172

Collected Steps per Second: 22,652.72728
Overall Steps per Second: 10,804.88418

Timestep Collection Time: 2.20848
Timestep Consumption Time: 2.42165
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.63013

Cumulative Model Updates: 176,396
Cumulative Timesteps: 1,471,110,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,704.18080
Policy Entropy: 2.96508
Value Function Loss: 0.00460

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.58456
Value Function Update Magnitude: 0.56687

Collected Steps per Second: 22,650.47716
Overall Steps per Second: 10,510.81913

Timestep Collection Time: 2.20825
Timestep Consumption Time: 2.55046
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.75872

Cumulative Model Updates: 176,402
Cumulative Timesteps: 1,471,160,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1471160398...
Checkpoint 1471160398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,653.47142
Policy Entropy: 2.94119
Value Function Loss: 0.00489

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.59230
Value Function Update Magnitude: 0.56241

Collected Steps per Second: 22,553.17182
Overall Steps per Second: 10,678.00371

Timestep Collection Time: 2.21769
Timestep Consumption Time: 2.46633
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.68402

Cumulative Model Updates: 176,408
Cumulative Timesteps: 1,471,210,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,212.39376
Policy Entropy: 2.91935
Value Function Loss: 0.00468

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.59872
Value Function Update Magnitude: 0.57589

Collected Steps per Second: 23,260.53666
Overall Steps per Second: 10,878.26672

Timestep Collection Time: 2.15042
Timestep Consumption Time: 2.44774
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59816

Cumulative Model Updates: 176,414
Cumulative Timesteps: 1,471,260,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1471260434...
Checkpoint 1471260434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,684.02723
Policy Entropy: 2.91410
Value Function Loss: 0.00498

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.59815
Value Function Update Magnitude: 0.58268

Collected Steps per Second: 22,933.27229
Overall Steps per Second: 10,660.86945

Timestep Collection Time: 2.18059
Timestep Consumption Time: 2.51021
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.69080

Cumulative Model Updates: 176,420
Cumulative Timesteps: 1,471,310,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.06384
Policy Entropy: 2.91663
Value Function Loss: 0.00476

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.60513
Value Function Update Magnitude: 0.55329

Collected Steps per Second: 23,189.54071
Overall Steps per Second: 10,873.48291

Timestep Collection Time: 2.15658
Timestep Consumption Time: 2.44269
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.59926

Cumulative Model Updates: 176,426
Cumulative Timesteps: 1,471,360,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1471360452...
Checkpoint 1471360452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.78926
Policy Entropy: 2.91379
Value Function Loss: 0.00519

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.59834
Value Function Update Magnitude: 0.55613

Collected Steps per Second: 23,119.99651
Overall Steps per Second: 10,790.83837

Timestep Collection Time: 2.16289
Timestep Consumption Time: 2.47123
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.63412

Cumulative Model Updates: 176,432
Cumulative Timesteps: 1,471,410,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.26535
Policy Entropy: 2.90340
Value Function Loss: 0.00525

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.60445
Value Function Update Magnitude: 0.57797

Collected Steps per Second: 23,406.47995
Overall Steps per Second: 10,831.07228

Timestep Collection Time: 2.13710
Timestep Consumption Time: 2.48128
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.61838

Cumulative Model Updates: 176,438
Cumulative Timesteps: 1,471,460,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1471460480...
Checkpoint 1471460480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.60081
Policy Entropy: 2.90507
Value Function Loss: 0.00522

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.59990
Value Function Update Magnitude: 0.57624

Collected Steps per Second: 22,883.60293
Overall Steps per Second: 10,601.60843

Timestep Collection Time: 2.18619
Timestep Consumption Time: 2.53271
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.71891

Cumulative Model Updates: 176,444
Cumulative Timesteps: 1,471,510,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.14503
Policy Entropy: 2.91973
Value Function Loss: 0.00463

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.59992
Value Function Update Magnitude: 0.58058

Collected Steps per Second: 22,764.57595
Overall Steps per Second: 10,633.01973

Timestep Collection Time: 2.19692
Timestep Consumption Time: 2.50654
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.70346

Cumulative Model Updates: 176,450
Cumulative Timesteps: 1,471,560,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1471560520...
Checkpoint 1471560520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,667.02820
Policy Entropy: 2.92855
Value Function Loss: 0.00494

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.60571
Value Function Update Magnitude: 0.57236

Collected Steps per Second: 22,696.42743
Overall Steps per Second: 10,845.60830

Timestep Collection Time: 2.20352
Timestep Consumption Time: 2.40775
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.61127

Cumulative Model Updates: 176,456
Cumulative Timesteps: 1,471,610,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,324.52444
Policy Entropy: 2.93746
Value Function Loss: 0.00464

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.60262
Value Function Update Magnitude: 0.57475

Collected Steps per Second: 22,850.02808
Overall Steps per Second: 10,644.35831

Timestep Collection Time: 2.18844
Timestep Consumption Time: 2.50944
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.69789

Cumulative Model Updates: 176,462
Cumulative Timesteps: 1,471,660,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1471660538...
Checkpoint 1471660538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.39748
Policy Entropy: 2.94354
Value Function Loss: 0.00479

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.59070
Value Function Update Magnitude: 0.56982

Collected Steps per Second: 22,543.13280
Overall Steps per Second: 10,585.23953

Timestep Collection Time: 2.21824
Timestep Consumption Time: 2.50589
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.72413

Cumulative Model Updates: 176,468
Cumulative Timesteps: 1,471,710,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,758.85898
Policy Entropy: 2.95286
Value Function Loss: 0.00468

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.58975
Value Function Update Magnitude: 0.55225

Collected Steps per Second: 23,111.77671
Overall Steps per Second: 10,786.53775

Timestep Collection Time: 2.16452
Timestep Consumption Time: 2.47329
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.63782

Cumulative Model Updates: 176,474
Cumulative Timesteps: 1,471,760,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1471760570...
Checkpoint 1471760570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.90902
Policy Entropy: 2.96181
Value Function Loss: 0.00459

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.57982
Value Function Update Magnitude: 0.54286

Collected Steps per Second: 23,020.49899
Overall Steps per Second: 10,676.05737

Timestep Collection Time: 2.17259
Timestep Consumption Time: 2.51210
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.68469

Cumulative Model Updates: 176,480
Cumulative Timesteps: 1,471,810,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,067.69128
Policy Entropy: 2.95631
Value Function Loss: 0.00454

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.57252
Value Function Update Magnitude: 0.53201

Collected Steps per Second: 23,076.85352
Overall Steps per Second: 10,872.12894

Timestep Collection Time: 2.16745
Timestep Consumption Time: 2.43312
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60057

Cumulative Model Updates: 176,486
Cumulative Timesteps: 1,471,860,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1471860602...
Checkpoint 1471860602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,666.11631
Policy Entropy: 2.94888
Value Function Loss: 0.00454

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.51828

Collected Steps per Second: 23,000.45445
Overall Steps per Second: 10,736.39025

Timestep Collection Time: 2.17404
Timestep Consumption Time: 2.48339
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.65743

Cumulative Model Updates: 176,492
Cumulative Timesteps: 1,471,910,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080.36508
Policy Entropy: 2.92592
Value Function Loss: 0.00475

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.57107
Value Function Update Magnitude: 0.51667

Collected Steps per Second: 22,766.18835
Overall Steps per Second: 10,832.51981

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.42104
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.61869

Cumulative Model Updates: 176,498
Cumulative Timesteps: 1,471,960,638

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1471960638...
Checkpoint 1471960638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.88505
Policy Entropy: 2.91667
Value Function Loss: 0.00523

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11024
Policy Update Magnitude: 0.58080
Value Function Update Magnitude: 0.52750

Collected Steps per Second: 22,940.12810
Overall Steps per Second: 10,678.70847

Timestep Collection Time: 2.18002
Timestep Consumption Time: 2.50313
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.68315

Cumulative Model Updates: 176,504
Cumulative Timesteps: 1,472,010,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.78392
Policy Entropy: 2.92832
Value Function Loss: 0.00516

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.58651
Value Function Update Magnitude: 0.53566

Collected Steps per Second: 22,669.53002
Overall Steps per Second: 10,840.39505

Timestep Collection Time: 2.20622
Timestep Consumption Time: 2.40745
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.61367

Cumulative Model Updates: 176,510
Cumulative Timesteps: 1,472,060,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1472060662...
Checkpoint 1472060662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.41611
Policy Entropy: 2.94038
Value Function Loss: 0.00487

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.58666
Value Function Update Magnitude: 0.53071

Collected Steps per Second: 22,638.66123
Overall Steps per Second: 10,744.54840

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.44609
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.65576

Cumulative Model Updates: 176,516
Cumulative Timesteps: 1,472,110,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.12680
Policy Entropy: 2.93620
Value Function Loss: 0.00477

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.59273
Value Function Update Magnitude: 0.52331

Collected Steps per Second: 22,764.54242
Overall Steps per Second: 10,776.05320

Timestep Collection Time: 2.19640
Timestep Consumption Time: 2.44352
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.63992

Cumulative Model Updates: 176,522
Cumulative Timesteps: 1,472,160,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1472160686...
Checkpoint 1472160686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,371.86331
Policy Entropy: 2.93023
Value Function Loss: 0.00516

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.60111
Value Function Update Magnitude: 0.54155

Collected Steps per Second: 23,000.27131
Overall Steps per Second: 10,722.20542

Timestep Collection Time: 2.17467
Timestep Consumption Time: 2.49023
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.66490

Cumulative Model Updates: 176,528
Cumulative Timesteps: 1,472,210,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.82332
Policy Entropy: 2.92378
Value Function Loss: 0.00528

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.60069
Value Function Update Magnitude: 0.56595

Collected Steps per Second: 23,451.86767
Overall Steps per Second: 10,919.02436

Timestep Collection Time: 2.13228
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.57971

Cumulative Model Updates: 176,534
Cumulative Timesteps: 1,472,260,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1472260710...
Checkpoint 1472260710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,773.81273
Policy Entropy: 2.94415
Value Function Loss: 0.00473

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.58665
Value Function Update Magnitude: 0.55527

Collected Steps per Second: 23,090.89752
Overall Steps per Second: 10,718.69125

Timestep Collection Time: 2.16709
Timestep Consumption Time: 2.50139
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.66848

Cumulative Model Updates: 176,540
Cumulative Timesteps: 1,472,310,750

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,143.81408
Policy Entropy: 2.93720
Value Function Loss: 0.00431

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.57250
Value Function Update Magnitude: 0.51579

Collected Steps per Second: 23,245.97860
Overall Steps per Second: 10,851.00664

Timestep Collection Time: 2.15194
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.61008

Cumulative Model Updates: 176,546
Cumulative Timesteps: 1,472,360,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1472360774...
Checkpoint 1472360774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.67481
Policy Entropy: 2.93711
Value Function Loss: 0.00430

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.56881
Value Function Update Magnitude: 0.51152

Collected Steps per Second: 22,986.06341
Overall Steps per Second: 10,689.33307

Timestep Collection Time: 2.17523
Timestep Consumption Time: 2.50233
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.67756

Cumulative Model Updates: 176,552
Cumulative Timesteps: 1,472,410,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.52084
Policy Entropy: 2.92237
Value Function Loss: 0.00474

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.53451

Collected Steps per Second: 23,491.87010
Overall Steps per Second: 10,844.95730

Timestep Collection Time: 2.12840
Timestep Consumption Time: 2.48204
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.61044

Cumulative Model Updates: 176,558
Cumulative Timesteps: 1,472,460,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1472460774...
Checkpoint 1472460774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.21185
Policy Entropy: 2.91900
Value Function Loss: 0.00469

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.54526

Collected Steps per Second: 22,392.14398
Overall Steps per Second: 10,653.60912

Timestep Collection Time: 2.23409
Timestep Consumption Time: 2.46160
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.69569

Cumulative Model Updates: 176,564
Cumulative Timesteps: 1,472,510,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,680.62710
Policy Entropy: 2.91291
Value Function Loss: 0.00487

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.58722
Value Function Update Magnitude: 0.55075

Collected Steps per Second: 22,911.08016
Overall Steps per Second: 10,888.37263

Timestep Collection Time: 2.18357
Timestep Consumption Time: 2.41105
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.59463

Cumulative Model Updates: 176,570
Cumulative Timesteps: 1,472,560,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1472560828...
Checkpoint 1472560828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,035.04272
Policy Entropy: 2.93385
Value Function Loss: 0.00460

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.58129
Value Function Update Magnitude: 0.56978

Collected Steps per Second: 22,589.00025
Overall Steps per Second: 10,653.41272

Timestep Collection Time: 2.21391
Timestep Consumption Time: 2.48036
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.69427

Cumulative Model Updates: 176,576
Cumulative Timesteps: 1,472,610,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.40223
Policy Entropy: 2.94553
Value Function Loss: 0.00476

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.57683
Value Function Update Magnitude: 0.57639

Collected Steps per Second: 22,840.27056
Overall Steps per Second: 10,619.80321

Timestep Collection Time: 2.19017
Timestep Consumption Time: 2.52028
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.71045

Cumulative Model Updates: 176,582
Cumulative Timesteps: 1,472,660,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1472660862...
Checkpoint 1472660862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,652.65657
Policy Entropy: 2.96159
Value Function Loss: 0.00466

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.57292
Value Function Update Magnitude: 0.56006

Collected Steps per Second: 23,222.00625
Overall Steps per Second: 10,871.40862

Timestep Collection Time: 2.15425
Timestep Consumption Time: 2.44736
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.60161

Cumulative Model Updates: 176,588
Cumulative Timesteps: 1,472,710,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.96809
Policy Entropy: 2.96298
Value Function Loss: 0.00483

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.57241
Value Function Update Magnitude: 0.55127

Collected Steps per Second: 23,214.70839
Overall Steps per Second: 10,938.39773

Timestep Collection Time: 2.15424
Timestep Consumption Time: 2.41773
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.57197

Cumulative Model Updates: 176,594
Cumulative Timesteps: 1,472,760,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1472760898...
Checkpoint 1472760898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,745.19815
Policy Entropy: 2.96830
Value Function Loss: 0.00474

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.55724

Collected Steps per Second: 23,006.48419
Overall Steps per Second: 10,657.46997

Timestep Collection Time: 2.17400
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.69305

Cumulative Model Updates: 176,600
Cumulative Timesteps: 1,472,810,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,054.73362
Policy Entropy: 2.96341
Value Function Loss: 0.00456

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.58391
Value Function Update Magnitude: 0.56435

Collected Steps per Second: 22,969.74779
Overall Steps per Second: 10,718.91657

Timestep Collection Time: 2.17704
Timestep Consumption Time: 2.48817
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.66521

Cumulative Model Updates: 176,606
Cumulative Timesteps: 1,472,860,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1472860920...
Checkpoint 1472860920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,891.99329
Policy Entropy: 2.95439
Value Function Loss: 0.00471

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.58581
Value Function Update Magnitude: 0.56181

Collected Steps per Second: 23,234.72286
Overall Steps per Second: 10,889.51360

Timestep Collection Time: 2.15290
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.59359

Cumulative Model Updates: 176,612
Cumulative Timesteps: 1,472,910,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.52058
Policy Entropy: 2.93554
Value Function Loss: 0.00490

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.58922
Value Function Update Magnitude: 0.55227

Collected Steps per Second: 23,062.15548
Overall Steps per Second: 10,890.57450

Timestep Collection Time: 2.16935
Timestep Consumption Time: 2.42453
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.59388

Cumulative Model Updates: 176,618
Cumulative Timesteps: 1,472,960,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1472960972...
Checkpoint 1472960972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,162.51996
Policy Entropy: 2.93806
Value Function Loss: 0.00542

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.59910
Value Function Update Magnitude: 0.56053

Collected Steps per Second: 22,510.33977
Overall Steps per Second: 10,637.62969

Timestep Collection Time: 2.22253
Timestep Consumption Time: 2.48058
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.70312

Cumulative Model Updates: 176,624
Cumulative Timesteps: 1,473,011,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,064.24597
Policy Entropy: 2.94029
Value Function Loss: 0.00522

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.58732
Value Function Update Magnitude: 0.53387

Collected Steps per Second: 22,764.33415
Overall Steps per Second: 10,694.40896

Timestep Collection Time: 2.19844
Timestep Consumption Time: 2.48120
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.67964

Cumulative Model Updates: 176,630
Cumulative Timesteps: 1,473,061,048

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1473061048...
Checkpoint 1473061048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.29004
Policy Entropy: 2.95817
Value Function Loss: 0.00496

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.50075

Collected Steps per Second: 23,274.08275
Overall Steps per Second: 10,849.15127

Timestep Collection Time: 2.14917
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.61050

Cumulative Model Updates: 176,636
Cumulative Timesteps: 1,473,111,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,967.14323
Policy Entropy: 2.95578
Value Function Loss: 0.00540

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.58999
Value Function Update Magnitude: 0.50795

Collected Steps per Second: 23,002.03977
Overall Steps per Second: 10,787.43255

Timestep Collection Time: 2.17485
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.63743

Cumulative Model Updates: 176,642
Cumulative Timesteps: 1,473,161,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1473161094...
Checkpoint 1473161094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,434.94787
Policy Entropy: 2.95822
Value Function Loss: 0.00533

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.59165
Value Function Update Magnitude: 0.52965

Collected Steps per Second: 23,006.11945
Overall Steps per Second: 10,788.33029

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.46189
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.63575

Cumulative Model Updates: 176,648
Cumulative Timesteps: 1,473,211,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,232.89339
Policy Entropy: 2.93522
Value Function Loss: 0.00569

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.59765
Value Function Update Magnitude: 0.53543

Collected Steps per Second: 22,906.85824
Overall Steps per Second: 10,818.87352

Timestep Collection Time: 2.18354
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.62322

Cumulative Model Updates: 176,654
Cumulative Timesteps: 1,473,261,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1473261124...
Checkpoint 1473261124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,727.12903
Policy Entropy: 2.92168
Value Function Loss: 0.00517

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.60636
Value Function Update Magnitude: 0.54209

Collected Steps per Second: 22,846.15323
Overall Steps per Second: 10,751.05440

Timestep Collection Time: 2.18908
Timestep Consumption Time: 2.46275
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.65182

Cumulative Model Updates: 176,660
Cumulative Timesteps: 1,473,311,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,197.14314
Policy Entropy: 2.91491
Value Function Loss: 0.00506

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.59991
Value Function Update Magnitude: 0.54636

Collected Steps per Second: 23,003.63057
Overall Steps per Second: 10,832.20332

Timestep Collection Time: 2.17409
Timestep Consumption Time: 2.44288
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.61697

Cumulative Model Updates: 176,666
Cumulative Timesteps: 1,473,361,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1473361148...
Checkpoint 1473361148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.08220
Policy Entropy: 2.92761
Value Function Loss: 0.00488

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.59045
Value Function Update Magnitude: 0.55887

Collected Steps per Second: 22,561.70417
Overall Steps per Second: 10,694.17588

Timestep Collection Time: 2.21721
Timestep Consumption Time: 2.46048
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.67769

Cumulative Model Updates: 176,672
Cumulative Timesteps: 1,473,411,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.22124
Policy Entropy: 2.95999
Value Function Loss: 0.00468

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.57764
Value Function Update Magnitude: 0.55641

Collected Steps per Second: 21,623.33057
Overall Steps per Second: 10,467.43557

Timestep Collection Time: 2.31278
Timestep Consumption Time: 2.46489
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.77767

Cumulative Model Updates: 176,678
Cumulative Timesteps: 1,473,461,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1473461182...
Checkpoint 1473461182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,443.96499
Policy Entropy: 2.96587
Value Function Loss: 0.00474

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10665
Policy Update Magnitude: 0.56961
Value Function Update Magnitude: 0.56247

Collected Steps per Second: 22,829.44160
Overall Steps per Second: 10,768.33866

Timestep Collection Time: 2.19138
Timestep Consumption Time: 2.45446
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.64584

Cumulative Model Updates: 176,684
Cumulative Timesteps: 1,473,511,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.15597
Policy Entropy: 2.96923
Value Function Loss: 0.00447

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.57081
Value Function Update Magnitude: 0.56170

Collected Steps per Second: 22,710.49226
Overall Steps per Second: 10,789.38641

Timestep Collection Time: 2.20251
Timestep Consumption Time: 2.43353
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.63604

Cumulative Model Updates: 176,690
Cumulative Timesteps: 1,473,561,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1473561230...
Checkpoint 1473561230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,343.83131
Policy Entropy: 2.94438
Value Function Loss: 0.00454

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.58232
Value Function Update Magnitude: 0.56540

Collected Steps per Second: 23,107.91685
Overall Steps per Second: 10,592.45020

Timestep Collection Time: 2.16393
Timestep Consumption Time: 2.55679
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.72072

Cumulative Model Updates: 176,696
Cumulative Timesteps: 1,473,611,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.31059
Policy Entropy: 2.93696
Value Function Loss: 0.00456

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.55197

Collected Steps per Second: 23,223.57806
Overall Steps per Second: 10,881.85044

Timestep Collection Time: 2.15367
Timestep Consumption Time: 2.44260
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.59628

Cumulative Model Updates: 176,702
Cumulative Timesteps: 1,473,661,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1473661250...
Checkpoint 1473661250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,253.25996
Policy Entropy: 2.94805
Value Function Loss: 0.00458

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.57090
Value Function Update Magnitude: 0.54224

Collected Steps per Second: 23,249.34873
Overall Steps per Second: 10,766.63654

Timestep Collection Time: 2.15068
Timestep Consumption Time: 2.49348
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.64416

Cumulative Model Updates: 176,708
Cumulative Timesteps: 1,473,711,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,113.75034
Policy Entropy: 2.94348
Value Function Loss: 0.00515

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.58598
Value Function Update Magnitude: 0.56504

Collected Steps per Second: 23,186.48958
Overall Steps per Second: 10,828.57905

Timestep Collection Time: 2.15643
Timestep Consumption Time: 2.46098
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.61741

Cumulative Model Updates: 176,714
Cumulative Timesteps: 1,473,761,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1473761252...
Checkpoint 1473761252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.79889
Policy Entropy: 2.94963
Value Function Loss: 0.00531

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.60990
Value Function Update Magnitude: 0.60835

Collected Steps per Second: 23,069.29982
Overall Steps per Second: 10,720.25781

Timestep Collection Time: 2.16816
Timestep Consumption Time: 2.49758
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.66575

Cumulative Model Updates: 176,720
Cumulative Timesteps: 1,473,811,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.83989
Policy Entropy: 2.94374
Value Function Loss: 0.00550

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.60725
Value Function Update Magnitude: 0.63739

Collected Steps per Second: 23,009.40880
Overall Steps per Second: 10,836.07201

Timestep Collection Time: 2.17424
Timestep Consumption Time: 2.44256
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.61680

Cumulative Model Updates: 176,726
Cumulative Timesteps: 1,473,861,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1473861298...
Checkpoint 1473861298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.73674
Policy Entropy: 2.95360
Value Function Loss: 0.00508

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.59913
Value Function Update Magnitude: 0.61684

Collected Steps per Second: 22,824.50331
Overall Steps per Second: 10,742.63598

Timestep Collection Time: 2.19177
Timestep Consumption Time: 2.46500
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.65677

Cumulative Model Updates: 176,732
Cumulative Timesteps: 1,473,911,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.45100
Policy Entropy: 2.95073
Value Function Loss: 0.00489

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.59416
Value Function Update Magnitude: 0.57142

Collected Steps per Second: 22,827.86745
Overall Steps per Second: 10,814.44561

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.43441
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.62585

Cumulative Model Updates: 176,738
Cumulative Timesteps: 1,473,961,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1473961350...
Checkpoint 1473961350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.13970
Policy Entropy: 2.95919
Value Function Loss: 0.00468

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.57968
Value Function Update Magnitude: 0.54865

Collected Steps per Second: 22,808.29217
Overall Steps per Second: 10,636.87966

Timestep Collection Time: 2.19341
Timestep Consumption Time: 2.50985
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.70326

Cumulative Model Updates: 176,744
Cumulative Timesteps: 1,474,011,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.71077
Policy Entropy: 2.95951
Value Function Loss: 0.00469

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.57771
Value Function Update Magnitude: 0.53119

Collected Steps per Second: 22,848.17107
Overall Steps per Second: 10,886.00503

Timestep Collection Time: 2.18845
Timestep Consumption Time: 2.40479
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.59324

Cumulative Model Updates: 176,750
Cumulative Timesteps: 1,474,061,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1474061380...
Checkpoint 1474061380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,462.30397
Policy Entropy: 2.96284
Value Function Loss: 0.00425

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.56803
Value Function Update Magnitude: 0.53751

Collected Steps per Second: 22,458.23830
Overall Steps per Second: 10,642.48102

Timestep Collection Time: 2.22733
Timestep Consumption Time: 2.47289
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.70022

Cumulative Model Updates: 176,756
Cumulative Timesteps: 1,474,111,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029.98623
Policy Entropy: 2.94567
Value Function Loss: 0.00435

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.57011
Value Function Update Magnitude: 0.53897

Collected Steps per Second: 22,983.32050
Overall Steps per Second: 10,667.77134

Timestep Collection Time: 2.17549
Timestep Consumption Time: 2.51152
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.68701

Cumulative Model Updates: 176,762
Cumulative Timesteps: 1,474,161,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1474161402...
Checkpoint 1474161402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,680.75027
Policy Entropy: 2.97182
Value Function Loss: 0.00402

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.56386
Value Function Update Magnitude: 0.54050

Collected Steps per Second: 22,964.49147
Overall Steps per Second: 10,788.60737

Timestep Collection Time: 2.17754
Timestep Consumption Time: 2.45754
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.63507

Cumulative Model Updates: 176,768
Cumulative Timesteps: 1,474,211,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,660.45064
Policy Entropy: 2.96818
Value Function Loss: 0.00447

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.56633
Value Function Update Magnitude: 0.55140

Collected Steps per Second: 23,309.02040
Overall Steps per Second: 10,786.63436

Timestep Collection Time: 2.14526
Timestep Consumption Time: 2.49047
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.63574

Cumulative Model Updates: 176,774
Cumulative Timesteps: 1,474,261,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1474261412...
Checkpoint 1474261412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,802.97880
Policy Entropy: 2.97769
Value Function Loss: 0.00460

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.57304
Value Function Update Magnitude: 0.54950

Collected Steps per Second: 23,080.56259
Overall Steps per Second: 10,893.82547

Timestep Collection Time: 2.16745
Timestep Consumption Time: 2.42469
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.59214

Cumulative Model Updates: 176,780
Cumulative Timesteps: 1,474,311,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,625.09143
Policy Entropy: 2.94970
Value Function Loss: 0.00487

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11389
Policy Update Magnitude: 0.58257
Value Function Update Magnitude: 0.55746

Collected Steps per Second: 23,227.25166
Overall Steps per Second: 10,896.83733

Timestep Collection Time: 2.15368
Timestep Consumption Time: 2.43701
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.59069

Cumulative Model Updates: 176,786
Cumulative Timesteps: 1,474,361,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1474361462...
Checkpoint 1474361462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.20370
Policy Entropy: 2.94303
Value Function Loss: 0.00470

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.57327

Collected Steps per Second: 22,951.14637
Overall Steps per Second: 10,636.19919

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.52380
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.70356

Cumulative Model Updates: 176,792
Cumulative Timesteps: 1,474,411,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.84089
Policy Entropy: 2.92982
Value Function Loss: 0.00441

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.58241
Value Function Update Magnitude: 0.57167

Collected Steps per Second: 22,711.35723
Overall Steps per Second: 10,660.11095

Timestep Collection Time: 2.20154
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.69038

Cumulative Model Updates: 176,798
Cumulative Timesteps: 1,474,461,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1474461490...
Checkpoint 1474461490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,392.82116
Policy Entropy: 2.93620
Value Function Loss: 0.00469

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11815
Policy Update Magnitude: 0.58879
Value Function Update Magnitude: 0.55514

Collected Steps per Second: 23,008.00216
Overall Steps per Second: 10,960.98495

Timestep Collection Time: 2.17429
Timestep Consumption Time: 2.38972
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.56401

Cumulative Model Updates: 176,804
Cumulative Timesteps: 1,474,511,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,491.23492
Policy Entropy: 2.93252
Value Function Loss: 0.00472

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.58620
Value Function Update Magnitude: 0.55440

Collected Steps per Second: 22,505.90619
Overall Steps per Second: 10,603.20597

Timestep Collection Time: 2.22279
Timestep Consumption Time: 2.49521
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.71801

Cumulative Model Updates: 176,810
Cumulative Timesteps: 1,474,561,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1474561542...
Checkpoint 1474561542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.21471
Policy Entropy: 2.95247
Value Function Loss: 0.00476

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.58046
Value Function Update Magnitude: 0.55112

Collected Steps per Second: 22,645.85416
Overall Steps per Second: 10,781.37927

Timestep Collection Time: 2.20870
Timestep Consumption Time: 2.43059
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.63930

Cumulative Model Updates: 176,816
Cumulative Timesteps: 1,474,611,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.23414
Policy Entropy: 2.96587
Value Function Loss: 0.00466

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.57592
Value Function Update Magnitude: 0.54340

Collected Steps per Second: 23,222.35017
Overall Steps per Second: 10,634.26780

Timestep Collection Time: 2.15387
Timestep Consumption Time: 2.54960
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.70347

Cumulative Model Updates: 176,822
Cumulative Timesteps: 1,474,661,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1474661578...
Checkpoint 1474661578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,744.69178
Policy Entropy: 2.98449
Value Function Loss: 0.00469

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.58029
Value Function Update Magnitude: 0.55407

Collected Steps per Second: 23,116.66975
Overall Steps per Second: 10,762.53404

Timestep Collection Time: 2.16337
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.64668

Cumulative Model Updates: 176,828
Cumulative Timesteps: 1,474,711,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,799.27171
Policy Entropy: 2.98448
Value Function Loss: 0.00445

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12032
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.56726

Collected Steps per Second: 22,909.63860
Overall Steps per Second: 10,688.43573

Timestep Collection Time: 2.18345
Timestep Consumption Time: 2.49656
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.68001

Cumulative Model Updates: 176,834
Cumulative Timesteps: 1,474,761,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1474761610...
Checkpoint 1474761610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,721.77608
Policy Entropy: 2.96328
Value Function Loss: 0.00447

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.56231
Value Function Update Magnitude: 0.55362

Collected Steps per Second: 22,873.34940
Overall Steps per Second: 10,645.23823

Timestep Collection Time: 2.18691
Timestep Consumption Time: 2.51209
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.69900

Cumulative Model Updates: 176,840
Cumulative Timesteps: 1,474,811,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.19866
Policy Entropy: 2.95350
Value Function Loss: 0.00452

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.57433
Value Function Update Magnitude: 0.53020

Collected Steps per Second: 23,101.62739
Overall Steps per Second: 10,859.70611

Timestep Collection Time: 2.16530
Timestep Consumption Time: 2.44090
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60620

Cumulative Model Updates: 176,846
Cumulative Timesteps: 1,474,861,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1474861654...
Checkpoint 1474861654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,088.68448
Policy Entropy: 2.92009
Value Function Loss: 0.00466

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.58627
Value Function Update Magnitude: 0.51645

Collected Steps per Second: 23,073.01285
Overall Steps per Second: 10,688.75114

Timestep Collection Time: 2.16729
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.67838

Cumulative Model Updates: 176,852
Cumulative Timesteps: 1,474,911,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,975.34342
Policy Entropy: 2.93930
Value Function Loss: 0.00445

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.50093

Collected Steps per Second: 22,812.25951
Overall Steps per Second: 10,675.86360

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.68365

Cumulative Model Updates: 176,858
Cumulative Timesteps: 1,474,961,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1474961662...
Checkpoint 1474961662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,406.92726
Policy Entropy: 2.95207
Value Function Loss: 0.00429

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.55980
Value Function Update Magnitude: 0.49027

Collected Steps per Second: 22,572.19522
Overall Steps per Second: 10,681.13090

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.46742
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.68377

Cumulative Model Updates: 176,864
Cumulative Timesteps: 1,475,011,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.04729
Policy Entropy: 2.95866
Value Function Loss: 0.00455

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.56513
Value Function Update Magnitude: 0.49896

Collected Steps per Second: 22,464.60220
Overall Steps per Second: 10,672.35335

Timestep Collection Time: 2.22661
Timestep Consumption Time: 2.46026
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.68688

Cumulative Model Updates: 176,870
Cumulative Timesteps: 1,475,061,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1475061710...
Checkpoint 1475061710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,552.71573
Policy Entropy: 2.94242
Value Function Loss: 0.00504

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.58189
Value Function Update Magnitude: 0.52521

Collected Steps per Second: 22,640.99100
Overall Steps per Second: 10,596.04311

Timestep Collection Time: 2.20838
Timestep Consumption Time: 2.51036
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.71874

Cumulative Model Updates: 176,876
Cumulative Timesteps: 1,475,111,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,168.93870
Policy Entropy: 2.92575
Value Function Loss: 0.00533

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.58602
Value Function Update Magnitude: 0.53889

Collected Steps per Second: 22,540.63118
Overall Steps per Second: 10,597.72617

Timestep Collection Time: 2.21822
Timestep Consumption Time: 2.49978
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.71799

Cumulative Model Updates: 176,882
Cumulative Timesteps: 1,475,161,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1475161710...
Checkpoint 1475161710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,024.77222
Policy Entropy: 2.94414
Value Function Loss: 0.00522

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.59424
Value Function Update Magnitude: 0.56191

Collected Steps per Second: 22,808.14984
Overall Steps per Second: 10,601.86243

Timestep Collection Time: 2.19334
Timestep Consumption Time: 2.52527
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.71860

Cumulative Model Updates: 176,888
Cumulative Timesteps: 1,475,211,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.97052
Policy Entropy: 2.94016
Value Function Loss: 0.00483

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.58821
Value Function Update Magnitude: 0.56716

Collected Steps per Second: 22,976.68245
Overall Steps per Second: 10,782.28376

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.46220
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.63928

Cumulative Model Updates: 176,894
Cumulative Timesteps: 1,475,261,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1475261758...
Checkpoint 1475261758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.15076
Policy Entropy: 2.94717
Value Function Loss: 0.00473

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.58103
Value Function Update Magnitude: 0.56099

Collected Steps per Second: 23,081.33943
Overall Steps per Second: 10,692.33786

Timestep Collection Time: 2.16660
Timestep Consumption Time: 2.51040
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.67699

Cumulative Model Updates: 176,900
Cumulative Timesteps: 1,475,311,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.88332
Policy Entropy: 2.93652
Value Function Loss: 0.00477

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.57231
Value Function Update Magnitude: 0.53805

Collected Steps per Second: 22,968.97150
Overall Steps per Second: 10,611.25402

Timestep Collection Time: 2.17737
Timestep Consumption Time: 2.53574
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.71311

Cumulative Model Updates: 176,906
Cumulative Timesteps: 1,475,361,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1475361778...
Checkpoint 1475361778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120.80977
Policy Entropy: 2.94395
Value Function Loss: 0.00510

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.58992
Value Function Update Magnitude: 0.53402

Collected Steps per Second: 22,829.24175
Overall Steps per Second: 10,706.01690

Timestep Collection Time: 2.19035
Timestep Consumption Time: 2.48030
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67064

Cumulative Model Updates: 176,912
Cumulative Timesteps: 1,475,411,782

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,266.92517
Policy Entropy: 2.93710
Value Function Loss: 0.00477

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.15595
Policy Update Magnitude: 0.59720
Value Function Update Magnitude: 0.55152

Collected Steps per Second: 23,303.90976
Overall Steps per Second: 10,743.87455

Timestep Collection Time: 2.14625
Timestep Consumption Time: 2.50905
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.65530

Cumulative Model Updates: 176,918
Cumulative Timesteps: 1,475,461,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1475461798...
Checkpoint 1475461798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,013.43599
Policy Entropy: 2.94322
Value Function Loss: 0.00483

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15434
Policy Update Magnitude: 0.58155
Value Function Update Magnitude: 0.53026

Collected Steps per Second: 23,123.61357
Overall Steps per Second: 10,987.63083

Timestep Collection Time: 2.16333
Timestep Consumption Time: 2.38943
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.55276

Cumulative Model Updates: 176,924
Cumulative Timesteps: 1,475,511,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,514.95113
Policy Entropy: 2.95256
Value Function Loss: 0.00472

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.58139
Value Function Update Magnitude: 0.52222

Collected Steps per Second: 22,656.68853
Overall Steps per Second: 10,588.97417

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.51635
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.72435

Cumulative Model Updates: 176,930
Cumulative Timesteps: 1,475,561,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1475561848...
Checkpoint 1475561848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,416.93259
Policy Entropy: 2.97026
Value Function Loss: 0.00459

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.58614
Value Function Update Magnitude: 0.54528

Collected Steps per Second: 22,740.13954
Overall Steps per Second: 10,629.90586

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.50616
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.70597

Cumulative Model Updates: 176,936
Cumulative Timesteps: 1,475,611,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,618.80333
Policy Entropy: 2.96433
Value Function Loss: 0.00445

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.53889

Collected Steps per Second: 22,663.06818
Overall Steps per Second: 10,766.51356

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.64589

Cumulative Model Updates: 176,942
Cumulative Timesteps: 1,475,661,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1475661892...
Checkpoint 1475661892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,032.98990
Policy Entropy: 2.95260
Value Function Loss: 0.00437

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.57378
Value Function Update Magnitude: 0.53875

Collected Steps per Second: 22,276.89297
Overall Steps per Second: 10,679.05727

Timestep Collection Time: 2.24565
Timestep Consumption Time: 2.43885
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.68450

Cumulative Model Updates: 176,948
Cumulative Timesteps: 1,475,711,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.22331
Policy Entropy: 2.95108
Value Function Loss: 0.00451

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.51482

Collected Steps per Second: 23,036.91402
Overall Steps per Second: 10,487.17095

Timestep Collection Time: 2.17095
Timestep Consumption Time: 2.59792
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.76887

Cumulative Model Updates: 176,954
Cumulative Timesteps: 1,475,761,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1475761930...
Checkpoint 1475761930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,402.01212
Policy Entropy: 2.96320
Value Function Loss: 0.00438

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.55791
Value Function Update Magnitude: 0.49843

Collected Steps per Second: 23,265.79580
Overall Steps per Second: 10,676.80421

Timestep Collection Time: 2.14925
Timestep Consumption Time: 2.53417
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.68342

Cumulative Model Updates: 176,960
Cumulative Timesteps: 1,475,811,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.71023
Policy Entropy: 2.96266
Value Function Loss: 0.00473

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.56649
Value Function Update Magnitude: 0.51323

Collected Steps per Second: 23,258.04683
Overall Steps per Second: 10,907.50807

Timestep Collection Time: 2.15074
Timestep Consumption Time: 2.43528
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.58602

Cumulative Model Updates: 176,966
Cumulative Timesteps: 1,475,861,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1475861956...
Checkpoint 1475861956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.25939
Policy Entropy: 2.96440
Value Function Loss: 0.00455

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.56849
Value Function Update Magnitude: 0.53605

Collected Steps per Second: 23,063.57423
Overall Steps per Second: 10,722.54445

Timestep Collection Time: 2.16792
Timestep Consumption Time: 2.49515
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.66307

Cumulative Model Updates: 176,972
Cumulative Timesteps: 1,475,911,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.94238
Policy Entropy: 2.97781
Value Function Loss: 0.00447

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.56536
Value Function Update Magnitude: 0.53172

Collected Steps per Second: 23,313.85326
Overall Steps per Second: 10,781.40869

Timestep Collection Time: 2.14662
Timestep Consumption Time: 2.49526
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.64188

Cumulative Model Updates: 176,978
Cumulative Timesteps: 1,475,962,002

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1475962002...
Checkpoint 1475962002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,679.16684
Policy Entropy: 2.97661
Value Function Loss: 0.00440

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.56904
Value Function Update Magnitude: 0.52382

Collected Steps per Second: 23,104.04674
Overall Steps per Second: 10,688.50615

Timestep Collection Time: 2.16473
Timestep Consumption Time: 2.51450
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.67923

Cumulative Model Updates: 176,984
Cumulative Timesteps: 1,476,012,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.23499
Policy Entropy: 2.96031
Value Function Loss: 0.00454

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.52639

Collected Steps per Second: 23,276.27376
Overall Steps per Second: 10,873.33500

Timestep Collection Time: 2.14863
Timestep Consumption Time: 2.45088
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.59951

Cumulative Model Updates: 176,990
Cumulative Timesteps: 1,476,062,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1476062028...
Checkpoint 1476062028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.07014
Policy Entropy: 2.94284
Value Function Loss: 0.00488

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.58428
Value Function Update Magnitude: 0.53494

Collected Steps per Second: 22,653.59794
Overall Steps per Second: 10,635.14162

Timestep Collection Time: 2.20724
Timestep Consumption Time: 2.49434
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.70158

Cumulative Model Updates: 176,996
Cumulative Timesteps: 1,476,112,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,554.71453
Policy Entropy: 2.95047
Value Function Loss: 0.00474

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.58295
Value Function Update Magnitude: 0.53786

Collected Steps per Second: 22,472.92611
Overall Steps per Second: 10,602.83400

Timestep Collection Time: 2.22508
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.71610

Cumulative Model Updates: 177,002
Cumulative Timesteps: 1,476,162,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1476162034...
Checkpoint 1476162034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,059.65957
Policy Entropy: 2.96041
Value Function Loss: 0.00483

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.57165
Value Function Update Magnitude: 0.53183

Collected Steps per Second: 22,938.00968
Overall Steps per Second: 10,856.76333

Timestep Collection Time: 2.18057
Timestep Consumption Time: 2.42651
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.60708

Cumulative Model Updates: 177,008
Cumulative Timesteps: 1,476,212,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.88727
Policy Entropy: 2.96881
Value Function Loss: 0.00466

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.56319
Value Function Update Magnitude: 0.51541

Collected Steps per Second: 22,702.97666
Overall Steps per Second: 10,729.77598

Timestep Collection Time: 2.20350
Timestep Consumption Time: 2.45885
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.66235

Cumulative Model Updates: 177,014
Cumulative Timesteps: 1,476,262,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1476262078...
Checkpoint 1476262078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.90672
Policy Entropy: 2.97272
Value Function Loss: 0.00487

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.51681

Collected Steps per Second: 23,238.11281
Overall Steps per Second: 10,809.51328

Timestep Collection Time: 2.15293
Timestep Consumption Time: 2.47540
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.62833

Cumulative Model Updates: 177,020
Cumulative Timesteps: 1,476,312,108

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.22280
Policy Entropy: 2.96780
Value Function Loss: 0.00500

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.56192
Value Function Update Magnitude: 0.52853

Collected Steps per Second: 22,978.31144
Overall Steps per Second: 10,683.76433

Timestep Collection Time: 2.17701
Timestep Consumption Time: 2.50524
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68224

Cumulative Model Updates: 177,026
Cumulative Timesteps: 1,476,362,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1476362132...
Checkpoint 1476362132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,350.89709
Policy Entropy: 2.96657
Value Function Loss: 0.00480

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.56782
Value Function Update Magnitude: 0.53095

Collected Steps per Second: 23,027.02233
Overall Steps per Second: 10,872.27443

Timestep Collection Time: 2.17145
Timestep Consumption Time: 2.42759
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.59904

Cumulative Model Updates: 177,032
Cumulative Timesteps: 1,476,412,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,718.98420
Policy Entropy: 2.96069
Value Function Loss: 0.00452

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.56709
Value Function Update Magnitude: 0.51862

Collected Steps per Second: 23,074.84802
Overall Steps per Second: 10,769.51444

Timestep Collection Time: 2.16825
Timestep Consumption Time: 2.47746
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.64571

Cumulative Model Updates: 177,038
Cumulative Timesteps: 1,476,462,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1476462166...
Checkpoint 1476462166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,286.17654
Policy Entropy: 2.97460
Value Function Loss: 0.00468

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.57423
Value Function Update Magnitude: 0.52877

Collected Steps per Second: 23,132.35107
Overall Steps per Second: 10,946.92164

Timestep Collection Time: 2.16182
Timestep Consumption Time: 2.40640
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.56822

Cumulative Model Updates: 177,044
Cumulative Timesteps: 1,476,512,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,780.72060
Policy Entropy: 2.97357
Value Function Loss: 0.00483

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.57744
Value Function Update Magnitude: 0.53958

Collected Steps per Second: 22,857.62217
Overall Steps per Second: 10,796.56100

Timestep Collection Time: 2.18885
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63407

Cumulative Model Updates: 177,050
Cumulative Timesteps: 1,476,562,206

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1476562206...
Checkpoint 1476562206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,211.88744
Policy Entropy: 2.98630
Value Function Loss: 0.00535

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.58159
Value Function Update Magnitude: 0.53982

Collected Steps per Second: 22,553.90609
Overall Steps per Second: 10,686.42778

Timestep Collection Time: 2.21762
Timestep Consumption Time: 2.46271
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.68033

Cumulative Model Updates: 177,056
Cumulative Timesteps: 1,476,612,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,341.13559
Policy Entropy: 2.96482
Value Function Loss: 0.00509

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.54521

Collected Steps per Second: 22,976.50102
Overall Steps per Second: 10,852.56725

Timestep Collection Time: 2.17692
Timestep Consumption Time: 2.43194
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.60886

Cumulative Model Updates: 177,062
Cumulative Timesteps: 1,476,662,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1476662240...
Checkpoint 1476662240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,438.53298
Policy Entropy: 2.97623
Value Function Loss: 0.00459

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.53328

Collected Steps per Second: 22,377.96953
Overall Steps per Second: 10,729.90191

Timestep Collection Time: 2.23514
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.66155

Cumulative Model Updates: 177,068
Cumulative Timesteps: 1,476,712,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025.45230
Policy Entropy: 2.94976
Value Function Loss: 0.00453

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.57650
Value Function Update Magnitude: 0.52525

Collected Steps per Second: 22,274.87221
Overall Steps per Second: 10,522.36315

Timestep Collection Time: 2.24531
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.75311

Cumulative Model Updates: 177,074
Cumulative Timesteps: 1,476,762,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1476762272...
Checkpoint 1476762272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,157.44966
Policy Entropy: 2.96025
Value Function Loss: 0.00454

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.54118

Collected Steps per Second: 23,063.76302
Overall Steps per Second: 10,879.29845

Timestep Collection Time: 2.16868
Timestep Consumption Time: 2.42886
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.59754

Cumulative Model Updates: 177,080
Cumulative Timesteps: 1,476,812,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.02724
Policy Entropy: 2.96066
Value Function Loss: 0.00489

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.58886
Value Function Update Magnitude: 0.54635

Collected Steps per Second: 23,156.37972
Overall Steps per Second: 10,943.06783

Timestep Collection Time: 2.16027
Timestep Consumption Time: 2.41103
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.57130

Cumulative Model Updates: 177,086
Cumulative Timesteps: 1,476,862,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1476862314...
Checkpoint 1476862314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,994.21089
Policy Entropy: 2.97052
Value Function Loss: 0.00490

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.58482
Value Function Update Magnitude: 0.56452

Collected Steps per Second: 23,330.87803
Overall Steps per Second: 10,741.26731

Timestep Collection Time: 2.14325
Timestep Consumption Time: 2.51206
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.65532

Cumulative Model Updates: 177,092
Cumulative Timesteps: 1,476,912,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.05949
Policy Entropy: 2.97010
Value Function Loss: 0.00487

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.58439
Value Function Update Magnitude: 0.56148

Collected Steps per Second: 23,058.28745
Overall Steps per Second: 10,817.26509

Timestep Collection Time: 2.16946
Timestep Consumption Time: 2.45500
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.62446

Cumulative Model Updates: 177,098
Cumulative Timesteps: 1,476,962,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1476962342...
Checkpoint 1476962342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.29464
Policy Entropy: 2.95970
Value Function Loss: 0.00506

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.58469
Value Function Update Magnitude: 0.54273

Collected Steps per Second: 22,900.34987
Overall Steps per Second: 10,679.80958

Timestep Collection Time: 2.18398
Timestep Consumption Time: 2.49906
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68304

Cumulative Model Updates: 177,104
Cumulative Timesteps: 1,477,012,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,144.06268
Policy Entropy: 2.96790
Value Function Loss: 0.00492

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.57788
Value Function Update Magnitude: 0.53053

Collected Steps per Second: 23,114.30735
Overall Steps per Second: 10,853.60106

Timestep Collection Time: 2.16455
Timestep Consumption Time: 2.44517
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.60971

Cumulative Model Updates: 177,110
Cumulative Timesteps: 1,477,062,388

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1477062388...
Checkpoint 1477062388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,375.79870
Policy Entropy: 2.95578
Value Function Loss: 0.00516

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.57550
Value Function Update Magnitude: 0.52421

Collected Steps per Second: 22,941.46737
Overall Steps per Second: 10,743.62521

Timestep Collection Time: 2.17963
Timestep Consumption Time: 2.47466
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.65429

Cumulative Model Updates: 177,116
Cumulative Timesteps: 1,477,112,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,048.07512
Policy Entropy: 2.95617
Value Function Loss: 0.00495

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.57163
Value Function Update Magnitude: 0.50895

Collected Steps per Second: 22,642.69170
Overall Steps per Second: 10,632.02151

Timestep Collection Time: 2.20875
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.70390

Cumulative Model Updates: 177,122
Cumulative Timesteps: 1,477,162,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1477162404...
Checkpoint 1477162404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.48227
Policy Entropy: 2.96831
Value Function Loss: 0.00479

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14417
Policy Update Magnitude: 0.56825
Value Function Update Magnitude: 0.49350

Collected Steps per Second: 22,929.73491
Overall Steps per Second: 10,855.19594

Timestep Collection Time: 2.18092
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.60683

Cumulative Model Updates: 177,128
Cumulative Timesteps: 1,477,212,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,306.61783
Policy Entropy: 2.97425
Value Function Loss: 0.00471

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.56636
Value Function Update Magnitude: 0.48185

Collected Steps per Second: 22,793.95762
Overall Steps per Second: 10,650.80077

Timestep Collection Time: 2.19400
Timestep Consumption Time: 2.50142
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.69542

Cumulative Model Updates: 177,134
Cumulative Timesteps: 1,477,262,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1477262422...
Checkpoint 1477262422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,065.42400
Policy Entropy: 2.96150
Value Function Loss: 0.00445

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.56378
Value Function Update Magnitude: 0.48593

Collected Steps per Second: 21,856.84622
Overall Steps per Second: 10,466.79140

Timestep Collection Time: 2.28871
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.77931

Cumulative Model Updates: 177,140
Cumulative Timesteps: 1,477,312,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,394.81748
Policy Entropy: 2.96847
Value Function Loss: 0.00420

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.50923

Collected Steps per Second: 22,528.01114
Overall Steps per Second: 10,584.52406

Timestep Collection Time: 2.21999
Timestep Consumption Time: 2.50502
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.72501

Cumulative Model Updates: 177,146
Cumulative Timesteps: 1,477,362,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1477362458...
Checkpoint 1477362458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,355.33185
Policy Entropy: 2.96932
Value Function Loss: 0.00463

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.52472

Collected Steps per Second: 22,531.21395
Overall Steps per Second: 10,593.38080

Timestep Collection Time: 2.21923
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.72012

Cumulative Model Updates: 177,152
Cumulative Timesteps: 1,477,412,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.36414
Policy Entropy: 2.96177
Value Function Loss: 0.00484

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.58363
Value Function Update Magnitude: 0.51909

Collected Steps per Second: 22,749.77516
Overall Steps per Second: 10,772.29389

Timestep Collection Time: 2.19905
Timestep Consumption Time: 2.44508
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.64414

Cumulative Model Updates: 177,158
Cumulative Timesteps: 1,477,462,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1477462488...
Checkpoint 1477462488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.52469
Policy Entropy: 2.94300
Value Function Loss: 0.00498

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.58958
Value Function Update Magnitude: 0.52752

Collected Steps per Second: 22,860.62610
Overall Steps per Second: 10,720.46111

Timestep Collection Time: 2.18778
Timestep Consumption Time: 2.47751
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.66528

Cumulative Model Updates: 177,164
Cumulative Timesteps: 1,477,512,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.38504
Policy Entropy: 2.94558
Value Function Loss: 0.00466

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.58009
Value Function Update Magnitude: 0.53306

Collected Steps per Second: 23,243.66243
Overall Steps per Second: 10,914.97700

Timestep Collection Time: 2.15190
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.58251

Cumulative Model Updates: 177,170
Cumulative Timesteps: 1,477,562,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1477562520...
Checkpoint 1477562520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,294.68375
Policy Entropy: 2.96640
Value Function Loss: 0.00435

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.52789

Collected Steps per Second: 23,011.40714
Overall Steps per Second: 10,695.14464

Timestep Collection Time: 2.17414
Timestep Consumption Time: 2.50368
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.67782

Cumulative Model Updates: 177,176
Cumulative Timesteps: 1,477,612,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,715.13652
Policy Entropy: 2.97121
Value Function Loss: 0.00404

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.49787

Collected Steps per Second: 23,135.16659
Overall Steps per Second: 10,838.58444

Timestep Collection Time: 2.16208
Timestep Consumption Time: 2.45292
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.61499

Cumulative Model Updates: 177,182
Cumulative Timesteps: 1,477,662,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1477662570...
Checkpoint 1477662570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,891.20964
Policy Entropy: 2.95410
Value Function Loss: 0.00458

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.58630
Value Function Update Magnitude: 0.51582

Collected Steps per Second: 23,000.22065
Overall Steps per Second: 10,768.62052

Timestep Collection Time: 2.17407
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.64349

Cumulative Model Updates: 177,188
Cumulative Timesteps: 1,477,712,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.35429
Policy Entropy: 2.95758
Value Function Loss: 0.00468

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.60097
Value Function Update Magnitude: 0.54755

Collected Steps per Second: 23,458.86517
Overall Steps per Second: 10,854.76276

Timestep Collection Time: 2.13216
Timestep Consumption Time: 2.47577
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.60793

Cumulative Model Updates: 177,194
Cumulative Timesteps: 1,477,762,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1477762592...
Checkpoint 1477762592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,944.02262
Policy Entropy: 2.95543
Value Function Loss: 0.00498

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.59794
Value Function Update Magnitude: 0.57282

Collected Steps per Second: 22,852.38112
Overall Steps per Second: 10,923.89487

Timestep Collection Time: 2.18936
Timestep Consumption Time: 2.39070
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.58005

Cumulative Model Updates: 177,200
Cumulative Timesteps: 1,477,812,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,869.45023
Policy Entropy: 2.97171
Value Function Loss: 0.00463

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.58320
Value Function Update Magnitude: 0.57022

Collected Steps per Second: 22,957.06957
Overall Steps per Second: 10,704.10923

Timestep Collection Time: 2.17876
Timestep Consumption Time: 2.49402
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.67278

Cumulative Model Updates: 177,206
Cumulative Timesteps: 1,477,862,642

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1477862642...
Checkpoint 1477862642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,670.64232
Policy Entropy: 2.95611
Value Function Loss: 0.00483

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.57560
Value Function Update Magnitude: 0.54525

Collected Steps per Second: 22,783.96174
Overall Steps per Second: 10,897.79779

Timestep Collection Time: 2.19479
Timestep Consumption Time: 2.39384
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.58863

Cumulative Model Updates: 177,212
Cumulative Timesteps: 1,477,912,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,750.49918
Policy Entropy: 2.95610
Value Function Loss: 0.00478

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.58453
Value Function Update Magnitude: 0.53710

Collected Steps per Second: 22,755.51955
Overall Steps per Second: 10,607.78368

Timestep Collection Time: 2.19824
Timestep Consumption Time: 2.51736
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.71559

Cumulative Model Updates: 177,218
Cumulative Timesteps: 1,477,962,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1477962670...
Checkpoint 1477962670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.31985
Policy Entropy: 2.94159
Value Function Loss: 0.00522

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.59759
Value Function Update Magnitude: 0.55414

Collected Steps per Second: 22,930.98439
Overall Steps per Second: 10,583.29124

Timestep Collection Time: 2.18098
Timestep Consumption Time: 2.54458
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.72556

Cumulative Model Updates: 177,224
Cumulative Timesteps: 1,478,012,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.38728
Policy Entropy: 2.96712
Value Function Loss: 0.00473

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.58240
Value Function Update Magnitude: 0.57110

Collected Steps per Second: 23,164.01057
Overall Steps per Second: 10,857.79678

Timestep Collection Time: 2.15861
Timestep Consumption Time: 2.44656
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.60517

Cumulative Model Updates: 177,230
Cumulative Timesteps: 1,478,062,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1478062684...
Checkpoint 1478062684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,354.21325
Policy Entropy: 2.97436
Value Function Loss: 0.00439

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.56616
Value Function Update Magnitude: 0.55766

Collected Steps per Second: 22,982.78369
Overall Steps per Second: 10,687.00257

Timestep Collection Time: 2.17589
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.67933

Cumulative Model Updates: 177,236
Cumulative Timesteps: 1,478,112,692

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,971.01581
Policy Entropy: 3.00231
Value Function Loss: 0.00398

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.50114

Collected Steps per Second: 23,141.30895
Overall Steps per Second: 10,882.08777

Timestep Collection Time: 2.16176
Timestep Consumption Time: 2.43533
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.59710

Cumulative Model Updates: 177,242
Cumulative Timesteps: 1,478,162,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1478162718...
Checkpoint 1478162718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,391.34332
Policy Entropy: 2.99538
Value Function Loss: 0.00425

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.55327
Value Function Update Magnitude: 0.47547

Collected Steps per Second: 23,136.80741
Overall Steps per Second: 10,733.36490

Timestep Collection Time: 2.16158
Timestep Consumption Time: 2.49791
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.65949

Cumulative Model Updates: 177,248
Cumulative Timesteps: 1,478,212,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,716.20647
Policy Entropy: 2.99834
Value Function Loss: 0.00457

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.55475
Value Function Update Magnitude: 0.48040

Collected Steps per Second: 23,046.03428
Overall Steps per Second: 10,812.52324

Timestep Collection Time: 2.16992
Timestep Consumption Time: 2.45509
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.62501

Cumulative Model Updates: 177,254
Cumulative Timesteps: 1,478,262,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1478262738...
Checkpoint 1478262738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,665.51120
Policy Entropy: 2.97459
Value Function Loss: 0.00471

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.51500

Collected Steps per Second: 22,799.82966
Overall Steps per Second: 10,730.30905

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.46700
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.66026

Cumulative Model Updates: 177,260
Cumulative Timesteps: 1,478,312,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.39872
Policy Entropy: 2.97070
Value Function Loss: 0.00473

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.56970
Value Function Update Magnitude: 0.52598

Collected Steps per Second: 22,965.62790
Overall Steps per Second: 10,787.72774

Timestep Collection Time: 2.17839
Timestep Consumption Time: 2.45911
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.63749

Cumulative Model Updates: 177,266
Cumulative Timesteps: 1,478,362,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1478362772...
Checkpoint 1478362772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,953.71996
Policy Entropy: 2.95734
Value Function Loss: 0.00499

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.57889
Value Function Update Magnitude: 0.53706

Collected Steps per Second: 22,496.48655
Overall Steps per Second: 10,644.65574

Timestep Collection Time: 2.22310
Timestep Consumption Time: 2.47522
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.69832

Cumulative Model Updates: 177,272
Cumulative Timesteps: 1,478,412,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,966.81491
Policy Entropy: 2.96510
Value Function Loss: 0.00474

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.58112
Value Function Update Magnitude: 0.52844

Collected Steps per Second: 23,131.72263
Overall Steps per Second: 10,834.34226

Timestep Collection Time: 2.16240
Timestep Consumption Time: 2.45440
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.61680

Cumulative Model Updates: 177,278
Cumulative Timesteps: 1,478,462,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1478462804...
Checkpoint 1478462804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,794.20958
Policy Entropy: 2.95728
Value Function Loss: 0.00486

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.58067
Value Function Update Magnitude: 0.51501

Collected Steps per Second: 23,060.46287
Overall Steps per Second: 10,703.29101

Timestep Collection Time: 2.16882
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.67277

Cumulative Model Updates: 177,284
Cumulative Timesteps: 1,478,512,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,555.66664
Policy Entropy: 2.96552
Value Function Loss: 0.00508

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.59304
Value Function Update Magnitude: 0.54184

Collected Steps per Second: 23,259.91829
Overall Steps per Second: 10,925.66982

Timestep Collection Time: 2.15031
Timestep Consumption Time: 2.42753
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.57784

Cumulative Model Updates: 177,290
Cumulative Timesteps: 1,478,562,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1478562834...
Checkpoint 1478562834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.64752
Policy Entropy: 2.97584
Value Function Loss: 0.00485

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.59383
Value Function Update Magnitude: 0.58852

Collected Steps per Second: 22,743.68334
Overall Steps per Second: 10,599.91959

Timestep Collection Time: 2.19938
Timestep Consumption Time: 2.51971
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.71909

Cumulative Model Updates: 177,296
Cumulative Timesteps: 1,478,612,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,597.48881
Policy Entropy: 2.98079
Value Function Loss: 0.00461

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.58122
Value Function Update Magnitude: 0.59576

Collected Steps per Second: 23,167.89924
Overall Steps per Second: 10,887.31177

Timestep Collection Time: 2.15928
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.59489

Cumulative Model Updates: 177,302
Cumulative Timesteps: 1,478,662,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1478662882...
Checkpoint 1478662882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,813.18972
Policy Entropy: 2.99566
Value Function Loss: 0.00436

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10942
Policy Update Magnitude: 0.58122
Value Function Update Magnitude: 0.56498

Collected Steps per Second: 22,920.48677
Overall Steps per Second: 10,682.55975

Timestep Collection Time: 2.18259
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.68296

Cumulative Model Updates: 177,308
Cumulative Timesteps: 1,478,712,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,255.99700
Policy Entropy: 2.98135
Value Function Loss: 0.00440

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.57428
Value Function Update Magnitude: 0.55860

Collected Steps per Second: 23,027.90586
Overall Steps per Second: 10,851.53933

Timestep Collection Time: 2.17241
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61004

Cumulative Model Updates: 177,314
Cumulative Timesteps: 1,478,762,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1478762934...
Checkpoint 1478762934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.20948
Policy Entropy: 2.97231
Value Function Loss: 0.00451

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.57367
Value Function Update Magnitude: 0.54690

Collected Steps per Second: 22,441.25414
Overall Steps per Second: 10,746.72667

Timestep Collection Time: 2.22857
Timestep Consumption Time: 2.42512
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.65370

Cumulative Model Updates: 177,320
Cumulative Timesteps: 1,478,812,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,610.75536
Policy Entropy: 2.95720
Value Function Loss: 0.00451

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.57713
Value Function Update Magnitude: 0.55253

Collected Steps per Second: 22,658.93287
Overall Steps per Second: 10,767.39365

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.43828
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.64606

Cumulative Model Updates: 177,326
Cumulative Timesteps: 1,478,862,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1478862972...
Checkpoint 1478862972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,386.30634
Policy Entropy: 2.96445
Value Function Loss: 0.00498

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.60007
Value Function Update Magnitude: 0.55852

Collected Steps per Second: 21,512.64935
Overall Steps per Second: 10,277.85542

Timestep Collection Time: 2.32440
Timestep Consumption Time: 2.54082
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.86522

Cumulative Model Updates: 177,332
Cumulative Timesteps: 1,478,912,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,547.77902
Policy Entropy: 2.96020
Value Function Loss: 0.00504

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.60765
Value Function Update Magnitude: 0.54667

Collected Steps per Second: 22,334.40226
Overall Steps per Second: 10,532.86772

Timestep Collection Time: 2.23959
Timestep Consumption Time: 2.50935
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.74894

Cumulative Model Updates: 177,338
Cumulative Timesteps: 1,478,962,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1478962996...
Checkpoint 1478962996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,574.44216
Policy Entropy: 2.94745
Value Function Loss: 0.00493

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.58873
Value Function Update Magnitude: 0.54514

Collected Steps per Second: 22,767.52133
Overall Steps per Second: 10,556.04486

Timestep Collection Time: 2.19646
Timestep Consumption Time: 2.54092
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.73738

Cumulative Model Updates: 177,344
Cumulative Timesteps: 1,479,013,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.16900
Policy Entropy: 2.94045
Value Function Loss: 0.00463

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.58380
Value Function Update Magnitude: 0.52764

Collected Steps per Second: 23,352.56655
Overall Steps per Second: 10,863.92749

Timestep Collection Time: 2.14152
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.60331

Cumulative Model Updates: 177,350
Cumulative Timesteps: 1,479,063,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1479063014...
Checkpoint 1479063014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,620.97075
Policy Entropy: 2.94457
Value Function Loss: 0.00438

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.58517
Value Function Update Magnitude: 0.50401

Collected Steps per Second: 22,871.41329
Overall Steps per Second: 10,683.86499

Timestep Collection Time: 2.18666
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.68108

Cumulative Model Updates: 177,356
Cumulative Timesteps: 1,479,113,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,454.58059
Policy Entropy: 2.95126
Value Function Loss: 0.00457

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.58826
Value Function Update Magnitude: 0.51259

Collected Steps per Second: 23,293.10321
Overall Steps per Second: 10,897.15653

Timestep Collection Time: 2.14776
Timestep Consumption Time: 2.44316
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.59092

Cumulative Model Updates: 177,362
Cumulative Timesteps: 1,479,163,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1479163054...
Checkpoint 1479163054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.40840
Policy Entropy: 2.96934
Value Function Loss: 0.00471

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.59341
Value Function Update Magnitude: 0.55049

Collected Steps per Second: 22,909.18321
Overall Steps per Second: 10,574.43239

Timestep Collection Time: 2.18332
Timestep Consumption Time: 2.54677
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.73009

Cumulative Model Updates: 177,368
Cumulative Timesteps: 1,479,213,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,676.49085
Policy Entropy: 2.96272
Value Function Loss: 0.00457

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.58970
Value Function Update Magnitude: 0.56936

Collected Steps per Second: 22,825.24595
Overall Steps per Second: 10,623.37745

Timestep Collection Time: 2.19056
Timestep Consumption Time: 2.51604
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.70660

Cumulative Model Updates: 177,374
Cumulative Timesteps: 1,479,263,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1479263072...
Checkpoint 1479263072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.39828
Policy Entropy: 2.95344
Value Function Loss: 0.00470

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.58986
Value Function Update Magnitude: 0.55212

Collected Steps per Second: 23,070.18536
Overall Steps per Second: 10,764.25176

Timestep Collection Time: 2.16782
Timestep Consumption Time: 2.47830
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.64612

Cumulative Model Updates: 177,380
Cumulative Timesteps: 1,479,313,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.18283
Policy Entropy: 2.95648
Value Function Loss: 0.00480

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.59623
Value Function Update Magnitude: 0.53580

Collected Steps per Second: 22,980.30152
Overall Steps per Second: 10,701.75381

Timestep Collection Time: 2.17578
Timestep Consumption Time: 2.49635
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.67213

Cumulative Model Updates: 177,386
Cumulative Timesteps: 1,479,363,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1479363084...
Checkpoint 1479363084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,391.99653
Policy Entropy: 2.95827
Value Function Loss: 0.00496

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.59142
Value Function Update Magnitude: 0.55066

Collected Steps per Second: 22,387.68517
Overall Steps per Second: 10,622.90938

Timestep Collection Time: 2.23364
Timestep Consumption Time: 2.47373
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.70737

Cumulative Model Updates: 177,392
Cumulative Timesteps: 1,479,413,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.58167
Policy Entropy: 2.97962
Value Function Loss: 0.00479

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.58633
Value Function Update Magnitude: 0.55089

Collected Steps per Second: 22,495.64818
Overall Steps per Second: 10,592.94579

Timestep Collection Time: 2.22390
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.72277

Cumulative Model Updates: 177,398
Cumulative Timesteps: 1,479,463,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1479463118...
Checkpoint 1479463118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,757.77057
Policy Entropy: 2.97997
Value Function Loss: 0.00482

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11617
Policy Update Magnitude: 0.59111
Value Function Update Magnitude: 0.56665

Collected Steps per Second: 22,447.18988
Overall Steps per Second: 10,565.29304

Timestep Collection Time: 2.22781
Timestep Consumption Time: 2.50543
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.73323

Cumulative Model Updates: 177,404
Cumulative Timesteps: 1,479,513,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,646.65254
Policy Entropy: 2.98338
Value Function Loss: 0.00506

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.60231
Value Function Update Magnitude: 0.59295

Collected Steps per Second: 22,985.76892
Overall Steps per Second: 10,771.76186

Timestep Collection Time: 2.17552
Timestep Consumption Time: 2.46680
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.64232

Cumulative Model Updates: 177,410
Cumulative Timesteps: 1,479,563,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1479563132...
Checkpoint 1479563132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,151.16746
Policy Entropy: 2.98715
Value Function Loss: 0.00499

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.60442
Value Function Update Magnitude: 0.57938

Collected Steps per Second: 22,817.10076
Overall Steps per Second: 10,753.28721

Timestep Collection Time: 2.19186
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.65086

Cumulative Model Updates: 177,416
Cumulative Timesteps: 1,479,613,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,443.35350
Policy Entropy: 3.00004
Value Function Loss: 0.00481

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.58850
Value Function Update Magnitude: 0.56051

Collected Steps per Second: 23,184.61631
Overall Steps per Second: 10,919.52598

Timestep Collection Time: 2.15669
Timestep Consumption Time: 2.42245
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.57914

Cumulative Model Updates: 177,422
Cumulative Timesteps: 1,479,663,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1479663146...
Checkpoint 1479663146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,165.18298
Policy Entropy: 3.00944
Value Function Loss: 0.00410

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.57219
Value Function Update Magnitude: 0.54723

Collected Steps per Second: 22,844.51533
Overall Steps per Second: 10,686.69779

Timestep Collection Time: 2.18932
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.68002

Cumulative Model Updates: 177,428
Cumulative Timesteps: 1,479,713,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,025.96894
Policy Entropy: 3.00659
Value Function Loss: 0.00413

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.56236
Value Function Update Magnitude: 0.51525

Collected Steps per Second: 23,484.36755
Overall Steps per Second: 10,798.18712

Timestep Collection Time: 2.12967
Timestep Consumption Time: 2.50203
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.63170

Cumulative Model Updates: 177,434
Cumulative Timesteps: 1,479,763,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1479763174...
Checkpoint 1479763174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,950.03244
Policy Entropy: 2.99324
Value Function Loss: 0.00451

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11472
Policy Update Magnitude: 0.57166
Value Function Update Magnitude: 0.49345

Collected Steps per Second: 22,945.69499
Overall Steps per Second: 10,694.67980

Timestep Collection Time: 2.18019
Timestep Consumption Time: 2.49746
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.67765

Cumulative Model Updates: 177,440
Cumulative Timesteps: 1,479,813,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.55988
Policy Entropy: 2.97698
Value Function Loss: 0.00509

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.58227
Value Function Update Magnitude: 0.51123

Collected Steps per Second: 22,673.80496
Overall Steps per Second: 10,901.19986

Timestep Collection Time: 2.20536
Timestep Consumption Time: 2.38165
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.58702

Cumulative Model Updates: 177,446
Cumulative Timesteps: 1,479,863,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1479863204...
Checkpoint 1479863204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,828.97158
Policy Entropy: 2.97166
Value Function Loss: 0.00502

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.11994
Policy Update Magnitude: 0.58127
Value Function Update Magnitude: 0.56363

Collected Steps per Second: 21,427.53636
Overall Steps per Second: 10,612.89309

Timestep Collection Time: 2.33457
Timestep Consumption Time: 2.37895
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.71351

Cumulative Model Updates: 177,452
Cumulative Timesteps: 1,479,913,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.40402
Policy Entropy: 2.96773
Value Function Loss: 0.00484

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.57843
Value Function Update Magnitude: 0.55994

Collected Steps per Second: 22,123.77150
Overall Steps per Second: 10,815.02864

Timestep Collection Time: 2.26110
Timestep Consumption Time: 2.36432
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62542

Cumulative Model Updates: 177,458
Cumulative Timesteps: 1,479,963,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1479963252...
Checkpoint 1479963252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,219.09113
Policy Entropy: 2.96854
Value Function Loss: 0.00468

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.58430
Value Function Update Magnitude: 0.53355

Collected Steps per Second: 21,624.78401
Overall Steps per Second: 10,701.85036

Timestep Collection Time: 2.31299
Timestep Consumption Time: 2.36078
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.67377

Cumulative Model Updates: 177,464
Cumulative Timesteps: 1,480,013,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,394.15625
Policy Entropy: 2.97448
Value Function Loss: 0.00444

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.57727
Value Function Update Magnitude: 0.51524

Collected Steps per Second: 22,483.96218
Overall Steps per Second: 10,877.56485

Timestep Collection Time: 2.22443
Timestep Consumption Time: 2.37347
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.59790

Cumulative Model Updates: 177,470
Cumulative Timesteps: 1,480,063,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1480063284...
Checkpoint 1480063284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,193.36190
Policy Entropy: 2.96932
Value Function Loss: 0.00458

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11872
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.48493

Collected Steps per Second: 22,050.13538
Overall Steps per Second: 10,743.88760

Timestep Collection Time: 2.26856
Timestep Consumption Time: 2.38730
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.65586

Cumulative Model Updates: 177,476
Cumulative Timesteps: 1,480,113,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,902.19037
Policy Entropy: 2.96913
Value Function Loss: 0.00480

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.57324
Value Function Update Magnitude: 0.47177

Collected Steps per Second: 22,521.46569
Overall Steps per Second: 10,736.74781

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.43738
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.65802

Cumulative Model Updates: 177,482
Cumulative Timesteps: 1,480,163,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1480163318...
Checkpoint 1480163318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,284.27658
Policy Entropy: 2.94331
Value Function Loss: 0.00473

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.57398
Value Function Update Magnitude: 0.48046

Collected Steps per Second: 23,000.62426
Overall Steps per Second: 10,757.13011

Timestep Collection Time: 2.17507
Timestep Consumption Time: 2.47561
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.65068

Cumulative Model Updates: 177,488
Cumulative Timesteps: 1,480,213,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.60738
Policy Entropy: 2.94763
Value Function Loss: 0.00464

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.57808
Value Function Update Magnitude: 0.51538

Collected Steps per Second: 23,390.66486
Overall Steps per Second: 10,918.27482

Timestep Collection Time: 2.13949
Timestep Consumption Time: 2.44402
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.58351

Cumulative Model Updates: 177,494
Cumulative Timesteps: 1,480,263,390

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1480263390...
Checkpoint 1480263390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,715.97700
Policy Entropy: 2.96090
Value Function Loss: 0.00416

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.53900

Collected Steps per Second: 22,752.95258
Overall Steps per Second: 10,651.37666

Timestep Collection Time: 2.19804
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.69536

Cumulative Model Updates: 177,500
Cumulative Timesteps: 1,480,313,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,461.19953
Policy Entropy: 2.98582
Value Function Loss: 0.00402

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.55471
Value Function Update Magnitude: 0.50870

Collected Steps per Second: 23,249.44062
Overall Steps per Second: 10,996.54900

Timestep Collection Time: 2.15068
Timestep Consumption Time: 2.39639
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.54706

Cumulative Model Updates: 177,506
Cumulative Timesteps: 1,480,363,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1480363404...
Checkpoint 1480363404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,308.48045
Policy Entropy: 3.00705
Value Function Loss: 0.00401

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.55037
Value Function Update Magnitude: 0.49850

Collected Steps per Second: 22,690.26329
Overall Steps per Second: 10,596.76383

Timestep Collection Time: 2.20368
Timestep Consumption Time: 2.51493
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.71861

Cumulative Model Updates: 177,512
Cumulative Timesteps: 1,480,413,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,844.45396
Policy Entropy: 2.99495
Value Function Loss: 0.00413

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.48773

Collected Steps per Second: 22,844.43496
Overall Steps per Second: 10,810.74725

Timestep Collection Time: 2.18950
Timestep Consumption Time: 2.43719
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.62669

Cumulative Model Updates: 177,518
Cumulative Timesteps: 1,480,463,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1480463424...
Checkpoint 1480463424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,569.81011
Policy Entropy: 2.97187
Value Function Loss: 0.00481

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.49353

Collected Steps per Second: 22,198.04112
Overall Steps per Second: 10,673.22377

Timestep Collection Time: 2.25263
Timestep Consumption Time: 2.43236
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.68499

Cumulative Model Updates: 177,524
Cumulative Timesteps: 1,480,513,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,061.50044
Policy Entropy: 2.94523
Value Function Loss: 0.00550

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.58752
Value Function Update Magnitude: 0.53411

Collected Steps per Second: 22,627.24330
Overall Steps per Second: 10,595.89094

Timestep Collection Time: 2.21096
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.72145

Cumulative Model Updates: 177,530
Cumulative Timesteps: 1,480,563,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1480563456...
Checkpoint 1480563456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,543.02983
Policy Entropy: 2.94299
Value Function Loss: 0.00566

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.58978
Value Function Update Magnitude: 0.54632

Collected Steps per Second: 22,685.53615
Overall Steps per Second: 10,589.21147

Timestep Collection Time: 2.20528
Timestep Consumption Time: 2.51915
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.72443

Cumulative Model Updates: 177,536
Cumulative Timesteps: 1,480,613,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,885.70236
Policy Entropy: 2.94061
Value Function Loss: 0.00543

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.59079
Value Function Update Magnitude: 0.53378

Collected Steps per Second: 23,426.08920
Overall Steps per Second: 10,865.46135

Timestep Collection Time: 2.13497
Timestep Consumption Time: 2.46806
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.60303

Cumulative Model Updates: 177,542
Cumulative Timesteps: 1,480,663,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1480663498...
Checkpoint 1480663498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.04684
Policy Entropy: 2.94763
Value Function Loss: 0.00541

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.59379
Value Function Update Magnitude: 0.53075

Collected Steps per Second: 22,972.05324
Overall Steps per Second: 10,704.92697

Timestep Collection Time: 2.17778
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.67336

Cumulative Model Updates: 177,548
Cumulative Timesteps: 1,480,713,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.11033
Policy Entropy: 2.97031
Value Function Loss: 0.00490

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.58358
Value Function Update Magnitude: 0.54372

Collected Steps per Second: 23,282.09791
Overall Steps per Second: 10,819.48173

Timestep Collection Time: 2.14783
Timestep Consumption Time: 2.47402
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.62185

Cumulative Model Updates: 177,554
Cumulative Timesteps: 1,480,763,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1480763532...
Checkpoint 1480763532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.57569
Policy Entropy: 2.97397
Value Function Loss: 0.00435

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.51744

Collected Steps per Second: 22,670.29518
Overall Steps per Second: 10,625.44961

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.50115
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.70757

Cumulative Model Updates: 177,560
Cumulative Timesteps: 1,480,813,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,175.27432
Policy Entropy: 2.96837
Value Function Loss: 0.00424

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.48151

Collected Steps per Second: 23,206.73833
Overall Steps per Second: 10,884.97814

Timestep Collection Time: 2.15567
Timestep Consumption Time: 2.44021
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.59588

Cumulative Model Updates: 177,566
Cumulative Timesteps: 1,480,863,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1480863578...
Checkpoint 1480863578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,713.11471
Policy Entropy: 2.95365
Value Function Loss: 0.00425

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.56307
Value Function Update Magnitude: 0.47128

Collected Steps per Second: 22,748.10743
Overall Steps per Second: 10,718.48012

Timestep Collection Time: 2.19913
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.66727

Cumulative Model Updates: 177,572
Cumulative Timesteps: 1,480,913,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,381.66897
Policy Entropy: 2.95981
Value Function Loss: 0.00436

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.56185
Value Function Update Magnitude: 0.47051

Collected Steps per Second: 22,867.40101
Overall Steps per Second: 10,806.28615

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.44266
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.63119

Cumulative Model Updates: 177,578
Cumulative Timesteps: 1,480,963,650

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1480963650...
Checkpoint 1480963650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,335.27573
Policy Entropy: 2.98155
Value Function Loss: 0.00379

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.54421
Value Function Update Magnitude: 0.46766

Collected Steps per Second: 22,085.43054
Overall Steps per Second: 10,477.75433

Timestep Collection Time: 2.26403
Timestep Consumption Time: 2.50818
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.77221

Cumulative Model Updates: 177,584
Cumulative Timesteps: 1,481,013,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,276.90111
Policy Entropy: 2.97452
Value Function Loss: 0.00387

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.53093
Value Function Update Magnitude: 0.44661

Collected Steps per Second: 22,839.62953
Overall Steps per Second: 10,667.75099

Timestep Collection Time: 2.18935
Timestep Consumption Time: 2.49805
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.68740

Cumulative Model Updates: 177,590
Cumulative Timesteps: 1,481,063,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1481063656...
Checkpoint 1481063656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,656.67625
Policy Entropy: 2.97211
Value Function Loss: 0.00376

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.53220
Value Function Update Magnitude: 0.44115

Collected Steps per Second: 21,206.59496
Overall Steps per Second: 10,585.30327

Timestep Collection Time: 2.35861
Timestep Consumption Time: 2.36662
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.72523

Cumulative Model Updates: 177,596
Cumulative Timesteps: 1,481,113,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,073.29571
Policy Entropy: 2.96631
Value Function Loss: 0.00411

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11853
Policy Update Magnitude: 0.53788
Value Function Update Magnitude: 0.42307

Collected Steps per Second: 20,543.16216
Overall Steps per Second: 10,174.15372

Timestep Collection Time: 2.43497
Timestep Consumption Time: 2.48161
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.91658

Cumulative Model Updates: 177,602
Cumulative Timesteps: 1,481,163,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1481163696...
Checkpoint 1481163696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,786.63180
Policy Entropy: 2.97052
Value Function Loss: 0.00446

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.55853
Value Function Update Magnitude: 0.43890

Collected Steps per Second: 18,726.37873
Overall Steps per Second: 9,635.57345

Timestep Collection Time: 2.67227
Timestep Consumption Time: 2.52119
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 5.19346

Cumulative Model Updates: 177,608
Cumulative Timesteps: 1,481,213,738

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,149.36985
Policy Entropy: 2.98235
Value Function Loss: 0.00457

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.56989
Value Function Update Magnitude: 0.49300

Collected Steps per Second: 20,239.93298
Overall Steps per Second: 10,147.10380

Timestep Collection Time: 2.47165
Timestep Consumption Time: 2.45843
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.93008

Cumulative Model Updates: 177,614
Cumulative Timesteps: 1,481,263,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1481263764...
Checkpoint 1481263764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,143.59234
Policy Entropy: 2.98213
Value Function Loss: 0.00446

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.56474
Value Function Update Magnitude: 0.51544

Collected Steps per Second: 17,855.65795
Overall Steps per Second: 9,348.95371

Timestep Collection Time: 2.80079
Timestep Consumption Time: 2.54847
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 5.34926

Cumulative Model Updates: 177,620
Cumulative Timesteps: 1,481,313,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.52239
Policy Entropy: 3.00423
Value Function Loss: 0.00472

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.56139
Value Function Update Magnitude: 0.52787

Collected Steps per Second: 18,831.28444
Overall Steps per Second: 9,684.75154

Timestep Collection Time: 2.65664
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 5.16565

Cumulative Model Updates: 177,626
Cumulative Timesteps: 1,481,363,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1481363802...
Checkpoint 1481363802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,340.71626
Policy Entropy: 3.00376
Value Function Loss: 0.00459

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.56166
Value Function Update Magnitude: 0.53072

Collected Steps per Second: 18,574.39960
Overall Steps per Second: 9,399.08301

Timestep Collection Time: 2.69252
Timestep Consumption Time: 2.62842
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 5.32094

Cumulative Model Updates: 177,632
Cumulative Timesteps: 1,481,413,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,732.05651
Policy Entropy: 3.00974
Value Function Loss: 0.00450

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.55913
Value Function Update Magnitude: 0.51405

Collected Steps per Second: 20,481.09228
Overall Steps per Second: 10,210.41091

Timestep Collection Time: 2.44157
Timestep Consumption Time: 2.45598
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.89755

Cumulative Model Updates: 177,638
Cumulative Timesteps: 1,481,463,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1481463820...
Checkpoint 1481463820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999.04456
Policy Entropy: 2.97893
Value Function Loss: 0.00455

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.56444
Value Function Update Magnitude: 0.50544

Collected Steps per Second: 20,362.98894
Overall Steps per Second: 10,114.27153

Timestep Collection Time: 2.45652
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.94568

Cumulative Model Updates: 177,644
Cumulative Timesteps: 1,481,513,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,851.99428
Policy Entropy: 2.97421
Value Function Loss: 0.00465

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.57477
Value Function Update Magnitude: 0.51909

Collected Steps per Second: 20,319.51957
Overall Steps per Second: 10,127.07330

Timestep Collection Time: 2.46069
Timestep Consumption Time: 2.47657
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.93726

Cumulative Model Updates: 177,650
Cumulative Timesteps: 1,481,563,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1481563842...
Checkpoint 1481563842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.18082
Policy Entropy: 2.95878
Value Function Loss: 0.00495

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.57896
Value Function Update Magnitude: 0.52167

Collected Steps per Second: 20,966.32777
Overall Steps per Second: 10,181.89255

Timestep Collection Time: 2.38611
Timestep Consumption Time: 2.52732
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.91343

Cumulative Model Updates: 177,656
Cumulative Timesteps: 1,481,613,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.69912
Policy Entropy: 2.97806
Value Function Loss: 0.00470

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.57694
Value Function Update Magnitude: 0.50496

Collected Steps per Second: 20,917.78354
Overall Steps per Second: 10,064.15187

Timestep Collection Time: 2.39098
Timestep Consumption Time: 2.57854
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.96952

Cumulative Model Updates: 177,662
Cumulative Timesteps: 1,481,663,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1481663884...
Checkpoint 1481663884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,190.70705
Policy Entropy: 2.97373
Value Function Loss: 0.00493

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.57065
Value Function Update Magnitude: 0.50733

Collected Steps per Second: 20,820.59551
Overall Steps per Second: 10,146.58246

Timestep Collection Time: 2.40262
Timestep Consumption Time: 2.52751
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.93013

Cumulative Model Updates: 177,668
Cumulative Timesteps: 1,481,713,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.19991
Policy Entropy: 2.98897
Value Function Loss: 0.00473

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.57705
Value Function Update Magnitude: 0.52326

Collected Steps per Second: 21,470.11457
Overall Steps per Second: 10,303.60308

Timestep Collection Time: 2.32882
Timestep Consumption Time: 2.52385
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.85267

Cumulative Model Updates: 177,674
Cumulative Timesteps: 1,481,763,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1481763908...
Checkpoint 1481763908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,633.77968
Policy Entropy: 2.99322
Value Function Loss: 0.00465

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.56969
Value Function Update Magnitude: 0.52834

Collected Steps per Second: 21,742.17763
Overall Steps per Second: 10,429.39262

Timestep Collection Time: 2.30005
Timestep Consumption Time: 2.49486
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.79491

Cumulative Model Updates: 177,680
Cumulative Timesteps: 1,481,813,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.26128
Policy Entropy: 3.01103
Value Function Loss: 0.00463

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.55901
Value Function Update Magnitude: 0.51469

Collected Steps per Second: 21,775.45220
Overall Steps per Second: 10,435.12184

Timestep Collection Time: 2.29662
Timestep Consumption Time: 2.49585
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.79247

Cumulative Model Updates: 177,686
Cumulative Timesteps: 1,481,863,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1481863926...
Checkpoint 1481863926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,738.82401
Policy Entropy: 2.99932
Value Function Loss: 0.00463

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.55882
Value Function Update Magnitude: 0.50206

Collected Steps per Second: 21,605.01842
Overall Steps per Second: 10,247.58045

Timestep Collection Time: 2.31437
Timestep Consumption Time: 2.56503
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.87940

Cumulative Model Updates: 177,692
Cumulative Timesteps: 1,481,913,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,795.58219
Policy Entropy: 3.00191
Value Function Loss: 0.00475

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.56406
Value Function Update Magnitude: 0.49642

Collected Steps per Second: 21,968.50952
Overall Steps per Second: 10,498.16474

Timestep Collection Time: 2.27671
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.76426

Cumulative Model Updates: 177,698
Cumulative Timesteps: 1,481,963,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1481963944...
Checkpoint 1481963944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.57928
Policy Entropy: 2.98170
Value Function Loss: 0.00477

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.56694
Value Function Update Magnitude: 0.49944

Collected Steps per Second: 21,954.75945
Overall Steps per Second: 10,487.76694

Timestep Collection Time: 2.27777
Timestep Consumption Time: 2.49045
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.76822

Cumulative Model Updates: 177,704
Cumulative Timesteps: 1,482,013,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.17773
Policy Entropy: 2.96999
Value Function Loss: 0.00494

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.57803
Value Function Update Magnitude: 0.50920

Collected Steps per Second: 21,831.01510
Overall Steps per Second: 10,477.89450

Timestep Collection Time: 2.29234
Timestep Consumption Time: 2.48382
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.77615

Cumulative Model Updates: 177,710
Cumulative Timesteps: 1,482,063,996

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1482063996...
Checkpoint 1482063996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274.72923
Policy Entropy: 2.95730
Value Function Loss: 0.00482

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.53398

Collected Steps per Second: 21,540.76981
Overall Steps per Second: 10,320.41666

Timestep Collection Time: 2.32155
Timestep Consumption Time: 2.52399
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.84554

Cumulative Model Updates: 177,716
Cumulative Timesteps: 1,482,114,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,454.01530
Policy Entropy: 2.96368
Value Function Loss: 0.00509

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.57730
Value Function Update Magnitude: 0.56313

Collected Steps per Second: 21,306.65090
Overall Steps per Second: 10,235.32574

Timestep Collection Time: 2.34781
Timestep Consumption Time: 2.53958
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.88739

Cumulative Model Updates: 177,722
Cumulative Timesteps: 1,482,164,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1482164028...
Checkpoint 1482164028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,464.45117
Policy Entropy: 2.96297
Value Function Loss: 0.00501

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.58057
Value Function Update Magnitude: 0.53839

Collected Steps per Second: 21,692.85625
Overall Steps per Second: 10,502.62033

Timestep Collection Time: 2.30620
Timestep Consumption Time: 2.45719
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.76338

Cumulative Model Updates: 177,728
Cumulative Timesteps: 1,482,214,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.19369
Policy Entropy: 2.97116
Value Function Loss: 0.00496

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.57812
Value Function Update Magnitude: 0.53128

Collected Steps per Second: 21,369.74403
Overall Steps per Second: 10,357.10929

Timestep Collection Time: 2.34088
Timestep Consumption Time: 2.48904
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.82992

Cumulative Model Updates: 177,734
Cumulative Timesteps: 1,482,264,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1482264080...
Checkpoint 1482264080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,318.87527
Policy Entropy: 2.97763
Value Function Loss: 0.00464

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.58082
Value Function Update Magnitude: 0.55205

Collected Steps per Second: 21,695.40555
Overall Steps per Second: 10,320.43127

Timestep Collection Time: 2.30537
Timestep Consumption Time: 2.54094
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.84631

Cumulative Model Updates: 177,740
Cumulative Timesteps: 1,482,314,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.71387
Policy Entropy: 2.97669
Value Function Loss: 0.00443

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.57588
Value Function Update Magnitude: 0.52933

Collected Steps per Second: 21,631.21409
Overall Steps per Second: 10,363.04124

Timestep Collection Time: 2.31240
Timestep Consumption Time: 2.51437
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.82677

Cumulative Model Updates: 177,746
Cumulative Timesteps: 1,482,364,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1482364116...
Checkpoint 1482364116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.01970
Policy Entropy: 2.97227
Value Function Loss: 0.00468

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.57860
Value Function Update Magnitude: 0.52313

Collected Steps per Second: 21,277.01850
Overall Steps per Second: 10,221.90432

Timestep Collection Time: 2.35033
Timestep Consumption Time: 2.54191
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.89224

Cumulative Model Updates: 177,752
Cumulative Timesteps: 1,482,414,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,490.44297
Policy Entropy: 2.95411
Value Function Loss: 0.00473

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.51842

Collected Steps per Second: 22,319.13934
Overall Steps per Second: 10,526.65974

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.51122
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.75288

Cumulative Model Updates: 177,758
Cumulative Timesteps: 1,482,464,156

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1482464156...
Checkpoint 1482464156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.16156
Policy Entropy: 2.94626
Value Function Loss: 0.00517

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.58604
Value Function Update Magnitude: 0.51217

Collected Steps per Second: 22,110.05095
Overall Steps per Second: 10,547.35794

Timestep Collection Time: 2.26196
Timestep Consumption Time: 2.47970
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.74166

Cumulative Model Updates: 177,764
Cumulative Timesteps: 1,482,514,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,193.12739
Policy Entropy: 2.94867
Value Function Loss: 0.00477

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.58104
Value Function Update Magnitude: 0.52708

Collected Steps per Second: 22,199.67111
Overall Steps per Second: 10,565.24281

Timestep Collection Time: 2.25355
Timestep Consumption Time: 2.48160
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73515

Cumulative Model Updates: 177,770
Cumulative Timesteps: 1,482,564,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1482564196...
Checkpoint 1482564196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,743.90106
Policy Entropy: 2.97473
Value Function Loss: 0.00459

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.56909
Value Function Update Magnitude: 0.53007

Collected Steps per Second: 21,871.23225
Overall Steps per Second: 10,463.19819

Timestep Collection Time: 2.28684
Timestep Consumption Time: 2.49334
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.78018

Cumulative Model Updates: 177,776
Cumulative Timesteps: 1,482,614,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,487.87341
Policy Entropy: 2.95549
Value Function Loss: 0.00456

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.56899
Value Function Update Magnitude: 0.52981

Collected Steps per Second: 21,701.21642
Overall Steps per Second: 10,520.90001

Timestep Collection Time: 2.30522
Timestep Consumption Time: 2.44970
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.75492

Cumulative Model Updates: 177,782
Cumulative Timesteps: 1,482,664,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1482664238...
Checkpoint 1482664238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.47046
Policy Entropy: 2.96841
Value Function Loss: 0.00446

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.52353

Collected Steps per Second: 21,835.71566
Overall Steps per Second: 10,387.15254

Timestep Collection Time: 2.29093
Timestep Consumption Time: 2.52502
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.81595

Cumulative Model Updates: 177,788
Cumulative Timesteps: 1,482,714,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.77555
Policy Entropy: 2.97375
Value Function Loss: 0.00442

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.56387
Value Function Update Magnitude: 0.50643

Collected Steps per Second: 22,221.09972
Overall Steps per Second: 10,432.63154

Timestep Collection Time: 2.25092
Timestep Consumption Time: 2.54346
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.79438

Cumulative Model Updates: 177,794
Cumulative Timesteps: 1,482,764,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1482764280...
Checkpoint 1482764280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.57555
Policy Entropy: 2.98739
Value Function Loss: 0.00427

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.50140

Collected Steps per Second: 21,833.23121
Overall Steps per Second: 10,508.12574

Timestep Collection Time: 2.29146
Timestep Consumption Time: 2.46962
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.76108

Cumulative Model Updates: 177,800
Cumulative Timesteps: 1,482,814,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,222.48595
Policy Entropy: 2.98995
Value Function Loss: 0.00417

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.51395

Collected Steps per Second: 21,906.62180
Overall Steps per Second: 10,464.92939

Timestep Collection Time: 2.28241
Timestep Consumption Time: 2.49545
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.77786

Cumulative Model Updates: 177,806
Cumulative Timesteps: 1,482,864,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1482864310...
Checkpoint 1482864310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,960.52782
Policy Entropy: 2.97535
Value Function Loss: 0.00427

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.50603

Collected Steps per Second: 20,950.15143
Overall Steps per Second: 10,240.42524

Timestep Collection Time: 2.38795
Timestep Consumption Time: 2.49739
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.88534

Cumulative Model Updates: 177,812
Cumulative Timesteps: 1,482,914,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,459.46494
Policy Entropy: 2.99166
Value Function Loss: 0.00411

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.55072
Value Function Update Magnitude: 0.49019

Collected Steps per Second: 21,432.97239
Overall Steps per Second: 10,329.47038

Timestep Collection Time: 2.33407
Timestep Consumption Time: 2.50897
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.84304

Cumulative Model Updates: 177,818
Cumulative Timesteps: 1,482,964,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1482964364...
Checkpoint 1482964364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.03003
Policy Entropy: 3.00230
Value Function Loss: 0.00453

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.48768

Collected Steps per Second: 20,397.59357
Overall Steps per Second: 10,009.44153

Timestep Collection Time: 2.45137
Timestep Consumption Time: 2.54412
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.99548

Cumulative Model Updates: 177,824
Cumulative Timesteps: 1,483,014,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,692.14631
Policy Entropy: 2.99481
Value Function Loss: 0.00476

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.58089
Value Function Update Magnitude: 0.51137

Collected Steps per Second: 20,931.83974
Overall Steps per Second: 10,162.09453

Timestep Collection Time: 2.38957
Timestep Consumption Time: 2.53245
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.92202

Cumulative Model Updates: 177,830
Cumulative Timesteps: 1,483,064,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1483064384...
Checkpoint 1483064384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.84368
Policy Entropy: 2.99142
Value Function Loss: 0.00511

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.59851
Value Function Update Magnitude: 0.54865

Collected Steps per Second: 21,396.08148
Overall Steps per Second: 10,421.53743

Timestep Collection Time: 2.33688
Timestep Consumption Time: 2.46088
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.79776

Cumulative Model Updates: 177,836
Cumulative Timesteps: 1,483,114,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154.83891
Policy Entropy: 2.96313
Value Function Loss: 0.00506

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.60151
Value Function Update Magnitude: 0.55964

Collected Steps per Second: 21,174.22601
Overall Steps per Second: 10,392.71442

Timestep Collection Time: 2.36240
Timestep Consumption Time: 2.45078
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.81318

Cumulative Model Updates: 177,842
Cumulative Timesteps: 1,483,164,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1483164406...
Checkpoint 1483164406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.73597
Policy Entropy: 2.97378
Value Function Loss: 0.00501

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.59318
Value Function Update Magnitude: 0.55561

Collected Steps per Second: 21,445.72948
Overall Steps per Second: 10,320.24583

Timestep Collection Time: 2.33193
Timestep Consumption Time: 2.51388
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.84581

Cumulative Model Updates: 177,848
Cumulative Timesteps: 1,483,214,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,883.67036
Policy Entropy: 2.96019
Value Function Loss: 0.00503

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.59368
Value Function Update Magnitude: 0.55283

Collected Steps per Second: 21,591.33015
Overall Steps per Second: 10,439.61166

Timestep Collection Time: 2.31695
Timestep Consumption Time: 2.47499
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.79194

Cumulative Model Updates: 177,854
Cumulative Timesteps: 1,483,264,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1483264442...
Checkpoint 1483264442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.88393
Policy Entropy: 2.98305
Value Function Loss: 0.00480

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.59813
Value Function Update Magnitude: 0.54532

Collected Steps per Second: 21,840.48757
Overall Steps per Second: 10,540.01683

Timestep Collection Time: 2.28960
Timestep Consumption Time: 2.45479
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.74439

Cumulative Model Updates: 177,860
Cumulative Timesteps: 1,483,314,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022.42191
Policy Entropy: 2.98125
Value Function Loss: 0.00477

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.59154
Value Function Update Magnitude: 0.54186

Collected Steps per Second: 21,887.61015
Overall Steps per Second: 10,531.26225

Timestep Collection Time: 2.28559
Timestep Consumption Time: 2.46465
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.75024

Cumulative Model Updates: 177,866
Cumulative Timesteps: 1,483,364,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1483364474...
Checkpoint 1483364474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,808.32260
Policy Entropy: 2.98657
Value Function Loss: 0.00453

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11196
Policy Update Magnitude: 0.58476
Value Function Update Magnitude: 0.52530

Collected Steps per Second: 22,209.15186
Overall Steps per Second: 10,573.00479

Timestep Collection Time: 2.25276
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.73205

Cumulative Model Updates: 177,872
Cumulative Timesteps: 1,483,414,506

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,538.36055
Policy Entropy: 2.99149
Value Function Loss: 0.00442

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11454
Policy Update Magnitude: 0.58271
Value Function Update Magnitude: 0.51565

Collected Steps per Second: 21,772.87273
Overall Steps per Second: 10,296.18972

Timestep Collection Time: 2.29708
Timestep Consumption Time: 2.56045
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.85753

Cumulative Model Updates: 177,878
Cumulative Timesteps: 1,483,464,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1483464520...
Checkpoint 1483464520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.69232
Policy Entropy: 2.97970
Value Function Loss: 0.00440

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11306
Policy Update Magnitude: 0.59205
Value Function Update Magnitude: 0.52899

Collected Steps per Second: 21,000.85573
Overall Steps per Second: 10,044.96048

Timestep Collection Time: 2.38124
Timestep Consumption Time: 2.59718
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.97842

Cumulative Model Updates: 177,884
Cumulative Timesteps: 1,483,514,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,951.66866
Policy Entropy: 2.97929
Value Function Loss: 0.00420

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.59264
Value Function Update Magnitude: 0.54276

Collected Steps per Second: 21,186.48735
Overall Steps per Second: 10,167.91824

Timestep Collection Time: 2.36075
Timestep Consumption Time: 2.55825
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.91900

Cumulative Model Updates: 177,890
Cumulative Timesteps: 1,483,564,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1483564544...
Checkpoint 1483564544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,424.33184
Policy Entropy: 2.96864
Value Function Loss: 0.00460

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.59608
Value Function Update Magnitude: 0.53801

Collected Steps per Second: 21,195.58259
Overall Steps per Second: 10,188.46397

Timestep Collection Time: 2.35945
Timestep Consumption Time: 2.54904
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.90849

Cumulative Model Updates: 177,896
Cumulative Timesteps: 1,483,614,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.38803
Policy Entropy: 2.97029
Value Function Loss: 0.00463

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.59666
Value Function Update Magnitude: 0.53922

Collected Steps per Second: 20,583.16329
Overall Steps per Second: 9,979.53089

Timestep Collection Time: 2.42966
Timestep Consumption Time: 2.58160
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 5.01126

Cumulative Model Updates: 177,902
Cumulative Timesteps: 1,483,664,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1483664564...
Checkpoint 1483664564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639.45793
Policy Entropy: 2.96778
Value Function Loss: 0.00488

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.59432
Value Function Update Magnitude: 0.53664

Collected Steps per Second: 19,957.97804
Overall Steps per Second: 9,810.60826

Timestep Collection Time: 2.50617
Timestep Consumption Time: 2.59219
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 5.09836

Cumulative Model Updates: 177,908
Cumulative Timesteps: 1,483,714,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.46350
Policy Entropy: 2.96341
Value Function Loss: 0.00491

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.59447
Value Function Update Magnitude: 0.52643

Collected Steps per Second: 19,749.77796
Overall Steps per Second: 9,922.71403

Timestep Collection Time: 2.53208
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 5.03975

Cumulative Model Updates: 177,914
Cumulative Timesteps: 1,483,764,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1483764590...
Checkpoint 1483764590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.27688
Policy Entropy: 2.95961
Value Function Loss: 0.00528

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.60403
Value Function Update Magnitude: 0.53877

Collected Steps per Second: 19,982.15055
Overall Steps per Second: 9,823.62340

Timestep Collection Time: 2.50293
Timestep Consumption Time: 2.58826
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 5.09120

Cumulative Model Updates: 177,920
Cumulative Timesteps: 1,483,814,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,278.13376
Policy Entropy: 2.96334
Value Function Loss: 0.00528

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.60251
Value Function Update Magnitude: 0.53782

Collected Steps per Second: 19,456.48461
Overall Steps per Second: 9,740.48718

Timestep Collection Time: 2.56994
Timestep Consumption Time: 2.56348
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 5.13342

Cumulative Model Updates: 177,926
Cumulative Timesteps: 1,483,864,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1483864606...
Checkpoint 1483864606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,140.24180
Policy Entropy: 2.96012
Value Function Loss: 0.00518

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.60169
Value Function Update Magnitude: 0.53300

Collected Steps per Second: 20,245.32128
Overall Steps per Second: 9,853.32916

Timestep Collection Time: 2.46990
Timestep Consumption Time: 2.60493
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 5.07483

Cumulative Model Updates: 177,932
Cumulative Timesteps: 1,483,914,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.63205
Policy Entropy: 2.97734
Value Function Loss: 0.00497

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.58805
Value Function Update Magnitude: 0.52781

Collected Steps per Second: 20,009.70878
Overall Steps per Second: 9,912.72218

Timestep Collection Time: 2.49939
Timestep Consumption Time: 2.54585
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 5.04523

Cumulative Model Updates: 177,938
Cumulative Timesteps: 1,483,964,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1483964622...
Checkpoint 1483964622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,941.94554
Policy Entropy: 2.99538
Value Function Loss: 0.00493

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.57727
Value Function Update Magnitude: 0.53658

Collected Steps per Second: 19,826.99319
Overall Steps per Second: 9,887.64500

Timestep Collection Time: 2.52202
Timestep Consumption Time: 2.53520
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 5.05722

Cumulative Model Updates: 177,944
Cumulative Timesteps: 1,484,014,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,488.89788
Policy Entropy: 2.99167
Value Function Loss: 0.00496

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.57704
Value Function Update Magnitude: 0.55182

Collected Steps per Second: 20,106.62389
Overall Steps per Second: 9,796.01272

Timestep Collection Time: 2.48704
Timestep Consumption Time: 2.61769
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 5.10473

Cumulative Model Updates: 177,950
Cumulative Timesteps: 1,484,064,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1484064632...
Checkpoint 1484064632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.95915
Policy Entropy: 2.97611
Value Function Loss: 0.00496

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.58752
Value Function Update Magnitude: 0.57086

Collected Steps per Second: 20,312.54600
Overall Steps per Second: 10,017.64042

Timestep Collection Time: 2.46252
Timestep Consumption Time: 2.53067
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.99319

Cumulative Model Updates: 177,956
Cumulative Timesteps: 1,484,114,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,863.60580
Policy Entropy: 2.95745
Value Function Loss: 0.00536

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.59328
Value Function Update Magnitude: 0.58117

Collected Steps per Second: 20,040.38778
Overall Steps per Second: 9,992.34218

Timestep Collection Time: 2.49506
Timestep Consumption Time: 2.50897
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 5.00403

Cumulative Model Updates: 177,962
Cumulative Timesteps: 1,484,164,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1484164654...
Checkpoint 1484164654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.14998
Policy Entropy: 2.94424
Value Function Loss: 0.00547

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.59293
Value Function Update Magnitude: 0.57682

Collected Steps per Second: 20,285.04750
Overall Steps per Second: 9,812.70928

Timestep Collection Time: 2.46586
Timestep Consumption Time: 2.63162
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 5.09747

Cumulative Model Updates: 177,968
Cumulative Timesteps: 1,484,214,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.22345
Policy Entropy: 2.95829
Value Function Loss: 0.00546

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.58992
Value Function Update Magnitude: 0.56948

Collected Steps per Second: 19,875.30215
Overall Steps per Second: 9,850.29501

Timestep Collection Time: 2.51669
Timestep Consumption Time: 2.56133
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 5.07802

Cumulative Model Updates: 177,974
Cumulative Timesteps: 1,484,264,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1484264694...
Checkpoint 1484264694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,994.63651
Policy Entropy: 2.97256
Value Function Loss: 0.00528

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11306
Policy Update Magnitude: 0.60265
Value Function Update Magnitude: 0.55566

Collected Steps per Second: 20,219.78889
Overall Steps per Second: 10,030.26678

Timestep Collection Time: 2.47490
Timestep Consumption Time: 2.51420
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.98910

Cumulative Model Updates: 177,980
Cumulative Timesteps: 1,484,314,736

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,742.80072
Policy Entropy: 2.98257
Value Function Loss: 0.00493

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.59580
Value Function Update Magnitude: 0.56359

Collected Steps per Second: 20,069.09003
Overall Steps per Second: 9,862.99124

Timestep Collection Time: 2.49179
Timestep Consumption Time: 2.57848
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 5.07027

Cumulative Model Updates: 177,986
Cumulative Timesteps: 1,484,364,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1484364744...
Checkpoint 1484364744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.39058
Policy Entropy: 3.00001
Value Function Loss: 0.00448

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.57437
Value Function Update Magnitude: 0.54152

Collected Steps per Second: 19,854.00250
Overall Steps per Second: 9,966.36859

Timestep Collection Time: 2.51899
Timestep Consumption Time: 2.49909
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 5.01808

Cumulative Model Updates: 177,992
Cumulative Timesteps: 1,484,414,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,028.79755
Policy Entropy: 2.99988
Value Function Loss: 0.00438

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.56828
Value Function Update Magnitude: 0.52800

Collected Steps per Second: 19,852.01335
Overall Steps per Second: 10,077.19963

Timestep Collection Time: 2.51924
Timestep Consumption Time: 2.44365
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.96289

Cumulative Model Updates: 177,998
Cumulative Timesteps: 1,484,464,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1484464768...
Checkpoint 1484464768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506.95760
Policy Entropy: 3.00094
Value Function Loss: 0.00464

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.58539
Value Function Update Magnitude: 0.56229

Collected Steps per Second: 20,457.06417
Overall Steps per Second: 10,295.15049

Timestep Collection Time: 2.44551
Timestep Consumption Time: 2.41386
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.85938

Cumulative Model Updates: 178,004
Cumulative Timesteps: 1,484,514,796

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,094.92052
Policy Entropy: 2.98693
Value Function Loss: 0.00487

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.58899
Value Function Update Magnitude: 0.56420

Collected Steps per Second: 20,676.07252
Overall Steps per Second: 10,368.17187

Timestep Collection Time: 2.41942
Timestep Consumption Time: 2.40535
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.82477

Cumulative Model Updates: 178,010
Cumulative Timesteps: 1,484,564,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1484564820...
Checkpoint 1484564820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,038.61471
Policy Entropy: 2.98146
Value Function Loss: 0.00477

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.57676
Value Function Update Magnitude: 0.56000

Collected Steps per Second: 20,416.50503
Overall Steps per Second: 10,302.12765

Timestep Collection Time: 2.45017
Timestep Consumption Time: 2.40552
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.85570

Cumulative Model Updates: 178,016
Cumulative Timesteps: 1,484,614,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.19668
Policy Entropy: 2.98666
Value Function Loss: 0.00433

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.55531

Collected Steps per Second: 21,617.58310
Overall Steps per Second: 10,503.34195

Timestep Collection Time: 2.31339
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.76134

Cumulative Model Updates: 178,022
Cumulative Timesteps: 1,484,664,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1484664854...
Checkpoint 1484664854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.45248
Policy Entropy: 2.99208
Value Function Loss: 0.00402

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.55882
Value Function Update Magnitude: 0.51908

Collected Steps per Second: 21,255.69011
Overall Steps per Second: 10,333.22769

Timestep Collection Time: 2.35353
Timestep Consumption Time: 2.48774
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.84128

Cumulative Model Updates: 178,028
Cumulative Timesteps: 1,484,714,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.34408
Policy Entropy: 3.00616
Value Function Loss: 0.00386

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.54608
Value Function Update Magnitude: 0.49365

Collected Steps per Second: 21,391.36634
Overall Steps per Second: 10,294.71547

Timestep Collection Time: 2.33739
Timestep Consumption Time: 2.51947
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.85686

Cumulative Model Updates: 178,034
Cumulative Timesteps: 1,484,764,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1484764880...
Checkpoint 1484764880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,879.31865
Policy Entropy: 3.00287
Value Function Loss: 0.00406

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.50613

Collected Steps per Second: 21,175.77950
Overall Steps per Second: 10,237.15635

Timestep Collection Time: 2.36185
Timestep Consumption Time: 2.52369
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.88554

Cumulative Model Updates: 178,040
Cumulative Timesteps: 1,484,814,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,555.46184
Policy Entropy: 2.99676
Value Function Loss: 0.00428

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.52677

Collected Steps per Second: 19,137.77183
Overall Steps per Second: 9,717.81105

Timestep Collection Time: 2.61368
Timestep Consumption Time: 2.53357
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 5.14725

Cumulative Model Updates: 178,046
Cumulative Timesteps: 1,484,864,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1484864914...
Checkpoint 1484864914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,973.95778
Policy Entropy: 2.99710
Value Function Loss: 0.00431

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.53299

Collected Steps per Second: 21,400.57895
Overall Steps per Second: 10,467.24701

Timestep Collection Time: 2.33741
Timestep Consumption Time: 2.44149
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.77891

Cumulative Model Updates: 178,052
Cumulative Timesteps: 1,484,914,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.11493
Policy Entropy: 2.99281
Value Function Loss: 0.00419

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.53819

Collected Steps per Second: 21,463.30170
Overall Steps per Second: 10,287.07042

Timestep Collection Time: 2.33068
Timestep Consumption Time: 2.53213
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.86280

Cumulative Model Updates: 178,058
Cumulative Timesteps: 1,484,964,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1484964960...
Checkpoint 1484964960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,872.25536
Policy Entropy: 2.98021
Value Function Loss: 0.00434

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.51970

Collected Steps per Second: 21,631.13406
Overall Steps per Second: 10,448.98893

Timestep Collection Time: 2.31185
Timestep Consumption Time: 2.47406
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.78592

Cumulative Model Updates: 178,064
Cumulative Timesteps: 1,485,014,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,026.23943
Policy Entropy: 2.96826
Value Function Loss: 0.00451

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.57996
Value Function Update Magnitude: 0.50954

Collected Steps per Second: 22,038.66457
Overall Steps per Second: 10,446.69083

Timestep Collection Time: 2.27019
Timestep Consumption Time: 2.51908
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.78927

Cumulative Model Updates: 178,070
Cumulative Timesteps: 1,485,065,000

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1485065000...
Checkpoint 1485065000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.78317
Policy Entropy: 2.97402
Value Function Loss: 0.00505

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.59017
Value Function Update Magnitude: 0.53103

Collected Steps per Second: 20,869.84830
Overall Steps per Second: 9,987.86492

Timestep Collection Time: 2.39599
Timestep Consumption Time: 2.61048
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 5.00648

Cumulative Model Updates: 178,076
Cumulative Timesteps: 1,485,115,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.31970
Policy Entropy: 2.99122
Value Function Loss: 0.00458

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.58021
Value Function Update Magnitude: 0.55029

Collected Steps per Second: 20,653.61821
Overall Steps per Second: 9,922.72006

Timestep Collection Time: 2.42272
Timestep Consumption Time: 2.62005
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 5.04277

Cumulative Model Updates: 178,082
Cumulative Timesteps: 1,485,165,042

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1485165042...
Checkpoint 1485165042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.56113
Policy Entropy: 2.96573
Value Function Loss: 0.00472

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.57179
Value Function Update Magnitude: 0.53734

Collected Steps per Second: 20,388.49808
Overall Steps per Second: 9,879.56606

Timestep Collection Time: 2.45383
Timestep Consumption Time: 2.61015
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 5.06399

Cumulative Model Updates: 178,088
Cumulative Timesteps: 1,485,215,072

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.09506
Policy Entropy: 2.93539
Value Function Loss: 0.00446

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.57879
Value Function Update Magnitude: 0.52394

Collected Steps per Second: 20,495.47132
Overall Steps per Second: 9,955.74331

Timestep Collection Time: 2.43966
Timestep Consumption Time: 2.58277
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 5.02243

Cumulative Model Updates: 178,094
Cumulative Timesteps: 1,485,265,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1485265074...
Checkpoint 1485265074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.11640
Policy Entropy: 2.90748
Value Function Loss: 0.00468

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.59038
Value Function Update Magnitude: 0.52638

Collected Steps per Second: 20,488.59718
Overall Steps per Second: 10,076.29372

Timestep Collection Time: 2.44155
Timestep Consumption Time: 2.52297
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.96452

Cumulative Model Updates: 178,100
Cumulative Timesteps: 1,485,315,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,795.10167
Policy Entropy: 2.91801
Value Function Loss: 0.00464

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.60126
Value Function Update Magnitude: 0.53951

Collected Steps per Second: 20,273.56624
Overall Steps per Second: 9,852.70325

Timestep Collection Time: 2.46636
Timestep Consumption Time: 2.60859
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 5.07495

Cumulative Model Updates: 178,106
Cumulative Timesteps: 1,485,365,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1485365100...
Checkpoint 1485365100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.13508
Policy Entropy: 2.94580
Value Function Loss: 0.00417

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.59037
Value Function Update Magnitude: 0.54193

Collected Steps per Second: 20,495.51772
Overall Steps per Second: 10,069.40323

Timestep Collection Time: 2.44063
Timestep Consumption Time: 2.52709
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.96772

Cumulative Model Updates: 178,112
Cumulative Timesteps: 1,485,415,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,659.21279
Policy Entropy: 2.94638
Value Function Loss: 0.00458

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.59239
Value Function Update Magnitude: 0.52425

Collected Steps per Second: 20,562.66995
Overall Steps per Second: 10,087.57174

Timestep Collection Time: 2.43305
Timestep Consumption Time: 2.52652
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.95957

Cumulative Model Updates: 178,118
Cumulative Timesteps: 1,485,465,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1485465152...
Checkpoint 1485465152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,889.37326
Policy Entropy: 2.94946
Value Function Loss: 0.00475

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.60190
Value Function Update Magnitude: 0.53873

Collected Steps per Second: 20,966.84007
Overall Steps per Second: 10,227.92358

Timestep Collection Time: 2.38519
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.88956

Cumulative Model Updates: 178,124
Cumulative Timesteps: 1,485,515,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216.61906
Policy Entropy: 2.96874
Value Function Loss: 0.00453

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.58228
Value Function Update Magnitude: 0.53887

Collected Steps per Second: 20,548.76592
Overall Steps per Second: 10,095.43907

Timestep Collection Time: 2.43440
Timestep Consumption Time: 2.52070
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.95511

Cumulative Model Updates: 178,130
Cumulative Timesteps: 1,485,565,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1485565186...
Checkpoint 1485565186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,870.39757
Policy Entropy: 2.99824
Value Function Loss: 0.00455

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.56488
Value Function Update Magnitude: 0.52313

Collected Steps per Second: 20,692.69609
Overall Steps per Second: 10,125.16548

Timestep Collection Time: 2.41737
Timestep Consumption Time: 2.52299
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.94036

Cumulative Model Updates: 178,136
Cumulative Timesteps: 1,485,615,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,662.69508
Policy Entropy: 2.99636
Value Function Loss: 0.00472

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.56982
Value Function Update Magnitude: 0.51937

Collected Steps per Second: 19,929.16333
Overall Steps per Second: 9,769.70865

Timestep Collection Time: 2.50969
Timestep Consumption Time: 2.60981
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 5.11950

Cumulative Model Updates: 178,142
Cumulative Timesteps: 1,485,665,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1485665224...
Checkpoint 1485665224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,131.89503
Policy Entropy: 2.97643
Value Function Loss: 0.00510

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.57421
Value Function Update Magnitude: 0.51649

Collected Steps per Second: 19,817.97972
Overall Steps per Second: 9,672.38766

Timestep Collection Time: 2.52347
Timestep Consumption Time: 2.64692
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 5.17039

Cumulative Model Updates: 178,148
Cumulative Timesteps: 1,485,715,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,965.88917
Policy Entropy: 2.96831
Value Function Loss: 0.00530

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.58209
Value Function Update Magnitude: 0.53651

Collected Steps per Second: 19,587.76320
Overall Steps per Second: 9,624.13437

Timestep Collection Time: 2.55323
Timestep Consumption Time: 2.64329
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 5.19652

Cumulative Model Updates: 178,154
Cumulative Timesteps: 1,485,765,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1485765246...
Checkpoint 1485765246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,497.12865
Policy Entropy: 2.96549
Value Function Loss: 0.00490

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.57811
Value Function Update Magnitude: 0.53317

Collected Steps per Second: 20,396.75373
Overall Steps per Second: 9,863.16690

Timestep Collection Time: 2.45176
Timestep Consumption Time: 2.61841
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 5.07018

Cumulative Model Updates: 178,160
Cumulative Timesteps: 1,485,815,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,352.11951
Policy Entropy: 2.96940
Value Function Loss: 0.00464

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.56942
Value Function Update Magnitude: 0.51068

Collected Steps per Second: 20,503.67225
Overall Steps per Second: 10,058.31497

Timestep Collection Time: 2.43869
Timestep Consumption Time: 2.53253
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.97121

Cumulative Model Updates: 178,166
Cumulative Timesteps: 1,485,865,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1485865256...
Checkpoint 1485865256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,787.62144
Policy Entropy: 2.96371
Value Function Loss: 0.00467

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.56929
Value Function Update Magnitude: 0.51317

Collected Steps per Second: 20,311.41297
Overall Steps per Second: 9,894.01552

Timestep Collection Time: 2.46285
Timestep Consumption Time: 2.59313
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 5.05599

Cumulative Model Updates: 178,172
Cumulative Timesteps: 1,485,915,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,703.55472
Policy Entropy: 2.95583
Value Function Loss: 0.00502

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.51239

Collected Steps per Second: 21,212.75916
Overall Steps per Second: 10,355.10635

Timestep Collection Time: 2.35745
Timestep Consumption Time: 2.47186
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.82931

Cumulative Model Updates: 178,178
Cumulative Timesteps: 1,485,965,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1485965288...
Checkpoint 1485965288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,697.32834
Policy Entropy: 2.96265
Value Function Loss: 0.00518

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.50958

Collected Steps per Second: 21,843.83701
Overall Steps per Second: 10,300.45181

Timestep Collection Time: 2.28952
Timestep Consumption Time: 2.56580
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.85532

Cumulative Model Updates: 178,184
Cumulative Timesteps: 1,486,015,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,461.64611
Policy Entropy: 2.97199
Value Function Loss: 0.00514

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11774
Policy Update Magnitude: 0.58144
Value Function Update Magnitude: 0.52264

Collected Steps per Second: 21,079.94190
Overall Steps per Second: 10,210.78672

Timestep Collection Time: 2.37335
Timestep Consumption Time: 2.52637
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.89972

Cumulative Model Updates: 178,190
Cumulative Timesteps: 1,486,065,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1486065330...
Checkpoint 1486065330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.64328
Policy Entropy: 2.97633
Value Function Loss: 0.00487

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.58118
Value Function Update Magnitude: 0.51705

Collected Steps per Second: 21,627.38624
Overall Steps per Second: 10,407.41019

Timestep Collection Time: 2.31309
Timestep Consumption Time: 2.49368
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.80677

Cumulative Model Updates: 178,196
Cumulative Timesteps: 1,486,115,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,389.94582
Policy Entropy: 2.96691
Value Function Loss: 0.00493

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.58538
Value Function Update Magnitude: 0.52658

Collected Steps per Second: 21,920.92547
Overall Steps per Second: 10,445.20631

Timestep Collection Time: 2.28266
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.79052

Cumulative Model Updates: 178,202
Cumulative Timesteps: 1,486,165,394

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1486165394...
Checkpoint 1486165394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.38588
Policy Entropy: 2.97240
Value Function Loss: 0.00481

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.58545
Value Function Update Magnitude: 0.53086

Collected Steps per Second: 21,089.95054
Overall Steps per Second: 10,203.30398

Timestep Collection Time: 2.37108
Timestep Consumption Time: 2.52988
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.90096

Cumulative Model Updates: 178,208
Cumulative Timesteps: 1,486,215,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,019.31727
Policy Entropy: 2.99042
Value Function Loss: 0.00433

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.52516

Collected Steps per Second: 21,222.47248
Overall Steps per Second: 10,246.37132

Timestep Collection Time: 2.35609
Timestep Consumption Time: 2.52388
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.87997

Cumulative Model Updates: 178,214
Cumulative Timesteps: 1,486,265,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1486265402...
Checkpoint 1486265402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,290.04834
Policy Entropy: 3.00841
Value Function Loss: 0.00421

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.51935

Collected Steps per Second: 21,790.83094
Overall Steps per Second: 10,441.35005

Timestep Collection Time: 2.29537
Timestep Consumption Time: 2.49501
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.79038

Cumulative Model Updates: 178,220
Cumulative Timesteps: 1,486,315,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.27807
Policy Entropy: 3.00756
Value Function Loss: 0.00394

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.49878

Collected Steps per Second: 23,464.69205
Overall Steps per Second: 10,927.06140

Timestep Collection Time: 2.13180
Timestep Consumption Time: 2.44601
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.57781

Cumulative Model Updates: 178,226
Cumulative Timesteps: 1,486,365,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1486365442...
Checkpoint 1486365442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,470.77102
Policy Entropy: 3.00367
Value Function Loss: 0.00397

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.48515

Collected Steps per Second: 22,758.58729
Overall Steps per Second: 10,718.07823

Timestep Collection Time: 2.19706
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.66520

Cumulative Model Updates: 178,232
Cumulative Timesteps: 1,486,415,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.26092
Policy Entropy: 2.98036
Value Function Loss: 0.00433

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.54977
Value Function Update Magnitude: 0.46982

Collected Steps per Second: 23,324.40321
Overall Steps per Second: 10,958.36601

Timestep Collection Time: 2.14428
Timestep Consumption Time: 2.41972
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.56400

Cumulative Model Updates: 178,238
Cumulative Timesteps: 1,486,465,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1486465458...
Checkpoint 1486465458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,447.67158
Policy Entropy: 2.97062
Value Function Loss: 0.00451

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.56934
Value Function Update Magnitude: 0.47610

Collected Steps per Second: 23,128.18881
Overall Steps per Second: 10,775.78731

Timestep Collection Time: 2.16238
Timestep Consumption Time: 2.47876
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.64115

Cumulative Model Updates: 178,244
Cumulative Timesteps: 1,486,515,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,520.10368
Policy Entropy: 2.97503
Value Function Loss: 0.00444

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.57654
Value Function Update Magnitude: 0.49773

Collected Steps per Second: 23,114.07056
Overall Steps per Second: 10,714.08250

Timestep Collection Time: 2.16370
Timestep Consumption Time: 2.50417
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.66788

Cumulative Model Updates: 178,250
Cumulative Timesteps: 1,486,565,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1486565482...
Checkpoint 1486565482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,860.95266
Policy Entropy: 2.97926
Value Function Loss: 0.00412

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.49688

Collected Steps per Second: 22,162.12516
Overall Steps per Second: 10,629.99022

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.44884
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.70612

Cumulative Model Updates: 178,256
Cumulative Timesteps: 1,486,615,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,770.74368
Policy Entropy: 2.95855
Value Function Loss: 0.00386

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.55905
Value Function Update Magnitude: 0.47235

Collected Steps per Second: 22,622.23388
Overall Steps per Second: 10,640.85331

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.70169

Cumulative Model Updates: 178,262
Cumulative Timesteps: 1,486,665,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1486665538...
Checkpoint 1486665538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,315.16151
Policy Entropy: 2.95258
Value Function Loss: 0.00451

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.56677
Value Function Update Magnitude: 0.48646

Collected Steps per Second: 22,578.93053
Overall Steps per Second: 10,682.30551

Timestep Collection Time: 2.21472
Timestep Consumption Time: 2.46648
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.68120

Cumulative Model Updates: 178,268
Cumulative Timesteps: 1,486,715,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,584.18757
Policy Entropy: 2.94892
Value Function Loss: 0.00472

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.58148
Value Function Update Magnitude: 0.52678

Collected Steps per Second: 23,393.24857
Overall Steps per Second: 10,768.48979

Timestep Collection Time: 2.13763
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.64373

Cumulative Model Updates: 178,274
Cumulative Timesteps: 1,486,765,550

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1486765550...
Checkpoint 1486765550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.30468
Policy Entropy: 2.94464
Value Function Loss: 0.00524

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.58868
Value Function Update Magnitude: 0.55327

Collected Steps per Second: 22,790.99478
Overall Steps per Second: 10,597.23811

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.52689
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.72293

Cumulative Model Updates: 178,280
Cumulative Timesteps: 1,486,815,600

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,691.21838
Policy Entropy: 2.94177
Value Function Loss: 0.00517

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.58622
Value Function Update Magnitude: 0.54973

Collected Steps per Second: 22,491.13769
Overall Steps per Second: 10,849.79291

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.38586
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60949

Cumulative Model Updates: 178,286
Cumulative Timesteps: 1,486,865,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1486865612...
Checkpoint 1486865612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.55129
Policy Entropy: 2.95443
Value Function Loss: 0.00525

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.59049
Value Function Update Magnitude: 0.53251

Collected Steps per Second: 22,289.40660
Overall Steps per Second: 10,713.96878

Timestep Collection Time: 2.24358
Timestep Consumption Time: 2.42397
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.66755

Cumulative Model Updates: 178,292
Cumulative Timesteps: 1,486,915,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.82216
Policy Entropy: 2.96650
Value Function Loss: 0.00496

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.58942
Value Function Update Magnitude: 0.54737

Collected Steps per Second: 22,959.30057
Overall Steps per Second: 10,871.08120

Timestep Collection Time: 2.17785
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.59954

Cumulative Model Updates: 178,298
Cumulative Timesteps: 1,486,965,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1486965622...
Checkpoint 1486965622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,338.61031
Policy Entropy: 2.95910
Value Function Loss: 0.00488

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.59521
Value Function Update Magnitude: 0.55479

Collected Steps per Second: 22,190.65394
Overall Steps per Second: 10,606.20259

Timestep Collection Time: 2.25437
Timestep Consumption Time: 2.46230
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.71667

Cumulative Model Updates: 178,304
Cumulative Timesteps: 1,487,015,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.15721
Policy Entropy: 2.94574
Value Function Loss: 0.00473

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.15041
Policy Update Magnitude: 0.59541
Value Function Update Magnitude: 0.54437

Collected Steps per Second: 22,818.76421
Overall Steps per Second: 10,988.10967

Timestep Collection Time: 2.19223
Timestep Consumption Time: 2.36033
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.55256

Cumulative Model Updates: 178,310
Cumulative Timesteps: 1,487,065,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1487065672...
Checkpoint 1487065672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.27977
Policy Entropy: 2.94695
Value Function Loss: 0.00480

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.60137
Value Function Update Magnitude: 0.53195

Collected Steps per Second: 22,221.60708
Overall Steps per Second: 10,679.87122

Timestep Collection Time: 2.25060
Timestep Consumption Time: 2.43223
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.68283

Cumulative Model Updates: 178,316
Cumulative Timesteps: 1,487,115,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.99838
Policy Entropy: 2.95220
Value Function Loss: 0.00471

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.59809
Value Function Update Magnitude: 0.54401

Collected Steps per Second: 22,164.29448
Overall Steps per Second: 10,835.02728

Timestep Collection Time: 2.25687
Timestep Consumption Time: 2.35982
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.61669

Cumulative Model Updates: 178,322
Cumulative Timesteps: 1,487,165,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1487165706...
Checkpoint 1487165706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,461.57409
Policy Entropy: 2.94770
Value Function Loss: 0.00453

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.59043
Value Function Update Magnitude: 0.55672

Collected Steps per Second: 21,838.17984
Overall Steps per Second: 10,671.46454

Timestep Collection Time: 2.29012
Timestep Consumption Time: 2.39640
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.68652

Cumulative Model Updates: 178,328
Cumulative Timesteps: 1,487,215,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,734.14859
Policy Entropy: 2.94782
Value Function Loss: 0.00445

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.58582
Value Function Update Magnitude: 0.53877

Collected Steps per Second: 22,153.73375
Overall Steps per Second: 10,589.65726

Timestep Collection Time: 2.25777
Timestep Consumption Time: 2.46552
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.72329

Cumulative Model Updates: 178,334
Cumulative Timesteps: 1,487,265,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1487265736...
Checkpoint 1487265736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.42787
Policy Entropy: 2.97284
Value Function Loss: 0.00444

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.58155
Value Function Update Magnitude: 0.51567

Collected Steps per Second: 22,776.90134
Overall Steps per Second: 10,867.42047

Timestep Collection Time: 2.19608
Timestep Consumption Time: 2.40666
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.60275

Cumulative Model Updates: 178,340
Cumulative Timesteps: 1,487,315,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,843.39198
Policy Entropy: 2.96700
Value Function Loss: 0.00518

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.59085
Value Function Update Magnitude: 0.53408

Collected Steps per Second: 23,073.07937
Overall Steps per Second: 10,766.20921

Timestep Collection Time: 2.16798
Timestep Consumption Time: 2.47822
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.64620

Cumulative Model Updates: 178,346
Cumulative Timesteps: 1,487,365,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1487365778...
Checkpoint 1487365778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,453.10278
Policy Entropy: 2.96115
Value Function Loss: 0.00506

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.59604
Value Function Update Magnitude: 0.56092

Collected Steps per Second: 22,920.26137
Overall Steps per Second: 10,859.67712

Timestep Collection Time: 2.18296
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.60732

Cumulative Model Updates: 178,352
Cumulative Timesteps: 1,487,415,812

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,774.17801
Policy Entropy: 2.92591
Value Function Loss: 0.00525

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.59763
Value Function Update Magnitude: 0.55521

Collected Steps per Second: 23,422.16281
Overall Steps per Second: 10,941.52319

Timestep Collection Time: 2.13610
Timestep Consumption Time: 2.43658
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.57267

Cumulative Model Updates: 178,358
Cumulative Timesteps: 1,487,465,844

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1487465844...
Checkpoint 1487465844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.71387
Policy Entropy: 2.90403
Value Function Loss: 0.00495

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.60316
Value Function Update Magnitude: 0.54199

Collected Steps per Second: 22,877.01862
Overall Steps per Second: 10,781.95916

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.45227
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.63830

Cumulative Model Updates: 178,364
Cumulative Timesteps: 1,487,515,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,362.37694
Policy Entropy: 2.90118
Value Function Loss: 0.00474

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.59679
Value Function Update Magnitude: 0.51526

Collected Steps per Second: 23,574.25232
Overall Steps per Second: 10,938.07794

Timestep Collection Time: 2.12198
Timestep Consumption Time: 2.45141
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.57338

Cumulative Model Updates: 178,370
Cumulative Timesteps: 1,487,565,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1487565878...
Checkpoint 1487565878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014.99634
Policy Entropy: 2.91193
Value Function Loss: 0.00466

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.58775
Value Function Update Magnitude: 0.49283

Collected Steps per Second: 22,909.00292
Overall Steps per Second: 10,877.23193

Timestep Collection Time: 2.18412
Timestep Consumption Time: 2.41595
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.60007

Cumulative Model Updates: 178,376
Cumulative Timesteps: 1,487,615,914

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.81932
Policy Entropy: 2.92438
Value Function Loss: 0.00436

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.58685
Value Function Update Magnitude: 0.48709

Collected Steps per Second: 22,902.35775
Overall Steps per Second: 10,684.23702

Timestep Collection Time: 2.18371
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.68091

Cumulative Model Updates: 178,382
Cumulative Timesteps: 1,487,665,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1487665926...
Checkpoint 1487665926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.65291
Policy Entropy: 2.92093
Value Function Loss: 0.00452

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.58808
Value Function Update Magnitude: 0.49671

Collected Steps per Second: 22,647.34667
Overall Steps per Second: 10,819.67228

Timestep Collection Time: 2.20821
Timestep Consumption Time: 2.41393
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62214

Cumulative Model Updates: 178,388
Cumulative Timesteps: 1,487,715,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.73178
Policy Entropy: 2.90993
Value Function Loss: 0.00492

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.59829
Value Function Update Magnitude: 0.51590

Collected Steps per Second: 22,834.03682
Overall Steps per Second: 10,768.32644

Timestep Collection Time: 2.19015
Timestep Consumption Time: 2.45402
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.64418

Cumulative Model Updates: 178,394
Cumulative Timesteps: 1,487,765,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1487765946...
Checkpoint 1487765946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.05483
Policy Entropy: 2.93328
Value Function Loss: 0.00541

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.60651
Value Function Update Magnitude: 0.52998

Collected Steps per Second: 22,613.65701
Overall Steps per Second: 10,800.09285

Timestep Collection Time: 2.21282
Timestep Consumption Time: 2.42047
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.63329

Cumulative Model Updates: 178,400
Cumulative Timesteps: 1,487,815,986

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,660.24890
Policy Entropy: 2.94872
Value Function Loss: 0.00504

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.60155
Value Function Update Magnitude: 0.53172

Collected Steps per Second: 23,531.23056
Overall Steps per Second: 10,995.32729

Timestep Collection Time: 2.12552
Timestep Consumption Time: 2.42333
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.54884

Cumulative Model Updates: 178,406
Cumulative Timesteps: 1,487,866,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1487866002...
Checkpoint 1487866002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.65680
Policy Entropy: 2.96328
Value Function Loss: 0.00476

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.60154
Value Function Update Magnitude: 0.54562

Collected Steps per Second: 23,239.86418
Overall Steps per Second: 10,799.03628

Timestep Collection Time: 2.15225
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.63171

Cumulative Model Updates: 178,412
Cumulative Timesteps: 1,487,916,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,280.79467
Policy Entropy: 2.96244
Value Function Loss: 0.00457

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.59843
Value Function Update Magnitude: 0.55066

Collected Steps per Second: 23,262.39837
Overall Steps per Second: 10,719.74379

Timestep Collection Time: 2.15025
Timestep Consumption Time: 2.51591
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.66616

Cumulative Model Updates: 178,418
Cumulative Timesteps: 1,487,966,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1487966040...
Checkpoint 1487966040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.15646
Policy Entropy: 2.95154
Value Function Loss: 0.00477

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.59730
Value Function Update Magnitude: 0.56744

Collected Steps per Second: 22,793.65036
Overall Steps per Second: 10,613.58411

Timestep Collection Time: 2.19368
Timestep Consumption Time: 2.51745
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.71113

Cumulative Model Updates: 178,424
Cumulative Timesteps: 1,488,016,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.56019
Policy Entropy: 2.95174
Value Function Loss: 0.00443

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.58642
Value Function Update Magnitude: 0.56870

Collected Steps per Second: 23,374.39638
Overall Steps per Second: 10,982.89368

Timestep Collection Time: 2.14020
Timestep Consumption Time: 2.41470
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.55490

Cumulative Model Updates: 178,430
Cumulative Timesteps: 1,488,066,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1488066068...
Checkpoint 1488066068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,949.52119
Policy Entropy: 2.94277
Value Function Loss: 0.00495

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.59251
Value Function Update Magnitude: 0.57645

Collected Steps per Second: 22,866.78522
Overall Steps per Second: 10,629.06894

Timestep Collection Time: 2.18701
Timestep Consumption Time: 2.51801
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.70502

Cumulative Model Updates: 178,436
Cumulative Timesteps: 1,488,116,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.31005
Policy Entropy: 2.95307
Value Function Loss: 0.00501

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.60504
Value Function Update Magnitude: 0.60190

Collected Steps per Second: 22,617.71080
Overall Steps per Second: 10,771.53041

Timestep Collection Time: 2.21110
Timestep Consumption Time: 2.43170
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.64279

Cumulative Model Updates: 178,442
Cumulative Timesteps: 1,488,166,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1488166088...
Checkpoint 1488166088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.74876
Policy Entropy: 2.94233
Value Function Loss: 0.00499

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.60239
Value Function Update Magnitude: 0.59949

Collected Steps per Second: 22,225.19348
Overall Steps per Second: 10,643.63985

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.44794
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.69764

Cumulative Model Updates: 178,448
Cumulative Timesteps: 1,488,216,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.19479
Policy Entropy: 2.95568
Value Function Loss: 0.00463

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.58115
Value Function Update Magnitude: 0.55315

Collected Steps per Second: 22,755.66539
Overall Steps per Second: 10,620.62972

Timestep Collection Time: 2.19743
Timestep Consumption Time: 2.51076
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.70820

Cumulative Model Updates: 178,454
Cumulative Timesteps: 1,488,266,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1488266092...
Checkpoint 1488266092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,391.32560
Policy Entropy: 2.97985
Value Function Loss: 0.00451

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.56233
Value Function Update Magnitude: 0.53705

Collected Steps per Second: 22,406.69034
Overall Steps per Second: 10,579.29140

Timestep Collection Time: 2.23228
Timestep Consumption Time: 2.49564
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.72792

Cumulative Model Updates: 178,460
Cumulative Timesteps: 1,488,316,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,247.31878
Policy Entropy: 2.98815
Value Function Loss: 0.00486

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.56516
Value Function Update Magnitude: 0.52308

Collected Steps per Second: 23,413.55714
Overall Steps per Second: 10,858.98878

Timestep Collection Time: 2.13637
Timestep Consumption Time: 2.46995
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60632

Cumulative Model Updates: 178,466
Cumulative Timesteps: 1,488,366,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1488366130...
Checkpoint 1488366130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.15151
Policy Entropy: 2.98757
Value Function Loss: 0.00477

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.57870
Value Function Update Magnitude: 0.52516

Collected Steps per Second: 22,780.62391
Overall Steps per Second: 10,672.98120

Timestep Collection Time: 2.19485
Timestep Consumption Time: 2.48988
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.68473

Cumulative Model Updates: 178,472
Cumulative Timesteps: 1,488,416,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.06380
Policy Entropy: 2.97315
Value Function Loss: 0.00491

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.58616
Value Function Update Magnitude: 0.52359

Collected Steps per Second: 23,223.30633
Overall Steps per Second: 10,908.27341

Timestep Collection Time: 2.15370
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.58514

Cumulative Model Updates: 178,478
Cumulative Timesteps: 1,488,466,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1488466146...
Checkpoint 1488466146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741.94258
Policy Entropy: 2.97573
Value Function Loss: 0.00445

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.56865
Value Function Update Magnitude: 0.50762

Collected Steps per Second: 23,154.78800
Overall Steps per Second: 10,723.65543

Timestep Collection Time: 2.15938
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.66259

Cumulative Model Updates: 178,484
Cumulative Timesteps: 1,488,516,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.53807
Policy Entropy: 2.97446
Value Function Loss: 0.00482

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.57135
Value Function Update Magnitude: 0.52340

Collected Steps per Second: 22,042.53637
Overall Steps per Second: 10,493.76296

Timestep Collection Time: 2.26861
Timestep Consumption Time: 2.49669
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.76531

Cumulative Model Updates: 178,490
Cumulative Timesteps: 1,488,566,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1488566152...
Checkpoint 1488566152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,740.76125
Policy Entropy: 2.95692
Value Function Loss: 0.00476

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.58913
Value Function Update Magnitude: 0.55207

Collected Steps per Second: 22,676.37342
Overall Steps per Second: 10,851.12059

Timestep Collection Time: 2.20538
Timestep Consumption Time: 2.40336
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.60874

Cumulative Model Updates: 178,496
Cumulative Timesteps: 1,488,616,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.17390
Policy Entropy: 2.95147
Value Function Loss: 0.00458

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.58862
Value Function Update Magnitude: 0.56586

Collected Steps per Second: 22,863.71845
Overall Steps per Second: 10,626.50485

Timestep Collection Time: 2.18748
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.70653

Cumulative Model Updates: 178,502
Cumulative Timesteps: 1,488,666,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1488666176...
Checkpoint 1488666176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,469.35727
Policy Entropy: 2.97016
Value Function Loss: 0.00425

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.57201
Value Function Update Magnitude: 0.56279

Collected Steps per Second: 22,853.51224
Overall Steps per Second: 10,614.60070

Timestep Collection Time: 2.18837
Timestep Consumption Time: 2.52325
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.71162

Cumulative Model Updates: 178,508
Cumulative Timesteps: 1,488,716,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,776.55341
Policy Entropy: 3.00529
Value Function Loss: 0.00383

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.54827
Value Function Update Magnitude: 0.53869

Collected Steps per Second: 16,065.93734
Overall Steps per Second: 7,154.46444

Timestep Collection Time: 3.11379
Timestep Consumption Time: 3.87848
PPO Batch Consumption Time: 0.46739
Total Iteration Time: 6.99228

Cumulative Model Updates: 178,514
Cumulative Timesteps: 1,488,766,214

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1488766214...
Checkpoint 1488766214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,919.00487
Policy Entropy: 3.02104
Value Function Loss: 0.00373

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.53079
Value Function Update Magnitude: 0.46634

Collected Steps per Second: 13,886.08932
Overall Steps per Second: 7,943.02753

Timestep Collection Time: 3.60274
Timestep Consumption Time: 2.69561
PPO Batch Consumption Time: 0.30406
Total Iteration Time: 6.29835

Cumulative Model Updates: 178,520
Cumulative Timesteps: 1,488,816,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,041.93222
Policy Entropy: 3.01772
Value Function Loss: 0.00374

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.53020
Value Function Update Magnitude: 0.43726

Collected Steps per Second: 21,085.24224
Overall Steps per Second: 10,269.95585

Timestep Collection Time: 2.37133
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.86857

Cumulative Model Updates: 178,526
Cumulative Timesteps: 1,488,866,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1488866242...
Checkpoint 1488866242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,159.04660
Policy Entropy: 3.00801
Value Function Loss: 0.00407

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.54059
Value Function Update Magnitude: 0.45489

Collected Steps per Second: 21,781.28595
Overall Steps per Second: 10,352.65038

Timestep Collection Time: 2.29564
Timestep Consumption Time: 2.53423
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.82987

Cumulative Model Updates: 178,532
Cumulative Timesteps: 1,488,916,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,499.84610
Policy Entropy: 3.01213
Value Function Loss: 0.00384

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.53890
Value Function Update Magnitude: 0.45282

Collected Steps per Second: 22,397.26587
Overall Steps per Second: 10,479.43554

Timestep Collection Time: 2.23358
Timestep Consumption Time: 2.54015
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.77373

Cumulative Model Updates: 178,538
Cumulative Timesteps: 1,488,966,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1488966270...
Checkpoint 1488966270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,567.40895
Policy Entropy: 3.00629
Value Function Loss: 0.00400

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.53371
Value Function Update Magnitude: 0.45520

Collected Steps per Second: 22,293.97993
Overall Steps per Second: 10,085.67846

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.71564
PPO Batch Consumption Time: 0.31250
Total Iteration Time: 4.95911

Cumulative Model Updates: 178,544
Cumulative Timesteps: 1,489,016,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,577.48858
Policy Entropy: 2.99802
Value Function Loss: 0.00377

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.44874

Collected Steps per Second: 21,184.82059
Overall Steps per Second: 10,031.24619

Timestep Collection Time: 2.36046
Timestep Consumption Time: 2.62456
PPO Batch Consumption Time: 0.31263
Total Iteration Time: 4.98502

Cumulative Model Updates: 178,550
Cumulative Timesteps: 1,489,066,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1489066292...
Checkpoint 1489066292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,180.45018
Policy Entropy: 2.96262
Value Function Loss: 0.00451

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.48068

Collected Steps per Second: 21,511.56741
Overall Steps per Second: 10,232.95126

Timestep Collection Time: 2.32489
Timestep Consumption Time: 2.56246
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.88735

Cumulative Model Updates: 178,556
Cumulative Timesteps: 1,489,116,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,603.51554
Policy Entropy: 2.94747
Value Function Loss: 0.00443

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11276
Policy Update Magnitude: 0.57265
Value Function Update Magnitude: 0.50137

Collected Steps per Second: 20,800.73560
Overall Steps per Second: 9,765.35106

Timestep Collection Time: 2.40501
Timestep Consumption Time: 2.71780
PPO Batch Consumption Time: 0.31740
Total Iteration Time: 5.12281

Cumulative Model Updates: 178,562
Cumulative Timesteps: 1,489,166,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1489166330...
Checkpoint 1489166330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.09432
Policy Entropy: 2.94508
Value Function Loss: 0.00475

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.50645

Collected Steps per Second: 19,978.90960
Overall Steps per Second: 10,140.94918

Timestep Collection Time: 2.50294
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.93110

Cumulative Model Updates: 178,568
Cumulative Timesteps: 1,489,216,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.50776
Policy Entropy: 2.95808
Value Function Loss: 0.00437

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.57118
Value Function Update Magnitude: 0.51290

Collected Steps per Second: 20,244.66883
Overall Steps per Second: 10,154.31991

Timestep Collection Time: 2.46998
Timestep Consumption Time: 2.45442
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.92441

Cumulative Model Updates: 178,574
Cumulative Timesteps: 1,489,266,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1489266340...
Checkpoint 1489266340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.01044
Policy Entropy: 2.95134
Value Function Loss: 0.00438

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.56309
Value Function Update Magnitude: 0.52802

Collected Steps per Second: 19,163.50151
Overall Steps per Second: 9,641.81999

Timestep Collection Time: 2.61038
Timestep Consumption Time: 2.57785
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 5.18823

Cumulative Model Updates: 178,580
Cumulative Timesteps: 1,489,316,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,072.11265
Policy Entropy: 2.95539
Value Function Loss: 0.00444

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.52342

Collected Steps per Second: 17,280.48288
Overall Steps per Second: 8,892.32334

Timestep Collection Time: 2.89541
Timestep Consumption Time: 2.73125
PPO Batch Consumption Time: 0.30807
Total Iteration Time: 5.62665

Cumulative Model Updates: 178,586
Cumulative Timesteps: 1,489,366,398

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1489366398...
Checkpoint 1489366398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,087.78289
Policy Entropy: 2.94677
Value Function Loss: 0.00473

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11554
Policy Update Magnitude: 0.56917
Value Function Update Magnitude: 0.51479

Collected Steps per Second: 22,213.51818
Overall Steps per Second: 10,351.31970

Timestep Collection Time: 2.25106
Timestep Consumption Time: 2.57963
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 4.83069

Cumulative Model Updates: 178,592
Cumulative Timesteps: 1,489,416,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,797.66511
Policy Entropy: 2.96014
Value Function Loss: 0.00466

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.56866
Value Function Update Magnitude: 0.51730

Collected Steps per Second: 19,618.12250
Overall Steps per Second: 9,588.86808

Timestep Collection Time: 2.55070
Timestep Consumption Time: 2.66785
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 5.21855

Cumulative Model Updates: 178,598
Cumulative Timesteps: 1,489,466,442

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1489466442...
Checkpoint 1489466442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,282.18590
Policy Entropy: 2.94432
Value Function Loss: 0.00479

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.57823
Value Function Update Magnitude: 0.51325

Collected Steps per Second: 15,547.50644
Overall Steps per Second: 8,607.03993

Timestep Collection Time: 3.21634
Timestep Consumption Time: 2.59356
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 5.80990

Cumulative Model Updates: 178,604
Cumulative Timesteps: 1,489,516,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.66725
Policy Entropy: 2.93530
Value Function Loss: 0.00478

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.59447
Value Function Update Magnitude: 0.52370

Collected Steps per Second: 14,398.95333
Overall Steps per Second: 6,626.95929

Timestep Collection Time: 3.47539
Timestep Consumption Time: 4.07588
PPO Batch Consumption Time: 0.53439
Total Iteration Time: 7.55128

Cumulative Model Updates: 178,610
Cumulative Timesteps: 1,489,566,490

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1489566490...
Checkpoint 1489566490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,329.85057
Policy Entropy: 2.92556
Value Function Loss: 0.00490

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.59857
Value Function Update Magnitude: 0.53748

Collected Steps per Second: 14,723.33881
Overall Steps per Second: 6,754.75077

Timestep Collection Time: 3.39719
Timestep Consumption Time: 4.00767
PPO Batch Consumption Time: 0.54139
Total Iteration Time: 7.40486

Cumulative Model Updates: 178,616
Cumulative Timesteps: 1,489,616,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.97247
Policy Entropy: 2.92447
Value Function Loss: 0.00485

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.59629
Value Function Update Magnitude: 0.55172

Collected Steps per Second: 14,198.93553
Overall Steps per Second: 6,979.61808

Timestep Collection Time: 3.52181
Timestep Consumption Time: 3.64276
PPO Batch Consumption Time: 0.47557
Total Iteration Time: 7.16458

Cumulative Model Updates: 178,622
Cumulative Timesteps: 1,489,666,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1489666514...
Checkpoint 1489666514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.02914
Policy Entropy: 2.94104
Value Function Loss: 0.00464

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.59127
Value Function Update Magnitude: 0.54951

Collected Steps per Second: 15,331.05648
Overall Steps per Second: 7,135.25178

Timestep Collection Time: 3.26148
Timestep Consumption Time: 3.74626
PPO Batch Consumption Time: 0.49379
Total Iteration Time: 7.00774

Cumulative Model Updates: 178,628
Cumulative Timesteps: 1,489,716,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,528.84665
Policy Entropy: 2.94771
Value Function Loss: 0.00424

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.57992
Value Function Update Magnitude: 0.52791

Collected Steps per Second: 14,990.10141
Overall Steps per Second: 7,236.91666

Timestep Collection Time: 3.33633
Timestep Consumption Time: 3.57434
PPO Batch Consumption Time: 0.45173
Total Iteration Time: 6.91068

Cumulative Model Updates: 178,634
Cumulative Timesteps: 1,489,766,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1489766528...
Checkpoint 1489766528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,840.33181
Policy Entropy: 2.94642
Value Function Loss: 0.00411

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.51841

Collected Steps per Second: 15,354.41434
Overall Steps per Second: 7,067.19961

Timestep Collection Time: 3.25822
Timestep Consumption Time: 3.82068
PPO Batch Consumption Time: 0.50802
Total Iteration Time: 7.07890

Cumulative Model Updates: 178,640
Cumulative Timesteps: 1,489,816,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,915.73130
Policy Entropy: 2.93783
Value Function Loss: 0.00441

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.59778
Value Function Update Magnitude: 0.54691

Collected Steps per Second: 15,828.32034
Overall Steps per Second: 7,526.19960

Timestep Collection Time: 3.16054
Timestep Consumption Time: 3.48638
PPO Batch Consumption Time: 0.45837
Total Iteration Time: 6.64691

Cumulative Model Updates: 178,646
Cumulative Timesteps: 1,489,866,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1489866582...
Checkpoint 1489866582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.09640
Policy Entropy: 2.93235
Value Function Loss: 0.00471

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.60021
Value Function Update Magnitude: 0.54208

Collected Steps per Second: 15,398.73072
Overall Steps per Second: 7,173.47041

Timestep Collection Time: 3.24884
Timestep Consumption Time: 3.72519
PPO Batch Consumption Time: 0.48977
Total Iteration Time: 6.97403

Cumulative Model Updates: 178,652
Cumulative Timesteps: 1,489,916,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,069.06944
Policy Entropy: 2.93924
Value Function Loss: 0.00486

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.59853
Value Function Update Magnitude: 0.50536

Collected Steps per Second: 15,151.86862
Overall Steps per Second: 7,530.98819

Timestep Collection Time: 3.30058
Timestep Consumption Time: 3.33998
PPO Batch Consumption Time: 0.43166
Total Iteration Time: 6.64056

Cumulative Model Updates: 178,658
Cumulative Timesteps: 1,489,966,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1489966620...
Checkpoint 1489966620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.51029
Policy Entropy: 2.94248
Value Function Loss: 0.00464

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.58494
Value Function Update Magnitude: 0.49519

Collected Steps per Second: 16,775.66421
Overall Steps per Second: 7,772.53248

Timestep Collection Time: 2.98158
Timestep Consumption Time: 3.45364
PPO Batch Consumption Time: 0.45097
Total Iteration Time: 6.43523

Cumulative Model Updates: 178,664
Cumulative Timesteps: 1,490,016,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.21060
Policy Entropy: 2.93765
Value Function Loss: 0.00486

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.59069
Value Function Update Magnitude: 0.49407

Collected Steps per Second: 16,035.60544
Overall Steps per Second: 7,252.82384

Timestep Collection Time: 3.11943
Timestep Consumption Time: 3.77747
PPO Batch Consumption Time: 0.50477
Total Iteration Time: 6.89690

Cumulative Model Updates: 178,670
Cumulative Timesteps: 1,490,066,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1490066660...
Checkpoint 1490066660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,065.80383
Policy Entropy: 2.94144
Value Function Loss: 0.00447

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.50579

Collected Steps per Second: 15,738.36202
Overall Steps per Second: 7,139.04484

Timestep Collection Time: 3.17860
Timestep Consumption Time: 3.82878
PPO Batch Consumption Time: 0.50677
Total Iteration Time: 7.00738

Cumulative Model Updates: 178,676
Cumulative Timesteps: 1,490,116,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.42249
Policy Entropy: 2.94190
Value Function Loss: 0.00439

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.56915
Value Function Update Magnitude: 0.50109

Collected Steps per Second: 15,117.39096
Overall Steps per Second: 6,916.36764

Timestep Collection Time: 3.30917
Timestep Consumption Time: 3.92382
PPO Batch Consumption Time: 0.51872
Total Iteration Time: 7.23299

Cumulative Model Updates: 178,682
Cumulative Timesteps: 1,490,166,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1490166712...
Checkpoint 1490166712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,180.81184
Policy Entropy: 2.93526
Value Function Loss: 0.00444

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.58563
Value Function Update Magnitude: 0.50469

Collected Steps per Second: 16,076.27148
Overall Steps per Second: 7,550.21680

Timestep Collection Time: 3.11192
Timestep Consumption Time: 3.51412
PPO Batch Consumption Time: 0.45550
Total Iteration Time: 6.62603

Cumulative Model Updates: 178,688
Cumulative Timesteps: 1,490,216,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,203.06808
Policy Entropy: 2.91455
Value Function Loss: 0.00462

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.60086
Value Function Update Magnitude: 0.52142

Collected Steps per Second: 15,349.45050
Overall Steps per Second: 7,013.61771

Timestep Collection Time: 3.25745
Timestep Consumption Time: 3.87154
PPO Batch Consumption Time: 0.51250
Total Iteration Time: 7.12899

Cumulative Model Updates: 178,694
Cumulative Timesteps: 1,490,266,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1490266740...
Checkpoint 1490266740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.99240
Policy Entropy: 2.93198
Value Function Loss: 0.00451

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.59291
Value Function Update Magnitude: 0.52216

Collected Steps per Second: 15,403.15458
Overall Steps per Second: 7,109.68241

Timestep Collection Time: 3.24726
Timestep Consumption Time: 3.78794
PPO Batch Consumption Time: 0.50254
Total Iteration Time: 7.03519

Cumulative Model Updates: 178,700
Cumulative Timesteps: 1,490,316,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,237.02167
Policy Entropy: 2.94327
Value Function Loss: 0.00433

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11265
Policy Update Magnitude: 0.58322
Value Function Update Magnitude: 0.49299

Collected Steps per Second: 15,219.19682
Overall Steps per Second: 7,352.22004

Timestep Collection Time: 3.28546
Timestep Consumption Time: 3.51548
PPO Batch Consumption Time: 0.45575
Total Iteration Time: 6.80094

Cumulative Model Updates: 178,706
Cumulative Timesteps: 1,490,366,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1490366760...
Checkpoint 1490366760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,369.68798
Policy Entropy: 2.94279
Value Function Loss: 0.00431

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.58531
Value Function Update Magnitude: 0.49744

Collected Steps per Second: 16,059.64803
Overall Steps per Second: 7,405.17475

Timestep Collection Time: 3.11352
Timestep Consumption Time: 3.63879
PPO Batch Consumption Time: 0.47952
Total Iteration Time: 6.75231

Cumulative Model Updates: 178,712
Cumulative Timesteps: 1,490,416,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,086.64815
Policy Entropy: 2.92151
Value Function Loss: 0.00468

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.60022
Value Function Update Magnitude: 0.53639

Collected Steps per Second: 15,460.27183
Overall Steps per Second: 7,065.04066

Timestep Collection Time: 3.23655
Timestep Consumption Time: 3.84592
PPO Batch Consumption Time: 0.50858
Total Iteration Time: 7.08248

Cumulative Model Updates: 178,718
Cumulative Timesteps: 1,490,466,800

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1490466800...
Checkpoint 1490466800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,879.40069
Policy Entropy: 2.92274
Value Function Loss: 0.00496

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.60769
Value Function Update Magnitude: 0.56872

Collected Steps per Second: 15,299.93424
Overall Steps per Second: 7,020.22697

Timestep Collection Time: 3.26864
Timestep Consumption Time: 3.85506
PPO Batch Consumption Time: 0.51071
Total Iteration Time: 7.12370

Cumulative Model Updates: 178,724
Cumulative Timesteps: 1,490,516,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,289.36521
Policy Entropy: 2.93492
Value Function Loss: 0.00482

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.60628
Value Function Update Magnitude: 0.58410

Collected Steps per Second: 15,219.89269
Overall Steps per Second: 7,159.46439

Timestep Collection Time: 3.28557
Timestep Consumption Time: 3.69903
PPO Batch Consumption Time: 0.48339
Total Iteration Time: 6.98460

Cumulative Model Updates: 178,730
Cumulative Timesteps: 1,490,566,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1490566816...
Checkpoint 1490566816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.29636
Policy Entropy: 2.94457
Value Function Loss: 0.00462

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.59640
Value Function Update Magnitude: 0.56006

Collected Steps per Second: 15,959.44510
Overall Steps per Second: 7,556.77324

Timestep Collection Time: 3.13432
Timestep Consumption Time: 3.48517
PPO Batch Consumption Time: 0.45143
Total Iteration Time: 6.61949

Cumulative Model Updates: 178,736
Cumulative Timesteps: 1,490,616,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.21701
Policy Entropy: 2.92608
Value Function Loss: 0.00491

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.60121
Value Function Update Magnitude: 0.54692

Collected Steps per Second: 15,867.65735
Overall Steps per Second: 7,050.28516

Timestep Collection Time: 3.15119
Timestep Consumption Time: 3.94101
PPO Batch Consumption Time: 0.52191
Total Iteration Time: 7.09220

Cumulative Model Updates: 178,742
Cumulative Timesteps: 1,490,666,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1490666840...
Checkpoint 1490666840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.02735
Policy Entropy: 2.92987
Value Function Loss: 0.00481

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.60533
Value Function Update Magnitude: 0.56085

Collected Steps per Second: 15,521.71641
Overall Steps per Second: 7,443.80217

Timestep Collection Time: 3.22271
Timestep Consumption Time: 3.49724
PPO Batch Consumption Time: 0.45290
Total Iteration Time: 6.71995

Cumulative Model Updates: 178,748
Cumulative Timesteps: 1,490,716,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.33209
Policy Entropy: 2.91618
Value Function Loss: 0.00481

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.59942
Value Function Update Magnitude: 0.56441

Collected Steps per Second: 15,580.73429
Overall Steps per Second: 7,187.04280

Timestep Collection Time: 3.21076
Timestep Consumption Time: 3.74982
PPO Batch Consumption Time: 0.49797
Total Iteration Time: 6.96058

Cumulative Model Updates: 178,754
Cumulative Timesteps: 1,490,766,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1490766888...
Checkpoint 1490766888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983.06495
Policy Entropy: 2.92903
Value Function Loss: 0.00471

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.60138
Value Function Update Magnitude: 0.56665

Collected Steps per Second: 15,577.17918
Overall Steps per Second: 7,635.28878

Timestep Collection Time: 3.21111
Timestep Consumption Time: 3.34005
PPO Batch Consumption Time: 0.43092
Total Iteration Time: 6.55116

Cumulative Model Updates: 178,760
Cumulative Timesteps: 1,490,816,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,813.93363
Policy Entropy: 2.92767
Value Function Loss: 0.00475

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.60134
Value Function Update Magnitude: 0.57552

Collected Steps per Second: 15,606.34403
Overall Steps per Second: 7,004.54134

Timestep Collection Time: 3.20549
Timestep Consumption Time: 3.93645
PPO Batch Consumption Time: 0.52137
Total Iteration Time: 7.14194

Cumulative Model Updates: 178,766
Cumulative Timesteps: 1,490,866,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1490866934...
Checkpoint 1490866934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,633.09779
Policy Entropy: 2.93984
Value Function Loss: 0.00439

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.56772

Collected Steps per Second: 14,574.02168
Overall Steps per Second: 8,349.72520

Timestep Collection Time: 3.43159
Timestep Consumption Time: 2.55807
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 5.98966

Cumulative Model Updates: 178,772
Cumulative Timesteps: 1,490,916,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.57429
Policy Entropy: 2.94305
Value Function Loss: 0.00422

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.52078

Collected Steps per Second: 17,410.86386
Overall Steps per Second: 9,192.98140

Timestep Collection Time: 2.87453
Timestep Consumption Time: 2.56963
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 5.44415

Cumulative Model Updates: 178,778
Cumulative Timesteps: 1,490,966,994

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1490966994...
Checkpoint 1490966994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,786.82921
Policy Entropy: 2.92994
Value Function Loss: 0.00420

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.56921
Value Function Update Magnitude: 0.50615

Collected Steps per Second: 18,224.76292
Overall Steps per Second: 9,452.38962

Timestep Collection Time: 2.74429
Timestep Consumption Time: 2.54686
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 5.29115

Cumulative Model Updates: 178,784
Cumulative Timesteps: 1,491,017,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,497.09616
Policy Entropy: 2.92094
Value Function Loss: 0.00448

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.50937

Collected Steps per Second: 21,106.38062
Overall Steps per Second: 10,012.88555

Timestep Collection Time: 2.36980
Timestep Consumption Time: 2.62556
PPO Batch Consumption Time: 0.31417
Total Iteration Time: 4.99536

Cumulative Model Updates: 178,790
Cumulative Timesteps: 1,491,067,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1491067026...
Checkpoint 1491067026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.75906
Policy Entropy: 2.91571
Value Function Loss: 0.00452

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.57912
Value Function Update Magnitude: 0.51143

Collected Steps per Second: 21,521.65186
Overall Steps per Second: 10,217.27623

Timestep Collection Time: 2.32436
Timestep Consumption Time: 2.57166
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.89602

Cumulative Model Updates: 178,796
Cumulative Timesteps: 1,491,117,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.53393
Policy Entropy: 2.92557
Value Function Loss: 0.00463

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.58066
Value Function Update Magnitude: 0.51370

Collected Steps per Second: 20,799.02585
Overall Steps per Second: 10,110.03867

Timestep Collection Time: 2.40521
Timestep Consumption Time: 2.54294
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.94815

Cumulative Model Updates: 178,802
Cumulative Timesteps: 1,491,167,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1491167076...
Checkpoint 1491167076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.35629
Policy Entropy: 2.93281
Value Function Loss: 0.00460

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.58344
Value Function Update Magnitude: 0.52495

Collected Steps per Second: 21,825.28297
Overall Steps per Second: 10,089.92977

Timestep Collection Time: 2.29156
Timestep Consumption Time: 2.66526
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.95682

Cumulative Model Updates: 178,808
Cumulative Timesteps: 1,491,217,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,060.17870
Policy Entropy: 2.92069
Value Function Loss: 0.00468

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.58336
Value Function Update Magnitude: 0.54081

Collected Steps per Second: 20,275.59794
Overall Steps per Second: 9,751.87443

Timestep Collection Time: 2.46622
Timestep Consumption Time: 2.66141
PPO Batch Consumption Time: 0.31055
Total Iteration Time: 5.12763

Cumulative Model Updates: 178,814
Cumulative Timesteps: 1,491,267,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1491267094...
Checkpoint 1491267094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.60788
Policy Entropy: 2.91634
Value Function Loss: 0.00456

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.58854
Value Function Update Magnitude: 0.55407

Collected Steps per Second: 20,225.74552
Overall Steps per Second: 9,929.87606

Timestep Collection Time: 2.47309
Timestep Consumption Time: 2.56424
PPO Batch Consumption Time: 0.30044
Total Iteration Time: 5.03732

Cumulative Model Updates: 178,820
Cumulative Timesteps: 1,491,317,114

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,904.19671
Policy Entropy: 2.90781
Value Function Loss: 0.00497

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.60140
Value Function Update Magnitude: 0.57127

Collected Steps per Second: 21,839.78751
Overall Steps per Second: 10,415.68390

Timestep Collection Time: 2.29041
Timestep Consumption Time: 2.51216
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.80257

Cumulative Model Updates: 178,826
Cumulative Timesteps: 1,491,367,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1491367136...
Checkpoint 1491367136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,101.53299
Policy Entropy: 2.92647
Value Function Loss: 0.00479

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.59531
Value Function Update Magnitude: 0.56698

Collected Steps per Second: 21,433.59497
Overall Steps per Second: 10,394.42205

Timestep Collection Time: 2.33316
Timestep Consumption Time: 2.47788
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.81104

Cumulative Model Updates: 178,832
Cumulative Timesteps: 1,491,417,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,116.09560
Policy Entropy: 2.92895
Value Function Loss: 0.00460

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.57992
Value Function Update Magnitude: 0.54745

Collected Steps per Second: 20,696.21518
Overall Steps per Second: 10,078.38473

Timestep Collection Time: 2.41600
Timestep Consumption Time: 2.54531
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.96131

Cumulative Model Updates: 178,838
Cumulative Timesteps: 1,491,467,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1491467146...
Checkpoint 1491467146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.47544
Policy Entropy: 2.93696
Value Function Loss: 0.00429

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11652
Policy Update Magnitude: 0.58016
Value Function Update Magnitude: 0.50085

Collected Steps per Second: 21,053.64694
Overall Steps per Second: 10,275.23397

Timestep Collection Time: 2.37612
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.86860

Cumulative Model Updates: 178,844
Cumulative Timesteps: 1,491,517,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,917.14022
Policy Entropy: 2.92734
Value Function Loss: 0.00450

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.58973
Value Function Update Magnitude: 0.49955

Collected Steps per Second: 21,344.97308
Overall Steps per Second: 10,243.61310

Timestep Collection Time: 2.34388
Timestep Consumption Time: 2.54014
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.88402

Cumulative Model Updates: 178,850
Cumulative Timesteps: 1,491,567,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1491567202...
Checkpoint 1491567202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.37312
Policy Entropy: 2.91272
Value Function Loss: 0.00439

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.58135
Value Function Update Magnitude: 0.50842

Collected Steps per Second: 22,480.15728
Overall Steps per Second: 10,241.69982

Timestep Collection Time: 2.22507
Timestep Consumption Time: 2.65888
PPO Batch Consumption Time: 0.30108
Total Iteration Time: 4.88395

Cumulative Model Updates: 178,856
Cumulative Timesteps: 1,491,617,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,530.37799
Policy Entropy: 2.90229
Value Function Loss: 0.00444

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.57984
Value Function Update Magnitude: 0.49286

Collected Steps per Second: 20,332.21841
Overall Steps per Second: 10,026.33693

Timestep Collection Time: 2.45925
Timestep Consumption Time: 2.52782
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.98707

Cumulative Model Updates: 178,862
Cumulative Timesteps: 1,491,667,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1491667224...
Checkpoint 1491667224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,781.71342
Policy Entropy: 2.90907
Value Function Loss: 0.00434

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.57845
Value Function Update Magnitude: 0.49187

Collected Steps per Second: 21,324.16766
Overall Steps per Second: 10,242.76868

Timestep Collection Time: 2.34673
Timestep Consumption Time: 2.53887
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.88559

Cumulative Model Updates: 178,868
Cumulative Timesteps: 1,491,717,266

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,661.93685
Policy Entropy: 2.92070
Value Function Loss: 0.00439

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.57686
Value Function Update Magnitude: 0.49913

Collected Steps per Second: 22,063.17118
Overall Steps per Second: 10,270.70735

Timestep Collection Time: 2.26695
Timestep Consumption Time: 2.60283
PPO Batch Consumption Time: 0.30461
Total Iteration Time: 4.86977

Cumulative Model Updates: 178,874
Cumulative Timesteps: 1,491,767,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1491767282...
Checkpoint 1491767282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,967.83297
Policy Entropy: 2.92412
Value Function Loss: 0.00444

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.57818
Value Function Update Magnitude: 0.51303

Collected Steps per Second: 21,947.84491
Overall Steps per Second: 10,202.65476

Timestep Collection Time: 2.27886
Timestep Consumption Time: 2.62340
PPO Batch Consumption Time: 0.31041
Total Iteration Time: 4.90225

Cumulative Model Updates: 178,880
Cumulative Timesteps: 1,491,817,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,068.11718
Policy Entropy: 2.91772
Value Function Loss: 0.00438

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.58507
Value Function Update Magnitude: 0.52554

Collected Steps per Second: 21,468.25899
Overall Steps per Second: 10,351.96173

Timestep Collection Time: 2.33042
Timestep Consumption Time: 2.50248
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.83290

Cumulative Model Updates: 178,886
Cumulative Timesteps: 1,491,867,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1491867328...
Checkpoint 1491867328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.52645
Policy Entropy: 2.89655
Value Function Loss: 0.00430

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.58188
Value Function Update Magnitude: 0.50737

Collected Steps per Second: 18,393.83863
Overall Steps per Second: 9,323.90174

Timestep Collection Time: 2.71950
Timestep Consumption Time: 2.64542
PPO Batch Consumption Time: 0.30790
Total Iteration Time: 5.36492

Cumulative Model Updates: 178,892
Cumulative Timesteps: 1,491,917,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,633.70880
Policy Entropy: 2.89932
Value Function Loss: 0.00430

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.58496
Value Function Update Magnitude: 0.49358

Collected Steps per Second: 20,681.93137
Overall Steps per Second: 10,147.20467

Timestep Collection Time: 2.41805
Timestep Consumption Time: 2.51040
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.92845

Cumulative Model Updates: 178,898
Cumulative Timesteps: 1,491,967,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1491967360...
Checkpoint 1491967360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,432.03452
Policy Entropy: 2.89449
Value Function Loss: 0.00464

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.59711
Value Function Update Magnitude: 0.52271

Collected Steps per Second: 20,544.83999
Overall Steps per Second: 9,917.49696

Timestep Collection Time: 2.43448
Timestep Consumption Time: 2.60873
PPO Batch Consumption Time: 0.30744
Total Iteration Time: 5.04321

Cumulative Model Updates: 178,904
Cumulative Timesteps: 1,492,017,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,529.31812
Policy Entropy: 2.91252
Value Function Loss: 0.00471

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.59901
Value Function Update Magnitude: 0.54823

Collected Steps per Second: 21,604.10501
Overall Steps per Second: 10,464.92124

Timestep Collection Time: 2.31613
Timestep Consumption Time: 2.46536
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.78150

Cumulative Model Updates: 178,910
Cumulative Timesteps: 1,492,067,414

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1492067414...
Checkpoint 1492067414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,821.13279
Policy Entropy: 2.89861
Value Function Loss: 0.00480

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.61155
Value Function Update Magnitude: 0.54456

Collected Steps per Second: 22,209.10830
Overall Steps per Second: 10,415.68126

Timestep Collection Time: 2.25223
Timestep Consumption Time: 2.55015
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.80237

Cumulative Model Updates: 178,916
Cumulative Timesteps: 1,492,117,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.90732
Policy Entropy: 2.89654
Value Function Loss: 0.00489

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.61428
Value Function Update Magnitude: 0.53435

Collected Steps per Second: 22,574.09722
Overall Steps per Second: 10,659.35941

Timestep Collection Time: 2.21493
Timestep Consumption Time: 2.47579
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.69071

Cumulative Model Updates: 178,922
Cumulative Timesteps: 1,492,167,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1492167434...
Checkpoint 1492167434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.53303
Policy Entropy: 2.89435
Value Function Loss: 0.00531

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.62975
Value Function Update Magnitude: 0.56807

Collected Steps per Second: 22,427.56663
Overall Steps per Second: 10,681.98814

Timestep Collection Time: 2.23029
Timestep Consumption Time: 2.45236
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.68265

Cumulative Model Updates: 178,928
Cumulative Timesteps: 1,492,217,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.85261
Policy Entropy: 2.91174
Value Function Loss: 0.00500

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.61119
Value Function Update Magnitude: 0.57497

Collected Steps per Second: 21,345.97587
Overall Steps per Second: 10,026.88334

Timestep Collection Time: 2.34358
Timestep Consumption Time: 2.64561
PPO Batch Consumption Time: 0.31112
Total Iteration Time: 4.98919

Cumulative Model Updates: 178,934
Cumulative Timesteps: 1,492,267,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1492267480...
Checkpoint 1492267480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,214.26092
Policy Entropy: 2.91061
Value Function Loss: 0.00488

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.59757
Value Function Update Magnitude: 0.55897

Collected Steps per Second: 22,388.47300
Overall Steps per Second: 10,569.78801

Timestep Collection Time: 2.23356
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.73103

Cumulative Model Updates: 178,940
Cumulative Timesteps: 1,492,317,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.97214
Policy Entropy: 2.93617
Value Function Loss: 0.00442

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.59247
Value Function Update Magnitude: 0.54926

Collected Steps per Second: 21,308.17199
Overall Steps per Second: 10,232.51479

Timestep Collection Time: 2.34764
Timestep Consumption Time: 2.54109
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.88873

Cumulative Model Updates: 178,946
Cumulative Timesteps: 1,492,367,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1492367510...
Checkpoint 1492367510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,931.30286
Policy Entropy: 2.92928
Value Function Loss: 0.00481

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.59975
Value Function Update Magnitude: 0.57442

Collected Steps per Second: 21,420.54134
Overall Steps per Second: 10,388.83985

Timestep Collection Time: 2.33524
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.81497

Cumulative Model Updates: 178,952
Cumulative Timesteps: 1,492,417,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,266.47478
Policy Entropy: 2.94234
Value Function Loss: 0.00488

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.60530
Value Function Update Magnitude: 0.57524

Collected Steps per Second: 22,827.52384
Overall Steps per Second: 10,616.02663

Timestep Collection Time: 2.19156
Timestep Consumption Time: 2.52093
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.71250

Cumulative Model Updates: 178,958
Cumulative Timesteps: 1,492,467,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1492467560...
Checkpoint 1492467560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.06040
Policy Entropy: 2.92683
Value Function Loss: 0.00498

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.59619
Value Function Update Magnitude: 0.54178

Collected Steps per Second: 22,540.89920
Overall Steps per Second: 10,561.39561

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.51704
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.73612

Cumulative Model Updates: 178,964
Cumulative Timesteps: 1,492,517,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.86002
Policy Entropy: 2.92755
Value Function Loss: 0.00492

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.60054
Value Function Update Magnitude: 0.52644

Collected Steps per Second: 22,115.05186
Overall Steps per Second: 10,388.43680

Timestep Collection Time: 2.26145
Timestep Consumption Time: 2.55275
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.81420

Cumulative Model Updates: 178,970
Cumulative Timesteps: 1,492,567,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1492567592...
Checkpoint 1492567592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,922.91044
Policy Entropy: 2.92009
Value Function Loss: 0.00519

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.61310
Value Function Update Magnitude: 0.53014

Collected Steps per Second: 20,405.32257
Overall Steps per Second: 10,222.50967

Timestep Collection Time: 2.45054
Timestep Consumption Time: 2.44102
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.89156

Cumulative Model Updates: 178,976
Cumulative Timesteps: 1,492,617,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.18489
Policy Entropy: 2.91522
Value Function Loss: 0.00525

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.62456
Value Function Update Magnitude: 0.57283

Collected Steps per Second: 21,435.53839
Overall Steps per Second: 10,037.01739

Timestep Collection Time: 2.33397
Timestep Consumption Time: 2.65057
PPO Batch Consumption Time: 0.31628
Total Iteration Time: 4.98455

Cumulative Model Updates: 178,982
Cumulative Timesteps: 1,492,667,626

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1492667626...
Checkpoint 1492667626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,360.32753
Policy Entropy: 2.90999
Value Function Loss: 0.00528

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.62287
Value Function Update Magnitude: 0.59890

Collected Steps per Second: 22,003.34049
Overall Steps per Second: 10,373.96899

Timestep Collection Time: 2.27302
Timestep Consumption Time: 2.54809
PPO Batch Consumption Time: 0.30089
Total Iteration Time: 4.82111

Cumulative Model Updates: 178,988
Cumulative Timesteps: 1,492,717,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.48199
Policy Entropy: 2.92941
Value Function Loss: 0.00467

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.60570
Value Function Update Magnitude: 0.56026

Collected Steps per Second: 22,375.42730
Overall Steps per Second: 10,443.61277

Timestep Collection Time: 2.23513
Timestep Consumption Time: 2.55363
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.78876

Cumulative Model Updates: 178,994
Cumulative Timesteps: 1,492,767,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1492767652...
Checkpoint 1492767652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.46852
Policy Entropy: 2.94238
Value Function Loss: 0.00463

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.59027
Value Function Update Magnitude: 0.51933

Collected Steps per Second: 22,089.59944
Overall Steps per Second: 10,604.64184

Timestep Collection Time: 2.26423
Timestep Consumption Time: 2.45219
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.71643

Cumulative Model Updates: 179,000
Cumulative Timesteps: 1,492,817,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,522.70126
Policy Entropy: 2.95624
Value Function Loss: 0.00455

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.58622
Value Function Update Magnitude: 0.50256

Collected Steps per Second: 23,016.85367
Overall Steps per Second: 10,544.83125

Timestep Collection Time: 2.17276
Timestep Consumption Time: 2.56985
PPO Batch Consumption Time: 0.30280
Total Iteration Time: 4.74261

Cumulative Model Updates: 179,006
Cumulative Timesteps: 1,492,867,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1492867678...
Checkpoint 1492867678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078.98871
Policy Entropy: 2.95924
Value Function Loss: 0.00463

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.58298
Value Function Update Magnitude: 0.51208

Collected Steps per Second: 22,720.00465
Overall Steps per Second: 10,338.05348

Timestep Collection Time: 2.20141
Timestep Consumption Time: 2.63664
PPO Batch Consumption Time: 0.30950
Total Iteration Time: 4.83805

Cumulative Model Updates: 179,012
Cumulative Timesteps: 1,492,917,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,808.52274
Policy Entropy: 2.95912
Value Function Loss: 0.00438

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.57244
Value Function Update Magnitude: 0.49458

Collected Steps per Second: 22,339.02683
Overall Steps per Second: 10,656.00699

Timestep Collection Time: 2.23832
Timestep Consumption Time: 2.45405
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.69238

Cumulative Model Updates: 179,018
Cumulative Timesteps: 1,492,967,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1492967696...
Checkpoint 1492967696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.66602
Policy Entropy: 2.97368
Value Function Loss: 0.00407

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.55197
Value Function Update Magnitude: 0.48750

Collected Steps per Second: 21,081.87451
Overall Steps per Second: 10,159.54374

Timestep Collection Time: 2.37322
Timestep Consumption Time: 2.55141
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.92463

Cumulative Model Updates: 179,024
Cumulative Timesteps: 1,493,017,728

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,276.43552
Policy Entropy: 2.95611
Value Function Loss: 0.00402

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.48280

Collected Steps per Second: 20,816.90168
Overall Steps per Second: 9,985.61421

Timestep Collection Time: 2.40237
Timestep Consumption Time: 2.60583
PPO Batch Consumption Time: 0.30526
Total Iteration Time: 5.00820

Cumulative Model Updates: 179,030
Cumulative Timesteps: 1,493,067,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1493067738...
Checkpoint 1493067738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,013.17366
Policy Entropy: 2.95146
Value Function Loss: 0.00402

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.47775

Collected Steps per Second: 21,694.75772
Overall Steps per Second: 10,365.56366

Timestep Collection Time: 2.30498
Timestep Consumption Time: 2.51926
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.82424

Cumulative Model Updates: 179,036
Cumulative Timesteps: 1,493,117,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,182.52690
Policy Entropy: 2.93573
Value Function Loss: 0.00393

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.56260
Value Function Update Magnitude: 0.47665

Collected Steps per Second: 21,973.57531
Overall Steps per Second: 10,583.73093

Timestep Collection Time: 2.27655
Timestep Consumption Time: 2.44995
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.72650

Cumulative Model Updates: 179,042
Cumulative Timesteps: 1,493,167,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1493167768...
Checkpoint 1493167768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.69091
Policy Entropy: 2.95760
Value Function Loss: 0.00411

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.56425
Value Function Update Magnitude: 0.46557

Collected Steps per Second: 21,833.37470
Overall Steps per Second: 10,285.41375

Timestep Collection Time: 2.29016
Timestep Consumption Time: 2.57128
PPO Batch Consumption Time: 0.30166
Total Iteration Time: 4.86145

Cumulative Model Updates: 179,048
Cumulative Timesteps: 1,493,217,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,998.56630
Policy Entropy: 2.95238
Value Function Loss: 0.00420

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.56957
Value Function Update Magnitude: 0.46567

Collected Steps per Second: 20,125.90561
Overall Steps per Second: 9,680.37762

Timestep Collection Time: 2.48535
Timestep Consumption Time: 2.68180
PPO Batch Consumption Time: 0.31065
Total Iteration Time: 5.16715

Cumulative Model Updates: 179,054
Cumulative Timesteps: 1,493,267,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1493267790...
Checkpoint 1493267790 saved!
