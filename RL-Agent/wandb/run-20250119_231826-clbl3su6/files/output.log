Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,384.84068
Policy Entropy: 1.98983
Value Function Loss: 0.09232

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00096
Policy Update Magnitude: 0.12790
Value Function Update Magnitude: 0.10216

Collected Steps per Second: 18,630.54680
Overall Steps per Second: 12,677.80900

Timestep Collection Time: 2.68484
Timestep Consumption Time: 1.26064
PPO Batch Consumption Time: 0.33369
Total Iteration Time: 3.94548

Cumulative Model Updates: 116,720
Cumulative Timesteps: 974,255,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,805.48417
Policy Entropy: 1.98406
Value Function Loss: 0.07869

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.28853
Value Function Update Magnitude: 0.15888

Collected Steps per Second: 20,686.44468
Overall Steps per Second: 11,769.30902

Timestep Collection Time: 2.41772
Timestep Consumption Time: 1.83181
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.24953

Cumulative Model Updates: 116,724
Cumulative Timesteps: 974,305,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 974305634...
Checkpoint 974305634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,686.75041
Policy Entropy: 1.95761
Value Function Loss: 0.07507

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07863
Policy Update Magnitude: 0.30123
Value Function Update Magnitude: 0.12230

Collected Steps per Second: 20,069.41418
Overall Steps per Second: 11,643.76063

Timestep Collection Time: 2.49165
Timestep Consumption Time: 1.80301
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.29466

Cumulative Model Updates: 116,728
Cumulative Timesteps: 974,355,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,642.53975
Policy Entropy: 1.93953
Value Function Loss: 0.07377

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.42279
Value Function Update Magnitude: 0.27964

Collected Steps per Second: 21,138.85899
Overall Steps per Second: 10,481.43113

Timestep Collection Time: 2.36645
Timestep Consumption Time: 2.40618
PPO Batch Consumption Time: 0.27643
Total Iteration Time: 4.77263

Cumulative Model Updates: 116,734
Cumulative Timesteps: 974,405,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 974405664...
Checkpoint 974405664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,125.40358
Policy Entropy: 1.91886
Value Function Loss: 0.06662

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.39959
Value Function Update Magnitude: 0.26505

Collected Steps per Second: 21,264.76481
Overall Steps per Second: 10,361.80851

Timestep Collection Time: 2.35319
Timestep Consumption Time: 2.47608
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.82927

Cumulative Model Updates: 116,740
Cumulative Timesteps: 974,455,704

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,929.08664
Policy Entropy: 1.91977
Value Function Loss: 0.06395

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.38327
Value Function Update Magnitude: 0.20565

Collected Steps per Second: 21,663.38904
Overall Steps per Second: 10,461.43892

Timestep Collection Time: 2.30823
Timestep Consumption Time: 2.47161
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.77984

Cumulative Model Updates: 116,746
Cumulative Timesteps: 974,505,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 974505708...
Checkpoint 974505708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,001.17324
Policy Entropy: 1.91195
Value Function Loss: 0.06662

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07759
Policy Update Magnitude: 0.37050
Value Function Update Magnitude: 0.16864

Collected Steps per Second: 21,192.03681
Overall Steps per Second: 10,502.02428

Timestep Collection Time: 2.35938
Timestep Consumption Time: 2.40161
PPO Batch Consumption Time: 0.27616
Total Iteration Time: 4.76099

Cumulative Model Updates: 116,752
Cumulative Timesteps: 974,555,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,176.65164
Policy Entropy: 1.89885
Value Function Loss: 0.06465

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.36300
Value Function Update Magnitude: 0.19120

Collected Steps per Second: 21,398.97980
Overall Steps per Second: 10,463.70709

Timestep Collection Time: 2.33778
Timestep Consumption Time: 2.44313
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.78091

Cumulative Model Updates: 116,758
Cumulative Timesteps: 974,605,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 974605734...
Checkpoint 974605734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,055.54963
Policy Entropy: 1.88419
Value Function Loss: 0.06871

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.36198
Value Function Update Magnitude: 0.19564

Collected Steps per Second: 21,122.80348
Overall Steps per Second: 10,221.65334

Timestep Collection Time: 2.36730
Timestep Consumption Time: 2.52467
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.89197

Cumulative Model Updates: 116,764
Cumulative Timesteps: 974,655,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,164.19537
Policy Entropy: 1.88575
Value Function Loss: 0.07092

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.35931
Value Function Update Magnitude: 0.24794

Collected Steps per Second: 21,972.47985
Overall Steps per Second: 10,471.26140

Timestep Collection Time: 2.27667
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.77727

Cumulative Model Updates: 116,770
Cumulative Timesteps: 974,705,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 974705762...
Checkpoint 974705762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,894.65090
Policy Entropy: 1.88280
Value Function Loss: 0.07188

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.36155
Value Function Update Magnitude: 0.26108

Collected Steps per Second: 21,687.42506
Overall Steps per Second: 10,582.76486

Timestep Collection Time: 2.30705
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.72788

Cumulative Model Updates: 116,776
Cumulative Timesteps: 974,755,796

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,461.87270
Policy Entropy: 1.88332
Value Function Loss: 0.07042

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.36398
Value Function Update Magnitude: 0.23250

Collected Steps per Second: 21,911.85442
Overall Steps per Second: 10,481.78184

Timestep Collection Time: 2.28278
Timestep Consumption Time: 2.48931
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.77209

Cumulative Model Updates: 116,782
Cumulative Timesteps: 974,805,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 974805816...
Checkpoint 974805816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,125.77896
Policy Entropy: 1.86615
Value Function Loss: 0.06952

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.36473
Value Function Update Magnitude: 0.30693

Collected Steps per Second: 21,933.70032
Overall Steps per Second: 10,616.75170

Timestep Collection Time: 2.27969
Timestep Consumption Time: 2.43004
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.70973

Cumulative Model Updates: 116,788
Cumulative Timesteps: 974,855,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,545.35978
Policy Entropy: 1.84831
Value Function Loss: 0.06847

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.36178
Value Function Update Magnitude: 0.32766

Collected Steps per Second: 21,906.21565
Overall Steps per Second: 10,485.02572

Timestep Collection Time: 2.28337
Timestep Consumption Time: 2.48724
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.77061

Cumulative Model Updates: 116,794
Cumulative Timesteps: 974,905,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 974905838...
Checkpoint 974905838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,411.88799
Policy Entropy: 1.83678
Value Function Loss: 0.07032

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08252
Policy Update Magnitude: 0.35766
Value Function Update Magnitude: 0.28880

Collected Steps per Second: 21,201.49942
Overall Steps per Second: 10,224.76971

Timestep Collection Time: 2.35870
Timestep Consumption Time: 2.53217
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.89087

Cumulative Model Updates: 116,800
Cumulative Timesteps: 974,955,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,672.10597
Policy Entropy: 1.82674
Value Function Loss: 0.06948

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.34631
Value Function Update Magnitude: 0.21712

Collected Steps per Second: 20,345.12588
Overall Steps per Second: 10,108.34044

Timestep Collection Time: 2.45798
Timestep Consumption Time: 2.48922
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.94720

Cumulative Model Updates: 116,806
Cumulative Timesteps: 975,005,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 975005854...
Checkpoint 975005854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,470.62537
Policy Entropy: 1.82398
Value Function Loss: 0.06975

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.34335
Value Function Update Magnitude: 0.28132

Collected Steps per Second: 21,288.29539
Overall Steps per Second: 10,465.18874

Timestep Collection Time: 2.35068
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.78176

Cumulative Model Updates: 116,812
Cumulative Timesteps: 975,055,896

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,990.20578
Policy Entropy: 1.81697
Value Function Loss: 0.06896

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.34964
Value Function Update Magnitude: 0.30006

Collected Steps per Second: 21,079.89104
Overall Steps per Second: 10,464.24712

Timestep Collection Time: 2.37221
Timestep Consumption Time: 2.40653
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.77875

Cumulative Model Updates: 116,818
Cumulative Timesteps: 975,105,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 975105902...
Checkpoint 975105902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,488.43752
Policy Entropy: 1.81643
Value Function Loss: 0.07412

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.35614
Value Function Update Magnitude: 0.25808

Collected Steps per Second: 21,562.47233
Overall Steps per Second: 10,397.54782

Timestep Collection Time: 2.31996
Timestep Consumption Time: 2.49118
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.81113

Cumulative Model Updates: 116,824
Cumulative Timesteps: 975,155,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,837.31013
Policy Entropy: 1.81360
Value Function Loss: 0.07757

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.36320
Value Function Update Magnitude: 0.30638

Collected Steps per Second: 21,878.42397
Overall Steps per Second: 10,353.29775

Timestep Collection Time: 2.28618
Timestep Consumption Time: 2.54494
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.83112

Cumulative Model Updates: 116,830
Cumulative Timesteps: 975,205,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 975205944...
Checkpoint 975205944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,714.28300
Policy Entropy: 1.80988
Value Function Loss: 0.07914

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.36617
Value Function Update Magnitude: 0.30014

Collected Steps per Second: 21,830.11694
Overall Steps per Second: 10,578.18208

Timestep Collection Time: 2.29069
Timestep Consumption Time: 2.43659
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.72728

Cumulative Model Updates: 116,836
Cumulative Timesteps: 975,255,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,421.20179
Policy Entropy: 1.81247
Value Function Loss: 0.07923

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.36516
Value Function Update Magnitude: 0.29676

Collected Steps per Second: 21,995.08328
Overall Steps per Second: 10,467.87642

Timestep Collection Time: 2.27505
Timestep Consumption Time: 2.50529
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.78034

Cumulative Model Updates: 116,842
Cumulative Timesteps: 975,305,990

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 975305990...
Checkpoint 975305990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,613.59190
Policy Entropy: 1.81330
Value Function Loss: 0.08338

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.37384
Value Function Update Magnitude: 0.35649

Collected Steps per Second: 21,863.55593
Overall Steps per Second: 10,595.76714

Timestep Collection Time: 2.28691
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.71887

Cumulative Model Updates: 116,848
Cumulative Timesteps: 975,355,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,567.03418
Policy Entropy: 1.80594
Value Function Loss: 0.07928

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.37429
Value Function Update Magnitude: 0.38259

Collected Steps per Second: 21,274.80445
Overall Steps per Second: 10,490.20633

Timestep Collection Time: 2.35180
Timestep Consumption Time: 2.41780
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.76959

Cumulative Model Updates: 116,854
Cumulative Timesteps: 975,406,024

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 975406024...
Checkpoint 975406024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,693.79344
Policy Entropy: 1.80054
Value Function Loss: 0.07486

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.36442
Value Function Update Magnitude: 0.33260

Collected Steps per Second: 21,094.83315
Overall Steps per Second: 10,573.83792

Timestep Collection Time: 2.37063
Timestep Consumption Time: 2.35878
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.72941

Cumulative Model Updates: 116,860
Cumulative Timesteps: 975,456,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,678.96329
Policy Entropy: 1.79494
Value Function Loss: 0.06650

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.35072
Value Function Update Magnitude: 0.30055

Collected Steps per Second: 20,826.52741
Overall Steps per Second: 10,523.16130

Timestep Collection Time: 2.40232
Timestep Consumption Time: 2.35214
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.75446

Cumulative Model Updates: 116,866
Cumulative Timesteps: 975,506,064

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 975506064...
Checkpoint 975506064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,779.21886
Policy Entropy: 1.80535
Value Function Loss: 0.06674

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.34599
Value Function Update Magnitude: 0.26921

Collected Steps per Second: 20,604.14187
Overall Steps per Second: 10,301.97144

Timestep Collection Time: 2.42806
Timestep Consumption Time: 2.42810
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.85616

Cumulative Model Updates: 116,872
Cumulative Timesteps: 975,556,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,627.54974
Policy Entropy: 1.80945
Value Function Loss: 0.06507

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07824
Policy Update Magnitude: 0.34978
Value Function Update Magnitude: 0.32179

Collected Steps per Second: 21,011.44552
Overall Steps per Second: 10,351.67699

Timestep Collection Time: 2.38042
Timestep Consumption Time: 2.45126
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.83168

Cumulative Model Updates: 116,878
Cumulative Timesteps: 975,606,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 975606108...
Checkpoint 975606108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,860.31516
Policy Entropy: 1.80668
Value Function Loss: 0.06906

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.34923
Value Function Update Magnitude: 0.33722

Collected Steps per Second: 20,315.06290
Overall Steps per Second: 10,228.76384

Timestep Collection Time: 2.46339
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.89248

Cumulative Model Updates: 116,884
Cumulative Timesteps: 975,656,152

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,912.65669
Policy Entropy: 1.79601
Value Function Loss: 0.07069

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07518
Policy Update Magnitude: 0.35183
Value Function Update Magnitude: 0.34394

Collected Steps per Second: 21,499.19974
Overall Steps per Second: 10,430.39399

Timestep Collection Time: 2.32651
Timestep Consumption Time: 2.46890
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.79541

Cumulative Model Updates: 116,890
Cumulative Timesteps: 975,706,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 975706170...
Checkpoint 975706170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,929.00982
Policy Entropy: 1.78696
Value Function Loss: 0.07348

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07444
Policy Update Magnitude: 0.35201
Value Function Update Magnitude: 0.38603

Collected Steps per Second: 21,241.72061
Overall Steps per Second: 10,386.84259

Timestep Collection Time: 2.35423
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.81455

Cumulative Model Updates: 116,896
Cumulative Timesteps: 975,756,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,050.20729
Policy Entropy: 1.79080
Value Function Loss: 0.07360

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.35399
Value Function Update Magnitude: 0.40840

Collected Steps per Second: 21,878.90656
Overall Steps per Second: 10,598.74113

Timestep Collection Time: 2.28558
Timestep Consumption Time: 2.43253
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.71811

Cumulative Model Updates: 116,902
Cumulative Timesteps: 975,806,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 975806184...
Checkpoint 975806184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,420.09811
Policy Entropy: 1.79081
Value Function Loss: 0.07316

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.35423
Value Function Update Magnitude: 0.37309

Collected Steps per Second: 21,913.47738
Overall Steps per Second: 10,486.53524

Timestep Collection Time: 2.28270
Timestep Consumption Time: 2.48741
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.77012

Cumulative Model Updates: 116,908
Cumulative Timesteps: 975,856,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,244.15645
Policy Entropy: 1.77936
Value Function Loss: 0.07497

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.35409
Value Function Update Magnitude: 0.31670

Collected Steps per Second: 22,051.57177
Overall Steps per Second: 10,620.79705

Timestep Collection Time: 2.26923
Timestep Consumption Time: 2.44228
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.71151

Cumulative Model Updates: 116,914
Cumulative Timesteps: 975,906,246

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 975906246...
Checkpoint 975906246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,252.38256
Policy Entropy: 1.77629
Value Function Loss: 0.07733

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.35518
Value Function Update Magnitude: 0.33805

Collected Steps per Second: 21,656.61408
Overall Steps per Second: 10,394.72935

Timestep Collection Time: 2.30969
Timestep Consumption Time: 2.50237
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.81205

Cumulative Model Updates: 116,920
Cumulative Timesteps: 975,956,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,043.65479
Policy Entropy: 1.77979
Value Function Loss: 0.07572

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.35638
Value Function Update Magnitude: 0.39604

Collected Steps per Second: 22,143.51628
Overall Steps per Second: 10,503.11054

Timestep Collection Time: 2.25890
Timestep Consumption Time: 2.50350
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.76240

Cumulative Model Updates: 116,926
Cumulative Timesteps: 976,006,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 976006286...
Checkpoint 976006286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,512.15464
Policy Entropy: 1.77544
Value Function Loss: 0.07254

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.35401
Value Function Update Magnitude: 0.40347

Collected Steps per Second: 22,006.85386
Overall Steps per Second: 10,444.88910

Timestep Collection Time: 2.27320
Timestep Consumption Time: 2.51632
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.78952

Cumulative Model Updates: 116,932
Cumulative Timesteps: 976,056,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,370.74285
Policy Entropy: 1.77526
Value Function Loss: 0.07254

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.35213
Value Function Update Magnitude: 0.40993

Collected Steps per Second: 21,811.85761
Overall Steps per Second: 10,493.55795

Timestep Collection Time: 2.29261
Timestep Consumption Time: 2.47279
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.76540

Cumulative Model Updates: 116,938
Cumulative Timesteps: 976,106,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 976106318...
Checkpoint 976106318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,110.98512
Policy Entropy: 1.77161
Value Function Loss: 0.06904

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.35340
Value Function Update Magnitude: 0.43596

Collected Steps per Second: 21,234.90748
Overall Steps per Second: 10,299.71164

Timestep Collection Time: 2.35527
Timestep Consumption Time: 2.50059
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.85586

Cumulative Model Updates: 116,944
Cumulative Timesteps: 976,156,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,517.69993
Policy Entropy: 1.77874
Value Function Loss: 0.06615

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.34224
Value Function Update Magnitude: 0.41650

Collected Steps per Second: 21,551.48912
Overall Steps per Second: 10,340.88136

Timestep Collection Time: 2.32003
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.83518

Cumulative Model Updates: 116,950
Cumulative Timesteps: 976,206,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 976206332...
Checkpoint 976206332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,750.45360
Policy Entropy: 1.77954
Value Function Loss: 0.06772

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.34405
Value Function Update Magnitude: 0.41598

Collected Steps per Second: 20,620.85325
Overall Steps per Second: 10,186.32204

Timestep Collection Time: 2.42677
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.91267

Cumulative Model Updates: 116,956
Cumulative Timesteps: 976,256,374

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,511.58279
Policy Entropy: 1.77433
Value Function Loss: 0.06605

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08118
Policy Update Magnitude: 0.34666
Value Function Update Magnitude: 0.41646

Collected Steps per Second: 19,862.29833
Overall Steps per Second: 9,914.58129

Timestep Collection Time: 2.51945
Timestep Consumption Time: 2.52787
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 5.04731

Cumulative Model Updates: 116,962
Cumulative Timesteps: 976,306,416

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 976306416...
Checkpoint 976306416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,822.24213
Policy Entropy: 1.76332
Value Function Loss: 0.07332

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.34765
Value Function Update Magnitude: 0.40793

Collected Steps per Second: 21,468.60506
Overall Steps per Second: 10,365.32915

Timestep Collection Time: 2.32954
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.82493

Cumulative Model Updates: 116,968
Cumulative Timesteps: 976,356,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,299.33740
Policy Entropy: 1.75096
Value Function Loss: 0.07004

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.35105
Value Function Update Magnitude: 0.41002

Collected Steps per Second: 21,649.63015
Overall Steps per Second: 10,512.03428

Timestep Collection Time: 2.31080
Timestep Consumption Time: 2.44832
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.75912

Cumulative Model Updates: 116,974
Cumulative Timesteps: 976,406,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 976406456...
Checkpoint 976406456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,801.64817
Policy Entropy: 1.75232
Value Function Loss: 0.07215

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08402
Policy Update Magnitude: 0.35462
Value Function Update Magnitude: 0.41814

Collected Steps per Second: 20,642.91338
Overall Steps per Second: 10,326.86282

Timestep Collection Time: 2.42301
Timestep Consumption Time: 2.42047
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.84348

Cumulative Model Updates: 116,980
Cumulative Timesteps: 976,456,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,483.78867
Policy Entropy: 1.76471
Value Function Loss: 0.07350

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.35752
Value Function Update Magnitude: 0.43594

Collected Steps per Second: 19,173.49940
Overall Steps per Second: 9,423.92412

Timestep Collection Time: 2.60964
Timestep Consumption Time: 2.69982
PPO Batch Consumption Time: 0.31615
Total Iteration Time: 5.30947

Cumulative Model Updates: 116,986
Cumulative Timesteps: 976,506,510

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 976506510...
Checkpoint 976506510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,081.24816
Policy Entropy: 1.77312
Value Function Loss: 0.08005

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.36489
Value Function Update Magnitude: 0.44453

Collected Steps per Second: 19,938.65110
Overall Steps per Second: 9,836.42132

Timestep Collection Time: 2.50890
Timestep Consumption Time: 2.57669
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 5.08559

Cumulative Model Updates: 116,992
Cumulative Timesteps: 976,556,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,592.67201
Policy Entropy: 1.77003
Value Function Loss: 0.07615

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.36510
Value Function Update Magnitude: 0.45500

Collected Steps per Second: 19,246.83865
Overall Steps per Second: 9,356.61131

Timestep Collection Time: 2.59918
Timestep Consumption Time: 2.74741
PPO Batch Consumption Time: 0.32347
Total Iteration Time: 5.34659

Cumulative Model Updates: 116,998
Cumulative Timesteps: 976,606,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 976606560...
Checkpoint 976606560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,987.76296
Policy Entropy: 1.75971
Value Function Loss: 0.07476

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.35908
Value Function Update Magnitude: 0.45554

Collected Steps per Second: 19,498.74754
Overall Steps per Second: 9,966.31879

Timestep Collection Time: 2.56519
Timestep Consumption Time: 2.45351
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 5.01870

Cumulative Model Updates: 117,004
Cumulative Timesteps: 976,656,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,291.05610
Policy Entropy: 1.75453
Value Function Loss: 0.07055

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.35891
Value Function Update Magnitude: 0.42053

Collected Steps per Second: 22,000.22366
Overall Steps per Second: 10,465.90480

Timestep Collection Time: 2.27307
Timestep Consumption Time: 2.50511
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.77818

Cumulative Model Updates: 117,010
Cumulative Timesteps: 976,706,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 976706586...
Checkpoint 976706586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,149.06411
Policy Entropy: 1.76747
Value Function Loss: 0.06972

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.35483
Value Function Update Magnitude: 0.41953

Collected Steps per Second: 20,388.34643
Overall Steps per Second: 9,883.50039

Timestep Collection Time: 2.45287
Timestep Consumption Time: 2.60708
PPO Batch Consumption Time: 0.30737
Total Iteration Time: 5.05995

Cumulative Model Updates: 117,016
Cumulative Timesteps: 976,756,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,008.30584
Policy Entropy: 1.76315
Value Function Loss: 0.06623

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.35106
Value Function Update Magnitude: 0.41216

Collected Steps per Second: 21,412.02004
Overall Steps per Second: 10,430.44048

Timestep Collection Time: 2.33532
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.79404

Cumulative Model Updates: 117,022
Cumulative Timesteps: 976,806,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 976806600...
Checkpoint 976806600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,890.08067
Policy Entropy: 1.75635
Value Function Loss: 0.06559

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.34699
Value Function Update Magnitude: 0.40357

Collected Steps per Second: 20,472.90042
Overall Steps per Second: 9,908.09615

Timestep Collection Time: 2.44303
Timestep Consumption Time: 2.60496
PPO Batch Consumption Time: 0.30866
Total Iteration Time: 5.04799

Cumulative Model Updates: 117,028
Cumulative Timesteps: 976,856,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,526.01395
Policy Entropy: 1.74599
Value Function Loss: 0.06641

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.34643
Value Function Update Magnitude: 0.39755

Collected Steps per Second: 20,194.79697
Overall Steps per Second: 9,943.15558

Timestep Collection Time: 2.47658
Timestep Consumption Time: 2.55341
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 5.02999

Cumulative Model Updates: 117,034
Cumulative Timesteps: 976,906,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 976906630...
Checkpoint 976906630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,503.07173
Policy Entropy: 1.74992
Value Function Loss: 0.07116

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.34882
Value Function Update Magnitude: 0.39356

Collected Steps per Second: 20,521.52272
Overall Steps per Second: 9,943.68710

Timestep Collection Time: 2.43734
Timestep Consumption Time: 2.59278
PPO Batch Consumption Time: 0.30649
Total Iteration Time: 5.03013

Cumulative Model Updates: 117,040
Cumulative Timesteps: 976,956,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,889.59780
Policy Entropy: 1.75447
Value Function Loss: 0.07638

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.35730
Value Function Update Magnitude: 0.40769

Collected Steps per Second: 20,440.39834
Overall Steps per Second: 10,096.66261

Timestep Collection Time: 2.44682
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.95352

Cumulative Model Updates: 117,046
Cumulative Timesteps: 977,006,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 977006662...
Checkpoint 977006662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,311.41872
Policy Entropy: 1.75910
Value Function Loss: 0.07944

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.36658
Value Function Update Magnitude: 0.43101

Collected Steps per Second: 21,602.59200
Overall Steps per Second: 10,394.33887

Timestep Collection Time: 2.31639
Timestep Consumption Time: 2.49777
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.81416

Cumulative Model Updates: 117,052
Cumulative Timesteps: 977,056,702

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,408.47955
Policy Entropy: 1.75662
Value Function Loss: 0.07572

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.36851
Value Function Update Magnitude: 0.44062

Collected Steps per Second: 21,870.54812
Overall Steps per Second: 10,478.36851

Timestep Collection Time: 2.28801
Timestep Consumption Time: 2.48754
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.77555

Cumulative Model Updates: 117,058
Cumulative Timesteps: 977,106,742

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 977106742...
Checkpoint 977106742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,458.54415
Policy Entropy: 1.75474
Value Function Loss: 0.07115

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.34642
Value Function Update Magnitude: 0.43269

Collected Steps per Second: 18,156.70202
Overall Steps per Second: 9,469.33505

Timestep Collection Time: 2.75513
Timestep Consumption Time: 2.52761
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 5.28274

Cumulative Model Updates: 117,064
Cumulative Timesteps: 977,156,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,211.95036
Policy Entropy: 1.76439
Value Function Loss: 0.07149

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.34654
Value Function Update Magnitude: 0.40435

Collected Steps per Second: 19,338.57107
Overall Steps per Second: 9,700.00632

Timestep Collection Time: 2.58633
Timestep Consumption Time: 2.56995
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 5.15629

Cumulative Model Updates: 117,070
Cumulative Timesteps: 977,206,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 977206782...
Checkpoint 977206782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,352.49250
Policy Entropy: 1.76062
Value Function Loss: 0.07185

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.35085
Value Function Update Magnitude: 0.40355

Collected Steps per Second: 19,450.75218
Overall Steps per Second: 10,005.55060

Timestep Collection Time: 2.57286
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 5.00162

Cumulative Model Updates: 117,076
Cumulative Timesteps: 977,256,826

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,166.44953
Policy Entropy: 1.75357
Value Function Loss: 0.07495

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.33864
Value Function Update Magnitude: 0.40816

Collected Steps per Second: 21,752.08366
Overall Steps per Second: 10,398.70441

Timestep Collection Time: 2.29891
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.80887

Cumulative Model Updates: 117,082
Cumulative Timesteps: 977,306,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 977306832...
Checkpoint 977306832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,302.23136
Policy Entropy: 1.75002
Value Function Loss: 0.07498

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.33777
Value Function Update Magnitude: 0.42477

Collected Steps per Second: 21,651.01126
Overall Steps per Second: 10,418.27026

Timestep Collection Time: 2.30992
Timestep Consumption Time: 2.49050
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.80041

Cumulative Model Updates: 117,088
Cumulative Timesteps: 977,356,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,925.85498
Policy Entropy: 1.76012
Value Function Loss: 0.07292

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.35276
Value Function Update Magnitude: 0.42507

Collected Steps per Second: 22,085.93366
Overall Steps per Second: 10,618.59233

Timestep Collection Time: 2.26524
Timestep Consumption Time: 2.44630
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.71155

Cumulative Model Updates: 117,094
Cumulative Timesteps: 977,406,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 977406874...
Checkpoint 977406874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,816.84344
Policy Entropy: 1.75959
Value Function Loss: 0.07205

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.35403
Value Function Update Magnitude: 0.41854

Collected Steps per Second: 21,303.57691
Overall Steps per Second: 10,271.33491

Timestep Collection Time: 2.34853
Timestep Consumption Time: 2.52251
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.87103

Cumulative Model Updates: 117,100
Cumulative Timesteps: 977,456,906

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,283.82601
Policy Entropy: 1.75391
Value Function Loss: 0.07451

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.35798
Value Function Update Magnitude: 0.40601

Collected Steps per Second: 21,936.83926
Overall Steps per Second: 10,390.32543

Timestep Collection Time: 2.27936
Timestep Consumption Time: 2.53300
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.81236

Cumulative Model Updates: 117,106
Cumulative Timesteps: 977,506,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 977506908...
Checkpoint 977506908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,727.26193
Policy Entropy: 1.74697
Value Function Loss: 0.07936

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.36157
Value Function Update Magnitude: 0.39993

Collected Steps per Second: 21,362.19074
Overall Steps per Second: 10,272.05291

Timestep Collection Time: 2.34133
Timestep Consumption Time: 2.52780
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.86913

Cumulative Model Updates: 117,112
Cumulative Timesteps: 977,556,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,776.48606
Policy Entropy: 1.75059
Value Function Loss: 0.07890

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.34777
Value Function Update Magnitude: 0.43066

Collected Steps per Second: 21,645.98584
Overall Steps per Second: 10,461.42123

Timestep Collection Time: 2.30999
Timestep Consumption Time: 2.46967
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.77966

Cumulative Model Updates: 117,118
Cumulative Timesteps: 977,606,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 977606926...
Checkpoint 977606926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,600.48962
Policy Entropy: 1.75684
Value Function Loss: 0.07672

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.35452
Value Function Update Magnitude: 0.42354

Collected Steps per Second: 21,367.33160
Overall Steps per Second: 10,300.77357

Timestep Collection Time: 2.34208
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.85828

Cumulative Model Updates: 117,124
Cumulative Timesteps: 977,656,970

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,837.89814
Policy Entropy: 1.75645
Value Function Loss: 0.07566

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.36022
Value Function Update Magnitude: 0.42962

Collected Steps per Second: 21,305.51600
Overall Steps per Second: 10,417.39329

Timestep Collection Time: 2.34747
Timestep Consumption Time: 2.45354
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.80101

Cumulative Model Updates: 117,130
Cumulative Timesteps: 977,706,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 977706984...
Checkpoint 977706984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,938.42151
Policy Entropy: 1.75745
Value Function Loss: 0.07707

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.36500
Value Function Update Magnitude: 0.43406

Collected Steps per Second: 21,601.32086
Overall Steps per Second: 10,539.13359

Timestep Collection Time: 2.31588
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.74669

Cumulative Model Updates: 117,136
Cumulative Timesteps: 977,757,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,196.55867
Policy Entropy: 1.75250
Value Function Loss: 0.08190

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.36859
Value Function Update Magnitude: 0.41247

Collected Steps per Second: 21,152.87124
Overall Steps per Second: 10,324.28442

Timestep Collection Time: 2.36450
Timestep Consumption Time: 2.48000
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.84450

Cumulative Model Updates: 117,142
Cumulative Timesteps: 977,807,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 977807026...
Checkpoint 977807026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,671.85789
Policy Entropy: 1.75659
Value Function Loss: 0.08997

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.37738
Value Function Update Magnitude: 0.45430

Collected Steps per Second: 21,102.75523
Overall Steps per Second: 10,424.17450

Timestep Collection Time: 2.37031
Timestep Consumption Time: 2.42815
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.79846

Cumulative Model Updates: 117,148
Cumulative Timesteps: 977,857,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,347.56786
Policy Entropy: 1.74757
Value Function Loss: 0.08718

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.38058
Value Function Update Magnitude: 0.47273

Collected Steps per Second: 21,750.17050
Overall Steps per Second: 10,387.31966

Timestep Collection Time: 2.30012
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.81626

Cumulative Model Updates: 117,154
Cumulative Timesteps: 977,907,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 977907074...
Checkpoint 977907074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,497.49628
Policy Entropy: 1.76191
Value Function Loss: 0.08126

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.37114
Value Function Update Magnitude: 0.47268

Collected Steps per Second: 20,844.30955
Overall Steps per Second: 10,207.17088

Timestep Collection Time: 2.39970
Timestep Consumption Time: 2.50078
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.90048

Cumulative Model Updates: 117,160
Cumulative Timesteps: 977,957,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,464.19805
Policy Entropy: 1.76893
Value Function Loss: 0.07376

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.35953
Value Function Update Magnitude: 0.45998

Collected Steps per Second: 21,672.44838
Overall Steps per Second: 10,510.99432

Timestep Collection Time: 2.30745
Timestep Consumption Time: 2.45024
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.75768

Cumulative Model Updates: 117,166
Cumulative Timesteps: 978,007,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 978007102...
Checkpoint 978007102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,843.77362
Policy Entropy: 1.77283
Value Function Loss: 0.06854

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.34722
Value Function Update Magnitude: 0.44160

Collected Steps per Second: 19,965.23311
Overall Steps per Second: 10,091.50764

Timestep Collection Time: 2.50485
Timestep Consumption Time: 2.45080
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.95565

Cumulative Model Updates: 117,172
Cumulative Timesteps: 978,057,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,165.04160
Policy Entropy: 1.75588
Value Function Loss: 0.06982

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.34587
Value Function Update Magnitude: 0.43101

Collected Steps per Second: 21,629.80830
Overall Steps per Second: 10,503.75115

Timestep Collection Time: 2.31199
Timestep Consumption Time: 2.44897
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.76097

Cumulative Model Updates: 117,178
Cumulative Timesteps: 978,107,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 978107120...
Checkpoint 978107120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,048.72026
Policy Entropy: 1.75108
Value Function Loss: 0.06939

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.35019
Value Function Update Magnitude: 0.42904

Collected Steps per Second: 21,444.59076
Overall Steps per Second: 10,280.49937

Timestep Collection Time: 2.33187
Timestep Consumption Time: 2.53229
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.86416

Cumulative Model Updates: 117,184
Cumulative Timesteps: 978,157,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,402.58629
Policy Entropy: 1.75885
Value Function Loss: 0.07067

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.34691
Value Function Update Magnitude: 0.42933

Collected Steps per Second: 21,497.37509
Overall Steps per Second: 10,422.88022

Timestep Collection Time: 2.32652
Timestep Consumption Time: 2.47197
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.79848

Cumulative Model Updates: 117,190
Cumulative Timesteps: 978,207,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 978207140...
Checkpoint 978207140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,364.58908
Policy Entropy: 1.76297
Value Function Loss: 0.07209

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.34890
Value Function Update Magnitude: 0.43969

Collected Steps per Second: 21,770.11840
Overall Steps per Second: 10,531.20965

Timestep Collection Time: 2.29774
Timestep Consumption Time: 2.45215
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.74988

Cumulative Model Updates: 117,196
Cumulative Timesteps: 978,257,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,864.12573
Policy Entropy: 1.77027
Value Function Loss: 0.07226

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.35148
Value Function Update Magnitude: 0.43108

Collected Steps per Second: 20,289.68504
Overall Steps per Second: 10,068.40391

Timestep Collection Time: 2.46667
Timestep Consumption Time: 2.50413
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.97080

Cumulative Model Updates: 117,202
Cumulative Timesteps: 978,307,210

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 978307210...
Checkpoint 978307210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,537.12719
Policy Entropy: 1.75566
Value Function Loss: 0.07500

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.35252
Value Function Update Magnitude: 0.41651

Collected Steps per Second: 20,778.19674
Overall Steps per Second: 10,233.30436

Timestep Collection Time: 2.40656
Timestep Consumption Time: 2.47984
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.88640

Cumulative Model Updates: 117,208
Cumulative Timesteps: 978,357,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,920.87810
Policy Entropy: 1.77163
Value Function Loss: 0.07892

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.35809
Value Function Update Magnitude: 0.40067

Collected Steps per Second: 21,409.22555
Overall Steps per Second: 10,433.05478

Timestep Collection Time: 2.33656
Timestep Consumption Time: 2.45820
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.79476

Cumulative Model Updates: 117,214
Cumulative Timesteps: 978,407,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 978407238...
Checkpoint 978407238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,829.61777
Policy Entropy: 1.77175
Value Function Loss: 0.07768

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.35832
Value Function Update Magnitude: 0.35473

Collected Steps per Second: 20,819.73762
Overall Steps per Second: 10,318.57720

Timestep Collection Time: 2.40195
Timestep Consumption Time: 2.44445
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.84640

Cumulative Model Updates: 117,220
Cumulative Timesteps: 978,457,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,301.61191
Policy Entropy: 1.77022
Value Function Loss: 0.07273

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.35025
Value Function Update Magnitude: 0.30127

Collected Steps per Second: 20,899.80470
Overall Steps per Second: 10,363.40603

Timestep Collection Time: 2.39332
Timestep Consumption Time: 2.43327
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.82660

Cumulative Model Updates: 117,226
Cumulative Timesteps: 978,507,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 978507266...
Checkpoint 978507266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,484.78083
Policy Entropy: 1.75970
Value Function Loss: 0.07010

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.34201
Value Function Update Magnitude: 0.28553

Collected Steps per Second: 20,410.44424
Overall Steps per Second: 10,207.52761

Timestep Collection Time: 2.44973
Timestep Consumption Time: 2.44862
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.89835

Cumulative Model Updates: 117,232
Cumulative Timesteps: 978,557,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,200.19835
Policy Entropy: 1.75147
Value Function Loss: 0.07462

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.34793
Value Function Update Magnitude: 0.30350

Collected Steps per Second: 21,228.56657
Overall Steps per Second: 10,428.53301

Timestep Collection Time: 2.35588
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.79569

Cumulative Model Updates: 117,238
Cumulative Timesteps: 978,607,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 978607278...
Checkpoint 978607278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,484.63460
Policy Entropy: 1.75293
Value Function Loss: 0.07156

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.35286
Value Function Update Magnitude: 0.40128

Collected Steps per Second: 20,934.63137
Overall Steps per Second: 10,402.64248

Timestep Collection Time: 2.38992
Timestep Consumption Time: 2.41963
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.80955

Cumulative Model Updates: 117,244
Cumulative Timesteps: 978,657,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,732.09702
Policy Entropy: 1.76378
Value Function Loss: 0.07220

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.34992
Value Function Update Magnitude: 0.43754

Collected Steps per Second: 20,903.34135
Overall Steps per Second: 10,345.08710

Timestep Collection Time: 2.39368
Timestep Consumption Time: 2.44301
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.83669

Cumulative Model Updates: 117,250
Cumulative Timesteps: 978,707,346

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 978707346...
Checkpoint 978707346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,328.42217
Policy Entropy: 1.76633
Value Function Loss: 0.07497

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.35325
Value Function Update Magnitude: 0.42420

Collected Steps per Second: 21,059.12469
Overall Steps per Second: 10,574.66571

Timestep Collection Time: 2.37531
Timestep Consumption Time: 2.35505
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.73036

Cumulative Model Updates: 117,256
Cumulative Timesteps: 978,757,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,846.92098
Policy Entropy: 1.76032
Value Function Loss: 0.07737

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.35744
Value Function Update Magnitude: 0.41807

Collected Steps per Second: 21,027.61078
Overall Steps per Second: 10,426.58592

Timestep Collection Time: 2.37916
Timestep Consumption Time: 2.41896
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.79812

Cumulative Model Updates: 117,262
Cumulative Timesteps: 978,807,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 978807396...
Checkpoint 978807396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,144.02322
Policy Entropy: 1.75595
Value Function Loss: 0.07975

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.35084
Value Function Update Magnitude: 0.42193

Collected Steps per Second: 21,326.77637
Overall Steps per Second: 10,362.52577

Timestep Collection Time: 2.34531
Timestep Consumption Time: 2.48150
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.82682

Cumulative Model Updates: 117,268
Cumulative Timesteps: 978,857,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,981.01502
Policy Entropy: 1.75372
Value Function Loss: 0.08360

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.34059
Value Function Update Magnitude: 0.40532

Collected Steps per Second: 21,471.07329
Overall Steps per Second: 10,305.53480

Timestep Collection Time: 2.32965
Timestep Consumption Time: 2.52406
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.85370

Cumulative Model Updates: 117,274
Cumulative Timesteps: 978,907,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 978907434...
Checkpoint 978907434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,530.53639
Policy Entropy: 1.76082
Value Function Loss: 0.08357

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.34547
Value Function Update Magnitude: 0.36433

Collected Steps per Second: 21,414.33080
Overall Steps per Second: 10,394.07777

Timestep Collection Time: 2.33713
Timestep Consumption Time: 2.47792
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.81505

Cumulative Model Updates: 117,280
Cumulative Timesteps: 978,957,482

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,344.99524
Policy Entropy: 1.77414
Value Function Loss: 0.07796

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.34497
Value Function Update Magnitude: 0.39979

Collected Steps per Second: 21,671.77097
Overall Steps per Second: 10,440.41387

Timestep Collection Time: 2.30835
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.79157

Cumulative Model Updates: 117,286
Cumulative Timesteps: 979,007,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 979007508...
Checkpoint 979007508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,759.63564
Policy Entropy: 1.77693
Value Function Loss: 0.07240

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.34131
Value Function Update Magnitude: 0.40581

Collected Steps per Second: 21,788.33228
Overall Steps per Second: 10,446.99844

Timestep Collection Time: 2.29481
Timestep Consumption Time: 2.49126
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.78606

Cumulative Model Updates: 117,292
Cumulative Timesteps: 979,057,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,882.76031
Policy Entropy: 1.77160
Value Function Loss: 0.07271

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.34639
Value Function Update Magnitude: 0.41180

Collected Steps per Second: 20,226.31798
Overall Steps per Second: 10,094.46714

Timestep Collection Time: 2.47252
Timestep Consumption Time: 2.48168
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.95420

Cumulative Model Updates: 117,298
Cumulative Timesteps: 979,107,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 979107518...
Checkpoint 979107518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,998.49471
Policy Entropy: 1.77054
Value Function Loss: 0.07584

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.35039
Value Function Update Magnitude: 0.42461

Collected Steps per Second: 21,458.28298
Overall Steps per Second: 10,314.36567

Timestep Collection Time: 2.33113
Timestep Consumption Time: 2.51861
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.84974

Cumulative Model Updates: 117,304
Cumulative Timesteps: 979,157,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,700.59994
Policy Entropy: 1.77707
Value Function Loss: 0.07448

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.35206
Value Function Update Magnitude: 0.42937

Collected Steps per Second: 21,283.10292
Overall Steps per Second: 10,371.34399

Timestep Collection Time: 2.35060
Timestep Consumption Time: 2.47308
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.82368

Cumulative Model Updates: 117,310
Cumulative Timesteps: 979,207,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 979207568...
Checkpoint 979207568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,371.66590
Policy Entropy: 1.78049
Value Function Loss: 0.07347

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.35210
Value Function Update Magnitude: 0.42350

Collected Steps per Second: 21,302.04093
Overall Steps per Second: 10,326.98050

Timestep Collection Time: 2.34747
Timestep Consumption Time: 2.49479
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.84227

Cumulative Model Updates: 117,316
Cumulative Timesteps: 979,257,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,188.71072
Policy Entropy: 1.78227
Value Function Loss: 0.07387

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.35068
Value Function Update Magnitude: 0.40438

Collected Steps per Second: 21,764.07675
Overall Steps per Second: 10,413.36403

Timestep Collection Time: 2.29746
Timestep Consumption Time: 2.50426
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.80171

Cumulative Model Updates: 117,322
Cumulative Timesteps: 979,307,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 979307576...
Checkpoint 979307576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,374.50598
Policy Entropy: 1.78579
Value Function Loss: 0.07496

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.34634
Value Function Update Magnitude: 0.39625

Collected Steps per Second: 20,774.43271
Overall Steps per Second: 10,119.81691

Timestep Collection Time: 2.40815
Timestep Consumption Time: 2.53542
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.94357

Cumulative Model Updates: 117,328
Cumulative Timesteps: 979,357,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,512.86036
Policy Entropy: 1.77023
Value Function Loss: 0.07493

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.34799
Value Function Update Magnitude: 0.38942

Collected Steps per Second: 20,099.57090
Overall Steps per Second: 10,001.35373

Timestep Collection Time: 2.48771
Timestep Consumption Time: 2.51181
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.99952

Cumulative Model Updates: 117,334
Cumulative Timesteps: 979,407,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 979407606...
Checkpoint 979407606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,083.84645
Policy Entropy: 1.75235
Value Function Loss: 0.07910

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08189
Policy Update Magnitude: 0.35164
Value Function Update Magnitude: 0.38434

Collected Steps per Second: 21,204.13091
Overall Steps per Second: 10,131.65889

Timestep Collection Time: 2.35850
Timestep Consumption Time: 2.57751
PPO Batch Consumption Time: 0.30665
Total Iteration Time: 4.93601

Cumulative Model Updates: 117,340
Cumulative Timesteps: 979,457,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,727.30536
Policy Entropy: 1.74000
Value Function Loss: 0.08116

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.35681
Value Function Update Magnitude: 0.40354

Collected Steps per Second: 17,720.40054
Overall Steps per Second: 9,637.13733

Timestep Collection Time: 2.82240
Timestep Consumption Time: 2.36732
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 5.18972

Cumulative Model Updates: 117,346
Cumulative Timesteps: 979,507,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 979507630...
Checkpoint 979507630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,880.30885
Policy Entropy: 1.74875
Value Function Loss: 0.08631

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.35651
Value Function Update Magnitude: 0.42630

Collected Steps per Second: 19,980.08944
Overall Steps per Second: 9,883.23953

Timestep Collection Time: 2.50259
Timestep Consumption Time: 2.55668
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 5.05927

Cumulative Model Updates: 117,352
Cumulative Timesteps: 979,557,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,674.62913
Policy Entropy: 1.75678
Value Function Loss: 0.08405

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.35600
Value Function Update Magnitude: 0.42686

Collected Steps per Second: 20,846.19840
Overall Steps per Second: 10,197.08359

Timestep Collection Time: 2.39861
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.90356

Cumulative Model Updates: 117,358
Cumulative Timesteps: 979,607,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 979607634...
Checkpoint 979607634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,621.91924
Policy Entropy: 1.74709
Value Function Loss: 0.08477

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.35549
Value Function Update Magnitude: 0.42279

Collected Steps per Second: 21,821.49913
Overall Steps per Second: 10,477.57177

Timestep Collection Time: 2.29343
Timestep Consumption Time: 2.48306
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.77649

Cumulative Model Updates: 117,364
Cumulative Timesteps: 979,657,680

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,946.43693
Policy Entropy: 1.74106
Value Function Loss: 0.07710

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.35458
Value Function Update Magnitude: 0.39878

Collected Steps per Second: 21,176.45754
Overall Steps per Second: 10,437.08616

Timestep Collection Time: 2.36225
Timestep Consumption Time: 2.43066
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.79291

Cumulative Model Updates: 117,370
Cumulative Timesteps: 979,707,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 979707704...
Checkpoint 979707704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,110.46297
Policy Entropy: 1.74585
Value Function Loss: 0.08029

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.35338
Value Function Update Magnitude: 0.36196

Collected Steps per Second: 21,425.69798
Overall Steps per Second: 10,214.27864

Timestep Collection Time: 2.33393
Timestep Consumption Time: 2.56177
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.89570

Cumulative Model Updates: 117,376
Cumulative Timesteps: 979,757,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,385.50437
Policy Entropy: 1.75529
Value Function Loss: 0.07783

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.35443
Value Function Update Magnitude: 0.33412

Collected Steps per Second: 20,635.51869
Overall Steps per Second: 10,060.73692

Timestep Collection Time: 2.42398
Timestep Consumption Time: 2.54783
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.97180

Cumulative Model Updates: 117,382
Cumulative Timesteps: 979,807,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 979807730...
Checkpoint 979807730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,840.07530
Policy Entropy: 1.77059
Value Function Loss: 0.08043

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.34670
Value Function Update Magnitude: 0.35897

Collected Steps per Second: 20,589.99300
Overall Steps per Second: 10,153.78871

Timestep Collection Time: 2.43031
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.92821

Cumulative Model Updates: 117,388
Cumulative Timesteps: 979,857,770

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,710.49125
Policy Entropy: 1.78010
Value Function Loss: 0.07325

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.34105
Value Function Update Magnitude: 0.35398

Collected Steps per Second: 20,267.12746
Overall Steps per Second: 9,958.78282

Timestep Collection Time: 2.46853
Timestep Consumption Time: 2.55518
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 5.02371

Cumulative Model Updates: 117,394
Cumulative Timesteps: 979,907,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 979907800...
Checkpoint 979907800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,087.05194
Policy Entropy: 1.79226
Value Function Loss: 0.07359

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.34437
Value Function Update Magnitude: 0.37028

Collected Steps per Second: 21,495.90605
Overall Steps per Second: 10,357.31215

Timestep Collection Time: 2.32714
Timestep Consumption Time: 2.50268
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.82982

Cumulative Model Updates: 117,400
Cumulative Timesteps: 979,957,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,674.64890
Policy Entropy: 1.77340
Value Function Loss: 0.07518

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.34198
Value Function Update Magnitude: 0.39889

Collected Steps per Second: 21,858.09539
Overall Steps per Second: 10,401.65412

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.52106
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.81000

Cumulative Model Updates: 117,406
Cumulative Timesteps: 980,007,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 980007856...
Checkpoint 980007856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,629.43287
Policy Entropy: 1.76304
Value Function Loss: 0.07353

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.34114
Value Function Update Magnitude: 0.40168

Collected Steps per Second: 21,522.22140
Overall Steps per Second: 10,187.94092

Timestep Collection Time: 2.32364
Timestep Consumption Time: 2.58510
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 4.90874

Cumulative Model Updates: 117,412
Cumulative Timesteps: 980,057,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,277.25870
Policy Entropy: 1.75331
Value Function Loss: 0.07228

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08601
Policy Update Magnitude: 0.34141
Value Function Update Magnitude: 0.37800

Collected Steps per Second: 21,615.13968
Overall Steps per Second: 10,338.81335

Timestep Collection Time: 2.31329
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.83634

Cumulative Model Updates: 117,418
Cumulative Timesteps: 980,107,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 980107868...
Checkpoint 980107868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,543.90629
Policy Entropy: 1.75811
Value Function Loss: 0.06989

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.34323
Value Function Update Magnitude: 0.37706

Collected Steps per Second: 21,435.14873
Overall Steps per Second: 10,390.49637

Timestep Collection Time: 2.33346
Timestep Consumption Time: 2.48036
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.81382

Cumulative Model Updates: 117,424
Cumulative Timesteps: 980,157,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,870.11852
Policy Entropy: 1.76781
Value Function Loss: 0.07469

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07826
Policy Update Magnitude: 0.34605
Value Function Update Magnitude: 0.39849

Collected Steps per Second: 21,340.82095
Overall Steps per Second: 10,409.86509

Timestep Collection Time: 2.34471
Timestep Consumption Time: 2.46208
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.80679

Cumulative Model Updates: 117,430
Cumulative Timesteps: 980,207,924

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 980207924...
Checkpoint 980207924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,437.97033
Policy Entropy: 1.76999
Value Function Loss: 0.07170

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.33987
Value Function Update Magnitude: 0.39863

Collected Steps per Second: 21,625.48305
Overall Steps per Second: 10,347.33810

Timestep Collection Time: 2.31310
Timestep Consumption Time: 2.52118
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.83429

Cumulative Model Updates: 117,436
Cumulative Timesteps: 980,257,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,173.74475
Policy Entropy: 1.77661
Value Function Loss: 0.07101

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.32167
Value Function Update Magnitude: 0.37801

Collected Steps per Second: 21,908.20606
Overall Steps per Second: 10,384.31130

Timestep Collection Time: 2.28271
Timestep Consumption Time: 2.53321
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.81592

Cumulative Model Updates: 117,442
Cumulative Timesteps: 980,307,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 980307956...
Checkpoint 980307956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,763.71396
Policy Entropy: 1.76979
Value Function Loss: 0.07389

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.32854
Value Function Update Magnitude: 0.37910

Collected Steps per Second: 21,525.11505
Overall Steps per Second: 10,512.17872

Timestep Collection Time: 2.32315
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.75696

Cumulative Model Updates: 117,448
Cumulative Timesteps: 980,357,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,707.68984
Policy Entropy: 1.76925
Value Function Loss: 0.07658

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.34531
Value Function Update Magnitude: 0.38416

Collected Steps per Second: 21,766.87968
Overall Steps per Second: 10,480.00673

Timestep Collection Time: 2.29799
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.77290

Cumulative Model Updates: 117,454
Cumulative Timesteps: 980,407,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 980407982...
Checkpoint 980407982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,544.06125
Policy Entropy: 1.76712
Value Function Loss: 0.07633

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.34050
Value Function Update Magnitude: 0.39741

Collected Steps per Second: 21,703.66571
Overall Steps per Second: 10,356.73552

Timestep Collection Time: 2.30394
Timestep Consumption Time: 2.52422
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.82816

Cumulative Model Updates: 117,460
Cumulative Timesteps: 980,457,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,076.36095
Policy Entropy: 1.76046
Value Function Loss: 0.07803

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.33185
Value Function Update Magnitude: 0.39047

Collected Steps per Second: 21,325.61932
Overall Steps per Second: 10,312.23856

Timestep Collection Time: 2.34572
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.85094

Cumulative Model Updates: 117,466
Cumulative Timesteps: 980,508,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 980508010...
Checkpoint 980508010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,591.71066
Policy Entropy: 1.75578
Value Function Loss: 0.07439

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.34065
Value Function Update Magnitude: 0.40382

Collected Steps per Second: 21,080.22694
Overall Steps per Second: 10,247.47931

Timestep Collection Time: 2.37218
Timestep Consumption Time: 2.50766
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.87983

Cumulative Model Updates: 117,472
Cumulative Timesteps: 980,558,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,438.57449
Policy Entropy: 1.74368
Value Function Loss: 0.07353

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.33916
Value Function Update Magnitude: 0.40791

Collected Steps per Second: 21,478.67048
Overall Steps per Second: 10,509.00744

Timestep Collection Time: 2.32892
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.75992

Cumulative Model Updates: 117,478
Cumulative Timesteps: 980,608,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 980608038...
Checkpoint 980608038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,054.01006
Policy Entropy: 1.74919
Value Function Loss: 0.06970

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.34017
Value Function Update Magnitude: 0.40295

Collected Steps per Second: 20,696.41239
Overall Steps per Second: 10,405.61320

Timestep Collection Time: 2.41713
Timestep Consumption Time: 2.39046
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.80760

Cumulative Model Updates: 117,484
Cumulative Timesteps: 980,658,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,221.05527
Policy Entropy: 1.74407
Value Function Loss: 0.07178

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.34251
Value Function Update Magnitude: 0.39845

Collected Steps per Second: 20,956.68766
Overall Steps per Second: 10,203.33004

Timestep Collection Time: 2.38826
Timestep Consumption Time: 2.51700
PPO Batch Consumption Time: 0.30542
Total Iteration Time: 4.90526

Cumulative Model Updates: 117,490
Cumulative Timesteps: 980,708,114

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 980708114...
Checkpoint 980708114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,601.78694
Policy Entropy: 1.73720
Value Function Loss: 0.07514

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.34302
Value Function Update Magnitude: 0.38570

Collected Steps per Second: 21,039.37102
Overall Steps per Second: 10,438.37631

Timestep Collection Time: 2.37650
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.79002

Cumulative Model Updates: 117,496
Cumulative Timesteps: 980,758,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,115.21366
Policy Entropy: 1.73251
Value Function Loss: 0.07505

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.34166
Value Function Update Magnitude: 0.33430

Collected Steps per Second: 20,612.76349
Overall Steps per Second: 10,264.38046

Timestep Collection Time: 2.42588
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.87160

Cumulative Model Updates: 117,502
Cumulative Timesteps: 980,808,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 980808118...
Checkpoint 980808118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,467.86562
Policy Entropy: 1.73656
Value Function Loss: 0.07659

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.34334
Value Function Update Magnitude: 0.37719

Collected Steps per Second: 20,468.93009
Overall Steps per Second: 10,195.89412

Timestep Collection Time: 2.44273
Timestep Consumption Time: 2.46121
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 4.90393

Cumulative Model Updates: 117,508
Cumulative Timesteps: 980,858,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,993.64101
Policy Entropy: 1.73793
Value Function Loss: 0.07234

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.34629
Value Function Update Magnitude: 0.40344

Collected Steps per Second: 21,014.68936
Overall Steps per Second: 10,424.45279

Timestep Collection Time: 2.38024
Timestep Consumption Time: 2.41809
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.79833

Cumulative Model Updates: 117,514
Cumulative Timesteps: 980,908,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 980908138...
Checkpoint 980908138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,227.93337
Policy Entropy: 1.74317
Value Function Loss: 0.07292

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.34230
Value Function Update Magnitude: 0.40177

Collected Steps per Second: 20,958.17867
Overall Steps per Second: 10,551.78414

Timestep Collection Time: 2.38675
Timestep Consumption Time: 2.35387
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.74062

Cumulative Model Updates: 117,520
Cumulative Timesteps: 980,958,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,589.48119
Policy Entropy: 1.75060
Value Function Loss: 0.07963

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.33807
Value Function Update Magnitude: 0.39787

Collected Steps per Second: 20,803.10617
Overall Steps per Second: 10,183.54728

Timestep Collection Time: 2.40512
Timestep Consumption Time: 2.50810
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.91322

Cumulative Model Updates: 117,526
Cumulative Timesteps: 981,008,194

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 981008194...
Checkpoint 981008194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,243.96294
Policy Entropy: 1.75022
Value Function Loss: 0.08177

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.32437
Value Function Update Magnitude: 0.40544

Collected Steps per Second: 21,362.59489
Overall Steps per Second: 10,509.21134

Timestep Collection Time: 2.34213
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.76097

Cumulative Model Updates: 117,532
Cumulative Timesteps: 981,058,228

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,008.10719
Policy Entropy: 1.75330
Value Function Loss: 0.07959

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.33938
Value Function Update Magnitude: 0.40912

Collected Steps per Second: 21,094.33530
Overall Steps per Second: 10,440.67151

Timestep Collection Time: 2.37030
Timestep Consumption Time: 2.41866
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.78896

Cumulative Model Updates: 117,538
Cumulative Timesteps: 981,108,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 981108228...
Checkpoint 981108228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,761.60415
Policy Entropy: 1.74498
Value Function Loss: 0.07128

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.34219
Value Function Update Magnitude: 0.40110

Collected Steps per Second: 21,376.31819
Overall Steps per Second: 10,318.21825

Timestep Collection Time: 2.33913
Timestep Consumption Time: 2.50686
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.84599

Cumulative Model Updates: 117,544
Cumulative Timesteps: 981,158,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,640.80459
Policy Entropy: 1.74926
Value Function Loss: 0.06880

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.33647
Value Function Update Magnitude: 0.39133

Collected Steps per Second: 21,901.54659
Overall Steps per Second: 10,361.77495

Timestep Collection Time: 2.28294
Timestep Consumption Time: 2.54248
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.82543

Cumulative Model Updates: 117,550
Cumulative Timesteps: 981,208,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 981208230...
Checkpoint 981208230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,111.45704
Policy Entropy: 1.74410
Value Function Loss: 0.07250

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.33994
Value Function Update Magnitude: 0.39081

Collected Steps per Second: 21,432.59673
Overall Steps per Second: 10,310.15291

Timestep Collection Time: 2.33345
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.85075

Cumulative Model Updates: 117,556
Cumulative Timesteps: 981,258,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,536.79511
Policy Entropy: 1.74058
Value Function Loss: 0.07136

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.33951
Value Function Update Magnitude: 0.38807

Collected Steps per Second: 21,728.27878
Overall Steps per Second: 10,404.47062

Timestep Collection Time: 2.30179
Timestep Consumption Time: 2.50518
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.80697

Cumulative Model Updates: 117,562
Cumulative Timesteps: 981,308,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 981308256...
Checkpoint 981308256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,228.05421
Policy Entropy: 1.72803
Value Function Loss: 0.07216

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.33949
Value Function Update Magnitude: 0.36364

Collected Steps per Second: 21,346.73170
Overall Steps per Second: 10,151.55883

Timestep Collection Time: 2.34265
Timestep Consumption Time: 2.58349
PPO Batch Consumption Time: 0.30504
Total Iteration Time: 4.92614

Cumulative Model Updates: 117,568
Cumulative Timesteps: 981,358,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,028.58151
Policy Entropy: 1.72221
Value Function Loss: 0.06724

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.33694
Value Function Update Magnitude: 0.35503

Collected Steps per Second: 20,684.68423
Overall Steps per Second: 10,087.72150

Timestep Collection Time: 2.41763
Timestep Consumption Time: 2.53968
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.95731

Cumulative Model Updates: 117,574
Cumulative Timesteps: 981,408,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 981408272...
Checkpoint 981408272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,674.74448
Policy Entropy: 1.71427
Value Function Loss: 0.06604

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.33036
Value Function Update Magnitude: 0.36213

Collected Steps per Second: 21,643.14430
Overall Steps per Second: 10,385.49443

Timestep Collection Time: 2.31168
Timestep Consumption Time: 2.50581
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.81749

Cumulative Model Updates: 117,580
Cumulative Timesteps: 981,458,304

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,601.46961
Policy Entropy: 1.71306
Value Function Loss: 0.06667

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.32908
Value Function Update Magnitude: 0.36339

Collected Steps per Second: 21,703.96474
Overall Steps per Second: 10,323.14511

Timestep Collection Time: 2.30456
Timestep Consumption Time: 2.54067
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.84523

Cumulative Model Updates: 117,586
Cumulative Timesteps: 981,508,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 981508322...
Checkpoint 981508322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,587.24452
Policy Entropy: 1.71486
Value Function Loss: 0.07262

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.33322
Value Function Update Magnitude: 0.37031

Collected Steps per Second: 21,424.11348
Overall Steps per Second: 10,349.91149

Timestep Collection Time: 2.33531
Timestep Consumption Time: 2.49874
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.83405

Cumulative Model Updates: 117,592
Cumulative Timesteps: 981,558,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,149.18966
Policy Entropy: 1.71660
Value Function Loss: 0.07620

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.34072
Value Function Update Magnitude: 0.39014

Collected Steps per Second: 21,574.54587
Overall Steps per Second: 10,339.42614

Timestep Collection Time: 2.31829
Timestep Consumption Time: 2.51912
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.83741

Cumulative Model Updates: 117,598
Cumulative Timesteps: 981,608,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 981608370...
Checkpoint 981608370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,190.83970
Policy Entropy: 1.72312
Value Function Loss: 0.07119

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.33910
Value Function Update Magnitude: 0.38998

Collected Steps per Second: 21,632.13919
Overall Steps per Second: 10,506.34244

Timestep Collection Time: 2.31212
Timestep Consumption Time: 2.44844
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.76055

Cumulative Model Updates: 117,604
Cumulative Timesteps: 981,658,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,963.44137
Policy Entropy: 1.72473
Value Function Loss: 0.07332

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.33435
Value Function Update Magnitude: 0.38758

Collected Steps per Second: 20,685.93276
Overall Steps per Second: 9,959.53523

Timestep Collection Time: 2.41797
Timestep Consumption Time: 2.60415
PPO Batch Consumption Time: 0.30971
Total Iteration Time: 5.02212

Cumulative Model Updates: 117,610
Cumulative Timesteps: 981,708,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 981708404...
Checkpoint 981708404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,033.84751
Policy Entropy: 1.71986
Value Function Loss: 0.07432

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.33813
Value Function Update Magnitude: 0.39340

Collected Steps per Second: 21,404.45552
Overall Steps per Second: 10,329.80689

Timestep Collection Time: 2.33634
Timestep Consumption Time: 2.50480
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.84114

Cumulative Model Updates: 117,616
Cumulative Timesteps: 981,758,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,376.38632
Policy Entropy: 1.71961
Value Function Loss: 0.07698

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.34166
Value Function Update Magnitude: 0.39721

Collected Steps per Second: 21,273.29514
Overall Steps per Second: 10,433.70345

Timestep Collection Time: 2.35224
Timestep Consumption Time: 2.44375
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.79600

Cumulative Model Updates: 117,622
Cumulative Timesteps: 981,808,452

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 981808452...
Checkpoint 981808452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,742.04256
Policy Entropy: 1.71696
Value Function Loss: 0.07529

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.34171
Value Function Update Magnitude: 0.39625

Collected Steps per Second: 21,140.27827
Overall Steps per Second: 10,225.68075

Timestep Collection Time: 2.36591
Timestep Consumption Time: 2.52530
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.89121

Cumulative Model Updates: 117,628
Cumulative Timesteps: 981,858,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,698.62002
Policy Entropy: 1.72735
Value Function Loss: 0.07672

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.34178
Value Function Update Magnitude: 0.39243

Collected Steps per Second: 21,794.60114
Overall Steps per Second: 10,487.61254

Timestep Collection Time: 2.29451
Timestep Consumption Time: 2.47378
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.76829

Cumulative Model Updates: 117,634
Cumulative Timesteps: 981,908,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 981908476...
Checkpoint 981908476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,256.05292
Policy Entropy: 1.72942
Value Function Loss: 0.07279

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.33988
Value Function Update Magnitude: 0.34736

Collected Steps per Second: 21,285.85851
Overall Steps per Second: 10,283.43898

Timestep Collection Time: 2.35029
Timestep Consumption Time: 2.51462
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.86491

Cumulative Model Updates: 117,640
Cumulative Timesteps: 981,958,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,830.16859
Policy Entropy: 1.72894
Value Function Loss: 0.06992

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.33616
Value Function Update Magnitude: 0.34999

Collected Steps per Second: 21,179.70069
Overall Steps per Second: 9,714.42010

Timestep Collection Time: 2.36132
Timestep Consumption Time: 2.78691
PPO Batch Consumption Time: 0.31824
Total Iteration Time: 5.14822

Cumulative Model Updates: 117,646
Cumulative Timesteps: 982,008,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 982008516...
Checkpoint 982008516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,535.26102
Policy Entropy: 1.72931
Value Function Loss: 0.06602

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.33011
Value Function Update Magnitude: 0.37728

Collected Steps per Second: 17,101.15898
Overall Steps per Second: 9,152.34381

Timestep Collection Time: 2.92436
Timestep Consumption Time: 2.53981
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 5.46417

Cumulative Model Updates: 117,652
Cumulative Timesteps: 982,058,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,561.82145
Policy Entropy: 1.72601
Value Function Loss: 0.06768

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.31914
Value Function Update Magnitude: 0.38682

Collected Steps per Second: 20,331.86494
Overall Steps per Second: 9,373.17141

Timestep Collection Time: 2.46037
Timestep Consumption Time: 2.87656
PPO Batch Consumption Time: 0.33296
Total Iteration Time: 5.33693

Cumulative Model Updates: 117,658
Cumulative Timesteps: 982,108,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 982108550...
Checkpoint 982108550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,249.32543
Policy Entropy: 1.73117
Value Function Loss: 0.07149

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.32427
Value Function Update Magnitude: 0.38325

Collected Steps per Second: 19,029.70641
Overall Steps per Second: 9,597.97171

Timestep Collection Time: 2.62831
Timestep Consumption Time: 2.58279
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 5.21110

Cumulative Model Updates: 117,664
Cumulative Timesteps: 982,158,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,860.02751
Policy Entropy: 1.73125
Value Function Loss: 0.07158

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.33308
Value Function Update Magnitude: 0.38869

Collected Steps per Second: 20,807.30219
Overall Steps per Second: 10,234.53362

Timestep Collection Time: 2.40377
Timestep Consumption Time: 2.48321
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.88698

Cumulative Model Updates: 117,670
Cumulative Timesteps: 982,208,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 982208582...
Checkpoint 982208582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,750.67543
Policy Entropy: 1.74369
Value Function Loss: 0.06732

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.32916
Value Function Update Magnitude: 0.38807

Collected Steps per Second: 20,460.33337
Overall Steps per Second: 9,593.57354

Timestep Collection Time: 2.44463
Timestep Consumption Time: 2.76907
PPO Batch Consumption Time: 0.33173
Total Iteration Time: 5.21370

Cumulative Model Updates: 117,676
Cumulative Timesteps: 982,258,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,488.32181
Policy Entropy: 1.75203
Value Function Loss: 0.06513

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.32912
Value Function Update Magnitude: 0.37383

Collected Steps per Second: 20,700.13603
Overall Steps per Second: 9,944.85265

Timestep Collection Time: 2.41564
Timestep Consumption Time: 2.61249
PPO Batch Consumption Time: 0.30740
Total Iteration Time: 5.02813

Cumulative Model Updates: 117,682
Cumulative Timesteps: 982,308,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 982308604...
Checkpoint 982308604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,998.40094
Policy Entropy: 1.74956
Value Function Loss: 0.06559

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.33305
Value Function Update Magnitude: 0.35949

Collected Steps per Second: 19,719.73156
Overall Steps per Second: 9,925.49311

Timestep Collection Time: 2.53614
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 5.03874

Cumulative Model Updates: 117,688
Cumulative Timesteps: 982,358,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,580.35612
Policy Entropy: 1.73069
Value Function Loss: 0.06479

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.33176
Value Function Update Magnitude: 0.36949

Collected Steps per Second: 19,929.29392
Overall Steps per Second: 9,852.01278

Timestep Collection Time: 2.50957
Timestep Consumption Time: 2.56695
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 5.07653

Cumulative Model Updates: 117,694
Cumulative Timesteps: 982,408,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 982408630...
Checkpoint 982408630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,798.71433
Policy Entropy: 1.73018
Value Function Loss: 0.06407

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.32831
Value Function Update Magnitude: 0.36553

Collected Steps per Second: 19,799.53721
Overall Steps per Second: 9,957.74767

Timestep Collection Time: 2.52572
Timestep Consumption Time: 2.49630
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 5.02202

Cumulative Model Updates: 117,700
Cumulative Timesteps: 982,458,638

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,874.08826
Policy Entropy: 1.71955
Value Function Loss: 0.06311

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.32297
Value Function Update Magnitude: 0.34623

Collected Steps per Second: 21,163.40248
Overall Steps per Second: 10,136.51901

Timestep Collection Time: 2.36380
Timestep Consumption Time: 2.57143
PPO Batch Consumption Time: 0.29946
Total Iteration Time: 4.93522

Cumulative Model Updates: 117,706
Cumulative Timesteps: 982,508,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 982508664...
Checkpoint 982508664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,794.29631
Policy Entropy: 1.72011
Value Function Loss: 0.06812

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07551
Policy Update Magnitude: 0.32712
Value Function Update Magnitude: 0.35234

Collected Steps per Second: 19,766.01519
Overall Steps per Second: 9,808.91506

Timestep Collection Time: 2.52980
Timestep Consumption Time: 2.56801
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 5.09781

Cumulative Model Updates: 117,712
Cumulative Timesteps: 982,558,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,992.48349
Policy Entropy: 1.70349
Value Function Loss: 0.07372

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.33804
Value Function Update Magnitude: 0.38338

Collected Steps per Second: 19,393.12328
Overall Steps per Second: 9,858.51006

Timestep Collection Time: 2.57896
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 5.07318

Cumulative Model Updates: 117,718
Cumulative Timesteps: 982,608,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 982608682...
Checkpoint 982608682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,685.34032
Policy Entropy: 1.71194
Value Function Loss: 0.07779

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.34225
Value Function Update Magnitude: 0.38392

Collected Steps per Second: 20,671.74450
Overall Steps per Second: 10,218.14207

Timestep Collection Time: 2.41982
Timestep Consumption Time: 2.47559
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.89541

Cumulative Model Updates: 117,724
Cumulative Timesteps: 982,658,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,741.20017
Policy Entropy: 1.70502
Value Function Loss: 0.07712

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.34255
Value Function Update Magnitude: 0.35274

Collected Steps per Second: 21,398.59484
Overall Steps per Second: 10,361.17578

Timestep Collection Time: 2.33744
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.82744

Cumulative Model Updates: 117,730
Cumulative Timesteps: 982,708,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 982708722...
Checkpoint 982708722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,554.51663
Policy Entropy: 1.70837
Value Function Loss: 0.07096

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.33511
Value Function Update Magnitude: 0.37231

Collected Steps per Second: 21,572.94681
Overall Steps per Second: 10,414.39942

Timestep Collection Time: 2.31911
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.80393

Cumulative Model Updates: 117,736
Cumulative Timesteps: 982,758,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,964.96145
Policy Entropy: 1.70675
Value Function Loss: 0.06621

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.33186
Value Function Update Magnitude: 0.37024

Collected Steps per Second: 21,366.44491
Overall Steps per Second: 10,304.29763

Timestep Collection Time: 2.34031
Timestep Consumption Time: 2.51243
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.85273

Cumulative Model Updates: 117,742
Cumulative Timesteps: 982,808,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 982808756...
Checkpoint 982808756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,451.80112
Policy Entropy: 1.70685
Value Function Loss: 0.06680

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.33207
Value Function Update Magnitude: 0.36542

Collected Steps per Second: 21,537.57091
Overall Steps per Second: 10,301.58177

Timestep Collection Time: 2.32264
Timestep Consumption Time: 2.53331
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.85595

Cumulative Model Updates: 117,748
Cumulative Timesteps: 982,858,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,146.86584
Policy Entropy: 1.71518
Value Function Loss: 0.07230

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.33811
Value Function Update Magnitude: 0.36506

Collected Steps per Second: 21,511.28960
Overall Steps per Second: 10,361.47897

Timestep Collection Time: 2.32501
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.82692

Cumulative Model Updates: 117,754
Cumulative Timesteps: 982,908,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 982908794...
Checkpoint 982908794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,421.30659
Policy Entropy: 1.71772
Value Function Loss: 0.07308

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.34287
Value Function Update Magnitude: 0.35817

Collected Steps per Second: 20,974.94718
Overall Steps per Second: 10,194.25869

Timestep Collection Time: 2.38485
Timestep Consumption Time: 2.52203
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.90688

Cumulative Model Updates: 117,760
Cumulative Timesteps: 982,958,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,260.37529
Policy Entropy: 1.72394
Value Function Loss: 0.08051

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.34734
Value Function Update Magnitude: 0.37232

Collected Steps per Second: 20,980.47905
Overall Steps per Second: 10,201.83515

Timestep Collection Time: 2.38317
Timestep Consumption Time: 2.51791
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.90108

Cumulative Model Updates: 117,766
Cumulative Timesteps: 983,008,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 983008816...
Checkpoint 983008816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,955.94041
Policy Entropy: 1.72088
Value Function Loss: 0.08172

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.35141
Value Function Update Magnitude: 0.39976

Collected Steps per Second: 21,201.01706
Overall Steps per Second: 10,275.33986

Timestep Collection Time: 2.35885
Timestep Consumption Time: 2.50814
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.86699

Cumulative Model Updates: 117,772
Cumulative Timesteps: 983,058,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,028.74620
Policy Entropy: 1.73270
Value Function Loss: 0.07880

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.34838
Value Function Update Magnitude: 0.42054

Collected Steps per Second: 21,359.32511
Overall Steps per Second: 10,461.38611

Timestep Collection Time: 2.34212
Timestep Consumption Time: 2.43985
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.78197

Cumulative Model Updates: 117,778
Cumulative Timesteps: 983,108,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 983108852...
Checkpoint 983108852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,859.51978
Policy Entropy: 1.73272
Value Function Loss: 0.07154

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.34161
Value Function Update Magnitude: 0.43104

Collected Steps per Second: 21,632.69407
Overall Steps per Second: 10,541.75428

Timestep Collection Time: 2.31224
Timestep Consumption Time: 2.43270
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.74494

Cumulative Model Updates: 117,784
Cumulative Timesteps: 983,158,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,503.76222
Policy Entropy: 1.73600
Value Function Loss: 0.07081

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.33651
Value Function Update Magnitude: 0.41024

Collected Steps per Second: 21,880.17985
Overall Steps per Second: 10,550.73406

Timestep Collection Time: 2.28554
Timestep Consumption Time: 2.45423
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.73976

Cumulative Model Updates: 117,790
Cumulative Timesteps: 983,208,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 983208880...
Checkpoint 983208880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,448.33018
Policy Entropy: 1.74409
Value Function Loss: 0.06785

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.33356
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 21,566.58344
Overall Steps per Second: 10,497.22181

Timestep Collection Time: 2.31859
Timestep Consumption Time: 2.44496
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.76355

Cumulative Model Updates: 117,796
Cumulative Timesteps: 983,258,884

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,213.05099
Policy Entropy: 1.73398
Value Function Loss: 0.06964

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.33493
Value Function Update Magnitude: 0.36754

Collected Steps per Second: 21,881.23778
Overall Steps per Second: 10,602.98009

Timestep Collection Time: 2.28552
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.71660

Cumulative Model Updates: 117,802
Cumulative Timesteps: 983,308,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 983308894...
Checkpoint 983308894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,832.90706
Policy Entropy: 1.73394
Value Function Loss: 0.07162

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.33740
Value Function Update Magnitude: 0.38400

Collected Steps per Second: 20,946.30744
Overall Steps per Second: 10,189.99513

Timestep Collection Time: 2.38801
Timestep Consumption Time: 2.52073
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.90874

Cumulative Model Updates: 117,808
Cumulative Timesteps: 983,358,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,210.56366
Policy Entropy: 1.71478
Value Function Loss: 0.07593

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08639
Policy Update Magnitude: 0.34165
Value Function Update Magnitude: 0.39076

Collected Steps per Second: 20,023.44728
Overall Steps per Second: 10,157.35886

Timestep Collection Time: 2.49837
Timestep Consumption Time: 2.42673
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.92510

Cumulative Model Updates: 117,814
Cumulative Timesteps: 983,408,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 983408940...
Checkpoint 983408940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,602.22698
Policy Entropy: 1.72324
Value Function Loss: 0.08417

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.34917
Value Function Update Magnitude: 0.39106

Collected Steps per Second: 21,162.89722
Overall Steps per Second: 10,451.88892

Timestep Collection Time: 2.36319
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.78497

Cumulative Model Updates: 117,820
Cumulative Timesteps: 983,458,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,905.57739
Policy Entropy: 1.71203
Value Function Loss: 0.07957

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.35384
Value Function Update Magnitude: 0.39566

Collected Steps per Second: 21,001.81417
Overall Steps per Second: 10,561.25044

Timestep Collection Time: 2.38103
Timestep Consumption Time: 2.35382
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.73486

Cumulative Model Updates: 117,826
Cumulative Timesteps: 983,508,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 983508958...
Checkpoint 983508958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,367.72536
Policy Entropy: 1.71534
Value Function Loss: 0.07585

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.34689
Value Function Update Magnitude: 0.40638

Collected Steps per Second: 20,881.17228
Overall Steps per Second: 10,416.11904

Timestep Collection Time: 2.39584
Timestep Consumption Time: 2.40710
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.80294

Cumulative Model Updates: 117,832
Cumulative Timesteps: 983,558,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,002.81951
Policy Entropy: 1.71878
Value Function Loss: 0.06629

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.33418
Value Function Update Magnitude: 0.39109

Collected Steps per Second: 21,074.48794
Overall Steps per Second: 10,394.80560

Timestep Collection Time: 2.37339
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.81183

Cumulative Model Updates: 117,838
Cumulative Timesteps: 983,609,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 983609004...
Checkpoint 983609004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,217.96963
Policy Entropy: 1.72407
Value Function Loss: 0.07695

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07825
Policy Update Magnitude: 0.33503
Value Function Update Magnitude: 0.35630

Collected Steps per Second: 17,932.58443
Overall Steps per Second: 9,071.55323

Timestep Collection Time: 2.78889
Timestep Consumption Time: 2.72417
PPO Batch Consumption Time: 0.33102
Total Iteration Time: 5.51306

Cumulative Model Updates: 117,844
Cumulative Timesteps: 983,659,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,393.98632
Policy Entropy: 1.70584
Value Function Loss: 0.08183

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.34863
Value Function Update Magnitude: 0.39239

Collected Steps per Second: 20,737.95329
Overall Steps per Second: 9,889.73296

Timestep Collection Time: 2.41123
Timestep Consumption Time: 2.64492
PPO Batch Consumption Time: 0.32577
Total Iteration Time: 5.05615

Cumulative Model Updates: 117,850
Cumulative Timesteps: 983,709,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 983709020...
Checkpoint 983709020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,076.87356
Policy Entropy: 1.69705
Value Function Loss: 0.08301

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.35003
Value Function Update Magnitude: 0.43272

Collected Steps per Second: 18,313.36951
Overall Steps per Second: 9,658.74228

Timestep Collection Time: 2.73036
Timestep Consumption Time: 2.44651
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 5.17686

Cumulative Model Updates: 117,856
Cumulative Timesteps: 983,759,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,333.24328
Policy Entropy: 1.68573
Value Function Loss: 0.07477

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.34246
Value Function Update Magnitude: 0.41555

Collected Steps per Second: 18,335.59086
Overall Steps per Second: 8,944.26942

Timestep Collection Time: 2.72857
Timestep Consumption Time: 2.86495
PPO Batch Consumption Time: 0.34879
Total Iteration Time: 5.59353

Cumulative Model Updates: 117,862
Cumulative Timesteps: 983,809,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 983809052...
Checkpoint 983809052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,923.90010
Policy Entropy: 1.69690
Value Function Loss: 0.07305

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.33917
Value Function Update Magnitude: 0.40243

Collected Steps per Second: 18,706.65006
Overall Steps per Second: 9,401.68918

Timestep Collection Time: 2.67456
Timestep Consumption Time: 2.64704
PPO Batch Consumption Time: 0.31463
Total Iteration Time: 5.32160

Cumulative Model Updates: 117,868
Cumulative Timesteps: 983,859,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,320.44132
Policy Entropy: 1.70431
Value Function Loss: 0.07144

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.33496
Value Function Update Magnitude: 0.41802

Collected Steps per Second: 21,765.87288
Overall Steps per Second: 10,605.58857

Timestep Collection Time: 2.29736
Timestep Consumption Time: 2.41751
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.71487

Cumulative Model Updates: 117,874
Cumulative Timesteps: 983,909,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 983909088...
Checkpoint 983909088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,970.05289
Policy Entropy: 1.72216
Value Function Loss: 0.06798

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.33530
Value Function Update Magnitude: 0.41678

Collected Steps per Second: 21,200.57609
Overall Steps per Second: 10,266.61630

Timestep Collection Time: 2.35899
Timestep Consumption Time: 2.51233
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.87132

Cumulative Model Updates: 117,880
Cumulative Timesteps: 983,959,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,199.24907
Policy Entropy: 1.72538
Value Function Loss: 0.06940

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.33524
Value Function Update Magnitude: 0.39368

Collected Steps per Second: 21,098.53328
Overall Steps per Second: 10,250.92596

Timestep Collection Time: 2.37097
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.87995

Cumulative Model Updates: 117,886
Cumulative Timesteps: 984,009,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 984009124...
Checkpoint 984009124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,453.79607
Policy Entropy: 1.73378
Value Function Loss: 0.07103

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.33609
Value Function Update Magnitude: 0.38851

Collected Steps per Second: 20,711.61199
Overall Steps per Second: 10,043.54479

Timestep Collection Time: 2.41439
Timestep Consumption Time: 2.56453
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 4.97892

Cumulative Model Updates: 117,892
Cumulative Timesteps: 984,059,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,402.86703
Policy Entropy: 1.73156
Value Function Loss: 0.06868

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.33341
Value Function Update Magnitude: 0.38359

Collected Steps per Second: 21,381.40776
Overall Steps per Second: 10,187.80633

Timestep Collection Time: 2.33857
Timestep Consumption Time: 2.56945
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.90802

Cumulative Model Updates: 117,898
Cumulative Timesteps: 984,109,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 984109132...
Checkpoint 984109132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,419.15019
Policy Entropy: 1.72823
Value Function Loss: 0.06696

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08284
Policy Update Magnitude: 0.33010
Value Function Update Magnitude: 0.34958

Collected Steps per Second: 19,748.29567
Overall Steps per Second: 9,858.77010

Timestep Collection Time: 2.53369
Timestep Consumption Time: 2.54159
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 5.07528

Cumulative Model Updates: 117,904
Cumulative Timesteps: 984,159,168

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,589.51384
Policy Entropy: 1.72154
Value Function Loss: 0.07280

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.33163
Value Function Update Magnitude: 0.34648

Collected Steps per Second: 21,348.36484
Overall Steps per Second: 10,198.26375

Timestep Collection Time: 2.34416
Timestep Consumption Time: 2.56295
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.90711

Cumulative Model Updates: 117,910
Cumulative Timesteps: 984,209,212

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 984209212...
Checkpoint 984209212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,734.88138
Policy Entropy: 1.71471
Value Function Loss: 0.07138

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.33286
Value Function Update Magnitude: 0.35009

Collected Steps per Second: 20,719.12320
Overall Steps per Second: 10,157.67603

Timestep Collection Time: 2.41477
Timestep Consumption Time: 2.51076
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.92554

Cumulative Model Updates: 117,916
Cumulative Timesteps: 984,259,244

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,935.48019
Policy Entropy: 1.71400
Value Function Loss: 0.06680

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.33146
Value Function Update Magnitude: 0.35274

Collected Steps per Second: 21,838.38443
Overall Steps per Second: 10,584.54430

Timestep Collection Time: 2.29083
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.72651

Cumulative Model Updates: 117,922
Cumulative Timesteps: 984,309,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 984309272...
Checkpoint 984309272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,488.23730
Policy Entropy: 1.71485
Value Function Loss: 0.06439

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.32752
Value Function Update Magnitude: 0.35032

Collected Steps per Second: 21,043.32489
Overall Steps per Second: 10,243.95385

Timestep Collection Time: 2.37814
Timestep Consumption Time: 2.50708
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.88522

Cumulative Model Updates: 117,928
Cumulative Timesteps: 984,359,316

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,249.79890
Policy Entropy: 1.72167
Value Function Loss: 0.06334

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.32572
Value Function Update Magnitude: 0.34948

Collected Steps per Second: 21,300.53472
Overall Steps per Second: 10,387.70741

Timestep Collection Time: 2.34755
Timestep Consumption Time: 2.46622
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.81377

Cumulative Model Updates: 117,934
Cumulative Timesteps: 984,409,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 984409320...
Checkpoint 984409320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,936.46588
Policy Entropy: 1.72091
Value Function Loss: 0.07095

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.33182
Value Function Update Magnitude: 0.36067

Collected Steps per Second: 21,121.99868
Overall Steps per Second: 10,238.81309

Timestep Collection Time: 2.36739
Timestep Consumption Time: 2.51638
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.88377

Cumulative Model Updates: 117,940
Cumulative Timesteps: 984,459,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,425.20251
Policy Entropy: 1.72537
Value Function Loss: 0.06820

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.33363
Value Function Update Magnitude: 0.37383

Collected Steps per Second: 20,851.02330
Overall Steps per Second: 10,418.68656

Timestep Collection Time: 2.39825
Timestep Consumption Time: 2.40139
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.79965

Cumulative Model Updates: 117,946
Cumulative Timesteps: 984,509,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 984509330...
Checkpoint 984509330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,968.34321
Policy Entropy: 1.73290
Value Function Loss: 0.06842

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.32782
Value Function Update Magnitude: 0.36946

Collected Steps per Second: 19,720.39031
Overall Steps per Second: 9,451.64116

Timestep Collection Time: 2.53616
Timestep Consumption Time: 2.75541
PPO Batch Consumption Time: 0.33259
Total Iteration Time: 5.29157

Cumulative Model Updates: 117,952
Cumulative Timesteps: 984,559,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,138.35965
Policy Entropy: 1.71864
Value Function Loss: 0.06648

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.31775
Value Function Update Magnitude: 0.36206

Collected Steps per Second: 18,586.22557
Overall Steps per Second: 9,213.77726

Timestep Collection Time: 2.69059
Timestep Consumption Time: 2.73693
PPO Batch Consumption Time: 0.33870
Total Iteration Time: 5.42752

Cumulative Model Updates: 117,958
Cumulative Timesteps: 984,609,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 984609352...
Checkpoint 984609352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,566.77335
Policy Entropy: 1.71734
Value Function Loss: 0.06476

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.32220
Value Function Update Magnitude: 0.37400

Collected Steps per Second: 17,684.64859
Overall Steps per Second: 9,347.81196

Timestep Collection Time: 2.82754
Timestep Consumption Time: 2.52174
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 5.34927

Cumulative Model Updates: 117,964
Cumulative Timesteps: 984,659,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,293.66647
Policy Entropy: 1.70327
Value Function Loss: 0.06744

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.32708
Value Function Update Magnitude: 0.36792

Collected Steps per Second: 18,980.60143
Overall Steps per Second: 8,898.66685

Timestep Collection Time: 2.63490
Timestep Consumption Time: 2.98527
PPO Batch Consumption Time: 0.35884
Total Iteration Time: 5.62017

Cumulative Model Updates: 117,970
Cumulative Timesteps: 984,709,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 984709368...
Checkpoint 984709368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,510.90296
Policy Entropy: 1.72077
Value Function Loss: 0.07148

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.33739
Value Function Update Magnitude: 0.35804

Collected Steps per Second: 18,572.74453
Overall Steps per Second: 8,763.91579

Timestep Collection Time: 2.69233
Timestep Consumption Time: 3.01334
PPO Batch Consumption Time: 0.36232
Total Iteration Time: 5.70567

Cumulative Model Updates: 117,976
Cumulative Timesteps: 984,759,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,818.97876
Policy Entropy: 1.72373
Value Function Loss: 0.07249

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.33729
Value Function Update Magnitude: 0.36084

Collected Steps per Second: 18,754.86667
Overall Steps per Second: 9,701.23413

Timestep Collection Time: 2.66789
Timestep Consumption Time: 2.48980
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 5.15769

Cumulative Model Updates: 117,982
Cumulative Timesteps: 984,809,408

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 984809408...
Checkpoint 984809408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,054.31878
Policy Entropy: 1.73118
Value Function Loss: 0.06930

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.32066
Value Function Update Magnitude: 0.35948

Collected Steps per Second: 20,304.02972
Overall Steps per Second: 10,108.73578

Timestep Collection Time: 2.46454
Timestep Consumption Time: 2.48564
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.95017

Cumulative Model Updates: 117,988
Cumulative Timesteps: 984,859,448

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,820.81825
Policy Entropy: 1.73319
Value Function Loss: 0.06403

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.29729
Value Function Update Magnitude: 0.34770

Collected Steps per Second: 21,891.17192
Overall Steps per Second: 10,357.33982

Timestep Collection Time: 2.28457
Timestep Consumption Time: 2.54408
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.82865

Cumulative Model Updates: 117,994
Cumulative Timesteps: 984,909,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 984909460...
Checkpoint 984909460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,069.45413
Policy Entropy: 1.73727
Value Function Loss: 0.06653

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.30824
Value Function Update Magnitude: 0.33406

Collected Steps per Second: 21,432.87333
Overall Steps per Second: 10,302.69645

Timestep Collection Time: 2.33352
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.85446

Cumulative Model Updates: 118,000
Cumulative Timesteps: 984,959,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,112.78828
Policy Entropy: 1.73966
Value Function Loss: 0.06944

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.32396
Value Function Update Magnitude: 0.34561

Collected Steps per Second: 21,871.21546
Overall Steps per Second: 10,379.52868

Timestep Collection Time: 2.28693
Timestep Consumption Time: 2.53198
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.81891

Cumulative Model Updates: 118,006
Cumulative Timesteps: 985,009,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 985009492...
Checkpoint 985009492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,456.32487
Policy Entropy: 1.72413
Value Function Loss: 0.06960

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.32970
Value Function Update Magnitude: 0.33432

Collected Steps per Second: 17,705.04739
Overall Steps per Second: 9,055.43591

Timestep Collection Time: 2.82507
Timestep Consumption Time: 2.69846
PPO Batch Consumption Time: 0.30605
Total Iteration Time: 5.52353

Cumulative Model Updates: 118,012
Cumulative Timesteps: 985,059,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,096.97348
Policy Entropy: 1.71922
Value Function Loss: 0.07423

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07883
Policy Update Magnitude: 0.33276
Value Function Update Magnitude: 0.33509

Collected Steps per Second: 19,589.55443
Overall Steps per Second: 10,044.55903

Timestep Collection Time: 2.55381
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.98061

Cumulative Model Updates: 118,018
Cumulative Timesteps: 985,109,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 985109538...
Checkpoint 985109538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,392.27163
Policy Entropy: 1.71564
Value Function Loss: 0.07521

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.33657
Value Function Update Magnitude: 0.35001

Collected Steps per Second: 19,709.15828
Overall Steps per Second: 9,896.90363

Timestep Collection Time: 2.53730
Timestep Consumption Time: 2.51560
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 5.05289

Cumulative Model Updates: 118,024
Cumulative Timesteps: 985,159,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,329.89673
Policy Entropy: 1.71023
Value Function Loss: 0.07725

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.33748
Value Function Update Magnitude: 0.33113

Collected Steps per Second: 20,856.19827
Overall Steps per Second: 10,000.21633

Timestep Collection Time: 2.39823
Timestep Consumption Time: 2.60346
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 5.00169

Cumulative Model Updates: 118,030
Cumulative Timesteps: 985,209,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 985209564...
Checkpoint 985209564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,915.75438
Policy Entropy: 1.70465
Value Function Loss: 0.07597

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.33817
Value Function Update Magnitude: 0.32699

Collected Steps per Second: 20,435.72820
Overall Steps per Second: 9,740.27858

Timestep Collection Time: 2.44728
Timestep Consumption Time: 2.68727
PPO Batch Consumption Time: 0.31726
Total Iteration Time: 5.13456

Cumulative Model Updates: 118,036
Cumulative Timesteps: 985,259,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,283.83789
Policy Entropy: 1.70916
Value Function Loss: 0.07531

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.33671
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 21,483.25578
Overall Steps per Second: 10,262.43395

Timestep Collection Time: 2.32898
Timestep Consumption Time: 2.54647
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.87545

Cumulative Model Updates: 118,042
Cumulative Timesteps: 985,309,610

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 985309610...
Checkpoint 985309610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,713.63033
Policy Entropy: 1.70737
Value Function Loss: 0.07661

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.34315
Value Function Update Magnitude: 0.35511

Collected Steps per Second: 20,206.30635
Overall Steps per Second: 10,052.80062

Timestep Collection Time: 2.47497
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.97473

Cumulative Model Updates: 118,048
Cumulative Timesteps: 985,359,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,916.40146
Policy Entropy: 1.71716
Value Function Loss: 0.07769

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.34503
Value Function Update Magnitude: 0.37854

Collected Steps per Second: 19,744.16907
Overall Steps per Second: 9,875.26914

Timestep Collection Time: 2.53300
Timestep Consumption Time: 2.53137
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 5.06437

Cumulative Model Updates: 118,054
Cumulative Timesteps: 985,409,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 985409632...
Checkpoint 985409632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,849.39070
Policy Entropy: 1.70983
Value Function Loss: 0.07796

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.33950
Value Function Update Magnitude: 0.39270

Collected Steps per Second: 19,583.11949
Overall Steps per Second: 9,981.43508

Timestep Collection Time: 2.55404
Timestep Consumption Time: 2.45687
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 5.01090

Cumulative Model Updates: 118,060
Cumulative Timesteps: 985,459,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,585.65073
Policy Entropy: 1.70596
Value Function Loss: 0.07967

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.33940
Value Function Update Magnitude: 0.38019

Collected Steps per Second: 20,998.80004
Overall Steps per Second: 10,146.29475

Timestep Collection Time: 2.38166
Timestep Consumption Time: 2.54743
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.92909

Cumulative Model Updates: 118,066
Cumulative Timesteps: 985,509,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 985509660...
Checkpoint 985509660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,805.13197
Policy Entropy: 1.71117
Value Function Loss: 0.07618

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.34247
Value Function Update Magnitude: 0.36551

Collected Steps per Second: 18,081.70394
Overall Steps per Second: 8,944.51600

Timestep Collection Time: 2.76622
Timestep Consumption Time: 2.82581
PPO Batch Consumption Time: 0.33892
Total Iteration Time: 5.59203

Cumulative Model Updates: 118,072
Cumulative Timesteps: 985,559,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,904.96957
Policy Entropy: 1.72992
Value Function Loss: 0.07351

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.33778
Value Function Update Magnitude: 0.36425

Collected Steps per Second: 18,912.85147
Overall Steps per Second: 9,295.36729

Timestep Collection Time: 2.64370
Timestep Consumption Time: 2.73532
PPO Batch Consumption Time: 0.32255
Total Iteration Time: 5.37902

Cumulative Model Updates: 118,078
Cumulative Timesteps: 985,609,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 985609678...
Checkpoint 985609678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,299.67456
Policy Entropy: 1.74665
Value Function Loss: 0.07196

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.33727
Value Function Update Magnitude: 0.36128

Collected Steps per Second: 19,309.44937
Overall Steps per Second: 9,360.84251

Timestep Collection Time: 2.59023
Timestep Consumption Time: 2.75287
PPO Batch Consumption Time: 0.32100
Total Iteration Time: 5.34311

Cumulative Model Updates: 118,084
Cumulative Timesteps: 985,659,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,467.40867
Policy Entropy: 1.73786
Value Function Loss: 0.08204

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.34407
Value Function Update Magnitude: 0.37374

Collected Steps per Second: 20,284.15087
Overall Steps per Second: 10,244.14125

Timestep Collection Time: 2.46587
Timestep Consumption Time: 2.41673
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.88260

Cumulative Model Updates: 118,090
Cumulative Timesteps: 985,709,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 985709712...
Checkpoint 985709712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,784.54516
Policy Entropy: 1.73670
Value Function Loss: 0.08275

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.34517
Value Function Update Magnitude: 0.40015

Collected Steps per Second: 19,066.56773
Overall Steps per Second: 9,307.06783

Timestep Collection Time: 2.62313
Timestep Consumption Time: 2.75064
PPO Batch Consumption Time: 0.32245
Total Iteration Time: 5.37377

Cumulative Model Updates: 118,096
Cumulative Timesteps: 985,759,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,098.69748
Policy Entropy: 1.73718
Value Function Loss: 0.07892

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.31912
Value Function Update Magnitude: 0.39627

Collected Steps per Second: 20,601.25357
Overall Steps per Second: 9,585.53138

Timestep Collection Time: 2.42743
Timestep Consumption Time: 2.78960
PPO Batch Consumption Time: 0.32559
Total Iteration Time: 5.21703

Cumulative Model Updates: 118,102
Cumulative Timesteps: 985,809,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 985809734...
Checkpoint 985809734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,354.40121
Policy Entropy: 1.74005
Value Function Loss: 0.07003

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.30033
Value Function Update Magnitude: 0.37866

Collected Steps per Second: 19,225.24921
Overall Steps per Second: 9,341.05918

Timestep Collection Time: 2.60137
Timestep Consumption Time: 2.75263
PPO Batch Consumption Time: 0.33497
Total Iteration Time: 5.35400

Cumulative Model Updates: 118,108
Cumulative Timesteps: 985,859,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,486.09298
Policy Entropy: 1.73744
Value Function Loss: 0.06748

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.30960
Value Function Update Magnitude: 0.32590

Collected Steps per Second: 19,296.08755
Overall Steps per Second: 9,611.25560

Timestep Collection Time: 2.59151
Timestep Consumption Time: 2.61135
PPO Batch Consumption Time: 0.30889
Total Iteration Time: 5.20286

Cumulative Model Updates: 118,114
Cumulative Timesteps: 985,909,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 985909752...
Checkpoint 985909752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,166.04100
Policy Entropy: 1.72733
Value Function Loss: 0.06654

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.32275
Value Function Update Magnitude: 0.30781

Collected Steps per Second: 18,156.54703
Overall Steps per Second: 8,951.49470

Timestep Collection Time: 2.75449
Timestep Consumption Time: 2.83251
PPO Batch Consumption Time: 0.33889
Total Iteration Time: 5.58700

Cumulative Model Updates: 118,120
Cumulative Timesteps: 985,959,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,218.18021
Policy Entropy: 1.71926
Value Function Loss: 0.06699

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.32355
Value Function Update Magnitude: 0.31934

Collected Steps per Second: 18,831.93569
Overall Steps per Second: 9,550.40466

Timestep Collection Time: 2.65538
Timestep Consumption Time: 2.58063
PPO Batch Consumption Time: 0.29889
Total Iteration Time: 5.23601

Cumulative Model Updates: 118,126
Cumulative Timesteps: 986,009,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 986009770...
Checkpoint 986009770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,235.87531
Policy Entropy: 1.71030
Value Function Loss: 0.06915

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.32191
Value Function Update Magnitude: 0.31433

Collected Steps per Second: 18,049.90143
Overall Steps per Second: 8,882.56558

Timestep Collection Time: 2.77209
Timestep Consumption Time: 2.86096
PPO Batch Consumption Time: 0.34244
Total Iteration Time: 5.63306

Cumulative Model Updates: 118,132
Cumulative Timesteps: 986,059,806

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,652.38478
Policy Entropy: 1.70995
Value Function Loss: 0.07304

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.30400
Value Function Update Magnitude: 0.34207

Collected Steps per Second: 18,077.93504
Overall Steps per Second: 8,884.70537

Timestep Collection Time: 2.76713
Timestep Consumption Time: 2.86322
PPO Batch Consumption Time: 0.34133
Total Iteration Time: 5.63035

Cumulative Model Updates: 118,138
Cumulative Timesteps: 986,109,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 986109830...
Checkpoint 986109830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,743.60626
Policy Entropy: 1.70977
Value Function Loss: 0.07454

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.32183
Value Function Update Magnitude: 0.37606

Collected Steps per Second: 18,833.57739
Overall Steps per Second: 9,048.41243

Timestep Collection Time: 2.65568
Timestep Consumption Time: 2.87192
PPO Batch Consumption Time: 0.33691
Total Iteration Time: 5.52760

Cumulative Model Updates: 118,144
Cumulative Timesteps: 986,159,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,127.37850
Policy Entropy: 1.71640
Value Function Loss: 0.07667

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08753
Policy Update Magnitude: 0.33106
Value Function Update Magnitude: 0.39590

Collected Steps per Second: 19,143.43592
Overall Steps per Second: 9,930.03847

Timestep Collection Time: 2.61280
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 5.03704

Cumulative Model Updates: 118,150
Cumulative Timesteps: 986,209,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 986209864...
Checkpoint 986209864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,507.63700
Policy Entropy: 1.71975
Value Function Loss: 0.07551

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.33518
Value Function Update Magnitude: 0.36249

Collected Steps per Second: 21,546.27643
Overall Steps per Second: 10,497.64990

Timestep Collection Time: 2.32105
Timestep Consumption Time: 2.44287
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.76392

Cumulative Model Updates: 118,156
Cumulative Timesteps: 986,259,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,317.98298
Policy Entropy: 1.72873
Value Function Loss: 0.07645

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.32119
Value Function Update Magnitude: 0.31531

Collected Steps per Second: 21,346.47565
Overall Steps per Second: 10,446.23414

Timestep Collection Time: 2.34268
Timestep Consumption Time: 2.44450
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.78718

Cumulative Model Updates: 118,162
Cumulative Timesteps: 986,309,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 986309882...
Checkpoint 986309882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,324.65749
Policy Entropy: 1.72856
Value Function Loss: 0.07989

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.32945
Value Function Update Magnitude: 0.34782

Collected Steps per Second: 21,000.45993
Overall Steps per Second: 10,369.14148

Timestep Collection Time: 2.38319
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.82663

Cumulative Model Updates: 118,168
Cumulative Timesteps: 986,359,930

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,578.98832
Policy Entropy: 1.71970
Value Function Loss: 0.08077

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.34353
Value Function Update Magnitude: 0.37065

Collected Steps per Second: 21,700.55199
Overall Steps per Second: 10,137.48986

Timestep Collection Time: 2.30575
Timestep Consumption Time: 2.62999
PPO Batch Consumption Time: 0.30054
Total Iteration Time: 4.93574

Cumulative Model Updates: 118,174
Cumulative Timesteps: 986,409,966

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 986409966...
Checkpoint 986409966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,485.52863
Policy Entropy: 1.71167
Value Function Loss: 0.07804

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.34200
Value Function Update Magnitude: 0.38250

Collected Steps per Second: 20,921.56421
Overall Steps per Second: 10,169.89217

Timestep Collection Time: 2.39122
Timestep Consumption Time: 2.52801
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.91923

Cumulative Model Updates: 118,180
Cumulative Timesteps: 986,459,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,927.56330
Policy Entropy: 1.71677
Value Function Loss: 0.07721

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.31963
Value Function Update Magnitude: 0.37083

Collected Steps per Second: 21,809.17478
Overall Steps per Second: 10,426.78928

Timestep Collection Time: 2.29445
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.79918

Cumulative Model Updates: 118,186
Cumulative Timesteps: 986,510,034

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 986510034...
Checkpoint 986510034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,766.73677
Policy Entropy: 1.71633
Value Function Loss: 0.07868

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.31125
Value Function Update Magnitude: 0.37760

Collected Steps per Second: 21,230.52857
Overall Steps per Second: 10,351.98016

Timestep Collection Time: 2.35604
Timestep Consumption Time: 2.47588
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.83193

Cumulative Model Updates: 118,192
Cumulative Timesteps: 986,560,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,003.19864
Policy Entropy: 1.71848
Value Function Loss: 0.07358

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.32259
Value Function Update Magnitude: 0.36481

Collected Steps per Second: 20,376.69170
Overall Steps per Second: 10,057.98629

Timestep Collection Time: 2.45398
Timestep Consumption Time: 2.51759
PPO Batch Consumption Time: 0.30272
Total Iteration Time: 4.97157

Cumulative Model Updates: 118,198
Cumulative Timesteps: 986,610,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 986610058...
Checkpoint 986610058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,781.39327
Policy Entropy: 1.71589
Value Function Loss: 0.06976

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.31717
Value Function Update Magnitude: 0.36832

Collected Steps per Second: 19,932.13492
Overall Steps per Second: 9,951.13052

Timestep Collection Time: 2.50871
Timestep Consumption Time: 2.51624
PPO Batch Consumption Time: 0.30312
Total Iteration Time: 5.02496

Cumulative Model Updates: 118,204
Cumulative Timesteps: 986,660,062

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,381.44722
Policy Entropy: 1.71523
Value Function Loss: 0.06690

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.31506
Value Function Update Magnitude: 0.37026

Collected Steps per Second: 19,341.82865
Overall Steps per Second: 10,070.35131

Timestep Collection Time: 2.58569
Timestep Consumption Time: 2.38057
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.96626

Cumulative Model Updates: 118,210
Cumulative Timesteps: 986,710,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 986710074...
Checkpoint 986710074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,022.48554
Policy Entropy: 1.70210
Value Function Loss: 0.07226

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.32854
Value Function Update Magnitude: 0.37250

Collected Steps per Second: 20,238.87818
Overall Steps per Second: 10,175.26240

Timestep Collection Time: 2.47069
Timestep Consumption Time: 2.44358
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.91427

Cumulative Model Updates: 118,216
Cumulative Timesteps: 986,760,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,934.95471
Policy Entropy: 1.70007
Value Function Loss: 0.07313

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.32204
Value Function Update Magnitude: 0.36472

Collected Steps per Second: 21,208.20068
Overall Steps per Second: 10,425.32064

Timestep Collection Time: 2.35767
Timestep Consumption Time: 2.43853
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.79621

Cumulative Model Updates: 118,222
Cumulative Timesteps: 986,810,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 986810080...
Checkpoint 986810080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,353.87215
Policy Entropy: 1.69942
Value Function Loss: 0.07342

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.33138
Value Function Update Magnitude: 0.36308

Collected Steps per Second: 21,222.48054
Overall Steps per Second: 10,450.29990

Timestep Collection Time: 2.35750
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.78761

Cumulative Model Updates: 118,228
Cumulative Timesteps: 986,860,112

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,275.44938
Policy Entropy: 1.71601
Value Function Loss: 0.06917

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.33083
Value Function Update Magnitude: 0.36454

Collected Steps per Second: 19,220.39737
Overall Steps per Second: 9,630.55666

Timestep Collection Time: 2.60172
Timestep Consumption Time: 2.59072
PPO Batch Consumption Time: 0.30423
Total Iteration Time: 5.19243

Cumulative Model Updates: 118,234
Cumulative Timesteps: 986,910,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 986910118...
Checkpoint 986910118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,906.84262
Policy Entropy: 1.71672
Value Function Loss: 0.07505

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.33887
Value Function Update Magnitude: 0.36251

Collected Steps per Second: 19,892.50207
Overall Steps per Second: 9,958.30143

Timestep Collection Time: 2.51462
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 5.02315

Cumulative Model Updates: 118,240
Cumulative Timesteps: 986,960,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,623.27136
Policy Entropy: 1.71489
Value Function Loss: 0.07297

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.34100
Value Function Update Magnitude: 0.35315

Collected Steps per Second: 21,449.16834
Overall Steps per Second: 10,365.91639

Timestep Collection Time: 2.33128
Timestep Consumption Time: 2.49261
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.82389

Cumulative Model Updates: 118,246
Cumulative Timesteps: 987,010,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 987010144...
Checkpoint 987010144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,709.60261
Policy Entropy: 1.70752
Value Function Loss: 0.07401

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.33782
Value Function Update Magnitude: 0.34177

Collected Steps per Second: 20,783.40624
Overall Steps per Second: 10,361.33623

Timestep Collection Time: 2.40759
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.82930

Cumulative Model Updates: 118,252
Cumulative Timesteps: 987,060,182

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,653.07648
Policy Entropy: 1.71669
Value Function Loss: 0.06985

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.33303
Value Function Update Magnitude: 0.35564

Collected Steps per Second: 21,657.73775
Overall Steps per Second: 10,245.39991

Timestep Collection Time: 2.30883
Timestep Consumption Time: 2.57180
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.88063

Cumulative Model Updates: 118,258
Cumulative Timesteps: 987,110,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 987110186...
Checkpoint 987110186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,261.25758
Policy Entropy: 1.73819
Value Function Loss: 0.06874

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.31808
Value Function Update Magnitude: 0.35077

Collected Steps per Second: 20,385.81354
Overall Steps per Second: 10,034.84450

Timestep Collection Time: 2.45367
Timestep Consumption Time: 2.53096
PPO Batch Consumption Time: 0.30363
Total Iteration Time: 4.98463

Cumulative Model Updates: 118,264
Cumulative Timesteps: 987,160,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,088.09833
Policy Entropy: 1.73343
Value Function Loss: 0.07234

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.33255

Collected Steps per Second: 20,232.39233
Overall Steps per Second: 9,895.17760

Timestep Collection Time: 2.47336
Timestep Consumption Time: 2.58385
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 5.05721

Cumulative Model Updates: 118,270
Cumulative Timesteps: 987,210,248

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 987210248...
Checkpoint 987210248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,246.67678
Policy Entropy: 1.73978
Value Function Loss: 0.07380

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.32760
Value Function Update Magnitude: 0.31848

Collected Steps per Second: 20,291.09129
Overall Steps per Second: 9,604.47282

Timestep Collection Time: 2.46522
Timestep Consumption Time: 2.74298
PPO Batch Consumption Time: 0.31470
Total Iteration Time: 5.20820

Cumulative Model Updates: 118,276
Cumulative Timesteps: 987,260,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,945.90636
Policy Entropy: 1.71811
Value Function Loss: 0.07928

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.33761
Value Function Update Magnitude: 0.36451

Collected Steps per Second: 19,139.32467
Overall Steps per Second: 9,684.74892

Timestep Collection Time: 2.61493
Timestep Consumption Time: 2.55278
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 5.16771

Cumulative Model Updates: 118,282
Cumulative Timesteps: 987,310,318

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 987310318...
Checkpoint 987310318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,698.00275
Policy Entropy: 1.71630
Value Function Loss: 0.07459

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.34045
Value Function Update Magnitude: 0.37604

Collected Steps per Second: 21,366.98463
Overall Steps per Second: 10,336.64828

Timestep Collection Time: 2.34081
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.83871

Cumulative Model Updates: 118,288
Cumulative Timesteps: 987,360,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,013.96754
Policy Entropy: 1.70208
Value Function Loss: 0.07076

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.33371
Value Function Update Magnitude: 0.36937

Collected Steps per Second: 20,424.45909
Overall Steps per Second: 9,736.63847

Timestep Collection Time: 2.44873
Timestep Consumption Time: 2.68795
PPO Batch Consumption Time: 0.31417
Total Iteration Time: 5.13668

Cumulative Model Updates: 118,294
Cumulative Timesteps: 987,410,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 987410348...
Checkpoint 987410348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,777.72359
Policy Entropy: 1.70256
Value Function Loss: 0.07003

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.33273
Value Function Update Magnitude: 0.37784

Collected Steps per Second: 20,173.41439
Overall Steps per Second: 9,945.92965

Timestep Collection Time: 2.47891
Timestep Consumption Time: 2.54908
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 5.02799

Cumulative Model Updates: 118,300
Cumulative Timesteps: 987,460,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,586.67014
Policy Entropy: 1.70142
Value Function Loss: 0.07173

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.33879
Value Function Update Magnitude: 0.38880

Collected Steps per Second: 20,611.40773
Overall Steps per Second: 10,035.50481

Timestep Collection Time: 2.42584
Timestep Consumption Time: 2.55647
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.98231

Cumulative Model Updates: 118,306
Cumulative Timesteps: 987,510,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 987510356...
Checkpoint 987510356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,774.48020
Policy Entropy: 1.71086
Value Function Loss: 0.07478

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.34076
Value Function Update Magnitude: 0.38941

Collected Steps per Second: 21,140.50844
Overall Steps per Second: 10,148.68308

Timestep Collection Time: 2.36513
Timestep Consumption Time: 2.56162
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 4.92675

Cumulative Model Updates: 118,312
Cumulative Timesteps: 987,560,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,036.78602
Policy Entropy: 1.70696
Value Function Loss: 0.07718

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.34161
Value Function Update Magnitude: 0.38743

Collected Steps per Second: 20,641.50715
Overall Steps per Second: 10,022.16429

Timestep Collection Time: 2.42405
Timestep Consumption Time: 2.56849
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.99253

Cumulative Model Updates: 118,318
Cumulative Timesteps: 987,610,392

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 987610392...
Checkpoint 987610392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,639.16346
Policy Entropy: 1.70323
Value Function Loss: 0.07662

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.34210
Value Function Update Magnitude: 0.38485

Collected Steps per Second: 20,955.64075
Overall Steps per Second: 10,156.74916

Timestep Collection Time: 2.38618
Timestep Consumption Time: 2.53705
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.92323

Cumulative Model Updates: 118,324
Cumulative Timesteps: 987,660,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,837.96735
Policy Entropy: 1.70169
Value Function Loss: 0.07364

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.33818
Value Function Update Magnitude: 0.38207

Collected Steps per Second: 20,783.56440
Overall Steps per Second: 10,055.29831

Timestep Collection Time: 2.40604
Timestep Consumption Time: 2.56706
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.97310

Cumulative Model Updates: 118,330
Cumulative Timesteps: 987,710,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 987710402...
Checkpoint 987710402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,218.35135
Policy Entropy: 1.71123
Value Function Loss: 0.07411

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.34262
Value Function Update Magnitude: 0.36888

Collected Steps per Second: 20,825.02734
Overall Steps per Second: 10,006.00652

Timestep Collection Time: 2.40163
Timestep Consumption Time: 2.59677
PPO Batch Consumption Time: 0.30436
Total Iteration Time: 4.99840

Cumulative Model Updates: 118,336
Cumulative Timesteps: 987,760,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,817.62681
Policy Entropy: 1.71007
Value Function Loss: 0.07100

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.34505
Value Function Update Magnitude: 0.32951

Collected Steps per Second: 18,921.09504
Overall Steps per Second: 9,288.87092

Timestep Collection Time: 2.64319
Timestep Consumption Time: 2.74089
PPO Batch Consumption Time: 0.31849
Total Iteration Time: 5.38408

Cumulative Model Updates: 118,342
Cumulative Timesteps: 987,810,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 987810428...
Checkpoint 987810428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,691.32090
Policy Entropy: 1.70272
Value Function Loss: 0.07061

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.33662
Value Function Update Magnitude: 0.35063

Collected Steps per Second: 20,534.84305
Overall Steps per Second: 10,146.37661

Timestep Collection Time: 2.43722
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.30257
Total Iteration Time: 4.93260

Cumulative Model Updates: 118,348
Cumulative Timesteps: 987,860,476

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,694.79901
Policy Entropy: 1.69712
Value Function Loss: 0.06529

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.32868
Value Function Update Magnitude: 0.34815

Collected Steps per Second: 20,109.40132
Overall Steps per Second: 9,952.00485

Timestep Collection Time: 2.48670
Timestep Consumption Time: 2.53802
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 5.02472

Cumulative Model Updates: 118,354
Cumulative Timesteps: 987,910,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 987910482...
Checkpoint 987910482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,614.69269
Policy Entropy: 1.69433
Value Function Loss: 0.07030

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.31907
Value Function Update Magnitude: 0.34303

Collected Steps per Second: 20,478.04939
Overall Steps per Second: 10,196.49635

Timestep Collection Time: 2.44193
Timestep Consumption Time: 2.46230
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.90423

Cumulative Model Updates: 118,360
Cumulative Timesteps: 987,960,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,464.65369
Policy Entropy: 1.69722
Value Function Loss: 0.06896

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.32390
Value Function Update Magnitude: 0.34497

Collected Steps per Second: 20,097.20116
Overall Steps per Second: 10,058.96971

Timestep Collection Time: 2.48900
Timestep Consumption Time: 2.48387
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.97288

Cumulative Model Updates: 118,366
Cumulative Timesteps: 988,010,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 988010510...
Checkpoint 988010510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,112.69350
Policy Entropy: 1.69450
Value Function Loss: 0.06966

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.32104
Value Function Update Magnitude: 0.34897

Collected Steps per Second: 20,606.01696
Overall Steps per Second: 10,189.00818

Timestep Collection Time: 2.42725
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 4.90882

Cumulative Model Updates: 118,372
Cumulative Timesteps: 988,060,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,755.64971
Policy Entropy: 1.70559
Value Function Loss: 0.07715

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.33585
Value Function Update Magnitude: 0.34257

Collected Steps per Second: 20,288.49686
Overall Steps per Second: 10,069.54236

Timestep Collection Time: 2.46573
Timestep Consumption Time: 2.50232
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.96805

Cumulative Model Updates: 118,378
Cumulative Timesteps: 988,110,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 988110552...
Checkpoint 988110552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,698.61718
Policy Entropy: 1.69281
Value Function Loss: 0.08000

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.34381
Value Function Update Magnitude: 0.33452

Collected Steps per Second: 20,436.18130
Overall Steps per Second: 10,195.43894

Timestep Collection Time: 2.44791
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.90670

Cumulative Model Updates: 118,384
Cumulative Timesteps: 988,160,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,579.27331
Policy Entropy: 1.68465
Value Function Loss: 0.08173

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.34167
Value Function Update Magnitude: 0.36234

Collected Steps per Second: 18,993.55002
Overall Steps per Second: 9,663.97732

Timestep Collection Time: 2.63247
Timestep Consumption Time: 2.54138
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 5.17385

Cumulative Model Updates: 118,390
Cumulative Timesteps: 988,210,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988210578...
Checkpoint 988210578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,622.30022
Policy Entropy: 1.68072
Value Function Loss: 0.07413

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.33770
Value Function Update Magnitude: 0.38752

Collected Steps per Second: 21,075.92189
Overall Steps per Second: 10,198.38807

Timestep Collection Time: 2.37361
Timestep Consumption Time: 2.53168
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.90529

Cumulative Model Updates: 118,396
Cumulative Timesteps: 988,260,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,624.80937
Policy Entropy: 1.67952
Value Function Loss: 0.07971

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.34106
Value Function Update Magnitude: 0.38272

Collected Steps per Second: 20,668.52963
Overall Steps per Second: 10,077.69401

Timestep Collection Time: 2.41933
Timestep Consumption Time: 2.54252
PPO Batch Consumption Time: 0.29805
Total Iteration Time: 4.96185

Cumulative Model Updates: 118,402
Cumulative Timesteps: 988,310,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 988310608...
Checkpoint 988310608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,558.58699
Policy Entropy: 1.69300
Value Function Loss: 0.08096

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.34327
Value Function Update Magnitude: 0.39244

Collected Steps per Second: 21,266.09811
Overall Steps per Second: 9,774.48913

Timestep Collection Time: 2.35210
Timestep Consumption Time: 2.76530
PPO Batch Consumption Time: 0.33543
Total Iteration Time: 5.11740

Cumulative Model Updates: 118,408
Cumulative Timesteps: 988,360,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,403.13876
Policy Entropy: 1.69195
Value Function Loss: 0.07835

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.34120
Value Function Update Magnitude: 0.40632

Collected Steps per Second: 17,454.00330
Overall Steps per Second: 9,129.39776

Timestep Collection Time: 2.86479
Timestep Consumption Time: 2.61224
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 5.47703

Cumulative Model Updates: 118,414
Cumulative Timesteps: 988,410,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 988410630...
Checkpoint 988410630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,569.31767
Policy Entropy: 1.70444
Value Function Loss: 0.07542

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.34024
Value Function Update Magnitude: 0.40118

Collected Steps per Second: 19,810.44896
Overall Steps per Second: 9,386.82884

Timestep Collection Time: 2.52483
Timestep Consumption Time: 2.80370
PPO Batch Consumption Time: 0.34568
Total Iteration Time: 5.32853

Cumulative Model Updates: 118,420
Cumulative Timesteps: 988,460,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,162.85799
Policy Entropy: 1.70288
Value Function Loss: 0.07533

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.34340
Value Function Update Magnitude: 0.39987

Collected Steps per Second: 17,755.00900
Overall Steps per Second: 9,195.30524

Timestep Collection Time: 2.81633
Timestep Consumption Time: 2.62166
PPO Batch Consumption Time: 0.30313
Total Iteration Time: 5.43799

Cumulative Model Updates: 118,426
Cumulative Timesteps: 988,510,652

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 988510652...
Checkpoint 988510652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,988.49514
Policy Entropy: 1.69823
Value Function Loss: 0.07614

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.34413
Value Function Update Magnitude: 0.40732

Collected Steps per Second: 19,933.95745
Overall Steps per Second: 9,488.49836

Timestep Collection Time: 2.50838
Timestep Consumption Time: 2.76137
PPO Batch Consumption Time: 0.32310
Total Iteration Time: 5.26975

Cumulative Model Updates: 118,432
Cumulative Timesteps: 988,560,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,381.52347
Policy Entropy: 1.69751
Value Function Loss: 0.08186

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.34852
Value Function Update Magnitude: 0.39593

Collected Steps per Second: 18,561.61263
Overall Steps per Second: 9,332.96806

Timestep Collection Time: 2.69599
Timestep Consumption Time: 2.66586
PPO Batch Consumption Time: 0.31477
Total Iteration Time: 5.36185

Cumulative Model Updates: 118,438
Cumulative Timesteps: 988,610,696

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 988610696...
Checkpoint 988610696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,607.72941
Policy Entropy: 1.70685
Value Function Loss: 0.08008

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.34772
Value Function Update Magnitude: 0.38145

Collected Steps per Second: 18,699.09398
Overall Steps per Second: 9,660.13424

Timestep Collection Time: 2.67478
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 5.17757

Cumulative Model Updates: 118,444
Cumulative Timesteps: 988,660,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,128.27379
Policy Entropy: 1.69803
Value Function Loss: 0.08118

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.34355
Value Function Update Magnitude: 0.37810

Collected Steps per Second: 20,432.34345
Overall Steps per Second: 10,040.61616

Timestep Collection Time: 2.44896
Timestep Consumption Time: 2.53460
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.98356

Cumulative Model Updates: 118,450
Cumulative Timesteps: 988,710,750

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 988710750...
Checkpoint 988710750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,369.99150
Policy Entropy: 1.69921
Value Function Loss: 0.07639

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.34439
Value Function Update Magnitude: 0.38696

Collected Steps per Second: 19,537.92514
Overall Steps per Second: 9,860.37329

Timestep Collection Time: 2.55964
Timestep Consumption Time: 2.51218
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 5.07182

Cumulative Model Updates: 118,456
Cumulative Timesteps: 988,760,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,878.83289
Policy Entropy: 1.68023
Value Function Loss: 0.07731

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.34589
Value Function Update Magnitude: 0.40094

Collected Steps per Second: 21,422.22564
Overall Steps per Second: 10,443.61505

Timestep Collection Time: 2.33552
Timestep Consumption Time: 2.45516
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.79068

Cumulative Model Updates: 118,462
Cumulative Timesteps: 988,810,792

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 988810792...
Checkpoint 988810792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,566.52792
Policy Entropy: 1.68308
Value Function Loss: 0.07542

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.34638
Value Function Update Magnitude: 0.40752

Collected Steps per Second: 21,525.27731
Overall Steps per Second: 10,310.38692

Timestep Collection Time: 2.32387
Timestep Consumption Time: 2.52774
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.85161

Cumulative Model Updates: 118,468
Cumulative Timesteps: 988,860,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,151.35305
Policy Entropy: 1.68049
Value Function Loss: 0.07281

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.34311
Value Function Update Magnitude: 0.39131

Collected Steps per Second: 21,636.45821
Overall Steps per Second: 10,397.48393

Timestep Collection Time: 2.31276
Timestep Consumption Time: 2.49994
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.81270

Cumulative Model Updates: 118,474
Cumulative Timesteps: 988,910,854

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 988910854...
Checkpoint 988910854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,370.44796
Policy Entropy: 1.68670
Value Function Loss: 0.07367

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.34121
Value Function Update Magnitude: 0.37687

Collected Steps per Second: 21,299.40593
Overall Steps per Second: 10,270.55103

Timestep Collection Time: 2.34936
Timestep Consumption Time: 2.52282
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.87218

Cumulative Model Updates: 118,480
Cumulative Timesteps: 988,960,894

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,889.24282
Policy Entropy: 1.69118
Value Function Loss: 0.07030

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.33371
Value Function Update Magnitude: 0.34540

Collected Steps per Second: 21,840.93740
Overall Steps per Second: 10,387.63883

Timestep Collection Time: 2.29001
Timestep Consumption Time: 2.52494
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.81495

Cumulative Model Updates: 118,486
Cumulative Timesteps: 989,010,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 989010910...
Checkpoint 989010910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,366.47364
Policy Entropy: 1.70136
Value Function Loss: 0.07255

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.33092
Value Function Update Magnitude: 0.33022

Collected Steps per Second: 21,551.92941
Overall Steps per Second: 10,582.01797

Timestep Collection Time: 2.32026
Timestep Consumption Time: 2.40531
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.72556

Cumulative Model Updates: 118,492
Cumulative Timesteps: 989,060,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,748.57936
Policy Entropy: 1.69262
Value Function Loss: 0.06942

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.33407
Value Function Update Magnitude: 0.33129

Collected Steps per Second: 21,758.95663
Overall Steps per Second: 10,406.68904

Timestep Collection Time: 2.29790
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.80460

Cumulative Model Updates: 118,498
Cumulative Timesteps: 989,110,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 989110916...
Checkpoint 989110916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,373.81895
Policy Entropy: 1.68770
Value Function Loss: 0.06953

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.33080
Value Function Update Magnitude: 0.34768

Collected Steps per Second: 21,187.37342
Overall Steps per Second: 10,376.53745

Timestep Collection Time: 2.35999
Timestep Consumption Time: 2.45877
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.81876

Cumulative Model Updates: 118,504
Cumulative Timesteps: 989,160,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,991.52018
Policy Entropy: 1.68998
Value Function Loss: 0.07002

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.32868
Value Function Update Magnitude: 0.35362

Collected Steps per Second: 21,646.03444
Overall Steps per Second: 10,269.68267

Timestep Collection Time: 2.31026
Timestep Consumption Time: 2.55922
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.86948

Cumulative Model Updates: 118,510
Cumulative Timesteps: 989,210,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 989210926...
Checkpoint 989210926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,321.99672
Policy Entropy: 1.69542
Value Function Loss: 0.07302

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.33220
Value Function Update Magnitude: 0.36028

Collected Steps per Second: 21,283.54109
Overall Steps per Second: 10,217.14737

Timestep Collection Time: 2.35027
Timestep Consumption Time: 2.54562
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.89589

Cumulative Model Updates: 118,516
Cumulative Timesteps: 989,260,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,479.90662
Policy Entropy: 1.68026
Value Function Loss: 0.08053

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.33893
Value Function Update Magnitude: 0.36449

Collected Steps per Second: 19,655.62833
Overall Steps per Second: 9,618.12360

Timestep Collection Time: 2.54411
Timestep Consumption Time: 2.65504
PPO Batch Consumption Time: 0.31629
Total Iteration Time: 5.19914

Cumulative Model Updates: 118,522
Cumulative Timesteps: 989,310,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 989310954...
Checkpoint 989310954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,273.47276
Policy Entropy: 1.67625
Value Function Loss: 0.08093

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.34432
Value Function Update Magnitude: 0.36974

Collected Steps per Second: 21,329.66936
Overall Steps per Second: 10,358.92587

Timestep Collection Time: 2.34500
Timestep Consumption Time: 2.48350
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.82849

Cumulative Model Updates: 118,528
Cumulative Timesteps: 989,360,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,549.66959
Policy Entropy: 1.70014
Value Function Loss: 0.07811

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.34069
Value Function Update Magnitude: 0.38782

Collected Steps per Second: 20,608.94607
Overall Steps per Second: 9,350.34032

Timestep Collection Time: 2.42730
Timestep Consumption Time: 2.92267
PPO Batch Consumption Time: 0.35111
Total Iteration Time: 5.34997

Cumulative Model Updates: 118,534
Cumulative Timesteps: 989,410,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 989410996...
Checkpoint 989410996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,448.78263
Policy Entropy: 1.70909
Value Function Loss: 0.07613

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.33847
Value Function Update Magnitude: 0.40388

Collected Steps per Second: 19,412.43891
Overall Steps per Second: 9,880.20284

Timestep Collection Time: 2.57752
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 5.06427

Cumulative Model Updates: 118,540
Cumulative Timesteps: 989,461,032

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,527.18962
Policy Entropy: 1.71130
Value Function Loss: 0.07526

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.34349
Value Function Update Magnitude: 0.42270

Collected Steps per Second: 21,896.52081
Overall Steps per Second: 10,465.79089

Timestep Collection Time: 2.28420
Timestep Consumption Time: 2.49480
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.77900

Cumulative Model Updates: 118,546
Cumulative Timesteps: 989,511,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 989511048...
Checkpoint 989511048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,790.77406
Policy Entropy: 1.71612
Value Function Loss: 0.07945

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.34675
Value Function Update Magnitude: 0.41371

Collected Steps per Second: 21,675.62764
Overall Steps per Second: 10,468.22690

Timestep Collection Time: 2.30849
Timestep Consumption Time: 2.47150
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.77999

Cumulative Model Updates: 118,552
Cumulative Timesteps: 989,561,086

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,238.13884
Policy Entropy: 1.70690
Value Function Loss: 0.07453

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.34353
Value Function Update Magnitude: 0.37238

Collected Steps per Second: 21,664.56321
Overall Steps per Second: 10,520.59840

Timestep Collection Time: 2.30865
Timestep Consumption Time: 2.44545
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.75410

Cumulative Model Updates: 118,558
Cumulative Timesteps: 989,611,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 989611102...
Checkpoint 989611102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,080.54543
Policy Entropy: 1.71223
Value Function Loss: 0.07281

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.33860
Value Function Update Magnitude: 0.36723

Collected Steps per Second: 19,981.12468
Overall Steps per Second: 10,102.12792

Timestep Collection Time: 2.50316
Timestep Consumption Time: 2.44787
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.95104

Cumulative Model Updates: 118,564
Cumulative Timesteps: 989,661,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,564.62729
Policy Entropy: 1.70202
Value Function Loss: 0.07822

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.34100
Value Function Update Magnitude: 0.36862

Collected Steps per Second: 17,892.81139
Overall Steps per Second: 9,217.73825

Timestep Collection Time: 2.79453
Timestep Consumption Time: 2.63001
PPO Batch Consumption Time: 0.30431
Total Iteration Time: 5.42454

Cumulative Model Updates: 118,570
Cumulative Timesteps: 989,711,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 989711120...
Checkpoint 989711120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,825.41285
Policy Entropy: 1.70982
Value Function Loss: 0.07843

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.34567
Value Function Update Magnitude: 0.37289

Collected Steps per Second: 19,899.36903
Overall Steps per Second: 9,503.61270

Timestep Collection Time: 2.51294
Timestep Consumption Time: 2.74884
PPO Batch Consumption Time: 0.32753
Total Iteration Time: 5.26179

Cumulative Model Updates: 118,576
Cumulative Timesteps: 989,761,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,141.87866
Policy Entropy: 1.70861
Value Function Loss: 0.07741

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.33825
Value Function Update Magnitude: 0.36299

Collected Steps per Second: 18,952.54040
Overall Steps per Second: 9,481.49054

Timestep Collection Time: 2.63912
Timestep Consumption Time: 2.63621
PPO Batch Consumption Time: 0.31268
Total Iteration Time: 5.27533

Cumulative Model Updates: 118,582
Cumulative Timesteps: 989,811,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 989811144...
Checkpoint 989811144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,619.26919
Policy Entropy: 1.70705
Value Function Loss: 0.07367

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.32469
Value Function Update Magnitude: 0.35432

Collected Steps per Second: 20,171.34637
Overall Steps per Second: 9,951.46389

Timestep Collection Time: 2.48005
Timestep Consumption Time: 2.54695
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 5.02700

Cumulative Model Updates: 118,588
Cumulative Timesteps: 989,861,170

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,084.89822
Policy Entropy: 1.71513
Value Function Loss: 0.06859

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.32459
Value Function Update Magnitude: 0.35318

Collected Steps per Second: 20,607.58267
Overall Steps per Second: 10,024.91965

Timestep Collection Time: 2.42804
Timestep Consumption Time: 2.56312
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.99116

Cumulative Model Updates: 118,594
Cumulative Timesteps: 989,911,206

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 989911206...
Checkpoint 989911206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,892.53424
Policy Entropy: 1.70563
Value Function Loss: 0.06561

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.32209
Value Function Update Magnitude: 0.35694

Collected Steps per Second: 20,350.30409
Overall Steps per Second: 9,757.99646

Timestep Collection Time: 2.45716
Timestep Consumption Time: 2.66725
PPO Batch Consumption Time: 0.30082
Total Iteration Time: 5.12441

Cumulative Model Updates: 118,600
Cumulative Timesteps: 989,961,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,667.37675
Policy Entropy: 1.70130
Value Function Loss: 0.07829

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.30630
Value Function Update Magnitude: 0.35757

Collected Steps per Second: 20,782.04449
Overall Steps per Second: 9,804.19346

Timestep Collection Time: 2.40708
Timestep Consumption Time: 2.69523
PPO Batch Consumption Time: 0.31691
Total Iteration Time: 5.10231

Cumulative Model Updates: 118,606
Cumulative Timesteps: 990,011,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 990011234...
Checkpoint 990011234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,709.35644
Policy Entropy: 1.67867
Value Function Loss: 0.08645

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.31749
Value Function Update Magnitude: 0.39443

Collected Steps per Second: 19,750.44699
Overall Steps per Second: 9,697.28577

Timestep Collection Time: 2.53290
Timestep Consumption Time: 2.62586
PPO Batch Consumption Time: 0.30970
Total Iteration Time: 5.15876

Cumulative Model Updates: 118,612
Cumulative Timesteps: 990,061,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,431.00998
Policy Entropy: 1.69256
Value Function Loss: 0.08371

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.33389
Value Function Update Magnitude: 0.42551

Collected Steps per Second: 19,106.93516
Overall Steps per Second: 9,960.28582

Timestep Collection Time: 2.61957
Timestep Consumption Time: 2.40558
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 5.02516

Cumulative Model Updates: 118,618
Cumulative Timesteps: 990,111,312

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 990111312...
Checkpoint 990111312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,861.29513
Policy Entropy: 1.69673
Value Function Loss: 0.07472

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.33668
Value Function Update Magnitude: 0.41887

Collected Steps per Second: 20,507.41924
Overall Steps per Second: 10,028.29268

Timestep Collection Time: 2.43931
Timestep Consumption Time: 2.54897
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.98829

Cumulative Model Updates: 118,624
Cumulative Timesteps: 990,161,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,363.23117
Policy Entropy: 1.69871
Value Function Loss: 0.06999

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.33869
Value Function Update Magnitude: 0.39979

Collected Steps per Second: 20,814.65442
Overall Steps per Second: 10,025.13380

Timestep Collection Time: 2.40244
Timestep Consumption Time: 2.58562
PPO Batch Consumption Time: 0.30042
Total Iteration Time: 4.98806

Cumulative Model Updates: 118,630
Cumulative Timesteps: 990,211,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 990211342...
Checkpoint 990211342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,751.13335
Policy Entropy: 1.68971
Value Function Loss: 0.06917

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.33601
Value Function Update Magnitude: 0.36904

Collected Steps per Second: 20,486.38306
Overall Steps per Second: 10,101.30814

Timestep Collection Time: 2.44152
Timestep Consumption Time: 2.51011
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.95164

Cumulative Model Updates: 118,636
Cumulative Timesteps: 990,261,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,431.30258
Policy Entropy: 1.69794
Value Function Loss: 0.06753

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.33221
Value Function Update Magnitude: 0.34111

Collected Steps per Second: 20,732.45791
Overall Steps per Second: 9,947.35903

Timestep Collection Time: 2.41370
Timestep Consumption Time: 2.61698
PPO Batch Consumption Time: 0.30634
Total Iteration Time: 5.03068

Cumulative Model Updates: 118,642
Cumulative Timesteps: 990,311,402

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 990311402...
Checkpoint 990311402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,431.58833
Policy Entropy: 1.71011
Value Function Loss: 0.06443

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.33145
Value Function Update Magnitude: 0.33515

Collected Steps per Second: 18,991.54004
Overall Steps per Second: 9,318.51247

Timestep Collection Time: 2.63370
Timestep Consumption Time: 2.73390
PPO Batch Consumption Time: 0.31003
Total Iteration Time: 5.36759

Cumulative Model Updates: 118,648
Cumulative Timesteps: 990,361,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,721.47124
Policy Entropy: 1.70412
Value Function Loss: 0.07039

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.33578
Value Function Update Magnitude: 0.34681

Collected Steps per Second: 18,253.26791
Overall Steps per Second: 9,499.94228

Timestep Collection Time: 2.73935
Timestep Consumption Time: 2.52406
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 5.26340

Cumulative Model Updates: 118,654
Cumulative Timesteps: 990,411,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 990411422...
Checkpoint 990411422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,872.75675
Policy Entropy: 1.69973
Value Function Loss: 0.07072

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.33611
Value Function Update Magnitude: 0.37080

Collected Steps per Second: 19,819.22812
Overall Steps per Second: 9,938.85227

Timestep Collection Time: 2.52290
Timestep Consumption Time: 2.50806
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 5.03096

Cumulative Model Updates: 118,660
Cumulative Timesteps: 990,461,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,536.78649
Policy Entropy: 1.70151
Value Function Loss: 0.07202

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.33076
Value Function Update Magnitude: 0.37174

Collected Steps per Second: 20,867.60349
Overall Steps per Second: 10,090.13234

Timestep Collection Time: 2.39683
Timestep Consumption Time: 2.56010
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.95692

Cumulative Model Updates: 118,666
Cumulative Timesteps: 990,511,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 990511440...
Checkpoint 990511440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,075.56654
Policy Entropy: 1.69142
Value Function Loss: 0.07040

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.32903
Value Function Update Magnitude: 0.36589

Collected Steps per Second: 20,559.33199
Overall Steps per Second: 10,081.87692

Timestep Collection Time: 2.43403
Timestep Consumption Time: 2.52953
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.96356

Cumulative Model Updates: 118,672
Cumulative Timesteps: 990,561,482

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,585.30516
Policy Entropy: 1.69834
Value Function Loss: 0.06985

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.33320
Value Function Update Magnitude: 0.38654

Collected Steps per Second: 17,899.93986
Overall Steps per Second: 9,140.13454

Timestep Collection Time: 2.79409
Timestep Consumption Time: 2.67782
PPO Batch Consumption Time: 0.30581
Total Iteration Time: 5.47191

Cumulative Model Updates: 118,678
Cumulative Timesteps: 990,611,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 990611496...
Checkpoint 990611496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,979.23631
Policy Entropy: 1.70058
Value Function Loss: 0.07014

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.33101
Value Function Update Magnitude: 0.39847

Collected Steps per Second: 18,141.55280
Overall Steps per Second: 9,329.17779

Timestep Collection Time: 2.75621
Timestep Consumption Time: 2.60353
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 5.35974

Cumulative Model Updates: 118,684
Cumulative Timesteps: 990,661,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,464.71983
Policy Entropy: 1.71056
Value Function Loss: 0.07036

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.32146
Value Function Update Magnitude: 0.39242

Collected Steps per Second: 20,717.44242
Overall Steps per Second: 10,038.93243

Timestep Collection Time: 2.41391
Timestep Consumption Time: 2.56770
PPO Batch Consumption Time: 0.30056
Total Iteration Time: 4.98161

Cumulative Model Updates: 118,690
Cumulative Timesteps: 990,711,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 990711508...
Checkpoint 990711508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,975.43841
Policy Entropy: 1.71499
Value Function Loss: 0.07269

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.29701
Value Function Update Magnitude: 0.36852

Collected Steps per Second: 19,947.30422
Overall Steps per Second: 9,845.29475

Timestep Collection Time: 2.50821
Timestep Consumption Time: 2.57361
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 5.08182

Cumulative Model Updates: 118,696
Cumulative Timesteps: 990,761,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,696.57337
Policy Entropy: 1.70229
Value Function Loss: 0.07595

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.32042
Value Function Update Magnitude: 0.37979

Collected Steps per Second: 20,986.18457
Overall Steps per Second: 10,090.76220

Timestep Collection Time: 2.38404
Timestep Consumption Time: 2.57415
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.95820

Cumulative Model Updates: 118,702
Cumulative Timesteps: 990,811,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 990811572...
Checkpoint 990811572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,991.14986
Policy Entropy: 1.71428
Value Function Loss: 0.07066

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08685
Policy Update Magnitude: 0.32884
Value Function Update Magnitude: 0.38351

Collected Steps per Second: 20,750.56305
Overall Steps per Second: 10,028.03419

Timestep Collection Time: 2.41054
Timestep Consumption Time: 2.57748
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.98802

Cumulative Model Updates: 118,708
Cumulative Timesteps: 990,861,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,613.92559
Policy Entropy: 1.69828
Value Function Loss: 0.07022

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.33070
Value Function Update Magnitude: 0.36755

Collected Steps per Second: 19,328.90971
Overall Steps per Second: 9,678.12057

Timestep Collection Time: 2.58856
Timestep Consumption Time: 2.58125
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 5.16981

Cumulative Model Updates: 118,714
Cumulative Timesteps: 990,911,626

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 990911626...
Checkpoint 990911626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,674.52035
Policy Entropy: 1.71936
Value Function Loss: 0.07128

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07709
Policy Update Magnitude: 0.33483
Value Function Update Magnitude: 0.35492

Collected Steps per Second: 20,388.24235
Overall Steps per Second: 9,950.48193

Timestep Collection Time: 2.45337
Timestep Consumption Time: 2.57352
PPO Batch Consumption Time: 0.30271
Total Iteration Time: 5.02689

Cumulative Model Updates: 118,720
Cumulative Timesteps: 990,961,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,507.89854
Policy Entropy: 1.72317
Value Function Loss: 0.07413

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.33432
Value Function Update Magnitude: 0.31735

Collected Steps per Second: 19,469.04295
Overall Steps per Second: 9,348.18876

Timestep Collection Time: 2.56910
Timestep Consumption Time: 2.78145
PPO Batch Consumption Time: 0.32035
Total Iteration Time: 5.35056

Cumulative Model Updates: 118,726
Cumulative Timesteps: 991,011,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 991011664...
Checkpoint 991011664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,383.59060
Policy Entropy: 1.72989
Value Function Loss: 0.07862

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.31688
Value Function Update Magnitude: 0.35095

Collected Steps per Second: 18,972.46650
Overall Steps per Second: 9,453.46517

Timestep Collection Time: 2.63814
Timestep Consumption Time: 2.65643
PPO Batch Consumption Time: 0.31151
Total Iteration Time: 5.29457

Cumulative Model Updates: 118,732
Cumulative Timesteps: 991,061,716

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,678.46226
Policy Entropy: 1.72936
Value Function Loss: 0.08203

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.32755
Value Function Update Magnitude: 0.37812

Collected Steps per Second: 18,877.39298
Overall Steps per Second: 9,343.64471

Timestep Collection Time: 2.65111
Timestep Consumption Time: 2.70505
PPO Batch Consumption Time: 0.31307
Total Iteration Time: 5.35615

Cumulative Model Updates: 118,738
Cumulative Timesteps: 991,111,762

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 991111762...
Checkpoint 991111762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,998.32160
Policy Entropy: 1.72002
Value Function Loss: 0.07629

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.33451
Value Function Update Magnitude: 0.38999

Collected Steps per Second: 18,091.63943
Overall Steps per Second: 9,512.02176

Timestep Collection Time: 2.76526
Timestep Consumption Time: 2.49419
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 5.25945

Cumulative Model Updates: 118,744
Cumulative Timesteps: 991,161,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,144.50171
Policy Entropy: 1.71843
Value Function Loss: 0.07138

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.33307
Value Function Update Magnitude: 0.38814

Collected Steps per Second: 20,510.43247
Overall Steps per Second: 10,082.45289

Timestep Collection Time: 2.43778
Timestep Consumption Time: 2.52133
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.95911

Cumulative Model Updates: 118,750
Cumulative Timesteps: 991,211,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 991211790...
Checkpoint 991211790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,072.08721
Policy Entropy: 1.70822
Value Function Loss: 0.07236

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.33507
Value Function Update Magnitude: 0.37812

Collected Steps per Second: 18,971.19041
Overall Steps per Second: 9,760.82944

Timestep Collection Time: 2.63716
Timestep Consumption Time: 2.48843
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 5.12559

Cumulative Model Updates: 118,756
Cumulative Timesteps: 991,261,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,973.68494
Policy Entropy: 1.71598
Value Function Loss: 0.07024

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.33577
Value Function Update Magnitude: 0.38510

Collected Steps per Second: 20,233.64649
Overall Steps per Second: 10,059.68887

Timestep Collection Time: 2.47301
Timestep Consumption Time: 2.50110
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.97411

Cumulative Model Updates: 118,762
Cumulative Timesteps: 991,311,858

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 991311858...
Checkpoint 991311858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,626.45583
Policy Entropy: 1.71840
Value Function Loss: 0.07476

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.33801
Value Function Update Magnitude: 0.38096

Collected Steps per Second: 20,190.83523
Overall Steps per Second: 9,918.27247

Timestep Collection Time: 2.47825
Timestep Consumption Time: 2.56678
PPO Batch Consumption Time: 0.30112
Total Iteration Time: 5.04503

Cumulative Model Updates: 118,768
Cumulative Timesteps: 991,361,896

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,396.49506
Policy Entropy: 1.71852
Value Function Loss: 0.07227

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.33229
Value Function Update Magnitude: 0.37413

Collected Steps per Second: 20,660.99310
Overall Steps per Second: 9,996.79163

Timestep Collection Time: 2.42002
Timestep Consumption Time: 2.58159
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 5.00160

Cumulative Model Updates: 118,774
Cumulative Timesteps: 991,411,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 991411896...
Checkpoint 991411896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,838.66826
Policy Entropy: 1.70801
Value Function Loss: 0.07170

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.30526
Value Function Update Magnitude: 0.36895

Collected Steps per Second: 18,610.34751
Overall Steps per Second: 9,245.37838

Timestep Collection Time: 2.68764
Timestep Consumption Time: 2.72241
PPO Batch Consumption Time: 0.30921
Total Iteration Time: 5.41005

Cumulative Model Updates: 118,780
Cumulative Timesteps: 991,461,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,851.55052
Policy Entropy: 1.72552
Value Function Loss: 0.06277

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.30801
Value Function Update Magnitude: 0.36652

Collected Steps per Second: 19,797.35834
Overall Steps per Second: 9,550.45469

Timestep Collection Time: 2.52609
Timestep Consumption Time: 2.71031
PPO Batch Consumption Time: 0.31980
Total Iteration Time: 5.23640

Cumulative Model Updates: 118,786
Cumulative Timesteps: 991,511,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 991511924...
Checkpoint 991511924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,641.60779
Policy Entropy: 1.72364
Value Function Loss: 0.06493

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.32069
Value Function Update Magnitude: 0.37538

Collected Steps per Second: 20,774.86327
Overall Steps per Second: 10,234.70469

Timestep Collection Time: 2.40743
Timestep Consumption Time: 2.47928
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.88671

Cumulative Model Updates: 118,792
Cumulative Timesteps: 991,561,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,503.08644
Policy Entropy: 1.73384
Value Function Loss: 0.06628

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.32512
Value Function Update Magnitude: 0.38192

Collected Steps per Second: 20,896.15668
Overall Steps per Second: 10,367.30149

Timestep Collection Time: 2.39355
Timestep Consumption Time: 2.43085
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.82440

Cumulative Model Updates: 118,798
Cumulative Timesteps: 991,611,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 991611954...
Checkpoint 991611954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,411.46400
Policy Entropy: 1.71213
Value Function Loss: 0.06979

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.32801
Value Function Update Magnitude: 0.37665

Collected Steps per Second: 19,750.80459
Overall Steps per Second: 10,223.45681

Timestep Collection Time: 2.53164
Timestep Consumption Time: 2.35927
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.89091

Cumulative Model Updates: 118,804
Cumulative Timesteps: 991,661,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,717.35477
Policy Entropy: 1.71932
Value Function Loss: 0.07247

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.32951
Value Function Update Magnitude: 0.39776

Collected Steps per Second: 19,739.64379
Overall Steps per Second: 10,024.96984

Timestep Collection Time: 2.53419
Timestep Consumption Time: 2.45575
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.98994

Cumulative Model Updates: 118,810
Cumulative Timesteps: 991,711,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 991711980...
Checkpoint 991711980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,471.02162
Policy Entropy: 1.72265
Value Function Loss: 0.07423

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.33779
Value Function Update Magnitude: 0.38358

Collected Steps per Second: 18,387.44848
Overall Steps per Second: 9,543.26523

Timestep Collection Time: 2.72044
Timestep Consumption Time: 2.52116
PPO Batch Consumption Time: 0.30006
Total Iteration Time: 5.24160

Cumulative Model Updates: 118,816
Cumulative Timesteps: 991,762,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,451.19675
Policy Entropy: 1.72543
Value Function Loss: 0.08068

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.34137
Value Function Update Magnitude: 0.37884

Collected Steps per Second: 19,689.03698
Overall Steps per Second: 9,967.49852

Timestep Collection Time: 2.54040
Timestep Consumption Time: 2.47771
PPO Batch Consumption Time: 0.29910
Total Iteration Time: 5.01811

Cumulative Model Updates: 118,822
Cumulative Timesteps: 991,812,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 991812020...
Checkpoint 991812020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,420.73669
Policy Entropy: 1.72353
Value Function Loss: 0.07802

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.33996
Value Function Update Magnitude: 0.39193

Collected Steps per Second: 19,699.54277
Overall Steps per Second: 10,063.60589

Timestep Collection Time: 2.53823
Timestep Consumption Time: 2.43037
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.96860

Cumulative Model Updates: 118,828
Cumulative Timesteps: 991,862,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,274.11968
Policy Entropy: 1.72188
Value Function Loss: 0.07561

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.34119
Value Function Update Magnitude: 0.40058

Collected Steps per Second: 20,460.58561
Overall Steps per Second: 10,161.09519

Timestep Collection Time: 2.44568
Timestep Consumption Time: 2.47899
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 4.92467

Cumulative Model Updates: 118,834
Cumulative Timesteps: 991,912,062

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 991912062...
Checkpoint 991912062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,788.51606
Policy Entropy: 1.71878
Value Function Loss: 0.07111

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.33604
Value Function Update Magnitude: 0.39328

Collected Steps per Second: 19,692.31903
Overall Steps per Second: 10,036.13587

Timestep Collection Time: 2.53916
Timestep Consumption Time: 2.44303
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.98220

Cumulative Model Updates: 118,840
Cumulative Timesteps: 991,962,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,974.70363
Policy Entropy: 1.71883
Value Function Loss: 0.06572

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.33283
Value Function Update Magnitude: 0.36268

Collected Steps per Second: 18,886.31187
Overall Steps per Second: 9,579.32772

Timestep Collection Time: 2.64784
Timestep Consumption Time: 2.57256
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 5.22041

Cumulative Model Updates: 118,846
Cumulative Timesteps: 992,012,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 992012072...
Checkpoint 992012072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,112.45949
Policy Entropy: 1.71311
Value Function Loss: 0.06965

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.32648
Value Function Update Magnitude: 0.34610

Collected Steps per Second: 20,940.09826
Overall Steps per Second: 10,104.37891

Timestep Collection Time: 2.38786
Timestep Consumption Time: 2.56069
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 4.94855

Cumulative Model Updates: 118,852
Cumulative Timesteps: 992,062,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,366.15925
Policy Entropy: 1.69895
Value Function Loss: 0.06793

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.32820
Value Function Update Magnitude: 0.34209

Collected Steps per Second: 21,960.12325
Overall Steps per Second: 10,383.36728

Timestep Collection Time: 2.27704
Timestep Consumption Time: 2.53874
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.81578

Cumulative Model Updates: 118,858
Cumulative Timesteps: 992,112,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 992112078...
Checkpoint 992112078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,007.30347
Policy Entropy: 1.70929
Value Function Loss: 0.07219

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.33164
Value Function Update Magnitude: 0.34912

Collected Steps per Second: 19,574.55694
Overall Steps per Second: 9,985.00673

Timestep Collection Time: 2.55638
Timestep Consumption Time: 2.45513
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 5.01151

Cumulative Model Updates: 118,864
Cumulative Timesteps: 992,162,118

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,510.61597
Policy Entropy: 1.70412
Value Function Loss: 0.07254

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.33426
Value Function Update Magnitude: 0.34948

Collected Steps per Second: 20,101.05747
Overall Steps per Second: 9,958.08657

Timestep Collection Time: 2.48833
Timestep Consumption Time: 2.53453
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 5.02285

Cumulative Model Updates: 118,870
Cumulative Timesteps: 992,212,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 992212136...
Checkpoint 992212136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,255.35646
Policy Entropy: 1.71129
Value Function Loss: 0.07662

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.33757
Value Function Update Magnitude: 0.34811

Collected Steps per Second: 20,308.54751
Overall Steps per Second: 10,195.05045

Timestep Collection Time: 2.46320
Timestep Consumption Time: 2.44350
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.90669

Cumulative Model Updates: 118,876
Cumulative Timesteps: 992,262,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,357.68140
Policy Entropy: 1.69853
Value Function Loss: 0.08046

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08236
Policy Update Magnitude: 0.33569
Value Function Update Magnitude: 0.35915

Collected Steps per Second: 21,579.88760
Overall Steps per Second: 10,414.13690

Timestep Collection Time: 2.31836
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.80405

Cumulative Model Updates: 118,882
Cumulative Timesteps: 992,312,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 992312190...
Checkpoint 992312190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,873.86259
Policy Entropy: 1.70959
Value Function Loss: 0.07817

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.34142
Value Function Update Magnitude: 0.37024

Collected Steps per Second: 21,788.10719
Overall Steps per Second: 10,567.36804

Timestep Collection Time: 2.29492
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.73174

Cumulative Model Updates: 118,888
Cumulative Timesteps: 992,362,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,715.77069
Policy Entropy: 1.71463
Value Function Loss: 0.07360

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.32921
Value Function Update Magnitude: 0.37270

Collected Steps per Second: 21,613.87147
Overall Steps per Second: 10,485.07897

Timestep Collection Time: 2.31333
Timestep Consumption Time: 2.45535
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.76868

Cumulative Model Updates: 118,894
Cumulative Timesteps: 992,412,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 992412192...
Checkpoint 992412192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,997.95378
Policy Entropy: 1.71744
Value Function Loss: 0.06706

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.29791
Value Function Update Magnitude: 0.35415

Collected Steps per Second: 21,628.64510
Overall Steps per Second: 10,380.12002

Timestep Collection Time: 2.31286
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.81921

Cumulative Model Updates: 118,900
Cumulative Timesteps: 992,462,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,684.99670
Policy Entropy: 1.71558
Value Function Loss: 0.06875

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.28318
Value Function Update Magnitude: 0.34235

Collected Steps per Second: 21,987.17345
Overall Steps per Second: 10,449.25661

Timestep Collection Time: 2.27478
Timestep Consumption Time: 2.51178
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.78656

Cumulative Model Updates: 118,906
Cumulative Timesteps: 992,512,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 992512232...
Checkpoint 992512232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,030.95166
Policy Entropy: 1.71265
Value Function Loss: 0.06825

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.28704
Value Function Update Magnitude: 0.34589

Collected Steps per Second: 21,061.79104
Overall Steps per Second: 10,247.15053

Timestep Collection Time: 2.37454
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.88058

Cumulative Model Updates: 118,912
Cumulative Timesteps: 992,562,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,862.15234
Policy Entropy: 1.70795
Value Function Loss: 0.07110

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.31225
Value Function Update Magnitude: 0.36131

Collected Steps per Second: 21,519.10270
Overall Steps per Second: 10,303.24125

Timestep Collection Time: 2.32407
Timestep Consumption Time: 2.52993
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.85401

Cumulative Model Updates: 118,918
Cumulative Timesteps: 992,612,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 992612256...
Checkpoint 992612256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,799.16701
Policy Entropy: 1.70503
Value Function Loss: 0.06638

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.30529
Value Function Update Magnitude: 0.35597

Collected Steps per Second: 21,553.24781
Overall Steps per Second: 10,370.85530

Timestep Collection Time: 2.32114
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.82390

Cumulative Model Updates: 118,924
Cumulative Timesteps: 992,662,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,968.27068
Policy Entropy: 1.71026
Value Function Loss: 0.06763

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.31877
Value Function Update Magnitude: 0.33749

Collected Steps per Second: 21,815.36973
Overall Steps per Second: 10,184.49086

Timestep Collection Time: 2.29270
Timestep Consumption Time: 2.61830
PPO Batch Consumption Time: 0.30648
Total Iteration Time: 4.91100

Cumulative Model Updates: 118,930
Cumulative Timesteps: 992,712,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 992712300...
Checkpoint 992712300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,656.58532
Policy Entropy: 1.71142
Value Function Loss: 0.06519

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.32379
Value Function Update Magnitude: 0.33530

Collected Steps per Second: 21,100.43688
Overall Steps per Second: 10,176.64548

Timestep Collection Time: 2.37076
Timestep Consumption Time: 2.54481
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.91557

Cumulative Model Updates: 118,936
Cumulative Timesteps: 992,762,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,575.24530
Policy Entropy: 1.70806
Value Function Loss: 0.06916

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.30313
Value Function Update Magnitude: 0.33341

Collected Steps per Second: 21,499.64424
Overall Steps per Second: 10,485.05285

Timestep Collection Time: 2.32683
Timestep Consumption Time: 2.44434
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.77117

Cumulative Model Updates: 118,942
Cumulative Timesteps: 992,812,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 992812350...
Checkpoint 992812350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,963.92339
Policy Entropy: 1.69713
Value Function Loss: 0.07028

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.29997
Value Function Update Magnitude: 0.34060

Collected Steps per Second: 21,250.91744
Overall Steps per Second: 10,246.13875

Timestep Collection Time: 2.35425
Timestep Consumption Time: 2.52856
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.88282

Cumulative Model Updates: 118,948
Cumulative Timesteps: 992,862,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,479.02924
Policy Entropy: 1.70073
Value Function Loss: 0.06925

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.32237
Value Function Update Magnitude: 0.36480

Collected Steps per Second: 21,438.24043
Overall Steps per Second: 10,470.93147

Timestep Collection Time: 2.33293
Timestep Consumption Time: 2.44353
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.77646

Cumulative Model Updates: 118,954
Cumulative Timesteps: 992,912,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 992912394...
Checkpoint 992912394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,243.40619
Policy Entropy: 1.69561
Value Function Loss: 0.07441

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.32993
Value Function Update Magnitude: 0.38232

Collected Steps per Second: 21,735.86680
Overall Steps per Second: 10,577.42754

Timestep Collection Time: 2.30071
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.72780

Cumulative Model Updates: 118,960
Cumulative Timesteps: 992,962,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,830.48113
Policy Entropy: 1.69457
Value Function Loss: 0.07744

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.33968
Value Function Update Magnitude: 0.35875

Collected Steps per Second: 21,659.93836
Overall Steps per Second: 10,457.89549

Timestep Collection Time: 2.30979
Timestep Consumption Time: 2.47415
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.78395

Cumulative Model Updates: 118,966
Cumulative Timesteps: 993,012,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 993012432...
Checkpoint 993012432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,893.62093
Policy Entropy: 1.69019
Value Function Loss: 0.07486

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.33726
Value Function Update Magnitude: 0.34725

Collected Steps per Second: 20,478.41329
Overall Steps per Second: 10,173.99661

Timestep Collection Time: 2.44326
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.91783

Cumulative Model Updates: 118,972
Cumulative Timesteps: 993,062,466

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,811.94430
Policy Entropy: 1.70447
Value Function Loss: 0.06798

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.33036
Value Function Update Magnitude: 0.36841

Collected Steps per Second: 21,014.27076
Overall Steps per Second: 10,520.95274

Timestep Collection Time: 2.37962
Timestep Consumption Time: 2.37337
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.75299

Cumulative Model Updates: 118,978
Cumulative Timesteps: 993,112,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 993112472...
Checkpoint 993112472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,426.46142
Policy Entropy: 1.71152
Value Function Loss: 0.06588

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.32776
Value Function Update Magnitude: 0.36322

Collected Steps per Second: 20,957.86487
Overall Steps per Second: 10,379.70012

Timestep Collection Time: 2.38603
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.81767

Cumulative Model Updates: 118,984
Cumulative Timesteps: 993,162,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,220.83304
Policy Entropy: 1.72629
Value Function Loss: 0.06846

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.32448
Value Function Update Magnitude: 0.36330

Collected Steps per Second: 20,968.54425
Overall Steps per Second: 10,326.30108

Timestep Collection Time: 2.38624
Timestep Consumption Time: 2.45925
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.84549

Cumulative Model Updates: 118,990
Cumulative Timesteps: 993,212,514

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 993212514...
Checkpoint 993212514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,362.50055
Policy Entropy: 1.71516
Value Function Loss: 0.06410

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.31787
Value Function Update Magnitude: 0.35036

Collected Steps per Second: 20,484.62926
Overall Steps per Second: 10,245.63302

Timestep Collection Time: 2.44193
Timestep Consumption Time: 2.44035
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.88228

Cumulative Model Updates: 118,996
Cumulative Timesteps: 993,262,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,219.14976
Policy Entropy: 1.71683
Value Function Loss: 0.06533

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.32149
Value Function Update Magnitude: 0.32509

Collected Steps per Second: 21,654.53722
Overall Steps per Second: 10,368.46140

Timestep Collection Time: 2.30972
Timestep Consumption Time: 2.51414
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.82386

Cumulative Model Updates: 119,002
Cumulative Timesteps: 993,312,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 993312552...
Checkpoint 993312552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,547.27075
Policy Entropy: 1.72206
Value Function Loss: 0.06855

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.32496
Value Function Update Magnitude: 0.33259

Collected Steps per Second: 20,305.49878
Overall Steps per Second: 10,125.87938

Timestep Collection Time: 2.46426
Timestep Consumption Time: 2.47734
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.94160

Cumulative Model Updates: 119,008
Cumulative Timesteps: 993,362,590

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,747.59618
Policy Entropy: 1.72624
Value Function Loss: 0.07437

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.32833
Value Function Update Magnitude: 0.35510

Collected Steps per Second: 21,094.55306
Overall Steps per Second: 10,369.31508

Timestep Collection Time: 2.37170
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.82481

Cumulative Model Updates: 119,014
Cumulative Timesteps: 993,412,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 993412620...
Checkpoint 993412620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,070.50351
Policy Entropy: 1.71895
Value Function Loss: 0.06649

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.31834
Value Function Update Magnitude: 0.36999

Collected Steps per Second: 21,693.88815
Overall Steps per Second: 10,409.50745

Timestep Collection Time: 2.30498
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.80369

Cumulative Model Updates: 119,020
Cumulative Timesteps: 993,462,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,567.49998
Policy Entropy: 1.70986
Value Function Loss: 0.06225

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.30996
Value Function Update Magnitude: 0.35736

Collected Steps per Second: 21,900.66080
Overall Steps per Second: 10,587.91020

Timestep Collection Time: 2.28331
Timestep Consumption Time: 2.43962
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.72293

Cumulative Model Updates: 119,026
Cumulative Timesteps: 993,512,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 993512630...
Checkpoint 993512630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,795.41691
Policy Entropy: 1.70289
Value Function Loss: 0.06472

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07904
Policy Update Magnitude: 0.31948
Value Function Update Magnitude: 0.33772

Collected Steps per Second: 21,436.76929
Overall Steps per Second: 10,484.32900

Timestep Collection Time: 2.33319
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.77055

Cumulative Model Updates: 119,032
Cumulative Timesteps: 993,562,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,995.14872
Policy Entropy: 1.71236
Value Function Loss: 0.07702

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.33508
Value Function Update Magnitude: 0.32140

Collected Steps per Second: 21,655.44823
Overall Steps per Second: 10,517.61391

Timestep Collection Time: 2.30990
Timestep Consumption Time: 2.44612
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.75602

Cumulative Model Updates: 119,038
Cumulative Timesteps: 993,612,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 993612668...
Checkpoint 993612668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,468.94363
Policy Entropy: 1.70628
Value Function Loss: 0.08107

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.34494
Value Function Update Magnitude: 0.30442

Collected Steps per Second: 21,524.98812
Overall Steps per Second: 10,356.69286

Timestep Collection Time: 2.32316
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.82838

Cumulative Model Updates: 119,044
Cumulative Timesteps: 993,662,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,829.48466
Policy Entropy: 1.70707
Value Function Loss: 0.07746

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.34268
Value Function Update Magnitude: 0.34104

Collected Steps per Second: 22,171.04335
Overall Steps per Second: 10,652.35631

Timestep Collection Time: 2.25610
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.69567

Cumulative Model Updates: 119,050
Cumulative Timesteps: 993,712,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 993712694...
Checkpoint 993712694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,785.31136
Policy Entropy: 1.68807
Value Function Loss: 0.06899

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07918
Policy Update Magnitude: 0.33248
Value Function Update Magnitude: 0.34561

Collected Steps per Second: 21,406.47740
Overall Steps per Second: 10,294.04923

Timestep Collection Time: 2.33602
Timestep Consumption Time: 2.52174
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.85776

Cumulative Model Updates: 119,056
Cumulative Timesteps: 993,762,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,104.35983
Policy Entropy: 1.67172
Value Function Loss: 0.06403

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.32369
Value Function Update Magnitude: 0.32751

Collected Steps per Second: 21,365.67338
Overall Steps per Second: 10,420.78616

Timestep Collection Time: 2.34142
Timestep Consumption Time: 2.45918
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.80060

Cumulative Model Updates: 119,062
Cumulative Timesteps: 993,812,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 993812726...
Checkpoint 993812726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,632.99066
Policy Entropy: 1.67232
Value Function Loss: 0.06400

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.32424
Value Function Update Magnitude: 0.29718

Collected Steps per Second: 21,136.03617
Overall Steps per Second: 10,230.94851

Timestep Collection Time: 2.36695
Timestep Consumption Time: 2.52292
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.88987

Cumulative Model Updates: 119,068
Cumulative Timesteps: 993,862,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,497.07948
Policy Entropy: 1.67140
Value Function Loss: 0.06840

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.32603
Value Function Update Magnitude: 0.25314

Collected Steps per Second: 21,250.95865
Overall Steps per Second: 10,408.82562

Timestep Collection Time: 2.35331
Timestep Consumption Time: 2.45127
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.80458

Cumulative Model Updates: 119,074
Cumulative Timesteps: 993,912,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 993912764...
Checkpoint 993912764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,401.61738
Policy Entropy: 1.68675
Value Function Loss: 0.07223

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.32814
Value Function Update Magnitude: 0.29004

Collected Steps per Second: 21,472.62860
Overall Steps per Second: 10,320.02815

Timestep Collection Time: 2.32957
Timestep Consumption Time: 2.51751
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.84708

Cumulative Model Updates: 119,080
Cumulative Timesteps: 993,962,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,362.48258
Policy Entropy: 1.68508
Value Function Loss: 0.07198

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08341
Policy Update Magnitude: 0.32713
Value Function Update Magnitude: 0.33080

Collected Steps per Second: 21,780.47120
Overall Steps per Second: 10,329.04592

Timestep Collection Time: 2.29582
Timestep Consumption Time: 2.54529
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.84111

Cumulative Model Updates: 119,086
Cumulative Timesteps: 994,012,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 994012790...
Checkpoint 994012790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,270.40424
Policy Entropy: 1.68551
Value Function Loss: 0.07056

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.31995
Value Function Update Magnitude: 0.35156

Collected Steps per Second: 20,394.55849
Overall Steps per Second: 10,206.85420

Timestep Collection Time: 2.45232
Timestep Consumption Time: 2.44772
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.90004

Cumulative Model Updates: 119,092
Cumulative Timesteps: 994,062,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,597.52178
Policy Entropy: 1.67533
Value Function Loss: 0.07567

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.31074
Value Function Update Magnitude: 0.33915

Collected Steps per Second: 21,492.55824
Overall Steps per Second: 10,408.97072

Timestep Collection Time: 2.32769
Timestep Consumption Time: 2.47855
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.80624

Cumulative Model Updates: 119,098
Cumulative Timesteps: 994,112,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 994112832...
Checkpoint 994112832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,679.24887
Policy Entropy: 1.67768
Value Function Loss: 0.07885

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.33010
Value Function Update Magnitude: 0.36528

Collected Steps per Second: 21,713.32379
Overall Steps per Second: 10,372.83009

Timestep Collection Time: 2.30384
Timestep Consumption Time: 2.51876
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.82260

Cumulative Model Updates: 119,104
Cumulative Timesteps: 994,162,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,096.49254
Policy Entropy: 1.69022
Value Function Loss: 0.07546

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.33637
Value Function Update Magnitude: 0.37851

Collected Steps per Second: 21,691.89870
Overall Steps per Second: 10,375.30607

Timestep Collection Time: 2.30538
Timestep Consumption Time: 2.51453
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.81991

Cumulative Model Updates: 119,110
Cumulative Timesteps: 994,212,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 994212864...
Checkpoint 994212864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,539.29299
Policy Entropy: 1.69955
Value Function Loss: 0.07656

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.32096
Value Function Update Magnitude: 0.38120

Collected Steps per Second: 21,379.88992
Overall Steps per Second: 10,286.10632

Timestep Collection Time: 2.33930
Timestep Consumption Time: 2.52299
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.86229

Cumulative Model Updates: 119,116
Cumulative Timesteps: 994,262,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,761.62537
Policy Entropy: 1.70401
Value Function Loss: 0.07347

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.29733
Value Function Update Magnitude: 0.38325

Collected Steps per Second: 21,741.03665
Overall Steps per Second: 10,408.82973

Timestep Collection Time: 2.30026
Timestep Consumption Time: 2.50432
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.80457

Cumulative Model Updates: 119,122
Cumulative Timesteps: 994,312,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 994312888...
Checkpoint 994312888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,841.58071
Policy Entropy: 1.69999
Value Function Loss: 0.07272

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.30378
Value Function Update Magnitude: 0.36938

Collected Steps per Second: 21,707.01478
Overall Steps per Second: 10,560.30282

Timestep Collection Time: 2.30349
Timestep Consumption Time: 2.43141
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.73490

Cumulative Model Updates: 119,128
Cumulative Timesteps: 994,362,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,590.63115
Policy Entropy: 1.68838
Value Function Loss: 0.06869

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.31712
Value Function Update Magnitude: 0.34926

Collected Steps per Second: 21,495.18713
Overall Steps per Second: 10,456.49353

Timestep Collection Time: 2.32694
Timestep Consumption Time: 2.45650
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.78344

Cumulative Model Updates: 119,134
Cumulative Timesteps: 994,412,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 994412908...
Checkpoint 994412908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,149.85807
Policy Entropy: 1.68520
Value Function Loss: 0.06913

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.32023
Value Function Update Magnitude: 0.35362

Collected Steps per Second: 21,375.08090
Overall Steps per Second: 10,328.33603

Timestep Collection Time: 2.33927
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.84124

Cumulative Model Updates: 119,140
Cumulative Timesteps: 994,462,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,807.10361
Policy Entropy: 1.68304
Value Function Loss: 0.06818

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.32080
Value Function Update Magnitude: 0.36050

Collected Steps per Second: 21,122.99429
Overall Steps per Second: 10,387.11795

Timestep Collection Time: 2.36794
Timestep Consumption Time: 2.44745
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.81539

Cumulative Model Updates: 119,146
Cumulative Timesteps: 994,512,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 994512928...
Checkpoint 994512928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,001.28111
Policy Entropy: 1.68256
Value Function Loss: 0.06812

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08888
Policy Update Magnitude: 0.31277
Value Function Update Magnitude: 0.36264

Collected Steps per Second: 20,940.52614
Overall Steps per Second: 10,404.45422

Timestep Collection Time: 2.38771
Timestep Consumption Time: 2.41792
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.80563

Cumulative Model Updates: 119,152
Cumulative Timesteps: 994,562,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,310.61102
Policy Entropy: 1.68757
Value Function Loss: 0.06747

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.30799
Value Function Update Magnitude: 0.35960

Collected Steps per Second: 20,938.93486
Overall Steps per Second: 10,291.34709

Timestep Collection Time: 2.38876
Timestep Consumption Time: 2.47144
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.86020

Cumulative Model Updates: 119,158
Cumulative Timesteps: 994,612,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 994612946...
Checkpoint 994612946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,313.93898
Policy Entropy: 1.68695
Value Function Loss: 0.06653

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.31766
Value Function Update Magnitude: 0.36248

Collected Steps per Second: 20,783.27244
Overall Steps per Second: 10,358.08893

Timestep Collection Time: 2.40761
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.83081

Cumulative Model Updates: 119,164
Cumulative Timesteps: 994,662,984

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,495.57604
Policy Entropy: 1.69849
Value Function Loss: 0.06369

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.32037
Value Function Update Magnitude: 0.35737

Collected Steps per Second: 21,136.08082
Overall Steps per Second: 10,502.83487

Timestep Collection Time: 2.36733
Timestep Consumption Time: 2.39672
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.76405

Cumulative Model Updates: 119,170
Cumulative Timesteps: 994,713,020

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 994713020...
Checkpoint 994713020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,713.63135
Policy Entropy: 1.68926
Value Function Loss: 0.06173

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.32035
Value Function Update Magnitude: 0.33982

Collected Steps per Second: 21,373.12320
Overall Steps per Second: 10,411.88807

Timestep Collection Time: 2.34088
Timestep Consumption Time: 2.46439
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.80528

Cumulative Model Updates: 119,176
Cumulative Timesteps: 994,763,052

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,653.43645
Policy Entropy: 1.69752
Value Function Loss: 0.06947

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.32556
Value Function Update Magnitude: 0.33972

Collected Steps per Second: 20,135.08596
Overall Steps per Second: 9,914.98875

Timestep Collection Time: 2.48343
Timestep Consumption Time: 2.55985
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 5.04327

Cumulative Model Updates: 119,182
Cumulative Timesteps: 994,813,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 994813056...
Checkpoint 994813056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,125.84219
Policy Entropy: 1.69035
Value Function Loss: 0.07362

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.33385
Value Function Update Magnitude: 0.37055

Collected Steps per Second: 19,923.42853
Overall Steps per Second: 9,914.38547

Timestep Collection Time: 2.51101
Timestep Consumption Time: 2.53499
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 5.04600

Cumulative Model Updates: 119,188
Cumulative Timesteps: 994,863,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,132.16289
Policy Entropy: 1.69472
Value Function Loss: 0.07700

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08948
Policy Update Magnitude: 0.33780
Value Function Update Magnitude: 0.36622

Collected Steps per Second: 21,800.14715
Overall Steps per Second: 10,469.03058

Timestep Collection Time: 2.29356
Timestep Consumption Time: 2.48243
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.77599

Cumulative Model Updates: 119,194
Cumulative Timesteps: 994,913,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 994913084...
Checkpoint 994913084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,851.81604
Policy Entropy: 1.69039
Value Function Loss: 0.07411

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.33655
Value Function Update Magnitude: 0.39136

Collected Steps per Second: 21,451.22955
Overall Steps per Second: 10,552.44038

Timestep Collection Time: 2.33161
Timestep Consumption Time: 2.40814
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.73976

Cumulative Model Updates: 119,200
Cumulative Timesteps: 994,963,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,272.92114
Policy Entropy: 1.69670
Value Function Loss: 0.06915

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.33060
Value Function Update Magnitude: 0.39183

Collected Steps per Second: 21,251.40184
Overall Steps per Second: 10,415.21435

Timestep Collection Time: 2.35307
Timestep Consumption Time: 2.44818
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.80125

Cumulative Model Updates: 119,206
Cumulative Timesteps: 995,013,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 995013106...
Checkpoint 995013106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,630.18096
Policy Entropy: 1.70023
Value Function Loss: 0.06830

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.32832
Value Function Update Magnitude: 0.37480

Collected Steps per Second: 21,728.09571
Overall Steps per Second: 10,373.80678

Timestep Collection Time: 2.30163
Timestep Consumption Time: 2.51917
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.82080

Cumulative Model Updates: 119,212
Cumulative Timesteps: 995,063,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,969.97494
Policy Entropy: 1.70089
Value Function Loss: 0.06734

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.31831
Value Function Update Magnitude: 0.34927

Collected Steps per Second: 20,820.91850
Overall Steps per Second: 10,316.27603

Timestep Collection Time: 2.40287
Timestep Consumption Time: 2.44675
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.84962

Cumulative Model Updates: 119,218
Cumulative Timesteps: 995,113,146

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 995113146...
Checkpoint 995113146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,347.80220
Policy Entropy: 1.70064
Value Function Loss: 0.06884

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.31037
Value Function Update Magnitude: 0.29259

Collected Steps per Second: 21,442.02667
Overall Steps per Second: 10,305.48159

Timestep Collection Time: 2.33234
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.85276

Cumulative Model Updates: 119,224
Cumulative Timesteps: 995,163,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,920.16432
Policy Entropy: 1.70066
Value Function Loss: 0.06393

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.32183
Value Function Update Magnitude: 0.26996

Collected Steps per Second: 21,217.88919
Overall Steps per Second: 10,386.10497

Timestep Collection Time: 2.35669
Timestep Consumption Time: 2.45782
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.81451

Cumulative Model Updates: 119,230
Cumulative Timesteps: 995,213,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 995213160...
Checkpoint 995213160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,509.73181
Policy Entropy: 1.69706
Value Function Loss: 0.06706

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.32198
Value Function Update Magnitude: 0.27836

Collected Steps per Second: 21,592.46339
Overall Steps per Second: 10,365.01388

Timestep Collection Time: 2.31609
Timestep Consumption Time: 2.50880
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.82489

Cumulative Model Updates: 119,236
Cumulative Timesteps: 995,263,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,420.49248
Policy Entropy: 1.69204
Value Function Loss: 0.06533

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.32482
Value Function Update Magnitude: 0.27077

Collected Steps per Second: 21,006.25428
Overall Steps per Second: 10,392.29079

Timestep Collection Time: 2.38034
Timestep Consumption Time: 2.43111
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.81145

Cumulative Model Updates: 119,242
Cumulative Timesteps: 995,313,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 995313172...
Checkpoint 995313172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,034.48874
Policy Entropy: 1.67594
Value Function Loss: 0.07038

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.33000
Value Function Update Magnitude: 0.27473

Collected Steps per Second: 21,103.25362
Overall Steps per Second: 10,191.80321

Timestep Collection Time: 2.36930
Timestep Consumption Time: 2.53660
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.90590

Cumulative Model Updates: 119,248
Cumulative Timesteps: 995,363,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,642.81469
Policy Entropy: 1.66997
Value Function Loss: 0.06611

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.32979
Value Function Update Magnitude: 0.27595

Collected Steps per Second: 21,263.38712
Overall Steps per Second: 10,378.35864

Timestep Collection Time: 2.35259
Timestep Consumption Time: 2.46744
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.82003

Cumulative Model Updates: 119,254
Cumulative Timesteps: 995,413,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 995413196...
Checkpoint 995413196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,375.94489
Policy Entropy: 1.65722
Value Function Loss: 0.06740

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.33007
Value Function Update Magnitude: 0.29889

Collected Steps per Second: 21,354.28224
Overall Steps per Second: 10,240.87101

Timestep Collection Time: 2.34154
Timestep Consumption Time: 2.54105
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.88259

Cumulative Model Updates: 119,260
Cumulative Timesteps: 995,463,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,218.79046
Policy Entropy: 1.66203
Value Function Loss: 0.06333

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08259
Policy Update Magnitude: 0.32979
Value Function Update Magnitude: 0.31606

Collected Steps per Second: 21,702.39689
Overall Steps per Second: 10,435.03120

Timestep Collection Time: 2.30491
Timestep Consumption Time: 2.48875
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.79366

Cumulative Model Updates: 119,266
Cumulative Timesteps: 995,513,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 995513220...
Checkpoint 995513220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,171.00436
Policy Entropy: 1.66450
Value Function Loss: 0.06885

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.32983
Value Function Update Magnitude: 0.30931

Collected Steps per Second: 21,744.59581
Overall Steps per Second: 10,572.84292

Timestep Collection Time: 2.30025
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.73080

Cumulative Model Updates: 119,272
Cumulative Timesteps: 995,563,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,093.00500
Policy Entropy: 1.67287
Value Function Loss: 0.07112

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.33000
Value Function Update Magnitude: 0.27938

Collected Steps per Second: 21,676.49039
Overall Steps per Second: 10,479.58477

Timestep Collection Time: 2.30683
Timestep Consumption Time: 2.46473
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.77156

Cumulative Model Updates: 119,278
Cumulative Timesteps: 995,613,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 995613242...
Checkpoint 995613242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,955.48549
Policy Entropy: 1.67064
Value Function Loss: 0.07412

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.32707
Value Function Update Magnitude: 0.26893

Collected Steps per Second: 21,622.08632
Overall Steps per Second: 10,394.46388

Timestep Collection Time: 2.31245
Timestep Consumption Time: 2.49780
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.81025

Cumulative Model Updates: 119,284
Cumulative Timesteps: 995,663,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,914.89516
Policy Entropy: 1.67305
Value Function Loss: 0.07330

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.33160
Value Function Update Magnitude: 0.25255

Collected Steps per Second: 21,942.31788
Overall Steps per Second: 10,460.61559

Timestep Collection Time: 2.28034
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.78327

Cumulative Model Updates: 119,290
Cumulative Timesteps: 995,713,278

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 995713278...
Checkpoint 995713278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,490.48948
Policy Entropy: 1.66347
Value Function Loss: 0.07730

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.33788
Value Function Update Magnitude: 0.25584

Collected Steps per Second: 21,654.39153
Overall Steps per Second: 10,566.88995

Timestep Collection Time: 2.31029
Timestep Consumption Time: 2.42412
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.73441

Cumulative Model Updates: 119,296
Cumulative Timesteps: 995,763,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,120.17539
Policy Entropy: 1.67004
Value Function Loss: 0.07964

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.34600
Value Function Update Magnitude: 0.27353

Collected Steps per Second: 21,137.61984
Overall Steps per Second: 10,338.99150

Timestep Collection Time: 2.36696
Timestep Consumption Time: 2.47219
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.83916

Cumulative Model Updates: 119,302
Cumulative Timesteps: 995,813,338

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 995813338...
Checkpoint 995813338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,491.62965
Policy Entropy: 1.65303
Value Function Loss: 0.07474

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.34579
Value Function Update Magnitude: 0.26353

Collected Steps per Second: 20,403.45229
Overall Steps per Second: 10,327.52016

Timestep Collection Time: 2.45194
Timestep Consumption Time: 2.39221
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.84414

Cumulative Model Updates: 119,308
Cumulative Timesteps: 995,863,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,904.82792
Policy Entropy: 1.66293
Value Function Loss: 0.07452

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.34237
Value Function Update Magnitude: 0.26818

Collected Steps per Second: 20,623.95144
Overall Steps per Second: 10,463.01334

Timestep Collection Time: 2.42504
Timestep Consumption Time: 2.35503
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.78008

Cumulative Model Updates: 119,314
Cumulative Timesteps: 995,913,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 995913380...
Checkpoint 995913380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,573.35145
Policy Entropy: 1.66872
Value Function Loss: 0.07166

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.34004
Value Function Update Magnitude: 0.26032

Collected Steps per Second: 20,639.89194
Overall Steps per Second: 10,346.89828

Timestep Collection Time: 2.42346
Timestep Consumption Time: 2.41084
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.83430

Cumulative Model Updates: 119,320
Cumulative Timesteps: 995,963,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,774.16781
Policy Entropy: 1.68387
Value Function Loss: 0.07591

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.33741
Value Function Update Magnitude: 0.30400

Collected Steps per Second: 20,582.31697
Overall Steps per Second: 10,276.16368

Timestep Collection Time: 2.43044
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.86796

Cumulative Model Updates: 119,326
Cumulative Timesteps: 996,013,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 996013424...
Checkpoint 996013424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,471.25021
Policy Entropy: 1.67204
Value Function Loss: 0.07096

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.33122
Value Function Update Magnitude: 0.35601

Collected Steps per Second: 20,773.65503
Overall Steps per Second: 10,338.56784

Timestep Collection Time: 2.40805
Timestep Consumption Time: 2.43053
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.83858

Cumulative Model Updates: 119,332
Cumulative Timesteps: 996,063,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,855.56790
Policy Entropy: 1.67570
Value Function Loss: 0.07015

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.32750
Value Function Update Magnitude: 0.36622

Collected Steps per Second: 21,187.55563
Overall Steps per Second: 10,431.20030

Timestep Collection Time: 2.36006
Timestep Consumption Time: 2.43363
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.79370

Cumulative Model Updates: 119,338
Cumulative Timesteps: 996,113,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 996113452...
Checkpoint 996113452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,269.35854
Policy Entropy: 1.66194
Value Function Loss: 0.07041

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.33038
Value Function Update Magnitude: 0.36997

Collected Steps per Second: 20,440.33698
Overall Steps per Second: 10,136.99106

Timestep Collection Time: 2.44673
Timestep Consumption Time: 2.48688
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.93361

Cumulative Model Updates: 119,344
Cumulative Timesteps: 996,163,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,807.50258
Policy Entropy: 1.66864
Value Function Loss: 0.07035

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.32815
Value Function Update Magnitude: 0.38178

Collected Steps per Second: 21,656.21848
Overall Steps per Second: 10,368.53695

Timestep Collection Time: 2.31010
Timestep Consumption Time: 2.51488
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.82498

Cumulative Model Updates: 119,350
Cumulative Timesteps: 996,213,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 996213492...
Checkpoint 996213492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,327.96162
Policy Entropy: 1.66638
Value Function Loss: 0.06557

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.32476
Value Function Update Magnitude: 0.38007

Collected Steps per Second: 21,382.79602
Overall Steps per Second: 10,377.84060

Timestep Collection Time: 2.33992
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.82123

Cumulative Model Updates: 119,356
Cumulative Timesteps: 996,263,526

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,560.79779
Policy Entropy: 1.66758
Value Function Loss: 0.06371

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.31923
Value Function Update Magnitude: 0.35780

Collected Steps per Second: 21,828.58916
Overall Steps per Second: 10,651.96476

Timestep Collection Time: 2.29195
Timestep Consumption Time: 2.40484
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.69679

Cumulative Model Updates: 119,362
Cumulative Timesteps: 996,313,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 996313556...
Checkpoint 996313556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,572.12379
Policy Entropy: 1.67112
Value Function Loss: 0.06532

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31993
Value Function Update Magnitude: 0.34552

Collected Steps per Second: 21,452.96165
Overall Steps per Second: 10,282.70092

Timestep Collection Time: 2.33264
Timestep Consumption Time: 2.53398
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.86662

Cumulative Model Updates: 119,368
Cumulative Timesteps: 996,363,598

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,987.69016
Policy Entropy: 1.66101
Value Function Loss: 0.06369

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.32041
Value Function Update Magnitude: 0.33601

Collected Steps per Second: 21,488.87328
Overall Steps per Second: 10,475.30415

Timestep Collection Time: 2.32827
Timestep Consumption Time: 2.44791
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.77619

Cumulative Model Updates: 119,374
Cumulative Timesteps: 996,413,630

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 996413630...
Checkpoint 996413630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,092.85760
Policy Entropy: 1.65616
Value Function Loss: 0.06204

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.31672
Value Function Update Magnitude: 0.32311

Collected Steps per Second: 21,579.29234
Overall Steps per Second: 10,463.72193

Timestep Collection Time: 2.31768
Timestep Consumption Time: 2.46207
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.77975

Cumulative Model Updates: 119,380
Cumulative Timesteps: 996,463,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,273.61661
Policy Entropy: 1.64743
Value Function Loss: 0.06589

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.31100
Value Function Update Magnitude: 0.32994

Collected Steps per Second: 21,653.20066
Overall Steps per Second: 10,568.35614

Timestep Collection Time: 2.31005
Timestep Consumption Time: 2.42295
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.73300

Cumulative Model Updates: 119,386
Cumulative Timesteps: 996,513,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 996513664...
Checkpoint 996513664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,975.26479
Policy Entropy: 1.64922
Value Function Loss: 0.06947

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.31192
Value Function Update Magnitude: 0.34544

Collected Steps per Second: 21,635.96862
Overall Steps per Second: 10,389.72092

Timestep Collection Time: 2.31106
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.81264

Cumulative Model Updates: 119,392
Cumulative Timesteps: 996,563,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,226.47622
Policy Entropy: 1.66200
Value Function Loss: 0.07759

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.31255
Value Function Update Magnitude: 0.34035

Collected Steps per Second: 21,518.70161
Overall Steps per Second: 10,244.05294

Timestep Collection Time: 2.32495
Timestep Consumption Time: 2.55885
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.88381

Cumulative Model Updates: 119,398
Cumulative Timesteps: 996,613,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 996613696...
Checkpoint 996613696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,468.93578
Policy Entropy: 1.67447
Value Function Loss: 0.07340

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.32679
Value Function Update Magnitude: 0.35353

Collected Steps per Second: 21,408.29956
Overall Steps per Second: 10,288.63024

Timestep Collection Time: 2.33638
Timestep Consumption Time: 2.52510
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.86148

Cumulative Model Updates: 119,404
Cumulative Timesteps: 996,663,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,062.55659
Policy Entropy: 1.69420
Value Function Loss: 0.07512

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.32695
Value Function Update Magnitude: 0.35781

Collected Steps per Second: 21,823.92324
Overall Steps per Second: 10,452.35417

Timestep Collection Time: 2.29262
Timestep Consumption Time: 2.49424
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.78686

Cumulative Model Updates: 119,410
Cumulative Timesteps: 996,713,748

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 996713748...
Checkpoint 996713748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,190.95655
Policy Entropy: 1.68562
Value Function Loss: 0.06526

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.32285
Value Function Update Magnitude: 0.36490

Collected Steps per Second: 21,661.47713
Overall Steps per Second: 10,381.96034

Timestep Collection Time: 2.30926
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.81817

Cumulative Model Updates: 119,416
Cumulative Timesteps: 996,763,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,729.78945
Policy Entropy: 1.67936
Value Function Loss: 0.06451

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.32218
Value Function Update Magnitude: 0.34256

Collected Steps per Second: 21,907.64898
Overall Steps per Second: 10,334.99286

Timestep Collection Time: 2.28331
Timestep Consumption Time: 2.55675
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.84006

Cumulative Model Updates: 119,422
Cumulative Timesteps: 996,813,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 996813792...
Checkpoint 996813792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,975.73120
Policy Entropy: 1.66241
Value Function Loss: 0.06439

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.31381
Value Function Update Magnitude: 0.32399

Collected Steps per Second: 21,389.72947
Overall Steps per Second: 10,333.73224

Timestep Collection Time: 2.33851
Timestep Consumption Time: 2.50195
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.84046

Cumulative Model Updates: 119,428
Cumulative Timesteps: 996,863,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,027.57012
Policy Entropy: 1.68075
Value Function Loss: 0.07232

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.30859
Value Function Update Magnitude: 0.30580

Collected Steps per Second: 21,967.57789
Overall Steps per Second: 10,456.35341

Timestep Collection Time: 2.27754
Timestep Consumption Time: 2.50730
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.78484

Cumulative Model Updates: 119,434
Cumulative Timesteps: 996,913,844

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 996913844...
Checkpoint 996913844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,753.06662
Policy Entropy: 1.67720
Value Function Loss: 0.08037

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.31676
Value Function Update Magnitude: 0.25951

Collected Steps per Second: 21,443.91791
Overall Steps per Second: 10,460.00763

Timestep Collection Time: 2.33297
Timestep Consumption Time: 2.44982
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.78279

Cumulative Model Updates: 119,440
Cumulative Timesteps: 996,963,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,846.81256
Policy Entropy: 1.68156
Value Function Loss: 0.08381

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.32357
Value Function Update Magnitude: 0.26331

Collected Steps per Second: 21,708.08355
Overall Steps per Second: 10,494.03654

Timestep Collection Time: 2.30458
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.76728

Cumulative Model Updates: 119,446
Cumulative Timesteps: 997,013,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 997013900...
Checkpoint 997013900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,104.52127
Policy Entropy: 1.67628
Value Function Loss: 0.08520

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.31717
Value Function Update Magnitude: 0.35237

Collected Steps per Second: 21,527.35314
Overall Steps per Second: 10,518.05102

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.43188
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.75525

Cumulative Model Updates: 119,452
Cumulative Timesteps: 997,063,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,502.29452
Policy Entropy: 1.69038
Value Function Loss: 0.08114

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.32168
Value Function Update Magnitude: 0.39587

Collected Steps per Second: 20,816.60974
Overall Steps per Second: 9,927.65798

Timestep Collection Time: 2.40279
Timestep Consumption Time: 2.63545
PPO Batch Consumption Time: 0.30537
Total Iteration Time: 5.03825

Cumulative Model Updates: 119,458
Cumulative Timesteps: 997,113,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 997113934...
Checkpoint 997113934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,384.29539
Policy Entropy: 1.70209
Value Function Loss: 0.08089

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.33840
Value Function Update Magnitude: 0.36368

Collected Steps per Second: 20,457.80064
Overall Steps per Second: 9,913.06343

Timestep Collection Time: 2.44533
Timestep Consumption Time: 2.60115
PPO Batch Consumption Time: 0.30553
Total Iteration Time: 5.04647

Cumulative Model Updates: 119,464
Cumulative Timesteps: 997,163,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,893.70214
Policy Entropy: 1.69712
Value Function Loss: 0.07442

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.34053
Value Function Update Magnitude: 0.32589

Collected Steps per Second: 20,467.85121
Overall Steps per Second: 10,021.75916

Timestep Collection Time: 2.44383
Timestep Consumption Time: 2.54731
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.99114

Cumulative Model Updates: 119,470
Cumulative Timesteps: 997,213,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 997213980...
Checkpoint 997213980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,103.82024
Policy Entropy: 1.69355
Value Function Loss: 0.07232

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.33332
Value Function Update Magnitude: 0.31601

Collected Steps per Second: 21,273.18124
Overall Steps per Second: 10,121.22008

Timestep Collection Time: 2.35292
Timestep Consumption Time: 2.59254
PPO Batch Consumption Time: 0.30366
Total Iteration Time: 4.94545

Cumulative Model Updates: 119,476
Cumulative Timesteps: 997,264,034

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,572.13923
Policy Entropy: 1.67089
Value Function Loss: 0.07109

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.33317
Value Function Update Magnitude: 0.30466

Collected Steps per Second: 21,691.98997
Overall Steps per Second: 10,126.25520

Timestep Collection Time: 2.30527
Timestep Consumption Time: 2.63298
PPO Batch Consumption Time: 0.31101
Total Iteration Time: 4.93825

Cumulative Model Updates: 119,482
Cumulative Timesteps: 997,314,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 997314040...
Checkpoint 997314040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,613.53151
Policy Entropy: 1.66096
Value Function Loss: 0.07383

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.33450
Value Function Update Magnitude: 0.34989

Collected Steps per Second: 20,543.79488
Overall Steps per Second: 10,174.66936

Timestep Collection Time: 2.43470
Timestep Consumption Time: 2.48123
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.91593

Cumulative Model Updates: 119,488
Cumulative Timesteps: 997,364,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,833.82102
Policy Entropy: 1.65404
Value Function Loss: 0.07371

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.33619
Value Function Update Magnitude: 0.39025

Collected Steps per Second: 20,904.95582
Overall Steps per Second: 10,047.82543

Timestep Collection Time: 2.39197
Timestep Consumption Time: 2.58463
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.97660

Cumulative Model Updates: 119,494
Cumulative Timesteps: 997,414,062

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 997414062...
Checkpoint 997414062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,487.76247
Policy Entropy: 1.66612
Value Function Loss: 0.07664

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.34069
Value Function Update Magnitude: 0.39672

Collected Steps per Second: 19,619.16731
Overall Steps per Second: 9,773.40248

Timestep Collection Time: 2.55016
Timestep Consumption Time: 2.56904
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 5.11920

Cumulative Model Updates: 119,500
Cumulative Timesteps: 997,464,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,272.47950
Policy Entropy: 1.66221
Value Function Loss: 0.07383

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.32541
Value Function Update Magnitude: 0.40291

Collected Steps per Second: 22,042.46907
Overall Steps per Second: 10,617.34081

Timestep Collection Time: 2.26962
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.71191

Cumulative Model Updates: 119,506
Cumulative Timesteps: 997,514,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 997514122...
Checkpoint 997514122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,050.51614
Policy Entropy: 1.65604
Value Function Loss: 0.06717

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.31454
Value Function Update Magnitude: 0.38941

Collected Steps per Second: 21,590.78401
Overall Steps per Second: 10,192.31180

Timestep Collection Time: 2.31756
Timestep Consumption Time: 2.59182
PPO Batch Consumption Time: 0.30624
Total Iteration Time: 4.90939

Cumulative Model Updates: 119,512
Cumulative Timesteps: 997,564,160

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,637.54078
Policy Entropy: 1.64789
Value Function Loss: 0.06419

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.31481
Value Function Update Magnitude: 0.37545

Collected Steps per Second: 17,383.99197
Overall Steps per Second: 9,111.32650

Timestep Collection Time: 2.87874
Timestep Consumption Time: 2.61376
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 5.49250

Cumulative Model Updates: 119,518
Cumulative Timesteps: 997,614,204

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 997614204...
Checkpoint 997614204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,484.65993
Policy Entropy: 1.64362
Value Function Loss: 0.06675

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.32235
Value Function Update Magnitude: 0.37139

Collected Steps per Second: 20,668.23750
Overall Steps per Second: 10,011.83792

Timestep Collection Time: 2.42140
Timestep Consumption Time: 2.57729
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.99868

Cumulative Model Updates: 119,524
Cumulative Timesteps: 997,664,250

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,963.46281
Policy Entropy: 1.64572
Value Function Loss: 0.07051

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.32373
Value Function Update Magnitude: 0.37571

Collected Steps per Second: 20,597.18327
Overall Steps per Second: 9,994.76627

Timestep Collection Time: 2.42888
Timestep Consumption Time: 2.57654
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 5.00542

Cumulative Model Updates: 119,530
Cumulative Timesteps: 997,714,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 997714278...
Checkpoint 997714278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,124.73433
Policy Entropy: 1.64877
Value Function Loss: 0.06903

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.32487
Value Function Update Magnitude: 0.36289

Collected Steps per Second: 20,507.42153
Overall Steps per Second: 10,127.71688

Timestep Collection Time: 2.43882
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.93833

Cumulative Model Updates: 119,536
Cumulative Timesteps: 997,764,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,440.86608
Policy Entropy: 1.64630
Value Function Loss: 0.06511

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.32487
Value Function Update Magnitude: 0.29505

Collected Steps per Second: 20,005.42047
Overall Steps per Second: 10,120.62877

Timestep Collection Time: 2.50052
Timestep Consumption Time: 2.44225
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.94278

Cumulative Model Updates: 119,542
Cumulative Timesteps: 997,814,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 997814316...
Checkpoint 997814316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,130.37011
Policy Entropy: 1.65168
Value Function Loss: 0.06842

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.32640
Value Function Update Magnitude: 0.25779

Collected Steps per Second: 19,726.07071
Overall Steps per Second: 9,961.16103

Timestep Collection Time: 2.53522
Timestep Consumption Time: 2.48528
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 5.02050

Cumulative Model Updates: 119,548
Cumulative Timesteps: 997,864,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,143.76223
Policy Entropy: 1.66339
Value Function Loss: 0.06898

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.32583
Value Function Update Magnitude: 0.24642

Collected Steps per Second: 19,986.37961
Overall Steps per Second: 10,067.67307

Timestep Collection Time: 2.50330
Timestep Consumption Time: 2.46626
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.96957

Cumulative Model Updates: 119,554
Cumulative Timesteps: 997,914,358

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 997914358...
Checkpoint 997914358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,702.65069
Policy Entropy: 1.67367
Value Function Loss: 0.07561

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.32917
Value Function Update Magnitude: 0.29667

Collected Steps per Second: 19,852.22393
Overall Steps per Second: 10,015.21490

Timestep Collection Time: 2.51881
Timestep Consumption Time: 2.47399
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.99280

Cumulative Model Updates: 119,560
Cumulative Timesteps: 997,964,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,679.47336
Policy Entropy: 1.67596
Value Function Loss: 0.07300

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.33229
Value Function Update Magnitude: 0.35691

Collected Steps per Second: 19,968.24848
Overall Steps per Second: 10,008.38374

Timestep Collection Time: 2.50508
Timestep Consumption Time: 2.49293
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.99801

Cumulative Model Updates: 119,566
Cumulative Timesteps: 998,014,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 998014384...
Checkpoint 998014384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,700.61710
Policy Entropy: 1.66516
Value Function Loss: 0.07264

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.33364
Value Function Update Magnitude: 0.35918

Collected Steps per Second: 20,024.66145
Overall Steps per Second: 9,929.65669

Timestep Collection Time: 2.49742
Timestep Consumption Time: 2.53901
PPO Batch Consumption Time: 0.30503
Total Iteration Time: 5.03643

Cumulative Model Updates: 119,572
Cumulative Timesteps: 998,064,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,378.28889
Policy Entropy: 1.67372
Value Function Loss: 0.06863

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.32756
Value Function Update Magnitude: 0.34045

Collected Steps per Second: 20,213.67017
Overall Steps per Second: 10,081.19848

Timestep Collection Time: 2.47506
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.96270

Cumulative Model Updates: 119,578
Cumulative Timesteps: 998,114,424

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 998114424...
Checkpoint 998114424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,435.22212
Policy Entropy: 1.67159
Value Function Loss: 0.06745

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.30504
Value Function Update Magnitude: 0.35684

Collected Steps per Second: 21,609.33680
Overall Steps per Second: 10,550.91866

Timestep Collection Time: 2.31391
Timestep Consumption Time: 2.42521
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.73911

Cumulative Model Updates: 119,584
Cumulative Timesteps: 998,164,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,484.06341
Policy Entropy: 1.67969
Value Function Loss: 0.07098

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.30633
Value Function Update Magnitude: 0.37838

Collected Steps per Second: 21,578.66928
Overall Steps per Second: 10,436.11368

Timestep Collection Time: 2.31729
Timestep Consumption Time: 2.47415
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.79144

Cumulative Model Updates: 119,590
Cumulative Timesteps: 998,214,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 998214430...
Checkpoint 998214430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,459.93170
Policy Entropy: 1.66317
Value Function Loss: 0.07244

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.33424
Value Function Update Magnitude: 0.38900

Collected Steps per Second: 21,362.49924
Overall Steps per Second: 10,346.23409

Timestep Collection Time: 2.34092
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.83345

Cumulative Model Updates: 119,596
Cumulative Timesteps: 998,264,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,685.82114
Policy Entropy: 1.65850
Value Function Loss: 0.06682

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.33508
Value Function Update Magnitude: 0.36731

Collected Steps per Second: 21,927.50253
Overall Steps per Second: 10,443.76260

Timestep Collection Time: 2.28079
Timestep Consumption Time: 2.50791
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.78870

Cumulative Model Updates: 119,602
Cumulative Timesteps: 998,314,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 998314450...
Checkpoint 998314450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,797.27204
Policy Entropy: 1.65487
Value Function Loss: 0.06870

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.33134
Value Function Update Magnitude: 0.34130

Collected Steps per Second: 21,632.06072
Overall Steps per Second: 10,496.31983

Timestep Collection Time: 2.31148
Timestep Consumption Time: 2.45229
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.76376

Cumulative Model Updates: 119,608
Cumulative Timesteps: 998,364,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,629.67908
Policy Entropy: 1.66370
Value Function Loss: 0.07021

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.33449
Value Function Update Magnitude: 0.32807

Collected Steps per Second: 21,815.35144
Overall Steps per Second: 10,563.32391

Timestep Collection Time: 2.29279
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.73506

Cumulative Model Updates: 119,614
Cumulative Timesteps: 998,414,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 998414470...
Checkpoint 998414470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,223.92696
Policy Entropy: 1.66209
Value Function Loss: 0.07070

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.33237
Value Function Update Magnitude: 0.35540

Collected Steps per Second: 21,387.83300
Overall Steps per Second: 10,326.06552

Timestep Collection Time: 2.33909
Timestep Consumption Time: 2.50574
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.84483

Cumulative Model Updates: 119,620
Cumulative Timesteps: 998,464,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,016.10696
Policy Entropy: 1.66397
Value Function Loss: 0.06775

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.32703
Value Function Update Magnitude: 0.33464

Collected Steps per Second: 21,296.69067
Overall Steps per Second: 10,222.91519

Timestep Collection Time: 2.34853
Timestep Consumption Time: 2.54400
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.89254

Cumulative Model Updates: 119,626
Cumulative Timesteps: 998,514,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 998514514...
Checkpoint 998514514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,237.90987
Policy Entropy: 1.67050
Value Function Loss: 0.07168

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.32364
Value Function Update Magnitude: 0.29277

Collected Steps per Second: 21,440.87002
Overall Steps per Second: 10,301.68178

Timestep Collection Time: 2.33255
Timestep Consumption Time: 2.52219
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.85474

Cumulative Model Updates: 119,632
Cumulative Timesteps: 998,564,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,098.00939
Policy Entropy: 1.68017
Value Function Loss: 0.07970

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.33077
Value Function Update Magnitude: 0.29246

Collected Steps per Second: 21,774.87284
Overall Steps per Second: 10,404.78378

Timestep Collection Time: 2.29724
Timestep Consumption Time: 2.51036
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.80760

Cumulative Model Updates: 119,638
Cumulative Timesteps: 998,614,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 998614548...
Checkpoint 998614548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,450.25077
Policy Entropy: 1.68554
Value Function Loss: 0.08293

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.30838
Value Function Update Magnitude: 0.32877

Collected Steps per Second: 21,600.42411
Overall Steps per Second: 10,392.64322

Timestep Collection Time: 2.31542
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.81244

Cumulative Model Updates: 119,644
Cumulative Timesteps: 998,664,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,368.86606
Policy Entropy: 1.67032
Value Function Loss: 0.08175

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.30329
Value Function Update Magnitude: 0.38389

Collected Steps per Second: 21,677.11534
Overall Steps per Second: 10,359.23945

Timestep Collection Time: 2.30750
Timestep Consumption Time: 2.52104
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.82854

Cumulative Model Updates: 119,650
Cumulative Timesteps: 998,714,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 998714582...
Checkpoint 998714582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,743.73894
Policy Entropy: 1.66638
Value Function Loss: 0.07965

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.32796
Value Function Update Magnitude: 0.39943

Collected Steps per Second: 21,434.04572
Overall Steps per Second: 10,362.40428

Timestep Collection Time: 2.33376
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.82726

Cumulative Model Updates: 119,656
Cumulative Timesteps: 998,764,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,395.92183
Policy Entropy: 1.66179
Value Function Loss: 0.08111

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.34480
Value Function Update Magnitude: 0.40010

Collected Steps per Second: 21,351.16014
Overall Steps per Second: 10,325.81230

Timestep Collection Time: 2.34320
Timestep Consumption Time: 2.50194
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.84514

Cumulative Model Updates: 119,662
Cumulative Timesteps: 998,814,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 998814634...
Checkpoint 998814634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,292.95595
Policy Entropy: 1.67679
Value Function Loss: 0.08220

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.34949
Value Function Update Magnitude: 0.39233

Collected Steps per Second: 21,672.46917
Overall Steps per Second: 10,500.36936

Timestep Collection Time: 2.30846
Timestep Consumption Time: 2.45614
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.76459

Cumulative Model Updates: 119,668
Cumulative Timesteps: 998,864,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,599.36905
Policy Entropy: 1.69037
Value Function Loss: 0.07752

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.34890
Value Function Update Magnitude: 0.39372

Collected Steps per Second: 21,479.26407
Overall Steps per Second: 10,418.72154

Timestep Collection Time: 2.32857
Timestep Consumption Time: 2.47202
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.80059

Cumulative Model Updates: 119,674
Cumulative Timesteps: 998,914,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 998914680...
Checkpoint 998914680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,934.44262
Policy Entropy: 1.69284
Value Function Loss: 0.08246

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.34432
Value Function Update Magnitude: 0.37856

Collected Steps per Second: 21,320.61783
Overall Steps per Second: 10,288.30654

Timestep Collection Time: 2.34515
Timestep Consumption Time: 2.51474
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.85989

Cumulative Model Updates: 119,680
Cumulative Timesteps: 998,964,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,993.57404
Policy Entropy: 1.68249
Value Function Loss: 0.08196

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.34230
Value Function Update Magnitude: 0.37574

Collected Steps per Second: 20,855.59305
Overall Steps per Second: 10,294.62206

Timestep Collection Time: 2.39811
Timestep Consumption Time: 2.46016
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.85826

Cumulative Model Updates: 119,686
Cumulative Timesteps: 999,014,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 999014694...
Checkpoint 999014694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,638.44978
Policy Entropy: 1.68491
Value Function Loss: 0.08235

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.34136
Value Function Update Magnitude: 0.39137

Collected Steps per Second: 21,336.62500
Overall Steps per Second: 10,272.67660

Timestep Collection Time: 2.34386
Timestep Consumption Time: 2.52440
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.86825

Cumulative Model Updates: 119,692
Cumulative Timesteps: 999,064,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,357.66140
Policy Entropy: 1.68006
Value Function Loss: 0.06809

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.33490
Value Function Update Magnitude: 0.39257

Collected Steps per Second: 21,414.25729
Overall Steps per Second: 10,450.42869

Timestep Collection Time: 2.33545
Timestep Consumption Time: 2.45019
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.78564

Cumulative Model Updates: 119,698
Cumulative Timesteps: 999,114,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 999114716...
Checkpoint 999114716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,680.49592
Policy Entropy: 1.68480
Value Function Loss: 0.06631

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.32845
Value Function Update Magnitude: 0.37300

Collected Steps per Second: 21,284.69564
Overall Steps per Second: 10,279.14035

Timestep Collection Time: 2.34939
Timestep Consumption Time: 2.51542
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.86480

Cumulative Model Updates: 119,704
Cumulative Timesteps: 999,164,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,029.74639
Policy Entropy: 1.67803
Value Function Loss: 0.06530

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.32710
Value Function Update Magnitude: 0.34703

Collected Steps per Second: 21,584.15365
Overall Steps per Second: 10,342.26436

Timestep Collection Time: 2.31763
Timestep Consumption Time: 2.51923
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.83685

Cumulative Model Updates: 119,710
Cumulative Timesteps: 999,214,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 999214746...
Checkpoint 999214746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,356.99684
Policy Entropy: 1.68838
Value Function Loss: 0.06574

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.32376
Value Function Update Magnitude: 0.32333

Collected Steps per Second: 21,598.46335
Overall Steps per Second: 10,336.28367

Timestep Collection Time: 2.31554
Timestep Consumption Time: 2.52295
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.83849

Cumulative Model Updates: 119,716
Cumulative Timesteps: 999,264,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,297.66362
Policy Entropy: 1.69045
Value Function Loss: 0.06849

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.32306
Value Function Update Magnitude: 0.34415

Collected Steps per Second: 21,860.18904
Overall Steps per Second: 10,402.81265

Timestep Collection Time: 2.28754
Timestep Consumption Time: 2.51943
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.80697

Cumulative Model Updates: 119,722
Cumulative Timesteps: 999,314,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 999314764...
Checkpoint 999314764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,455.14162
Policy Entropy: 1.69311
Value Function Loss: 0.07022

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.32957
Value Function Update Magnitude: 0.37487

Collected Steps per Second: 21,535.65195
Overall Steps per Second: 10,336.93089

Timestep Collection Time: 2.32303
Timestep Consumption Time: 2.51670
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.83973

Cumulative Model Updates: 119,728
Cumulative Timesteps: 999,364,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,262.17002
Policy Entropy: 1.69731
Value Function Loss: 0.07526

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.33360
Value Function Update Magnitude: 0.41946

Collected Steps per Second: 20,384.70227
Overall Steps per Second: 9,940.39360

Timestep Collection Time: 2.45410
Timestep Consumption Time: 2.57850
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 5.03260

Cumulative Model Updates: 119,734
Cumulative Timesteps: 999,414,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 999414818...
Checkpoint 999414818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,273.72369
Policy Entropy: 1.68732
Value Function Loss: 0.07402

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.33655
Value Function Update Magnitude: 0.43313

Collected Steps per Second: 21,491.05232
Overall Steps per Second: 10,508.88766

Timestep Collection Time: 2.32664
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.75807

Cumulative Model Updates: 119,740
Cumulative Timesteps: 999,464,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,656.11585
Policy Entropy: 1.67667
Value Function Loss: 0.07240

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.32516
Value Function Update Magnitude: 0.41474

Collected Steps per Second: 21,469.21040
Overall Steps per Second: 10,484.26700

Timestep Collection Time: 2.32994
Timestep Consumption Time: 2.44121
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.77115

Cumulative Model Updates: 119,746
Cumulative Timesteps: 999,514,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 999514842...
Checkpoint 999514842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,844.04927
Policy Entropy: 1.67114
Value Function Loss: 0.06834

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.32346
Value Function Update Magnitude: 0.38864

Collected Steps per Second: 21,048.63238
Overall Steps per Second: 10,384.28478

Timestep Collection Time: 2.37574
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.81555

Cumulative Model Updates: 119,752
Cumulative Timesteps: 999,564,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,955.55977
Policy Entropy: 1.65933
Value Function Loss: 0.06666

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.32446
Value Function Update Magnitude: 0.36483

Collected Steps per Second: 21,183.53585
Overall Steps per Second: 10,414.16758

Timestep Collection Time: 2.36165
Timestep Consumption Time: 2.44220
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.80384

Cumulative Model Updates: 119,758
Cumulative Timesteps: 999,614,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 999614876...
Checkpoint 999614876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,330.40429
Policy Entropy: 1.65848
Value Function Loss: 0.06938

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.32518
Value Function Update Magnitude: 0.36564

Collected Steps per Second: 20,903.67171
Overall Steps per Second: 10,337.32979

Timestep Collection Time: 2.39269
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.83839

Cumulative Model Updates: 119,764
Cumulative Timesteps: 999,664,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,460.02445
Policy Entropy: 1.66623
Value Function Loss: 0.06797

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.32014
Value Function Update Magnitude: 0.35579

Collected Steps per Second: 20,959.04034
Overall Steps per Second: 10,378.78391

Timestep Collection Time: 2.38675
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.81983

Cumulative Model Updates: 119,770
Cumulative Timesteps: 999,714,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 999714916...
Checkpoint 999714916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,862.70574
Policy Entropy: 1.67781
Value Function Loss: 0.07160

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.30213
Value Function Update Magnitude: 0.34456

Collected Steps per Second: 21,108.48676
Overall Steps per Second: 10,447.84045

Timestep Collection Time: 2.36947
Timestep Consumption Time: 2.41774
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.78721

Cumulative Model Updates: 119,776
Cumulative Timesteps: 999,764,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,794.76734
Policy Entropy: 1.69404
Value Function Loss: 0.06846

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.31282
Value Function Update Magnitude: 0.33654

Collected Steps per Second: 21,371.59587
Overall Steps per Second: 10,459.90784

Timestep Collection Time: 2.34049
Timestep Consumption Time: 2.44158
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.78207

Cumulative Model Updates: 119,782
Cumulative Timesteps: 999,814,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 999814952...
Checkpoint 999814952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,451.44486
Policy Entropy: 1.70383
Value Function Loss: 0.07214

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.31859
Value Function Update Magnitude: 0.34472

Collected Steps per Second: 21,427.70871
Overall Steps per Second: 10,416.69856

Timestep Collection Time: 2.33399
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.80114

Cumulative Model Updates: 119,788
Cumulative Timesteps: 999,864,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,511.78706
Policy Entropy: 1.69864
Value Function Loss: 0.07225

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.32691
Value Function Update Magnitude: 0.35786

Collected Steps per Second: 21,414.63949
Overall Steps per Second: 10,352.07593

Timestep Collection Time: 2.33569
Timestep Consumption Time: 2.49600
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.83169

Cumulative Model Updates: 119,794
Cumulative Timesteps: 999,914,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 999914982...
Checkpoint 999914982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,690.04053
Policy Entropy: 1.68987
Value Function Loss: 0.07201

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.32175
Value Function Update Magnitude: 0.35682

Collected Steps per Second: 21,483.48814
Overall Steps per Second: 10,547.34276

Timestep Collection Time: 2.32914
Timestep Consumption Time: 2.41500
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.74413

Cumulative Model Updates: 119,800
Cumulative Timesteps: 999,965,020

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,306.59978
Policy Entropy: 1.67698
Value Function Loss: 0.07233

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.32430
Value Function Update Magnitude: 0.31882

Collected Steps per Second: 21,578.47810
Overall Steps per Second: 10,454.34878

Timestep Collection Time: 2.31749
Timestep Consumption Time: 2.46597
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.78346

Cumulative Model Updates: 119,806
Cumulative Timesteps: 1,000,015,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1000015028...
Checkpoint 1000015028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,988.53646
Policy Entropy: 1.67295
Value Function Loss: 0.07164

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.32872
Value Function Update Magnitude: 0.28196

Collected Steps per Second: 21,391.23987
Overall Steps per Second: 10,157.24289

Timestep Collection Time: 2.33787
Timestep Consumption Time: 2.58571
PPO Batch Consumption Time: 0.30774
Total Iteration Time: 4.92358

Cumulative Model Updates: 119,812
Cumulative Timesteps: 1,000,065,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,213.58580
Policy Entropy: 1.66567
Value Function Loss: 0.07344

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.33176
Value Function Update Magnitude: 0.29092

Collected Steps per Second: 21,808.82900
Overall Steps per Second: 10,520.92217

Timestep Collection Time: 2.29329
Timestep Consumption Time: 2.46047
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.75377

Cumulative Model Updates: 119,818
Cumulative Timesteps: 1,000,115,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1000115052...
Checkpoint 1000115052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,818.20159
Policy Entropy: 1.68213
Value Function Loss: 0.07287

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.33315
Value Function Update Magnitude: 0.33884

Collected Steps per Second: 21,508.51790
Overall Steps per Second: 10,438.46891

Timestep Collection Time: 2.32540
Timestep Consumption Time: 2.46610
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.79151

Cumulative Model Updates: 119,824
Cumulative Timesteps: 1,000,165,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,495.52918
Policy Entropy: 1.67067
Value Function Loss: 0.07407

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.33487
Value Function Update Magnitude: 0.37784

Collected Steps per Second: 21,915.66781
Overall Steps per Second: 10,449.36403

Timestep Collection Time: 2.28147
Timestep Consumption Time: 2.50351
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.78498

Cumulative Model Updates: 119,830
Cumulative Timesteps: 1,000,215,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1000215068...
Checkpoint 1000215068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,633.01915
Policy Entropy: 1.66925
Value Function Loss: 0.06991

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.33218
Value Function Update Magnitude: 0.38020

Collected Steps per Second: 21,654.00760
Overall Steps per Second: 10,424.65019

Timestep Collection Time: 2.31024
Timestep Consumption Time: 2.48858
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.79882

Cumulative Model Updates: 119,836
Cumulative Timesteps: 1,000,265,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,506.93954
Policy Entropy: 1.65648
Value Function Loss: 0.07623

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.33134
Value Function Update Magnitude: 0.35724

Collected Steps per Second: 21,806.88740
Overall Steps per Second: 10,455.23479

Timestep Collection Time: 2.29359
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.78382

Cumulative Model Updates: 119,842
Cumulative Timesteps: 1,000,315,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1000315110...
Checkpoint 1000315110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,725.03878
Policy Entropy: 1.65859
Value Function Loss: 0.07718

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.33640
Value Function Update Magnitude: 0.37541

Collected Steps per Second: 21,206.61241
Overall Steps per Second: 10,253.90624

Timestep Collection Time: 2.35898
Timestep Consumption Time: 2.51974
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.87873

Cumulative Model Updates: 119,848
Cumulative Timesteps: 1,000,365,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,369.94882
Policy Entropy: 1.66848
Value Function Loss: 0.07482

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.33786
Value Function Update Magnitude: 0.39531

Collected Steps per Second: 21,746.03133
Overall Steps per Second: 10,398.28911

Timestep Collection Time: 2.29964
Timestep Consumption Time: 2.50961
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.80925

Cumulative Model Updates: 119,854
Cumulative Timesteps: 1,000,415,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1000415144...
Checkpoint 1000415144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,194.96897
Policy Entropy: 1.67109
Value Function Loss: 0.07264

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.32342
Value Function Update Magnitude: 0.38955

Collected Steps per Second: 21,555.22639
Overall Steps per Second: 10,179.44477

Timestep Collection Time: 2.32055
Timestep Consumption Time: 2.59327
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.91382

Cumulative Model Updates: 119,860
Cumulative Timesteps: 1,000,465,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,734.02355
Policy Entropy: 1.67558
Value Function Loss: 0.07560

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.29308
Value Function Update Magnitude: 0.38790

Collected Steps per Second: 21,780.93076
Overall Steps per Second: 10,572.86245

Timestep Collection Time: 2.29632
Timestep Consumption Time: 2.43428
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.73060

Cumulative Model Updates: 119,866
Cumulative Timesteps: 1,000,515,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1000515180...
Checkpoint 1000515180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,697.50683
Policy Entropy: 1.66396
Value Function Loss: 0.07601

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.29581
Value Function Update Magnitude: 0.38555

Collected Steps per Second: 21,519.55558
Overall Steps per Second: 10,497.42229

Timestep Collection Time: 2.32477
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.76574

Cumulative Model Updates: 119,872
Cumulative Timesteps: 1,000,565,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,416.60780
Policy Entropy: 1.65968
Value Function Loss: 0.07130

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.30141
Value Function Update Magnitude: 0.37468

Collected Steps per Second: 21,848.23490
Overall Steps per Second: 10,578.69456

Timestep Collection Time: 2.28989
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.72932

Cumulative Model Updates: 119,878
Cumulative Timesteps: 1,000,615,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1000615238...
Checkpoint 1000615238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,956.79011
Policy Entropy: 1.65520
Value Function Loss: 0.06729

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.30741
Value Function Update Magnitude: 0.36686

Collected Steps per Second: 21,558.70916
Overall Steps per Second: 10,439.16665

Timestep Collection Time: 2.31962
Timestep Consumption Time: 2.47080
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.79042

Cumulative Model Updates: 119,884
Cumulative Timesteps: 1,000,665,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,182.69150
Policy Entropy: 1.66036
Value Function Loss: 0.06771

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.30605
Value Function Update Magnitude: 0.35041

Collected Steps per Second: 21,619.58557
Overall Steps per Second: 10,371.34277

Timestep Collection Time: 2.31290
Timestep Consumption Time: 2.50846
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.82136

Cumulative Model Updates: 119,890
Cumulative Timesteps: 1,000,715,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1000715250...
Checkpoint 1000715250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,389.05800
Policy Entropy: 1.65956
Value Function Loss: 0.06930

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.32333
Value Function Update Magnitude: 0.34012

Collected Steps per Second: 20,501.93372
Overall Steps per Second: 10,119.97204

Timestep Collection Time: 2.43909
Timestep Consumption Time: 2.50223
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.94132

Cumulative Model Updates: 119,896
Cumulative Timesteps: 1,000,765,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,276.90428
Policy Entropy: 1.66627
Value Function Loss: 0.06545

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.32585
Value Function Update Magnitude: 0.32509

Collected Steps per Second: 21,847.19825
Overall Steps per Second: 10,403.45883

Timestep Collection Time: 2.29009
Timestep Consumption Time: 2.51908
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.80917

Cumulative Model Updates: 119,902
Cumulative Timesteps: 1,000,815,288

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1000815288...
Checkpoint 1000815288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,688.91987
Policy Entropy: 1.66301
Value Function Loss: 0.06878

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.30815
Value Function Update Magnitude: 0.32185

Collected Steps per Second: 21,485.41369
Overall Steps per Second: 10,497.95520

Timestep Collection Time: 2.32865
Timestep Consumption Time: 2.43723
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.76588

Cumulative Model Updates: 119,908
Cumulative Timesteps: 1,000,865,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,006.01708
Policy Entropy: 1.67762
Value Function Loss: 0.06558

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.30643
Value Function Update Magnitude: 0.32801

Collected Steps per Second: 21,571.43287
Overall Steps per Second: 10,382.29864

Timestep Collection Time: 2.31890
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.81801

Cumulative Model Updates: 119,914
Cumulative Timesteps: 1,000,915,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1000915342...
Checkpoint 1000915342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,379.06514
Policy Entropy: 1.66912
Value Function Loss: 0.06738

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08087
Policy Update Magnitude: 0.31871
Value Function Update Magnitude: 0.33263

Collected Steps per Second: 21,251.18869
Overall Steps per Second: 10,164.49796

Timestep Collection Time: 2.35384
Timestep Consumption Time: 2.56740
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.92125

Cumulative Model Updates: 119,920
Cumulative Timesteps: 1,000,965,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,607.69833
Policy Entropy: 1.67326
Value Function Loss: 0.06367

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.31819
Value Function Update Magnitude: 0.32885

Collected Steps per Second: 18,816.14322
Overall Steps per Second: 9,593.73310

Timestep Collection Time: 2.65857
Timestep Consumption Time: 2.55567
PPO Batch Consumption Time: 0.30881
Total Iteration Time: 5.21424

Cumulative Model Updates: 119,926
Cumulative Timesteps: 1,001,015,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1001015388...
Checkpoint 1001015388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,063.69268
Policy Entropy: 1.68184
Value Function Loss: 0.06328

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.32291
Value Function Update Magnitude: 0.33524

Collected Steps per Second: 21,234.26275
Overall Steps per Second: 10,463.99762

Timestep Collection Time: 2.35544
Timestep Consumption Time: 2.42438
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.77982

Cumulative Model Updates: 119,932
Cumulative Timesteps: 1,001,065,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,834.55862
Policy Entropy: 1.68449
Value Function Loss: 0.06954

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.32741
Value Function Update Magnitude: 0.33483

Collected Steps per Second: 21,332.89883
Overall Steps per Second: 10,456.40163

Timestep Collection Time: 2.34445
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.78310

Cumulative Model Updates: 119,938
Cumulative Timesteps: 1,001,115,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1001115418...
Checkpoint 1001115418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,171.75739
Policy Entropy: 1.68283
Value Function Loss: 0.07391

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.31760
Value Function Update Magnitude: 0.35781

Collected Steps per Second: 20,674.09281
Overall Steps per Second: 10,289.04016

Timestep Collection Time: 2.41945
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.86148

Cumulative Model Updates: 119,944
Cumulative Timesteps: 1,001,165,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,953.27798
Policy Entropy: 1.66621
Value Function Loss: 0.07389

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.31583
Value Function Update Magnitude: 0.35975

Collected Steps per Second: 21,111.29403
Overall Steps per Second: 10,369.95745

Timestep Collection Time: 2.36963
Timestep Consumption Time: 2.45450
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.82413

Cumulative Model Updates: 119,950
Cumulative Timesteps: 1,001,215,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1001215464...
Checkpoint 1001215464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,013.21025
Policy Entropy: 1.67430
Value Function Loss: 0.07349

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07705
Policy Update Magnitude: 0.32346
Value Function Update Magnitude: 0.32668

Collected Steps per Second: 21,538.57623
Overall Steps per Second: 10,286.04737

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.54167
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.86504

Cumulative Model Updates: 119,956
Cumulative Timesteps: 1,001,265,506

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,668.08672
Policy Entropy: 1.67300
Value Function Loss: 0.07102

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.32503
Value Function Update Magnitude: 0.28237

Collected Steps per Second: 21,775.50391
Overall Steps per Second: 10,264.00440

Timestep Collection Time: 2.29653
Timestep Consumption Time: 2.57565
PPO Batch Consumption Time: 0.30839
Total Iteration Time: 4.87217

Cumulative Model Updates: 119,962
Cumulative Timesteps: 1,001,315,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1001315514...
Checkpoint 1001315514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,578.69883
Policy Entropy: 1.68882
Value Function Loss: 0.07264

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.32511
Value Function Update Magnitude: 0.28520

Collected Steps per Second: 21,414.54317
Overall Steps per Second: 10,361.11425

Timestep Collection Time: 2.33580
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.82767

Cumulative Model Updates: 119,968
Cumulative Timesteps: 1,001,365,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,950.00058
Policy Entropy: 1.68522
Value Function Loss: 0.06819

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.32133
Value Function Update Magnitude: 0.30345

Collected Steps per Second: 21,707.67161
Overall Steps per Second: 10,407.83443

Timestep Collection Time: 2.30370
Timestep Consumption Time: 2.50114
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.80484

Cumulative Model Updates: 119,974
Cumulative Timesteps: 1,001,415,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1001415542...
Checkpoint 1001415542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,314.93400
Policy Entropy: 1.67294
Value Function Loss: 0.06986

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.32039
Value Function Update Magnitude: 0.32058

Collected Steps per Second: 21,592.53751
Overall Steps per Second: 10,534.62783

Timestep Collection Time: 2.31589
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.74682

Cumulative Model Updates: 119,980
Cumulative Timesteps: 1,001,465,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,945.30732
Policy Entropy: 1.65770
Value Function Loss: 0.06575

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.29988
Value Function Update Magnitude: 0.30613

Collected Steps per Second: 21,530.97234
Overall Steps per Second: 10,484.14427

Timestep Collection Time: 2.32261
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.76987

Cumulative Model Updates: 119,986
Cumulative Timesteps: 1,001,515,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1001515556...
Checkpoint 1001515556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,725.93737
Policy Entropy: 1.65443
Value Function Loss: 0.07480

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.31366
Value Function Update Magnitude: 0.28099

Collected Steps per Second: 21,606.95156
Overall Steps per Second: 10,404.61042

Timestep Collection Time: 2.31426
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.80595

Cumulative Model Updates: 119,992
Cumulative Timesteps: 1,001,565,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,246.30138
Policy Entropy: 1.67498
Value Function Loss: 0.07430

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.32441
Value Function Update Magnitude: 0.31084

Collected Steps per Second: 21,880.94947
Overall Steps per Second: 10,391.95882

Timestep Collection Time: 2.28518
Timestep Consumption Time: 2.52642
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.81160

Cumulative Model Updates: 119,998
Cumulative Timesteps: 1,001,615,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1001615562...
Checkpoint 1001615562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,225.83824
Policy Entropy: 1.67649
Value Function Loss: 0.07626

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.32489
Value Function Update Magnitude: 0.34646

Collected Steps per Second: 21,409.34223
Overall Steps per Second: 10,461.12859

Timestep Collection Time: 2.33674
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.78228

Cumulative Model Updates: 120,004
Cumulative Timesteps: 1,001,665,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,782.72846
Policy Entropy: 1.66365
Value Function Loss: 0.07180

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.32621
Value Function Update Magnitude: 0.35467

Collected Steps per Second: 21,711.72430
Overall Steps per Second: 10,509.79057

Timestep Collection Time: 2.30502
Timestep Consumption Time: 2.45682
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.76185

Cumulative Model Updates: 120,010
Cumulative Timesteps: 1,001,715,636

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1001715636...
Checkpoint 1001715636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,583.97258
Policy Entropy: 1.64050
Value Function Loss: 0.07242

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.32858
Value Function Update Magnitude: 0.36540

Collected Steps per Second: 21,319.92103
Overall Steps per Second: 10,281.85126

Timestep Collection Time: 2.34579
Timestep Consumption Time: 2.51832
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.86410

Cumulative Model Updates: 120,016
Cumulative Timesteps: 1,001,765,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,438.18010
Policy Entropy: 1.64127
Value Function Loss: 0.06607

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.32426
Value Function Update Magnitude: 0.37229

Collected Steps per Second: 21,542.99947
Overall Steps per Second: 10,467.95645

Timestep Collection Time: 2.32224
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.77916

Cumulative Model Updates: 120,022
Cumulative Timesteps: 1,001,815,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1001815676...
Checkpoint 1001815676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,639.56628
Policy Entropy: 1.65099
Value Function Loss: 0.06809

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.32338
Value Function Update Magnitude: 0.36499

Collected Steps per Second: 21,567.88659
Overall Steps per Second: 10,511.87868

Timestep Collection Time: 2.31873
Timestep Consumption Time: 2.43875
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.75747

Cumulative Model Updates: 120,028
Cumulative Timesteps: 1,001,865,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,111.48019
Policy Entropy: 1.66409
Value Function Loss: 0.07082

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.32915
Value Function Update Magnitude: 0.37679

Collected Steps per Second: 21,616.18446
Overall Steps per Second: 10,530.29554

Timestep Collection Time: 2.31401
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.75010

Cumulative Model Updates: 120,034
Cumulative Timesteps: 1,001,915,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1001915706...
Checkpoint 1001915706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,184.03209
Policy Entropy: 1.66053
Value Function Loss: 0.07156

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08663
Policy Update Magnitude: 0.32831
Value Function Update Magnitude: 0.38306

Collected Steps per Second: 21,566.56381
Overall Steps per Second: 10,372.16067

Timestep Collection Time: 2.31933
Timestep Consumption Time: 2.50319
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.82252

Cumulative Model Updates: 120,040
Cumulative Timesteps: 1,001,965,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,186.42473
Policy Entropy: 1.65678
Value Function Loss: 0.07256

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.32594
Value Function Update Magnitude: 0.35771

Collected Steps per Second: 21,741.56732
Overall Steps per Second: 10,328.66753

Timestep Collection Time: 2.30158
Timestep Consumption Time: 2.54319
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.84477

Cumulative Model Updates: 120,046
Cumulative Timesteps: 1,002,015,766

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1002015766...
Checkpoint 1002015766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,701.84177
Policy Entropy: 1.65555
Value Function Loss: 0.07275

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.32712
Value Function Update Magnitude: 0.35890

Collected Steps per Second: 21,398.42073
Overall Steps per Second: 10,495.34053

Timestep Collection Time: 2.33671
Timestep Consumption Time: 2.42749
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.76421

Cumulative Model Updates: 120,052
Cumulative Timesteps: 1,002,065,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,380.19249
Policy Entropy: 1.66277
Value Function Loss: 0.06902

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.32311
Value Function Update Magnitude: 0.36389

Collected Steps per Second: 21,223.37069
Overall Steps per Second: 10,285.19822

Timestep Collection Time: 2.35655
Timestep Consumption Time: 2.50616
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.86272

Cumulative Model Updates: 120,058
Cumulative Timesteps: 1,002,115,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1002115782...
Checkpoint 1002115782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,602.79640
Policy Entropy: 1.67714
Value Function Loss: 0.06410

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.31601
Value Function Update Magnitude: 0.34072

Collected Steps per Second: 21,770.82932
Overall Steps per Second: 10,495.66935

Timestep Collection Time: 2.29785
Timestep Consumption Time: 2.46850
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.76635

Cumulative Model Updates: 120,064
Cumulative Timesteps: 1,002,165,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,729.71861
Policy Entropy: 1.68725
Value Function Loss: 0.06357

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07944
Policy Update Magnitude: 0.31745
Value Function Update Magnitude: 0.28038

Collected Steps per Second: 21,608.20661
Overall Steps per Second: 10,382.49841

Timestep Collection Time: 2.31495
Timestep Consumption Time: 2.50296
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.81792

Cumulative Model Updates: 120,070
Cumulative Timesteps: 1,002,215,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1002215830...
Checkpoint 1002215830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,503.15934
Policy Entropy: 1.68500
Value Function Loss: 0.07069

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.31978
Value Function Update Magnitude: 0.30345

Collected Steps per Second: 21,770.13810
Overall Steps per Second: 10,599.26615

Timestep Collection Time: 2.29691
Timestep Consumption Time: 2.42078
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.71769

Cumulative Model Updates: 120,076
Cumulative Timesteps: 1,002,265,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,913.54528
Policy Entropy: 1.67186
Value Function Loss: 0.06793

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.30903
Value Function Update Magnitude: 0.30977

Collected Steps per Second: 20,908.64817
Overall Steps per Second: 10,514.91767

Timestep Collection Time: 2.39174
Timestep Consumption Time: 2.36417
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.75591

Cumulative Model Updates: 120,082
Cumulative Timesteps: 1,002,315,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1002315842...
Checkpoint 1002315842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,606.29893
Policy Entropy: 1.66360
Value Function Loss: 0.06599

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.30275
Value Function Update Magnitude: 0.29078

Collected Steps per Second: 20,895.19365
Overall Steps per Second: 10,422.01101

Timestep Collection Time: 2.39356
Timestep Consumption Time: 2.40532
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.79888

Cumulative Model Updates: 120,088
Cumulative Timesteps: 1,002,365,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,806.25766
Policy Entropy: 1.64841
Value Function Loss: 0.06753

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.30561

Collected Steps per Second: 21,256.48048
Overall Steps per Second: 10,590.65107

Timestep Collection Time: 2.35251
Timestep Consumption Time: 2.36921
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.72171

Cumulative Model Updates: 120,094
Cumulative Timesteps: 1,002,415,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1002415862...
Checkpoint 1002415862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,112.89266
Policy Entropy: 1.63912
Value Function Loss: 0.06784

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.31576
Value Function Update Magnitude: 0.34170

Collected Steps per Second: 20,902.67539
Overall Steps per Second: 10,355.44026

Timestep Collection Time: 2.39357
Timestep Consumption Time: 2.43790
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.83147

Cumulative Model Updates: 120,100
Cumulative Timesteps: 1,002,465,894

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,232.72052
Policy Entropy: 1.64056
Value Function Loss: 0.07311

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.32739
Value Function Update Magnitude: 0.33869

Collected Steps per Second: 21,245.13656
Overall Steps per Second: 10,404.28260

Timestep Collection Time: 2.35489
Timestep Consumption Time: 2.45370
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.80860

Cumulative Model Updates: 120,106
Cumulative Timesteps: 1,002,515,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1002515924...
Checkpoint 1002515924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,490.16706
Policy Entropy: 1.66152
Value Function Loss: 0.07513

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.33618
Value Function Update Magnitude: 0.36155

Collected Steps per Second: 21,176.19340
Overall Steps per Second: 10,346.16238

Timestep Collection Time: 2.36152
Timestep Consumption Time: 2.47196
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.83348

Cumulative Model Updates: 120,112
Cumulative Timesteps: 1,002,565,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,240.76001
Policy Entropy: 1.67122
Value Function Loss: 0.07209

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.33056
Value Function Update Magnitude: 0.36313

Collected Steps per Second: 21,760.08753
Overall Steps per Second: 10,274.05511

Timestep Collection Time: 2.29880
Timestep Consumption Time: 2.56997
PPO Batch Consumption Time: 0.30550
Total Iteration Time: 4.86877

Cumulative Model Updates: 120,118
Cumulative Timesteps: 1,002,615,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1002615954...
Checkpoint 1002615954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,323.54092
Policy Entropy: 1.66438
Value Function Loss: 0.06350

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.29414
Value Function Update Magnitude: 0.34839

Collected Steps per Second: 21,364.03091
Overall Steps per Second: 10,356.09010

Timestep Collection Time: 2.34216
Timestep Consumption Time: 2.48959
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.83175

Cumulative Model Updates: 120,124
Cumulative Timesteps: 1,002,665,992

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,995.03797
Policy Entropy: 1.65298
Value Function Loss: 0.06006

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.29684
Value Function Update Magnitude: 0.32669

Collected Steps per Second: 21,838.98312
Overall Steps per Second: 10,461.66280

Timestep Collection Time: 2.29077
Timestep Consumption Time: 2.49127
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.78203

Cumulative Model Updates: 120,130
Cumulative Timesteps: 1,002,716,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1002716020...
Checkpoint 1002716020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,683.89390
Policy Entropy: 1.67630
Value Function Loss: 0.06649

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08090
Policy Update Magnitude: 0.31740
Value Function Update Magnitude: 0.32816

Collected Steps per Second: 21,740.64960
Overall Steps per Second: 10,556.29118

Timestep Collection Time: 2.30104
Timestep Consumption Time: 2.43794
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.73898

Cumulative Model Updates: 120,136
Cumulative Timesteps: 1,002,766,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,095.52298
Policy Entropy: 1.68042
Value Function Loss: 0.07718

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.32584
Value Function Update Magnitude: 0.35750

Collected Steps per Second: 21,711.25994
Overall Steps per Second: 10,381.19497

Timestep Collection Time: 2.30507
Timestep Consumption Time: 2.51576
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.82083

Cumulative Model Updates: 120,142
Cumulative Timesteps: 1,002,816,092

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1002816092...
Checkpoint 1002816092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,097.30396
Policy Entropy: 1.68223
Value Function Loss: 0.07928

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.31958
Value Function Update Magnitude: 0.39076

Collected Steps per Second: 21,550.81473
Overall Steps per Second: 10,356.93563

Timestep Collection Time: 2.32010
Timestep Consumption Time: 2.50758
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.82768

Cumulative Model Updates: 120,148
Cumulative Timesteps: 1,002,866,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,597.26422
Policy Entropy: 1.67445
Value Function Loss: 0.07550

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.32561
Value Function Update Magnitude: 0.37649

Collected Steps per Second: 21,563.52133
Overall Steps per Second: 10,338.99035

Timestep Collection Time: 2.31882
Timestep Consumption Time: 2.51743
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.83626

Cumulative Model Updates: 120,154
Cumulative Timesteps: 1,002,916,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1002916094...
Checkpoint 1002916094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,886.68980
Policy Entropy: 1.67908
Value Function Loss: 0.06985

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08584
Policy Update Magnitude: 0.32958
Value Function Update Magnitude: 0.35819

Collected Steps per Second: 21,640.51450
Overall Steps per Second: 10,555.32330

Timestep Collection Time: 2.31187
Timestep Consumption Time: 2.42792
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.73979

Cumulative Model Updates: 120,160
Cumulative Timesteps: 1,002,966,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,217.26069
Policy Entropy: 1.68488
Value Function Loss: 0.06983

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.32845
Value Function Update Magnitude: 0.32713

Collected Steps per Second: 21,701.38493
Overall Steps per Second: 10,484.57318

Timestep Collection Time: 2.30474
Timestep Consumption Time: 2.46570
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.77044

Cumulative Model Updates: 120,166
Cumulative Timesteps: 1,003,016,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1003016140...
Checkpoint 1003016140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,563.51738
Policy Entropy: 1.68792
Value Function Loss: 0.07147

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.32812
Value Function Update Magnitude: 0.29756

Collected Steps per Second: 21,450.94979
Overall Steps per Second: 10,323.12240

Timestep Collection Time: 2.33137
Timestep Consumption Time: 2.51310
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.84446

Cumulative Model Updates: 120,172
Cumulative Timesteps: 1,003,066,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,138.04776
Policy Entropy: 1.69219
Value Function Loss: 0.07036

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08427
Policy Update Magnitude: 0.32512
Value Function Update Magnitude: 0.34617

Collected Steps per Second: 22,153.42975
Overall Steps per Second: 10,463.59240

Timestep Collection Time: 2.25816
Timestep Consumption Time: 2.52280
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.78096

Cumulative Model Updates: 120,178
Cumulative Timesteps: 1,003,116,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1003116176...
Checkpoint 1003116176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,042.67939
Policy Entropy: 1.69182
Value Function Loss: 0.07185

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.32738
Value Function Update Magnitude: 0.36268

Collected Steps per Second: 21,828.34805
Overall Steps per Second: 10,546.77073

Timestep Collection Time: 2.29115
Timestep Consumption Time: 2.45078
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.74193

Cumulative Model Updates: 120,184
Cumulative Timesteps: 1,003,166,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,912.37652
Policy Entropy: 1.68488
Value Function Loss: 0.06594

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.32420
Value Function Update Magnitude: 0.37323

Collected Steps per Second: 22,053.93171
Overall Steps per Second: 10,734.34664

Timestep Collection Time: 2.26744
Timestep Consumption Time: 2.39106
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.65850

Cumulative Model Updates: 120,190
Cumulative Timesteps: 1,003,216,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1003216194...
Checkpoint 1003216194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,423.53889
Policy Entropy: 1.68609
Value Function Loss: 0.06431

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08004
Policy Update Magnitude: 0.31940
Value Function Update Magnitude: 0.35856

Collected Steps per Second: 21,291.99201
Overall Steps per Second: 10,190.03567

Timestep Collection Time: 2.34915
Timestep Consumption Time: 2.55937
PPO Batch Consumption Time: 0.30386
Total Iteration Time: 4.90852

Cumulative Model Updates: 120,196
Cumulative Timesteps: 1,003,266,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,782.99876
Policy Entropy: 1.67652
Value Function Loss: 0.06499

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.31655
Value Function Update Magnitude: 0.36271

Collected Steps per Second: 21,691.34750
Overall Steps per Second: 10,384.73252

Timestep Collection Time: 2.30608
Timestep Consumption Time: 2.51080
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.81688

Cumulative Model Updates: 120,202
Cumulative Timesteps: 1,003,316,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1003316234...
Checkpoint 1003316234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,338.20126
Policy Entropy: 1.68590
Value Function Loss: 0.06852

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.32187
Value Function Update Magnitude: 0.36255

Collected Steps per Second: 20,874.98953
Overall Steps per Second: 10,084.55643

Timestep Collection Time: 2.39655
Timestep Consumption Time: 2.56430
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.96085

Cumulative Model Updates: 120,208
Cumulative Timesteps: 1,003,366,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,875.51565
Policy Entropy: 1.69886
Value Function Loss: 0.06824

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.32278
Value Function Update Magnitude: 0.37568

Collected Steps per Second: 21,778.58281
Overall Steps per Second: 10,329.38700

Timestep Collection Time: 2.29583
Timestep Consumption Time: 2.54472
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.84056

Cumulative Model Updates: 120,214
Cumulative Timesteps: 1,003,416,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1003416262...
Checkpoint 1003416262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,290.56783
Policy Entropy: 1.70967
Value Function Loss: 0.06402

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.32128
Value Function Update Magnitude: 0.37811

Collected Steps per Second: 21,225.28057
Overall Steps per Second: 10,248.24294

Timestep Collection Time: 2.35615
Timestep Consumption Time: 2.52371
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.87986

Cumulative Model Updates: 120,220
Cumulative Timesteps: 1,003,466,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,043.56470
Policy Entropy: 1.71593
Value Function Loss: 0.06163

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.31182
Value Function Update Magnitude: 0.37137

Collected Steps per Second: 20,873.89241
Overall Steps per Second: 10,177.74705

Timestep Collection Time: 2.39553
Timestep Consumption Time: 2.51754
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.91307

Cumulative Model Updates: 120,226
Cumulative Timesteps: 1,003,516,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1003516276...
Checkpoint 1003516276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,236.25880
Policy Entropy: 1.70778
Value Function Loss: 0.06633

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.31276
Value Function Update Magnitude: 0.35301

Collected Steps per Second: 21,436.34757
Overall Steps per Second: 10,462.36018

Timestep Collection Time: 2.33342
Timestep Consumption Time: 2.44753
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.78095

Cumulative Model Updates: 120,232
Cumulative Timesteps: 1,003,566,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,072.68510
Policy Entropy: 1.69757
Value Function Loss: 0.06875

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.32364
Value Function Update Magnitude: 0.36324

Collected Steps per Second: 21,737.04676
Overall Steps per Second: 10,464.93825

Timestep Collection Time: 2.30050
Timestep Consumption Time: 2.47794
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.77843

Cumulative Model Updates: 120,238
Cumulative Timesteps: 1,003,616,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1003616302...
Checkpoint 1003616302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,283.63632
Policy Entropy: 1.68398
Value Function Loss: 0.07067

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.32657
Value Function Update Magnitude: 0.39600

Collected Steps per Second: 21,173.98640
Overall Steps per Second: 10,224.36167

Timestep Collection Time: 2.36186
Timestep Consumption Time: 2.52940
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.89126

Cumulative Model Updates: 120,244
Cumulative Timesteps: 1,003,666,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,395.43965
Policy Entropy: 1.68912
Value Function Loss: 0.06920

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07944
Policy Update Magnitude: 0.32534
Value Function Update Magnitude: 0.39574

Collected Steps per Second: 21,444.85849
Overall Steps per Second: 10,474.03752

Timestep Collection Time: 2.33231
Timestep Consumption Time: 2.44293
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.77524

Cumulative Model Updates: 120,250
Cumulative Timesteps: 1,003,716,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1003716328...
Checkpoint 1003716328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,450.56881
Policy Entropy: 1.69690
Value Function Loss: 0.07053

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07966
Policy Update Magnitude: 0.32824
Value Function Update Magnitude: 0.38417

Collected Steps per Second: 21,453.63680
Overall Steps per Second: 10,311.93745

Timestep Collection Time: 2.33145
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.85049

Cumulative Model Updates: 120,256
Cumulative Timesteps: 1,003,766,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,865.60445
Policy Entropy: 1.69757
Value Function Loss: 0.07602

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.32900
Value Function Update Magnitude: 0.36229

Collected Steps per Second: 21,177.70752
Overall Steps per Second: 10,358.69890

Timestep Collection Time: 2.36145
Timestep Consumption Time: 2.46638
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.82783

Cumulative Model Updates: 120,262
Cumulative Timesteps: 1,003,816,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1003816356...
Checkpoint 1003816356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,953.27660
Policy Entropy: 1.68879
Value Function Loss: 0.07785

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.33077
Value Function Update Magnitude: 0.38006

Collected Steps per Second: 20,947.87150
Overall Steps per Second: 10,165.65816

Timestep Collection Time: 2.38783
Timestep Consumption Time: 2.53266
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.92049

Cumulative Model Updates: 120,268
Cumulative Timesteps: 1,003,866,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,082.77638
Policy Entropy: 1.69533
Value Function Loss: 0.07805

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.41071

Collected Steps per Second: 21,752.50300
Overall Steps per Second: 10,359.70179

Timestep Collection Time: 2.29932
Timestep Consumption Time: 2.52862
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.82794

Cumulative Model Updates: 120,274
Cumulative Timesteps: 1,003,916,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1003916392...
Checkpoint 1003916392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,033.11703
Policy Entropy: 1.70526
Value Function Loss: 0.07839

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.31863
Value Function Update Magnitude: 0.40492

Collected Steps per Second: 20,596.71256
Overall Steps per Second: 10,214.98269

Timestep Collection Time: 2.42864
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.89692

Cumulative Model Updates: 120,280
Cumulative Timesteps: 1,003,966,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,129.93211
Policy Entropy: 1.72261
Value Function Loss: 0.07808

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.31687
Value Function Update Magnitude: 0.40158

Collected Steps per Second: 21,652.20828
Overall Steps per Second: 10,480.65835

Timestep Collection Time: 2.31099
Timestep Consumption Time: 2.46333
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.77432

Cumulative Model Updates: 120,286
Cumulative Timesteps: 1,004,016,452

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1004016452...
Checkpoint 1004016452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,436.89517
Policy Entropy: 1.72342
Value Function Loss: 0.07551

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.29212
Value Function Update Magnitude: 0.40320

Collected Steps per Second: 20,986.91637
Overall Steps per Second: 10,163.23301

Timestep Collection Time: 2.38282
Timestep Consumption Time: 2.53766
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.92048

Cumulative Model Updates: 120,292
Cumulative Timesteps: 1,004,066,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,309.97991
Policy Entropy: 1.70799
Value Function Loss: 0.06495

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.30594
Value Function Update Magnitude: 0.38841

Collected Steps per Second: 18,575.73569
Overall Steps per Second: 9,174.18467

Timestep Collection Time: 2.69179
Timestep Consumption Time: 2.75850
PPO Batch Consumption Time: 0.31984
Total Iteration Time: 5.45029

Cumulative Model Updates: 120,298
Cumulative Timesteps: 1,004,116,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1004116462...
Checkpoint 1004116462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,034.27895
Policy Entropy: 1.68907
Value Function Loss: 0.06538

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.30396
Value Function Update Magnitude: 0.36106

Collected Steps per Second: 19,677.73538
Overall Steps per Second: 9,596.95845

Timestep Collection Time: 2.54176
Timestep Consumption Time: 2.66990
PPO Batch Consumption Time: 0.30655
Total Iteration Time: 5.21165

Cumulative Model Updates: 120,304
Cumulative Timesteps: 1,004,166,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,278.59711
Policy Entropy: 1.68407
Value Function Loss: 0.06598

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.28896
Value Function Update Magnitude: 0.35230

Collected Steps per Second: 19,510.04630
Overall Steps per Second: 9,662.99783

Timestep Collection Time: 2.56340
Timestep Consumption Time: 2.61222
PPO Batch Consumption Time: 0.31385
Total Iteration Time: 5.17562

Cumulative Model Updates: 120,310
Cumulative Timesteps: 1,004,216,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1004216490...
Checkpoint 1004216490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,718.55739
Policy Entropy: 1.70046
Value Function Loss: 0.07150

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.30510
Value Function Update Magnitude: 0.35341

Collected Steps per Second: 19,337.64188
Overall Steps per Second: 10,074.15353

Timestep Collection Time: 2.58656
Timestep Consumption Time: 2.37842
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.96498

Cumulative Model Updates: 120,316
Cumulative Timesteps: 1,004,266,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,703.11230
Policy Entropy: 1.71085
Value Function Loss: 0.07010

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.30168
Value Function Update Magnitude: 0.36176

Collected Steps per Second: 19,485.40957
Overall Steps per Second: 9,851.34296

Timestep Collection Time: 2.56695
Timestep Consumption Time: 2.51033
PPO Batch Consumption Time: 0.30523
Total Iteration Time: 5.07728

Cumulative Model Updates: 120,322
Cumulative Timesteps: 1,004,316,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1004316526...
Checkpoint 1004316526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,293.58387
Policy Entropy: 1.69700
Value Function Loss: 0.06732

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.31888
Value Function Update Magnitude: 0.36211

Collected Steps per Second: 17,389.72031
Overall Steps per Second: 9,456.55152

Timestep Collection Time: 2.87653
Timestep Consumption Time: 2.41314
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 5.28967

Cumulative Model Updates: 120,328
Cumulative Timesteps: 1,004,366,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,968.89081
Policy Entropy: 1.69306
Value Function Loss: 0.06676

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.32963
Value Function Update Magnitude: 0.35071

Collected Steps per Second: 19,373.32714
Overall Steps per Second: 9,638.98190

Timestep Collection Time: 2.58118
Timestep Consumption Time: 2.60671
PPO Batch Consumption Time: 0.30271
Total Iteration Time: 5.18789

Cumulative Model Updates: 120,334
Cumulative Timesteps: 1,004,416,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1004416554...
Checkpoint 1004416554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,516.42283
Policy Entropy: 1.68475
Value Function Loss: 0.06887

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.33180
Value Function Update Magnitude: 0.34599

Collected Steps per Second: 19,024.58825
Overall Steps per Second: 9,782.21183

Timestep Collection Time: 2.62944
Timestep Consumption Time: 2.48433
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 5.11377

Cumulative Model Updates: 120,340
Cumulative Timesteps: 1,004,466,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,932.09658
Policy Entropy: 1.69459
Value Function Loss: 0.07520

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.33340
Value Function Update Magnitude: 0.33194

Collected Steps per Second: 18,461.13773
Overall Steps per Second: 9,461.93369

Timestep Collection Time: 2.71045
Timestep Consumption Time: 2.57790
PPO Batch Consumption Time: 0.30302
Total Iteration Time: 5.28835

Cumulative Model Updates: 120,346
Cumulative Timesteps: 1,004,516,616

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1004516616...
Checkpoint 1004516616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,811.88464
Policy Entropy: 1.70047
Value Function Loss: 0.07926

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.33269
Value Function Update Magnitude: 0.36392

Collected Steps per Second: 13,245.77548
Overall Steps per Second: 7,232.68506

Timestep Collection Time: 3.77705
Timestep Consumption Time: 3.14016
PPO Batch Consumption Time: 0.41525
Total Iteration Time: 6.91721

Cumulative Model Updates: 120,352
Cumulative Timesteps: 1,004,566,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,742.09321
Policy Entropy: 1.68933
Value Function Loss: 0.07097

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.32844
Value Function Update Magnitude: 0.37606

Collected Steps per Second: 15,213.11255
Overall Steps per Second: 6,837.65732

Timestep Collection Time: 3.28743
Timestep Consumption Time: 4.02677
PPO Batch Consumption Time: 0.54681
Total Iteration Time: 7.31420

Cumulative Model Updates: 120,358
Cumulative Timesteps: 1,004,616,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1004616658...
Checkpoint 1004616658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,519.55004
Policy Entropy: 1.68347
Value Function Loss: 0.06680

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.31975
Value Function Update Magnitude: 0.35962

Collected Steps per Second: 15,062.09909
Overall Steps per Second: 7,241.29344

Timestep Collection Time: 3.32145
Timestep Consumption Time: 3.58726
PPO Batch Consumption Time: 0.47118
Total Iteration Time: 6.90871

Cumulative Model Updates: 120,364
Cumulative Timesteps: 1,004,666,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,896.31769
Policy Entropy: 1.68799
Value Function Loss: 0.06274

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.31896
Value Function Update Magnitude: 0.34507

Collected Steps per Second: 15,183.18427
Overall Steps per Second: 7,098.89521

Timestep Collection Time: 3.29391
Timestep Consumption Time: 3.75113
PPO Batch Consumption Time: 0.50121
Total Iteration Time: 7.04504

Cumulative Model Updates: 120,370
Cumulative Timesteps: 1,004,716,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1004716698...
Checkpoint 1004716698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,937.83981
Policy Entropy: 1.70184
Value Function Loss: 0.06860

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.32351
Value Function Update Magnitude: 0.33526

Collected Steps per Second: 14,894.16142
Overall Steps per Second: 6,893.93016

Timestep Collection Time: 3.35877
Timestep Consumption Time: 3.89776
PPO Batch Consumption Time: 0.52167
Total Iteration Time: 7.25653

Cumulative Model Updates: 120,376
Cumulative Timesteps: 1,004,766,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,290.88140
Policy Entropy: 1.70877
Value Function Loss: 0.07066

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.32614
Value Function Update Magnitude: 0.34280

Collected Steps per Second: 14,829.13844
Overall Steps per Second: 7,088.51410

Timestep Collection Time: 3.37241
Timestep Consumption Time: 3.68266
PPO Batch Consumption Time: 0.48556
Total Iteration Time: 7.05508

Cumulative Model Updates: 120,382
Cumulative Timesteps: 1,004,816,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1004816734...
Checkpoint 1004816734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,079.12989
Policy Entropy: 1.70383
Value Function Loss: 0.06891

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.32269
Value Function Update Magnitude: 0.34799

Collected Steps per Second: 15,639.04624
Overall Steps per Second: 7,603.26982

Timestep Collection Time: 3.19981
Timestep Consumption Time: 3.38183
PPO Batch Consumption Time: 0.43970
Total Iteration Time: 6.58164

Cumulative Model Updates: 120,388
Cumulative Timesteps: 1,004,866,776

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,466.02772
Policy Entropy: 1.69711
Value Function Loss: 0.06862

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.32398
Value Function Update Magnitude: 0.33925

Collected Steps per Second: 14,754.26712
Overall Steps per Second: 6,958.90875

Timestep Collection Time: 3.39129
Timestep Consumption Time: 3.79892
PPO Batch Consumption Time: 0.49869
Total Iteration Time: 7.19021

Cumulative Model Updates: 120,394
Cumulative Timesteps: 1,004,916,812

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1004916812...
Checkpoint 1004916812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,279.64379
Policy Entropy: 1.69416
Value Function Loss: 0.07134

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.32641
Value Function Update Magnitude: 0.33212

Collected Steps per Second: 15,331.93664
Overall Steps per Second: 7,407.53372

Timestep Collection Time: 3.26391
Timestep Consumption Time: 3.49165
PPO Batch Consumption Time: 0.45931
Total Iteration Time: 6.75555

Cumulative Model Updates: 120,400
Cumulative Timesteps: 1,004,966,854

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,913.09731
Policy Entropy: 1.69154
Value Function Loss: 0.07480

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.33661
Value Function Update Magnitude: 0.32802

Collected Steps per Second: 15,664.31113
Overall Steps per Second: 7,525.12070

Timestep Collection Time: 3.19248
Timestep Consumption Time: 3.45299
PPO Batch Consumption Time: 0.44289
Total Iteration Time: 6.64547

Cumulative Model Updates: 120,406
Cumulative Timesteps: 1,005,016,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1005016862...
Checkpoint 1005016862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,929.90442
Policy Entropy: 1.69496
Value Function Loss: 0.07467

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.33874
Value Function Update Magnitude: 0.31947

Collected Steps per Second: 15,710.88553
Overall Steps per Second: 7,572.89043

Timestep Collection Time: 3.18391
Timestep Consumption Time: 3.42150
PPO Batch Consumption Time: 0.44111
Total Iteration Time: 6.60540

Cumulative Model Updates: 120,412
Cumulative Timesteps: 1,005,066,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,401.49237
Policy Entropy: 1.68823
Value Function Loss: 0.07972

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.33829
Value Function Update Magnitude: 0.30157

Collected Steps per Second: 14,882.49690
Overall Steps per Second: 7,138.58352

Timestep Collection Time: 3.36153
Timestep Consumption Time: 3.64658
PPO Batch Consumption Time: 0.47444
Total Iteration Time: 7.00811

Cumulative Model Updates: 120,418
Cumulative Timesteps: 1,005,116,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1005116912...
Checkpoint 1005116912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,781.28483
Policy Entropy: 1.68637
Value Function Loss: 0.07805

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.33589
Value Function Update Magnitude: 0.30361

Collected Steps per Second: 14,801.58629
Overall Steps per Second: 7,343.75960

Timestep Collection Time: 3.37856
Timestep Consumption Time: 3.43103
PPO Batch Consumption Time: 0.44228
Total Iteration Time: 6.80959

Cumulative Model Updates: 120,424
Cumulative Timesteps: 1,005,166,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,146.02048
Policy Entropy: 1.67445
Value Function Loss: 0.07870

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.32779
Value Function Update Magnitude: 0.32634

Collected Steps per Second: 15,459.88250
Overall Steps per Second: 7,422.43769

Timestep Collection Time: 3.23469
Timestep Consumption Time: 3.50271
PPO Batch Consumption Time: 0.45259
Total Iteration Time: 6.73741

Cumulative Model Updates: 120,430
Cumulative Timesteps: 1,005,216,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1005216928...
Checkpoint 1005216928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,828.62523
Policy Entropy: 1.67412
Value Function Loss: 0.06885

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.31493
Value Function Update Magnitude: 0.28082

Collected Steps per Second: 15,730.42161
Overall Steps per Second: 7,619.53759

Timestep Collection Time: 3.17932
Timestep Consumption Time: 3.38434
PPO Batch Consumption Time: 0.43484
Total Iteration Time: 6.56365

Cumulative Model Updates: 120,436
Cumulative Timesteps: 1,005,266,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,489.58406
Policy Entropy: 1.67965
Value Function Loss: 0.07113

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.30055
Value Function Update Magnitude: 0.26813

Collected Steps per Second: 15,517.62462
Overall Steps per Second: 7,165.03610

Timestep Collection Time: 3.22253
Timestep Consumption Time: 3.75664
PPO Batch Consumption Time: 0.49904
Total Iteration Time: 6.97917

Cumulative Model Updates: 120,442
Cumulative Timesteps: 1,005,316,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1005316946...
Checkpoint 1005316946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,281.68460
Policy Entropy: 1.69060
Value Function Loss: 0.06842

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.29668
Value Function Update Magnitude: 0.26890

Collected Steps per Second: 14,823.06610
Overall Steps per Second: 6,990.63516

Timestep Collection Time: 3.37312
Timestep Consumption Time: 3.77930
PPO Batch Consumption Time: 0.49857
Total Iteration Time: 7.15243

Cumulative Model Updates: 120,448
Cumulative Timesteps: 1,005,366,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,149.00637
Policy Entropy: 1.68967
Value Function Loss: 0.07076

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.31468
Value Function Update Magnitude: 0.32596

Collected Steps per Second: 14,950.70508
Overall Steps per Second: 7,209.69863

Timestep Collection Time: 3.34620
Timestep Consumption Time: 3.59279
PPO Batch Consumption Time: 0.46550
Total Iteration Time: 6.93899

Cumulative Model Updates: 120,454
Cumulative Timesteps: 1,005,416,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1005416974...
Checkpoint 1005416974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,984.04641
Policy Entropy: 1.69839
Value Function Loss: 0.07498

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.33074
Value Function Update Magnitude: 0.33454

Collected Steps per Second: 15,481.64341
Overall Steps per Second: 7,479.29234

Timestep Collection Time: 3.23131
Timestep Consumption Time: 3.45729
PPO Batch Consumption Time: 0.44638
Total Iteration Time: 6.68860

Cumulative Model Updates: 120,460
Cumulative Timesteps: 1,005,467,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,589.26118
Policy Entropy: 1.69053
Value Function Loss: 0.07703

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.31957
Value Function Update Magnitude: 0.33056

Collected Steps per Second: 16,000.70685
Overall Steps per Second: 7,247.75433

Timestep Collection Time: 3.12599
Timestep Consumption Time: 3.77519
PPO Batch Consumption Time: 0.49955
Total Iteration Time: 6.90117

Cumulative Model Updates: 120,466
Cumulative Timesteps: 1,005,517,018

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1005517018...
Checkpoint 1005517018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,834.15260
Policy Entropy: 1.69384
Value Function Loss: 0.07575

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.30596
Value Function Update Magnitude: 0.33228

Collected Steps per Second: 14,931.73233
Overall Steps per Second: 7,270.27205

Timestep Collection Time: 3.34924
Timestep Consumption Time: 3.52945
PPO Batch Consumption Time: 0.46402
Total Iteration Time: 6.87870

Cumulative Model Updates: 120,472
Cumulative Timesteps: 1,005,567,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,870.64175
Policy Entropy: 1.67198
Value Function Loss: 0.06568

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.32120
Value Function Update Magnitude: 0.32278

Collected Steps per Second: 15,100.39938
Overall Steps per Second: 7,042.96218

Timestep Collection Time: 3.31117
Timestep Consumption Time: 3.78811
PPO Batch Consumption Time: 0.49770
Total Iteration Time: 7.09929

Cumulative Model Updates: 120,478
Cumulative Timesteps: 1,005,617,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1005617028...
Checkpoint 1005617028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,759.23315
Policy Entropy: 1.67740
Value Function Loss: 0.06291

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.31982
Value Function Update Magnitude: 0.33000

Collected Steps per Second: 15,019.23067
Overall Steps per Second: 7,203.27007

Timestep Collection Time: 3.33093
Timestep Consumption Time: 3.61425
PPO Batch Consumption Time: 0.47335
Total Iteration Time: 6.94518

Cumulative Model Updates: 120,484
Cumulative Timesteps: 1,005,667,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,322.78446
Policy Entropy: 1.66958
Value Function Loss: 0.06246

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.31795
Value Function Update Magnitude: 0.33576

Collected Steps per Second: 14,860.32572
Overall Steps per Second: 7,073.51867

Timestep Collection Time: 3.36466
Timestep Consumption Time: 3.70395
PPO Batch Consumption Time: 0.48520
Total Iteration Time: 7.06862

Cumulative Model Updates: 120,490
Cumulative Timesteps: 1,005,717,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1005717056...
Checkpoint 1005717056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,753.96986
Policy Entropy: 1.69350
Value Function Loss: 0.06187

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.31927
Value Function Update Magnitude: 0.33218

Collected Steps per Second: 15,568.57018
Overall Steps per Second: 7,572.75730

Timestep Collection Time: 3.21237
Timestep Consumption Time: 3.39183
PPO Batch Consumption Time: 0.43982
Total Iteration Time: 6.60420

Cumulative Model Updates: 120,496
Cumulative Timesteps: 1,005,767,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,222.73611
Policy Entropy: 1.68905
Value Function Loss: 0.06550

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.32091
Value Function Update Magnitude: 0.31594

Collected Steps per Second: 15,437.71116
Overall Steps per Second: 7,334.73308

Timestep Collection Time: 3.23908
Timestep Consumption Time: 3.57834
PPO Batch Consumption Time: 0.46715
Total Iteration Time: 6.81743

Cumulative Model Updates: 120,502
Cumulative Timesteps: 1,005,817,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1005817072...
Checkpoint 1005817072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,168.72152
Policy Entropy: 1.69616
Value Function Loss: 0.07012

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.32577
Value Function Update Magnitude: 0.30065

Collected Steps per Second: 14,776.62797
Overall Steps per Second: 6,934.34014

Timestep Collection Time: 3.38643
Timestep Consumption Time: 3.82983
PPO Batch Consumption Time: 0.50793
Total Iteration Time: 7.21626

Cumulative Model Updates: 120,508
Cumulative Timesteps: 1,005,867,112

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,590.82660
Policy Entropy: 1.68847
Value Function Loss: 0.07136

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.32582
Value Function Update Magnitude: 0.27181

Collected Steps per Second: 15,735.27114
Overall Steps per Second: 7,246.74639

Timestep Collection Time: 3.18037
Timestep Consumption Time: 3.72535
PPO Batch Consumption Time: 0.48647
Total Iteration Time: 6.90572

Cumulative Model Updates: 120,514
Cumulative Timesteps: 1,005,917,156

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1005917156...
Checkpoint 1005917156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,929.80081
Policy Entropy: 1.67920
Value Function Loss: 0.07361

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.32683
Value Function Update Magnitude: 0.31080

Collected Steps per Second: 15,394.03716
Overall Steps per Second: 7,368.87117

Timestep Collection Time: 3.25139
Timestep Consumption Time: 3.54097
PPO Batch Consumption Time: 0.45933
Total Iteration Time: 6.79236

Cumulative Model Updates: 120,520
Cumulative Timesteps: 1,005,967,208

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,678.66339
Policy Entropy: 1.67692
Value Function Loss: 0.06584

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.32365
Value Function Update Magnitude: 0.33325

Collected Steps per Second: 14,894.71995
Overall Steps per Second: 7,160.00169

Timestep Collection Time: 3.35837
Timestep Consumption Time: 3.62794
PPO Batch Consumption Time: 0.47484
Total Iteration Time: 6.98631

Cumulative Model Updates: 120,526
Cumulative Timesteps: 1,006,017,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1006017230...
Checkpoint 1006017230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,130.27019
Policy Entropy: 1.68692
Value Function Loss: 0.06719

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.32254
Value Function Update Magnitude: 0.33369

Collected Steps per Second: 15,603.31908
Overall Steps per Second: 7,471.49272

Timestep Collection Time: 3.20573
Timestep Consumption Time: 3.48905
PPO Batch Consumption Time: 0.45324
Total Iteration Time: 6.69478

Cumulative Model Updates: 120,532
Cumulative Timesteps: 1,006,067,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,187.83590
Policy Entropy: 1.67710
Value Function Loss: 0.06307

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.32711
Value Function Update Magnitude: 0.33213

Collected Steps per Second: 15,900.57999
Overall Steps per Second: 7,172.08152

Timestep Collection Time: 3.14580
Timestep Consumption Time: 3.82847
PPO Batch Consumption Time: 0.50816
Total Iteration Time: 6.97427

Cumulative Model Updates: 120,538
Cumulative Timesteps: 1,006,117,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1006117270...
Checkpoint 1006117270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,309.74099
Policy Entropy: 1.67210
Value Function Loss: 0.07030

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.32584
Value Function Update Magnitude: 0.31516

Collected Steps per Second: 14,630.34291
Overall Steps per Second: 6,899.79300

Timestep Collection Time: 3.41797
Timestep Consumption Time: 3.82950
PPO Batch Consumption Time: 0.50963
Total Iteration Time: 7.24746

Cumulative Model Updates: 120,544
Cumulative Timesteps: 1,006,167,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,303.02211
Policy Entropy: 1.67552
Value Function Loss: 0.07566

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.33089
Value Function Update Magnitude: 0.34210

Collected Steps per Second: 15,404.10217
Overall Steps per Second: 7,190.75483

Timestep Collection Time: 3.24836
Timestep Consumption Time: 3.71030
PPO Batch Consumption Time: 0.48439
Total Iteration Time: 6.95866

Cumulative Model Updates: 120,550
Cumulative Timesteps: 1,006,217,314

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1006217314...
Checkpoint 1006217314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,885.81225
Policy Entropy: 1.69666
Value Function Loss: 0.07126

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.32615
Value Function Update Magnitude: 0.35254

Collected Steps per Second: 15,312.31231
Overall Steps per Second: 7,108.89300

Timestep Collection Time: 3.26678
Timestep Consumption Time: 3.76976
PPO Batch Consumption Time: 0.49870
Total Iteration Time: 7.03654

Cumulative Model Updates: 120,556
Cumulative Timesteps: 1,006,267,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,186.27536
Policy Entropy: 1.70365
Value Function Loss: 0.07280

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.32523
Value Function Update Magnitude: 0.34623

Collected Steps per Second: 15,240.28072
Overall Steps per Second: 7,045.30789

Timestep Collection Time: 3.28262
Timestep Consumption Time: 3.81828
PPO Batch Consumption Time: 0.50234
Total Iteration Time: 7.10090

Cumulative Model Updates: 120,562
Cumulative Timesteps: 1,006,317,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1006317364...
Checkpoint 1006317364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,751.76038
Policy Entropy: 1.68921
Value Function Loss: 0.07019

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.32986
Value Function Update Magnitude: 0.35219

Collected Steps per Second: 15,323.00509
Overall Steps per Second: 7,038.05815

Timestep Collection Time: 3.26476
Timestep Consumption Time: 3.84316
PPO Batch Consumption Time: 0.50952
Total Iteration Time: 7.10793

Cumulative Model Updates: 120,568
Cumulative Timesteps: 1,006,367,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,010.30146
Policy Entropy: 1.68070
Value Function Loss: 0.07457

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.32544
Value Function Update Magnitude: 0.36412

Collected Steps per Second: 15,498.19458
Overall Steps per Second: 7,413.97534

Timestep Collection Time: 3.22773
Timestep Consumption Time: 3.51953
PPO Batch Consumption Time: 0.45393
Total Iteration Time: 6.74726

Cumulative Model Updates: 120,574
Cumulative Timesteps: 1,006,417,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1006417414...
Checkpoint 1006417414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,679.58843
Policy Entropy: 1.67695
Value Function Loss: 0.07151

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.31511
Value Function Update Magnitude: 0.41451

Collected Steps per Second: 14,794.21000
Overall Steps per Second: 7,279.44912

Timestep Collection Time: 3.38051
Timestep Consumption Time: 3.48979
PPO Batch Consumption Time: 0.45166
Total Iteration Time: 6.87030

Cumulative Model Updates: 120,580
Cumulative Timesteps: 1,006,467,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,882.07409
Policy Entropy: 1.69300
Value Function Loss: 0.07685

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.32341
Value Function Update Magnitude: 0.41279

Collected Steps per Second: 15,598.67285
Overall Steps per Second: 7,550.18533

Timestep Collection Time: 3.20540
Timestep Consumption Time: 3.41695
PPO Batch Consumption Time: 0.44502
Total Iteration Time: 6.62235

Cumulative Model Updates: 120,586
Cumulative Timesteps: 1,006,517,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1006517426...
Checkpoint 1006517426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,615.93738
Policy Entropy: 1.70001
Value Function Loss: 0.07533

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.33380
Value Function Update Magnitude: 0.38954

Collected Steps per Second: 15,167.01212
Overall Steps per Second: 7,138.98313

Timestep Collection Time: 3.29742
Timestep Consumption Time: 3.70806
PPO Batch Consumption Time: 0.49053
Total Iteration Time: 7.00548

Cumulative Model Updates: 120,592
Cumulative Timesteps: 1,006,567,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,990.08047
Policy Entropy: 1.69977
Value Function Loss: 0.07673

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.33238
Value Function Update Magnitude: 0.36341

Collected Steps per Second: 14,804.36089
Overall Steps per Second: 7,197.63653

Timestep Collection Time: 3.38076
Timestep Consumption Time: 3.57291
PPO Batch Consumption Time: 0.46419
Total Iteration Time: 6.95367

Cumulative Model Updates: 120,598
Cumulative Timesteps: 1,006,617,488

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1006617488...
Checkpoint 1006617488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,758.85157
Policy Entropy: 1.69456
Value Function Loss: 0.07329

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.33489
Value Function Update Magnitude: 0.33874

Collected Steps per Second: 16,024.34804
Overall Steps per Second: 7,609.59436

Timestep Collection Time: 3.12088
Timestep Consumption Time: 3.45109
PPO Batch Consumption Time: 0.44575
Total Iteration Time: 6.57197

Cumulative Model Updates: 120,604
Cumulative Timesteps: 1,006,667,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,633.76590
Policy Entropy: 1.70846
Value Function Loss: 0.07988

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.33878
Value Function Update Magnitude: 0.35264

Collected Steps per Second: 15,667.00517
Overall Steps per Second: 7,475.77525

Timestep Collection Time: 3.19410
Timestep Consumption Time: 3.49979
PPO Batch Consumption Time: 0.45311
Total Iteration Time: 6.69389

Cumulative Model Updates: 120,610
Cumulative Timesteps: 1,006,717,540

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1006717540...
Checkpoint 1006717540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,267.78519
Policy Entropy: 1.71458
Value Function Loss: 0.07490

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.33604
Value Function Update Magnitude: 0.36923

Collected Steps per Second: 15,432.97488
Overall Steps per Second: 7,161.25743

Timestep Collection Time: 3.24280
Timestep Consumption Time: 3.74564
PPO Batch Consumption Time: 0.50142
Total Iteration Time: 6.98844

Cumulative Model Updates: 120,616
Cumulative Timesteps: 1,006,767,586

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,936.23082
Policy Entropy: 1.70982
Value Function Loss: 0.07251

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.32954
Value Function Update Magnitude: 0.36675

Collected Steps per Second: 14,682.01478
Overall Steps per Second: 7,108.59771

Timestep Collection Time: 3.40648
Timestep Consumption Time: 3.62922
PPO Batch Consumption Time: 0.47463
Total Iteration Time: 7.03571

Cumulative Model Updates: 120,622
Cumulative Timesteps: 1,006,817,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1006817600...
Checkpoint 1006817600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,522.28819
Policy Entropy: 1.69867
Value Function Loss: 0.06663

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08345
Policy Update Magnitude: 0.32118
Value Function Update Magnitude: 0.34340

Collected Steps per Second: 15,090.98786
Overall Steps per Second: 7,240.19627

Timestep Collection Time: 3.31496
Timestep Consumption Time: 3.59452
PPO Batch Consumption Time: 0.46846
Total Iteration Time: 6.90948

Cumulative Model Updates: 120,628
Cumulative Timesteps: 1,006,867,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,192.39598
Policy Entropy: 1.68459
Value Function Loss: 0.07001

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.32483
Value Function Update Magnitude: 0.32849

Collected Steps per Second: 15,551.79542
Overall Steps per Second: 7,422.87982

Timestep Collection Time: 3.21661
Timestep Consumption Time: 3.52256
PPO Batch Consumption Time: 0.45692
Total Iteration Time: 6.73916

Cumulative Model Updates: 120,634
Cumulative Timesteps: 1,006,917,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1006917650...
Checkpoint 1006917650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,727.35948
Policy Entropy: 1.70061
Value Function Loss: 0.07329

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.33236
Value Function Update Magnitude: 0.34717

Collected Steps per Second: 15,434.36712
Overall Steps per Second: 7,147.29117

Timestep Collection Time: 3.24173
Timestep Consumption Time: 3.75869
PPO Batch Consumption Time: 0.50181
Total Iteration Time: 7.00041

Cumulative Model Updates: 120,640
Cumulative Timesteps: 1,006,967,684

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,534.86269
Policy Entropy: 1.70628
Value Function Loss: 0.07233

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.33772
Value Function Update Magnitude: 0.37490

Collected Steps per Second: 15,393.42730
Overall Steps per Second: 7,357.45277

Timestep Collection Time: 3.24840
Timestep Consumption Time: 3.54797
PPO Batch Consumption Time: 0.46327
Total Iteration Time: 6.79637

Cumulative Model Updates: 120,646
Cumulative Timesteps: 1,007,017,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1007017688...
Checkpoint 1007017688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,355.31433
Policy Entropy: 1.72513
Value Function Loss: 0.07541

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.34025
Value Function Update Magnitude: 0.38122

Collected Steps per Second: 15,404.81474
Overall Steps per Second: 7,487.67329

Timestep Collection Time: 3.24626
Timestep Consumption Time: 3.43245
PPO Batch Consumption Time: 0.44828
Total Iteration Time: 6.67871

Cumulative Model Updates: 120,652
Cumulative Timesteps: 1,007,067,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,598.04846
Policy Entropy: 1.71251
Value Function Loss: 0.07678

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08118
Policy Update Magnitude: 0.33969
Value Function Update Magnitude: 0.38100

Collected Steps per Second: 15,481.33864
Overall Steps per Second: 7,438.37912

Timestep Collection Time: 3.23150
Timestep Consumption Time: 3.49416
PPO Batch Consumption Time: 0.45356
Total Iteration Time: 6.72566

Cumulative Model Updates: 120,658
Cumulative Timesteps: 1,007,117,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1007117724...
Checkpoint 1007117724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,374.39502
Policy Entropy: 1.70412
Value Function Loss: 0.07695

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.33678
Value Function Update Magnitude: 0.36291

Collected Steps per Second: 15,079.95767
Overall Steps per Second: 7,255.12035

Timestep Collection Time: 3.31579
Timestep Consumption Time: 3.57617
PPO Batch Consumption Time: 0.46892
Total Iteration Time: 6.89196

Cumulative Model Updates: 120,664
Cumulative Timesteps: 1,007,167,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,872.99952
Policy Entropy: 1.68864
Value Function Loss: 0.07719

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.32785
Value Function Update Magnitude: 0.34168

Collected Steps per Second: 16,476.39336
Overall Steps per Second: 7,858.82486

Timestep Collection Time: 3.03562
Timestep Consumption Time: 3.32869
PPO Batch Consumption Time: 0.42593
Total Iteration Time: 6.36431

Cumulative Model Updates: 120,670
Cumulative Timesteps: 1,007,217,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1007217742...
Checkpoint 1007217742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,866.15362
Policy Entropy: 1.69323
Value Function Loss: 0.07599

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.29385
Value Function Update Magnitude: 0.35650

Collected Steps per Second: 15,838.04453
Overall Steps per Second: 7,434.47757

Timestep Collection Time: 3.15746
Timestep Consumption Time: 3.56904
PPO Batch Consumption Time: 0.46569
Total Iteration Time: 6.72650

Cumulative Model Updates: 120,676
Cumulative Timesteps: 1,007,267,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,892.27601
Policy Entropy: 1.71714
Value Function Loss: 0.07757

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.30831
Value Function Update Magnitude: 0.36282

Collected Steps per Second: 15,429.87724
Overall Steps per Second: 7,024.37917

Timestep Collection Time: 3.24060
Timestep Consumption Time: 3.87776
PPO Batch Consumption Time: 0.51623
Total Iteration Time: 7.11835

Cumulative Model Updates: 120,682
Cumulative Timesteps: 1,007,317,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1007317752...
Checkpoint 1007317752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,995.54473
Policy Entropy: 1.72750
Value Function Loss: 0.07471

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.33025
Value Function Update Magnitude: 0.36759

Collected Steps per Second: 15,239.46135
Overall Steps per Second: 7,225.17336

Timestep Collection Time: 3.28384
Timestep Consumption Time: 3.64250
PPO Batch Consumption Time: 0.47893
Total Iteration Time: 6.92634

Cumulative Model Updates: 120,688
Cumulative Timesteps: 1,007,367,796

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,849.46922
Policy Entropy: 1.72491
Value Function Loss: 0.07159

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.31709
Value Function Update Magnitude: 0.38459

Collected Steps per Second: 15,332.38680
Overall Steps per Second: 8,033.10061

Timestep Collection Time: 3.26238
Timestep Consumption Time: 2.96436
PPO Batch Consumption Time: 0.36509
Total Iteration Time: 6.22674

Cumulative Model Updates: 120,694
Cumulative Timesteps: 1,007,417,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1007417816...
Checkpoint 1007417816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,812.70368
Policy Entropy: 1.69414
Value Function Loss: 0.07341

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.30808
Value Function Update Magnitude: 0.38229

Collected Steps per Second: 17,839.12875
Overall Steps per Second: 9,221.01616

Timestep Collection Time: 2.80485
Timestep Consumption Time: 2.62145
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 5.42630

Cumulative Model Updates: 120,700
Cumulative Timesteps: 1,007,467,852

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,092.52358
Policy Entropy: 1.68864
Value Function Loss: 0.07050

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.32941
Value Function Update Magnitude: 0.35994

Collected Steps per Second: 19,427.88918
Overall Steps per Second: 9,632.90270

Timestep Collection Time: 2.57434
Timestep Consumption Time: 2.61766
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 5.19200

Cumulative Model Updates: 120,706
Cumulative Timesteps: 1,007,517,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1007517866...
Checkpoint 1007517866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,459.20082
Policy Entropy: 1.68480
Value Function Loss: 0.06950

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.32735
Value Function Update Magnitude: 0.34652

Collected Steps per Second: 20,752.22049
Overall Steps per Second: 10,249.76302

Timestep Collection Time: 2.41025
Timestep Consumption Time: 2.46967
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.87992

Cumulative Model Updates: 120,712
Cumulative Timesteps: 1,007,567,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,808.83617
Policy Entropy: 1.68971
Value Function Loss: 0.06569

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.31848
Value Function Update Magnitude: 0.34246

Collected Steps per Second: 21,784.06433
Overall Steps per Second: 10,371.47190

Timestep Collection Time: 2.29526
Timestep Consumption Time: 2.52566
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.82092

Cumulative Model Updates: 120,718
Cumulative Timesteps: 1,007,617,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1007617884...
Checkpoint 1007617884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,653.48001
Policy Entropy: 1.70898
Value Function Loss: 0.06801

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.31874
Value Function Update Magnitude: 0.32933

Collected Steps per Second: 21,529.60288
Overall Steps per Second: 10,297.47038

Timestep Collection Time: 2.32350
Timestep Consumption Time: 2.53439
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.85789

Cumulative Model Updates: 120,724
Cumulative Timesteps: 1,007,667,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,768.25147
Policy Entropy: 1.71189
Value Function Loss: 0.07185

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.32157
Value Function Update Magnitude: 0.33109

Collected Steps per Second: 21,645.21176
Overall Steps per Second: 10,374.93358

Timestep Collection Time: 2.31118
Timestep Consumption Time: 2.51063
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.82181

Cumulative Model Updates: 120,730
Cumulative Timesteps: 1,007,717,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1007717934...
Checkpoint 1007717934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,246.72197
Policy Entropy: 1.72310
Value Function Loss: 0.07637

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.30766
Value Function Update Magnitude: 0.35245

Collected Steps per Second: 20,818.05991
Overall Steps per Second: 10,305.80221

Timestep Collection Time: 2.40205
Timestep Consumption Time: 2.45017
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.85222

Cumulative Model Updates: 120,736
Cumulative Timesteps: 1,007,767,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,823.76594
Policy Entropy: 1.70506
Value Function Loss: 0.07367

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.30803
Value Function Update Magnitude: 0.36749

Collected Steps per Second: 21,062.27442
Overall Steps per Second: 10,136.64717

Timestep Collection Time: 2.37515
Timestep Consumption Time: 2.56002
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.93516

Cumulative Model Updates: 120,742
Cumulative Timesteps: 1,007,817,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1007817966...
Checkpoint 1007817966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,883.10415
Policy Entropy: 1.70986
Value Function Loss: 0.07309

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.32107
Value Function Update Magnitude: 0.37374

Collected Steps per Second: 20,911.39054
Overall Steps per Second: 10,196.55436

Timestep Collection Time: 2.39133
Timestep Consumption Time: 2.51288
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.90421

Cumulative Model Updates: 120,748
Cumulative Timesteps: 1,007,867,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,979.88905
Policy Entropy: 1.71780
Value Function Loss: 0.06913

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.38394

Collected Steps per Second: 21,251.52376
Overall Steps per Second: 10,316.22597

Timestep Collection Time: 2.35305
Timestep Consumption Time: 2.49426
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.84732

Cumulative Model Updates: 120,754
Cumulative Timesteps: 1,007,917,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1007917978...
Checkpoint 1007917978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,067.44971
Policy Entropy: 1.70880
Value Function Loss: 0.06425

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.32059
Value Function Update Magnitude: 0.37895

Collected Steps per Second: 20,364.44846
Overall Steps per Second: 10,187.60727

Timestep Collection Time: 2.45595
Timestep Consumption Time: 2.45335
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.90930

Cumulative Model Updates: 120,760
Cumulative Timesteps: 1,007,967,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,434.29956
Policy Entropy: 1.70680
Value Function Loss: 0.06107

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07652
Policy Update Magnitude: 0.32073
Value Function Update Magnitude: 0.36561

Collected Steps per Second: 21,154.61661
Overall Steps per Second: 10,368.16994

Timestep Collection Time: 2.36450
Timestep Consumption Time: 2.45989
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.82438

Cumulative Model Updates: 120,766
Cumulative Timesteps: 1,008,018,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1008018012...
Checkpoint 1008018012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,593.89226
Policy Entropy: 1.69453
Value Function Loss: 0.07402

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.32544
Value Function Update Magnitude: 0.36438

Collected Steps per Second: 20,696.46183
Overall Steps per Second: 10,275.07300

Timestep Collection Time: 2.41761
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.86965

Cumulative Model Updates: 120,772
Cumulative Timesteps: 1,008,068,048

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,818.79437
Policy Entropy: 1.69466
Value Function Loss: 0.07942

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.33816
Value Function Update Magnitude: 0.39390

Collected Steps per Second: 21,275.21636
Overall Steps per Second: 10,310.89900

Timestep Collection Time: 2.35072
Timestep Consumption Time: 2.49969
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.85040

Cumulative Model Updates: 120,778
Cumulative Timesteps: 1,008,118,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1008118060...
Checkpoint 1008118060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,574.94901
Policy Entropy: 1.69052
Value Function Loss: 0.07963

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.33854
Value Function Update Magnitude: 0.39509

Collected Steps per Second: 21,411.84033
Overall Steps per Second: 10,438.16561

Timestep Collection Time: 2.33534
Timestep Consumption Time: 2.45515
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.79050

Cumulative Model Updates: 120,784
Cumulative Timesteps: 1,008,168,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,329.97509
Policy Entropy: 1.68729
Value Function Loss: 0.07547

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.33596
Value Function Update Magnitude: 0.38135

Collected Steps per Second: 21,737.22940
Overall Steps per Second: 10,367.33706

Timestep Collection Time: 2.30195
Timestep Consumption Time: 2.52456
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.82650

Cumulative Model Updates: 120,790
Cumulative Timesteps: 1,008,218,102

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1008218102...
Checkpoint 1008218102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,264.28627
Policy Entropy: 1.67619
Value Function Loss: 0.07260

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.33283
Value Function Update Magnitude: 0.35158

Collected Steps per Second: 21,333.71234
Overall Steps per Second: 10,256.86943

Timestep Collection Time: 2.34436
Timestep Consumption Time: 2.53178
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.87615

Cumulative Model Updates: 120,796
Cumulative Timesteps: 1,008,268,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,750.95917
Policy Entropy: 1.68467
Value Function Loss: 0.08342

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.33693
Value Function Update Magnitude: 0.36911

Collected Steps per Second: 21,686.25359
Overall Steps per Second: 10,442.67142

Timestep Collection Time: 2.30708
Timestep Consumption Time: 2.48403
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.79111

Cumulative Model Updates: 120,802
Cumulative Timesteps: 1,008,318,148

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1008318148...
Checkpoint 1008318148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,722.20889
Policy Entropy: 1.66961
Value Function Loss: 0.07703

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.33452
Value Function Update Magnitude: 0.38108

Collected Steps per Second: 21,640.10161
Overall Steps per Second: 10,359.59005

Timestep Collection Time: 2.31099
Timestep Consumption Time: 2.51642
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.82741

Cumulative Model Updates: 120,808
Cumulative Timesteps: 1,008,368,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,387.21847
Policy Entropy: 1.68348
Value Function Loss: 0.07291

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.31243
Value Function Update Magnitude: 0.37835

Collected Steps per Second: 21,860.31958
Overall Steps per Second: 10,415.59394

Timestep Collection Time: 2.28789
Timestep Consumption Time: 2.51395
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.80184

Cumulative Model Updates: 120,814
Cumulative Timesteps: 1,008,418,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1008418172...
Checkpoint 1008418172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,633.71264
Policy Entropy: 1.66550
Value Function Loss: 0.06343

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.30506
Value Function Update Magnitude: 0.35896

Collected Steps per Second: 21,468.35257
Overall Steps per Second: 10,446.63009

Timestep Collection Time: 2.33003
Timestep Consumption Time: 2.45830
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.78834

Cumulative Model Updates: 120,820
Cumulative Timesteps: 1,008,468,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,012.18373
Policy Entropy: 1.67476
Value Function Loss: 0.06310

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.31711
Value Function Update Magnitude: 0.34740

Collected Steps per Second: 21,480.56982
Overall Steps per Second: 10,467.30985

Timestep Collection Time: 2.32778
Timestep Consumption Time: 2.44919
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.77697

Cumulative Model Updates: 120,826
Cumulative Timesteps: 1,008,518,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1008518196...
Checkpoint 1008518196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,374.03404
Policy Entropy: 1.66939
Value Function Loss: 0.06827

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08888
Policy Update Magnitude: 0.32317
Value Function Update Magnitude: 0.34927

Collected Steps per Second: 20,965.31229
Overall Steps per Second: 10,230.92295

Timestep Collection Time: 2.38565
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.88871

Cumulative Model Updates: 120,832
Cumulative Timesteps: 1,008,568,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,572.07890
Policy Entropy: 1.68219
Value Function Loss: 0.07105

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.32635
Value Function Update Magnitude: 0.35716

Collected Steps per Second: 21,379.36898
Overall Steps per Second: 10,427.13236

Timestep Collection Time: 2.33936
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.79652

Cumulative Model Updates: 120,838
Cumulative Timesteps: 1,008,618,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1008618226...
Checkpoint 1008618226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,029.39643
Policy Entropy: 1.69875
Value Function Loss: 0.07430

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.32722
Value Function Update Magnitude: 0.34903

Collected Steps per Second: 21,322.84989
Overall Steps per Second: 10,264.56218

Timestep Collection Time: 2.34518
Timestep Consumption Time: 2.52653
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.87171

Cumulative Model Updates: 120,844
Cumulative Timesteps: 1,008,668,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,588.23519
Policy Entropy: 1.68368
Value Function Loss: 0.07418

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.33402
Value Function Update Magnitude: 0.35954

Collected Steps per Second: 21,456.07440
Overall Steps per Second: 10,451.84229

Timestep Collection Time: 2.33099
Timestep Consumption Time: 2.45419
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.78519

Cumulative Model Updates: 120,850
Cumulative Timesteps: 1,008,718,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1008718246...
Checkpoint 1008718246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,961.92516
Policy Entropy: 1.68744
Value Function Loss: 0.07592

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.33505
Value Function Update Magnitude: 0.36488

Collected Steps per Second: 21,270.64235
Overall Steps per Second: 10,033.41295

Timestep Collection Time: 2.35160
Timestep Consumption Time: 2.63374
PPO Batch Consumption Time: 0.30514
Total Iteration Time: 4.98534

Cumulative Model Updates: 120,856
Cumulative Timesteps: 1,008,768,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,451.80401
Policy Entropy: 1.68978
Value Function Loss: 0.07664

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.33228
Value Function Update Magnitude: 0.36874

Collected Steps per Second: 21,241.18774
Overall Steps per Second: 10,192.51567

Timestep Collection Time: 2.35486
Timestep Consumption Time: 2.55266
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.90752

Cumulative Model Updates: 120,862
Cumulative Timesteps: 1,008,818,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1008818286...
Checkpoint 1008818286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,944.61162
Policy Entropy: 1.69452
Value Function Loss: 0.08107

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.34155
Value Function Update Magnitude: 0.35679

Collected Steps per Second: 21,427.56701
Overall Steps per Second: 10,307.76619

Timestep Collection Time: 2.33540
Timestep Consumption Time: 2.51938
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.85479

Cumulative Model Updates: 120,868
Cumulative Timesteps: 1,008,868,328

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,212.46306
Policy Entropy: 1.68746
Value Function Loss: 0.07605

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.34130
Value Function Update Magnitude: 0.33119

Collected Steps per Second: 21,970.66579
Overall Steps per Second: 10,406.39476

Timestep Collection Time: 2.27722
Timestep Consumption Time: 2.53059
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.80781

Cumulative Model Updates: 120,874
Cumulative Timesteps: 1,008,918,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1008918360...
Checkpoint 1008918360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,540.00435
Policy Entropy: 1.67059
Value Function Loss: 0.07620

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.33846
Value Function Update Magnitude: 0.33915

Collected Steps per Second: 21,603.49769
Overall Steps per Second: 10,527.99888

Timestep Collection Time: 2.31666
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.75380

Cumulative Model Updates: 120,880
Cumulative Timesteps: 1,008,968,408

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,314.92505
Policy Entropy: 1.65733
Value Function Loss: 0.07185

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.32232
Value Function Update Magnitude: 0.32112

Collected Steps per Second: 21,905.21896
Overall Steps per Second: 10,572.91142

Timestep Collection Time: 2.28375
Timestep Consumption Time: 2.44778
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.73153

Cumulative Model Updates: 120,886
Cumulative Timesteps: 1,009,018,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1009018434...
Checkpoint 1009018434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,144.34704
Policy Entropy: 1.66913
Value Function Loss: 0.07179

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.33878

Collected Steps per Second: 21,858.98725
Overall Steps per Second: 10,565.71957

Timestep Collection Time: 2.28904
Timestep Consumption Time: 2.44666
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.73569

Cumulative Model Updates: 120,892
Cumulative Timesteps: 1,009,068,470

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,209.27148
Policy Entropy: 1.67143
Value Function Loss: 0.06687

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.32553
Value Function Update Magnitude: 0.35882

Collected Steps per Second: 21,817.45418
Overall Steps per Second: 10,553.59963

Timestep Collection Time: 2.29385
Timestep Consumption Time: 2.44823
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.74208

Cumulative Model Updates: 120,898
Cumulative Timesteps: 1,009,118,516

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1009118516...
Checkpoint 1009118516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,161.16043
Policy Entropy: 1.67984
Value Function Loss: 0.06446

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.32547
Value Function Update Magnitude: 0.35766

Collected Steps per Second: 21,021.78675
Overall Steps per Second: 10,219.54139

Timestep Collection Time: 2.37972
Timestep Consumption Time: 2.51541
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.89513

Cumulative Model Updates: 120,904
Cumulative Timesteps: 1,009,168,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,144.45051
Policy Entropy: 1.67675
Value Function Loss: 0.06146

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08189
Policy Update Magnitude: 0.31972
Value Function Update Magnitude: 0.35811

Collected Steps per Second: 21,489.37403
Overall Steps per Second: 10,391.44668

Timestep Collection Time: 2.32776
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.81377

Cumulative Model Updates: 120,910
Cumulative Timesteps: 1,009,218,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1009218564...
Checkpoint 1009218564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,723.27880
Policy Entropy: 1.66419
Value Function Loss: 0.06668

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.31764
Value Function Update Magnitude: 0.36158

Collected Steps per Second: 20,900.47131
Overall Steps per Second: 10,194.14784

Timestep Collection Time: 2.39286
Timestep Consumption Time: 2.51309
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.90595

Cumulative Model Updates: 120,916
Cumulative Timesteps: 1,009,268,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,043.42235
Policy Entropy: 1.65956
Value Function Loss: 0.06653

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.32269
Value Function Update Magnitude: 0.35354

Collected Steps per Second: 21,197.30508
Overall Steps per Second: 10,407.06674

Timestep Collection Time: 2.36096
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.80885

Cumulative Model Updates: 120,922
Cumulative Timesteps: 1,009,318,622

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1009318622...
Checkpoint 1009318622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,379.54941
Policy Entropy: 1.66008
Value Function Loss: 0.07143

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.32802
Value Function Update Magnitude: 0.33554

Collected Steps per Second: 20,922.90235
Overall Steps per Second: 10,197.10135

Timestep Collection Time: 2.39078
Timestep Consumption Time: 2.51473
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.90551

Cumulative Model Updates: 120,928
Cumulative Timesteps: 1,009,368,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,435.56889
Policy Entropy: 1.65624
Value Function Loss: 0.06720

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.32550
Value Function Update Magnitude: 0.34193

Collected Steps per Second: 21,268.68569
Overall Steps per Second: 10,104.33394

Timestep Collection Time: 2.35144
Timestep Consumption Time: 2.59812
PPO Batch Consumption Time: 0.30417
Total Iteration Time: 4.94956

Cumulative Model Updates: 120,934
Cumulative Timesteps: 1,009,418,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1009418656...
Checkpoint 1009418656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,037.36056
Policy Entropy: 1.64597
Value Function Loss: 0.06899

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.32110
Value Function Update Magnitude: 0.34121

Collected Steps per Second: 21,482.70689
Overall Steps per Second: 10,235.25165

Timestep Collection Time: 2.32932
Timestep Consumption Time: 2.55967
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.88899

Cumulative Model Updates: 120,940
Cumulative Timesteps: 1,009,468,696

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,035.55151
Policy Entropy: 1.64422
Value Function Loss: 0.06970

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.32826
Value Function Update Magnitude: 0.34691

Collected Steps per Second: 21,747.86362
Overall Steps per Second: 10,495.65037

Timestep Collection Time: 2.29908
Timestep Consumption Time: 2.46480
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.76388

Cumulative Model Updates: 120,946
Cumulative Timesteps: 1,009,518,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1009518696...
Checkpoint 1009518696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,274.67253
Policy Entropy: 1.66019
Value Function Loss: 0.07041

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.32967
Value Function Update Magnitude: 0.34666

Collected Steps per Second: 21,595.56844
Overall Steps per Second: 10,476.94747

Timestep Collection Time: 2.31585
Timestep Consumption Time: 2.45768
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.77353

Cumulative Model Updates: 120,952
Cumulative Timesteps: 1,009,568,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,816.90676
Policy Entropy: 1.68767
Value Function Loss: 0.06842

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.30942
Value Function Update Magnitude: 0.33166

Collected Steps per Second: 21,854.91398
Overall Steps per Second: 10,547.77666

Timestep Collection Time: 2.28928
Timestep Consumption Time: 2.45409
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.74337

Cumulative Model Updates: 120,958
Cumulative Timesteps: 1,009,618,740

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1009618740...
Checkpoint 1009618740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,198.03742
Policy Entropy: 1.69209
Value Function Loss: 0.07085

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.31184
Value Function Update Magnitude: 0.30925

Collected Steps per Second: 20,940.31496
Overall Steps per Second: 10,394.69949

Timestep Collection Time: 2.38994
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.81457

Cumulative Model Updates: 120,964
Cumulative Timesteps: 1,009,668,786

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,346.86714
Policy Entropy: 1.69690
Value Function Loss: 0.07122

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.32177
Value Function Update Magnitude: 0.32377

Collected Steps per Second: 21,010.87109
Overall Steps per Second: 10,402.03443

Timestep Collection Time: 2.38200
Timestep Consumption Time: 2.42936
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.81137

Cumulative Model Updates: 120,970
Cumulative Timesteps: 1,009,718,834

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1009718834...
Checkpoint 1009718834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,913.26539
Policy Entropy: 1.69307
Value Function Loss: 0.07321

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.32607
Value Function Update Magnitude: 0.33889

Collected Steps per Second: 20,930.52649
Overall Steps per Second: 10,505.06941

Timestep Collection Time: 2.39019
Timestep Consumption Time: 2.37208
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.76227

Cumulative Model Updates: 120,976
Cumulative Timesteps: 1,009,768,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,055.74713
Policy Entropy: 1.68837
Value Function Loss: 0.06884

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.31635
Value Function Update Magnitude: 0.35651

Collected Steps per Second: 20,905.72756
Overall Steps per Second: 10,517.30440

Timestep Collection Time: 2.39188
Timestep Consumption Time: 2.36257
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.75445

Cumulative Model Updates: 120,982
Cumulative Timesteps: 1,009,818,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1009818866...
Checkpoint 1009818866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,577.82464
Policy Entropy: 1.68657
Value Function Loss: 0.07153

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.31563
Value Function Update Magnitude: 0.36449

Collected Steps per Second: 20,601.80691
Overall Steps per Second: 10,318.67970

Timestep Collection Time: 2.42920
Timestep Consumption Time: 2.42083
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.85004

Cumulative Model Updates: 120,988
Cumulative Timesteps: 1,009,868,912

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,521.66702
Policy Entropy: 1.67984
Value Function Loss: 0.07431

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.32335
Value Function Update Magnitude: 0.36104

Collected Steps per Second: 20,995.13181
Overall Steps per Second: 10,377.99699

Timestep Collection Time: 2.38284
Timestep Consumption Time: 2.43775
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.82058

Cumulative Model Updates: 120,994
Cumulative Timesteps: 1,009,918,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1009918940...
Checkpoint 1009918940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,143.63350
Policy Entropy: 1.67557
Value Function Loss: 0.07417

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.30850
Value Function Update Magnitude: 0.35650

Collected Steps per Second: 20,949.12796
Overall Steps per Second: 10,528.79186

Timestep Collection Time: 2.38702
Timestep Consumption Time: 2.36243
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.74945

Cumulative Model Updates: 121,000
Cumulative Timesteps: 1,009,968,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,222.21222
Policy Entropy: 1.67668
Value Function Loss: 0.07201

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.32028
Value Function Update Magnitude: 0.35544

Collected Steps per Second: 21,266.36501
Overall Steps per Second: 10,352.10337

Timestep Collection Time: 2.35169
Timestep Consumption Time: 2.47940
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.83110

Cumulative Model Updates: 121,006
Cumulative Timesteps: 1,010,018,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1010018958...
Checkpoint 1010018958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,674.15310
Policy Entropy: 1.68707
Value Function Loss: 0.06731

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.32468
Value Function Update Magnitude: 0.35383

Collected Steps per Second: 20,863.13603
Overall Steps per Second: 10,194.63793

Timestep Collection Time: 2.39743
Timestep Consumption Time: 2.50887
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.90630

Cumulative Model Updates: 121,012
Cumulative Timesteps: 1,010,068,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,960.45081
Policy Entropy: 1.68462
Value Function Loss: 0.06968

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08832
Policy Update Magnitude: 0.32755
Value Function Update Magnitude: 0.34379

Collected Steps per Second: 21,632.26116
Overall Steps per Second: 10,373.28289

Timestep Collection Time: 2.31284
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.82316

Cumulative Model Updates: 121,018
Cumulative Timesteps: 1,010,119,008

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1010119008...
Checkpoint 1010119008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,793.10268
Policy Entropy: 1.67192
Value Function Loss: 0.06700

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.32783
Value Function Update Magnitude: 0.35287

Collected Steps per Second: 21,864.07742
Overall Steps per Second: 10,443.98549

Timestep Collection Time: 2.28741
Timestep Consumption Time: 2.50119
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.78859

Cumulative Model Updates: 121,024
Cumulative Timesteps: 1,010,169,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,661.81249
Policy Entropy: 1.65217
Value Function Loss: 0.07009

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.33033
Value Function Update Magnitude: 0.35463

Collected Steps per Second: 21,591.40744
Overall Steps per Second: 10,448.36833

Timestep Collection Time: 2.31629
Timestep Consumption Time: 2.47029
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.78658

Cumulative Model Updates: 121,030
Cumulative Timesteps: 1,010,219,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1010219032...
Checkpoint 1010219032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,620.59953
Policy Entropy: 1.65487
Value Function Loss: 0.07194

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.33915
Value Function Update Magnitude: 0.35688

Collected Steps per Second: 21,630.47170
Overall Steps per Second: 10,358.40401

Timestep Collection Time: 2.31313
Timestep Consumption Time: 2.51716
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.83028

Cumulative Model Updates: 121,036
Cumulative Timesteps: 1,010,269,066

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,837.05801
Policy Entropy: 1.65530
Value Function Loss: 0.06743

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.33569
Value Function Update Magnitude: 0.36210

Collected Steps per Second: 22,180.75054
Overall Steps per Second: 10,646.59308

Timestep Collection Time: 2.25466
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.69728

Cumulative Model Updates: 121,042
Cumulative Timesteps: 1,010,319,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1010319076...
Checkpoint 1010319076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,221.11099
Policy Entropy: 1.66388
Value Function Loss: 0.06680

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.32427
Value Function Update Magnitude: 0.35349

Collected Steps per Second: 21,504.52955
Overall Steps per Second: 10,373.52099

Timestep Collection Time: 2.32630
Timestep Consumption Time: 2.49617
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.82247

Cumulative Model Updates: 121,048
Cumulative Timesteps: 1,010,369,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,981.19481
Policy Entropy: 1.65709
Value Function Loss: 0.06261

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.32445
Value Function Update Magnitude: 0.34908

Collected Steps per Second: 21,771.25710
Overall Steps per Second: 10,367.34055

Timestep Collection Time: 2.29716
Timestep Consumption Time: 2.52684
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.82400

Cumulative Model Updates: 121,054
Cumulative Timesteps: 1,010,419,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1010419114...
Checkpoint 1010419114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,967.72026
Policy Entropy: 1.66605
Value Function Loss: 0.06768

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.32572
Value Function Update Magnitude: 0.36106

Collected Steps per Second: 21,540.15047
Overall Steps per Second: 10,327.47118

Timestep Collection Time: 2.32227
Timestep Consumption Time: 2.52132
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.84359

Cumulative Model Updates: 121,060
Cumulative Timesteps: 1,010,469,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,212.93974
Policy Entropy: 1.66110
Value Function Loss: 0.07084

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.33191
Value Function Update Magnitude: 0.36649

Collected Steps per Second: 21,605.70534
Overall Steps per Second: 10,353.05893

Timestep Collection Time: 2.31522
Timestep Consumption Time: 2.51639
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.83162

Cumulative Model Updates: 121,066
Cumulative Timesteps: 1,010,519,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1010519158...
Checkpoint 1010519158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,362.83439
Policy Entropy: 1.66746
Value Function Loss: 0.06701

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.33002
Value Function Update Magnitude: 0.37243

Collected Steps per Second: 21,095.74700
Overall Steps per Second: 10,213.37990

Timestep Collection Time: 2.37043
Timestep Consumption Time: 2.52570
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.89613

Cumulative Model Updates: 121,072
Cumulative Timesteps: 1,010,569,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,889.28234
Policy Entropy: 1.65885
Value Function Loss: 0.06409

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.32242
Value Function Update Magnitude: 0.36233

Collected Steps per Second: 21,656.38993
Overall Steps per Second: 10,423.32449

Timestep Collection Time: 2.30934
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.79809

Cumulative Model Updates: 121,078
Cumulative Timesteps: 1,010,619,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1010619176...
Checkpoint 1010619176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,450.61824
Policy Entropy: 1.67607
Value Function Loss: 0.06696

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.32554
Value Function Update Magnitude: 0.35928

Collected Steps per Second: 20,561.63910
Overall Steps per Second: 10,050.27064

Timestep Collection Time: 2.43249
Timestep Consumption Time: 2.54409
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.97658

Cumulative Model Updates: 121,084
Cumulative Timesteps: 1,010,669,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,609.23205
Policy Entropy: 1.67209
Value Function Loss: 0.07542

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.33228
Value Function Update Magnitude: 0.37342

Collected Steps per Second: 21,637.65305
Overall Steps per Second: 10,356.55357

Timestep Collection Time: 2.31208
Timestep Consumption Time: 2.51848
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.83056

Cumulative Model Updates: 121,090
Cumulative Timesteps: 1,010,719,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1010719220...
Checkpoint 1010719220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,689.48869
Policy Entropy: 1.68383
Value Function Loss: 0.07810

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.33445
Value Function Update Magnitude: 0.35188

Collected Steps per Second: 21,479.34408
Overall Steps per Second: 10,461.85036

Timestep Collection Time: 2.32838
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.78042

Cumulative Model Updates: 121,096
Cumulative Timesteps: 1,010,769,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,935.74675
Policy Entropy: 1.67369
Value Function Loss: 0.07635

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.32556
Value Function Update Magnitude: 0.29331

Collected Steps per Second: 21,884.54400
Overall Steps per Second: 10,552.42281

Timestep Collection Time: 2.28609
Timestep Consumption Time: 2.45500
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.74109

Cumulative Model Updates: 121,102
Cumulative Timesteps: 1,010,819,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1010819262...
Checkpoint 1010819262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,147.69947
Policy Entropy: 1.67331
Value Function Loss: 0.07063

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.31705
Value Function Update Magnitude: 0.27145

Collected Steps per Second: 21,338.35359
Overall Steps per Second: 10,274.39526

Timestep Collection Time: 2.34357
Timestep Consumption Time: 2.52367
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.86725

Cumulative Model Updates: 121,108
Cumulative Timesteps: 1,010,869,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,154.35883
Policy Entropy: 1.67923
Value Function Loss: 0.07126

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.32123
Value Function Update Magnitude: 0.26627

Collected Steps per Second: 21,946.20189
Overall Steps per Second: 10,425.14560

Timestep Collection Time: 2.27957
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.79878

Cumulative Model Updates: 121,114
Cumulative Timesteps: 1,010,919,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1010919298...
Checkpoint 1010919298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,547.92431
Policy Entropy: 1.66690
Value Function Loss: 0.07043

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.32790
Value Function Update Magnitude: 0.25009

Collected Steps per Second: 21,676.77124
Overall Steps per Second: 10,607.95101

Timestep Collection Time: 2.30735
Timestep Consumption Time: 2.40760
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.71495

Cumulative Model Updates: 121,120
Cumulative Timesteps: 1,010,969,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,546.76996
Policy Entropy: 1.67443
Value Function Loss: 0.06927

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.32326
Value Function Update Magnitude: 0.27271

Collected Steps per Second: 21,919.18572
Overall Steps per Second: 10,380.29539

Timestep Collection Time: 2.28248
Timestep Consumption Time: 2.53723
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.81971

Cumulative Model Updates: 121,126
Cumulative Timesteps: 1,011,019,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1011019344...
Checkpoint 1011019344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,021.18289
Policy Entropy: 1.66219
Value Function Loss: 0.06824

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.32317
Value Function Update Magnitude: 0.31142

Collected Steps per Second: 21,376.28369
Overall Steps per Second: 10,278.43629

Timestep Collection Time: 2.34054
Timestep Consumption Time: 2.52713
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.86767

Cumulative Model Updates: 121,132
Cumulative Timesteps: 1,011,069,376

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,449.61347
Policy Entropy: 1.66489
Value Function Loss: 0.06448

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.32720
Value Function Update Magnitude: 0.31410

Collected Steps per Second: 21,910.86008
Overall Steps per Second: 10,401.47884

Timestep Collection Time: 2.28416
Timestep Consumption Time: 2.52746
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.81162

Cumulative Model Updates: 121,138
Cumulative Timesteps: 1,011,119,424

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1011119424...
Checkpoint 1011119424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,118.55945
Policy Entropy: 1.66419
Value Function Loss: 0.07014

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.33101
Value Function Update Magnitude: 0.34259

Collected Steps per Second: 21,431.69094
Overall Steps per Second: 10,286.01644

Timestep Collection Time: 2.33393
Timestep Consumption Time: 2.52899
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.86291

Cumulative Model Updates: 121,144
Cumulative Timesteps: 1,011,169,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,984.88042
Policy Entropy: 1.67523
Value Function Loss: 0.06971

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.33197
Value Function Update Magnitude: 0.35012

Collected Steps per Second: 20,775.43724
Overall Steps per Second: 10,348.60453

Timestep Collection Time: 2.40852
Timestep Consumption Time: 2.42672
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.83524

Cumulative Model Updates: 121,150
Cumulative Timesteps: 1,011,219,482

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1011219482...
Checkpoint 1011219482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,119.30403
Policy Entropy: 1.68320
Value Function Loss: 0.07494

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.33520
Value Function Update Magnitude: 0.34041

Collected Steps per Second: 20,487.38090
Overall Steps per Second: 10,209.49137

Timestep Collection Time: 2.44101
Timestep Consumption Time: 2.45737
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.89838

Cumulative Model Updates: 121,156
Cumulative Timesteps: 1,011,269,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,071.56605
Policy Entropy: 1.67479
Value Function Loss: 0.07561

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.33464
Value Function Update Magnitude: 0.37217

Collected Steps per Second: 20,994.33196
Overall Steps per Second: 10,057.40054

Timestep Collection Time: 2.38236
Timestep Consumption Time: 2.59070
PPO Batch Consumption Time: 0.30526
Total Iteration Time: 4.97305

Cumulative Model Updates: 121,162
Cumulative Timesteps: 1,011,319,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1011319508...
Checkpoint 1011319508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,797.39734
Policy Entropy: 1.64841
Value Function Loss: 0.07372

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.32676
Value Function Update Magnitude: 0.37323

Collected Steps per Second: 21,186.54391
Overall Steps per Second: 10,234.81304

Timestep Collection Time: 2.36008
Timestep Consumption Time: 2.52540
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.88548

Cumulative Model Updates: 121,168
Cumulative Timesteps: 1,011,369,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,574.79464
Policy Entropy: 1.65295
Value Function Loss: 0.07668

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.31157
Value Function Update Magnitude: 0.37289

Collected Steps per Second: 21,583.88678
Overall Steps per Second: 10,474.66359

Timestep Collection Time: 2.31682
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.77400

Cumulative Model Updates: 121,174
Cumulative Timesteps: 1,011,419,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1011419516...
Checkpoint 1011419516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,230.47884
Policy Entropy: 1.65125
Value Function Loss: 0.07028

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08455
Policy Update Magnitude: 0.31009
Value Function Update Magnitude: 0.37480

Collected Steps per Second: 21,544.30602
Overall Steps per Second: 10,294.11901

Timestep Collection Time: 2.32219
Timestep Consumption Time: 2.53787
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.86006

Cumulative Model Updates: 121,180
Cumulative Timesteps: 1,011,469,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,961.72978
Policy Entropy: 1.65283
Value Function Loss: 0.07095

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.28022
Value Function Update Magnitude: 0.37688

Collected Steps per Second: 21,963.51680
Overall Steps per Second: 10,426.96317

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.52017
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.79795

Cumulative Model Updates: 121,186
Cumulative Timesteps: 1,011,519,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1011519574...
Checkpoint 1011519574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,672.94427
Policy Entropy: 1.65092
Value Function Loss: 0.06980

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.29909
Value Function Update Magnitude: 0.36451

Collected Steps per Second: 21,526.78601
Overall Steps per Second: 10,477.14234

Timestep Collection Time: 2.32455
Timestep Consumption Time: 2.45157
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.77611

Cumulative Model Updates: 121,192
Cumulative Timesteps: 1,011,569,614

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,000.81549
Policy Entropy: 1.66038
Value Function Loss: 0.07277

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.32975
Value Function Update Magnitude: 0.35220

Collected Steps per Second: 21,649.96345
Overall Steps per Second: 10,445.44686

Timestep Collection Time: 2.30957
Timestep Consumption Time: 2.47740
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.78697

Cumulative Model Updates: 121,198
Cumulative Timesteps: 1,011,619,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1011619616...
Checkpoint 1011619616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,365.09664
Policy Entropy: 1.66333
Value Function Loss: 0.07834

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.33312
Value Function Update Magnitude: 0.36798

Collected Steps per Second: 21,360.92322
Overall Steps per Second: 10,269.77613

Timestep Collection Time: 2.34072
Timestep Consumption Time: 2.52793
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.86866

Cumulative Model Updates: 121,204
Cumulative Timesteps: 1,011,669,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,701.16016
Policy Entropy: 1.68811
Value Function Loss: 0.07983

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.33604
Value Function Update Magnitude: 0.37945

Collected Steps per Second: 22,087.69908
Overall Steps per Second: 10,531.34558

Timestep Collection Time: 2.26479
Timestep Consumption Time: 2.48522
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.75001

Cumulative Model Updates: 121,210
Cumulative Timesteps: 1,011,719,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1011719640...
Checkpoint 1011719640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,952.37628
Policy Entropy: 1.67579
Value Function Loss: 0.07651

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.33004
Value Function Update Magnitude: 0.35086

Collected Steps per Second: 21,681.35713
Overall Steps per Second: 10,513.14717

Timestep Collection Time: 2.30714
Timestep Consumption Time: 2.45090
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.75804

Cumulative Model Updates: 121,216
Cumulative Timesteps: 1,011,769,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,994.19602
Policy Entropy: 1.68634
Value Function Loss: 0.07487

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.32305
Value Function Update Magnitude: 0.33701

Collected Steps per Second: 21,691.99749
Overall Steps per Second: 10,526.73125

Timestep Collection Time: 2.30537
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.75057

Cumulative Model Updates: 121,222
Cumulative Timesteps: 1,011,819,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1011819670...
Checkpoint 1011819670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,922.65031
Policy Entropy: 1.66433
Value Function Loss: 0.06884

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.32772
Value Function Update Magnitude: 0.36511

Collected Steps per Second: 21,159.59791
Overall Steps per Second: 10,221.89255

Timestep Collection Time: 2.36413
Timestep Consumption Time: 2.52968
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.89381

Cumulative Model Updates: 121,228
Cumulative Timesteps: 1,011,869,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,231.54909
Policy Entropy: 1.68594
Value Function Loss: 0.07034

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.32325
Value Function Update Magnitude: 0.38033

Collected Steps per Second: 21,398.60846
Overall Steps per Second: 10,401.47137

Timestep Collection Time: 2.33669
Timestep Consumption Time: 2.47051
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.80720

Cumulative Model Updates: 121,234
Cumulative Timesteps: 1,011,919,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1011919696...
Checkpoint 1011919696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,009.68788
Policy Entropy: 1.67932
Value Function Loss: 0.07306

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.32190
Value Function Update Magnitude: 0.37740

Collected Steps per Second: 20,991.83437
Overall Steps per Second: 10,031.60344

Timestep Collection Time: 2.38207
Timestep Consumption Time: 2.60258
PPO Batch Consumption Time: 0.30492
Total Iteration Time: 4.98465

Cumulative Model Updates: 121,240
Cumulative Timesteps: 1,011,969,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,633.55978
Policy Entropy: 1.67525
Value Function Loss: 0.07523

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.32576
Value Function Update Magnitude: 0.36101

Collected Steps per Second: 21,396.25589
Overall Steps per Second: 10,204.67491

Timestep Collection Time: 2.33704
Timestep Consumption Time: 2.56306
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.90011

Cumulative Model Updates: 121,246
Cumulative Timesteps: 1,012,019,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1012019704...
Checkpoint 1012019704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,177.10347
Policy Entropy: 1.66623
Value Function Loss: 0.07455

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.32533
Value Function Update Magnitude: 0.35145

Collected Steps per Second: 21,765.45200
Overall Steps per Second: 10,396.60213

Timestep Collection Time: 2.29841
Timestep Consumption Time: 2.51335
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.81176

Cumulative Model Updates: 121,252
Cumulative Timesteps: 1,012,069,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,256.06910
Policy Entropy: 1.67508
Value Function Loss: 0.07843

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.32817
Value Function Update Magnitude: 0.34880

Collected Steps per Second: 22,049.09754
Overall Steps per Second: 10,566.48777

Timestep Collection Time: 2.26894
Timestep Consumption Time: 2.46565
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.73459

Cumulative Model Updates: 121,258
Cumulative Timesteps: 1,012,119,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1012119758...
Checkpoint 1012119758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,339.11701
Policy Entropy: 1.68390
Value Function Loss: 0.08101

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.33848
Value Function Update Magnitude: 0.37286

Collected Steps per Second: 21,547.64101
Overall Steps per Second: 10,374.04768

Timestep Collection Time: 2.32137
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.82165

Cumulative Model Updates: 121,264
Cumulative Timesteps: 1,012,169,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,084.10929
Policy Entropy: 1.68855
Value Function Loss: 0.07966

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.34002
Value Function Update Magnitude: 0.38007

Collected Steps per Second: 21,851.39418
Overall Steps per Second: 10,434.96218

Timestep Collection Time: 2.28846
Timestep Consumption Time: 2.50370
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.79216

Cumulative Model Updates: 121,270
Cumulative Timesteps: 1,012,219,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1012219784...
Checkpoint 1012219784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,270.85505
Policy Entropy: 1.69930
Value Function Loss: 0.06900

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.33291
Value Function Update Magnitude: 0.36832

Collected Steps per Second: 21,534.77960
Overall Steps per Second: 10,357.65046

Timestep Collection Time: 2.32210
Timestep Consumption Time: 2.50582
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.82793

Cumulative Model Updates: 121,276
Cumulative Timesteps: 1,012,269,790

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,197.65574
Policy Entropy: 1.69276
Value Function Loss: 0.06874

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.33029
Value Function Update Magnitude: 0.36391

Collected Steps per Second: 22,103.98775
Overall Steps per Second: 10,650.21832

Timestep Collection Time: 2.26240
Timestep Consumption Time: 2.43309
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.69549

Cumulative Model Updates: 121,282
Cumulative Timesteps: 1,012,319,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1012319798...
Checkpoint 1012319798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,407.87078
Policy Entropy: 1.68811
Value Function Loss: 0.07288

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.33095
Value Function Update Magnitude: 0.35772

Collected Steps per Second: 21,544.73771
Overall Steps per Second: 10,412.22891

Timestep Collection Time: 2.32224
Timestep Consumption Time: 2.48288
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.80512

Cumulative Model Updates: 121,288
Cumulative Timesteps: 1,012,369,830

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,298.08056
Policy Entropy: 1.66786
Value Function Loss: 0.07433

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.33092
Value Function Update Magnitude: 0.34818

Collected Steps per Second: 21,513.08990
Overall Steps per Second: 10,304.55464

Timestep Collection Time: 2.32575
Timestep Consumption Time: 2.52978
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.85552

Cumulative Model Updates: 121,294
Cumulative Timesteps: 1,012,419,864

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1012419864...
Checkpoint 1012419864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,336.50712
Policy Entropy: 1.67081
Value Function Loss: 0.07372

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.32876
Value Function Update Magnitude: 0.35329

Collected Steps per Second: 21,084.20746
Overall Steps per Second: 10,205.53863

Timestep Collection Time: 2.37230
Timestep Consumption Time: 2.52877
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.90106

Cumulative Model Updates: 121,300
Cumulative Timesteps: 1,012,469,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,891.87209
Policy Entropy: 1.66199
Value Function Loss: 0.06993

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.33262
Value Function Update Magnitude: 0.36493

Collected Steps per Second: 21,346.29731
Overall Steps per Second: 10,506.45858

Timestep Collection Time: 2.34233
Timestep Consumption Time: 2.41665
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.75898

Cumulative Model Updates: 121,306
Cumulative Timesteps: 1,012,519,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1012519882...
Checkpoint 1012519882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,077.35920
Policy Entropy: 1.66288
Value Function Loss: 0.07125

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.33446
Value Function Update Magnitude: 0.37711

Collected Steps per Second: 21,299.33886
Overall Steps per Second: 10,406.45046

Timestep Collection Time: 2.34871
Timestep Consumption Time: 2.45850
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.80721

Cumulative Model Updates: 121,312
Cumulative Timesteps: 1,012,569,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,683.79500
Policy Entropy: 1.67323
Value Function Loss: 0.07252

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.32781
Value Function Update Magnitude: 0.36733

Collected Steps per Second: 21,442.82508
Overall Steps per Second: 10,111.76049

Timestep Collection Time: 2.33244
Timestep Consumption Time: 2.61369
PPO Batch Consumption Time: 0.30020
Total Iteration Time: 4.94612

Cumulative Model Updates: 121,318
Cumulative Timesteps: 1,012,619,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1012619922...
Checkpoint 1012619922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,837.58892
Policy Entropy: 1.69030
Value Function Loss: 0.07934

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.30202
Value Function Update Magnitude: 0.37181

Collected Steps per Second: 21,624.56080
Overall Steps per Second: 10,298.00275

Timestep Collection Time: 2.31283
Timestep Consumption Time: 2.54384
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.85667

Cumulative Model Updates: 121,324
Cumulative Timesteps: 1,012,669,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,454.68596
Policy Entropy: 1.71326
Value Function Loss: 0.08919

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.31931
Value Function Update Magnitude: 0.37618

Collected Steps per Second: 21,971.12877
Overall Steps per Second: 10,503.68499

Timestep Collection Time: 2.27617
Timestep Consumption Time: 2.48502
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.76119

Cumulative Model Updates: 121,330
Cumulative Timesteps: 1,012,719,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1012719946...
Checkpoint 1012719946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,518.07416
Policy Entropy: 1.71662
Value Function Loss: 0.09144

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.34529
Value Function Update Magnitude: 0.33449

Collected Steps per Second: 21,691.05780
Overall Steps per Second: 10,641.07669

Timestep Collection Time: 2.30611
Timestep Consumption Time: 2.39473
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.70084

Cumulative Model Updates: 121,336
Cumulative Timesteps: 1,012,769,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,120.69542
Policy Entropy: 1.70106
Value Function Loss: 0.08517

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.34327
Value Function Update Magnitude: 0.30527

Collected Steps per Second: 21,921.80195
Overall Steps per Second: 10,389.20312

Timestep Collection Time: 2.28138
Timestep Consumption Time: 2.53246
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.81384

Cumulative Model Updates: 121,342
Cumulative Timesteps: 1,012,819,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1012819980...
Checkpoint 1012819980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,696.57121
Policy Entropy: 1.69822
Value Function Loss: 0.07861

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.33376
Value Function Update Magnitude: 0.31946

Collected Steps per Second: 21,661.21339
Overall Steps per Second: 10,372.11863

Timestep Collection Time: 2.30864
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.82139

Cumulative Model Updates: 121,348
Cumulative Timesteps: 1,012,869,988

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,242.57625
Policy Entropy: 1.69403
Value Function Loss: 0.08110

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.33225
Value Function Update Magnitude: 0.35120

Collected Steps per Second: 21,964.86482
Overall Steps per Second: 10,220.02765

Timestep Collection Time: 2.27746
Timestep Consumption Time: 2.61725
PPO Batch Consumption Time: 0.31456
Total Iteration Time: 4.89470

Cumulative Model Updates: 121,354
Cumulative Timesteps: 1,012,920,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1012920012...
Checkpoint 1012920012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,406.09917
Policy Entropy: 1.70452
Value Function Loss: 0.08803

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.33578
Value Function Update Magnitude: 0.37600

Collected Steps per Second: 20,258.26103
Overall Steps per Second: 10,010.00801

Timestep Collection Time: 2.46843
Timestep Consumption Time: 2.52718
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 4.99560

Cumulative Model Updates: 121,360
Cumulative Timesteps: 1,012,970,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,237.35482
Policy Entropy: 1.69578
Value Function Loss: 0.08519

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.33885
Value Function Update Magnitude: 0.41584

Collected Steps per Second: 20,535.91004
Overall Steps per Second: 9,999.55082

Timestep Collection Time: 2.43476
Timestep Consumption Time: 2.56547
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 5.00022

Cumulative Model Updates: 121,366
Cumulative Timesteps: 1,013,020,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1013020018...
Checkpoint 1013020018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,093.86559
Policy Entropy: 1.69481
Value Function Loss: 0.07933

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.31009
Value Function Update Magnitude: 0.40226

Collected Steps per Second: 20,522.60334
Overall Steps per Second: 10,095.63256

Timestep Collection Time: 2.43692
Timestep Consumption Time: 2.51690
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.95383

Cumulative Model Updates: 121,372
Cumulative Timesteps: 1,013,070,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,118.81114
Policy Entropy: 1.69991
Value Function Loss: 0.07100

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.30620
Value Function Update Magnitude: 0.39040

Collected Steps per Second: 21,467.83282
Overall Steps per Second: 10,551.28614

Timestep Collection Time: 2.33037
Timestep Consumption Time: 2.41104
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.74141

Cumulative Model Updates: 121,378
Cumulative Timesteps: 1,013,120,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1013120058...
Checkpoint 1013120058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,824.71195
Policy Entropy: 1.70105
Value Function Loss: 0.07360

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.29315
Value Function Update Magnitude: 0.37503

Collected Steps per Second: 21,643.88490
Overall Steps per Second: 10,530.78707

Timestep Collection Time: 2.31160
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.75102

Cumulative Model Updates: 121,384
Cumulative Timesteps: 1,013,170,090

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,335.67251
Policy Entropy: 1.70441
Value Function Loss: 0.07900

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.29753
Value Function Update Magnitude: 0.37420

Collected Steps per Second: 21,873.02714
Overall Steps per Second: 10,348.03912

Timestep Collection Time: 2.28729
Timestep Consumption Time: 2.54744
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.83473

Cumulative Model Updates: 121,390
Cumulative Timesteps: 1,013,220,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1013220120...
Checkpoint 1013220120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,729.86962
Policy Entropy: 1.70675
Value Function Loss: 0.08436

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.32958
Value Function Update Magnitude: 0.40298

Collected Steps per Second: 21,265.58514
Overall Steps per Second: 10,350.19648

Timestep Collection Time: 2.35131
Timestep Consumption Time: 2.47971
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.83102

Cumulative Model Updates: 121,396
Cumulative Timesteps: 1,013,270,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,929.74056
Policy Entropy: 1.70990
Value Function Loss: 0.08199

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.33481
Value Function Update Magnitude: 0.41356

Collected Steps per Second: 21,242.74426
Overall Steps per Second: 10,418.23456

Timestep Collection Time: 2.35610
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.80408

Cumulative Model Updates: 121,402
Cumulative Timesteps: 1,013,320,172

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1013320172...
Checkpoint 1013320172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,594.79680
Policy Entropy: 1.70678
Value Function Loss: 0.07898

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.33281
Value Function Update Magnitude: 0.40245

Collected Steps per Second: 21,277.19939
Overall Steps per Second: 10,270.12890

Timestep Collection Time: 2.35097
Timestep Consumption Time: 2.51966
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.87063

Cumulative Model Updates: 121,408
Cumulative Timesteps: 1,013,370,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,855.54509
Policy Entropy: 1.71597
Value Function Loss: 0.07861

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.33286
Value Function Update Magnitude: 0.40834

Collected Steps per Second: 21,541.33831
Overall Steps per Second: 10,387.29708

Timestep Collection Time: 2.32205
Timestep Consumption Time: 2.49345
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.81550

Cumulative Model Updates: 121,414
Cumulative Timesteps: 1,013,420,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1013420214...
Checkpoint 1013420214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,239.00777
Policy Entropy: 1.71867
Value Function Loss: 0.07556

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.33020
Value Function Update Magnitude: 0.40883

Collected Steps per Second: 21,261.20904
Overall Steps per Second: 10,269.41548

Timestep Collection Time: 2.35227
Timestep Consumption Time: 2.51773
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.86999

Cumulative Model Updates: 121,420
Cumulative Timesteps: 1,013,470,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,169.36119
Policy Entropy: 1.69301
Value Function Loss: 0.07670

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.33245
Value Function Update Magnitude: 0.40400

Collected Steps per Second: 21,588.06659
Overall Steps per Second: 10,453.27926

Timestep Collection Time: 2.31674
Timestep Consumption Time: 2.46778
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.78453

Cumulative Model Updates: 121,426
Cumulative Timesteps: 1,013,520,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1013520240...
Checkpoint 1013520240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,399.66733
Policy Entropy: 1.67982
Value Function Loss: 0.07499

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.32445
Value Function Update Magnitude: 0.36463

Collected Steps per Second: 21,905.55459
Overall Steps per Second: 10,541.37801

Timestep Collection Time: 2.28289
Timestep Consumption Time: 2.46108
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.74397

Cumulative Model Updates: 121,432
Cumulative Timesteps: 1,013,570,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,234.18680
Policy Entropy: 1.69153
Value Function Loss: 0.08509

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.28913
Value Function Update Magnitude: 0.32470

Collected Steps per Second: 21,870.70764
Overall Steps per Second: 10,608.25437

Timestep Collection Time: 2.28699
Timestep Consumption Time: 2.42802
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.71501

Cumulative Model Updates: 121,438
Cumulative Timesteps: 1,013,620,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1013620266...
Checkpoint 1013620266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,365.98581
Policy Entropy: 1.71233
Value Function Loss: 0.08554

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.30063
Value Function Update Magnitude: 0.36734

Collected Steps per Second: 21,305.05810
Overall Steps per Second: 10,285.55967

Timestep Collection Time: 2.34808
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.86371

Cumulative Model Updates: 121,444
Cumulative Timesteps: 1,013,670,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,162.94139
Policy Entropy: 1.73469
Value Function Loss: 0.08936

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.29801
Value Function Update Magnitude: 0.39224

Collected Steps per Second: 22,157.71436
Overall Steps per Second: 10,501.35867

Timestep Collection Time: 2.25854
Timestep Consumption Time: 2.50694
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.76548

Cumulative Model Updates: 121,450
Cumulative Timesteps: 1,013,720,336

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1013720336...
Checkpoint 1013720336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,947.83244
Policy Entropy: 1.72092
Value Function Loss: 0.08202

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.28238
Value Function Update Magnitude: 0.41420

Collected Steps per Second: 21,941.24301
Overall Steps per Second: 10,434.94672

Timestep Collection Time: 2.28009
Timestep Consumption Time: 2.51418
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.79427

Cumulative Model Updates: 121,456
Cumulative Timesteps: 1,013,770,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,550.66738
Policy Entropy: 1.73313
Value Function Loss: 0.08203

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.29406
Value Function Update Magnitude: 0.40990

Collected Steps per Second: 22,063.01106
Overall Steps per Second: 10,467.29191

Timestep Collection Time: 2.26723
Timestep Consumption Time: 2.51165
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.77889

Cumulative Model Updates: 121,462
Cumulative Timesteps: 1,013,820,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1013820386...
Checkpoint 1013820386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,816.94146
Policy Entropy: 1.72942
Value Function Loss: 0.08075

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.30132
Value Function Update Magnitude: 0.38764

Collected Steps per Second: 21,441.13515
Overall Steps per Second: 10,143.39801

Timestep Collection Time: 2.33234
Timestep Consumption Time: 2.59776
PPO Batch Consumption Time: 0.30635
Total Iteration Time: 4.93010

Cumulative Model Updates: 121,468
Cumulative Timesteps: 1,013,870,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,395.92035
Policy Entropy: 1.73118
Value Function Loss: 0.08133

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.32000
Value Function Update Magnitude: 0.37466

Collected Steps per Second: 21,154.74634
Overall Steps per Second: 10,233.77297

Timestep Collection Time: 2.36448
Timestep Consumption Time: 2.52326
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.88774

Cumulative Model Updates: 121,474
Cumulative Timesteps: 1,013,920,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1013920414...
Checkpoint 1013920414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,028.55456
Policy Entropy: 1.71576
Value Function Loss: 0.07466

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08275
Policy Update Magnitude: 0.33203
Value Function Update Magnitude: 0.38554

Collected Steps per Second: 21,467.21101
Overall Steps per Second: 10,454.48834

Timestep Collection Time: 2.33044
Timestep Consumption Time: 2.45488
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.78531

Cumulative Model Updates: 121,480
Cumulative Timesteps: 1,013,970,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,571.89810
Policy Entropy: 1.70721
Value Function Loss: 0.07419

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.32993
Value Function Update Magnitude: 0.39294

Collected Steps per Second: 21,242.85476
Overall Steps per Second: 10,410.78508

Timestep Collection Time: 2.35524
Timestep Consumption Time: 2.45055
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.80579

Cumulative Model Updates: 121,486
Cumulative Timesteps: 1,014,020,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1014020474...
Checkpoint 1014020474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,944.10726
Policy Entropy: 1.70388
Value Function Loss: 0.07462

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.32371
Value Function Update Magnitude: 0.41147

Collected Steps per Second: 21,418.80347
Overall Steps per Second: 10,282.66833

Timestep Collection Time: 2.33533
Timestep Consumption Time: 2.52916
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.86450

Cumulative Model Updates: 121,492
Cumulative Timesteps: 1,014,070,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,120.25402
Policy Entropy: 1.70681
Value Function Loss: 0.07692

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.33203
Value Function Update Magnitude: 0.40801

Collected Steps per Second: 21,952.84282
Overall Steps per Second: 10,523.09350

Timestep Collection Time: 2.27870
Timestep Consumption Time: 2.47503
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.75374

Cumulative Model Updates: 121,498
Cumulative Timesteps: 1,014,120,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1014120518...
Checkpoint 1014120518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,431.24240
Policy Entropy: 1.69765
Value Function Loss: 0.07513

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.30633
Value Function Update Magnitude: 0.37495

Collected Steps per Second: 21,452.92260
Overall Steps per Second: 10,339.28069

Timestep Collection Time: 2.33180
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.83825

Cumulative Model Updates: 121,504
Cumulative Timesteps: 1,014,170,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,709.01887
Policy Entropy: 1.70106
Value Function Loss: 0.07530

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.30605
Value Function Update Magnitude: 0.36511

Collected Steps per Second: 21,507.17277
Overall Steps per Second: 10,282.44837

Timestep Collection Time: 2.32481
Timestep Consumption Time: 2.53785
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.86266

Cumulative Model Updates: 121,510
Cumulative Timesteps: 1,014,220,542

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1014220542...
Checkpoint 1014220542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,092.05102
Policy Entropy: 1.69016
Value Function Loss: 0.07123

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.29978
Value Function Update Magnitude: 0.35418

Collected Steps per Second: 21,571.16155
Overall Steps per Second: 10,401.94149

Timestep Collection Time: 2.31911
Timestep Consumption Time: 2.49018
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.80929

Cumulative Model Updates: 121,516
Cumulative Timesteps: 1,014,270,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,054.00198
Policy Entropy: 1.68315
Value Function Loss: 0.07382

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.31022
Value Function Update Magnitude: 0.35495

Collected Steps per Second: 22,109.87277
Overall Steps per Second: 10,632.29563

Timestep Collection Time: 2.26161
Timestep Consumption Time: 2.44142
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.70303

Cumulative Model Updates: 121,522
Cumulative Timesteps: 1,014,320,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1014320572...
Checkpoint 1014320572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,462.54230
Policy Entropy: 1.68025
Value Function Loss: 0.07105

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.32776
Value Function Update Magnitude: 0.35632

Collected Steps per Second: 21,773.48249
Overall Steps per Second: 10,399.71268

Timestep Collection Time: 2.29757
Timestep Consumption Time: 2.51276
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.81033

Cumulative Model Updates: 121,528
Cumulative Timesteps: 1,014,370,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,283.69081
Policy Entropy: 1.68944
Value Function Loss: 0.07567

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.33151
Value Function Update Magnitude: 0.35052

Collected Steps per Second: 22,064.21229
Overall Steps per Second: 10,667.54984

Timestep Collection Time: 2.26738
Timestep Consumption Time: 2.42235
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.68974

Cumulative Model Updates: 121,534
Cumulative Timesteps: 1,014,420,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1014420626...
Checkpoint 1014420626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,179.59086
Policy Entropy: 1.70349
Value Function Loss: 0.07888

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.33525
Value Function Update Magnitude: 0.35419

Collected Steps per Second: 20,995.87272
Overall Steps per Second: 10,347.91599

Timestep Collection Time: 2.38256
Timestep Consumption Time: 2.45165
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.83421

Cumulative Model Updates: 121,540
Cumulative Timesteps: 1,014,470,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,206.74344
Policy Entropy: 1.70776
Value Function Loss: 0.09144

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.33421
Value Function Update Magnitude: 0.37377

Collected Steps per Second: 21,644.85392
Overall Steps per Second: 10,338.90817

Timestep Collection Time: 2.31002
Timestep Consumption Time: 2.52608
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.83610

Cumulative Model Updates: 121,546
Cumulative Timesteps: 1,014,520,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1014520650...
Checkpoint 1014520650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,816.38479
Policy Entropy: 1.73382
Value Function Loss: 0.09371

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.33187
Value Function Update Magnitude: 0.39728

Collected Steps per Second: 20,901.39654
Overall Steps per Second: 10,271.83610

Timestep Collection Time: 2.39333
Timestep Consumption Time: 2.47668
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.87002

Cumulative Model Updates: 121,552
Cumulative Timesteps: 1,014,570,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,839.44727
Policy Entropy: 1.76134
Value Function Loss: 0.09880

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.33403
Value Function Update Magnitude: 0.40170

Collected Steps per Second: 21,550.36554
Overall Steps per Second: 10,457.68154

Timestep Collection Time: 2.32237
Timestep Consumption Time: 2.46339
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.78576

Cumulative Model Updates: 121,558
Cumulative Timesteps: 1,014,620,722

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1014620722...
Checkpoint 1014620722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,914.75314
Policy Entropy: 1.75859
Value Function Loss: 0.08994

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.31076
Value Function Update Magnitude: 0.39220

Collected Steps per Second: 21,540.49987
Overall Steps per Second: 10,235.23183

Timestep Collection Time: 2.32121
Timestep Consumption Time: 2.56388
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.88509

Cumulative Model Updates: 121,564
Cumulative Timesteps: 1,014,670,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,832.10958
Policy Entropy: 1.72405
Value Function Loss: 0.08486

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.28957
Value Function Update Magnitude: 0.36723

Collected Steps per Second: 21,910.97233
Overall Steps per Second: 10,410.39648

Timestep Collection Time: 2.28287
Timestep Consumption Time: 2.52194
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.80481

Cumulative Model Updates: 121,570
Cumulative Timesteps: 1,014,720,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1014720742...
Checkpoint 1014720742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,966.89095
Policy Entropy: 1.69714
Value Function Loss: 0.08270

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.31998
Value Function Update Magnitude: 0.38096

Collected Steps per Second: 21,560.22064
Overall Steps per Second: 10,344.43635

Timestep Collection Time: 2.31992
Timestep Consumption Time: 2.51534
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.83526

Cumulative Model Updates: 121,576
Cumulative Timesteps: 1,014,770,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,975.98397
Policy Entropy: 1.68368
Value Function Loss: 0.08362

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.34212
Value Function Update Magnitude: 0.38366

Collected Steps per Second: 21,972.73021
Overall Steps per Second: 10,517.65367

Timestep Collection Time: 2.27764
Timestep Consumption Time: 2.48064
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.75829

Cumulative Model Updates: 121,582
Cumulative Timesteps: 1,014,820,806

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1014820806...
Checkpoint 1014820806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,493.25183
Policy Entropy: 1.68084
Value Function Loss: 0.07590

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.33942
Value Function Update Magnitude: 0.38349

Collected Steps per Second: 21,629.09488
Overall Steps per Second: 10,520.31163

Timestep Collection Time: 2.31253
Timestep Consumption Time: 2.44189
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.75442

Cumulative Model Updates: 121,588
Cumulative Timesteps: 1,014,870,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,451.87891
Policy Entropy: 1.69253
Value Function Loss: 0.08043

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.33780
Value Function Update Magnitude: 0.36314

Collected Steps per Second: 21,166.52173
Overall Steps per Second: 10,367.61833

Timestep Collection Time: 2.36222
Timestep Consumption Time: 2.46049
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.82271

Cumulative Model Updates: 121,594
Cumulative Timesteps: 1,014,920,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1014920824...
Checkpoint 1014920824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,563.58139
Policy Entropy: 1.70275
Value Function Loss: 0.08261

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.34246
Value Function Update Magnitude: 0.37084

Collected Steps per Second: 21,572.67761
Overall Steps per Second: 10,320.48572

Timestep Collection Time: 2.31877
Timestep Consumption Time: 2.52810
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.84686

Cumulative Model Updates: 121,600
Cumulative Timesteps: 1,014,970,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,657.27372
Policy Entropy: 1.71016
Value Function Loss: 0.08193

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.33188
Value Function Update Magnitude: 0.39512

Collected Steps per Second: 21,843.18320
Overall Steps per Second: 10,392.97837

Timestep Collection Time: 2.29014
Timestep Consumption Time: 2.52311
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.81325

Cumulative Model Updates: 121,606
Cumulative Timesteps: 1,015,020,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1015020870...
Checkpoint 1015020870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,703.69174
Policy Entropy: 1.70305
Value Function Loss: 0.07916

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.33263
Value Function Update Magnitude: 0.39780

Collected Steps per Second: 21,263.58942
Overall Steps per Second: 10,292.54489

Timestep Collection Time: 2.35172
Timestep Consumption Time: 2.50675
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.85847

Cumulative Model Updates: 121,612
Cumulative Timesteps: 1,015,070,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,176.71050
Policy Entropy: 1.69772
Value Function Loss: 0.08040

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.32287
Value Function Update Magnitude: 0.38736

Collected Steps per Second: 21,419.32037
Overall Steps per Second: 10,325.02756

Timestep Collection Time: 2.33471
Timestep Consumption Time: 2.50866
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.84338

Cumulative Model Updates: 121,618
Cumulative Timesteps: 1,015,120,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1015120884...
Checkpoint 1015120884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,660.50376
Policy Entropy: 1.72243
Value Function Loss: 0.09015

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.32749
Value Function Update Magnitude: 0.37390

Collected Steps per Second: 21,261.23254
Overall Steps per Second: 10,202.63633

Timestep Collection Time: 2.35226
Timestep Consumption Time: 2.54961
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.90187

Cumulative Model Updates: 121,624
Cumulative Timesteps: 1,015,170,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,960.26709
Policy Entropy: 1.72094
Value Function Loss: 0.08747

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.32384
Value Function Update Magnitude: 0.38315

Collected Steps per Second: 21,109.03163
Overall Steps per Second: 10,373.80613

Timestep Collection Time: 2.36913
Timestep Consumption Time: 2.45167
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.82080

Cumulative Model Updates: 121,630
Cumulative Timesteps: 1,015,220,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1015220906...
Checkpoint 1015220906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,611.59494
Policy Entropy: 1.74803
Value Function Loss: 0.08913

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.31726
Value Function Update Magnitude: 0.37456

Collected Steps per Second: 21,476.74253
Overall Steps per Second: 10,381.77590

Timestep Collection Time: 2.32810
Timestep Consumption Time: 2.48803
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.81613

Cumulative Model Updates: 121,636
Cumulative Timesteps: 1,015,270,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,532.86975
Policy Entropy: 1.71404
Value Function Loss: 0.08469

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.31626
Value Function Update Magnitude: 0.36824

Collected Steps per Second: 21,806.89121
Overall Steps per Second: 10,366.86958

Timestep Collection Time: 2.29359
Timestep Consumption Time: 2.53101
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.82460

Cumulative Model Updates: 121,642
Cumulative Timesteps: 1,015,320,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1015320922...
Checkpoint 1015320922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,416.61744
Policy Entropy: 1.69924
Value Function Loss: 0.07917

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.33727
Value Function Update Magnitude: 0.37528

Collected Steps per Second: 21,560.99353
Overall Steps per Second: 10,277.23625

Timestep Collection Time: 2.32086
Timestep Consumption Time: 2.54816
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.86901

Cumulative Model Updates: 121,648
Cumulative Timesteps: 1,015,370,962

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,833.71127
Policy Entropy: 1.64970
Value Function Loss: 0.07886

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.34249
Value Function Update Magnitude: 0.36274

Collected Steps per Second: 22,097.27448
Overall Steps per Second: 10,411.80950

Timestep Collection Time: 2.26381
Timestep Consumption Time: 2.54074
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.80454

Cumulative Model Updates: 121,654
Cumulative Timesteps: 1,015,420,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1015420986...
Checkpoint 1015420986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,357.25175
Policy Entropy: 1.66708
Value Function Loss: 0.07893

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.34425
Value Function Update Magnitude: 0.35724

Collected Steps per Second: 21,429.29656
Overall Steps per Second: 10,299.34621

Timestep Collection Time: 2.33456
Timestep Consumption Time: 2.52283
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.85740

Cumulative Model Updates: 121,660
Cumulative Timesteps: 1,015,471,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,609.81812
Policy Entropy: 1.67966
Value Function Loss: 0.07945

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.34281
Value Function Update Magnitude: 0.36589

Collected Steps per Second: 21,793.68385
Overall Steps per Second: 10,369.80370

Timestep Collection Time: 2.29635
Timestep Consumption Time: 2.52977
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.82613

Cumulative Model Updates: 121,666
Cumulative Timesteps: 1,015,521,060

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1015521060...
Checkpoint 1015521060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,197.87781
Policy Entropy: 1.69296
Value Function Loss: 0.07152

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.33647
Value Function Update Magnitude: 0.36470

Collected Steps per Second: 21,634.76598
Overall Steps per Second: 10,369.10856

Timestep Collection Time: 2.31294
Timestep Consumption Time: 2.51293
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.82587

Cumulative Model Updates: 121,672
Cumulative Timesteps: 1,015,571,100

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,596.99295
Policy Entropy: 1.68512
Value Function Loss: 0.07136

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.32583
Value Function Update Magnitude: 0.35614

Collected Steps per Second: 22,059.40518
Overall Steps per Second: 10,492.68117

Timestep Collection Time: 2.26788
Timestep Consumption Time: 2.50002
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.76789

Cumulative Model Updates: 121,678
Cumulative Timesteps: 1,015,621,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1015621128...
Checkpoint 1015621128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,922.89448
Policy Entropy: 1.69490
Value Function Loss: 0.07641

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.33105
Value Function Update Magnitude: 0.35427

Collected Steps per Second: 21,810.61611
Overall Steps per Second: 10,431.82533

Timestep Collection Time: 2.29274
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.79360

Cumulative Model Updates: 121,684
Cumulative Timesteps: 1,015,671,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,194.31255
Policy Entropy: 1.69878
Value Function Loss: 0.07354

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.33155
Value Function Update Magnitude: 0.36386

Collected Steps per Second: 21,890.82445
Overall Steps per Second: 10,469.23083

Timestep Collection Time: 2.28598
Timestep Consumption Time: 2.49393
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.77991

Cumulative Model Updates: 121,690
Cumulative Timesteps: 1,015,721,176

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1015721176...
Checkpoint 1015721176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,984.27067
Policy Entropy: 1.69055
Value Function Loss: 0.07416

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.33098
Value Function Update Magnitude: 0.36424

Collected Steps per Second: 20,889.40196
Overall Steps per Second: 10,197.58930

Timestep Collection Time: 2.39394
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.90390

Cumulative Model Updates: 121,696
Cumulative Timesteps: 1,015,771,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,947.86581
Policy Entropy: 1.67952
Value Function Loss: 0.07134

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.32817
Value Function Update Magnitude: 0.35075

Collected Steps per Second: 21,117.91528
Overall Steps per Second: 10,388.19934

Timestep Collection Time: 2.36842
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.81469

Cumulative Model Updates: 121,702
Cumulative Timesteps: 1,015,821,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1015821200...
Checkpoint 1015821200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,372.91087
Policy Entropy: 1.68466
Value Function Loss: 0.07666

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.32825
Value Function Update Magnitude: 0.34006

Collected Steps per Second: 20,958.49696
Overall Steps per Second: 10,280.47562

Timestep Collection Time: 2.38653
Timestep Consumption Time: 2.47881
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.86534

Cumulative Model Updates: 121,708
Cumulative Timesteps: 1,015,871,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,576.55285
Policy Entropy: 1.69006
Value Function Loss: 0.07582

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.33227
Value Function Update Magnitude: 0.35181

Collected Steps per Second: 21,625.89230
Overall Steps per Second: 10,535.21722

Timestep Collection Time: 2.31269
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.74732

Cumulative Model Updates: 121,714
Cumulative Timesteps: 1,015,921,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1015921232...
Checkpoint 1015921232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,887.13467
Policy Entropy: 1.69359
Value Function Loss: 0.07640

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.33436
Value Function Update Magnitude: 0.35033

Collected Steps per Second: 21,312.51192
Overall Steps per Second: 10,308.90566

Timestep Collection Time: 2.34820
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.85464

Cumulative Model Updates: 121,720
Cumulative Timesteps: 1,015,971,278

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,577.80458
Policy Entropy: 1.69569
Value Function Loss: 0.07598

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08276
Policy Update Magnitude: 0.33267
Value Function Update Magnitude: 0.31254

Collected Steps per Second: 21,503.90207
Overall Steps per Second: 10,284.55251

Timestep Collection Time: 2.32665
Timestep Consumption Time: 2.53812
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.86477

Cumulative Model Updates: 121,726
Cumulative Timesteps: 1,016,021,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1016021310...
Checkpoint 1016021310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,173.58750
Policy Entropy: 1.68654
Value Function Loss: 0.07294

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.33009
Value Function Update Magnitude: 0.34467

Collected Steps per Second: 21,534.62048
Overall Steps per Second: 10,264.85156

Timestep Collection Time: 2.32268
Timestep Consumption Time: 2.55007
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.87274

Cumulative Model Updates: 121,732
Cumulative Timesteps: 1,016,071,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,743.76908
Policy Entropy: 1.69511
Value Function Loss: 0.07738

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.32628
Value Function Update Magnitude: 0.33394

Collected Steps per Second: 21,683.06469
Overall Steps per Second: 10,393.61690

Timestep Collection Time: 2.30742
Timestep Consumption Time: 2.50630
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.81372

Cumulative Model Updates: 121,738
Cumulative Timesteps: 1,016,121,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1016121360...
Checkpoint 1016121360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,268.34510
Policy Entropy: 1.70950
Value Function Loss: 0.08115

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.31851
Value Function Update Magnitude: 0.32447

Collected Steps per Second: 21,844.47405
Overall Steps per Second: 10,567.70002

Timestep Collection Time: 2.28973
Timestep Consumption Time: 2.44337
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.73310

Cumulative Model Updates: 121,744
Cumulative Timesteps: 1,016,171,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,547.56057
Policy Entropy: 1.72148
Value Function Loss: 0.07825

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.30369
Value Function Update Magnitude: 0.31315

Collected Steps per Second: 21,307.16318
Overall Steps per Second: 10,431.49842

Timestep Collection Time: 2.34682
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.79356

Cumulative Model Updates: 121,750
Cumulative Timesteps: 1,016,221,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1016221382...
Checkpoint 1016221382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,223.35108
Policy Entropy: 1.68734
Value Function Loss: 0.06784

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.29531
Value Function Update Magnitude: 0.32971

Collected Steps per Second: 21,527.01175
Overall Steps per Second: 10,313.65627

Timestep Collection Time: 2.32276
Timestep Consumption Time: 2.52538
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.84814

Cumulative Model Updates: 121,756
Cumulative Timesteps: 1,016,271,384

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,454.30337
Policy Entropy: 1.67057
Value Function Loss: 0.06532

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.30408
Value Function Update Magnitude: 0.33348

Collected Steps per Second: 21,806.85535
Overall Steps per Second: 10,447.75764

Timestep Collection Time: 2.29377
Timestep Consumption Time: 2.49386
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.78763

Cumulative Model Updates: 121,762
Cumulative Timesteps: 1,016,321,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1016321404...
Checkpoint 1016321404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,565.06577
Policy Entropy: 1.66796
Value Function Loss: 0.07052

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.30434
Value Function Update Magnitude: 0.34798

Collected Steps per Second: 21,187.39826
Overall Steps per Second: 10,581.51449

Timestep Collection Time: 2.36074
Timestep Consumption Time: 2.36618
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.72692

Cumulative Model Updates: 121,768
Cumulative Timesteps: 1,016,371,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,584.84659
Policy Entropy: 1.68275
Value Function Loss: 0.07201

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.31518
Value Function Update Magnitude: 0.34237

Collected Steps per Second: 20,663.38344
Overall Steps per Second: 10,436.58308

Timestep Collection Time: 2.42022
Timestep Consumption Time: 2.37158
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.79180

Cumulative Model Updates: 121,774
Cumulative Timesteps: 1,016,421,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1016421432...
Checkpoint 1016421432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,955.98052
Policy Entropy: 1.67484
Value Function Loss: 0.07239

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09703
Policy Update Magnitude: 0.30472
Value Function Update Magnitude: 0.31116

Collected Steps per Second: 20,270.94206
Overall Steps per Second: 10,266.20850

Timestep Collection Time: 2.46718
Timestep Consumption Time: 2.40434
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.87152

Cumulative Model Updates: 121,780
Cumulative Timesteps: 1,016,471,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,148.85769
Policy Entropy: 1.66283
Value Function Loss: 0.06989

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.30222
Value Function Update Magnitude: 0.29354

Collected Steps per Second: 20,464.63644
Overall Steps per Second: 10,396.67925

Timestep Collection Time: 2.44422
Timestep Consumption Time: 2.36694
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.81115

Cumulative Model Updates: 121,786
Cumulative Timesteps: 1,016,521,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1016521464...
Checkpoint 1016521464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,458.12406
Policy Entropy: 1.64596
Value Function Loss: 0.06831

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08888
Policy Update Magnitude: 0.31562
Value Function Update Magnitude: 0.31728

Collected Steps per Second: 20,894.96117
Overall Steps per Second: 10,354.84107

Timestep Collection Time: 2.39512
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.83310

Cumulative Model Updates: 121,792
Cumulative Timesteps: 1,016,571,510

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,347.13317
Policy Entropy: 1.65526
Value Function Loss: 0.07087

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.30242
Value Function Update Magnitude: 0.31457

Collected Steps per Second: 21,340.93321
Overall Steps per Second: 10,363.48978

Timestep Collection Time: 2.34320
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.82521

Cumulative Model Updates: 121,798
Cumulative Timesteps: 1,016,621,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1016621516...
Checkpoint 1016621516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,497.05187
Policy Entropy: 1.64991
Value Function Loss: 0.07002

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.30321
Value Function Update Magnitude: 0.30059

Collected Steps per Second: 21,287.42425
Overall Steps per Second: 10,322.60430

Timestep Collection Time: 2.34880
Timestep Consumption Time: 2.49493
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.84374

Cumulative Model Updates: 121,804
Cumulative Timesteps: 1,016,671,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,077.95846
Policy Entropy: 1.66527
Value Function Loss: 0.07417

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.31573
Value Function Update Magnitude: 0.28545

Collected Steps per Second: 21,878.12797
Overall Steps per Second: 10,514.10005

Timestep Collection Time: 2.28603
Timestep Consumption Time: 2.47082
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.75685

Cumulative Model Updates: 121,810
Cumulative Timesteps: 1,016,721,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1016721530...
Checkpoint 1016721530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,862.11062
Policy Entropy: 1.65091
Value Function Loss: 0.07075

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.32811
Value Function Update Magnitude: 0.28035

Collected Steps per Second: 21,723.27343
Overall Steps per Second: 10,405.88745

Timestep Collection Time: 2.30251
Timestep Consumption Time: 2.50419
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.80670

Cumulative Model Updates: 121,816
Cumulative Timesteps: 1,016,771,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,244.33164
Policy Entropy: 1.66821
Value Function Loss: 0.07839

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.33130
Value Function Update Magnitude: 0.29636

Collected Steps per Second: 21,939.60299
Overall Steps per Second: 10,483.17351

Timestep Collection Time: 2.28035
Timestep Consumption Time: 2.49206
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.77241

Cumulative Model Updates: 121,822
Cumulative Timesteps: 1,016,821,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1016821578...
Checkpoint 1016821578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,612.69475
Policy Entropy: 1.67476
Value Function Loss: 0.07329

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.33183
Value Function Update Magnitude: 0.34133

Collected Steps per Second: 21,846.99064
Overall Steps per Second: 10,561.86603

Timestep Collection Time: 2.29038
Timestep Consumption Time: 2.44723
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.73761

Cumulative Model Updates: 121,828
Cumulative Timesteps: 1,016,871,616

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,339.43413
Policy Entropy: 1.68680
Value Function Loss: 0.06957

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.32377
Value Function Update Magnitude: 0.36304

Collected Steps per Second: 21,799.20777
Overall Steps per Second: 10,563.61712

Timestep Collection Time: 2.29458
Timestep Consumption Time: 2.44054
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.73512

Cumulative Model Updates: 121,834
Cumulative Timesteps: 1,016,921,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1016921636...
Checkpoint 1016921636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,938.16342
Policy Entropy: 1.70098
Value Function Loss: 0.07227

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.32310
Value Function Update Magnitude: 0.34044

Collected Steps per Second: 21,596.20902
Overall Steps per Second: 10,539.57036

Timestep Collection Time: 2.31568
Timestep Consumption Time: 2.42929
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.74498

Cumulative Model Updates: 121,840
Cumulative Timesteps: 1,016,971,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,417.48338
Policy Entropy: 1.70650
Value Function Loss: 0.07928

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.32858
Value Function Update Magnitude: 0.33239

Collected Steps per Second: 21,321.51177
Overall Steps per Second: 10,483.16221

Timestep Collection Time: 2.34618
Timestep Consumption Time: 2.42567
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.77184

Cumulative Model Updates: 121,846
Cumulative Timesteps: 1,017,021,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1017021670...
Checkpoint 1017021670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,491.36135
Policy Entropy: 1.70412
Value Function Loss: 0.07844

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08639
Policy Update Magnitude: 0.33081
Value Function Update Magnitude: 0.33983

Collected Steps per Second: 21,328.39262
Overall Steps per Second: 10,250.63796

Timestep Collection Time: 2.34439
Timestep Consumption Time: 2.53355
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.87794

Cumulative Model Updates: 121,852
Cumulative Timesteps: 1,017,071,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,551.26065
Policy Entropy: 1.69024
Value Function Loss: 0.07673

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.32573
Value Function Update Magnitude: 0.31610

Collected Steps per Second: 21,427.54334
Overall Steps per Second: 10,462.47657

Timestep Collection Time: 2.33373
Timestep Consumption Time: 2.44583
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.77956

Cumulative Model Updates: 121,858
Cumulative Timesteps: 1,017,121,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1017121678...
Checkpoint 1017121678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,079.11613
Policy Entropy: 1.68093
Value Function Loss: 0.07817

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.31440
Value Function Update Magnitude: 0.27300

Collected Steps per Second: 21,323.21934
Overall Steps per Second: 10,189.45565

Timestep Collection Time: 2.34627
Timestep Consumption Time: 2.56371
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.90998

Cumulative Model Updates: 121,864
Cumulative Timesteps: 1,017,171,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,803.77278
Policy Entropy: 1.67548
Value Function Loss: 0.07470

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.30648
Value Function Update Magnitude: 0.26358

Collected Steps per Second: 21,804.33939
Overall Steps per Second: 10,429.04467

Timestep Collection Time: 2.29340
Timestep Consumption Time: 2.50148
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.79488

Cumulative Model Updates: 121,870
Cumulative Timesteps: 1,017,221,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1017221714...
Checkpoint 1017221714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,278.25873
Policy Entropy: 1.66505
Value Function Loss: 0.07355

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.31710
Value Function Update Magnitude: 0.26471

Collected Steps per Second: 21,677.77127
Overall Steps per Second: 10,371.23072

Timestep Collection Time: 2.30762
Timestep Consumption Time: 2.51573
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.82334

Cumulative Model Updates: 121,876
Cumulative Timesteps: 1,017,271,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,030.04788
Policy Entropy: 1.66492
Value Function Loss: 0.07442

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.32677
Value Function Update Magnitude: 0.30459

Collected Steps per Second: 22,094.55790
Overall Steps per Second: 10,496.13443

Timestep Collection Time: 2.26300
Timestep Consumption Time: 2.50066
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.76366

Cumulative Model Updates: 121,882
Cumulative Timesteps: 1,017,321,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1017321738...
Checkpoint 1017321738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,119.42146
Policy Entropy: 1.66721
Value Function Loss: 0.07059

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.33008
Value Function Update Magnitude: 0.35265

Collected Steps per Second: 21,957.17065
Overall Steps per Second: 10,439.76808

Timestep Collection Time: 2.27798
Timestep Consumption Time: 2.51312
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.79110

Cumulative Model Updates: 121,888
Cumulative Timesteps: 1,017,371,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,113.31630
Policy Entropy: 1.69294
Value Function Loss: 0.06961

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.32926
Value Function Update Magnitude: 0.36058

Collected Steps per Second: 21,976.65251
Overall Steps per Second: 10,455.42390

Timestep Collection Time: 2.27569
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.78335

Cumulative Model Updates: 121,894
Cumulative Timesteps: 1,017,421,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1017421768...
Checkpoint 1017421768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,908.27088
Policy Entropy: 1.69759
Value Function Loss: 0.07210

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07773
Policy Update Magnitude: 0.33006
Value Function Update Magnitude: 0.35417

Collected Steps per Second: 21,681.70566
Overall Steps per Second: 10,545.44305

Timestep Collection Time: 2.30729
Timestep Consumption Time: 2.43656
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.74385

Cumulative Model Updates: 121,900
Cumulative Timesteps: 1,017,471,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,295.16259
Policy Entropy: 1.67847
Value Function Loss: 0.07350

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.32880
Value Function Update Magnitude: 0.33404

Collected Steps per Second: 21,304.09798
Overall Steps per Second: 10,302.53688

Timestep Collection Time: 2.34697
Timestep Consumption Time: 2.50621
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.85317

Cumulative Model Updates: 121,906
Cumulative Timesteps: 1,017,521,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1017521794...
Checkpoint 1017521794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,514.07375
Policy Entropy: 1.66917
Value Function Loss: 0.07564

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.32910
Value Function Update Magnitude: 0.32885

Collected Steps per Second: 20,842.03869
Overall Steps per Second: 10,513.73314

Timestep Collection Time: 2.40034
Timestep Consumption Time: 2.35801
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.75835

Cumulative Model Updates: 121,912
Cumulative Timesteps: 1,017,571,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,796.65309
Policy Entropy: 1.66218
Value Function Loss: 0.06818

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.32727
Value Function Update Magnitude: 0.31089

Collected Steps per Second: 20,859.72399
Overall Steps per Second: 10,355.46280

Timestep Collection Time: 2.39716
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.82876

Cumulative Model Updates: 121,918
Cumulative Timesteps: 1,017,621,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1017621826...
Checkpoint 1017621826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,425.27135
Policy Entropy: 1.70050
Value Function Loss: 0.07391

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.32693
Value Function Update Magnitude: 0.30960

Collected Steps per Second: 20,464.78369
Overall Steps per Second: 10,226.24018

Timestep Collection Time: 2.44449
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.89192

Cumulative Model Updates: 121,924
Cumulative Timesteps: 1,017,671,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,581.83373
Policy Entropy: 1.70045
Value Function Loss: 0.07604

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.33019
Value Function Update Magnitude: 0.33164

Collected Steps per Second: 20,742.50365
Overall Steps per Second: 10,448.14695

Timestep Collection Time: 2.41099
Timestep Consumption Time: 2.37550
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.78649

Cumulative Model Updates: 121,930
Cumulative Timesteps: 1,017,721,862

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1017721862...
Checkpoint 1017721862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,181.77757
Policy Entropy: 1.69308
Value Function Loss: 0.07803

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.33331
Value Function Update Magnitude: 0.34014

Collected Steps per Second: 20,506.15787
Overall Steps per Second: 10,242.77233

Timestep Collection Time: 2.44024
Timestep Consumption Time: 2.44515
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.88540

Cumulative Model Updates: 121,936
Cumulative Timesteps: 1,017,771,902

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,030.33025
Policy Entropy: 1.68825
Value Function Loss: 0.07584

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.32368
Value Function Update Magnitude: 0.33879

Collected Steps per Second: 20,826.08789
Overall Steps per Second: 10,204.09308

Timestep Collection Time: 2.40208
Timestep Consumption Time: 2.50046
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.90254

Cumulative Model Updates: 121,942
Cumulative Timesteps: 1,017,821,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1017821928...
Checkpoint 1017821928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,981.46795
Policy Entropy: 1.69115
Value Function Loss: 0.07169

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.31913
Value Function Update Magnitude: 0.33512

Collected Steps per Second: 21,814.27254
Overall Steps per Second: 10,394.02492

Timestep Collection Time: 2.29235
Timestep Consumption Time: 2.51868
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.81103

Cumulative Model Updates: 121,948
Cumulative Timesteps: 1,017,871,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,819.42734
Policy Entropy: 1.68846
Value Function Loss: 0.07301

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.31643
Value Function Update Magnitude: 0.34634

Collected Steps per Second: 21,858.36580
Overall Steps per Second: 10,487.68050

Timestep Collection Time: 2.28809
Timestep Consumption Time: 2.48074
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.76883

Cumulative Model Updates: 121,954
Cumulative Timesteps: 1,017,921,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1017921948...
Checkpoint 1017921948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,021.66114
Policy Entropy: 1.69010
Value Function Loss: 0.07228

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.31374
Value Function Update Magnitude: 0.36023

Collected Steps per Second: 21,537.95913
Overall Steps per Second: 10,566.10006

Timestep Collection Time: 2.32176
Timestep Consumption Time: 2.41092
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.73268

Cumulative Model Updates: 121,960
Cumulative Timesteps: 1,017,971,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,783.48892
Policy Entropy: 1.69092
Value Function Loss: 0.07268

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.31863
Value Function Update Magnitude: 0.35995

Collected Steps per Second: 21,828.10654
Overall Steps per Second: 10,512.15574

Timestep Collection Time: 2.29172
Timestep Consumption Time: 2.46696
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.75868

Cumulative Model Updates: 121,966
Cumulative Timesteps: 1,018,021,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1018021978...
Checkpoint 1018021978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,601.59236
Policy Entropy: 1.69762
Value Function Loss: 0.07192

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.32477
Value Function Update Magnitude: 0.34941

Collected Steps per Second: 21,792.44849
Overall Steps per Second: 10,603.59940

Timestep Collection Time: 2.29529
Timestep Consumption Time: 2.42198
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.71727

Cumulative Model Updates: 121,972
Cumulative Timesteps: 1,018,071,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,827.76219
Policy Entropy: 1.68766
Value Function Loss: 0.07558

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.32152
Value Function Update Magnitude: 0.34167

Collected Steps per Second: 21,816.65076
Overall Steps per Second: 10,573.16488

Timestep Collection Time: 2.29384
Timestep Consumption Time: 2.43927
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.73311

Cumulative Model Updates: 121,978
Cumulative Timesteps: 1,018,122,042

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1018122042...
Checkpoint 1018122042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,565.55765
Policy Entropy: 1.68126
Value Function Loss: 0.07287

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.32688
Value Function Update Magnitude: 0.32924

Collected Steps per Second: 21,697.18904
Overall Steps per Second: 10,534.13605

Timestep Collection Time: 2.30518
Timestep Consumption Time: 2.44281
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.74799

Cumulative Model Updates: 121,984
Cumulative Timesteps: 1,018,172,058

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,582.55673
Policy Entropy: 1.66098
Value Function Loss: 0.07341

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.32934
Value Function Update Magnitude: 0.29420

Collected Steps per Second: 21,410.20282
Overall Steps per Second: 10,445.71504

Timestep Collection Time: 2.33543
Timestep Consumption Time: 2.45141
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.78684

Cumulative Model Updates: 121,990
Cumulative Timesteps: 1,018,222,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1018222060...
Checkpoint 1018222060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,099.56964
Policy Entropy: 1.65170
Value Function Loss: 0.07291

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.32804
Value Function Update Magnitude: 0.30925

Collected Steps per Second: 21,224.89208
Overall Steps per Second: 10,254.15407

Timestep Collection Time: 2.35676
Timestep Consumption Time: 2.52146
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.87822

Cumulative Model Updates: 121,996
Cumulative Timesteps: 1,018,272,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,837.55233
Policy Entropy: 1.65080
Value Function Loss: 0.07608

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08341
Policy Update Magnitude: 0.33161
Value Function Update Magnitude: 0.33374

Collected Steps per Second: 21,345.07684
Overall Steps per Second: 10,528.62413

Timestep Collection Time: 2.34424
Timestep Consumption Time: 2.40833
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.75257

Cumulative Model Updates: 122,002
Cumulative Timesteps: 1,018,322,120

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1018322120...
Checkpoint 1018322120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,667.45399
Policy Entropy: 1.67220
Value Function Loss: 0.07379

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.33422
Value Function Update Magnitude: 0.36087

Collected Steps per Second: 21,333.14364
Overall Steps per Second: 10,312.84014

Timestep Collection Time: 2.34480
Timestep Consumption Time: 2.50566
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.85046

Cumulative Model Updates: 122,008
Cumulative Timesteps: 1,018,372,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,400.50660
Policy Entropy: 1.68591
Value Function Loss: 0.07220

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.33181
Value Function Update Magnitude: 0.36871

Collected Steps per Second: 21,264.30028
Overall Steps per Second: 10,318.21248

Timestep Collection Time: 2.35202
Timestep Consumption Time: 2.49514
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.84716

Cumulative Model Updates: 122,014
Cumulative Timesteps: 1,018,422,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1018422156...
Checkpoint 1018422156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,190.41248
Policy Entropy: 1.67130
Value Function Loss: 0.07193

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.32991
Value Function Update Magnitude: 0.36841

Collected Steps per Second: 21,591.03098
Overall Steps per Second: 10,285.42909

Timestep Collection Time: 2.31578
Timestep Consumption Time: 2.54547
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.86125

Cumulative Model Updates: 122,020
Cumulative Timesteps: 1,018,472,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,458.77382
Policy Entropy: 1.67623
Value Function Loss: 0.07856

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.32897
Value Function Update Magnitude: 0.37901

Collected Steps per Second: 21,891.03136
Overall Steps per Second: 10,405.33898

Timestep Collection Time: 2.28523
Timestep Consumption Time: 2.52250
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.80772

Cumulative Model Updates: 122,026
Cumulative Timesteps: 1,018,522,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1018522182...
Checkpoint 1018522182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,125.34536
Policy Entropy: 1.67248
Value Function Loss: 0.07451

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.31542
Value Function Update Magnitude: 0.38722

Collected Steps per Second: 21,700.12576
Overall Steps per Second: 10,519.90450

Timestep Collection Time: 2.30496
Timestep Consumption Time: 2.44964
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.75461

Cumulative Model Updates: 122,032
Cumulative Timesteps: 1,018,572,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,274.48067
Policy Entropy: 1.67865
Value Function Loss: 0.07339

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.31668
Value Function Update Magnitude: 0.37669

Collected Steps per Second: 21,885.91544
Overall Steps per Second: 10,571.03344

Timestep Collection Time: 2.28512
Timestep Consumption Time: 2.44592
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.73104

Cumulative Model Updates: 122,038
Cumulative Timesteps: 1,018,622,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1018622212...
Checkpoint 1018622212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,391.54768
Policy Entropy: 1.67450
Value Function Loss: 0.07295

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.28359
Value Function Update Magnitude: 0.37253

Collected Steps per Second: 20,970.99428
Overall Steps per Second: 10,182.28062

Timestep Collection Time: 2.38444
Timestep Consumption Time: 2.52645
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.91088

Cumulative Model Updates: 122,044
Cumulative Timesteps: 1,018,672,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,192.55753
Policy Entropy: 1.67660
Value Function Loss: 0.07073

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.28451
Value Function Update Magnitude: 0.36897

Collected Steps per Second: 21,287.27507
Overall Steps per Second: 10,414.49971

Timestep Collection Time: 2.35014
Timestep Consumption Time: 2.45355
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.80369

Cumulative Model Updates: 122,050
Cumulative Timesteps: 1,018,722,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1018722244...
Checkpoint 1018722244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,566.68652
Policy Entropy: 1.69142
Value Function Loss: 0.07073

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.29945
Value Function Update Magnitude: 0.36971

Collected Steps per Second: 21,315.93025
Overall Steps per Second: 10,296.85483

Timestep Collection Time: 2.34595
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.85643

Cumulative Model Updates: 122,056
Cumulative Timesteps: 1,018,772,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,772.94909
Policy Entropy: 1.67965
Value Function Loss: 0.06496

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.31698
Value Function Update Magnitude: 0.34433

Collected Steps per Second: 21,526.51178
Overall Steps per Second: 10,372.79081

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.49829
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.82165

Cumulative Model Updates: 122,062
Cumulative Timesteps: 1,018,822,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1018822264...
Checkpoint 1018822264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,363.08929
Policy Entropy: 1.67676
Value Function Loss: 0.06843

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.31488
Value Function Update Magnitude: 0.33711

Collected Steps per Second: 21,622.27964
Overall Steps per Second: 10,299.83309

Timestep Collection Time: 2.31326
Timestep Consumption Time: 2.54293
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.85620

Cumulative Model Updates: 122,068
Cumulative Timesteps: 1,018,872,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,908.81683
Policy Entropy: 1.68562
Value Function Loss: 0.06863

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.31217
Value Function Update Magnitude: 0.34757

Collected Steps per Second: 21,687.51911
Overall Steps per Second: 10,365.40326

Timestep Collection Time: 2.30658
Timestep Consumption Time: 2.51947
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.82605

Cumulative Model Updates: 122,074
Cumulative Timesteps: 1,018,922,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1018922306...
Checkpoint 1018922306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,815.46444
Policy Entropy: 1.67260
Value Function Loss: 0.06995

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09307
Policy Update Magnitude: 0.31557
Value Function Update Magnitude: 0.35339

Collected Steps per Second: 21,698.92066
Overall Steps per Second: 10,536.93647

Timestep Collection Time: 2.30482
Timestep Consumption Time: 2.44154
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.74635

Cumulative Model Updates: 122,080
Cumulative Timesteps: 1,018,972,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,537.11259
Policy Entropy: 1.66570
Value Function Loss: 0.07662

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.32231
Value Function Update Magnitude: 0.36069

Collected Steps per Second: 21,685.85455
Overall Steps per Second: 10,503.93548

Timestep Collection Time: 2.30694
Timestep Consumption Time: 2.45584
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.76279

Cumulative Model Updates: 122,086
Cumulative Timesteps: 1,019,022,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1019022346...
Checkpoint 1019022346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,527.89755
Policy Entropy: 1.65277
Value Function Loss: 0.07634

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.30530
Value Function Update Magnitude: 0.37040

Collected Steps per Second: 21,393.31196
Overall Steps per Second: 10,263.50319

Timestep Collection Time: 2.33737
Timestep Consumption Time: 2.53465
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.87202

Cumulative Model Updates: 122,092
Cumulative Timesteps: 1,019,072,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,595.06332
Policy Entropy: 1.66506
Value Function Loss: 0.07872

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.30471
Value Function Update Magnitude: 0.37486

Collected Steps per Second: 21,563.80991
Overall Steps per Second: 10,438.44647

Timestep Collection Time: 2.31963
Timestep Consumption Time: 2.47227
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.79190

Cumulative Model Updates: 122,098
Cumulative Timesteps: 1,019,122,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1019122370...
Checkpoint 1019122370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,867.88151
Policy Entropy: 1.66757
Value Function Loss: 0.07048

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.32090
Value Function Update Magnitude: 0.38263

Collected Steps per Second: 21,712.77267
Overall Steps per Second: 10,558.41696

Timestep Collection Time: 2.30408
Timestep Consumption Time: 2.43413
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.73821

Cumulative Model Updates: 122,104
Cumulative Timesteps: 1,019,172,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,249.58075
Policy Entropy: 1.66447
Value Function Loss: 0.06503

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.32695
Value Function Update Magnitude: 0.38556

Collected Steps per Second: 21,828.43269
Overall Steps per Second: 10,535.34884

Timestep Collection Time: 2.29224
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.74934

Cumulative Model Updates: 122,110
Cumulative Timesteps: 1,019,222,434

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1019222434...
Checkpoint 1019222434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,759.68979
Policy Entropy: 1.68047
Value Function Loss: 0.06413

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.32016
Value Function Update Magnitude: 0.36731

Collected Steps per Second: 21,462.76716
Overall Steps per Second: 10,336.38949

Timestep Collection Time: 2.32980
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.83767

Cumulative Model Updates: 122,116
Cumulative Timesteps: 1,019,272,438

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,417.84329
Policy Entropy: 1.68963
Value Function Loss: 0.06811

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.31819
Value Function Update Magnitude: 0.35354

Collected Steps per Second: 20,254.30477
Overall Steps per Second: 10,328.56954

Timestep Collection Time: 2.46989
Timestep Consumption Time: 2.37356
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.84346

Cumulative Model Updates: 122,122
Cumulative Timesteps: 1,019,322,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1019322464...
Checkpoint 1019322464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,285.94746
Policy Entropy: 1.69437
Value Function Loss: 0.07256

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.31858
Value Function Update Magnitude: 0.36533

Collected Steps per Second: 20,673.16290
Overall Steps per Second: 10,315.63927

Timestep Collection Time: 2.42082
Timestep Consumption Time: 2.43065
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.85147

Cumulative Model Updates: 122,128
Cumulative Timesteps: 1,019,372,510

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,561.67191
Policy Entropy: 1.67916
Value Function Loss: 0.07225

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.30986
Value Function Update Magnitude: 0.36050

Collected Steps per Second: 20,707.84854
Overall Steps per Second: 10,344.13848

Timestep Collection Time: 2.41638
Timestep Consumption Time: 2.42095
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.83733

Cumulative Model Updates: 122,134
Cumulative Timesteps: 1,019,422,548

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1019422548...
Checkpoint 1019422548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,705.39699
Policy Entropy: 1.67831
Value Function Loss: 0.07047

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.28871
Value Function Update Magnitude: 0.34026

Collected Steps per Second: 20,863.32959
Overall Steps per Second: 10,318.05167

Timestep Collection Time: 2.39655
Timestep Consumption Time: 2.44933
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.84588

Cumulative Model Updates: 122,140
Cumulative Timesteps: 1,019,472,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,101.23107
Policy Entropy: 1.68194
Value Function Loss: 0.07001

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.30514
Value Function Update Magnitude: 0.32775

Collected Steps per Second: 21,107.12399
Overall Steps per Second: 10,358.65534

Timestep Collection Time: 2.36896
Timestep Consumption Time: 2.45811
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.82707

Cumulative Model Updates: 122,146
Cumulative Timesteps: 1,019,522,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1019522550...
Checkpoint 1019522550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,288.76116
Policy Entropy: 1.69190
Value Function Loss: 0.07198

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.31911
Value Function Update Magnitude: 0.33709

Collected Steps per Second: 21,358.30481
Overall Steps per Second: 10,280.19039

Timestep Collection Time: 2.34110
Timestep Consumption Time: 2.52281
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.86392

Cumulative Model Updates: 122,152
Cumulative Timesteps: 1,019,572,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,089.87599
Policy Entropy: 1.69496
Value Function Loss: 0.07037

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.31176
Value Function Update Magnitude: 0.35374

Collected Steps per Second: 21,953.21635
Overall Steps per Second: 10,464.51620

Timestep Collection Time: 2.27775
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.77843

Cumulative Model Updates: 122,158
Cumulative Timesteps: 1,019,622,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1019622556...
Checkpoint 1019622556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,856.58346
Policy Entropy: 1.69098
Value Function Loss: 0.07293

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.32365
Value Function Update Magnitude: 0.34229

Collected Steps per Second: 21,651.23555
Overall Steps per Second: 10,581.68723

Timestep Collection Time: 2.31118
Timestep Consumption Time: 2.41774
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.72892

Cumulative Model Updates: 122,164
Cumulative Timesteps: 1,019,672,596

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,736.18740
Policy Entropy: 1.69659
Value Function Loss: 0.07260

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.33020
Value Function Update Magnitude: 0.33642

Collected Steps per Second: 21,804.71560
Overall Steps per Second: 10,389.45909

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.52009
PPO Batch Consumption Time: 0.30163
Total Iteration Time: 4.81373

Cumulative Model Updates: 122,170
Cumulative Timesteps: 1,019,722,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1019722608...
Checkpoint 1019722608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,726.55726
Policy Entropy: 1.70158
Value Function Loss: 0.07770

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 0.33130
Value Function Update Magnitude: 0.32481

Collected Steps per Second: 21,600.51704
Overall Steps per Second: 10,599.73698

Timestep Collection Time: 2.31578
Timestep Consumption Time: 2.40340
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.71917

Cumulative Model Updates: 122,176
Cumulative Timesteps: 1,019,772,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,045.40021
Policy Entropy: 1.70486
Value Function Loss: 0.07356

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.32938
Value Function Update Magnitude: 0.33092

Collected Steps per Second: 21,969.58180
Overall Steps per Second: 10,478.22866

Timestep Collection Time: 2.27587
Timestep Consumption Time: 2.49592
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.77180

Cumulative Model Updates: 122,182
Cumulative Timesteps: 1,019,822,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1019822630...
Checkpoint 1019822630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,217.84550
Policy Entropy: 1.69685
Value Function Loss: 0.07014

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.32365

Collected Steps per Second: 21,524.97849
Overall Steps per Second: 10,343.78066

Timestep Collection Time: 2.32353
Timestep Consumption Time: 2.51164
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.83518

Cumulative Model Updates: 122,188
Cumulative Timesteps: 1,019,872,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,845.49360
Policy Entropy: 1.70122
Value Function Loss: 0.07142

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.30689
Value Function Update Magnitude: 0.30269

Collected Steps per Second: 21,071.09666
Overall Steps per Second: 10,411.59530

Timestep Collection Time: 2.37330
Timestep Consumption Time: 2.42981
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.80311

Cumulative Model Updates: 122,194
Cumulative Timesteps: 1,019,922,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1019922652...
Checkpoint 1019922652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,224.21115
Policy Entropy: 1.70173
Value Function Loss: 0.07083

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.29188
Value Function Update Magnitude: 0.27193

Collected Steps per Second: 21,356.27952
Overall Steps per Second: 10,344.68139

Timestep Collection Time: 2.34320
Timestep Consumption Time: 2.49426
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.83746

Cumulative Model Updates: 122,200
Cumulative Timesteps: 1,019,972,694

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,436.26748
Policy Entropy: 1.71201
Value Function Loss: 0.07283

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.30323

Collected Steps per Second: 21,441.77592
Overall Steps per Second: 10,303.08517

Timestep Collection Time: 2.33227
Timestep Consumption Time: 2.52142
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.85369

Cumulative Model Updates: 122,206
Cumulative Timesteps: 1,020,022,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1020022702...
Checkpoint 1020022702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,593.69468
Policy Entropy: 1.70220
Value Function Loss: 0.06316

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.31992
Value Function Update Magnitude: 0.32276

Collected Steps per Second: 21,124.62035
Overall Steps per Second: 10,235.64622

Timestep Collection Time: 2.36747
Timestep Consumption Time: 2.51859
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.88606

Cumulative Model Updates: 122,212
Cumulative Timesteps: 1,020,072,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,421.18433
Policy Entropy: 1.68685
Value Function Loss: 0.06174

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.31557
Value Function Update Magnitude: 0.31488

Collected Steps per Second: 21,384.61445
Overall Steps per Second: 10,371.12972

Timestep Collection Time: 2.33888
Timestep Consumption Time: 2.48374
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.82262

Cumulative Model Updates: 122,218
Cumulative Timesteps: 1,020,122,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1020122730...
Checkpoint 1020122730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,994.07129
Policy Entropy: 1.70440
Value Function Loss: 0.06502

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.31529
Value Function Update Magnitude: 0.31817

Collected Steps per Second: 21,622.99988
Overall Steps per Second: 10,381.46765

Timestep Collection Time: 2.31235
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.81627

Cumulative Model Updates: 122,224
Cumulative Timesteps: 1,020,172,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,867.43474
Policy Entropy: 1.69908
Value Function Loss: 0.07104

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.32153
Value Function Update Magnitude: 0.33465

Collected Steps per Second: 22,041.17492
Overall Steps per Second: 10,428.02184

Timestep Collection Time: 2.26984
Timestep Consumption Time: 2.52781
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.79765

Cumulative Model Updates: 122,230
Cumulative Timesteps: 1,020,222,760

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1020222760...
Checkpoint 1020222760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,288.03529
Policy Entropy: 1.71241
Value Function Loss: 0.07620

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.32793
Value Function Update Magnitude: 0.33667

Collected Steps per Second: 21,836.97709
Overall Steps per Second: 10,381.29993

Timestep Collection Time: 2.29052
Timestep Consumption Time: 2.52757
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.81809

Cumulative Model Updates: 122,236
Cumulative Timesteps: 1,020,272,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,671.11600
Policy Entropy: 1.69681
Value Function Loss: 0.07173

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.32713
Value Function Update Magnitude: 0.33239

Collected Steps per Second: 21,464.57977
Overall Steps per Second: 10,505.16474

Timestep Collection Time: 2.33063
Timestep Consumption Time: 2.43141
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.76204

Cumulative Model Updates: 122,242
Cumulative Timesteps: 1,020,322,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1020322804...
Checkpoint 1020322804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,832.74574
Policy Entropy: 1.70775
Value Function Loss: 0.07105

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.32351
Value Function Update Magnitude: 0.32201

Collected Steps per Second: 20,701.56023
Overall Steps per Second: 10,182.69364

Timestep Collection Time: 2.41537
Timestep Consumption Time: 2.49511
PPO Batch Consumption Time: 0.30467
Total Iteration Time: 4.91049

Cumulative Model Updates: 122,248
Cumulative Timesteps: 1,020,372,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,131.51655
Policy Entropy: 1.69980
Value Function Loss: 0.06664

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.32221
Value Function Update Magnitude: 0.33357

Collected Steps per Second: 21,078.11179
Overall Steps per Second: 10,527.42811

Timestep Collection Time: 2.37270
Timestep Consumption Time: 2.37794
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.75064

Cumulative Model Updates: 122,254
Cumulative Timesteps: 1,020,422,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1020422818...
Checkpoint 1020422818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,473.76031
Policy Entropy: 1.70901
Value Function Loss: 0.06756

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.32377
Value Function Update Magnitude: 0.35365

Collected Steps per Second: 21,019.62277
Overall Steps per Second: 10,389.17462

Timestep Collection Time: 2.37921
Timestep Consumption Time: 2.43446
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.81366

Cumulative Model Updates: 122,260
Cumulative Timesteps: 1,020,472,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,346.78407
Policy Entropy: 1.70597
Value Function Loss: 0.06481

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.32323
Value Function Update Magnitude: 0.36381

Collected Steps per Second: 20,370.90423
Overall Steps per Second: 10,347.43442

Timestep Collection Time: 2.45556
Timestep Consumption Time: 2.37868
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.83424

Cumulative Model Updates: 122,266
Cumulative Timesteps: 1,020,522,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1020522850...
Checkpoint 1020522850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,069.98948
Policy Entropy: 1.71869
Value Function Loss: 0.06499

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.32033
Value Function Update Magnitude: 0.35200

Collected Steps per Second: 20,808.98335
Overall Steps per Second: 10,510.02194

Timestep Collection Time: 2.40281
Timestep Consumption Time: 2.35456
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.75736

Cumulative Model Updates: 122,272
Cumulative Timesteps: 1,020,572,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,386.18763
Policy Entropy: 1.72129
Value Function Loss: 0.06599

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.31892
Value Function Update Magnitude: 0.32792

Collected Steps per Second: 20,748.15691
Overall Steps per Second: 10,456.32138

Timestep Collection Time: 2.41159
Timestep Consumption Time: 2.37365
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.78524

Cumulative Model Updates: 122,278
Cumulative Timesteps: 1,020,622,886

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1020622886...
Checkpoint 1020622886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,635.55761
Policy Entropy: 1.71500
Value Function Loss: 0.07121

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.32139
Value Function Update Magnitude: 0.33188

Collected Steps per Second: 20,767.70928
Overall Steps per Second: 10,303.94198

Timestep Collection Time: 2.40816
Timestep Consumption Time: 2.44551
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.85368

Cumulative Model Updates: 122,284
Cumulative Timesteps: 1,020,672,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,136.95056
Policy Entropy: 1.71092
Value Function Loss: 0.06585

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.32184
Value Function Update Magnitude: 0.35331

Collected Steps per Second: 20,993.41777
Overall Steps per Second: 10,385.90125

Timestep Collection Time: 2.38170
Timestep Consumption Time: 2.43252
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.81422

Cumulative Model Updates: 122,290
Cumulative Timesteps: 1,020,722,898

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1020722898...
Checkpoint 1020722898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,640.34341
Policy Entropy: 1.70649
Value Function Loss: 0.06677

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.31779
Value Function Update Magnitude: 0.35253

Collected Steps per Second: 21,303.66391
Overall Steps per Second: 10,349.66197

Timestep Collection Time: 2.34711
Timestep Consumption Time: 2.48416
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.83127

Cumulative Model Updates: 122,296
Cumulative Timesteps: 1,020,772,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,776.96778
Policy Entropy: 1.71476
Value Function Loss: 0.06814

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.32350
Value Function Update Magnitude: 0.34931

Collected Steps per Second: 21,725.05142
Overall Steps per Second: 10,417.82787

Timestep Collection Time: 2.30269
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.80196

Cumulative Model Updates: 122,302
Cumulative Timesteps: 1,020,822,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1020822926...
Checkpoint 1020822926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,208.04445
Policy Entropy: 1.70874
Value Function Loss: 0.06791

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.32331
Value Function Update Magnitude: 0.33476

Collected Steps per Second: 21,486.84408
Overall Steps per Second: 10,487.35440

Timestep Collection Time: 2.32794
Timestep Consumption Time: 2.44162
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.76955

Cumulative Model Updates: 122,308
Cumulative Timesteps: 1,020,872,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,392.83574
Policy Entropy: 1.69474
Value Function Loss: 0.06915

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.32220
Value Function Update Magnitude: 0.32697

Collected Steps per Second: 21,586.79420
Overall Steps per Second: 10,518.41303

Timestep Collection Time: 2.31753
Timestep Consumption Time: 2.43870
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.75623

Cumulative Model Updates: 122,314
Cumulative Timesteps: 1,020,922,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1020922974...
Checkpoint 1020922974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,494.88261
Policy Entropy: 1.68331
Value Function Loss: 0.06599

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.32034
Value Function Update Magnitude: 0.32995

Collected Steps per Second: 21,678.08806
Overall Steps per Second: 10,551.13245

Timestep Collection Time: 2.30731
Timestep Consumption Time: 2.43323
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.74053

Cumulative Model Updates: 122,320
Cumulative Timesteps: 1,020,972,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,522.98885
Policy Entropy: 1.68362
Value Function Loss: 0.06835

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08185
Policy Update Magnitude: 0.31966
Value Function Update Magnitude: 0.33724

Collected Steps per Second: 21,717.97104
Overall Steps per Second: 10,363.66096

Timestep Collection Time: 2.30353
Timestep Consumption Time: 2.52372
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.82725

Cumulative Model Updates: 122,326
Cumulative Timesteps: 1,021,023,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1021023020...
Checkpoint 1021023020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,261.91292
Policy Entropy: 1.70304
Value Function Loss: 0.06969

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.32463
Value Function Update Magnitude: 0.34538

Collected Steps per Second: 21,875.52992
Overall Steps per Second: 10,411.08485

Timestep Collection Time: 2.28630
Timestep Consumption Time: 2.51762
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.80392

Cumulative Model Updates: 122,332
Cumulative Timesteps: 1,021,073,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,103.44262
Policy Entropy: 1.70622
Value Function Loss: 0.06935

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.32381
Value Function Update Magnitude: 0.29716

Collected Steps per Second: 21,894.84034
Overall Steps per Second: 10,404.50487

Timestep Collection Time: 2.28474
Timestep Consumption Time: 2.52318
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.80792

Cumulative Model Updates: 122,338
Cumulative Timesteps: 1,021,123,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1021123058...
Checkpoint 1021123058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,751.21404
Policy Entropy: 1.70900
Value Function Loss: 0.06944

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.32341
Value Function Update Magnitude: 0.27523

Collected Steps per Second: 21,765.42075
Overall Steps per Second: 10,564.47596

Timestep Collection Time: 2.29842
Timestep Consumption Time: 2.43689
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.73530

Cumulative Model Updates: 122,344
Cumulative Timesteps: 1,021,173,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,891.08423
Policy Entropy: 1.68609
Value Function Loss: 0.06725

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.32238
Value Function Update Magnitude: 0.29829

Collected Steps per Second: 21,513.21578
Overall Steps per Second: 10,471.55986

Timestep Collection Time: 2.32434
Timestep Consumption Time: 2.45088
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.77522

Cumulative Model Updates: 122,350
Cumulative Timesteps: 1,021,223,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1021223088...
Checkpoint 1021223088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,007.42277
Policy Entropy: 1.67806
Value Function Loss: 0.06983

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08013
Policy Update Magnitude: 0.32412
Value Function Update Magnitude: 0.33131

Collected Steps per Second: 21,213.50960
Overall Steps per Second: 10,235.01437

Timestep Collection Time: 2.35831
Timestep Consumption Time: 2.52962
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.88793

Cumulative Model Updates: 122,356
Cumulative Timesteps: 1,021,273,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,794.86930
Policy Entropy: 1.67208
Value Function Loss: 0.06843

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.32744
Value Function Update Magnitude: 0.35349

Collected Steps per Second: 21,524.02695
Overall Steps per Second: 10,462.80747

Timestep Collection Time: 2.32354
Timestep Consumption Time: 2.45644
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.77998

Cumulative Model Updates: 122,362
Cumulative Timesteps: 1,021,323,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1021323128...
Checkpoint 1021323128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,445.11511
Policy Entropy: 1.67745
Value Function Loss: 0.07131

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.32716
Value Function Update Magnitude: 0.36861

Collected Steps per Second: 21,453.00978
Overall Steps per Second: 10,275.67182

Timestep Collection Time: 2.33068
Timestep Consumption Time: 2.53519
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.86586

Cumulative Model Updates: 122,368
Cumulative Timesteps: 1,021,373,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,083.49984
Policy Entropy: 1.69402
Value Function Loss: 0.07277

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.32961
Value Function Update Magnitude: 0.36894

Collected Steps per Second: 22,015.46197
Overall Steps per Second: 10,418.43600

Timestep Collection Time: 2.27177
Timestep Consumption Time: 2.52876
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.80053

Cumulative Model Updates: 122,374
Cumulative Timesteps: 1,021,423,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1021423142...
Checkpoint 1021423142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,377.38276
Policy Entropy: 1.70015
Value Function Loss: 0.07618

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.32987
Value Function Update Magnitude: 0.36715

Collected Steps per Second: 22,024.85665
Overall Steps per Second: 10,622.88030

Timestep Collection Time: 2.27107
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.70870

Cumulative Model Updates: 122,380
Cumulative Timesteps: 1,021,473,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,190.32959
Policy Entropy: 1.69695
Value Function Loss: 0.08029

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.33494
Value Function Update Magnitude: 0.36248

Collected Steps per Second: 21,807.46286
Overall Steps per Second: 10,457.61276

Timestep Collection Time: 2.29371
Timestep Consumption Time: 2.48941
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.78312

Cumulative Model Updates: 122,386
Cumulative Timesteps: 1,021,523,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1021523182...
Checkpoint 1021523182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,910.79846
Policy Entropy: 1.68252
Value Function Loss: 0.07809

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.33776
Value Function Update Magnitude: 0.38716

Collected Steps per Second: 21,570.17266
Overall Steps per Second: 10,367.20407

Timestep Collection Time: 2.31913
Timestep Consumption Time: 2.50609
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.82522

Cumulative Model Updates: 122,392
Cumulative Timesteps: 1,021,573,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,174.44191
Policy Entropy: 1.68087
Value Function Loss: 0.07331

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.33620
Value Function Update Magnitude: 0.37025

Collected Steps per Second: 21,883.56768
Overall Steps per Second: 10,413.34363

Timestep Collection Time: 2.28610
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.80422

Cumulative Model Updates: 122,398
Cumulative Timesteps: 1,021,623,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1021623234...
Checkpoint 1021623234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,832.92634
Policy Entropy: 1.67260
Value Function Loss: 0.06728

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.32816
Value Function Update Magnitude: 0.38022

Collected Steps per Second: 21,162.87663
Overall Steps per Second: 10,143.66658

Timestep Collection Time: 2.36319
Timestep Consumption Time: 2.56717
PPO Batch Consumption Time: 0.30296
Total Iteration Time: 4.93037

Cumulative Model Updates: 122,404
Cumulative Timesteps: 1,021,673,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,301.75745
Policy Entropy: 1.68689
Value Function Loss: 0.06493

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08046
Policy Update Magnitude: 0.32064
Value Function Update Magnitude: 0.38806

Collected Steps per Second: 21,975.82747
Overall Steps per Second: 10,423.01443

Timestep Collection Time: 2.27541
Timestep Consumption Time: 2.52205
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.79746

Cumulative Model Updates: 122,410
Cumulative Timesteps: 1,021,723,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1021723250...
Checkpoint 1021723250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,984.04930
Policy Entropy: 1.68788
Value Function Loss: 0.06484

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.32210
Value Function Update Magnitude: 0.37642

Collected Steps per Second: 21,568.99479
Overall Steps per Second: 10,394.06286

Timestep Collection Time: 2.31981
Timestep Consumption Time: 2.49409
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.81390

Cumulative Model Updates: 122,416
Cumulative Timesteps: 1,021,773,286

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,271.10697
Policy Entropy: 1.68604
Value Function Loss: 0.06922

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.32748
Value Function Update Magnitude: 0.35277

Collected Steps per Second: 21,371.59355
Overall Steps per Second: 10,276.05397

Timestep Collection Time: 2.34077
Timestep Consumption Time: 2.52744
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.86821

Cumulative Model Updates: 122,422
Cumulative Timesteps: 1,021,823,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1021823312...
Checkpoint 1021823312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,456.42752
Policy Entropy: 1.67097
Value Function Loss: 0.06823

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.32655
Value Function Update Magnitude: 0.32154

Collected Steps per Second: 21,210.31964
Overall Steps per Second: 10,249.40317

Timestep Collection Time: 2.35838
Timestep Consumption Time: 2.52210
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.88048

Cumulative Model Updates: 122,428
Cumulative Timesteps: 1,021,873,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,101.83934
Policy Entropy: 1.67120
Value Function Loss: 0.06892

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.32494
Value Function Update Magnitude: 0.31857

Collected Steps per Second: 21,046.93788
Overall Steps per Second: 10,385.74888

Timestep Collection Time: 2.37640
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.81583

Cumulative Model Updates: 122,434
Cumulative Timesteps: 1,021,923,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1021923350...
Checkpoint 1021923350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,286.12053
Policy Entropy: 1.68072
Value Function Loss: 0.06664

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.32367
Value Function Update Magnitude: 0.30635

Collected Steps per Second: 21,366.06957
Overall Steps per Second: 10,284.17965

Timestep Collection Time: 2.34016
Timestep Consumption Time: 2.52168
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.86184

Cumulative Model Updates: 122,440
Cumulative Timesteps: 1,021,973,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,175.38963
Policy Entropy: 1.67359
Value Function Loss: 0.06471

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.32002
Value Function Update Magnitude: 0.31639

Collected Steps per Second: 22,011.46372
Overall Steps per Second: 10,380.40441

Timestep Collection Time: 2.27254
Timestep Consumption Time: 2.54634
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.81889

Cumulative Model Updates: 122,446
Cumulative Timesteps: 1,022,023,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1022023372...
Checkpoint 1022023372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,820.29448
Policy Entropy: 1.66078
Value Function Loss: 0.06877

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.31701
Value Function Update Magnitude: 0.31898

Collected Steps per Second: 21,683.49316
Overall Steps per Second: 10,322.32451

Timestep Collection Time: 2.30609
Timestep Consumption Time: 2.53817
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.84426

Cumulative Model Updates: 122,452
Cumulative Timesteps: 1,022,073,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,094.35540
Policy Entropy: 1.67434
Value Function Loss: 0.06985

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.32490
Value Function Update Magnitude: 0.33320

Collected Steps per Second: 21,619.54824
Overall Steps per Second: 10,324.50347

Timestep Collection Time: 2.31402
Timestep Consumption Time: 2.53154
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.84556

Cumulative Model Updates: 122,458
Cumulative Timesteps: 1,022,123,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1022123404...
Checkpoint 1022123404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,838.13565
Policy Entropy: 1.68364
Value Function Loss: 0.07078

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.32879
Value Function Update Magnitude: 0.33526

Collected Steps per Second: 21,602.39731
Overall Steps per Second: 10,359.12360

Timestep Collection Time: 2.31576
Timestep Consumption Time: 2.51341
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.82917

Cumulative Model Updates: 122,464
Cumulative Timesteps: 1,022,173,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,576.10125
Policy Entropy: 1.68361
Value Function Loss: 0.06925

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.32525
Value Function Update Magnitude: 0.32254

Collected Steps per Second: 21,966.85703
Overall Steps per Second: 10,426.74843

Timestep Collection Time: 2.27734
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.79785

Cumulative Model Updates: 122,470
Cumulative Timesteps: 1,022,223,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1022223456...
Checkpoint 1022223456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,921.56225
Policy Entropy: 1.66515
Value Function Loss: 0.06845

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.30893
Value Function Update Magnitude: 0.30201

Collected Steps per Second: 21,771.27834
Overall Steps per Second: 10,424.12426

Timestep Collection Time: 2.29807
Timestep Consumption Time: 2.50156
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.79964

Cumulative Model Updates: 122,476
Cumulative Timesteps: 1,022,273,488

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,601.66799
Policy Entropy: 1.66635
Value Function Loss: 0.06476

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.28504
Value Function Update Magnitude: 0.30619

Collected Steps per Second: 21,597.58102
Overall Steps per Second: 10,351.95616

Timestep Collection Time: 2.31572
Timestep Consumption Time: 2.51564
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.83136

Cumulative Model Updates: 122,482
Cumulative Timesteps: 1,022,323,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1022323502...
Checkpoint 1022323502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,669.16247
Policy Entropy: 1.66457
Value Function Loss: 0.06868

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.28886
Value Function Update Magnitude: 0.32671

Collected Steps per Second: 21,156.46487
Overall Steps per Second: 10,323.06884

Timestep Collection Time: 2.36419
Timestep Consumption Time: 2.48107
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.84526

Cumulative Model Updates: 122,488
Cumulative Timesteps: 1,022,373,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,179.38508
Policy Entropy: 1.67460
Value Function Loss: 0.07078

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.30572
Value Function Update Magnitude: 0.34048

Collected Steps per Second: 21,481.20914
Overall Steps per Second: 10,477.83040

Timestep Collection Time: 2.32929
Timestep Consumption Time: 2.44612
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.77542

Cumulative Model Updates: 122,494
Cumulative Timesteps: 1,022,423,556

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1022423556...
Checkpoint 1022423556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,507.56791
Policy Entropy: 1.68640
Value Function Loss: 0.07029

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.31827
Value Function Update Magnitude: 0.34398

Collected Steps per Second: 21,036.21661
Overall Steps per Second: 10,251.92013

Timestep Collection Time: 2.37780
Timestep Consumption Time: 2.50128
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.87909

Cumulative Model Updates: 122,500
Cumulative Timesteps: 1,022,473,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,574.25519
Policy Entropy: 1.69724
Value Function Loss: 0.06988

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.31991
Value Function Update Magnitude: 0.34259

Collected Steps per Second: 21,453.73114
Overall Steps per Second: 10,525.59183

Timestep Collection Time: 2.33125
Timestep Consumption Time: 2.42041
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.75166

Cumulative Model Updates: 122,506
Cumulative Timesteps: 1,022,523,590

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1022523590...
Checkpoint 1022523590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,469.87765
Policy Entropy: 1.68613
Value Function Loss: 0.07008

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.32350
Value Function Update Magnitude: 0.34756

Collected Steps per Second: 21,555.29849
Overall Steps per Second: 10,365.39940

Timestep Collection Time: 2.32017
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.82490

Cumulative Model Updates: 122,512
Cumulative Timesteps: 1,022,573,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,473.25117
Policy Entropy: 1.66766
Value Function Loss: 0.07188

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07755
Policy Update Magnitude: 0.32845
Value Function Update Magnitude: 0.34271

Collected Steps per Second: 21,891.78311
Overall Steps per Second: 10,365.63058

Timestep Collection Time: 2.28433
Timestep Consumption Time: 2.54008
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.82441

Cumulative Model Updates: 122,518
Cumulative Timesteps: 1,022,623,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1022623610...
Checkpoint 1022623610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,257.85632
Policy Entropy: 1.67131
Value Function Loss: 0.07350

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.32624
Value Function Update Magnitude: 0.36412

Collected Steps per Second: 21,705.92523
Overall Steps per Second: 10,497.64369

Timestep Collection Time: 2.30536
Timestep Consumption Time: 2.46142
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.76678

Cumulative Model Updates: 122,524
Cumulative Timesteps: 1,022,673,650

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,503.24078
Policy Entropy: 1.68921
Value Function Loss: 0.07392

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.32403
Value Function Update Magnitude: 0.36355

Collected Steps per Second: 21,956.44994
Overall Steps per Second: 10,452.44514

Timestep Collection Time: 2.27869
Timestep Consumption Time: 2.50794
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.78663

Cumulative Model Updates: 122,530
Cumulative Timesteps: 1,022,723,682

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1022723682...
Checkpoint 1022723682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,616.15617
Policy Entropy: 1.69641
Value Function Loss: 0.07413

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.31973
Value Function Update Magnitude: 0.35379

Collected Steps per Second: 21,894.01905
Overall Steps per Second: 10,581.99581

Timestep Collection Time: 2.28537
Timestep Consumption Time: 2.44304
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.72841

Cumulative Model Updates: 122,536
Cumulative Timesteps: 1,022,773,718

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,102.97615
Policy Entropy: 1.69577
Value Function Loss: 0.07427

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.32392
Value Function Update Magnitude: 0.35829

Collected Steps per Second: 21,860.29588
Overall Steps per Second: 10,568.41371

Timestep Collection Time: 2.28771
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73203

Cumulative Model Updates: 122,542
Cumulative Timesteps: 1,022,823,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1022823728...
Checkpoint 1022823728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,532.16225
Policy Entropy: 1.69398
Value Function Loss: 0.07011

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.32205
Value Function Update Magnitude: 0.34343

Collected Steps per Second: 21,849.05850
Overall Steps per Second: 10,549.79331

Timestep Collection Time: 2.28861
Timestep Consumption Time: 2.45120
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.73981

Cumulative Model Updates: 122,548
Cumulative Timesteps: 1,022,873,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,450.30972
Policy Entropy: 1.69819
Value Function Loss: 0.07312

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.32019
Value Function Update Magnitude: 0.33222

Collected Steps per Second: 22,140.30990
Overall Steps per Second: 10,427.94202

Timestep Collection Time: 2.25995
Timestep Consumption Time: 2.53831
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.79826

Cumulative Model Updates: 122,554
Cumulative Timesteps: 1,022,923,768

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1022923768...
Checkpoint 1022923768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,628.58173
Policy Entropy: 1.68564
Value Function Loss: 0.07308

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.32519
Value Function Update Magnitude: 0.32843

Collected Steps per Second: 21,027.46439
Overall Steps per Second: 10,236.83794

Timestep Collection Time: 2.38013
Timestep Consumption Time: 2.50888
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.88901

Cumulative Model Updates: 122,560
Cumulative Timesteps: 1,022,973,816

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,869.33387
Policy Entropy: 1.69492
Value Function Loss: 0.07429

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.32662
Value Function Update Magnitude: 0.33036

Collected Steps per Second: 21,544.64009
Overall Steps per Second: 10,454.14290

Timestep Collection Time: 2.32188
Timestep Consumption Time: 2.46321
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.78509

Cumulative Model Updates: 122,566
Cumulative Timesteps: 1,023,023,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1023023840...
Checkpoint 1023023840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,570.31014
Policy Entropy: 1.70122
Value Function Loss: 0.07096

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.31330
Value Function Update Magnitude: 0.32828

Collected Steps per Second: 21,118.57506
Overall Steps per Second: 10,220.50392

Timestep Collection Time: 2.36815
Timestep Consumption Time: 2.52515
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.89330

Cumulative Model Updates: 122,572
Cumulative Timesteps: 1,023,073,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,882.99158
Policy Entropy: 1.70041
Value Function Loss: 0.06848

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.33984

Collected Steps per Second: 21,390.48136
Overall Steps per Second: 10,452.92636

Timestep Collection Time: 2.33833
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.78507

Cumulative Model Updates: 122,578
Cumulative Timesteps: 1,023,123,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1023123870...
Checkpoint 1023123870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,345.81277
Policy Entropy: 1.68338
Value Function Loss: 0.06414

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.31834
Value Function Update Magnitude: 0.33804

Collected Steps per Second: 21,107.48933
Overall Steps per Second: 10,253.01459

Timestep Collection Time: 2.37053
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.88013

Cumulative Model Updates: 122,584
Cumulative Timesteps: 1,023,173,906

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,901.87496
Policy Entropy: 1.67841
Value Function Loss: 0.06400

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.31721
Value Function Update Magnitude: 0.33223

Collected Steps per Second: 21,657.75329
Overall Steps per Second: 10,488.25287

Timestep Collection Time: 2.30975
Timestep Consumption Time: 2.45978
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.76953

Cumulative Model Updates: 122,590
Cumulative Timesteps: 1,023,223,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1023223930...
Checkpoint 1023223930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,228.40683
Policy Entropy: 1.67532
Value Function Loss: 0.06104

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.31410
Value Function Update Magnitude: 0.33130

Collected Steps per Second: 21,986.07033
Overall Steps per Second: 10,544.96126

Timestep Collection Time: 2.27444
Timestep Consumption Time: 2.46773
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.74217

Cumulative Model Updates: 122,596
Cumulative Timesteps: 1,023,273,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,835.61540
Policy Entropy: 1.67987
Value Function Loss: 0.06793

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.31826
Value Function Update Magnitude: 0.33404

Collected Steps per Second: 22,077.34373
Overall Steps per Second: 10,509.43698

Timestep Collection Time: 2.26486
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.75782

Cumulative Model Updates: 122,602
Cumulative Timesteps: 1,023,323,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1023323938...
Checkpoint 1023323938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,506.90722
Policy Entropy: 1.69283
Value Function Loss: 0.07126

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.32030
Value Function Update Magnitude: 0.32084

Collected Steps per Second: 21,560.23492
Overall Steps per Second: 10,557.63327

Timestep Collection Time: 2.31983
Timestep Consumption Time: 2.41760
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.73743

Cumulative Model Updates: 122,608
Cumulative Timesteps: 1,023,373,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,284.97222
Policy Entropy: 1.70616
Value Function Loss: 0.07465

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.31315
Value Function Update Magnitude: 0.30694

Collected Steps per Second: 21,865.91534
Overall Steps per Second: 10,529.26094

Timestep Collection Time: 2.28730
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.75000

Cumulative Model Updates: 122,614
Cumulative Timesteps: 1,023,423,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1023423968...
Checkpoint 1023423968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,002.45812
Policy Entropy: 1.70867
Value Function Loss: 0.07454

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.30181
Value Function Update Magnitude: 0.31569

Collected Steps per Second: 21,512.20974
Overall Steps per Second: 10,572.11677

Timestep Collection Time: 2.32445
Timestep Consumption Time: 2.40535
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.72980

Cumulative Model Updates: 122,620
Cumulative Timesteps: 1,023,473,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,344.99932
Policy Entropy: 1.71166
Value Function Loss: 0.07893

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.31721
Value Function Update Magnitude: 0.34130

Collected Steps per Second: 21,703.15043
Overall Steps per Second: 10,531.46183

Timestep Collection Time: 2.30400
Timestep Consumption Time: 2.44406
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.74806

Cumulative Model Updates: 122,626
Cumulative Timesteps: 1,023,523,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1023523976...
Checkpoint 1023523976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,154.09608
Policy Entropy: 1.69400
Value Function Loss: 0.07311

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.32551
Value Function Update Magnitude: 0.34608

Collected Steps per Second: 21,411.78532
Overall Steps per Second: 10,218.69716

Timestep Collection Time: 2.33535
Timestep Consumption Time: 2.55803
PPO Batch Consumption Time: 0.30182
Total Iteration Time: 4.89338

Cumulative Model Updates: 122,632
Cumulative Timesteps: 1,023,573,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,932.44263
Policy Entropy: 1.68198
Value Function Loss: 0.06852

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.32416
Value Function Update Magnitude: 0.33245

Collected Steps per Second: 21,584.43400
Overall Steps per Second: 10,321.39270

Timestep Collection Time: 2.31713
Timestep Consumption Time: 2.52853
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.84566

Cumulative Model Updates: 122,638
Cumulative Timesteps: 1,023,623,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1023623994...
Checkpoint 1023623994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,723.25469
Policy Entropy: 1.67539
Value Function Loss: 0.06364

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.32202
Value Function Update Magnitude: 0.32227

Collected Steps per Second: 20,930.04057
Overall Steps per Second: 10,343.63346

Timestep Collection Time: 2.39111
Timestep Consumption Time: 2.44723
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.83834

Cumulative Model Updates: 122,644
Cumulative Timesteps: 1,023,674,040

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,946.56886
Policy Entropy: 1.68698
Value Function Loss: 0.06592

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.32420
Value Function Update Magnitude: 0.34108

Collected Steps per Second: 21,565.98382
Overall Steps per Second: 10,460.73188

Timestep Collection Time: 2.32041
Timestep Consumption Time: 2.46338
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.78380

Cumulative Model Updates: 122,650
Cumulative Timesteps: 1,023,724,082

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1023724082...
Checkpoint 1023724082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,585.94843
Policy Entropy: 1.69431
Value Function Loss: 0.06300

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.32329
Value Function Update Magnitude: 0.34933

Collected Steps per Second: 21,167.67893
Overall Steps per Second: 10,215.75223

Timestep Collection Time: 2.36360
Timestep Consumption Time: 2.53393
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.89753

Cumulative Model Updates: 122,656
Cumulative Timesteps: 1,023,774,114

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,871.34592
Policy Entropy: 1.69166
Value Function Loss: 0.06170

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07582
Policy Update Magnitude: 0.31531
Value Function Update Magnitude: 0.29470

Collected Steps per Second: 21,635.43594
Overall Steps per Second: 10,529.58338

Timestep Collection Time: 2.31112
Timestep Consumption Time: 2.43760
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.74872

Cumulative Model Updates: 122,662
Cumulative Timesteps: 1,023,824,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1023824116...
Checkpoint 1023824116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,257.66474
Policy Entropy: 1.69595
Value Function Loss: 0.06422

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.31481
Value Function Update Magnitude: 0.23909

Collected Steps per Second: 21,807.97515
Overall Steps per Second: 10,476.85879

Timestep Collection Time: 2.29347
Timestep Consumption Time: 2.48048
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.77395

Cumulative Model Updates: 122,668
Cumulative Timesteps: 1,023,874,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,578.30295
Policy Entropy: 1.68758
Value Function Loss: 0.06375

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.31445
Value Function Update Magnitude: 0.24749

Collected Steps per Second: 22,090.74993
Overall Steps per Second: 10,498.70442

Timestep Collection Time: 2.26366
Timestep Consumption Time: 2.49940
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.76306

Cumulative Model Updates: 122,674
Cumulative Timesteps: 1,023,924,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1023924138...
Checkpoint 1023924138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,309.41992
Policy Entropy: 1.68298
Value Function Loss: 0.06338

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07808
Policy Update Magnitude: 0.31180
Value Function Update Magnitude: 0.24939

Collected Steps per Second: 21,385.21835
Overall Steps per Second: 10,282.66964

Timestep Collection Time: 2.33984
Timestep Consumption Time: 2.52641
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.86625

Cumulative Model Updates: 122,680
Cumulative Timesteps: 1,023,974,176

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,450.70725
Policy Entropy: 1.66644
Value Function Loss: 0.06272

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.31170
Value Function Update Magnitude: 0.25260

Collected Steps per Second: 22,003.97471
Overall Steps per Second: 10,421.72258

Timestep Collection Time: 2.27277
Timestep Consumption Time: 2.52586
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.79863

Cumulative Model Updates: 122,686
Cumulative Timesteps: 1,024,024,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1024024186...
Checkpoint 1024024186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,456.13418
Policy Entropy: 1.67800
Value Function Loss: 0.06620

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.31074
Value Function Update Magnitude: 0.27888

Collected Steps per Second: 21,531.35733
Overall Steps per Second: 10,381.50474

Timestep Collection Time: 2.32387
Timestep Consumption Time: 2.49586
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.81973

Cumulative Model Updates: 122,692
Cumulative Timesteps: 1,024,074,222

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,854.06741
Policy Entropy: 1.68181
Value Function Loss: 0.06586

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.29881

Collected Steps per Second: 22,023.58366
Overall Steps per Second: 10,619.92676

Timestep Collection Time: 2.27066
Timestep Consumption Time: 2.43823
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.70888

Cumulative Model Updates: 122,698
Cumulative Timesteps: 1,024,124,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1024124230...
Checkpoint 1024124230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,646.06409
Policy Entropy: 1.68523
Value Function Loss: 0.06451

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.30983
Value Function Update Magnitude: 0.26813

Collected Steps per Second: 21,674.46980
Overall Steps per Second: 10,389.67988

Timestep Collection Time: 2.30760
Timestep Consumption Time: 2.50641
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.81401

Cumulative Model Updates: 122,704
Cumulative Timesteps: 1,024,174,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,596.01376
Policy Entropy: 1.67002
Value Function Loss: 0.06275

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.31309
Value Function Update Magnitude: 0.25932

Collected Steps per Second: 21,629.66175
Overall Steps per Second: 10,178.54196

Timestep Collection Time: 2.31192
Timestep Consumption Time: 2.60097
PPO Batch Consumption Time: 0.30519
Total Iteration Time: 4.91288

Cumulative Model Updates: 122,710
Cumulative Timesteps: 1,024,224,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1024224252...
Checkpoint 1024224252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,709.23040
Policy Entropy: 1.67233
Value Function Loss: 0.05976

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.31040
Value Function Update Magnitude: 0.25607

Collected Steps per Second: 21,052.92499
Overall Steps per Second: 10,226.55103

Timestep Collection Time: 2.37497
Timestep Consumption Time: 2.51427
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.88923

Cumulative Model Updates: 122,716
Cumulative Timesteps: 1,024,274,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,700.33989
Policy Entropy: 1.68231
Value Function Loss: 0.05850

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07502
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.25528

Collected Steps per Second: 21,610.40989
Overall Steps per Second: 10,539.49584

Timestep Collection Time: 2.31379
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.74425

Cumulative Model Updates: 122,722
Cumulative Timesteps: 1,024,324,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1024324254...
Checkpoint 1024324254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,486.64321
Policy Entropy: 1.68888
Value Function Loss: 0.06279

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.30723
Value Function Update Magnitude: 0.26394

Collected Steps per Second: 20,589.86228
Overall Steps per Second: 10,264.09430

Timestep Collection Time: 2.43052
Timestep Consumption Time: 2.44512
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.87564

Cumulative Model Updates: 122,728
Cumulative Timesteps: 1,024,374,298

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,927.14728
Policy Entropy: 1.68650
Value Function Loss: 0.06574

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.29219

Collected Steps per Second: 21,055.93488
Overall Steps per Second: 10,431.21305

Timestep Collection Time: 2.37529
Timestep Consumption Time: 2.41936
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.79465

Cumulative Model Updates: 122,734
Cumulative Timesteps: 1,024,424,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1024424312...
Checkpoint 1024424312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,736.43494
Policy Entropy: 1.68783
Value Function Loss: 0.06972

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.31578
Value Function Update Magnitude: 0.32300

Collected Steps per Second: 20,498.66176
Overall Steps per Second: 10,223.61726

Timestep Collection Time: 2.44104
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.89435

Cumulative Model Updates: 122,740
Cumulative Timesteps: 1,024,474,350

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,216.12235
Policy Entropy: 1.68318
Value Function Loss: 0.06471

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.31879
Value Function Update Magnitude: 0.35586

Collected Steps per Second: 21,030.51455
Overall Steps per Second: 10,506.63653

Timestep Collection Time: 2.37835
Timestep Consumption Time: 2.38226
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.76061

Cumulative Model Updates: 122,746
Cumulative Timesteps: 1,024,524,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1024524368...
Checkpoint 1024524368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,633.80793
Policy Entropy: 1.68738
Value Function Loss: 0.07254

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.32336
Value Function Update Magnitude: 0.37528

Collected Steps per Second: 20,884.16710
Overall Steps per Second: 10,336.35235

Timestep Collection Time: 2.39531
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.83962

Cumulative Model Updates: 122,752
Cumulative Timesteps: 1,024,574,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,355.43090
Policy Entropy: 1.67745
Value Function Loss: 0.07361

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.33100
Value Function Update Magnitude: 0.39477

Collected Steps per Second: 21,560.24966
Overall Steps per Second: 10,659.41146

Timestep Collection Time: 2.32112
Timestep Consumption Time: 2.37369
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.69482

Cumulative Model Updates: 122,758
Cumulative Timesteps: 1,024,624,436

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1024624436...
Checkpoint 1024624436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,706.09453
Policy Entropy: 1.68853
Value Function Loss: 0.07637

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.33068
Value Function Update Magnitude: 0.40239

Collected Steps per Second: 21,289.39546
Overall Steps per Second: 10,304.51318

Timestep Collection Time: 2.34962
Timestep Consumption Time: 2.50476
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.85438

Cumulative Model Updates: 122,764
Cumulative Timesteps: 1,024,674,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,089.75691
Policy Entropy: 1.68968
Value Function Loss: 0.06707

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.32224
Value Function Update Magnitude: 0.41035

Collected Steps per Second: 22,013.88250
Overall Steps per Second: 10,501.68681

Timestep Collection Time: 2.27211
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.76285

Cumulative Model Updates: 122,770
Cumulative Timesteps: 1,024,724,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1024724476...
Checkpoint 1024724476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,494.98118
Policy Entropy: 1.67428
Value Function Loss: 0.05913

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.30599
Value Function Update Magnitude: 0.38638

Collected Steps per Second: 21,734.88489
Overall Steps per Second: 10,539.88633

Timestep Collection Time: 2.30165
Timestep Consumption Time: 2.44471
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.74635

Cumulative Model Updates: 122,776
Cumulative Timesteps: 1,024,774,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,769.50013
Policy Entropy: 1.67513
Value Function Loss: 0.06400

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.30955
Value Function Update Magnitude: 0.35006

Collected Steps per Second: 21,927.96653
Overall Steps per Second: 10,440.69562

Timestep Collection Time: 2.28028
Timestep Consumption Time: 2.50886
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.78914

Cumulative Model Updates: 122,782
Cumulative Timesteps: 1,024,824,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1024824504...
Checkpoint 1024824504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,851.35640
Policy Entropy: 1.66272
Value Function Loss: 0.06325

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.30629
Value Function Update Magnitude: 0.32501

Collected Steps per Second: 21,752.54838
Overall Steps per Second: 10,206.85716

Timestep Collection Time: 2.29867
Timestep Consumption Time: 2.60019
PPO Batch Consumption Time: 0.30523
Total Iteration Time: 4.89886

Cumulative Model Updates: 122,788
Cumulative Timesteps: 1,024,874,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,499.51657
Policy Entropy: 1.68704
Value Function Loss: 0.07026

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07874
Policy Update Magnitude: 0.31083
Value Function Update Magnitude: 0.32124

Collected Steps per Second: 21,684.16451
Overall Steps per Second: 10,493.61936

Timestep Collection Time: 2.30740
Timestep Consumption Time: 2.46064
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.76804

Cumulative Model Updates: 122,794
Cumulative Timesteps: 1,024,924,540

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1024924540...
Checkpoint 1024924540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,715.08234
Policy Entropy: 1.69203
Value Function Loss: 0.06513

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07966
Policy Update Magnitude: 0.31914
Value Function Update Magnitude: 0.32155

Collected Steps per Second: 21,134.26945
Overall Steps per Second: 10,238.41462

Timestep Collection Time: 2.36696
Timestep Consumption Time: 2.51895
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.88591

Cumulative Model Updates: 122,800
Cumulative Timesteps: 1,024,974,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,215.70828
Policy Entropy: 1.69159
Value Function Loss: 0.06192

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.31168
Value Function Update Magnitude: 0.33515

Collected Steps per Second: 21,537.29322
Overall Steps per Second: 10,381.98349

Timestep Collection Time: 2.32155
Timestep Consumption Time: 2.49448
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.81604

Cumulative Model Updates: 122,806
Cumulative Timesteps: 1,025,024,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1025024564...
Checkpoint 1025024564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,262.93165
Policy Entropy: 1.68429
Value Function Loss: 0.05941

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.30624
Value Function Update Magnitude: 0.32622

Collected Steps per Second: 21,372.52064
Overall Steps per Second: 10,297.75956

Timestep Collection Time: 2.34179
Timestep Consumption Time: 2.51849
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.86028

Cumulative Model Updates: 122,812
Cumulative Timesteps: 1,025,074,614

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,138.80954
Policy Entropy: 1.67184
Value Function Loss: 0.05559

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.30395
Value Function Update Magnitude: 0.32698

Collected Steps per Second: 21,562.57166
Overall Steps per Second: 10,413.24484

Timestep Collection Time: 2.31957
Timestep Consumption Time: 2.48354
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.80311

Cumulative Model Updates: 122,818
Cumulative Timesteps: 1,025,124,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1025124630...
Checkpoint 1025124630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,007.97652
Policy Entropy: 1.68789
Value Function Loss: 0.05873

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.30265
Value Function Update Magnitude: 0.32391

Collected Steps per Second: 21,610.44307
Overall Steps per Second: 10,330.80711

Timestep Collection Time: 2.31370
Timestep Consumption Time: 2.52620
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.83989

Cumulative Model Updates: 122,824
Cumulative Timesteps: 1,025,174,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,567.08851
Policy Entropy: 1.67209
Value Function Loss: 0.05726

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.30178
Value Function Update Magnitude: 0.32228

Collected Steps per Second: 21,955.82426
Overall Steps per Second: 10,366.12681

Timestep Collection Time: 2.27803
Timestep Consumption Time: 2.54692
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.82495

Cumulative Model Updates: 122,830
Cumulative Timesteps: 1,025,224,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1025224646...
Checkpoint 1025224646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,426.24217
Policy Entropy: 1.69434
Value Function Loss: 0.06326

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07711
Policy Update Magnitude: 0.30934
Value Function Update Magnitude: 0.30147

Collected Steps per Second: 21,727.27585
Overall Steps per Second: 10,488.00254

Timestep Collection Time: 2.30144
Timestep Consumption Time: 2.46629
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.76773

Cumulative Model Updates: 122,836
Cumulative Timesteps: 1,025,274,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,029.56194
Policy Entropy: 1.68618
Value Function Loss: 0.06931

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.31080
Value Function Update Magnitude: 0.28815

Collected Steps per Second: 20,377.26961
Overall Steps per Second: 10,088.07986

Timestep Collection Time: 2.45411
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.95714

Cumulative Model Updates: 122,842
Cumulative Timesteps: 1,025,324,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1025324658...
Checkpoint 1025324658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,947.76927
Policy Entropy: 1.69696
Value Function Loss: 0.06863

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.29733
Value Function Update Magnitude: 0.32313

Collected Steps per Second: 21,547.58694
Overall Steps per Second: 10,371.03591

Timestep Collection Time: 2.32072
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.82170

Cumulative Model Updates: 122,848
Cumulative Timesteps: 1,025,374,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,351.68068
Policy Entropy: 1.68631
Value Function Loss: 0.07095

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.31129
Value Function Update Magnitude: 0.35048

Collected Steps per Second: 22,107.39811
Overall Steps per Second: 10,646.98823

Timestep Collection Time: 2.26259
Timestep Consumption Time: 2.43545
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.69804

Cumulative Model Updates: 122,854
Cumulative Timesteps: 1,025,424,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1025424684...
Checkpoint 1025424684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,011.33605
Policy Entropy: 1.67850
Value Function Loss: 0.06785

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.31803
Value Function Update Magnitude: 0.35693

Collected Steps per Second: 21,702.00576
Overall Steps per Second: 10,432.97971

Timestep Collection Time: 2.30569
Timestep Consumption Time: 2.49045
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.79614

Cumulative Model Updates: 122,860
Cumulative Timesteps: 1,025,474,722

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,400.13558
Policy Entropy: 1.69788
Value Function Loss: 0.06917

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.32195
Value Function Update Magnitude: 0.36580

Collected Steps per Second: 22,203.00933
Overall Steps per Second: 10,681.26742

Timestep Collection Time: 2.25231
Timestep Consumption Time: 2.42953
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.68184

Cumulative Model Updates: 122,866
Cumulative Timesteps: 1,025,524,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1025524730...
Checkpoint 1025524730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,665.63317
Policy Entropy: 1.69300
Value Function Loss: 0.06515

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.31828
Value Function Update Magnitude: 0.35154

Collected Steps per Second: 21,383.94882
Overall Steps per Second: 10,324.24080

Timestep Collection Time: 2.33961
Timestep Consumption Time: 2.50627
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.84588

Cumulative Model Updates: 122,872
Cumulative Timesteps: 1,025,574,760

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,956.40221
Policy Entropy: 1.68713
Value Function Loss: 0.06419

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.31613
Value Function Update Magnitude: 0.34112

Collected Steps per Second: 21,422.59552
Overall Steps per Second: 10,370.70931

Timestep Collection Time: 2.33473
Timestep Consumption Time: 2.48808
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.82281

Cumulative Model Updates: 122,878
Cumulative Timesteps: 1,025,624,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1025624776...
Checkpoint 1025624776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,054.92226
Policy Entropy: 1.66592
Value Function Loss: 0.06626

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.31737
Value Function Update Magnitude: 0.35352

Collected Steps per Second: 21,408.85757
Overall Steps per Second: 10,339.50244

Timestep Collection Time: 2.33679
Timestep Consumption Time: 2.50174
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.83853

Cumulative Model Updates: 122,884
Cumulative Timesteps: 1,025,674,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,050.94904
Policy Entropy: 1.65483
Value Function Loss: 0.06640

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.32121
Value Function Update Magnitude: 0.36430

Collected Steps per Second: 21,502.63163
Overall Steps per Second: 10,546.93729

Timestep Collection Time: 2.32548
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.74109

Cumulative Model Updates: 122,890
Cumulative Timesteps: 1,025,724,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1025724808...
Checkpoint 1025724808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,070.53909
Policy Entropy: 1.66341
Value Function Loss: 0.06722

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.31606
Value Function Update Magnitude: 0.34451

Collected Steps per Second: 21,147.65599
Overall Steps per Second: 10,431.76800

Timestep Collection Time: 2.36442
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.79324

Cumulative Model Updates: 122,896
Cumulative Timesteps: 1,025,774,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,325.51372
Policy Entropy: 1.67376
Value Function Loss: 0.06684

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.31592
Value Function Update Magnitude: 0.33481

Collected Steps per Second: 21,463.35383
Overall Steps per Second: 10,482.93269

Timestep Collection Time: 2.32983
Timestep Consumption Time: 2.44040
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.77023

Cumulative Model Updates: 122,902
Cumulative Timesteps: 1,025,824,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1025824816...
Checkpoint 1025824816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,585.49351
Policy Entropy: 1.68321
Value Function Loss: 0.06363

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.31835
Value Function Update Magnitude: 0.32959

Collected Steps per Second: 21,345.55019
Overall Steps per Second: 10,625.35138

Timestep Collection Time: 2.34456
Timestep Consumption Time: 2.36549
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.71006

Cumulative Model Updates: 122,908
Cumulative Timesteps: 1,025,874,862

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,239.71602
Policy Entropy: 1.67855
Value Function Loss: 0.06428

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.31436
Value Function Update Magnitude: 0.33296

Collected Steps per Second: 21,435.55403
Overall Steps per Second: 10,505.21448

Timestep Collection Time: 2.33407
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.76259

Cumulative Model Updates: 122,914
Cumulative Timesteps: 1,025,924,894

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1025924894...
Checkpoint 1025924894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,762.61338
Policy Entropy: 1.68414
Value Function Loss: 0.07575

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.32289
Value Function Update Magnitude: 0.32168

Collected Steps per Second: 13,387.53619
Overall Steps per Second: 7,060.10483

Timestep Collection Time: 3.73825
Timestep Consumption Time: 3.35031
PPO Batch Consumption Time: 0.43337
Total Iteration Time: 7.08856

Cumulative Model Updates: 122,920
Cumulative Timesteps: 1,025,974,940

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,640.97150
Policy Entropy: 1.66904
Value Function Loss: 0.08031

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.33377
Value Function Update Magnitude: 0.34530

Collected Steps per Second: 16,625.00662
Overall Steps per Second: 9,256.92293

Timestep Collection Time: 3.00776
Timestep Consumption Time: 2.39404
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 5.40179

Cumulative Model Updates: 122,926
Cumulative Timesteps: 1,026,024,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1026024944...
Checkpoint 1026024944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,332.87748
Policy Entropy: 1.68360
Value Function Loss: 0.07817

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09196
Policy Update Magnitude: 0.33197
Value Function Update Magnitude: 0.37510

Collected Steps per Second: 20,555.58186
Overall Steps per Second: 10,087.23439

Timestep Collection Time: 2.43311
Timestep Consumption Time: 2.52504
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.95815

Cumulative Model Updates: 122,932
Cumulative Timesteps: 1,026,074,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,063.88125
Policy Entropy: 1.67170
Value Function Loss: 0.07089

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.32647
Value Function Update Magnitude: 0.36192

Collected Steps per Second: 21,416.75486
Overall Steps per Second: 10,495.69771

Timestep Collection Time: 2.33546
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.76557

Cumulative Model Updates: 122,938
Cumulative Timesteps: 1,026,124,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1026124976...
Checkpoint 1026124976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,333.35188
Policy Entropy: 1.68524
Value Function Loss: 0.06654

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.32190
Value Function Update Magnitude: 0.34520

Collected Steps per Second: 21,641.19147
Overall Steps per Second: 10,599.93851

Timestep Collection Time: 2.31133
Timestep Consumption Time: 2.40756
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.71890

Cumulative Model Updates: 122,944
Cumulative Timesteps: 1,026,174,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,838.71672
Policy Entropy: 1.68272
Value Function Loss: 0.06891

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.31311
Value Function Update Magnitude: 0.33340

Collected Steps per Second: 21,267.75547
Overall Steps per Second: 10,416.92737

Timestep Collection Time: 2.35239
Timestep Consumption Time: 2.45037
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.80276

Cumulative Model Updates: 122,950
Cumulative Timesteps: 1,026,225,026

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1026225026...
Checkpoint 1026225026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,365.42146
Policy Entropy: 1.68271
Value Function Loss: 0.06788

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.31579
Value Function Update Magnitude: 0.34549

Collected Steps per Second: 21,391.65935
Overall Steps per Second: 10,274.59391

Timestep Collection Time: 2.33876
Timestep Consumption Time: 2.53053
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.86929

Cumulative Model Updates: 122,956
Cumulative Timesteps: 1,026,275,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,508.86293
Policy Entropy: 1.69681
Value Function Loss: 0.07000

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.32364
Value Function Update Magnitude: 0.36507

Collected Steps per Second: 21,705.09263
Overall Steps per Second: 10,459.82813

Timestep Collection Time: 2.30517
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.78344

Cumulative Model Updates: 122,962
Cumulative Timesteps: 1,026,325,090

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1026325090...
Checkpoint 1026325090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,406.84851
Policy Entropy: 1.69342
Value Function Loss: 0.06845

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.32659
Value Function Update Magnitude: 0.37887

Collected Steps per Second: 21,511.59158
Overall Steps per Second: 10,360.31406

Timestep Collection Time: 2.32554
Timestep Consumption Time: 2.50308
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.82862

Cumulative Model Updates: 122,968
Cumulative Timesteps: 1,026,375,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,067.45998
Policy Entropy: 1.66504
Value Function Loss: 0.06718

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.32070
Value Function Update Magnitude: 0.36777

Collected Steps per Second: 19,340.57549
Overall Steps per Second: 9,811.14892

Timestep Collection Time: 2.58545
Timestep Consumption Time: 2.51121
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 5.09665

Cumulative Model Updates: 122,974
Cumulative Timesteps: 1,026,425,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1026425120...
Checkpoint 1026425120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,138.38243
Policy Entropy: 1.64323
Value Function Loss: 0.06022

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.30474
Value Function Update Magnitude: 0.35532

Collected Steps per Second: 20,985.75950
Overall Steps per Second: 10,258.78461

Timestep Collection Time: 2.38447
Timestep Consumption Time: 2.49330
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.87777

Cumulative Model Updates: 122,980
Cumulative Timesteps: 1,026,475,160

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,474.76903
Policy Entropy: 1.64538
Value Function Loss: 0.06050

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.29473
Value Function Update Magnitude: 0.33518

Collected Steps per Second: 21,984.74668
Overall Steps per Second: 10,486.86139

Timestep Collection Time: 2.27503
Timestep Consumption Time: 2.49436
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.76940

Cumulative Model Updates: 122,986
Cumulative Timesteps: 1,026,525,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1026525176...
Checkpoint 1026525176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,314.89923
Policy Entropy: 1.65440
Value Function Loss: 0.06202

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.28905
Value Function Update Magnitude: 0.32987

Collected Steps per Second: 21,660.37442
Overall Steps per Second: 10,417.70239

Timestep Collection Time: 2.30975
Timestep Consumption Time: 2.49265
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.80240

Cumulative Model Updates: 122,992
Cumulative Timesteps: 1,026,575,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,930.98033
Policy Entropy: 1.64288
Value Function Loss: 0.06337

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.30134
Value Function Update Magnitude: 0.33313

Collected Steps per Second: 22,022.34951
Overall Steps per Second: 10,481.64603

Timestep Collection Time: 2.27106
Timestep Consumption Time: 2.50052
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.77158

Cumulative Model Updates: 122,998
Cumulative Timesteps: 1,026,625,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1026625220...
Checkpoint 1026625220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,291.45356
Policy Entropy: 1.62357
Value Function Loss: 0.05848

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.29964
Value Function Update Magnitude: 0.32012

Collected Steps per Second: 21,777.45136
Overall Steps per Second: 10,434.29831

Timestep Collection Time: 2.29696
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.79400

Cumulative Model Updates: 123,004
Cumulative Timesteps: 1,026,675,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,523.17075
Policy Entropy: 1.63218
Value Function Loss: 0.06512

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.29195
Value Function Update Magnitude: 0.31565

Collected Steps per Second: 22,124.27917
Overall Steps per Second: 10,490.59637

Timestep Collection Time: 2.26195
Timestep Consumption Time: 2.50842
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.77037

Cumulative Model Updates: 123,010
Cumulative Timesteps: 1,026,725,286

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1026725286...
Checkpoint 1026725286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,267.84031
Policy Entropy: 1.65636
Value Function Loss: 0.06816

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.29399
Value Function Update Magnitude: 0.33023

Collected Steps per Second: 21,498.69208
Overall Steps per Second: 10,543.28705

Timestep Collection Time: 2.32805
Timestep Consumption Time: 2.41905
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.74710

Cumulative Model Updates: 123,016
Cumulative Timesteps: 1,026,775,336

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,306.50666
Policy Entropy: 1.69085
Value Function Loss: 0.07107

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.34940

Collected Steps per Second: 21,330.04373
Overall Steps per Second: 10,442.83629

Timestep Collection Time: 2.34533
Timestep Consumption Time: 2.44513
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.79046

Cumulative Model Updates: 123,022
Cumulative Timesteps: 1,026,825,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1026825362...
Checkpoint 1026825362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,166.43910
Policy Entropy: 1.69130
Value Function Loss: 0.06942

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.32085
Value Function Update Magnitude: 0.35437

Collected Steps per Second: 21,211.19556
Overall Steps per Second: 10,283.72062

Timestep Collection Time: 2.35838
Timestep Consumption Time: 2.50601
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.86439

Cumulative Model Updates: 123,028
Cumulative Timesteps: 1,026,875,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,393.24800
Policy Entropy: 1.68464
Value Function Loss: 0.06855

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.32053
Value Function Update Magnitude: 0.34602

Collected Steps per Second: 21,584.36842
Overall Steps per Second: 10,503.95748

Timestep Collection Time: 2.31723
Timestep Consumption Time: 2.44440
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.76163

Cumulative Model Updates: 123,034
Cumulative Timesteps: 1,026,925,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1026925402...
Checkpoint 1026925402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,595.50749
Policy Entropy: 1.67793
Value Function Loss: 0.07151

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.32075
Value Function Update Magnitude: 0.35260

Collected Steps per Second: 21,599.24146
Overall Steps per Second: 10,540.06959

Timestep Collection Time: 2.31508
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.74418

Cumulative Model Updates: 123,040
Cumulative Timesteps: 1,026,975,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,253.43058
Policy Entropy: 1.66120
Value Function Loss: 0.06795

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.32390
Value Function Update Magnitude: 0.32968

Collected Steps per Second: 21,825.56665
Overall Steps per Second: 10,502.73372

Timestep Collection Time: 2.29227
Timestep Consumption Time: 2.47126
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.76352

Cumulative Model Updates: 123,046
Cumulative Timesteps: 1,027,025,436

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1027025436...
Checkpoint 1027025436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,550.65153
Policy Entropy: 1.64957
Value Function Loss: 0.06834

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.31519
Value Function Update Magnitude: 0.30195

Collected Steps per Second: 21,769.85283
Overall Steps per Second: 10,487.97008

Timestep Collection Time: 2.29786
Timestep Consumption Time: 2.47180
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.76966

Cumulative Model Updates: 123,052
Cumulative Timesteps: 1,027,075,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,444.68575
Policy Entropy: 1.64412
Value Function Loss: 0.06598

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.28021
Value Function Update Magnitude: 0.34775

Collected Steps per Second: 21,790.21329
Overall Steps per Second: 10,539.56701

Timestep Collection Time: 2.29580
Timestep Consumption Time: 2.45069
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.74649

Cumulative Model Updates: 123,058
Cumulative Timesteps: 1,027,125,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1027125486...
Checkpoint 1027125486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,156.19316
Policy Entropy: 1.64674
Value Function Loss: 0.06602

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.28256
Value Function Update Magnitude: 0.36558

Collected Steps per Second: 21,572.93015
Overall Steps per Second: 10,338.83896

Timestep Collection Time: 2.31920
Timestep Consumption Time: 2.52003
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.83923

Cumulative Model Updates: 123,064
Cumulative Timesteps: 1,027,175,518

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,909.00416
Policy Entropy: 1.65840
Value Function Loss: 0.06674

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.28085
Value Function Update Magnitude: 0.35279

Collected Steps per Second: 22,026.22802
Overall Steps per Second: 10,449.81921

Timestep Collection Time: 2.27075
Timestep Consumption Time: 2.51556
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.78630

Cumulative Model Updates: 123,070
Cumulative Timesteps: 1,027,225,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1027225534...
Checkpoint 1027225534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,911.42308
Policy Entropy: 1.66228
Value Function Loss: 0.06422

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.29311
Value Function Update Magnitude: 0.33615

Collected Steps per Second: 21,719.53469
Overall Steps per Second: 10,530.47034

Timestep Collection Time: 2.30208
Timestep Consumption Time: 2.44605
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.74813

Cumulative Model Updates: 123,076
Cumulative Timesteps: 1,027,275,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,286.29939
Policy Entropy: 1.65887
Value Function Loss: 0.06341

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.29710
Value Function Update Magnitude: 0.32990

Collected Steps per Second: 21,671.60723
Overall Steps per Second: 10,532.16856

Timestep Collection Time: 2.30726
Timestep Consumption Time: 2.44029
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.74755

Cumulative Model Updates: 123,082
Cumulative Timesteps: 1,027,325,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1027325536...
Checkpoint 1027325536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,003.31747
Policy Entropy: 1.64928
Value Function Loss: 0.06462

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.30833
Value Function Update Magnitude: 0.32815

Collected Steps per Second: 21,239.20449
Overall Steps per Second: 10,288.00446

Timestep Collection Time: 2.35423
Timestep Consumption Time: 2.50599
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.86022

Cumulative Model Updates: 123,088
Cumulative Timesteps: 1,027,375,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,566.06849
Policy Entropy: 1.64026
Value Function Loss: 0.06765

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.31980
Value Function Update Magnitude: 0.33848

Collected Steps per Second: 21,635.47661
Overall Steps per Second: 10,365.77975

Timestep Collection Time: 2.31167
Timestep Consumption Time: 2.51325
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.82491

Cumulative Model Updates: 123,094
Cumulative Timesteps: 1,027,425,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1027425552...
Checkpoint 1027425552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,131.02151
Policy Entropy: 1.64149
Value Function Loss: 0.07242

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.32680
Value Function Update Magnitude: 0.35572

Collected Steps per Second: 20,593.58962
Overall Steps per Second: 10,294.14690

Timestep Collection Time: 2.42959
Timestep Consumption Time: 2.43084
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.86043

Cumulative Model Updates: 123,100
Cumulative Timesteps: 1,027,475,586

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,493.95483
Policy Entropy: 1.65822
Value Function Loss: 0.06936

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.31283
Value Function Update Magnitude: 0.38277

Collected Steps per Second: 20,962.60630
Overall Steps per Second: 10,377.13095

Timestep Collection Time: 2.38530
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.81848

Cumulative Model Updates: 123,106
Cumulative Timesteps: 1,027,525,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1027525588...
Checkpoint 1027525588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,314.45119
Policy Entropy: 1.67208
Value Function Loss: 0.07117

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.29861
Value Function Update Magnitude: 0.37598

Collected Steps per Second: 20,678.83740
Overall Steps per Second: 10,335.32839

Timestep Collection Time: 2.42016
Timestep Consumption Time: 2.42207
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.84223

Cumulative Model Updates: 123,112
Cumulative Timesteps: 1,027,575,634

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,601.77157
Policy Entropy: 1.66186
Value Function Loss: 0.07402

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.37850

Collected Steps per Second: 21,024.84167
Overall Steps per Second: 10,362.29847

Timestep Collection Time: 2.37928
Timestep Consumption Time: 2.44822
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.82750

Cumulative Model Updates: 123,118
Cumulative Timesteps: 1,027,625,658

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1027625658...
Checkpoint 1027625658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,749.30064
Policy Entropy: 1.65783
Value Function Loss: 0.06986

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.32286
Value Function Update Magnitude: 0.36733

Collected Steps per Second: 21,097.22797
Overall Steps per Second: 10,330.83075

Timestep Collection Time: 2.37055
Timestep Consumption Time: 2.47049
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.84104

Cumulative Model Updates: 123,124
Cumulative Timesteps: 1,027,675,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,164.95464
Policy Entropy: 1.66123
Value Function Loss: 0.06815

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.31379
Value Function Update Magnitude: 0.34154

Collected Steps per Second: 21,490.94829
Overall Steps per Second: 10,348.46580

Timestep Collection Time: 2.32731
Timestep Consumption Time: 2.50587
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.83318

Cumulative Model Updates: 123,130
Cumulative Timesteps: 1,027,725,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1027725686...
Checkpoint 1027725686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,609.31160
Policy Entropy: 1.65242
Value Function Loss: 0.06769

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.30187
Value Function Update Magnitude: 0.32830

Collected Steps per Second: 21,556.65198
Overall Steps per Second: 10,541.47751

Timestep Collection Time: 2.32012
Timestep Consumption Time: 2.42438
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.74450

Cumulative Model Updates: 123,136
Cumulative Timesteps: 1,027,775,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,773.25430
Policy Entropy: 1.66329
Value Function Loss: 0.06713

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.30497
Value Function Update Magnitude: 0.36091

Collected Steps per Second: 21,833.82285
Overall Steps per Second: 10,429.94060

Timestep Collection Time: 2.29076
Timestep Consumption Time: 2.50467
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.79543

Cumulative Model Updates: 123,142
Cumulative Timesteps: 1,027,825,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1027825716...
Checkpoint 1027825716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,087.26928
Policy Entropy: 1.66166
Value Function Loss: 0.06668

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.31482
Value Function Update Magnitude: 0.35903

Collected Steps per Second: 21,665.76353
Overall Steps per Second: 10,576.50604

Timestep Collection Time: 2.30936
Timestep Consumption Time: 2.42132
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.73067

Cumulative Model Updates: 123,148
Cumulative Timesteps: 1,027,875,750

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,025.98338
Policy Entropy: 1.67626
Value Function Loss: 0.06849

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.32395
Value Function Update Magnitude: 0.33826

Collected Steps per Second: 22,034.28946
Overall Steps per Second: 10,529.78255

Timestep Collection Time: 2.27055
Timestep Consumption Time: 2.48073
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.75129

Cumulative Model Updates: 123,154
Cumulative Timesteps: 1,027,925,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1027925780...
Checkpoint 1027925780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,691.50549
Policy Entropy: 1.66966
Value Function Loss: 0.07088

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.32580
Value Function Update Magnitude: 0.34294

Collected Steps per Second: 21,459.09027
Overall Steps per Second: 10,555.62991

Timestep Collection Time: 2.33048
Timestep Consumption Time: 2.40728
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.73776

Cumulative Model Updates: 123,160
Cumulative Timesteps: 1,027,975,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,791.59983
Policy Entropy: 1.66359
Value Function Loss: 0.07695

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.30622
Value Function Update Magnitude: 0.34559

Collected Steps per Second: 21,539.13926
Overall Steps per Second: 10,485.86676

Timestep Collection Time: 2.32182
Timestep Consumption Time: 2.44746
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.76928

Cumulative Model Updates: 123,166
Cumulative Timesteps: 1,028,025,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1028025800...
Checkpoint 1028025800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,653.95539
Policy Entropy: 1.65425
Value Function Loss: 0.07909

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.31944
Value Function Update Magnitude: 0.35435

Collected Steps per Second: 21,358.73789
Overall Steps per Second: 10,261.59669

Timestep Collection Time: 2.34293
Timestep Consumption Time: 2.53370
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.87663

Cumulative Model Updates: 123,172
Cumulative Timesteps: 1,028,075,842

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,113.63312
Policy Entropy: 1.66289
Value Function Loss: 0.08376

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.33027
Value Function Update Magnitude: 0.36851

Collected Steps per Second: 21,049.72513
Overall Steps per Second: 10,381.09466

Timestep Collection Time: 2.37656
Timestep Consumption Time: 2.44239
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.81895

Cumulative Model Updates: 123,178
Cumulative Timesteps: 1,028,125,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1028125868...
Checkpoint 1028125868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,545.33281
Policy Entropy: 1.66975
Value Function Loss: 0.07634

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.31648
Value Function Update Magnitude: 0.33685

Collected Steps per Second: 21,032.50261
Overall Steps per Second: 10,362.52533

Timestep Collection Time: 2.37803
Timestep Consumption Time: 2.44859
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.82662

Cumulative Model Updates: 123,184
Cumulative Timesteps: 1,028,175,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,216.93966
Policy Entropy: 1.68148
Value Function Loss: 0.06990

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.33411

Collected Steps per Second: 21,630.41058
Overall Steps per Second: 10,371.33438

Timestep Collection Time: 2.31175
Timestep Consumption Time: 2.50962
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.82137

Cumulative Model Updates: 123,190
Cumulative Timesteps: 1,028,225,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1028225888...
Checkpoint 1028225888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,746.87061
Policy Entropy: 1.69553
Value Function Loss: 0.06786

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.31038
Value Function Update Magnitude: 0.27487

Collected Steps per Second: 21,811.14183
Overall Steps per Second: 10,388.68501

Timestep Collection Time: 2.29360
Timestep Consumption Time: 2.52183
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.81543

Cumulative Model Updates: 123,196
Cumulative Timesteps: 1,028,275,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,812.55589
Policy Entropy: 1.71370
Value Function Loss: 0.07496

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.32589
Value Function Update Magnitude: 0.30121

Collected Steps per Second: 22,083.48618
Overall Steps per Second: 10,288.21146

Timestep Collection Time: 2.26459
Timestep Consumption Time: 2.59632
PPO Batch Consumption Time: 0.30316
Total Iteration Time: 4.86090

Cumulative Model Updates: 123,202
Cumulative Timesteps: 1,028,325,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1028325924...
Checkpoint 1028325924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,212.69560
Policy Entropy: 1.70016
Value Function Loss: 0.07637

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.32563
Value Function Update Magnitude: 0.32566

Collected Steps per Second: 21,532.27383
Overall Steps per Second: 10,504.07794

Timestep Collection Time: 2.32312
Timestep Consumption Time: 2.43903
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.76215

Cumulative Model Updates: 123,208
Cumulative Timesteps: 1,028,375,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,113.68653
Policy Entropy: 1.69892
Value Function Loss: 0.07882

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.29966
Value Function Update Magnitude: 0.32216

Collected Steps per Second: 21,597.68634
Overall Steps per Second: 10,488.81973

Timestep Collection Time: 2.31543
Timestep Consumption Time: 2.45231
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.76774

Cumulative Model Updates: 123,214
Cumulative Timesteps: 1,028,425,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1028425954...
Checkpoint 1028425954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,978.34835
Policy Entropy: 1.67495
Value Function Loss: 0.07058

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.31673
Value Function Update Magnitude: 0.32167

Collected Steps per Second: 21,553.03970
Overall Steps per Second: 10,316.54782

Timestep Collection Time: 2.32134
Timestep Consumption Time: 2.52834
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.84968

Cumulative Model Updates: 123,220
Cumulative Timesteps: 1,028,475,986

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,593.39851
Policy Entropy: 1.68802
Value Function Loss: 0.07157

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.32197
Value Function Update Magnitude: 0.34200

Collected Steps per Second: 21,773.79516
Overall Steps per Second: 10,415.47679

Timestep Collection Time: 2.29735
Timestep Consumption Time: 2.50531
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.80266

Cumulative Model Updates: 123,226
Cumulative Timesteps: 1,028,526,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1028526008...
Checkpoint 1028526008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,770.37230
Policy Entropy: 1.66605
Value Function Loss: 0.06890

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.32522
Value Function Update Magnitude: 0.35230

Collected Steps per Second: 21,943.34553
Overall Steps per Second: 10,586.86832

Timestep Collection Time: 2.27960
Timestep Consumption Time: 2.44531
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.72491

Cumulative Model Updates: 123,232
Cumulative Timesteps: 1,028,576,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,455.29848
Policy Entropy: 1.69531
Value Function Loss: 0.07889

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08214
Policy Update Magnitude: 0.32748
Value Function Update Magnitude: 0.31346

Collected Steps per Second: 21,422.96559
Overall Steps per Second: 10,447.18108

Timestep Collection Time: 2.33506
Timestep Consumption Time: 2.45321
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.78828

Cumulative Model Updates: 123,238
Cumulative Timesteps: 1,028,626,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1028626054...
Checkpoint 1028626054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,611.77252
Policy Entropy: 1.69226
Value Function Loss: 0.07889

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.32157
Value Function Update Magnitude: 0.26231

Collected Steps per Second: 21,195.90268
Overall Steps per Second: 10,251.37743

Timestep Collection Time: 2.35980
Timestep Consumption Time: 2.51935
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.87915

Cumulative Model Updates: 123,244
Cumulative Timesteps: 1,028,676,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,269.83615
Policy Entropy: 1.71464
Value Function Loss: 0.08566

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.32831
Value Function Update Magnitude: 0.25501

Collected Steps per Second: 21,175.22857
Overall Steps per Second: 10,418.15516

Timestep Collection Time: 2.36125
Timestep Consumption Time: 2.43806
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.79931

Cumulative Model Updates: 123,250
Cumulative Timesteps: 1,028,726,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1028726072...
Checkpoint 1028726072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,921.98047
Policy Entropy: 1.70469
Value Function Loss: 0.07679

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.33015
Value Function Update Magnitude: 0.32325

Collected Steps per Second: 21,035.56822
Overall Steps per Second: 10,231.66244

Timestep Collection Time: 2.37826
Timestep Consumption Time: 2.51127
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.88953

Cumulative Model Updates: 123,256
Cumulative Timesteps: 1,028,776,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,275.36564
Policy Entropy: 1.69447
Value Function Loss: 0.07134

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.32789
Value Function Update Magnitude: 0.36256

Collected Steps per Second: 21,047.10173
Overall Steps per Second: 10,392.15382

Timestep Collection Time: 2.37676
Timestep Consumption Time: 2.43687
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.81363

Cumulative Model Updates: 123,262
Cumulative Timesteps: 1,028,826,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1028826124...
Checkpoint 1028826124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,248.33491
Policy Entropy: 1.66896
Value Function Loss: 0.06024

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.31762
Value Function Update Magnitude: 0.34398

Collected Steps per Second: 21,300.83897
Overall Steps per Second: 10,255.07343

Timestep Collection Time: 2.34845
Timestep Consumption Time: 2.52952
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.87798

Cumulative Model Updates: 123,268
Cumulative Timesteps: 1,028,876,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,053.43550
Policy Entropy: 1.67517
Value Function Loss: 0.06479

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07615
Policy Update Magnitude: 0.31329
Value Function Update Magnitude: 0.32861

Collected Steps per Second: 21,191.22694
Overall Steps per Second: 10,231.38898

Timestep Collection Time: 2.36154
Timestep Consumption Time: 2.52968
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.89122

Cumulative Model Updates: 123,274
Cumulative Timesteps: 1,028,926,192

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1028926192...
Checkpoint 1028926192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,127.74996
Policy Entropy: 1.66058
Value Function Loss: 0.06504

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.31825
Value Function Update Magnitude: 0.31703

Collected Steps per Second: 21,706.69909
Overall Steps per Second: 10,311.85347

Timestep Collection Time: 2.30427
Timestep Consumption Time: 2.54627
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.85053

Cumulative Model Updates: 123,280
Cumulative Timesteps: 1,028,976,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,748.80360
Policy Entropy: 1.68087
Value Function Loss: 0.07411

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.32652
Value Function Update Magnitude: 0.32074

Collected Steps per Second: 21,054.89610
Overall Steps per Second: 10,191.46015

Timestep Collection Time: 2.37531
Timestep Consumption Time: 2.53193
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.90725

Cumulative Model Updates: 123,286
Cumulative Timesteps: 1,029,026,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1029026222...
Checkpoint 1029026222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,965.92569
Policy Entropy: 1.67616
Value Function Loss: 0.06867

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.32679
Value Function Update Magnitude: 0.31662

Collected Steps per Second: 21,764.30646
Overall Steps per Second: 10,541.11085

Timestep Collection Time: 2.29817
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.74504

Cumulative Model Updates: 123,292
Cumulative Timesteps: 1,029,076,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,855.38232
Policy Entropy: 1.70165
Value Function Loss: 0.07343

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.32182
Value Function Update Magnitude: 0.32180

Collected Steps per Second: 21,665.97194
Overall Steps per Second: 10,532.59672

Timestep Collection Time: 2.30860
Timestep Consumption Time: 2.44028
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.74888

Cumulative Model Updates: 123,298
Cumulative Timesteps: 1,029,126,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1029126258...
Checkpoint 1029126258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,797.51783
Policy Entropy: 1.68376
Value Function Loss: 0.07006

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.32178
Value Function Update Magnitude: 0.33274

Collected Steps per Second: 21,433.99548
Overall Steps per Second: 10,330.24169

Timestep Collection Time: 2.33405
Timestep Consumption Time: 2.50882
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.84287

Cumulative Model Updates: 123,304
Cumulative Timesteps: 1,029,176,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,190.12252
Policy Entropy: 1.69667
Value Function Loss: 0.07428

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.32160
Value Function Update Magnitude: 0.34575

Collected Steps per Second: 21,862.84846
Overall Steps per Second: 10,421.52343

Timestep Collection Time: 2.28744
Timestep Consumption Time: 2.51128
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.79872

Cumulative Model Updates: 123,310
Cumulative Timesteps: 1,029,226,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1029226296...
Checkpoint 1029226296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,761.75216
Policy Entropy: 1.69033
Value Function Loss: 0.06900

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.32241
Value Function Update Magnitude: 0.34883

Collected Steps per Second: 21,783.10538
Overall Steps per Second: 10,539.88697

Timestep Collection Time: 2.29637
Timestep Consumption Time: 2.44960
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.74597

Cumulative Model Updates: 123,316
Cumulative Timesteps: 1,029,276,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,851.13831
Policy Entropy: 1.70361
Value Function Loss: 0.06827

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.31830
Value Function Update Magnitude: 0.33684

Collected Steps per Second: 21,072.60618
Overall Steps per Second: 10,531.46751

Timestep Collection Time: 2.37512
Timestep Consumption Time: 2.37730
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.75242

Cumulative Model Updates: 123,322
Cumulative Timesteps: 1,029,326,368

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1029326368...
Checkpoint 1029326368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,036.18804
Policy Entropy: 1.69133
Value Function Loss: 0.06566

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07971
Policy Update Magnitude: 0.31635
Value Function Update Magnitude: 0.32245

Collected Steps per Second: 20,548.75986
Overall Steps per Second: 10,277.56431

Timestep Collection Time: 2.43402
Timestep Consumption Time: 2.43251
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.86652

Cumulative Model Updates: 123,328
Cumulative Timesteps: 1,029,376,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,693.49999
Policy Entropy: 1.67794
Value Function Loss: 0.06460

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.31576
Value Function Update Magnitude: 0.32216

Collected Steps per Second: 20,652.61725
Overall Steps per Second: 10,324.61223

Timestep Collection Time: 2.42110
Timestep Consumption Time: 2.42189
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.84299

Cumulative Model Updates: 123,334
Cumulative Timesteps: 1,029,426,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1029426386...
Checkpoint 1029426386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,552.67742
Policy Entropy: 1.66111
Value Function Loss: 0.06493

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.31288

Collected Steps per Second: 20,696.23862
Overall Steps per Second: 10,321.93544

Timestep Collection Time: 2.41609
Timestep Consumption Time: 2.42835
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.84444

Cumulative Model Updates: 123,340
Cumulative Timesteps: 1,029,476,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,311.97781
Policy Entropy: 1.65343
Value Function Loss: 0.06358

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.31389
Value Function Update Magnitude: 0.30563

Collected Steps per Second: 21,176.78182
Overall Steps per Second: 10,333.92051

Timestep Collection Time: 2.36325
Timestep Consumption Time: 2.47964
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.84289

Cumulative Model Updates: 123,346
Cumulative Timesteps: 1,029,526,436

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1029526436...
Checkpoint 1029526436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,022.85804
Policy Entropy: 1.66861
Value Function Loss: 0.06817

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.31826
Value Function Update Magnitude: 0.30332

Collected Steps per Second: 21,438.56244
Overall Steps per Second: 10,391.53667

Timestep Collection Time: 2.33253
Timestep Consumption Time: 2.47966
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.81219

Cumulative Model Updates: 123,352
Cumulative Timesteps: 1,029,576,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,446.75763
Policy Entropy: 1.71595
Value Function Loss: 0.08255

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.32593
Value Function Update Magnitude: 0.29168

Collected Steps per Second: 21,851.74104
Overall Steps per Second: 10,309.11428

Timestep Collection Time: 2.28851
Timestep Consumption Time: 2.56234
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.85085

Cumulative Model Updates: 123,358
Cumulative Timesteps: 1,029,626,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1029626450...
Checkpoint 1029626450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,608.47661
Policy Entropy: 1.73658
Value Function Loss: 0.08140

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.32593
Value Function Update Magnitude: 0.30115

Collected Steps per Second: 21,318.71193
Overall Steps per Second: 10,360.42942

Timestep Collection Time: 2.34761
Timestep Consumption Time: 2.48308
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.83069

Cumulative Model Updates: 123,364
Cumulative Timesteps: 1,029,676,498

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,708.06404
Policy Entropy: 1.73657
Value Function Loss: 0.08142

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.32839
Value Function Update Magnitude: 0.30655

Collected Steps per Second: 22,192.18790
Overall Steps per Second: 10,628.72286

Timestep Collection Time: 2.25350
Timestep Consumption Time: 2.45168
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.70517

Cumulative Model Updates: 123,370
Cumulative Timesteps: 1,029,726,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1029726508...
Checkpoint 1029726508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,676.49370
Policy Entropy: 1.69048
Value Function Loss: 0.06946

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.32725
Value Function Update Magnitude: 0.30528

Collected Steps per Second: 21,607.90814
Overall Steps per Second: 10,418.60629

Timestep Collection Time: 2.31471
Timestep Consumption Time: 2.48593
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.80064

Cumulative Model Updates: 123,376
Cumulative Timesteps: 1,029,776,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,697.34303
Policy Entropy: 1.68573
Value Function Loss: 0.07313

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.32098
Value Function Update Magnitude: 0.33749

Collected Steps per Second: 21,117.89423
Overall Steps per Second: 10,311.47506

Timestep Collection Time: 2.36899
Timestep Consumption Time: 2.48270
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.85168

Cumulative Model Updates: 123,382
Cumulative Timesteps: 1,029,826,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1029826552...
Checkpoint 1029826552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,241.53687
Policy Entropy: 1.71766
Value Function Loss: 0.08082

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.32570
Value Function Update Magnitude: 0.35672

Collected Steps per Second: 21,080.74747
Overall Steps per Second: 10,197.13038

Timestep Collection Time: 2.37221
Timestep Consumption Time: 2.53191
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.90412

Cumulative Model Updates: 123,388
Cumulative Timesteps: 1,029,876,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,645.05812
Policy Entropy: 1.73753
Value Function Loss: 0.08636

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.31387
Value Function Update Magnitude: 0.37878

Collected Steps per Second: 21,457.50150
Overall Steps per Second: 10,550.33466

Timestep Collection Time: 2.33121
Timestep Consumption Time: 2.41006
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.74127

Cumulative Model Updates: 123,394
Cumulative Timesteps: 1,029,926,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1029926582...
Checkpoint 1029926582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,260.12192
Policy Entropy: 1.71125
Value Function Loss: 0.08317

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.31037
Value Function Update Magnitude: 0.38020

Collected Steps per Second: 21,360.44639
Overall Steps per Second: 10,474.32158

Timestep Collection Time: 2.34152
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.77511

Cumulative Model Updates: 123,400
Cumulative Timesteps: 1,029,976,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,211.22140
Policy Entropy: 1.71139
Value Function Loss: 0.08004

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.32684
Value Function Update Magnitude: 0.36737

Collected Steps per Second: 21,819.88903
Overall Steps per Second: 10,526.43409

Timestep Collection Time: 2.29231
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.75166

Cumulative Model Updates: 123,406
Cumulative Timesteps: 1,030,026,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1030026616...
Checkpoint 1030026616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,380.55701
Policy Entropy: 1.70716
Value Function Loss: 0.07699

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.33302
Value Function Update Magnitude: 0.37384

Collected Steps per Second: 21,148.68791
Overall Steps per Second: 10,202.84552

Timestep Collection Time: 2.36440
Timestep Consumption Time: 2.53658
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.90099

Cumulative Model Updates: 123,412
Cumulative Timesteps: 1,030,076,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,325.03210
Policy Entropy: 1.72724
Value Function Loss: 0.07631

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.33269
Value Function Update Magnitude: 0.36435

Collected Steps per Second: 21,986.19246
Overall Steps per Second: 10,447.64712

Timestep Collection Time: 2.27434
Timestep Consumption Time: 2.51181
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.78615

Cumulative Model Updates: 123,418
Cumulative Timesteps: 1,030,126,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1030126624...
Checkpoint 1030126624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,631.25704
Policy Entropy: 1.68089
Value Function Loss: 0.07014

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.32727
Value Function Update Magnitude: 0.35716

Collected Steps per Second: 21,506.33585
Overall Steps per Second: 10,346.18722

Timestep Collection Time: 2.32648
Timestep Consumption Time: 2.50951
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.83598

Cumulative Model Updates: 123,424
Cumulative Timesteps: 1,030,176,658

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,985.19357
Policy Entropy: 1.67574
Value Function Loss: 0.06682

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.32417
Value Function Update Magnitude: 0.36382

Collected Steps per Second: 21,799.59401
Overall Steps per Second: 10,405.20231

Timestep Collection Time: 2.29445
Timestep Consumption Time: 2.51257
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.80702

Cumulative Model Updates: 123,430
Cumulative Timesteps: 1,030,226,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1030226676...
Checkpoint 1030226676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,467.73982
Policy Entropy: 1.66781
Value Function Loss: 0.06343

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.31920
Value Function Update Magnitude: 0.36094

Collected Steps per Second: 21,384.51870
Overall Steps per Second: 10,296.37892

Timestep Collection Time: 2.33936
Timestep Consumption Time: 2.51925
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.85860

Cumulative Model Updates: 123,436
Cumulative Timesteps: 1,030,276,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,606.96675
Policy Entropy: 1.68210
Value Function Loss: 0.06539

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.31832
Value Function Update Magnitude: 0.35529

Collected Steps per Second: 21,742.45515
Overall Steps per Second: 10,463.85240

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.47940
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.77969

Cumulative Model Updates: 123,442
Cumulative Timesteps: 1,030,326,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1030326716...
Checkpoint 1030326716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,960.43101
Policy Entropy: 1.67142
Value Function Loss: 0.06367

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.31822
Value Function Update Magnitude: 0.34391

Collected Steps per Second: 21,815.25900
Overall Steps per Second: 10,506.83006

Timestep Collection Time: 2.29417
Timestep Consumption Time: 2.46920
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.76338

Cumulative Model Updates: 123,448
Cumulative Timesteps: 1,030,376,764

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,791.19234
Policy Entropy: 1.67969
Value Function Loss: 0.06977

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.32248
Value Function Update Magnitude: 0.34534

Collected Steps per Second: 21,081.99730
Overall Steps per Second: 10,406.74448

Timestep Collection Time: 2.37226
Timestep Consumption Time: 2.43347
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.80573

Cumulative Model Updates: 123,454
Cumulative Timesteps: 1,030,426,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1030426776...
Checkpoint 1030426776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,078.23606
Policy Entropy: 1.69955
Value Function Loss: 0.07523

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.32953
Value Function Update Magnitude: 0.35387

Collected Steps per Second: 21,297.75012
Overall Steps per Second: 10,304.68191

Timestep Collection Time: 2.34879
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.85449

Cumulative Model Updates: 123,460
Cumulative Timesteps: 1,030,476,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,241.00078
Policy Entropy: 1.70983
Value Function Loss: 0.07669

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.33191
Value Function Update Magnitude: 0.35986

Collected Steps per Second: 21,666.74595
Overall Steps per Second: 10,383.27899

Timestep Collection Time: 2.30815
Timestep Consumption Time: 2.50825
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.81640

Cumulative Model Updates: 123,466
Cumulative Timesteps: 1,030,526,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1030526810...
Checkpoint 1030526810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,543.07735
Policy Entropy: 1.71697
Value Function Loss: 0.07625

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.32795
Value Function Update Magnitude: 0.35993

Collected Steps per Second: 20,648.56062
Overall Steps per Second: 10,315.92989

Timestep Collection Time: 2.42264
Timestep Consumption Time: 2.42656
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.84920

Cumulative Model Updates: 123,472
Cumulative Timesteps: 1,030,576,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,066.77080
Policy Entropy: 1.70251
Value Function Loss: 0.07224

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.32181
Value Function Update Magnitude: 0.35789

Collected Steps per Second: 20,880.07570
Overall Steps per Second: 10,324.67339

Timestep Collection Time: 2.39549
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.84451

Cumulative Model Updates: 123,478
Cumulative Timesteps: 1,030,626,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1030626852...
Checkpoint 1030626852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,423.82056
Policy Entropy: 1.71316
Value Function Loss: 0.07794

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.29711
Value Function Update Magnitude: 0.34769

Collected Steps per Second: 20,565.07163
Overall Steps per Second: 10,239.17157

Timestep Collection Time: 2.43247
Timestep Consumption Time: 2.45308
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.88555

Cumulative Model Updates: 123,484
Cumulative Timesteps: 1,030,676,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,528.82357
Policy Entropy: 1.69468
Value Function Loss: 0.07326

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.29966
Value Function Update Magnitude: 0.35255

Collected Steps per Second: 20,884.95989
Overall Steps per Second: 10,454.72910

Timestep Collection Time: 2.39541
Timestep Consumption Time: 2.38979
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.78520

Cumulative Model Updates: 123,490
Cumulative Timesteps: 1,030,726,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1030726904...
Checkpoint 1030726904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,535.60353
Policy Entropy: 1.69640
Value Function Loss: 0.07503

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.31943
Value Function Update Magnitude: 0.34512

Collected Steps per Second: 21,193.83009
Overall Steps per Second: 10,518.52562

Timestep Collection Time: 2.35937
Timestep Consumption Time: 2.39453
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.75390

Cumulative Model Updates: 123,496
Cumulative Timesteps: 1,030,776,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,685.75789
Policy Entropy: 1.69691
Value Function Loss: 0.07683

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.32567
Value Function Update Magnitude: 0.32158

Collected Steps per Second: 21,420.39843
Overall Steps per Second: 10,516.48952

Timestep Collection Time: 2.33609
Timestep Consumption Time: 2.42215
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.75824

Cumulative Model Updates: 123,502
Cumulative Timesteps: 1,030,826,948

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1030826948...
Checkpoint 1030826948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,041.49608
Policy Entropy: 1.72315
Value Function Loss: 0.08144

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.33115
Value Function Update Magnitude: 0.34345

Collected Steps per Second: 21,843.54145
Overall Steps per Second: 10,575.85315

Timestep Collection Time: 2.29020
Timestep Consumption Time: 2.44001
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.73021

Cumulative Model Updates: 123,508
Cumulative Timesteps: 1,030,876,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,678.83567
Policy Entropy: 1.72535
Value Function Loss: 0.08429

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.33366
Value Function Update Magnitude: 0.37726

Collected Steps per Second: 21,762.32908
Overall Steps per Second: 10,529.41432

Timestep Collection Time: 2.29755
Timestep Consumption Time: 2.45105
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.74860

Cumulative Model Updates: 123,514
Cumulative Timesteps: 1,030,926,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1030926974...
Checkpoint 1030926974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,074.89672
Policy Entropy: 1.71058
Value Function Loss: 0.08081

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.33246
Value Function Update Magnitude: 0.40095

Collected Steps per Second: 21,429.14382
Overall Steps per Second: 10,558.24498

Timestep Collection Time: 2.33355
Timestep Consumption Time: 2.40265
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.73620

Cumulative Model Updates: 123,520
Cumulative Timesteps: 1,030,976,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,253.81842
Policy Entropy: 1.68779
Value Function Loss: 0.07535

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.32658
Value Function Update Magnitude: 0.39467

Collected Steps per Second: 21,485.40773
Overall Steps per Second: 10,493.55561

Timestep Collection Time: 2.32828
Timestep Consumption Time: 2.43884
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.76712

Cumulative Model Updates: 123,526
Cumulative Timesteps: 1,031,027,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1031027004...
Checkpoint 1031027004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,423.06163
Policy Entropy: 1.67561
Value Function Loss: 0.07061

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.32665
Value Function Update Magnitude: 0.37228

Collected Steps per Second: 21,336.03561
Overall Steps per Second: 10,266.38665

Timestep Collection Time: 2.34430
Timestep Consumption Time: 2.52772
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.87202

Cumulative Model Updates: 123,532
Cumulative Timesteps: 1,031,077,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,080.96314
Policy Entropy: 1.66796
Value Function Loss: 0.07282

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.32460
Value Function Update Magnitude: 0.36555

Collected Steps per Second: 21,777.49801
Overall Steps per Second: 10,431.77518

Timestep Collection Time: 2.29604
Timestep Consumption Time: 2.49720
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.79324

Cumulative Model Updates: 123,538
Cumulative Timesteps: 1,031,127,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1031127024...
Checkpoint 1031127024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,765.11033
Policy Entropy: 1.66622
Value Function Loss: 0.07034

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.32897
Value Function Update Magnitude: 0.36307

Collected Steps per Second: 21,384.74064
Overall Steps per Second: 10,286.31978

Timestep Collection Time: 2.33849
Timestep Consumption Time: 2.52311
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.86160

Cumulative Model Updates: 123,544
Cumulative Timesteps: 1,031,177,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,176.61310
Policy Entropy: 1.69363
Value Function Loss: 0.07559

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.32921
Value Function Update Magnitude: 0.35126

Collected Steps per Second: 21,844.88914
Overall Steps per Second: 10,363.72187

Timestep Collection Time: 2.28886
Timestep Consumption Time: 2.53566
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.82452

Cumulative Model Updates: 123,550
Cumulative Timesteps: 1,031,227,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1031227032...
Checkpoint 1031227032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,369.84341
Policy Entropy: 1.69745
Value Function Loss: 0.07519

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.33028
Value Function Update Magnitude: 0.35876

Collected Steps per Second: 21,726.70584
Overall Steps per Second: 10,516.32396

Timestep Collection Time: 2.30224
Timestep Consumption Time: 2.45418
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.75641

Cumulative Model Updates: 123,556
Cumulative Timesteps: 1,031,277,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,582.90116
Policy Entropy: 1.69591
Value Function Loss: 0.07477

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.32493
Value Function Update Magnitude: 0.36874

Collected Steps per Second: 21,852.01674
Overall Steps per Second: 10,550.25901

Timestep Collection Time: 2.28913
Timestep Consumption Time: 2.45218
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.74131

Cumulative Model Updates: 123,562
Cumulative Timesteps: 1,031,327,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1031327074...
Checkpoint 1031327074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,490.54980
Policy Entropy: 1.68018
Value Function Loss: 0.06951

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.32527
Value Function Update Magnitude: 0.36365

Collected Steps per Second: 21,245.79459
Overall Steps per Second: 10,255.48754

Timestep Collection Time: 2.35491
Timestep Consumption Time: 2.52365
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.87856

Cumulative Model Updates: 123,568
Cumulative Timesteps: 1,031,377,106

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,460.23646
Policy Entropy: 1.68616
Value Function Loss: 0.07314

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.33263
Value Function Update Magnitude: 0.37212

Collected Steps per Second: 21,515.04692
Overall Steps per Second: 10,379.75692

Timestep Collection Time: 2.32498
Timestep Consumption Time: 2.49421
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.81919

Cumulative Model Updates: 123,574
Cumulative Timesteps: 1,031,427,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1031427128...
Checkpoint 1031427128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,263.84452
Policy Entropy: 1.70043
Value Function Loss: 0.07647

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.31659
Value Function Update Magnitude: 0.37337

Collected Steps per Second: 21,435.15570
Overall Steps per Second: 10,323.63459

Timestep Collection Time: 2.33262
Timestep Consumption Time: 2.51064
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.84326

Cumulative Model Updates: 123,580
Cumulative Timesteps: 1,031,477,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,596.33537
Policy Entropy: 1.70347
Value Function Loss: 0.07772

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.29312
Value Function Update Magnitude: 0.35050

Collected Steps per Second: 21,809.23765
Overall Steps per Second: 10,369.89219

Timestep Collection Time: 2.29261
Timestep Consumption Time: 2.52904
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.82165

Cumulative Model Updates: 123,586
Cumulative Timesteps: 1,031,527,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1031527128...
Checkpoint 1031527128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,034.48985
Policy Entropy: 1.70141
Value Function Loss: 0.08203

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.31202
Value Function Update Magnitude: 0.31414

Collected Steps per Second: 21,190.73816
Overall Steps per Second: 10,232.97489

Timestep Collection Time: 2.36047
Timestep Consumption Time: 2.52765
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.88812

Cumulative Model Updates: 123,592
Cumulative Timesteps: 1,031,577,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,445.00661
Policy Entropy: 1.68476
Value Function Loss: 0.07822

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.33589
Value Function Update Magnitude: 0.27064

Collected Steps per Second: 20,795.21169
Overall Steps per Second: 10,210.76758

Timestep Collection Time: 2.40546
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.89895

Cumulative Model Updates: 123,598
Cumulative Timesteps: 1,031,627,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1031627170...
Checkpoint 1031627170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,050.18719
Policy Entropy: 1.68082
Value Function Loss: 0.07848

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.33286
Value Function Update Magnitude: 0.29848

Collected Steps per Second: 20,586.54108
Overall Steps per Second: 10,037.03907

Timestep Collection Time: 2.42955
Timestep Consumption Time: 2.55359
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.98314

Cumulative Model Updates: 123,604
Cumulative Timesteps: 1,031,677,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,118.80064
Policy Entropy: 1.67624
Value Function Loss: 0.07264

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.32901
Value Function Update Magnitude: 0.32458

Collected Steps per Second: 21,571.04929
Overall Steps per Second: 10,412.49219

Timestep Collection Time: 2.31820
Timestep Consumption Time: 2.48430
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.80250

Cumulative Model Updates: 123,610
Cumulative Timesteps: 1,031,727,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1031727192...
Checkpoint 1031727192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,398.61569
Policy Entropy: 1.67666
Value Function Loss: 0.07959

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.31063
Value Function Update Magnitude: 0.34816

Collected Steps per Second: 21,784.38002
Overall Steps per Second: 10,412.64743

Timestep Collection Time: 2.29587
Timestep Consumption Time: 2.50733
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.80320

Cumulative Model Updates: 123,616
Cumulative Timesteps: 1,031,777,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,481.16236
Policy Entropy: 1.67628
Value Function Loss: 0.08249

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.29776
Value Function Update Magnitude: 0.34976

Collected Steps per Second: 21,761.93346
Overall Steps per Second: 10,403.84681

Timestep Collection Time: 2.29842
Timestep Consumption Time: 2.50923
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.80764

Cumulative Model Updates: 123,622
Cumulative Timesteps: 1,031,827,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1031827224...
Checkpoint 1031827224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,871.21018
Policy Entropy: 1.68686
Value Function Loss: 0.08685

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.31856
Value Function Update Magnitude: 0.34023

Collected Steps per Second: 21,702.16005
Overall Steps per Second: 10,537.57300

Timestep Collection Time: 2.30419
Timestep Consumption Time: 2.44130
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.74550

Cumulative Model Updates: 123,628
Cumulative Timesteps: 1,031,877,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,859.07456
Policy Entropy: 1.68287
Value Function Loss: 0.08215

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.33586
Value Function Update Magnitude: 0.35847

Collected Steps per Second: 21,709.74792
Overall Steps per Second: 10,355.65408

Timestep Collection Time: 2.30357
Timestep Consumption Time: 2.52567
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.82925

Cumulative Model Updates: 123,634
Cumulative Timesteps: 1,031,927,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1031927240...
Checkpoint 1031927240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,878.21061
Policy Entropy: 1.67745
Value Function Loss: 0.07426

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.32242
Value Function Update Magnitude: 0.35647

Collected Steps per Second: 21,499.00998
Overall Steps per Second: 10,355.52828

Timestep Collection Time: 2.32708
Timestep Consumption Time: 2.50415
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.83124

Cumulative Model Updates: 123,640
Cumulative Timesteps: 1,031,977,270

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,004.03743
Policy Entropy: 1.67022
Value Function Loss: 0.06958

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.29064
Value Function Update Magnitude: 0.34665

Collected Steps per Second: 21,963.61226
Overall Steps per Second: 10,460.21037

Timestep Collection Time: 2.27777
Timestep Consumption Time: 2.50493
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.78270

Cumulative Model Updates: 123,646
Cumulative Timesteps: 1,032,027,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1032027298...
Checkpoint 1032027298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,146.13028
Policy Entropy: 1.68684
Value Function Loss: 0.06759

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.28658
Value Function Update Magnitude: 0.34303

Collected Steps per Second: 21,789.29742
Overall Steps per Second: 10,503.46903

Timestep Collection Time: 2.29590
Timestep Consumption Time: 2.46691
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.76281

Cumulative Model Updates: 123,652
Cumulative Timesteps: 1,032,077,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,704.42390
Policy Entropy: 1.68505
Value Function Loss: 0.06807

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.30475
Value Function Update Magnitude: 0.34598

Collected Steps per Second: 21,480.34935
Overall Steps per Second: 10,463.51439

Timestep Collection Time: 2.32790
Timestep Consumption Time: 2.45100
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.77889

Cumulative Model Updates: 123,658
Cumulative Timesteps: 1,032,127,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1032127328...
Checkpoint 1032127328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,455.80462
Policy Entropy: 1.69291
Value Function Loss: 0.07028

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.31117
Value Function Update Magnitude: 0.34404

Collected Steps per Second: 21,236.46895
Overall Steps per Second: 10,283.48460

Timestep Collection Time: 2.35519
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.86372

Cumulative Model Updates: 123,664
Cumulative Timesteps: 1,032,177,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,481.94033
Policy Entropy: 1.67882
Value Function Loss: 0.06769

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.31669
Value Function Update Magnitude: 0.34011

Collected Steps per Second: 20,594.15182
Overall Steps per Second: 10,412.21086

Timestep Collection Time: 2.42904
Timestep Consumption Time: 2.37532
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.80436

Cumulative Model Updates: 123,670
Cumulative Timesteps: 1,032,227,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1032227368...
Checkpoint 1032227368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,168.11464
Policy Entropy: 1.66962
Value Function Loss: 0.07642

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.32430
Value Function Update Magnitude: 0.32185

Collected Steps per Second: 20,198.85588
Overall Steps per Second: 10,165.66961

Timestep Collection Time: 2.47648
Timestep Consumption Time: 2.44420
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.92068

Cumulative Model Updates: 123,676
Cumulative Timesteps: 1,032,277,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,957.32197
Policy Entropy: 1.67478
Value Function Loss: 0.07914

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.33852
Value Function Update Magnitude: 0.33985

Collected Steps per Second: 20,738.98974
Overall Steps per Second: 10,461.63223

Timestep Collection Time: 2.41217
Timestep Consumption Time: 2.36968
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.78185

Cumulative Model Updates: 123,682
Cumulative Timesteps: 1,032,327,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1032327416...
Checkpoint 1032327416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,311.74431
Policy Entropy: 1.68645
Value Function Loss: 0.08137

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.33382
Value Function Update Magnitude: 0.37880

Collected Steps per Second: 20,884.88449
Overall Steps per Second: 10,363.95661

Timestep Collection Time: 2.39580
Timestep Consumption Time: 2.43209
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.82789

Cumulative Model Updates: 123,688
Cumulative Timesteps: 1,032,377,452

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,210.28803
Policy Entropy: 1.69538
Value Function Loss: 0.07680

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.33211
Value Function Update Magnitude: 0.38664

Collected Steps per Second: 21,206.89617
Overall Steps per Second: 10,407.11681

Timestep Collection Time: 2.35857
Timestep Consumption Time: 2.44756
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.80613

Cumulative Model Updates: 123,694
Cumulative Timesteps: 1,032,427,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1032427470...
Checkpoint 1032427470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,030.81003
Policy Entropy: 1.68719
Value Function Loss: 0.07174

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.33271
Value Function Update Magnitude: 0.39900

Collected Steps per Second: 21,086.80147
Overall Steps per Second: 10,491.02937

Timestep Collection Time: 2.37248
Timestep Consumption Time: 2.39617
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.76865

Cumulative Model Updates: 123,700
Cumulative Timesteps: 1,032,477,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,726.79086
Policy Entropy: 1.68057
Value Function Loss: 0.06930

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.33047
Value Function Update Magnitude: 0.40097

Collected Steps per Second: 21,289.20166
Overall Steps per Second: 10,466.17938

Timestep Collection Time: 2.34945
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.77901

Cumulative Model Updates: 123,706
Cumulative Timesteps: 1,032,527,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1032527516...
Checkpoint 1032527516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,408.35759
Policy Entropy: 1.68586
Value Function Loss: 0.07060

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07639
Policy Update Magnitude: 0.32748
Value Function Update Magnitude: 0.39805

Collected Steps per Second: 21,661.69248
Overall Steps per Second: 10,583.45209

Timestep Collection Time: 2.30942
Timestep Consumption Time: 2.41739
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.72681

Cumulative Model Updates: 123,712
Cumulative Timesteps: 1,032,577,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,614.65427
Policy Entropy: 1.67689
Value Function Loss: 0.07384

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.33146
Value Function Update Magnitude: 0.39218

Collected Steps per Second: 21,784.77265
Overall Steps per Second: 10,581.39282

Timestep Collection Time: 2.29555
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.72603

Cumulative Model Updates: 123,718
Cumulative Timesteps: 1,032,627,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1032627550...
Checkpoint 1032627550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,424.86597
Policy Entropy: 1.67540
Value Function Loss: 0.07268

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.32893
Value Function Update Magnitude: 0.40249

Collected Steps per Second: 21,925.77905
Overall Steps per Second: 10,582.28144

Timestep Collection Time: 2.28161
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.72734

Cumulative Model Updates: 123,724
Cumulative Timesteps: 1,032,677,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,494.25598
Policy Entropy: 1.66363
Value Function Loss: 0.06754

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.31786
Value Function Update Magnitude: 0.39677

Collected Steps per Second: 21,733.85961
Overall Steps per Second: 10,469.57608

Timestep Collection Time: 2.30102
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.77670

Cumulative Model Updates: 123,730
Cumulative Timesteps: 1,032,727,586

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1032727586...
Checkpoint 1032727586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,486.60961
Policy Entropy: 1.68606
Value Function Loss: 0.07099

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.30647
Value Function Update Magnitude: 0.38682

Collected Steps per Second: 21,039.79402
Overall Steps per Second: 10,179.40458

Timestep Collection Time: 2.37740
Timestep Consumption Time: 2.53644
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.91384

Cumulative Model Updates: 123,736
Cumulative Timesteps: 1,032,777,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,879.92438
Policy Entropy: 1.68697
Value Function Loss: 0.07155

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.31671
Value Function Update Magnitude: 0.38733

Collected Steps per Second: 21,272.57883
Overall Steps per Second: 10,393.03207

Timestep Collection Time: 2.35176
Timestep Consumption Time: 2.46185
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.81361

Cumulative Model Updates: 123,742
Cumulative Timesteps: 1,032,827,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1032827634...
Checkpoint 1032827634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,016.56130
Policy Entropy: 1.68756
Value Function Loss: 0.07265

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.31355
Value Function Update Magnitude: 0.38011

Collected Steps per Second: 20,896.41764
Overall Steps per Second: 10,261.95236

Timestep Collection Time: 2.39438
Timestep Consumption Time: 2.48130
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.87568

Cumulative Model Updates: 123,748
Cumulative Timesteps: 1,032,877,668

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,386.10697
Policy Entropy: 1.67729
Value Function Loss: 0.06610

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.29349
Value Function Update Magnitude: 0.35245

Collected Steps per Second: 21,491.71577
Overall Steps per Second: 10,432.14102

Timestep Collection Time: 2.32834
Timestep Consumption Time: 2.46838
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.79671

Cumulative Model Updates: 123,754
Cumulative Timesteps: 1,032,927,708

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1032927708...
Checkpoint 1032927708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,460.39532
Policy Entropy: 1.68802
Value Function Loss: 0.06668

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.30795
Value Function Update Magnitude: 0.34261

Collected Steps per Second: 21,488.33726
Overall Steps per Second: 10,258.31864

Timestep Collection Time: 2.32861
Timestep Consumption Time: 2.54919
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.87780

Cumulative Model Updates: 123,760
Cumulative Timesteps: 1,032,977,746

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,737.93074
Policy Entropy: 1.70344
Value Function Loss: 0.07001

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.31998
Value Function Update Magnitude: 0.33837

Collected Steps per Second: 21,589.46293
Overall Steps per Second: 10,450.46906

Timestep Collection Time: 2.31743
Timestep Consumption Time: 2.47011
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.78754

Cumulative Model Updates: 123,766
Cumulative Timesteps: 1,033,027,778

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1033027778...
Checkpoint 1033027778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,941.87821
Policy Entropy: 1.69156
Value Function Loss: 0.06842

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.31973
Value Function Update Magnitude: 0.34439

Collected Steps per Second: 21,524.72544
Overall Steps per Second: 10,330.59366

Timestep Collection Time: 2.32347
Timestep Consumption Time: 2.51769
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.84115

Cumulative Model Updates: 123,772
Cumulative Timesteps: 1,033,077,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,114.74139
Policy Entropy: 1.67913
Value Function Loss: 0.06773

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.32133
Value Function Update Magnitude: 0.35024

Collected Steps per Second: 22,033.70478
Overall Steps per Second: 10,457.37139

Timestep Collection Time: 2.27016
Timestep Consumption Time: 2.51307
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.78323

Cumulative Model Updates: 123,778
Cumulative Timesteps: 1,033,127,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1033127810...
Checkpoint 1033127810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,289.07188
Policy Entropy: 1.66486
Value Function Loss: 0.06227

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.32222
Value Function Update Magnitude: 0.34926

Collected Steps per Second: 21,429.52696
Overall Steps per Second: 10,448.87121

Timestep Collection Time: 2.33454
Timestep Consumption Time: 2.45335
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.78789

Cumulative Model Updates: 123,784
Cumulative Timesteps: 1,033,177,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,253.55839
Policy Entropy: 1.66436
Value Function Loss: 0.06616

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.32067
Value Function Update Magnitude: 0.35107

Collected Steps per Second: 21,767.34441
Overall Steps per Second: 10,544.39908

Timestep Collection Time: 2.29812
Timestep Consumption Time: 2.44601
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.74413

Cumulative Model Updates: 123,790
Cumulative Timesteps: 1,033,227,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1033227862...
Checkpoint 1033227862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,908.48705
Policy Entropy: 1.67969
Value Function Loss: 0.07113

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.32494
Value Function Update Magnitude: 0.34257

Collected Steps per Second: 21,821.47782
Overall Steps per Second: 10,570.73047

Timestep Collection Time: 2.29215
Timestep Consumption Time: 2.43960
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.73174

Cumulative Model Updates: 123,796
Cumulative Timesteps: 1,033,277,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,756.58597
Policy Entropy: 1.67460
Value Function Loss: 0.07047

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.32041
Value Function Update Magnitude: 0.32728

Collected Steps per Second: 21,314.67911
Overall Steps per Second: 10,431.54261

Timestep Collection Time: 2.34636
Timestep Consumption Time: 2.44794
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.79431

Cumulative Model Updates: 123,802
Cumulative Timesteps: 1,033,327,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1033327892...
Checkpoint 1033327892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,712.71101
Policy Entropy: 1.67040
Value Function Loss: 0.06667

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.31712
Value Function Update Magnitude: 0.35106

Collected Steps per Second: 21,267.93937
Overall Steps per Second: 10,274.50956

Timestep Collection Time: 2.35124
Timestep Consumption Time: 2.51576
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.86700

Cumulative Model Updates: 123,808
Cumulative Timesteps: 1,033,377,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,750.15125
Policy Entropy: 1.66059
Value Function Loss: 0.06683

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.31926
Value Function Update Magnitude: 0.35540

Collected Steps per Second: 21,702.94421
Overall Steps per Second: 10,438.69422

Timestep Collection Time: 2.30420
Timestep Consumption Time: 2.48643
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.79064

Cumulative Model Updates: 123,814
Cumulative Timesteps: 1,033,427,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1033427906...
Checkpoint 1033427906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,128.76657
Policy Entropy: 1.68620
Value Function Loss: 0.06644

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.31944
Value Function Update Magnitude: 0.33760

Collected Steps per Second: 21,386.74924
Overall Steps per Second: 10,307.17797

Timestep Collection Time: 2.33902
Timestep Consumption Time: 2.51430
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.85332

Cumulative Model Updates: 123,820
Cumulative Timesteps: 1,033,477,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,648.81704
Policy Entropy: 1.70114
Value Function Loss: 0.07045

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.31921
Value Function Update Magnitude: 0.28759

Collected Steps per Second: 21,148.43665
Overall Steps per Second: 10,284.40292

Timestep Collection Time: 2.36471
Timestep Consumption Time: 2.49799
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.86270

Cumulative Model Updates: 123,826
Cumulative Timesteps: 1,033,527,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1033527940...
Checkpoint 1033527940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,349.98364
Policy Entropy: 1.70731
Value Function Loss: 0.06530

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.31714
Value Function Update Magnitude: 0.32121

Collected Steps per Second: 21,300.41168
Overall Steps per Second: 10,269.86541

Timestep Collection Time: 2.34869
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.87134

Cumulative Model Updates: 123,832
Cumulative Timesteps: 1,033,577,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,391.78301
Policy Entropy: 1.70062
Value Function Loss: 0.07134

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.31872
Value Function Update Magnitude: 0.37136

Collected Steps per Second: 21,807.97184
Overall Steps per Second: 10,427.56955

Timestep Collection Time: 2.29301
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.79556

Cumulative Model Updates: 123,838
Cumulative Timesteps: 1,033,627,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1033627974...
Checkpoint 1033627974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,258.69350
Policy Entropy: 1.68988
Value Function Loss: 0.06846

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.32529
Value Function Update Magnitude: 0.38026

Collected Steps per Second: 21,707.24283
Overall Steps per Second: 10,384.96113

Timestep Collection Time: 2.30347
Timestep Consumption Time: 2.51138
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.81485

Cumulative Model Updates: 123,844
Cumulative Timesteps: 1,033,677,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,283.41283
Policy Entropy: 1.68879
Value Function Loss: 0.07071

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.32962
Value Function Update Magnitude: 0.37685

Collected Steps per Second: 22,083.70603
Overall Steps per Second: 10,515.73180

Timestep Collection Time: 2.26547
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.75763

Cumulative Model Updates: 123,850
Cumulative Timesteps: 1,033,728,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1033728006...
Checkpoint 1033728006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,561.24633
Policy Entropy: 1.67429
Value Function Loss: 0.06913

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.32924
Value Function Update Magnitude: 0.34937

Collected Steps per Second: 21,652.52148
Overall Steps per Second: 10,410.67978

Timestep Collection Time: 2.31059
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.80564

Cumulative Model Updates: 123,856
Cumulative Timesteps: 1,033,778,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,810.07667
Policy Entropy: 1.68726
Value Function Loss: 0.07099

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.32912
Value Function Update Magnitude: 0.29731

Collected Steps per Second: 21,735.12208
Overall Steps per Second: 10,442.36006

Timestep Collection Time: 2.30171
Timestep Consumption Time: 2.48916
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.79087

Cumulative Model Updates: 123,862
Cumulative Timesteps: 1,033,828,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1033828064...
Checkpoint 1033828064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,908.98225
Policy Entropy: 1.68535
Value Function Loss: 0.07518

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.33195
Value Function Update Magnitude: 0.31637

Collected Steps per Second: 21,665.67212
Overall Steps per Second: 10,384.81782

Timestep Collection Time: 2.30826
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.81568

Cumulative Model Updates: 123,868
Cumulative Timesteps: 1,033,878,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,445.51653
Policy Entropy: 1.69619
Value Function Loss: 0.07233

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.32806
Value Function Update Magnitude: 0.33694

Collected Steps per Second: 21,740.74503
Overall Steps per Second: 10,365.42463

Timestep Collection Time: 2.30103
Timestep Consumption Time: 2.52521
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.82624

Cumulative Model Updates: 123,874
Cumulative Timesteps: 1,033,928,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1033928100...
Checkpoint 1033928100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,784.36016
Policy Entropy: 1.69413
Value Function Loss: 0.07337

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.33022
Value Function Update Magnitude: 0.36536

Collected Steps per Second: 21,250.42013
Overall Steps per Second: 10,500.54435

Timestep Collection Time: 2.35374
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.76337

Cumulative Model Updates: 123,880
Cumulative Timesteps: 1,033,978,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,310.69951
Policy Entropy: 1.67834
Value Function Loss: 0.06954

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.33208
Value Function Update Magnitude: 0.36078

Collected Steps per Second: 21,351.74416
Overall Steps per Second: 10,453.57249

Timestep Collection Time: 2.34285
Timestep Consumption Time: 2.44250
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.78535

Cumulative Model Updates: 123,886
Cumulative Timesteps: 1,034,028,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1034028142...
Checkpoint 1034028142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,471.42631
Policy Entropy: 1.68194
Value Function Loss: 0.07080

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.32966
Value Function Update Magnitude: 0.33585

Collected Steps per Second: 21,082.28407
Overall Steps per Second: 10,245.07619

Timestep Collection Time: 2.37175
Timestep Consumption Time: 2.50883
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.88059

Cumulative Model Updates: 123,892
Cumulative Timesteps: 1,034,078,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,177.26523
Policy Entropy: 1.68125
Value Function Loss: 0.06997

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.33009
Value Function Update Magnitude: 0.34636

Collected Steps per Second: 21,467.60327
Overall Steps per Second: 10,446.92967

Timestep Collection Time: 2.32993
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.78782

Cumulative Model Updates: 123,898
Cumulative Timesteps: 1,034,128,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1034128162...
Checkpoint 1034128162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,628.35823
Policy Entropy: 1.69266
Value Function Loss: 0.06675

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.32161
Value Function Update Magnitude: 0.36347

Collected Steps per Second: 21,245.06745
Overall Steps per Second: 10,168.60987

Timestep Collection Time: 2.35499
Timestep Consumption Time: 2.56525
PPO Batch Consumption Time: 0.30301
Total Iteration Time: 4.92024

Cumulative Model Updates: 123,904
Cumulative Timesteps: 1,034,178,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,280.80609
Policy Entropy: 1.68028
Value Function Loss: 0.06533

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.31465
Value Function Update Magnitude: 0.36624

Collected Steps per Second: 21,773.01316
Overall Steps per Second: 10,481.74392

Timestep Collection Time: 2.29660
Timestep Consumption Time: 2.47398
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.77058

Cumulative Model Updates: 123,910
Cumulative Timesteps: 1,034,228,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1034228198...
Checkpoint 1034228198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,457.34465
Policy Entropy: 1.68307
Value Function Loss: 0.06233

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.31459
Value Function Update Magnitude: 0.35648

Collected Steps per Second: 21,485.06280
Overall Steps per Second: 10,260.78658

Timestep Collection Time: 2.32738
Timestep Consumption Time: 2.54593
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.87331

Cumulative Model Updates: 123,916
Cumulative Timesteps: 1,034,278,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,457.40277
Policy Entropy: 1.69544
Value Function Loss: 0.06886

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.30894
Value Function Update Magnitude: 0.34599

Collected Steps per Second: 21,528.76994
Overall Steps per Second: 10,462.77597

Timestep Collection Time: 2.32322
Timestep Consumption Time: 2.45716
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.78038

Cumulative Model Updates: 123,922
Cumulative Timesteps: 1,034,328,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1034328218...
Checkpoint 1034328218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,212.24782
Policy Entropy: 1.69719
Value Function Loss: 0.07175

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.31268
Value Function Update Magnitude: 0.34678

Collected Steps per Second: 21,712.87078
Overall Steps per Second: 10,611.88268

Timestep Collection Time: 2.30416
Timestep Consumption Time: 2.41036
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.71453

Cumulative Model Updates: 123,928
Cumulative Timesteps: 1,034,378,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,050.19006
Policy Entropy: 1.69158
Value Function Loss: 0.07372

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.32433
Value Function Update Magnitude: 0.33706

Collected Steps per Second: 22,005.31288
Overall Steps per Second: 10,456.11259

Timestep Collection Time: 2.27327
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.78419

Cumulative Model Updates: 123,934
Cumulative Timesteps: 1,034,428,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1034428272...
Checkpoint 1034428272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,362.93782
Policy Entropy: 1.67949
Value Function Loss: 0.07439

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.32940
Value Function Update Magnitude: 0.31781

Collected Steps per Second: 21,747.90670
Overall Steps per Second: 10,398.08144

Timestep Collection Time: 2.30018
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.81089

Cumulative Model Updates: 123,940
Cumulative Timesteps: 1,034,478,296

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,963.26420
Policy Entropy: 1.69494
Value Function Loss: 0.06835

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.32788
Value Function Update Magnitude: 0.31161

Collected Steps per Second: 22,055.84008
Overall Steps per Second: 10,643.40315

Timestep Collection Time: 2.26815
Timestep Consumption Time: 2.43204
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.70019

Cumulative Model Updates: 123,946
Cumulative Timesteps: 1,034,528,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1034528322...
Checkpoint 1034528322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,331.05905
Policy Entropy: 1.69349
Value Function Loss: 0.07075

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.32405
Value Function Update Magnitude: 0.31079

Collected Steps per Second: 21,431.77859
Overall Steps per Second: 10,289.08514

Timestep Collection Time: 2.33317
Timestep Consumption Time: 2.52674
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.85991

Cumulative Model Updates: 123,952
Cumulative Timesteps: 1,034,578,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,522.10993
Policy Entropy: 1.68278
Value Function Loss: 0.06566

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.32429
Value Function Update Magnitude: 0.32630

Collected Steps per Second: 21,461.13380
Overall Steps per Second: 10,453.49410

Timestep Collection Time: 2.33017
Timestep Consumption Time: 2.45369
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.78385

Cumulative Model Updates: 123,958
Cumulative Timesteps: 1,034,628,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1034628334...
Checkpoint 1034628334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,977.95949
Policy Entropy: 1.66404
Value Function Loss: 0.07021

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.32878
Value Function Update Magnitude: 0.34244

Collected Steps per Second: 21,339.87573
Overall Steps per Second: 10,290.91961

Timestep Collection Time: 2.34369
Timestep Consumption Time: 2.51633
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.86001

Cumulative Model Updates: 123,964
Cumulative Timesteps: 1,034,678,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,665.81264
Policy Entropy: 1.67101
Value Function Loss: 0.06728

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.32835
Value Function Update Magnitude: 0.34302

Collected Steps per Second: 21,513.96594
Overall Steps per Second: 10,385.48169

Timestep Collection Time: 2.32640
Timestep Consumption Time: 2.49283
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.81923

Cumulative Model Updates: 123,970
Cumulative Timesteps: 1,034,728,398

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1034728398...
Checkpoint 1034728398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,460.28434
Policy Entropy: 1.67337
Value Function Loss: 0.06414

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.31897
Value Function Update Magnitude: 0.34062

Collected Steps per Second: 21,395.51473
Overall Steps per Second: 10,290.04014

Timestep Collection Time: 2.33778
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.86082

Cumulative Model Updates: 123,976
Cumulative Timesteps: 1,034,778,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,062.10731
Policy Entropy: 1.68776
Value Function Loss: 0.06230

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.30676
Value Function Update Magnitude: 0.33899

Collected Steps per Second: 21,344.01311
Overall Steps per Second: 10,325.79794

Timestep Collection Time: 2.34342
Timestep Consumption Time: 2.50056
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.84398

Cumulative Model Updates: 123,982
Cumulative Timesteps: 1,034,828,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1034828434...
Checkpoint 1034828434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,128.70020
Policy Entropy: 1.67916
Value Function Loss: 0.06392

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.31453
Value Function Update Magnitude: 0.34929

Collected Steps per Second: 21,920.32262
Overall Steps per Second: 10,428.19341

Timestep Collection Time: 2.28208
Timestep Consumption Time: 2.51491
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.79700

Cumulative Model Updates: 123,988
Cumulative Timesteps: 1,034,878,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,767.29910
Policy Entropy: 1.69136
Value Function Loss: 0.06782

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.30399
Value Function Update Magnitude: 0.33730

Collected Steps per Second: 21,988.47770
Overall Steps per Second: 10,454.06667

Timestep Collection Time: 2.27437
Timestep Consumption Time: 2.50941
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.78378

Cumulative Model Updates: 123,994
Cumulative Timesteps: 1,034,928,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1034928468...
Checkpoint 1034928468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,740.75002
Policy Entropy: 1.69633
Value Function Loss: 0.06948

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.29734
Value Function Update Magnitude: 0.33788

Collected Steps per Second: 21,988.13151
Overall Steps per Second: 10,521.76335

Timestep Collection Time: 2.27486
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.75396

Cumulative Model Updates: 124,000
Cumulative Timesteps: 1,034,978,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,144.97300
Policy Entropy: 1.71144
Value Function Loss: 0.07008

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.30552
Value Function Update Magnitude: 0.35439

Collected Steps per Second: 22,182.32553
Overall Steps per Second: 10,460.02944

Timestep Collection Time: 2.25477
Timestep Consumption Time: 2.52686
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.78163

Cumulative Model Updates: 124,006
Cumulative Timesteps: 1,035,028,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1035028504...
Checkpoint 1035028504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,956.73885
Policy Entropy: 1.72117
Value Function Loss: 0.06817

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.36241

Collected Steps per Second: 21,906.31901
Overall Steps per Second: 10,572.49208

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.44896
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.73342

Cumulative Model Updates: 124,012
Cumulative Timesteps: 1,035,078,548

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,250.66200
Policy Entropy: 1.70888
Value Function Loss: 0.06519

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.31493
Value Function Update Magnitude: 0.36154

Collected Steps per Second: 22,149.32769
Overall Steps per Second: 10,464.75939

Timestep Collection Time: 2.25885
Timestep Consumption Time: 2.52215
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.78100

Cumulative Model Updates: 124,018
Cumulative Timesteps: 1,035,128,580

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1035128580...
Checkpoint 1035128580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,734.61489
Policy Entropy: 1.66981
Value Function Loss: 0.06512

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.32413
Value Function Update Magnitude: 0.35533

Collected Steps per Second: 21,885.99710
Overall Steps per Second: 10,593.98701

Timestep Collection Time: 2.28603
Timestep Consumption Time: 2.43665
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.72268

Cumulative Model Updates: 124,024
Cumulative Timesteps: 1,035,178,612

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,560.73828
Policy Entropy: 1.63797
Value Function Loss: 0.06546

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.32481
Value Function Update Magnitude: 0.35797

Collected Steps per Second: 21,590.30914
Overall Steps per Second: 10,478.86279

Timestep Collection Time: 2.31687
Timestep Consumption Time: 2.45674
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.77361

Cumulative Model Updates: 124,030
Cumulative Timesteps: 1,035,228,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1035228634...
Checkpoint 1035228634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,259.53990
Policy Entropy: 1.64889
Value Function Loss: 0.07057

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.33040
Value Function Update Magnitude: 0.36528

Collected Steps per Second: 21,247.36027
Overall Steps per Second: 10,275.21555

Timestep Collection Time: 2.35483
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.86939

Cumulative Model Updates: 124,036
Cumulative Timesteps: 1,035,278,668

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,488.45600
Policy Entropy: 1.66724
Value Function Loss: 0.06791

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.32484
Value Function Update Magnitude: 0.36847

Collected Steps per Second: 21,505.21452
Overall Steps per Second: 10,328.98352

Timestep Collection Time: 2.32567
Timestep Consumption Time: 2.51643
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.84210

Cumulative Model Updates: 124,042
Cumulative Timesteps: 1,035,328,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1035328682...
Checkpoint 1035328682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,619.98155
Policy Entropy: 1.69290
Value Function Loss: 0.06772

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.31038
Value Function Update Magnitude: 0.36391

Collected Steps per Second: 21,563.24936
Overall Steps per Second: 10,348.90521

Timestep Collection Time: 2.31969
Timestep Consumption Time: 2.51367
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.83336

Cumulative Model Updates: 124,048
Cumulative Timesteps: 1,035,378,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,659.52292
Policy Entropy: 1.68636
Value Function Loss: 0.06458

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.31806
Value Function Update Magnitude: 0.34833

Collected Steps per Second: 21,950.71656
Overall Steps per Second: 10,384.39622

Timestep Collection Time: 2.27874
Timestep Consumption Time: 2.53810
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.81684

Cumulative Model Updates: 124,054
Cumulative Timesteps: 1,035,428,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1035428722...
Checkpoint 1035428722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,141.18171
Policy Entropy: 1.69578
Value Function Loss: 0.06547

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.32101
Value Function Update Magnitude: 0.33285

Collected Steps per Second: 21,777.75016
Overall Steps per Second: 10,499.32993

Timestep Collection Time: 2.29647
Timestep Consumption Time: 2.46688
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.76335

Cumulative Model Updates: 124,060
Cumulative Timesteps: 1,035,478,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,784.91156
Policy Entropy: 1.69319
Value Function Loss: 0.06276

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.32046
Value Function Update Magnitude: 0.32442

Collected Steps per Second: 21,943.05137
Overall Steps per Second: 10,623.15978

Timestep Collection Time: 2.28072
Timestep Consumption Time: 2.43031
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.71103

Cumulative Model Updates: 124,066
Cumulative Timesteps: 1,035,528,780

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1035528780...
Checkpoint 1035528780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,494.36296
Policy Entropy: 1.70517
Value Function Loss: 0.07110

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.32460
Value Function Update Magnitude: 0.32210

Collected Steps per Second: 20,854.76336
Overall Steps per Second: 10,130.25432

Timestep Collection Time: 2.39773
Timestep Consumption Time: 2.53838
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.93611

Cumulative Model Updates: 124,072
Cumulative Timesteps: 1,035,578,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,965.14796
Policy Entropy: 1.71508
Value Function Loss: 0.07320

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.33180
Value Function Update Magnitude: 0.33604

Collected Steps per Second: 21,304.40970
Overall Steps per Second: 10,443.21895

Timestep Collection Time: 2.34759
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.78914

Cumulative Model Updates: 124,078
Cumulative Timesteps: 1,035,628,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1035628798...
Checkpoint 1035628798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,988.47902
Policy Entropy: 1.71772
Value Function Loss: 0.07650

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.33002
Value Function Update Magnitude: 0.34818

Collected Steps per Second: 21,156.71935
Overall Steps per Second: 10,591.79112

Timestep Collection Time: 2.36369
Timestep Consumption Time: 2.35770
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.72139

Cumulative Model Updates: 124,084
Cumulative Timesteps: 1,035,678,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,245.42156
Policy Entropy: 1.70362
Value Function Loss: 0.07367

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.33252
Value Function Update Magnitude: 0.35634

Collected Steps per Second: 21,306.82454
Overall Steps per Second: 10,491.56476

Timestep Collection Time: 2.34685
Timestep Consumption Time: 2.41926
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.76611

Cumulative Model Updates: 124,090
Cumulative Timesteps: 1,035,728,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1035728810...
Checkpoint 1035728810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,951.16122
Policy Entropy: 1.68311
Value Function Loss: 0.07212

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.33273
Value Function Update Magnitude: 0.36440

Collected Steps per Second: 21,245.40232
Overall Steps per Second: 10,609.71516

Timestep Collection Time: 2.35402
Timestep Consumption Time: 2.35978
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.71379

Cumulative Model Updates: 124,096
Cumulative Timesteps: 1,035,778,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,264.60669
Policy Entropy: 1.68496
Value Function Loss: 0.07945

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.33377
Value Function Update Magnitude: 0.38077

Collected Steps per Second: 21,468.49982
Overall Steps per Second: 10,480.20431

Timestep Collection Time: 2.32937
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.77166

Cumulative Model Updates: 124,102
Cumulative Timesteps: 1,035,828,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1035828830...
Checkpoint 1035828830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,074.73538
Policy Entropy: 1.69335
Value Function Loss: 0.07993

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.34117
Value Function Update Magnitude: 0.39660

Collected Steps per Second: 20,532.58239
Overall Steps per Second: 10,256.40521

Timestep Collection Time: 2.43525
Timestep Consumption Time: 2.43995
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.87520

Cumulative Model Updates: 124,108
Cumulative Timesteps: 1,035,878,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,405.68100
Policy Entropy: 1.69580
Value Function Loss: 0.08277

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.32284
Value Function Update Magnitude: 0.38493

Collected Steps per Second: 21,142.58288
Overall Steps per Second: 10,415.41602

Timestep Collection Time: 2.36584
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.80250

Cumulative Model Updates: 124,114
Cumulative Timesteps: 1,035,928,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1035928852...
Checkpoint 1035928852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,499.81458
Policy Entropy: 1.68566
Value Function Loss: 0.08361

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.30938
Value Function Update Magnitude: 0.40343

Collected Steps per Second: 21,467.33634
Overall Steps per Second: 10,552.97220

Timestep Collection Time: 2.33014
Timestep Consumption Time: 2.40994
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.74009

Cumulative Model Updates: 124,120
Cumulative Timesteps: 1,035,978,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,573.04196
Policy Entropy: 1.67027
Value Function Loss: 0.07955

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.31937
Value Function Update Magnitude: 0.41516

Collected Steps per Second: 21,683.24960
Overall Steps per Second: 10,567.72381

Timestep Collection Time: 2.30685
Timestep Consumption Time: 2.42643
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73328

Cumulative Model Updates: 124,126
Cumulative Timesteps: 1,036,028,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1036028894...
Checkpoint 1036028894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,854.51793
Policy Entropy: 1.66176
Value Function Loss: 0.07277

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.33198
Value Function Update Magnitude: 0.40348

Collected Steps per Second: 21,640.75048
Overall Steps per Second: 10,509.29996

Timestep Collection Time: 2.31138
Timestep Consumption Time: 2.44821
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.75959

Cumulative Model Updates: 124,132
Cumulative Timesteps: 1,036,078,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,013.18032
Policy Entropy: 1.65610
Value Function Loss: 0.06816

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.33375
Value Function Update Magnitude: 0.37435

Collected Steps per Second: 22,192.52944
Overall Steps per Second: 10,467.61646

Timestep Collection Time: 2.25382
Timestep Consumption Time: 2.52453
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.77836

Cumulative Model Updates: 124,138
Cumulative Timesteps: 1,036,128,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1036128932...
Checkpoint 1036128932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,510.52228
Policy Entropy: 1.64697
Value Function Loss: 0.06835

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.33483
Value Function Update Magnitude: 0.37526

Collected Steps per Second: 21,495.80731
Overall Steps per Second: 10,290.58124

Timestep Collection Time: 2.32650
Timestep Consumption Time: 2.53328
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.85978

Cumulative Model Updates: 124,144
Cumulative Timesteps: 1,036,178,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,814.20161
Policy Entropy: 1.64658
Value Function Loss: 0.06514

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.32551
Value Function Update Magnitude: 0.36949

Collected Steps per Second: 22,082.13097
Overall Steps per Second: 10,423.89254

Timestep Collection Time: 2.26654
Timestep Consumption Time: 2.53493
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.80147

Cumulative Model Updates: 124,150
Cumulative Timesteps: 1,036,228,992

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1036228992...
Checkpoint 1036228992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,904.33103
Policy Entropy: 1.65329
Value Function Loss: 0.06442

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.31770
Value Function Update Magnitude: 0.35442

Collected Steps per Second: 21,737.06649
Overall Steps per Second: 10,610.15316

Timestep Collection Time: 2.30141
Timestep Consumption Time: 2.41350
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.71492

Cumulative Model Updates: 124,156
Cumulative Timesteps: 1,036,279,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,347.19802
Policy Entropy: 1.66788
Value Function Loss: 0.06895

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.32400
Value Function Update Magnitude: 0.35902

Collected Steps per Second: 22,097.24094
Overall Steps per Second: 10,463.07058

Timestep Collection Time: 2.26345
Timestep Consumption Time: 2.51679
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.78024

Cumulative Model Updates: 124,162
Cumulative Timesteps: 1,036,329,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1036329034...
Checkpoint 1036329034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,769.56130
Policy Entropy: 1.67459
Value Function Loss: 0.06923

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.32726
Value Function Update Magnitude: 0.36820

Collected Steps per Second: 21,629.45122
Overall Steps per Second: 10,386.73784

Timestep Collection Time: 2.31333
Timestep Consumption Time: 2.50397
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.81730

Cumulative Model Updates: 124,168
Cumulative Timesteps: 1,036,379,070

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,026.60065
Policy Entropy: 1.66279
Value Function Loss: 0.06923

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.32420
Value Function Update Magnitude: 0.37207

Collected Steps per Second: 21,581.92190
Overall Steps per Second: 10,315.38387

Timestep Collection Time: 2.31712
Timestep Consumption Time: 2.53078
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.84790

Cumulative Model Updates: 124,174
Cumulative Timesteps: 1,036,429,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1036429078...
Checkpoint 1036429078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,874.14008
Policy Entropy: 1.66998
Value Function Loss: 0.06873

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.32363
Value Function Update Magnitude: 0.36558

Collected Steps per Second: 21,251.72056
Overall Steps per Second: 10,359.42508

Timestep Collection Time: 2.35388
Timestep Consumption Time: 2.47496
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.82884

Cumulative Model Updates: 124,180
Cumulative Timesteps: 1,036,479,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,942.01965
Policy Entropy: 1.66712
Value Function Loss: 0.06718

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.32378
Value Function Update Magnitude: 0.35206

Collected Steps per Second: 21,583.31264
Overall Steps per Second: 10,336.75828

Timestep Collection Time: 2.31799
Timestep Consumption Time: 2.52201
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.84001

Cumulative Model Updates: 124,186
Cumulative Timesteps: 1,036,529,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1036529132...
Checkpoint 1036529132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,307.43262
Policy Entropy: 1.68325
Value Function Loss: 0.06391

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.31703
Value Function Update Magnitude: 0.34546

Collected Steps per Second: 21,580.20927
Overall Steps per Second: 10,371.01639

Timestep Collection Time: 2.31768
Timestep Consumption Time: 2.50499
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.82267

Cumulative Model Updates: 124,192
Cumulative Timesteps: 1,036,579,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,315.04191
Policy Entropy: 1.68482
Value Function Loss: 0.06417

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.30715
Value Function Update Magnitude: 0.33476

Collected Steps per Second: 22,144.47958
Overall Steps per Second: 10,410.83834

Timestep Collection Time: 2.25916
Timestep Consumption Time: 2.54621
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.80538

Cumulative Model Updates: 124,198
Cumulative Timesteps: 1,036,629,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1036629176...
Checkpoint 1036629176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,357.23138
Policy Entropy: 1.69527
Value Function Loss: 0.06832

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.32050
Value Function Update Magnitude: 0.33350

Collected Steps per Second: 21,801.88120
Overall Steps per Second: 10,394.75292

Timestep Collection Time: 2.29448
Timestep Consumption Time: 2.51795
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.81243

Cumulative Model Updates: 124,204
Cumulative Timesteps: 1,036,679,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,940.99037
Policy Entropy: 1.70767
Value Function Loss: 0.07375

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.32844
Value Function Update Magnitude: 0.33980

Collected Steps per Second: 22,181.33653
Overall Steps per Second: 10,556.61905

Timestep Collection Time: 2.25496
Timestep Consumption Time: 2.48311
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.73807

Cumulative Model Updates: 124,210
Cumulative Timesteps: 1,036,729,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1036729218...
Checkpoint 1036729218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,694.38955
Policy Entropy: 1.70652
Value Function Loss: 0.07314

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.32603
Value Function Update Magnitude: 0.35306

Collected Steps per Second: 21,632.69431
Overall Steps per Second: 10,549.20087

Timestep Collection Time: 2.31141
Timestep Consumption Time: 2.42848
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.73989

Cumulative Model Updates: 124,216
Cumulative Timesteps: 1,036,779,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,406.07420
Policy Entropy: 1.69545
Value Function Loss: 0.07241

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.32507
Value Function Update Magnitude: 0.36179

Collected Steps per Second: 22,254.64626
Overall Steps per Second: 10,520.66457

Timestep Collection Time: 2.24744
Timestep Consumption Time: 2.50663
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.75407

Cumulative Model Updates: 124,222
Cumulative Timesteps: 1,036,829,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1036829236...
Checkpoint 1036829236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,348.89297
Policy Entropy: 1.66628
Value Function Loss: 0.06355

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.31635
Value Function Update Magnitude: 0.35392

Collected Steps per Second: 21,668.28652
Overall Steps per Second: 10,366.05693

Timestep Collection Time: 2.30844
Timestep Consumption Time: 2.51692
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.82536

Cumulative Model Updates: 124,228
Cumulative Timesteps: 1,036,879,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,485.15105
Policy Entropy: 1.66344
Value Function Loss: 0.06531

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.31304
Value Function Update Magnitude: 0.34015

Collected Steps per Second: 22,208.35964
Overall Steps per Second: 10,683.90379

Timestep Collection Time: 2.25194
Timestep Consumption Time: 2.42912
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.68106

Cumulative Model Updates: 124,234
Cumulative Timesteps: 1,036,929,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1036929268...
Checkpoint 1036929268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,055.20103
Policy Entropy: 1.67399
Value Function Loss: 0.06344

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.31552
Value Function Update Magnitude: 0.33585

Collected Steps per Second: 20,906.40633
Overall Steps per Second: 10,254.02706

Timestep Collection Time: 2.39219
Timestep Consumption Time: 2.48512
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.87730

Cumulative Model Updates: 124,240
Cumulative Timesteps: 1,036,979,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,063.65833
Policy Entropy: 1.68242
Value Function Loss: 0.06779

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07649
Policy Update Magnitude: 0.32139
Value Function Update Magnitude: 0.34426

Collected Steps per Second: 21,761.88419
Overall Steps per Second: 10,393.52034

Timestep Collection Time: 2.29833
Timestep Consumption Time: 2.51390
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.81223

Cumulative Model Updates: 124,246
Cumulative Timesteps: 1,037,029,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1037029296...
Checkpoint 1037029296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,114.67233
Policy Entropy: 1.68851
Value Function Loss: 0.06660

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.31973
Value Function Update Magnitude: 0.33342

Collected Steps per Second: 21,486.32927
Overall Steps per Second: 10,301.06015

Timestep Collection Time: 2.32734
Timestep Consumption Time: 2.52711
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.85445

Cumulative Model Updates: 124,252
Cumulative Timesteps: 1,037,079,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,553.62866
Policy Entropy: 1.68939
Value Function Loss: 0.06545

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.31852
Value Function Update Magnitude: 0.34363

Collected Steps per Second: 21,610.94051
Overall Steps per Second: 10,413.43914

Timestep Collection Time: 2.31457
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.80341

Cumulative Model Updates: 124,258
Cumulative Timesteps: 1,037,129,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1037129322...
Checkpoint 1037129322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,173.94446
Policy Entropy: 1.69604
Value Function Loss: 0.06453

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07874
Policy Update Magnitude: 0.32179
Value Function Update Magnitude: 0.33205

Collected Steps per Second: 21,684.79144
Overall Steps per Second: 10,563.95711

Timestep Collection Time: 2.30705
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.73573

Cumulative Model Updates: 124,264
Cumulative Timesteps: 1,037,179,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,987.65116
Policy Entropy: 1.68931
Value Function Loss: 0.06553

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.32099
Value Function Update Magnitude: 0.33092

Collected Steps per Second: 21,999.86943
Overall Steps per Second: 10,505.61508

Timestep Collection Time: 2.27310
Timestep Consumption Time: 2.48702
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.76012

Cumulative Model Updates: 124,270
Cumulative Timesteps: 1,037,229,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1037229358...
Checkpoint 1037229358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,822.91728
Policy Entropy: 1.68263
Value Function Loss: 0.06578

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.31456
Value Function Update Magnitude: 0.31916

Collected Steps per Second: 20,556.57978
Overall Steps per Second: 10,225.44917

Timestep Collection Time: 2.43280
Timestep Consumption Time: 2.45794
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.89074

Cumulative Model Updates: 124,276
Cumulative Timesteps: 1,037,279,368

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,852.57612
Policy Entropy: 1.69139
Value Function Loss: 0.06597

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.32102
Value Function Update Magnitude: 0.33836

Collected Steps per Second: 21,817.97277
Overall Steps per Second: 10,450.82262

Timestep Collection Time: 2.29261
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.78623

Cumulative Model Updates: 124,282
Cumulative Timesteps: 1,037,329,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1037329388...
Checkpoint 1037329388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,807.02858
Policy Entropy: 1.70179
Value Function Loss: 0.07097

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.32818
Value Function Update Magnitude: 0.35953

Collected Steps per Second: 21,512.32700
Overall Steps per Second: 10,368.54834

Timestep Collection Time: 2.32453
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.82285

Cumulative Model Updates: 124,288
Cumulative Timesteps: 1,037,379,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,718.64150
Policy Entropy: 1.70332
Value Function Loss: 0.07279

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.33005
Value Function Update Magnitude: 0.31152

Collected Steps per Second: 21,895.98118
Overall Steps per Second: 10,473.99419

Timestep Collection Time: 2.28471
Timestep Consumption Time: 2.49150
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.77621

Cumulative Model Updates: 124,294
Cumulative Timesteps: 1,037,429,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1037429420...
Checkpoint 1037429420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,251.23762
Policy Entropy: 1.70226
Value Function Loss: 0.07561

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.32473
Value Function Update Magnitude: 0.27564

Collected Steps per Second: 22,054.50005
Overall Steps per Second: 10,416.39325

Timestep Collection Time: 2.26720
Timestep Consumption Time: 2.53312
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.80032

Cumulative Model Updates: 124,300
Cumulative Timesteps: 1,037,479,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,640.61525
Policy Entropy: 1.70138
Value Function Loss: 0.07312

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.32407
Value Function Update Magnitude: 0.31797

Collected Steps per Second: 22,095.52647
Overall Steps per Second: 10,515.65823

Timestep Collection Time: 2.26290
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.75481

Cumulative Model Updates: 124,306
Cumulative Timesteps: 1,037,529,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1037529422...
Checkpoint 1037529422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,472.15678
Policy Entropy: 1.69538
Value Function Loss: 0.07879

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.32669
Value Function Update Magnitude: 0.33240

Collected Steps per Second: 21,937.87195
Overall Steps per Second: 10,586.90023

Timestep Collection Time: 2.28117
Timestep Consumption Time: 2.44580
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.72697

Cumulative Model Updates: 124,312
Cumulative Timesteps: 1,037,579,466

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,978.12333
Policy Entropy: 1.68943
Value Function Loss: 0.07876

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.32406
Value Function Update Magnitude: 0.34849

Collected Steps per Second: 21,990.61604
Overall Steps per Second: 10,473.02339

Timestep Collection Time: 2.27388
Timestep Consumption Time: 2.50067
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.77455

Cumulative Model Updates: 124,318
Cumulative Timesteps: 1,037,629,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1037629470...
Checkpoint 1037629470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,825.70407
Policy Entropy: 1.67936
Value Function Loss: 0.07490

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.32415
Value Function Update Magnitude: 0.37096

Collected Steps per Second: 22,158.43868
Overall Steps per Second: 10,636.86044

Timestep Collection Time: 2.25774
Timestep Consumption Time: 2.44553
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.70327

Cumulative Model Updates: 124,324
Cumulative Timesteps: 1,037,679,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,332.31761
Policy Entropy: 1.69466
Value Function Loss: 0.06808

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.31855
Value Function Update Magnitude: 0.36886

Collected Steps per Second: 22,184.49889
Overall Steps per Second: 10,488.26599

Timestep Collection Time: 2.25437
Timestep Consumption Time: 2.51401
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.76838

Cumulative Model Updates: 124,330
Cumulative Timesteps: 1,037,729,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1037729510...
Checkpoint 1037729510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,782.11680
Policy Entropy: 1.69693
Value Function Loss: 0.06942

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.31754
Value Function Update Magnitude: 0.35227

Collected Steps per Second: 21,624.47187
Overall Steps per Second: 10,583.28734

Timestep Collection Time: 2.31294
Timestep Consumption Time: 2.41301
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.72594

Cumulative Model Updates: 124,336
Cumulative Timesteps: 1,037,779,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,958.05834
Policy Entropy: 1.67216
Value Function Loss: 0.06778

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08163
Policy Update Magnitude: 0.32377
Value Function Update Magnitude: 0.36356

Collected Steps per Second: 21,463.73249
Overall Steps per Second: 10,455.78514

Timestep Collection Time: 2.33026
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.78357

Cumulative Model Updates: 124,342
Cumulative Timesteps: 1,037,829,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1037829542...
Checkpoint 1037829542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,444.19031
Policy Entropy: 1.66735
Value Function Loss: 0.06875

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.32355
Value Function Update Magnitude: 0.37178

Collected Steps per Second: 21,495.27454
Overall Steps per Second: 10,345.01311

Timestep Collection Time: 2.32749
Timestep Consumption Time: 2.50866
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.83615

Cumulative Model Updates: 124,348
Cumulative Timesteps: 1,037,879,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,336.27158
Policy Entropy: 1.68292
Value Function Loss: 0.07180

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.32419
Value Function Update Magnitude: 0.39559

Collected Steps per Second: 21,708.28803
Overall Steps per Second: 10,388.24207

Timestep Collection Time: 2.30548
Timestep Consumption Time: 2.51228
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.81775

Cumulative Model Updates: 124,354
Cumulative Timesteps: 1,037,929,620

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1037929620...
Checkpoint 1037929620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,886.08835
Policy Entropy: 1.71818
Value Function Loss: 0.07494

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.33158
Value Function Update Magnitude: 0.38029

Collected Steps per Second: 21,600.19198
Overall Steps per Second: 10,529.76066

Timestep Collection Time: 2.31526
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.74940

Cumulative Model Updates: 124,360
Cumulative Timesteps: 1,037,979,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,770.90562
Policy Entropy: 1.70529
Value Function Loss: 0.07246

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.32829
Value Function Update Magnitude: 0.36714

Collected Steps per Second: 21,629.01061
Overall Steps per Second: 10,499.33573

Timestep Collection Time: 2.31199
Timestep Consumption Time: 2.45079
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.76278

Cumulative Model Updates: 124,366
Cumulative Timesteps: 1,038,029,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1038029636...
Checkpoint 1038029636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,731.88312
Policy Entropy: 1.69058
Value Function Loss: 0.07152

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.32771
Value Function Update Magnitude: 0.38050

Collected Steps per Second: 21,605.69448
Overall Steps per Second: 10,339.98985

Timestep Collection Time: 2.31541
Timestep Consumption Time: 2.52270
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.83811

Cumulative Model Updates: 124,372
Cumulative Timesteps: 1,038,079,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,373.91232
Policy Entropy: 1.69813
Value Function Loss: 0.07439

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.33160
Value Function Update Magnitude: 0.40282

Collected Steps per Second: 20,552.03577
Overall Steps per Second: 9,640.30829

Timestep Collection Time: 2.43343
Timestep Consumption Time: 2.75437
PPO Batch Consumption Time: 0.31746
Total Iteration Time: 5.18780

Cumulative Model Updates: 124,378
Cumulative Timesteps: 1,038,129,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1038129674...
Checkpoint 1038129674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,795.07668
Policy Entropy: 1.69112
Value Function Loss: 0.06967

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.33320
Value Function Update Magnitude: 0.39113

Collected Steps per Second: 20,830.95164
Overall Steps per Second: 10,113.81457

Timestep Collection Time: 2.40200
Timestep Consumption Time: 2.54529
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.94729

Cumulative Model Updates: 124,384
Cumulative Timesteps: 1,038,179,710

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,530.50036
Policy Entropy: 1.68943
Value Function Loss: 0.06632

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.31824
Value Function Update Magnitude: 0.37328

Collected Steps per Second: 21,237.47059
Overall Steps per Second: 10,042.47338

Timestep Collection Time: 2.35480
Timestep Consumption Time: 2.62505
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.97985

Cumulative Model Updates: 124,390
Cumulative Timesteps: 1,038,229,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1038229720...
Checkpoint 1038229720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,436.92357
Policy Entropy: 1.68854
Value Function Loss: 0.06470

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.30478
Value Function Update Magnitude: 0.35980

Collected Steps per Second: 21,548.53932
Overall Steps per Second: 10,028.70359

Timestep Collection Time: 2.32109
Timestep Consumption Time: 2.66620
PPO Batch Consumption Time: 0.31637
Total Iteration Time: 4.98728

Cumulative Model Updates: 124,396
Cumulative Timesteps: 1,038,279,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,632.47921
Policy Entropy: 1.71080
Value Function Loss: 0.07135

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.31627
Value Function Update Magnitude: 0.35676

Collected Steps per Second: 21,283.90341
Overall Steps per Second: 10,114.01163

Timestep Collection Time: 2.35107
Timestep Consumption Time: 2.59652
PPO Batch Consumption Time: 0.30564
Total Iteration Time: 4.94759

Cumulative Model Updates: 124,402
Cumulative Timesteps: 1,038,329,776

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1038329776...
Checkpoint 1038329776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,410.31836
Policy Entropy: 1.69122
Value Function Loss: 0.07058

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.30826
Value Function Update Magnitude: 0.35291

Collected Steps per Second: 20,483.14624
Overall Steps per Second: 10,199.63925

Timestep Collection Time: 2.44211
Timestep Consumption Time: 2.46219
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.90429

Cumulative Model Updates: 124,408
Cumulative Timesteps: 1,038,379,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,037.17095
Policy Entropy: 1.68946
Value Function Loss: 0.06998

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.30573
Value Function Update Magnitude: 0.34870

Collected Steps per Second: 19,675.00486
Overall Steps per Second: 10,058.57494

Timestep Collection Time: 2.54221
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.97267

Cumulative Model Updates: 124,414
Cumulative Timesteps: 1,038,429,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1038429816...
Checkpoint 1038429816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,645.53135
Policy Entropy: 1.66666
Value Function Loss: 0.06593

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.30454
Value Function Update Magnitude: 0.34964

Collected Steps per Second: 20,111.94321
Overall Steps per Second: 10,008.37113

Timestep Collection Time: 2.48658
Timestep Consumption Time: 2.51023
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.99682

Cumulative Model Updates: 124,420
Cumulative Timesteps: 1,038,479,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,486.85970
Policy Entropy: 1.67367
Value Function Loss: 0.07589

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.30673
Value Function Update Magnitude: 0.35286

Collected Steps per Second: 21,512.62083
Overall Steps per Second: 9,988.07389

Timestep Collection Time: 2.32524
Timestep Consumption Time: 2.68293
PPO Batch Consumption Time: 0.31065
Total Iteration Time: 5.00817

Cumulative Model Updates: 124,426
Cumulative Timesteps: 1,038,529,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1038529848...
Checkpoint 1038529848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,371.52631
Policy Entropy: 1.68549
Value Function Loss: 0.08353

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.31896
Value Function Update Magnitude: 0.33216

Collected Steps per Second: 20,885.25138
Overall Steps per Second: 9,364.46957

Timestep Collection Time: 2.39480
Timestep Consumption Time: 2.94624
PPO Batch Consumption Time: 0.36411
Total Iteration Time: 5.34104

Cumulative Model Updates: 124,432
Cumulative Timesteps: 1,038,579,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,566.22326
Policy Entropy: 1.66937
Value Function Loss: 0.08580

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.33173
Value Function Update Magnitude: 0.27753

Collected Steps per Second: 20,567.95068
Overall Steps per Second: 9,892.91133

Timestep Collection Time: 2.43136
Timestep Consumption Time: 2.62358
PPO Batch Consumption Time: 0.30442
Total Iteration Time: 5.05493

Cumulative Model Updates: 124,438
Cumulative Timesteps: 1,038,629,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1038629872...
Checkpoint 1038629872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,698.38346
Policy Entropy: 1.67588
Value Function Loss: 0.08045

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.33201
Value Function Update Magnitude: 0.23504

Collected Steps per Second: 20,253.14364
Overall Steps per Second: 10,059.35470

Timestep Collection Time: 2.46944
Timestep Consumption Time: 2.50245
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.97189

Cumulative Model Updates: 124,444
Cumulative Timesteps: 1,038,679,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,676.14103
Policy Entropy: 1.65993
Value Function Loss: 0.07317

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.31668
Value Function Update Magnitude: 0.23425

Collected Steps per Second: 21,408.52658
Overall Steps per Second: 10,278.78496

Timestep Collection Time: 2.33580
Timestep Consumption Time: 2.52917
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.86497

Cumulative Model Updates: 124,450
Cumulative Timesteps: 1,038,729,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1038729892...
Checkpoint 1038729892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,592.81281
Policy Entropy: 1.68020
Value Function Loss: 0.07397

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.29450
Value Function Update Magnitude: 0.29704

Collected Steps per Second: 20,756.60076
Overall Steps per Second: 10,017.83929

Timestep Collection Time: 2.40945
Timestep Consumption Time: 2.58284
PPO Batch Consumption Time: 0.30233
Total Iteration Time: 4.99229

Cumulative Model Updates: 124,456
Cumulative Timesteps: 1,038,779,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,549.59935
Policy Entropy: 1.68824
Value Function Loss: 0.07699

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.30582
Value Function Update Magnitude: 0.32345

Collected Steps per Second: 20,577.97450
Overall Steps per Second: 10,048.83832

Timestep Collection Time: 2.43075
Timestep Consumption Time: 2.54694
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.97769

Cumulative Model Updates: 124,462
Cumulative Timesteps: 1,038,829,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1038829924...
Checkpoint 1038829924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,027.93357
Policy Entropy: 1.71004
Value Function Loss: 0.08347

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.32895
Value Function Update Magnitude: 0.35938

Collected Steps per Second: 21,016.59358
Overall Steps per Second: 10,220.45323

Timestep Collection Time: 2.38012
Timestep Consumption Time: 2.51418
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.89430

Cumulative Model Updates: 124,468
Cumulative Timesteps: 1,038,879,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,493.44268
Policy Entropy: 1.69772
Value Function Loss: 0.08106

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.33177
Value Function Update Magnitude: 0.39433

Collected Steps per Second: 19,317.27347
Overall Steps per Second: 9,699.67140

Timestep Collection Time: 2.58836
Timestep Consumption Time: 2.56646
PPO Batch Consumption Time: 0.30762
Total Iteration Time: 5.15481

Cumulative Model Updates: 124,474
Cumulative Timesteps: 1,038,929,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1038929946...
Checkpoint 1038929946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,839.66528
Policy Entropy: 1.69066
Value Function Loss: 0.07576

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.33380
Value Function Update Magnitude: 0.38918

Collected Steps per Second: 20,676.42657
Overall Steps per Second: 10,380.08809

Timestep Collection Time: 2.41947
Timestep Consumption Time: 2.39995
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.81942

Cumulative Model Updates: 124,480
Cumulative Timesteps: 1,038,979,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,988.66436
Policy Entropy: 1.66192
Value Function Loss: 0.07783

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.33670
Value Function Update Magnitude: 0.38800

Collected Steps per Second: 21,161.87557
Overall Steps per Second: 10,426.32634

Timestep Collection Time: 2.36340
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.79690

Cumulative Model Updates: 124,486
Cumulative Timesteps: 1,039,029,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1039029986...
Checkpoint 1039029986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,292.28119
Policy Entropy: 1.66919
Value Function Loss: 0.07293

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.33707
Value Function Update Magnitude: 0.37989

Collected Steps per Second: 21,126.38341
Overall Steps per Second: 10,567.04112

Timestep Collection Time: 2.36766
Timestep Consumption Time: 2.36593
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.73359

Cumulative Model Updates: 124,492
Cumulative Timesteps: 1,039,080,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,128.27664
Policy Entropy: 1.67403
Value Function Loss: 0.07515

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.32392
Value Function Update Magnitude: 0.34979

Collected Steps per Second: 21,180.91318
Overall Steps per Second: 10,197.49768

Timestep Collection Time: 2.36184
Timestep Consumption Time: 2.54387
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 4.90571

Cumulative Model Updates: 124,498
Cumulative Timesteps: 1,039,130,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1039130032...
Checkpoint 1039130032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,990.64662
Policy Entropy: 1.67254
Value Function Loss: 0.06913

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.32227
Value Function Update Magnitude: 0.33410

Collected Steps per Second: 18,827.40022
Overall Steps per Second: 9,742.28101

Timestep Collection Time: 2.65687
Timestep Consumption Time: 2.47765
PPO Batch Consumption Time: 0.31050
Total Iteration Time: 5.13453

Cumulative Model Updates: 124,504
Cumulative Timesteps: 1,039,180,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,219.37466
Policy Entropy: 1.66950
Value Function Loss: 0.06868

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.30349
Value Function Update Magnitude: 0.32228

Collected Steps per Second: 19,530.90528
Overall Steps per Second: 9,902.90802

Timestep Collection Time: 2.56097
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 5.05084

Cumulative Model Updates: 124,510
Cumulative Timesteps: 1,039,230,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1039230072...
Checkpoint 1039230072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,487.45475
Policy Entropy: 1.66499
Value Function Loss: 0.06536

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.28701
Value Function Update Magnitude: 0.32430

Collected Steps per Second: 17,032.81418
Overall Steps per Second: 8,813.48719

Timestep Collection Time: 2.93715
Timestep Consumption Time: 2.73915
PPO Batch Consumption Time: 0.31025
Total Iteration Time: 5.67630

Cumulative Model Updates: 124,516
Cumulative Timesteps: 1,039,280,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,321.92814
Policy Entropy: 1.66986
Value Function Loss: 0.06364

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.28251
Value Function Update Magnitude: 0.31193

Collected Steps per Second: 20,435.89548
Overall Steps per Second: 9,915.01812

Timestep Collection Time: 2.44716
Timestep Consumption Time: 2.59670
PPO Batch Consumption Time: 0.30704
Total Iteration Time: 5.04386

Cumulative Model Updates: 124,522
Cumulative Timesteps: 1,039,330,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1039330110...
Checkpoint 1039330110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,307.12774
Policy Entropy: 1.67204
Value Function Loss: 0.06446

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.29980
Value Function Update Magnitude: 0.29814

Collected Steps per Second: 18,653.58479
Overall Steps per Second: 9,559.84035

Timestep Collection Time: 2.68088
Timestep Consumption Time: 2.55017
PPO Batch Consumption Time: 0.31242
Total Iteration Time: 5.23105

Cumulative Model Updates: 124,528
Cumulative Timesteps: 1,039,380,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,448.42424
Policy Entropy: 1.67592
Value Function Loss: 0.06540

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.31622
Value Function Update Magnitude: 0.29062

Collected Steps per Second: 20,911.66834
Overall Steps per Second: 9,938.09483

Timestep Collection Time: 2.39311
Timestep Consumption Time: 2.64246
PPO Batch Consumption Time: 0.30197
Total Iteration Time: 5.03557

Cumulative Model Updates: 124,534
Cumulative Timesteps: 1,039,430,162

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1039430162...
Checkpoint 1039430162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,937.91236
Policy Entropy: 1.67819
Value Function Loss: 0.06852

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.31624
Value Function Update Magnitude: 0.28272

Collected Steps per Second: 19,137.47314
Overall Steps per Second: 9,141.31222

Timestep Collection Time: 2.61382
Timestep Consumption Time: 2.85826
PPO Batch Consumption Time: 0.32747
Total Iteration Time: 5.47208

Cumulative Model Updates: 124,540
Cumulative Timesteps: 1,039,480,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,563.85091
Policy Entropy: 1.66797
Value Function Loss: 0.06533

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.31274
Value Function Update Magnitude: 0.29971

Collected Steps per Second: 21,328.52850
Overall Steps per Second: 10,220.09909

Timestep Collection Time: 2.34653
Timestep Consumption Time: 2.55049
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.89702

Cumulative Model Updates: 124,546
Cumulative Timesteps: 1,039,530,232

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1039530232...
Checkpoint 1039530232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,169.24002
Policy Entropy: 1.66559
Value Function Loss: 0.06780

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.31474
Value Function Update Magnitude: 0.32802

Collected Steps per Second: 20,850.01790
Overall Steps per Second: 10,161.25436

Timestep Collection Time: 2.39942
Timestep Consumption Time: 2.52399
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.92341

Cumulative Model Updates: 124,552
Cumulative Timesteps: 1,039,580,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,611.36167
Policy Entropy: 1.64926
Value Function Loss: 0.06009

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.31768
Value Function Update Magnitude: 0.33926

Collected Steps per Second: 20,415.12940
Overall Steps per Second: 10,035.76579

Timestep Collection Time: 2.44946
Timestep Consumption Time: 2.53332
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.98278

Cumulative Model Updates: 124,558
Cumulative Timesteps: 1,039,630,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1039630266...
Checkpoint 1039630266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,689.31659
Policy Entropy: 1.66869
Value Function Loss: 0.06666

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.31719
Value Function Update Magnitude: 0.30592

Collected Steps per Second: 20,878.70420
Overall Steps per Second: 10,262.07633

Timestep Collection Time: 2.39517
Timestep Consumption Time: 2.47792
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.87309

Cumulative Model Updates: 124,564
Cumulative Timesteps: 1,039,680,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,364.41256
Policy Entropy: 1.67539
Value Function Loss: 0.07294

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.31740
Value Function Update Magnitude: 0.27258

Collected Steps per Second: 21,365.71624
Overall Steps per Second: 10,364.61643

Timestep Collection Time: 2.34020
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.82411

Cumulative Model Updates: 124,570
Cumulative Timesteps: 1,039,730,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1039730274...
Checkpoint 1039730274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,720.64036
Policy Entropy: 1.67977
Value Function Loss: 0.07506

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.31231
Value Function Update Magnitude: 0.27755

Collected Steps per Second: 20,986.70308
Overall Steps per Second: 10,287.12279

Timestep Collection Time: 2.38389
Timestep Consumption Time: 2.47947
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.86336

Cumulative Model Updates: 124,576
Cumulative Timesteps: 1,039,780,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,553.63106
Policy Entropy: 1.67813
Value Function Loss: 0.07618

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.29572
Value Function Update Magnitude: 0.28386

Collected Steps per Second: 21,209.45182
Overall Steps per Second: 10,333.39366

Timestep Collection Time: 2.35838
Timestep Consumption Time: 2.48223
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.84062

Cumulative Model Updates: 124,582
Cumulative Timesteps: 1,039,830,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1039830324...
Checkpoint 1039830324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,250.80062
Policy Entropy: 1.66466
Value Function Loss: 0.07167

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.29565

Collected Steps per Second: 20,248.16836
Overall Steps per Second: 9,929.96505

Timestep Collection Time: 2.47074
Timestep Consumption Time: 2.56734
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 5.03808

Cumulative Model Updates: 124,588
Cumulative Timesteps: 1,039,880,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,737.07131
Policy Entropy: 1.67265
Value Function Loss: 0.06608

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.31161
Value Function Update Magnitude: 0.33919

Collected Steps per Second: 20,991.90134
Overall Steps per Second: 10,161.03365

Timestep Collection Time: 2.38244
Timestep Consumption Time: 2.53950
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.92194

Cumulative Model Updates: 124,594
Cumulative Timesteps: 1,039,930,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1039930364...
Checkpoint 1039930364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,317.12050
Policy Entropy: 1.65788
Value Function Loss: 0.06438

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31158
Value Function Update Magnitude: 0.34417

Collected Steps per Second: 21,177.19846
Overall Steps per Second: 10,240.37561

Timestep Collection Time: 2.36273
Timestep Consumption Time: 2.52342
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.88615

Cumulative Model Updates: 124,600
Cumulative Timesteps: 1,039,980,400

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,712.86727
Policy Entropy: 1.66706
Value Function Loss: 0.06693

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.32222
Value Function Update Magnitude: 0.34207

Collected Steps per Second: 21,214.70719
Overall Steps per Second: 10,272.71535

Timestep Collection Time: 2.35770
Timestep Consumption Time: 2.51131
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.86901

Cumulative Model Updates: 124,606
Cumulative Timesteps: 1,040,030,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1040030418...
Checkpoint 1040030418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,003.66237
Policy Entropy: 1.64985
Value Function Loss: 0.06314

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31834
Value Function Update Magnitude: 0.35363

Collected Steps per Second: 20,749.85696
Overall Steps per Second: 10,234.60098

Timestep Collection Time: 2.41081
Timestep Consumption Time: 2.47692
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.88773

Cumulative Model Updates: 124,612
Cumulative Timesteps: 1,040,080,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,786.16587
Policy Entropy: 1.62995
Value Function Loss: 0.06131

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07594
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.33674

Collected Steps per Second: 21,146.15562
Overall Steps per Second: 10,332.78303

Timestep Collection Time: 2.36582
Timestep Consumption Time: 2.47586
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.84168

Cumulative Model Updates: 124,618
Cumulative Timesteps: 1,040,130,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1040130470...
Checkpoint 1040130470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,126.57743
Policy Entropy: 1.62747
Value Function Loss: 0.06400

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.32010
Value Function Update Magnitude: 0.31701

Collected Steps per Second: 20,936.40541
Overall Steps per Second: 10,265.69321

Timestep Collection Time: 2.38904
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.87235

Cumulative Model Updates: 124,624
Cumulative Timesteps: 1,040,180,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,341.04032
Policy Entropy: 1.64327
Value Function Loss: 0.06405

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.31991
Value Function Update Magnitude: 0.31827

Collected Steps per Second: 20,896.23593
Overall Steps per Second: 10,103.72709

Timestep Collection Time: 2.39421
Timestep Consumption Time: 2.55743
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.95164

Cumulative Model Updates: 124,630
Cumulative Timesteps: 1,040,230,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1040230518...
Checkpoint 1040230518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,354.19757
Policy Entropy: 1.65584
Value Function Loss: 0.06793

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.31964
Value Function Update Magnitude: 0.32789

Collected Steps per Second: 21,001.97992
Overall Steps per Second: 10,151.98779

Timestep Collection Time: 2.38197
Timestep Consumption Time: 2.54574
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.92770

Cumulative Model Updates: 124,636
Cumulative Timesteps: 1,040,280,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,096.35813
Policy Entropy: 1.65153
Value Function Loss: 0.06499

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.32271
Value Function Update Magnitude: 0.33124

Collected Steps per Second: 20,867.20869
Overall Steps per Second: 10,105.32915

Timestep Collection Time: 2.39764
Timestep Consumption Time: 2.55341
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.95105

Cumulative Model Updates: 124,642
Cumulative Timesteps: 1,040,330,576

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1040330576...
Checkpoint 1040330576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,232.40794
Policy Entropy: 1.64748
Value Function Loss: 0.06807

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.31969
Value Function Update Magnitude: 0.34811

Collected Steps per Second: 21,157.78474
Overall Steps per Second: 10,163.53036

Timestep Collection Time: 2.36433
Timestep Consumption Time: 2.55758
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.92191

Cumulative Model Updates: 124,648
Cumulative Timesteps: 1,040,380,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,488.49481
Policy Entropy: 1.66589
Value Function Loss: 0.06836

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.31810
Value Function Update Magnitude: 0.34853

Collected Steps per Second: 20,909.00921
Overall Steps per Second: 10,140.85836

Timestep Collection Time: 2.39351
Timestep Consumption Time: 2.54157
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.93509

Cumulative Model Updates: 124,654
Cumulative Timesteps: 1,040,430,646

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1040430646...
Checkpoint 1040430646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,420.56535
Policy Entropy: 1.64128
Value Function Loss: 0.07264

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.32643
Value Function Update Magnitude: 0.34514

Collected Steps per Second: 20,707.67380
Overall Steps per Second: 10,078.64198

Timestep Collection Time: 2.41524
Timestep Consumption Time: 2.54713
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.96237

Cumulative Model Updates: 124,660
Cumulative Timesteps: 1,040,480,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,753.28800
Policy Entropy: 1.64039
Value Function Loss: 0.07449

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08036
Policy Update Magnitude: 0.33740
Value Function Update Magnitude: 0.34608

Collected Steps per Second: 20,999.97762
Overall Steps per Second: 10,145.68839

Timestep Collection Time: 2.38191
Timestep Consumption Time: 2.54827
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.93017

Cumulative Model Updates: 124,666
Cumulative Timesteps: 1,040,530,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1040530680...
Checkpoint 1040530680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,207.20157
Policy Entropy: 1.62684
Value Function Loss: 0.07577

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.32960
Value Function Update Magnitude: 0.33901

Collected Steps per Second: 20,875.16227
Overall Steps per Second: 10,130.27193

Timestep Collection Time: 2.39567
Timestep Consumption Time: 2.54102
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.93669

Cumulative Model Updates: 124,672
Cumulative Timesteps: 1,040,580,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,187.53527
Policy Entropy: 1.63476
Value Function Loss: 0.07480

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.32688
Value Function Update Magnitude: 0.32360

Collected Steps per Second: 21,054.98604
Overall Steps per Second: 10,203.19039

Timestep Collection Time: 2.37578
Timestep Consumption Time: 2.52680
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.90258

Cumulative Model Updates: 124,678
Cumulative Timesteps: 1,040,630,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1040630712...
Checkpoint 1040630712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,363.50215
Policy Entropy: 1.63145
Value Function Loss: 0.07115

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.33099
Value Function Update Magnitude: 0.34260

Collected Steps per Second: 21,244.96497
Overall Steps per Second: 10,372.31840

Timestep Collection Time: 2.35369
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.82091

Cumulative Model Updates: 124,684
Cumulative Timesteps: 1,040,680,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,117.57593
Policy Entropy: 1.64015
Value Function Loss: 0.06381

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.31906
Value Function Update Magnitude: 0.33737

Collected Steps per Second: 21,048.96447
Overall Steps per Second: 10,175.53531

Timestep Collection Time: 2.37617
Timestep Consumption Time: 2.53914
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.91532

Cumulative Model Updates: 124,690
Cumulative Timesteps: 1,040,730,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1040730732...
Checkpoint 1040730732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,822.98284
Policy Entropy: 1.65691
Value Function Loss: 0.06555

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.31646
Value Function Update Magnitude: 0.33172

Collected Steps per Second: 20,286.40620
Overall Steps per Second: 10,159.87279

Timestep Collection Time: 2.46608
Timestep Consumption Time: 2.45799
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.92408

Cumulative Model Updates: 124,696
Cumulative Timesteps: 1,040,780,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,860.51826
Policy Entropy: 1.64754
Value Function Loss: 0.06620

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.31462
Value Function Update Magnitude: 0.32585

Collected Steps per Second: 20,390.47092
Overall Steps per Second: 10,195.24751

Timestep Collection Time: 2.45350
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.90699

Cumulative Model Updates: 124,702
Cumulative Timesteps: 1,040,830,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1040830788...
Checkpoint 1040830788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,891.83843
Policy Entropy: 1.64669
Value Function Loss: 0.07066

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.32005
Value Function Update Magnitude: 0.34021

Collected Steps per Second: 20,849.25632
Overall Steps per Second: 10,450.76419

Timestep Collection Time: 2.39826
Timestep Consumption Time: 2.38627
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.78453

Cumulative Model Updates: 124,708
Cumulative Timesteps: 1,040,880,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,189.81164
Policy Entropy: 1.63926
Value Function Loss: 0.06823

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.32635
Value Function Update Magnitude: 0.35296

Collected Steps per Second: 20,680.31499
Overall Steps per Second: 10,403.33759

Timestep Collection Time: 2.41921
Timestep Consumption Time: 2.38982
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.80903

Cumulative Model Updates: 124,714
Cumulative Timesteps: 1,040,930,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1040930820...
Checkpoint 1040930820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,103.52425
Policy Entropy: 1.65258
Value Function Loss: 0.06447

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.32216
Value Function Update Magnitude: 0.37168

Collected Steps per Second: 20,518.47241
Overall Steps per Second: 10,281.74016

Timestep Collection Time: 2.43712
Timestep Consumption Time: 2.42645
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.86357

Cumulative Model Updates: 124,720
Cumulative Timesteps: 1,040,980,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,363.38543
Policy Entropy: 1.64290
Value Function Loss: 0.06161

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07862
Policy Update Magnitude: 0.31857
Value Function Update Magnitude: 0.36233

Collected Steps per Second: 20,630.72841
Overall Steps per Second: 10,026.71297

Timestep Collection Time: 2.42357
Timestep Consumption Time: 2.56311
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.98668

Cumulative Model Updates: 124,726
Cumulative Timesteps: 1,041,030,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1041030826...
Checkpoint 1041030826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,959.40743
Policy Entropy: 1.65091
Value Function Loss: 0.06200

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.31788
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 21,055.41598
Overall Steps per Second: 10,201.45135

Timestep Collection Time: 2.37716
Timestep Consumption Time: 2.52921
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.90636

Cumulative Model Updates: 124,732
Cumulative Timesteps: 1,041,080,878

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,539.56684
Policy Entropy: 1.64833
Value Function Loss: 0.06361

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.31696
Value Function Update Magnitude: 0.34644

Collected Steps per Second: 20,356.12020
Overall Steps per Second: 10,038.17722

Timestep Collection Time: 2.45754
Timestep Consumption Time: 2.52603
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.98357

Cumulative Model Updates: 124,738
Cumulative Timesteps: 1,041,130,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1041130904...
Checkpoint 1041130904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,167.07446
Policy Entropy: 1.64867
Value Function Loss: 0.06379

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.31362
Value Function Update Magnitude: 0.34106

Collected Steps per Second: 20,491.09637
Overall Steps per Second: 10,033.22234

Timestep Collection Time: 2.44077
Timestep Consumption Time: 2.54407
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.98484

Cumulative Model Updates: 124,744
Cumulative Timesteps: 1,041,180,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,761.21707
Policy Entropy: 1.64484
Value Function Loss: 0.06197

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.30039
Value Function Update Magnitude: 0.33006

Collected Steps per Second: 20,740.29012
Overall Steps per Second: 10,228.50491

Timestep Collection Time: 2.41183
Timestep Consumption Time: 2.47862
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.89045

Cumulative Model Updates: 124,750
Cumulative Timesteps: 1,041,230,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1041230940...
Checkpoint 1041230940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,941.52359
Policy Entropy: 1.64250
Value Function Loss: 0.06487

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.30737
Value Function Update Magnitude: 0.33617

Collected Steps per Second: 21,124.88626
Overall Steps per Second: 10,166.80749

Timestep Collection Time: 2.36858
Timestep Consumption Time: 2.55292
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.92151

Cumulative Model Updates: 124,756
Cumulative Timesteps: 1,041,280,976

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,142.81365
Policy Entropy: 1.65409
Value Function Loss: 0.06996

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.32314
Value Function Update Magnitude: 0.34946

Collected Steps per Second: 20,901.36685
Overall Steps per Second: 10,164.91522

Timestep Collection Time: 2.39257
Timestep Consumption Time: 2.52710
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.91967

Cumulative Model Updates: 124,762
Cumulative Timesteps: 1,041,330,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1041330984...
Checkpoint 1041330984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,454.50656
Policy Entropy: 1.65881
Value Function Loss: 0.07030

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.32738
Value Function Update Magnitude: 0.37148

Collected Steps per Second: 21,256.44404
Overall Steps per Second: 10,201.84755

Timestep Collection Time: 2.35279
Timestep Consumption Time: 2.54946
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.90225

Cumulative Model Updates: 124,768
Cumulative Timesteps: 1,041,380,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,613.50161
Policy Entropy: 1.65804
Value Function Loss: 0.07095

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08004
Policy Update Magnitude: 0.32982
Value Function Update Magnitude: 0.36093

Collected Steps per Second: 21,083.72808
Overall Steps per Second: 10,270.90498

Timestep Collection Time: 2.37150
Timestep Consumption Time: 2.49662
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.86812

Cumulative Model Updates: 124,774
Cumulative Timesteps: 1,041,430,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1041430996...
Checkpoint 1041430996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,869.26079
Policy Entropy: 1.64250
Value Function Loss: 0.06993

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.32922
Value Function Update Magnitude: 0.35638

Collected Steps per Second: 21,137.15136
Overall Steps per Second: 10,304.95357

Timestep Collection Time: 2.36626
Timestep Consumption Time: 2.48733
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.85359

Cumulative Model Updates: 124,780
Cumulative Timesteps: 1,041,481,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,398.49074
Policy Entropy: 1.64509
Value Function Loss: 0.07066

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.32833
Value Function Update Magnitude: 0.36007

Collected Steps per Second: 21,121.46795
Overall Steps per Second: 10,245.14576

Timestep Collection Time: 2.36830
Timestep Consumption Time: 2.51421
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.88251

Cumulative Model Updates: 124,786
Cumulative Timesteps: 1,041,531,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1041531034...
Checkpoint 1041531034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,971.20011
Policy Entropy: 1.63151
Value Function Loss: 0.07103

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.31991
Value Function Update Magnitude: 0.36238

Collected Steps per Second: 20,895.92708
Overall Steps per Second: 10,342.76909

Timestep Collection Time: 2.39281
Timestep Consumption Time: 2.44148
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.83430

Cumulative Model Updates: 124,792
Cumulative Timesteps: 1,041,581,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,007.01005
Policy Entropy: 1.62392
Value Function Loss: 0.06403

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.29022
Value Function Update Magnitude: 0.35546

Collected Steps per Second: 21,095.22349
Overall Steps per Second: 10,140.08516

Timestep Collection Time: 2.37134
Timestep Consumption Time: 2.56195
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.93329

Cumulative Model Updates: 124,798
Cumulative Timesteps: 1,041,631,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1041631058...
Checkpoint 1041631058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,457.24264
Policy Entropy: 1.60920
Value Function Loss: 0.06291

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.30637
Value Function Update Magnitude: 0.33843

Collected Steps per Second: 20,491.83014
Overall Steps per Second: 10,125.49853

Timestep Collection Time: 2.44107
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.94020

Cumulative Model Updates: 124,804
Cumulative Timesteps: 1,041,681,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,382.85848
Policy Entropy: 1.61271
Value Function Loss: 0.05763

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.30956
Value Function Update Magnitude: 0.31113

Collected Steps per Second: 21,189.78980
Overall Steps per Second: 10,165.42044

Timestep Collection Time: 2.36085
Timestep Consumption Time: 2.56034
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.92119

Cumulative Model Updates: 124,810
Cumulative Timesteps: 1,041,731,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1041731106...
Checkpoint 1041731106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,511.97204
Policy Entropy: 1.62833
Value Function Loss: 0.06085

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.31254
Value Function Update Magnitude: 0.29103

Collected Steps per Second: 21,489.00773
Overall Steps per Second: 10,315.48551

Timestep Collection Time: 2.32677
Timestep Consumption Time: 2.52031
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.84708

Cumulative Model Updates: 124,816
Cumulative Timesteps: 1,041,781,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,545.19976
Policy Entropy: 1.64063
Value Function Loss: 0.06232

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.31150
Value Function Update Magnitude: 0.30036

Collected Steps per Second: 21,245.77835
Overall Steps per Second: 10,255.67779

Timestep Collection Time: 2.35491
Timestep Consumption Time: 2.52355
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.87847

Cumulative Model Updates: 124,822
Cumulative Timesteps: 1,041,831,138

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1041831138...
Checkpoint 1041831138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,648.31420
Policy Entropy: 1.64079
Value Function Loss: 0.06118

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07480
Policy Update Magnitude: 0.30911
Value Function Update Magnitude: 0.31760

Collected Steps per Second: 21,067.80750
Overall Steps per Second: 10,228.92028

Timestep Collection Time: 2.37509
Timestep Consumption Time: 2.51672
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.89182

Cumulative Model Updates: 124,828
Cumulative Timesteps: 1,041,881,176

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,850.93458
Policy Entropy: 1.62889
Value Function Loss: 0.06075

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.31019
Value Function Update Magnitude: 0.32850

Collected Steps per Second: 20,845.08167
Overall Steps per Second: 10,102.86773

Timestep Collection Time: 2.39874
Timestep Consumption Time: 2.55054
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.94929

Cumulative Model Updates: 124,834
Cumulative Timesteps: 1,041,931,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1041931178...
Checkpoint 1041931178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,366.93800
Policy Entropy: 1.64028
Value Function Loss: 0.06131

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.31259
Value Function Update Magnitude: 0.32498

Collected Steps per Second: 21,056.24030
Overall Steps per Second: 10,096.56841

Timestep Collection Time: 2.37611
Timestep Consumption Time: 2.57923
PPO Batch Consumption Time: 0.30354
Total Iteration Time: 4.95535

Cumulative Model Updates: 124,840
Cumulative Timesteps: 1,041,981,210

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,190.21658
Policy Entropy: 1.64202
Value Function Loss: 0.06878

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.32177
Value Function Update Magnitude: 0.32098

Collected Steps per Second: 21,534.74985
Overall Steps per Second: 10,470.82340

Timestep Collection Time: 2.32248
Timestep Consumption Time: 2.45403
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.77651

Cumulative Model Updates: 124,846
Cumulative Timesteps: 1,042,031,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1042031224...
Checkpoint 1042031224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,721.35019
Policy Entropy: 1.63440
Value Function Loss: 0.06758

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.32353
Value Function Update Magnitude: 0.30671

Collected Steps per Second: 21,656.32956
Overall Steps per Second: 10,353.65538

Timestep Collection Time: 2.30999
Timestep Consumption Time: 2.52173
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.83172

Cumulative Model Updates: 124,852
Cumulative Timesteps: 1,042,081,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,442.82483
Policy Entropy: 1.61981
Value Function Loss: 0.07131

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.32502
Value Function Update Magnitude: 0.32706

Collected Steps per Second: 21,815.14117
Overall Steps per Second: 10,378.14217

Timestep Collection Time: 2.29281
Timestep Consumption Time: 2.52674
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.81955

Cumulative Model Updates: 124,858
Cumulative Timesteps: 1,042,131,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1042131268...
Checkpoint 1042131268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,951.31722
Policy Entropy: 1.63590
Value Function Loss: 0.07204

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.32800
Value Function Update Magnitude: 0.32337

Collected Steps per Second: 21,012.74438
Overall Steps per Second: 10,199.90734

Timestep Collection Time: 2.38056
Timestep Consumption Time: 2.52361
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.90416

Cumulative Model Updates: 124,864
Cumulative Timesteps: 1,042,181,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,859.60280
Policy Entropy: 1.62741
Value Function Loss: 0.07298

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.33039
Value Function Update Magnitude: 0.30567

Collected Steps per Second: 21,609.00522
Overall Steps per Second: 10,470.05906

Timestep Collection Time: 2.31496
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.77781

Cumulative Model Updates: 124,870
Cumulative Timesteps: 1,042,231,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1042231314...
Checkpoint 1042231314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,603.23582
Policy Entropy: 1.62294
Value Function Loss: 0.06729

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.32256
Value Function Update Magnitude: 0.25413

Collected Steps per Second: 21,645.27828
Overall Steps per Second: 10,377.51160

Timestep Collection Time: 2.31099
Timestep Consumption Time: 2.50924
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.82023

Cumulative Model Updates: 124,876
Cumulative Timesteps: 1,042,281,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,788.38269
Policy Entropy: 1.61778
Value Function Loss: 0.06637

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08721
Policy Update Magnitude: 0.31095
Value Function Update Magnitude: 0.23850

Collected Steps per Second: 21,898.12407
Overall Steps per Second: 10,423.09335

Timestep Collection Time: 2.28385
Timestep Consumption Time: 2.51434
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.79819

Cumulative Model Updates: 124,882
Cumulative Timesteps: 1,042,331,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1042331348...
Checkpoint 1042331348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,784.68942
Policy Entropy: 1.62816
Value Function Loss: 0.06783

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.31989
Value Function Update Magnitude: 0.28749

Collected Steps per Second: 21,746.99876
Overall Steps per Second: 10,572.24639

Timestep Collection Time: 2.30119
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.73353

Cumulative Model Updates: 124,888
Cumulative Timesteps: 1,042,381,392

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,508.37471
Policy Entropy: 1.63745
Value Function Loss: 0.06858

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.31569
Value Function Update Magnitude: 0.32020

Collected Steps per Second: 21,761.11645
Overall Steps per Second: 10,374.36332

Timestep Collection Time: 2.29860
Timestep Consumption Time: 2.52291
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.82150

Cumulative Model Updates: 124,894
Cumulative Timesteps: 1,042,431,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1042431412...
Checkpoint 1042431412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,252.45341
Policy Entropy: 1.62344
Value Function Loss: 0.06902

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08502
Policy Update Magnitude: 0.32086
Value Function Update Magnitude: 0.33481

Collected Steps per Second: 21,625.05889
Overall Steps per Second: 10,381.14221

Timestep Collection Time: 2.31296
Timestep Consumption Time: 2.50519
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.81816

Cumulative Model Updates: 124,900
Cumulative Timesteps: 1,042,481,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,396.79755
Policy Entropy: 1.61155
Value Function Loss: 0.06569

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.32529
Value Function Update Magnitude: 0.32967

Collected Steps per Second: 21,550.35850
Overall Steps per Second: 10,297.31257

Timestep Collection Time: 2.32145
Timestep Consumption Time: 2.53691
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.85836

Cumulative Model Updates: 124,906
Cumulative Timesteps: 1,042,531,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1042531458...
Checkpoint 1042531458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,201.27905
Policy Entropy: 1.60728
Value Function Loss: 0.06535

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.32289
Value Function Update Magnitude: 0.33646

Collected Steps per Second: 21,392.32952
Overall Steps per Second: 10,379.23815

Timestep Collection Time: 2.33794
Timestep Consumption Time: 2.48072
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.81866

Cumulative Model Updates: 124,912
Cumulative Timesteps: 1,042,581,472

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,999.09457
Policy Entropy: 1.61070
Value Function Loss: 0.06586

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.32246
Value Function Update Magnitude: 0.36015

Collected Steps per Second: 21,887.82035
Overall Steps per Second: 10,469.29950

Timestep Collection Time: 2.28538
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.77797

Cumulative Model Updates: 124,918
Cumulative Timesteps: 1,042,631,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1042631494...
Checkpoint 1042631494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,771.96210
Policy Entropy: 1.63050
Value Function Loss: 0.06894

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08171
Policy Update Magnitude: 0.32705
Value Function Update Magnitude: 0.37738

Collected Steps per Second: 21,184.22207
Overall Steps per Second: 10,438.62006

Timestep Collection Time: 2.36157
Timestep Consumption Time: 2.43102
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.79259

Cumulative Model Updates: 124,924
Cumulative Timesteps: 1,042,681,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,341.66319
Policy Entropy: 1.64743
Value Function Loss: 0.07264

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.32482
Value Function Update Magnitude: 0.37869

Collected Steps per Second: 19,769.69632
Overall Steps per Second: 9,941.78558

Timestep Collection Time: 2.53034
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 5.03169

Cumulative Model Updates: 124,930
Cumulative Timesteps: 1,042,731,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1042731546...
Checkpoint 1042731546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,849.57044
Policy Entropy: 1.65514
Value Function Loss: 0.07480

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.32731
Value Function Update Magnitude: 0.39196

Collected Steps per Second: 20,320.56386
Overall Steps per Second: 10,337.70697

Timestep Collection Time: 2.46125
Timestep Consumption Time: 2.37677
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.83802

Cumulative Model Updates: 124,936
Cumulative Timesteps: 1,042,781,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,629.38902
Policy Entropy: 1.64456
Value Function Loss: 0.07246

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.32584
Value Function Update Magnitude: 0.39797

Collected Steps per Second: 20,238.82444
Overall Steps per Second: 10,268.00798

Timestep Collection Time: 2.47188
Timestep Consumption Time: 2.40034
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.87222

Cumulative Model Updates: 124,942
Cumulative Timesteps: 1,042,831,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1042831588...
Checkpoint 1042831588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,649.54086
Policy Entropy: 1.63692
Value Function Loss: 0.07556

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.32747
Value Function Update Magnitude: 0.40991

Collected Steps per Second: 20,131.26975
Overall Steps per Second: 10,245.43538

Timestep Collection Time: 2.48499
Timestep Consumption Time: 2.39777
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.88276

Cumulative Model Updates: 124,948
Cumulative Timesteps: 1,042,881,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,274.56382
Policy Entropy: 1.65845
Value Function Loss: 0.07816

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.31685
Value Function Update Magnitude: 0.39432

Collected Steps per Second: 20,362.94881
Overall Steps per Second: 10,153.25634

Timestep Collection Time: 2.45740
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.92847

Cumulative Model Updates: 124,954
Cumulative Timesteps: 1,042,931,654

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1042931654...
Checkpoint 1042931654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,153.70019
Policy Entropy: 1.65229
Value Function Loss: 0.06981

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.29680
Value Function Update Magnitude: 0.36544

Collected Steps per Second: 20,031.86115
Overall Steps per Second: 10,239.73781

Timestep Collection Time: 2.49702
Timestep Consumption Time: 2.38787
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.88489

Cumulative Model Updates: 124,960
Cumulative Timesteps: 1,042,981,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,692.67872
Policy Entropy: 1.64484
Value Function Loss: 0.07010

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.29604
Value Function Update Magnitude: 0.35303

Collected Steps per Second: 20,692.21526
Overall Steps per Second: 10,131.70446

Timestep Collection Time: 2.41695
Timestep Consumption Time: 2.51924
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.93619

Cumulative Model Updates: 124,966
Cumulative Timesteps: 1,043,031,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1043031686...
Checkpoint 1043031686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,506.82558
Policy Entropy: 1.61298
Value Function Loss: 0.06673

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.28759
Value Function Update Magnitude: 0.35508

Collected Steps per Second: 21,151.18175
Overall Steps per Second: 10,384.01838

Timestep Collection Time: 2.36573
Timestep Consumption Time: 2.45302
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.81875

Cumulative Model Updates: 124,972
Cumulative Timesteps: 1,043,081,724

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,621.48640
Policy Entropy: 1.64018
Value Function Loss: 0.06751

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.30810
Value Function Update Magnitude: 0.36825

Collected Steps per Second: 21,275.66531
Overall Steps per Second: 10,311.64554

Timestep Collection Time: 2.35076
Timestep Consumption Time: 2.49948
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.85024

Cumulative Model Updates: 124,978
Cumulative Timesteps: 1,043,131,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1043131738...
Checkpoint 1043131738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,306.31868
Policy Entropy: 1.66430
Value Function Loss: 0.07068

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.32755
Value Function Update Magnitude: 0.37139

Collected Steps per Second: 21,256.36430
Overall Steps per Second: 10,410.99069

Timestep Collection Time: 2.35393
Timestep Consumption Time: 2.45214
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.80607

Cumulative Model Updates: 124,984
Cumulative Timesteps: 1,043,181,774

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,135.47301
Policy Entropy: 1.68012
Value Function Loss: 0.06956

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.33060
Value Function Update Magnitude: 0.37253

Collected Steps per Second: 21,020.91631
Overall Steps per Second: 10,222.19787

Timestep Collection Time: 2.38039
Timestep Consumption Time: 2.51464
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.89503

Cumulative Model Updates: 124,990
Cumulative Timesteps: 1,043,231,812

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1043231812...
Checkpoint 1043231812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,816.92907
Policy Entropy: 1.66723
Value Function Loss: 0.07036

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.32248
Value Function Update Magnitude: 0.35809

Collected Steps per Second: 21,161.06614
Overall Steps per Second: 10,358.23549

Timestep Collection Time: 2.36491
Timestep Consumption Time: 2.46642
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.83132

Cumulative Model Updates: 124,996
Cumulative Timesteps: 1,043,281,856

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,599.74588
Policy Entropy: 1.63477
Value Function Loss: 0.06643

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.31621
Value Function Update Magnitude: 0.33892

Collected Steps per Second: 21,323.11311
Overall Steps per Second: 10,218.92368

Timestep Collection Time: 2.34609
Timestep Consumption Time: 2.54933
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.89543

Cumulative Model Updates: 125,002
Cumulative Timesteps: 1,043,331,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1043331882...
Checkpoint 1043331882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,236.51105
Policy Entropy: 1.63725
Value Function Loss: 0.07119

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.32250
Value Function Update Magnitude: 0.35630

Collected Steps per Second: 21,140.13287
Overall Steps per Second: 10,177.85240

Timestep Collection Time: 2.36630
Timestep Consumption Time: 2.54868
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.91499

Cumulative Model Updates: 125,008
Cumulative Timesteps: 1,043,381,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,070.42658
Policy Entropy: 1.64017
Value Function Loss: 0.07181

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.32368
Value Function Update Magnitude: 0.36994

Collected Steps per Second: 21,158.30176
Overall Steps per Second: 10,357.12837

Timestep Collection Time: 2.36418
Timestep Consumption Time: 2.46554
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.82972

Cumulative Model Updates: 125,014
Cumulative Timesteps: 1,043,431,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1043431928...
Checkpoint 1043431928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,437.96481
Policy Entropy: 1.63788
Value Function Loss: 0.07290

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.32603
Value Function Update Magnitude: 0.35408

Collected Steps per Second: 20,905.46732
Overall Steps per Second: 10,265.01794

Timestep Collection Time: 2.39306
Timestep Consumption Time: 2.48058
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.87364

Cumulative Model Updates: 125,020
Cumulative Timesteps: 1,043,481,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,764.54717
Policy Entropy: 1.64644
Value Function Loss: 0.07067

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.32776
Value Function Update Magnitude: 0.34003

Collected Steps per Second: 21,380.78671
Overall Steps per Second: 10,422.31845

Timestep Collection Time: 2.34014
Timestep Consumption Time: 2.46052
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.80066

Cumulative Model Updates: 125,026
Cumulative Timesteps: 1,043,531,990

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1043531990...
Checkpoint 1043531990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,671.87465
Policy Entropy: 1.64114
Value Function Loss: 0.06607

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.31748
Value Function Update Magnitude: 0.34156

Collected Steps per Second: 20,812.77807
Overall Steps per Second: 10,218.64282

Timestep Collection Time: 2.40247
Timestep Consumption Time: 2.49075
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.89321

Cumulative Model Updates: 125,032
Cumulative Timesteps: 1,043,581,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,757.36950
Policy Entropy: 1.66474
Value Function Loss: 0.06925

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.32084
Value Function Update Magnitude: 0.35322

Collected Steps per Second: 21,341.74211
Overall Steps per Second: 10,356.21138

Timestep Collection Time: 2.34320
Timestep Consumption Time: 2.48559
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.82879

Cumulative Model Updates: 125,038
Cumulative Timesteps: 1,043,632,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1043632000...
Checkpoint 1043632000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,588.07596
Policy Entropy: 1.65257
Value Function Loss: 0.06710

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.32485
Value Function Update Magnitude: 0.36357

Collected Steps per Second: 19,982.64862
Overall Steps per Second: 9,237.81932

Timestep Collection Time: 2.50297
Timestep Consumption Time: 2.91129
PPO Batch Consumption Time: 0.33990
Total Iteration Time: 5.41426

Cumulative Model Updates: 125,044
Cumulative Timesteps: 1,043,682,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,218.66557
Policy Entropy: 1.66570
Value Function Loss: 0.06427

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.32133
Value Function Update Magnitude: 0.35557

Collected Steps per Second: 21,187.16158
Overall Steps per Second: 10,325.51282

Timestep Collection Time: 2.35992
Timestep Consumption Time: 2.48245
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.84237

Cumulative Model Updates: 125,050
Cumulative Timesteps: 1,043,732,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1043732016...
Checkpoint 1043732016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,201.94669
Policy Entropy: 1.66041
Value Function Loss: 0.06354

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.31109
Value Function Update Magnitude: 0.34113

Collected Steps per Second: 20,666.21180
Overall Steps per Second: 10,206.62643

Timestep Collection Time: 2.42018
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.90035

Cumulative Model Updates: 125,056
Cumulative Timesteps: 1,043,782,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,136.24445
Policy Entropy: 1.63751
Value Function Loss: 0.06862

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.32289
Value Function Update Magnitude: 0.34214

Collected Steps per Second: 20,928.71453
Overall Steps per Second: 10,076.36391

Timestep Collection Time: 2.38973
Timestep Consumption Time: 2.57377
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.96350

Cumulative Model Updates: 125,062
Cumulative Timesteps: 1,043,832,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1043832046...
Checkpoint 1043832046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,440.33587
Policy Entropy: 1.63227
Value Function Loss: 0.07192

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.33066
Value Function Update Magnitude: 0.36064

Collected Steps per Second: 21,125.92915
Overall Steps per Second: 10,206.45407

Timestep Collection Time: 2.36742
Timestep Consumption Time: 2.53281
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.90023

Cumulative Model Updates: 125,068
Cumulative Timesteps: 1,043,882,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,726.85064
Policy Entropy: 1.62713
Value Function Loss: 0.07478

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.33305
Value Function Update Magnitude: 0.34533

Collected Steps per Second: 21,269.23347
Overall Steps per Second: 10,221.82221

Timestep Collection Time: 2.35213
Timestep Consumption Time: 2.54211
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.89423

Cumulative Model Updates: 125,074
Cumulative Timesteps: 1,043,932,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1043932088...
Checkpoint 1043932088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,848.04502
Policy Entropy: 1.64715
Value Function Loss: 0.06966

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.33069
Value Function Update Magnitude: 0.28925

Collected Steps per Second: 21,305.03319
Overall Steps per Second: 10,377.31607

Timestep Collection Time: 2.34714
Timestep Consumption Time: 2.47163
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.81878

Cumulative Model Updates: 125,080
Cumulative Timesteps: 1,043,982,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,745.05102
Policy Entropy: 1.65485
Value Function Loss: 0.06875

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.32457
Value Function Update Magnitude: 0.25138

Collected Steps per Second: 21,191.45449
Overall Steps per Second: 10,195.11500

Timestep Collection Time: 2.36001
Timestep Consumption Time: 2.54548
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.90549

Cumulative Model Updates: 125,086
Cumulative Timesteps: 1,044,032,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1044032106...
Checkpoint 1044032106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,859.30754
Policy Entropy: 1.64980
Value Function Loss: 0.06639

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.32146
Value Function Update Magnitude: 0.25171

Collected Steps per Second: 21,174.11582
Overall Steps per Second: 10,164.82283

Timestep Collection Time: 2.36156
Timestep Consumption Time: 2.55776
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.91932

Cumulative Model Updates: 125,092
Cumulative Timesteps: 1,044,082,110

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,975.59968
Policy Entropy: 1.65845
Value Function Loss: 0.06853

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.31978
Value Function Update Magnitude: 0.30075

Collected Steps per Second: 21,367.38354
Overall Steps per Second: 10,362.01189

Timestep Collection Time: 2.34104
Timestep Consumption Time: 2.48640
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.82744

Cumulative Model Updates: 125,098
Cumulative Timesteps: 1,044,132,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1044132132...
Checkpoint 1044132132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,256.57031
Policy Entropy: 1.66434
Value Function Loss: 0.06604

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.31946
Value Function Update Magnitude: 0.32618

Collected Steps per Second: 20,545.63442
Overall Steps per Second: 10,204.80586

Timestep Collection Time: 2.43468
Timestep Consumption Time: 2.46713
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.90181

Cumulative Model Updates: 125,104
Cumulative Timesteps: 1,044,182,154

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,854.20444
Policy Entropy: 1.66105
Value Function Loss: 0.06464

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.32012
Value Function Update Magnitude: 0.33260

Collected Steps per Second: 20,987.41376
Overall Steps per Second: 10,126.66203

Timestep Collection Time: 2.38333
Timestep Consumption Time: 2.55610
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.93944

Cumulative Model Updates: 125,110
Cumulative Timesteps: 1,044,232,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1044232174...
Checkpoint 1044232174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,813.33711
Policy Entropy: 1.64788
Value Function Loss: 0.06197

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.32223
Value Function Update Magnitude: 0.32584

Collected Steps per Second: 20,795.25683
Overall Steps per Second: 10,073.30560

Timestep Collection Time: 2.40497
Timestep Consumption Time: 2.55983
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.96481

Cumulative Model Updates: 125,116
Cumulative Timesteps: 1,044,282,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,995.63190
Policy Entropy: 1.62818
Value Function Loss: 0.06565

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.32157
Value Function Update Magnitude: 0.33120

Collected Steps per Second: 21,278.97084
Overall Steps per Second: 10,228.61549

Timestep Collection Time: 2.34974
Timestep Consumption Time: 2.53851
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.88825

Cumulative Model Updates: 125,122
Cumulative Timesteps: 1,044,332,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1044332186...
Checkpoint 1044332186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,515.47853
Policy Entropy: 1.64040
Value Function Loss: 0.06549

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.32236
Value Function Update Magnitude: 0.33198

Collected Steps per Second: 21,142.26313
Overall Steps per Second: 10,173.60807

Timestep Collection Time: 2.36522
Timestep Consumption Time: 2.55005
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.91527

Cumulative Model Updates: 125,128
Cumulative Timesteps: 1,044,382,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,483.75515
Policy Entropy: 1.62645
Value Function Loss: 0.06963

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.32059
Value Function Update Magnitude: 0.33321

Collected Steps per Second: 21,257.71424
Overall Steps per Second: 10,353.76702

Timestep Collection Time: 2.35331
Timestep Consumption Time: 2.47836
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.83167

Cumulative Model Updates: 125,134
Cumulative Timesteps: 1,044,432,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1044432218...
Checkpoint 1044432218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,951.91947
Policy Entropy: 1.63652
Value Function Loss: 0.07054

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.32229
Value Function Update Magnitude: 0.32833

Collected Steps per Second: 21,007.94102
Overall Steps per Second: 10,316.75213

Timestep Collection Time: 2.38100
Timestep Consumption Time: 2.46742
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.84843

Cumulative Model Updates: 125,140
Cumulative Timesteps: 1,044,482,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,697.18874
Policy Entropy: 1.62969
Value Function Loss: 0.07198

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.32409
Value Function Update Magnitude: 0.33119

Collected Steps per Second: 21,398.65425
Overall Steps per Second: 10,385.15029

Timestep Collection Time: 2.33669
Timestep Consumption Time: 2.47807
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.81476

Cumulative Model Updates: 125,146
Cumulative Timesteps: 1,044,532,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1044532240...
Checkpoint 1044532240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,614.29098
Policy Entropy: 1.65538
Value Function Loss: 0.07420

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.32504
Value Function Update Magnitude: 0.32516

Collected Steps per Second: 21,291.51129
Overall Steps per Second: 10,215.09387

Timestep Collection Time: 2.34854
Timestep Consumption Time: 2.54657
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.89511

Cumulative Model Updates: 125,152
Cumulative Timesteps: 1,044,582,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,508.56889
Policy Entropy: 1.64068
Value Function Loss: 0.07236

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.32741
Value Function Update Magnitude: 0.33684

Collected Steps per Second: 21,400.27407
Overall Steps per Second: 10,360.11153

Timestep Collection Time: 2.33745
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.82833

Cumulative Model Updates: 125,158
Cumulative Timesteps: 1,044,632,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1044632266...
Checkpoint 1044632266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,333.09154
Policy Entropy: 1.65337
Value Function Loss: 0.07641

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.32940
Value Function Update Magnitude: 0.35799

Collected Steps per Second: 20,936.03870
Overall Steps per Second: 10,263.78026

Timestep Collection Time: 2.38861
Timestep Consumption Time: 2.48367
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.87228

Cumulative Model Updates: 125,164
Cumulative Timesteps: 1,044,682,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,252.65418
Policy Entropy: 1.64553
Value Function Loss: 0.07027

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.33257
Value Function Update Magnitude: 0.35520

Collected Steps per Second: 20,677.73863
Overall Steps per Second: 10,392.89044

Timestep Collection Time: 2.41941
Timestep Consumption Time: 2.39426
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.81368

Cumulative Model Updates: 125,170
Cumulative Timesteps: 1,044,732,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1044732302...
Checkpoint 1044732302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,151.35508
Policy Entropy: 1.66954
Value Function Loss: 0.07130

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.32487
Value Function Update Magnitude: 0.35862

Collected Steps per Second: 20,304.63693
Overall Steps per Second: 10,294.16041

Timestep Collection Time: 2.46367
Timestep Consumption Time: 2.39578
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.85945

Cumulative Model Updates: 125,176
Cumulative Timesteps: 1,044,782,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,407.17718
Policy Entropy: 1.65452
Value Function Loss: 0.06360

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.31923
Value Function Update Magnitude: 0.36507

Collected Steps per Second: 20,530.87384
Overall Steps per Second: 10,340.82519

Timestep Collection Time: 2.43575
Timestep Consumption Time: 2.40023
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.83598

Cumulative Model Updates: 125,182
Cumulative Timesteps: 1,044,832,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1044832334...
Checkpoint 1044832334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,906.81118
Policy Entropy: 1.64762
Value Function Loss: 0.06804

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.32851
Value Function Update Magnitude: 0.37625

Collected Steps per Second: 20,362.39079
Overall Steps per Second: 10,281.04525

Timestep Collection Time: 2.45629
Timestep Consumption Time: 2.40858
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.86488

Cumulative Model Updates: 125,188
Cumulative Timesteps: 1,044,882,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,164.82680
Policy Entropy: 1.64243
Value Function Loss: 0.06888

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.32992
Value Function Update Magnitude: 0.38020

Collected Steps per Second: 20,438.50698
Overall Steps per Second: 10,191.95203

Timestep Collection Time: 2.44646
Timestep Consumption Time: 2.45957
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.90603

Cumulative Model Updates: 125,194
Cumulative Timesteps: 1,044,932,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1044932352...
Checkpoint 1044932352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,469.03233
Policy Entropy: 1.64270
Value Function Loss: 0.06910

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08209
Policy Update Magnitude: 0.32896
Value Function Update Magnitude: 0.37791

Collected Steps per Second: 20,397.98751
Overall Steps per Second: 10,079.75839

Timestep Collection Time: 2.45201
Timestep Consumption Time: 2.51002
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.96202

Cumulative Model Updates: 125,200
Cumulative Timesteps: 1,044,982,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,024.93208
Policy Entropy: 1.64351
Value Function Loss: 0.06628

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.32540
Value Function Update Magnitude: 0.36585

Collected Steps per Second: 21,001.99687
Overall Steps per Second: 10,346.70248

Timestep Collection Time: 2.38073
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.83246

Cumulative Model Updates: 125,206
Cumulative Timesteps: 1,045,032,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1045032368...
Checkpoint 1045032368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,979.84594
Policy Entropy: 1.64963
Value Function Loss: 0.06471

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.32252
Value Function Update Magnitude: 0.37166

Collected Steps per Second: 21,065.56258
Overall Steps per Second: 10,256.82050

Timestep Collection Time: 2.37373
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.87520

Cumulative Model Updates: 125,212
Cumulative Timesteps: 1,045,082,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,369.43312
Policy Entropy: 1.65328
Value Function Loss: 0.06649

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.32432
Value Function Update Magnitude: 0.36887

Collected Steps per Second: 20,941.29364
Overall Steps per Second: 10,189.18063

Timestep Collection Time: 2.38782
Timestep Consumption Time: 2.51974
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.90756

Cumulative Model Updates: 125,218
Cumulative Timesteps: 1,045,132,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1045132376...
Checkpoint 1045132376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,277.86271
Policy Entropy: 1.66100
Value Function Loss: 0.06728

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.32521
Value Function Update Magnitude: 0.36187

Collected Steps per Second: 21,369.32116
Overall Steps per Second: 10,441.26763

Timestep Collection Time: 2.34121
Timestep Consumption Time: 2.45036
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.79156

Cumulative Model Updates: 125,224
Cumulative Timesteps: 1,045,182,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,311.06570
Policy Entropy: 1.65603
Value Function Loss: 0.06762

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.32324
Value Function Update Magnitude: 0.36001

Collected Steps per Second: 20,875.58099
Overall Steps per Second: 10,080.68599

Timestep Collection Time: 2.39648
Timestep Consumption Time: 2.56627
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.96276

Cumulative Model Updates: 125,230
Cumulative Timesteps: 1,045,232,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1045232434...
Checkpoint 1045232434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,432.12700
Policy Entropy: 1.66547
Value Function Loss: 0.06638

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.32675
Value Function Update Magnitude: 0.32828

Collected Steps per Second: 21,115.59993
Overall Steps per Second: 10,201.41514

Timestep Collection Time: 2.36924
Timestep Consumption Time: 2.53478
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.90403

Cumulative Model Updates: 125,236
Cumulative Timesteps: 1,045,282,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,732.41743
Policy Entropy: 1.65355
Value Function Loss: 0.06740

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.32340
Value Function Update Magnitude: 0.28380

Collected Steps per Second: 20,998.41017
Overall Steps per Second: 10,155.98492

Timestep Collection Time: 2.38209
Timestep Consumption Time: 2.54309
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.92517

Cumulative Model Updates: 125,242
Cumulative Timesteps: 1,045,332,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1045332482...
Checkpoint 1045332482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,566.17443
Policy Entropy: 1.63935
Value Function Loss: 0.06382

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.32241
Value Function Update Magnitude: 0.29159

Collected Steps per Second: 20,992.05394
Overall Steps per Second: 10,126.29510

Timestep Collection Time: 2.38309
Timestep Consumption Time: 2.55712
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.94021

Cumulative Model Updates: 125,248
Cumulative Timesteps: 1,045,382,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,413.90300
Policy Entropy: 1.62018
Value Function Loss: 0.06231

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.32224
Value Function Update Magnitude: 0.30522

Collected Steps per Second: 20,778.25615
Overall Steps per Second: 10,078.48252

Timestep Collection Time: 2.40723
Timestep Consumption Time: 2.55562
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.96285

Cumulative Model Updates: 125,254
Cumulative Timesteps: 1,045,432,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1045432526...
Checkpoint 1045432526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,989.56045
Policy Entropy: 1.62601
Value Function Loss: 0.06139

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.31214
Value Function Update Magnitude: 0.32474

Collected Steps per Second: 21,208.97791
Overall Steps per Second: 10,176.56420

Timestep Collection Time: 2.35749
Timestep Consumption Time: 2.55576
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.91325

Cumulative Model Updates: 125,260
Cumulative Timesteps: 1,045,482,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,802.56509
Policy Entropy: 1.64563
Value Function Loss: 0.06694

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.28780
Value Function Update Magnitude: 0.33150

Collected Steps per Second: 20,713.62780
Overall Steps per Second: 10,039.09329

Timestep Collection Time: 2.41445
Timestep Consumption Time: 2.56728
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.98172

Cumulative Model Updates: 125,266
Cumulative Timesteps: 1,045,532,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1045532538...
Checkpoint 1045532538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,065.43533
Policy Entropy: 1.64682
Value Function Loss: 0.06717

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.29592
Value Function Update Magnitude: 0.33897

Collected Steps per Second: 21,211.05110
Overall Steps per Second: 10,214.51962

Timestep Collection Time: 2.35802
Timestep Consumption Time: 2.53854
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.89656

Cumulative Model Updates: 125,272
Cumulative Timesteps: 1,045,582,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,578.45488
Policy Entropy: 1.64786
Value Function Loss: 0.07047

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.28984
Value Function Update Magnitude: 0.33831

Collected Steps per Second: 20,682.01100
Overall Steps per Second: 10,079.83927

Timestep Collection Time: 2.41843
Timestep Consumption Time: 2.54375
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.96218

Cumulative Model Updates: 125,278
Cumulative Timesteps: 1,045,632,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1045632572...
Checkpoint 1045632572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,086.50262
Policy Entropy: 1.64527
Value Function Loss: 0.06841

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.30835
Value Function Update Magnitude: 0.33422

Collected Steps per Second: 20,808.67278
Overall Steps per Second: 10,133.24447

Timestep Collection Time: 2.40381
Timestep Consumption Time: 2.53242
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.93623

Cumulative Model Updates: 125,284
Cumulative Timesteps: 1,045,682,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,016.21822
Policy Entropy: 1.65465
Value Function Loss: 0.06705

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.32360
Value Function Update Magnitude: 0.31985

Collected Steps per Second: 20,801.35661
Overall Steps per Second: 10,079.04412

Timestep Collection Time: 2.40494
Timestep Consumption Time: 2.55843
PPO Batch Consumption Time: 0.29805
Total Iteration Time: 4.96337

Cumulative Model Updates: 125,290
Cumulative Timesteps: 1,045,732,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1045732618...
Checkpoint 1045732618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,265.81892
Policy Entropy: 1.63776
Value Function Loss: 0.06240

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.32113
Value Function Update Magnitude: 0.32747

Collected Steps per Second: 21,158.85176
Overall Steps per Second: 10,201.85572

Timestep Collection Time: 2.36393
Timestep Consumption Time: 2.53891
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.90283

Cumulative Model Updates: 125,296
Cumulative Timesteps: 1,045,782,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,408.77743
Policy Entropy: 1.63205
Value Function Loss: 0.06446

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.29720
Value Function Update Magnitude: 0.33840

Collected Steps per Second: 20,315.25456
Overall Steps per Second: 10,170.45665

Timestep Collection Time: 2.46120
Timestep Consumption Time: 2.45500
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.91620

Cumulative Model Updates: 125,302
Cumulative Timesteps: 1,045,832,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1045832636...
Checkpoint 1045832636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,563.40278
Policy Entropy: 1.64172
Value Function Loss: 0.06780

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.30101
Value Function Update Magnitude: 0.34887

Collected Steps per Second: 20,559.54866
Overall Steps per Second: 10,215.07419

Timestep Collection Time: 2.43332
Timestep Consumption Time: 2.46415
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.89747

Cumulative Model Updates: 125,308
Cumulative Timesteps: 1,045,882,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,784.47114
Policy Entropy: 1.65643
Value Function Loss: 0.07386

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.29746
Value Function Update Magnitude: 0.35711

Collected Steps per Second: 20,336.66407
Overall Steps per Second: 10,283.10413

Timestep Collection Time: 2.45871
Timestep Consumption Time: 2.40383
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.86254

Cumulative Model Updates: 125,314
Cumulative Timesteps: 1,045,932,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1045932666...
Checkpoint 1045932666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,342.34616
Policy Entropy: 1.65214
Value Function Loss: 0.06850

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.31775
Value Function Update Magnitude: 0.35185

Collected Steps per Second: 20,255.03095
Overall Steps per Second: 10,187.47135

Timestep Collection Time: 2.46872
Timestep Consumption Time: 2.43966
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.90838

Cumulative Model Updates: 125,320
Cumulative Timesteps: 1,045,982,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,847.39189
Policy Entropy: 1.63688
Value Function Loss: 0.07424

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.30424
Value Function Update Magnitude: 0.32302

Collected Steps per Second: 20,086.95032
Overall Steps per Second: 10,051.87624

Timestep Collection Time: 2.49117
Timestep Consumption Time: 2.48701
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 4.97818

Cumulative Model Updates: 125,326
Cumulative Timesteps: 1,046,032,710

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1046032710...
Checkpoint 1046032710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,090.50314
Policy Entropy: 1.64181
Value Function Loss: 0.07018

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.30117
Value Function Update Magnitude: 0.28357

Collected Steps per Second: 20,433.47206
Overall Steps per Second: 10,213.67401

Timestep Collection Time: 2.44716
Timestep Consumption Time: 2.44863
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.89579

Cumulative Model Updates: 125,332
Cumulative Timesteps: 1,046,082,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,030.10830
Policy Entropy: 1.64250
Value Function Loss: 0.07042

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.31928
Value Function Update Magnitude: 0.32459

Collected Steps per Second: 20,404.05695
Overall Steps per Second: 10,030.20855

Timestep Collection Time: 2.45118
Timestep Consumption Time: 2.53516
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.98634

Cumulative Model Updates: 125,338
Cumulative Timesteps: 1,046,132,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1046132728...
Checkpoint 1046132728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,619.14637
Policy Entropy: 1.64365
Value Function Loss: 0.06806

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.32540
Value Function Update Magnitude: 0.31181

Collected Steps per Second: 20,984.45409
Overall Steps per Second: 10,233.22956

Timestep Collection Time: 2.38424
Timestep Consumption Time: 2.50493
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.88917

Cumulative Model Updates: 125,344
Cumulative Timesteps: 1,046,182,760

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,648.38652
Policy Entropy: 1.65512
Value Function Loss: 0.07778

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.32931
Value Function Update Magnitude: 0.34668

Collected Steps per Second: 21,131.23527
Overall Steps per Second: 10,354.61942

Timestep Collection Time: 2.36635
Timestep Consumption Time: 2.46279
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.82915

Cumulative Model Updates: 125,350
Cumulative Timesteps: 1,046,232,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1046232764...
Checkpoint 1046232764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,782.94697
Policy Entropy: 1.66604
Value Function Loss: 0.07960

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.33847
Value Function Update Magnitude: 0.38580

Collected Steps per Second: 21,097.49740
Overall Steps per Second: 10,281.91047

Timestep Collection Time: 2.37175
Timestep Consumption Time: 2.49485
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.86661

Cumulative Model Updates: 125,356
Cumulative Timesteps: 1,046,282,802

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,673.41971
Policy Entropy: 1.67588
Value Function Loss: 0.07817

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.34289
Value Function Update Magnitude: 0.38394

Collected Steps per Second: 20,471.87228
Overall Steps per Second: 10,050.58753

Timestep Collection Time: 2.44306
Timestep Consumption Time: 2.53317
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.97623

Cumulative Model Updates: 125,362
Cumulative Timesteps: 1,046,332,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1046332816...
Checkpoint 1046332816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,506.46596
Policy Entropy: 1.64893
Value Function Loss: 0.07158

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.33739
Value Function Update Magnitude: 0.33520

Collected Steps per Second: 21,123.30708
Overall Steps per Second: 10,233.00576

Timestep Collection Time: 2.36810
Timestep Consumption Time: 2.52020
PPO Batch Consumption Time: 0.29841
Total Iteration Time: 4.88830

Cumulative Model Updates: 125,368
Cumulative Timesteps: 1,046,382,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,324.74294
Policy Entropy: 1.64185
Value Function Loss: 0.06632

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.32939
Value Function Update Magnitude: 0.34140

Collected Steps per Second: 21,064.30225
Overall Steps per Second: 10,320.54425

Timestep Collection Time: 2.37482
Timestep Consumption Time: 2.47221
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.84703

Cumulative Model Updates: 125,374
Cumulative Timesteps: 1,046,432,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1046432862...
Checkpoint 1046432862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,582.59829
Policy Entropy: 1.63017
Value Function Loss: 0.06518

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.32633
Value Function Update Magnitude: 0.34820

Collected Steps per Second: 21,158.27913
Overall Steps per Second: 10,336.66800

Timestep Collection Time: 2.36371
Timestep Consumption Time: 2.47460
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.83831

Cumulative Model Updates: 125,380
Cumulative Timesteps: 1,046,482,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,700.72968
Policy Entropy: 1.64436
Value Function Loss: 0.06457

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.32308
Value Function Update Magnitude: 0.36280

Collected Steps per Second: 21,187.15692
Overall Steps per Second: 10,336.02839

Timestep Collection Time: 2.36049
Timestep Consumption Time: 2.47812
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.83861

Cumulative Model Updates: 125,386
Cumulative Timesteps: 1,046,532,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1046532886...
Checkpoint 1046532886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,777.77939
Policy Entropy: 1.66469
Value Function Loss: 0.06857

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.32614
Value Function Update Magnitude: 0.37986

Collected Steps per Second: 21,152.46639
Overall Steps per Second: 10,296.09710

Timestep Collection Time: 2.36426
Timestep Consumption Time: 2.49292
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.85718

Cumulative Model Updates: 125,392
Cumulative Timesteps: 1,046,582,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,263.23795
Policy Entropy: 1.64598
Value Function Loss: 0.06357

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.32665
Value Function Update Magnitude: 0.38455

Collected Steps per Second: 21,199.03840
Overall Steps per Second: 10,201.92139

Timestep Collection Time: 2.35935
Timestep Consumption Time: 2.54325
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.90261

Cumulative Model Updates: 125,398
Cumulative Timesteps: 1,046,632,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1046632912...
Checkpoint 1046632912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,537.80995
Policy Entropy: 1.63348
Value Function Loss: 0.06241

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.31574
Value Function Update Magnitude: 0.36973

Collected Steps per Second: 21,313.01233
Overall Steps per Second: 10,370.60358

Timestep Collection Time: 2.34608
Timestep Consumption Time: 2.47543
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.82151

Cumulative Model Updates: 125,404
Cumulative Timesteps: 1,046,682,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,380.34043
Policy Entropy: 1.62262
Value Function Loss: 0.06392

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.31533
Value Function Update Magnitude: 0.34588

Collected Steps per Second: 21,115.33028
Overall Steps per Second: 10,131.07211

Timestep Collection Time: 2.37003
Timestep Consumption Time: 2.56962
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.93965

Cumulative Model Updates: 125,410
Cumulative Timesteps: 1,046,732,958

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1046732958...
Checkpoint 1046732958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,004.22760
Policy Entropy: 1.62650
Value Function Loss: 0.06383

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.31755
Value Function Update Magnitude: 0.34029

Collected Steps per Second: 20,911.97383
Overall Steps per Second: 10,244.63402

Timestep Collection Time: 2.39126
Timestep Consumption Time: 2.48993
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.88119

Cumulative Model Updates: 125,416
Cumulative Timesteps: 1,046,782,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,517.42669
Policy Entropy: 1.63180
Value Function Loss: 0.06686

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.32748
Value Function Update Magnitude: 0.35373

Collected Steps per Second: 20,920.66479
Overall Steps per Second: 10,165.74868

Timestep Collection Time: 2.39170
Timestep Consumption Time: 2.53032
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.92202

Cumulative Model Updates: 125,422
Cumulative Timesteps: 1,046,833,000

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1046833000...
Checkpoint 1046833000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,929.33266
Policy Entropy: 1.63721
Value Function Loss: 0.06770

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.33038
Value Function Update Magnitude: 0.34642

Collected Steps per Second: 21,178.99900
Overall Steps per Second: 10,228.74272

Timestep Collection Time: 2.36187
Timestep Consumption Time: 2.52847
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.89034

Cumulative Model Updates: 125,428
Cumulative Timesteps: 1,046,883,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,699.44965
Policy Entropy: 1.64868
Value Function Loss: 0.06521

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.32887
Value Function Update Magnitude: 0.34290

Collected Steps per Second: 21,170.17900
Overall Steps per Second: 10,320.88504

Timestep Collection Time: 2.36323
Timestep Consumption Time: 2.48422
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.84745

Cumulative Model Updates: 125,434
Cumulative Timesteps: 1,046,933,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1046933052...
Checkpoint 1046933052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,956.63072
Policy Entropy: 1.65135
Value Function Loss: 0.06158

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.31566
Value Function Update Magnitude: 0.34860

Collected Steps per Second: 20,885.49365
Overall Steps per Second: 10,182.29239

Timestep Collection Time: 2.39458
Timestep Consumption Time: 2.51708
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.91166

Cumulative Model Updates: 125,440
Cumulative Timesteps: 1,046,983,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,147.65170
Policy Entropy: 1.65033
Value Function Loss: 0.05904

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.31533
Value Function Update Magnitude: 0.33969

Collected Steps per Second: 20,980.58145
Overall Steps per Second: 10,108.09354

Timestep Collection Time: 2.38363
Timestep Consumption Time: 2.56389
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.94752

Cumulative Model Updates: 125,446
Cumulative Timesteps: 1,047,033,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1047033074...
Checkpoint 1047033074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,761.98759
Policy Entropy: 1.64482
Value Function Loss: 0.06044

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.30289
Value Function Update Magnitude: 0.33293

Collected Steps per Second: 21,120.40710
Overall Steps per Second: 10,158.67000

Timestep Collection Time: 2.36757
Timestep Consumption Time: 2.55473
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.92230

Cumulative Model Updates: 125,452
Cumulative Timesteps: 1,047,083,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,996.34091
Policy Entropy: 1.67011
Value Function Loss: 0.06387

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.30091
Value Function Update Magnitude: 0.33219

Collected Steps per Second: 21,286.75226
Overall Steps per Second: 10,396.34755

Timestep Collection Time: 2.34982
Timestep Consumption Time: 2.46149
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.81131

Cumulative Model Updates: 125,458
Cumulative Timesteps: 1,047,133,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1047133098...
Checkpoint 1047133098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,333.41936
Policy Entropy: 1.67409
Value Function Loss: 0.06895

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.30563
Value Function Update Magnitude: 0.33814

Collected Steps per Second: 21,108.98489
Overall Steps per Second: 10,236.73033

Timestep Collection Time: 2.36904
Timestep Consumption Time: 2.51612
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.88515

Cumulative Model Updates: 125,464
Cumulative Timesteps: 1,047,183,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,831.09897
Policy Entropy: 1.66108
Value Function Loss: 0.07269

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.29891
Value Function Update Magnitude: 0.35161

Collected Steps per Second: 21,211.51278
Overall Steps per Second: 10,328.51544

Timestep Collection Time: 2.35778
Timestep Consumption Time: 2.48435
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.84213

Cumulative Model Updates: 125,470
Cumulative Timesteps: 1,047,233,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1047233118...
Checkpoint 1047233118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,921.04197
Policy Entropy: 1.63093
Value Function Loss: 0.06837

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.28924
Value Function Update Magnitude: 0.36767

Collected Steps per Second: 21,000.73138
Overall Steps per Second: 10,278.38435

Timestep Collection Time: 2.38125
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.86536

Cumulative Model Updates: 125,476
Cumulative Timesteps: 1,047,283,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,440.02098
Policy Entropy: 1.63074
Value Function Loss: 0.06389

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.30599
Value Function Update Magnitude: 0.36620

Collected Steps per Second: 21,160.53421
Overall Steps per Second: 10,157.67778

Timestep Collection Time: 2.36346
Timestep Consumption Time: 2.56011
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.92357

Cumulative Model Updates: 125,482
Cumulative Timesteps: 1,047,333,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1047333138...
Checkpoint 1047333138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,150.53327
Policy Entropy: 1.66617
Value Function Loss: 0.06366

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08102
Policy Update Magnitude: 0.31980
Value Function Update Magnitude: 0.33973

Collected Steps per Second: 20,920.02428
Overall Steps per Second: 10,116.50917

Timestep Collection Time: 2.39063
Timestep Consumption Time: 2.55297
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.94360

Cumulative Model Updates: 125,488
Cumulative Timesteps: 1,047,383,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,999.40630
Policy Entropy: 1.67510
Value Function Loss: 0.06260

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.31980
Value Function Update Magnitude: 0.31779

Collected Steps per Second: 21,273.43420
Overall Steps per Second: 10,336.53431

Timestep Collection Time: 2.35073
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.83799

Cumulative Model Updates: 125,494
Cumulative Timesteps: 1,047,433,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1047433158...
Checkpoint 1047433158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,442.49344
Policy Entropy: 1.66004
Value Function Loss: 0.06733

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.32293
Value Function Update Magnitude: 0.32636

Collected Steps per Second: 20,705.92903
Overall Steps per Second: 10,229.80702

Timestep Collection Time: 2.41564
Timestep Consumption Time: 2.47380
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.88944

Cumulative Model Updates: 125,500
Cumulative Timesteps: 1,047,483,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,242.91746
Policy Entropy: 1.64531
Value Function Loss: 0.06584

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.32531
Value Function Update Magnitude: 0.33577

Collected Steps per Second: 21,000.27358
Overall Steps per Second: 10,132.21464

Timestep Collection Time: 2.38102
Timestep Consumption Time: 2.55394
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.93495

Cumulative Model Updates: 125,506
Cumulative Timesteps: 1,047,533,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1047533178...
Checkpoint 1047533178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,910.26680
Policy Entropy: 1.64399
Value Function Loss: 0.06706

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.32692
Value Function Update Magnitude: 0.33351

Collected Steps per Second: 20,918.27531
Overall Steps per Second: 10,196.23699

Timestep Collection Time: 2.39102
Timestep Consumption Time: 2.51432
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.90534

Cumulative Model Updates: 125,512
Cumulative Timesteps: 1,047,583,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,978.70569
Policy Entropy: 1.63959
Value Function Loss: 0.06557

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.31603
Value Function Update Magnitude: 0.30898

Collected Steps per Second: 21,119.43568
Overall Steps per Second: 10,208.91817

Timestep Collection Time: 2.36758
Timestep Consumption Time: 2.53029
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.89787

Cumulative Model Updates: 125,518
Cumulative Timesteps: 1,047,633,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1047633196...
Checkpoint 1047633196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,624.22480
Policy Entropy: 1.65827
Value Function Loss: 0.06697

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.29555
Value Function Update Magnitude: 0.30169

Collected Steps per Second: 20,658.09709
Overall Steps per Second: 10,072.46314

Timestep Collection Time: 2.42133
Timestep Consumption Time: 2.54469
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.96601

Cumulative Model Updates: 125,524
Cumulative Timesteps: 1,047,683,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,523.69239
Policy Entropy: 1.65724
Value Function Loss: 0.06787

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.31405
Value Function Update Magnitude: 0.32247

Collected Steps per Second: 21,598.62752
Overall Steps per Second: 10,397.20755

Timestep Collection Time: 2.31552
Timestep Consumption Time: 2.49462
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.81014

Cumulative Model Updates: 125,530
Cumulative Timesteps: 1,047,733,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1047733228...
Checkpoint 1047733228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,994.84836
Policy Entropy: 1.66880
Value Function Loss: 0.06502

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.32296
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 20,862.46979
Overall Steps per Second: 10,273.37314

Timestep Collection Time: 2.39684
Timestep Consumption Time: 2.47050
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.86734

Cumulative Model Updates: 125,536
Cumulative Timesteps: 1,047,783,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,962.61495
Policy Entropy: 1.64433
Value Function Loss: 0.06564

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.32121
Value Function Update Magnitude: 0.32113

Collected Steps per Second: 21,083.58661
Overall Steps per Second: 10,315.43208

Timestep Collection Time: 2.37275
Timestep Consumption Time: 2.47688
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.84963

Cumulative Model Updates: 125,542
Cumulative Timesteps: 1,047,833,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1047833258...
Checkpoint 1047833258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,491.98586
Policy Entropy: 1.64593
Value Function Loss: 0.06896

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.32066
Value Function Update Magnitude: 0.30480

Collected Steps per Second: 20,546.70517
Overall Steps per Second: 10,205.83529

Timestep Collection Time: 2.43475
Timestep Consumption Time: 2.46696
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.90171

Cumulative Model Updates: 125,548
Cumulative Timesteps: 1,047,883,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,223.83833
Policy Entropy: 1.65167
Value Function Loss: 0.06916

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.32009
Value Function Update Magnitude: 0.31130

Collected Steps per Second: 21,279.85615
Overall Steps per Second: 10,216.36210

Timestep Collection Time: 2.34992
Timestep Consumption Time: 2.54478
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.89470

Cumulative Model Updates: 125,554
Cumulative Timesteps: 1,047,933,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1047933290...
Checkpoint 1047933290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,436.78204
Policy Entropy: 1.66872
Value Function Loss: 0.07022

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.32143
Value Function Update Magnitude: 0.34601

Collected Steps per Second: 20,834.43078
Overall Steps per Second: 10,099.06824

Timestep Collection Time: 2.40141
Timestep Consumption Time: 2.55271
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.95412

Cumulative Model Updates: 125,560
Cumulative Timesteps: 1,047,983,322

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,395.81180
Policy Entropy: 1.66300
Value Function Loss: 0.06391

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.30317
Value Function Update Magnitude: 0.34971

Collected Steps per Second: 21,561.84846
Overall Steps per Second: 10,418.06224

Timestep Collection Time: 2.31965
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.80089

Cumulative Model Updates: 125,566
Cumulative Timesteps: 1,048,033,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1048033338...
Checkpoint 1048033338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,907.06396
Policy Entropy: 1.65109
Value Function Loss: 0.06614

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.29707
Value Function Update Magnitude: 0.35020

Collected Steps per Second: 20,216.38220
Overall Steps per Second: 10,246.35614

Timestep Collection Time: 2.47482
Timestep Consumption Time: 2.40808
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.88291

Cumulative Model Updates: 125,572
Cumulative Timesteps: 1,048,083,370

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,120.51916
Policy Entropy: 1.64027
Value Function Loss: 0.06187

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07417
Policy Update Magnitude: 0.31263
Value Function Update Magnitude: 0.33039

Collected Steps per Second: 20,654.34576
Overall Steps per Second: 10,250.02434

Timestep Collection Time: 2.42215
Timestep Consumption Time: 2.45862
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.88077

Cumulative Model Updates: 125,578
Cumulative Timesteps: 1,048,133,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1048133398...
Checkpoint 1048133398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,344.43448
Policy Entropy: 1.64252
Value Function Loss: 0.06708

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.31975
Value Function Update Magnitude: 0.32624

Collected Steps per Second: 20,468.04569
Overall Steps per Second: 10,342.43702

Timestep Collection Time: 2.44469
Timestep Consumption Time: 2.39344
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.83812

Cumulative Model Updates: 125,584
Cumulative Timesteps: 1,048,183,436

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,058.72310
Policy Entropy: 1.65041
Value Function Loss: 0.06630

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07994
Policy Update Magnitude: 0.32141
Value Function Update Magnitude: 0.33578

Collected Steps per Second: 20,744.62522
Overall Steps per Second: 10,275.63744

Timestep Collection Time: 2.41142
Timestep Consumption Time: 2.45679
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.86821

Cumulative Model Updates: 125,590
Cumulative Timesteps: 1,048,233,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1048233460...
Checkpoint 1048233460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,340.63829
Policy Entropy: 1.64435
Value Function Loss: 0.06281

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08115
Policy Update Magnitude: 0.31574
Value Function Update Magnitude: 0.33874

Collected Steps per Second: 20,339.52073
Overall Steps per Second: 10,143.91399

Timestep Collection Time: 2.46004
Timestep Consumption Time: 2.47257
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.93261

Cumulative Model Updates: 125,596
Cumulative Timesteps: 1,048,283,496

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,242.21098
Policy Entropy: 1.63496
Value Function Loss: 0.06262

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.31223
Value Function Update Magnitude: 0.32359

Collected Steps per Second: 20,793.65642
Overall Steps per Second: 10,286.31209

Timestep Collection Time: 2.40573
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.86316

Cumulative Model Updates: 125,602
Cumulative Timesteps: 1,048,333,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1048333520...
Checkpoint 1048333520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,580.40616
Policy Entropy: 1.62864
Value Function Loss: 0.06491

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08663
Policy Update Magnitude: 0.31642
Value Function Update Magnitude: 0.33238

Collected Steps per Second: 20,683.41107
Overall Steps per Second: 10,260.49778

Timestep Collection Time: 2.41817
Timestep Consumption Time: 2.45645
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.87462

Cumulative Model Updates: 125,608
Cumulative Timesteps: 1,048,383,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,015.82824
Policy Entropy: 1.64726
Value Function Loss: 0.06851

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.31647
Value Function Update Magnitude: 0.34634

Collected Steps per Second: 21,074.48433
Overall Steps per Second: 10,226.04383

Timestep Collection Time: 2.37301
Timestep Consumption Time: 2.51744
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.89045

Cumulative Model Updates: 125,614
Cumulative Timesteps: 1,048,433,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1048433546...
Checkpoint 1048433546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,301.74735
Policy Entropy: 1.64024
Value Function Loss: 0.06993

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.32074
Value Function Update Magnitude: 0.36088

Collected Steps per Second: 20,893.43409
Overall Steps per Second: 10,169.29303

Timestep Collection Time: 2.39386
Timestep Consumption Time: 2.52447
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.91834

Cumulative Model Updates: 125,620
Cumulative Timesteps: 1,048,483,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,768.96722
Policy Entropy: 1.64455
Value Function Loss: 0.06166

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.31799
Value Function Update Magnitude: 0.35033

Collected Steps per Second: 21,509.14027
Overall Steps per Second: 10,339.41213

Timestep Collection Time: 2.32599
Timestep Consumption Time: 2.51278
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.83877

Cumulative Model Updates: 125,626
Cumulative Timesteps: 1,048,533,592

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1048533592...
Checkpoint 1048533592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,817.35294
Policy Entropy: 1.63445
Value Function Loss: 0.05981

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.31371
Value Function Update Magnitude: 0.33035

Collected Steps per Second: 20,682.49847
Overall Steps per Second: 10,195.87100

Timestep Collection Time: 2.41847
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.90591

Cumulative Model Updates: 125,632
Cumulative Timesteps: 1,048,583,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,803.62732
Policy Entropy: 1.65153
Value Function Loss: 0.06168

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.30627
Value Function Update Magnitude: 0.32096

Collected Steps per Second: 21,402.93614
Overall Steps per Second: 10,435.57693

Timestep Collection Time: 2.33660
Timestep Consumption Time: 2.45566
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.79226

Cumulative Model Updates: 125,638
Cumulative Timesteps: 1,048,633,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1048633622...
Checkpoint 1048633622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,214.83948
Policy Entropy: 1.65843
Value Function Loss: 0.06528

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.30753
Value Function Update Magnitude: 0.32759

Collected Steps per Second: 20,956.32954
Overall Steps per Second: 10,187.12960

Timestep Collection Time: 2.38696
Timestep Consumption Time: 2.52335
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.91031

Cumulative Model Updates: 125,644
Cumulative Timesteps: 1,048,683,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,033.44982
Policy Entropy: 1.64868
Value Function Loss: 0.06257

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.29888
Value Function Update Magnitude: 0.33718

Collected Steps per Second: 21,453.17042
Overall Steps per Second: 10,401.29435

Timestep Collection Time: 2.33084
Timestep Consumption Time: 2.47663
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.80748

Cumulative Model Updates: 125,650
Cumulative Timesteps: 1,048,733,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1048733648...
Checkpoint 1048733648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,852.76668
Policy Entropy: 1.64967
Value Function Loss: 0.06187

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.31259
Value Function Update Magnitude: 0.34525

Collected Steps per Second: 20,593.75178
Overall Steps per Second: 10,215.02753

Timestep Collection Time: 2.42802
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.89495

Cumulative Model Updates: 125,656
Cumulative Timesteps: 1,048,783,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,246.84940
Policy Entropy: 1.64634
Value Function Loss: 0.06338

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.31665
Value Function Update Magnitude: 0.34628

Collected Steps per Second: 21,231.04760
Overall Steps per Second: 10,187.14339

Timestep Collection Time: 2.35589
Timestep Consumption Time: 2.55402
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.90991

Cumulative Model Updates: 125,662
Cumulative Timesteps: 1,048,833,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1048833668...
Checkpoint 1048833668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,921.73835
Policy Entropy: 1.65683
Value Function Loss: 0.05855

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.31610
Value Function Update Magnitude: 0.33602

Collected Steps per Second: 21,083.20474
Overall Steps per Second: 10,137.90448

Timestep Collection Time: 2.37298
Timestep Consumption Time: 2.56197
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.93494

Cumulative Model Updates: 125,668
Cumulative Timesteps: 1,048,883,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,441.27989
Policy Entropy: 1.65435
Value Function Loss: 0.05889

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.31045
Value Function Update Magnitude: 0.33022

Collected Steps per Second: 21,444.58407
Overall Steps per Second: 10,398.82267

Timestep Collection Time: 2.33374
Timestep Consumption Time: 2.47892
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.81266

Cumulative Model Updates: 125,674
Cumulative Timesteps: 1,048,933,744

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1048933744...
Checkpoint 1048933744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,891.63219
Policy Entropy: 1.67952
Value Function Loss: 0.05892

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.30907
Value Function Update Magnitude: 0.33805

Collected Steps per Second: 20,834.62564
Overall Steps per Second: 10,208.28623

Timestep Collection Time: 2.40043
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.89916

Cumulative Model Updates: 125,680
Cumulative Timesteps: 1,048,983,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,840.86873
Policy Entropy: 1.68907
Value Function Loss: 0.06491

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.31091
Value Function Update Magnitude: 0.36374

Collected Steps per Second: 21,065.34085
Overall Steps per Second: 10,133.46072

Timestep Collection Time: 2.37357
Timestep Consumption Time: 2.56058
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.93415

Cumulative Model Updates: 125,686
Cumulative Timesteps: 1,049,033,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1049033756...
Checkpoint 1049033756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,761.96015
Policy Entropy: 1.69024
Value Function Loss: 0.06183

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.30594
Value Function Update Magnitude: 0.34702

Collected Steps per Second: 20,948.97535
Overall Steps per Second: 10,157.00667

Timestep Collection Time: 2.38828
Timestep Consumption Time: 2.53758
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.92586

Cumulative Model Updates: 125,692
Cumulative Timesteps: 1,049,083,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,846.05743
Policy Entropy: 1.67859
Value Function Loss: 0.06111

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.30908
Value Function Update Magnitude: 0.32915

Collected Steps per Second: 21,329.73562
Overall Steps per Second: 10,270.19872

Timestep Collection Time: 2.34668
Timestep Consumption Time: 2.52704
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.87371

Cumulative Model Updates: 125,698
Cumulative Timesteps: 1,049,133,842

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1049133842...
Checkpoint 1049133842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,626.65774
Policy Entropy: 1.67282
Value Function Loss: 0.06023

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.31391
Value Function Update Magnitude: 0.33006

Collected Steps per Second: 20,893.70795
Overall Steps per Second: 10,161.83743

Timestep Collection Time: 2.39373
Timestep Consumption Time: 2.52801
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.92175

Cumulative Model Updates: 125,704
Cumulative Timesteps: 1,049,183,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,125.20640
Policy Entropy: 1.66934
Value Function Loss: 0.06789

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.32107
Value Function Update Magnitude: 0.33694

Collected Steps per Second: 21,297.60179
Overall Steps per Second: 10,289.02240

Timestep Collection Time: 2.34806
Timestep Consumption Time: 2.51227
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.86033

Cumulative Model Updates: 125,710
Cumulative Timesteps: 1,049,233,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1049233864...
Checkpoint 1049233864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,656.98142
Policy Entropy: 1.67375
Value Function Loss: 0.06931

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.32463
Value Function Update Magnitude: 0.35861

Collected Steps per Second: 20,770.37338
Overall Steps per Second: 10,212.63145

Timestep Collection Time: 2.40805
Timestep Consumption Time: 2.48942
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.89746

Cumulative Model Updates: 125,716
Cumulative Timesteps: 1,049,283,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,096.09662
Policy Entropy: 1.67379
Value Function Loss: 0.06830

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.32317
Value Function Update Magnitude: 0.37596

Collected Steps per Second: 20,984.65211
Overall Steps per Second: 10,157.40979

Timestep Collection Time: 2.38298
Timestep Consumption Time: 2.54013
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.92311

Cumulative Model Updates: 125,722
Cumulative Timesteps: 1,049,333,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1049333886...
Checkpoint 1049333886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,593.45507
Policy Entropy: 1.67068
Value Function Loss: 0.06355

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.31957
Value Function Update Magnitude: 0.36275

Collected Steps per Second: 20,759.52991
Overall Steps per Second: 10,085.12527

Timestep Collection Time: 2.40998
Timestep Consumption Time: 2.55079
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.96077

Cumulative Model Updates: 125,728
Cumulative Timesteps: 1,049,383,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,159.38945
Policy Entropy: 1.65890
Value Function Loss: 0.05975

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.31148
Value Function Update Magnitude: 0.34555

Collected Steps per Second: 21,100.30989
Overall Steps per Second: 10,201.18901

Timestep Collection Time: 2.36992
Timestep Consumption Time: 2.53206
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.90198

Cumulative Model Updates: 125,734
Cumulative Timesteps: 1,049,433,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1049433922...
Checkpoint 1049433922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,093.64375
Policy Entropy: 1.66763
Value Function Loss: 0.06018

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.30823
Value Function Update Magnitude: 0.33770

Collected Steps per Second: 20,903.86063
Overall Steps per Second: 10,126.63928

Timestep Collection Time: 2.39257
Timestep Consumption Time: 2.54628
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.93885

Cumulative Model Updates: 125,740
Cumulative Timesteps: 1,049,483,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,267.70287
Policy Entropy: 1.67318
Value Function Loss: 0.05973

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.30407
Value Function Update Magnitude: 0.34369

Collected Steps per Second: 21,328.91282
Overall Steps per Second: 10,361.84555

Timestep Collection Time: 2.34470
Timestep Consumption Time: 2.48166
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.82636

Cumulative Model Updates: 125,746
Cumulative Timesteps: 1,049,533,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1049533946...
Checkpoint 1049533946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,143.23066
Policy Entropy: 1.67513
Value Function Loss: 0.06642

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.28935
Value Function Update Magnitude: 0.32936

Collected Steps per Second: 20,731.68022
Overall Steps per Second: 10,251.18688

Timestep Collection Time: 2.41196
Timestep Consumption Time: 2.46591
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.87787

Cumulative Model Updates: 125,752
Cumulative Timesteps: 1,049,583,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,810.41695
Policy Entropy: 1.68760
Value Function Loss: 0.06595

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.28307
Value Function Update Magnitude: 0.33379

Collected Steps per Second: 21,220.63730
Overall Steps per Second: 10,350.87817

Timestep Collection Time: 2.35657
Timestep Consumption Time: 2.47471
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.83128

Cumulative Model Updates: 125,758
Cumulative Timesteps: 1,049,633,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1049633958...
Checkpoint 1049633958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,120.92681
Policy Entropy: 1.69279
Value Function Loss: 0.06200

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.29229
Value Function Update Magnitude: 0.35853

Collected Steps per Second: 20,332.21317
Overall Steps per Second: 10,008.71189

Timestep Collection Time: 2.45935
Timestep Consumption Time: 2.53670
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.99605

Cumulative Model Updates: 125,764
Cumulative Timesteps: 1,049,683,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,322.33714
Policy Entropy: 1.69592
Value Function Loss: 0.05718

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.29808
Value Function Update Magnitude: 0.33852

Collected Steps per Second: 21,401.67954
Overall Steps per Second: 10,305.25598

Timestep Collection Time: 2.33767
Timestep Consumption Time: 2.51714
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.85480

Cumulative Model Updates: 125,770
Cumulative Timesteps: 1,049,733,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1049733992...
Checkpoint 1049733992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,857.20650
Policy Entropy: 1.67836
Value Function Loss: 0.05885

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.30254
Value Function Update Magnitude: 0.31433

Collected Steps per Second: 20,276.54456
Overall Steps per Second: 10,199.06471

Timestep Collection Time: 2.46620
Timestep Consumption Time: 2.43680
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.90300

Cumulative Model Updates: 125,776
Cumulative Timesteps: 1,049,783,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,066.15801
Policy Entropy: 1.67606
Value Function Loss: 0.05865

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08046
Policy Update Magnitude: 0.30567
Value Function Update Magnitude: 0.30537

Collected Steps per Second: 20,814.81841
Overall Steps per Second: 10,406.84207

Timestep Collection Time: 2.40290
Timestep Consumption Time: 2.40317
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.80607

Cumulative Model Updates: 125,782
Cumulative Timesteps: 1,049,834,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1049834014...
Checkpoint 1049834014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,969.10860
Policy Entropy: 1.68926
Value Function Loss: 0.06149

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.30831
Value Function Update Magnitude: 0.29483

Collected Steps per Second: 19,952.43596
Overall Steps per Second: 10,178.80776

Timestep Collection Time: 2.50706
Timestep Consumption Time: 2.40727
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.91433

Cumulative Model Updates: 125,788
Cumulative Timesteps: 1,049,884,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,853.68932
Policy Entropy: 1.69121
Value Function Loss: 0.06140

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.30192
Value Function Update Magnitude: 0.31869

Collected Steps per Second: 20,536.72291
Overall Steps per Second: 10,204.51930

Timestep Collection Time: 2.43632
Timestep Consumption Time: 2.46680
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.90312

Cumulative Model Updates: 125,794
Cumulative Timesteps: 1,049,934,070

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1049934070...
Checkpoint 1049934070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,839.96681
Policy Entropy: 1.70241
Value Function Loss: 0.06005

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.27096
Value Function Update Magnitude: 0.34800

Collected Steps per Second: 20,336.98598
Overall Steps per Second: 10,179.96537

Timestep Collection Time: 2.46123
Timestep Consumption Time: 2.45568
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.91691

Cumulative Model Updates: 125,800
Cumulative Timesteps: 1,049,984,124

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,318.69589
Policy Entropy: 1.70316
Value Function Loss: 0.05941

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.27867
Value Function Update Magnitude: 0.34466

Collected Steps per Second: 20,887.27323
Overall Steps per Second: 10,315.59817

Timestep Collection Time: 2.39514
Timestep Consumption Time: 2.45460
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.84974

Cumulative Model Updates: 125,806
Cumulative Timesteps: 1,050,034,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1050034152...
Checkpoint 1050034152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,133.95757
Policy Entropy: 1.69990
Value Function Loss: 0.06277

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.26995
Value Function Update Magnitude: 0.35434

Collected Steps per Second: 20,942.71624
Overall Steps per Second: 10,329.16114

Timestep Collection Time: 2.38766
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.84105

Cumulative Model Updates: 125,812
Cumulative Timesteps: 1,050,084,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,141.28450
Policy Entropy: 1.69535
Value Function Loss: 0.06024

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.28971
Value Function Update Magnitude: 0.35070

Collected Steps per Second: 21,295.95580
Overall Steps per Second: 10,383.69889

Timestep Collection Time: 2.34899
Timestep Consumption Time: 2.46856
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.81755

Cumulative Model Updates: 125,818
Cumulative Timesteps: 1,050,134,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1050134180...
Checkpoint 1050134180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,242.97462
Policy Entropy: 1.68808
Value Function Loss: 0.05852

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.30088
Value Function Update Magnitude: 0.33366

Collected Steps per Second: 21,110.64903
Overall Steps per Second: 10,207.43293

Timestep Collection Time: 2.36970
Timestep Consumption Time: 2.53123
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.90094

Cumulative Model Updates: 125,824
Cumulative Timesteps: 1,050,184,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,876.25916
Policy Entropy: 1.67537
Value Function Loss: 0.05134

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.29226
Value Function Update Magnitude: 0.31079

Collected Steps per Second: 21,227.82500
Overall Steps per Second: 10,201.75765

Timestep Collection Time: 2.35596
Timestep Consumption Time: 2.54633
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.90229

Cumulative Model Updates: 125,830
Cumulative Timesteps: 1,050,234,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1050234218...
Checkpoint 1050234218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,181.83144
Policy Entropy: 1.66190
Value Function Loss: 0.05541

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.29107
Value Function Update Magnitude: 0.26415

Collected Steps per Second: 20,857.23912
Overall Steps per Second: 10,109.13876

Timestep Collection Time: 2.39830
Timestep Consumption Time: 2.54989
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.94820

Cumulative Model Updates: 125,836
Cumulative Timesteps: 1,050,284,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,538.12726
Policy Entropy: 1.65632
Value Function Loss: 0.06026

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.30070
Value Function Update Magnitude: 0.28262

Collected Steps per Second: 21,374.81442
Overall Steps per Second: 10,364.71330

Timestep Collection Time: 2.33948
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.82464

Cumulative Model Updates: 125,842
Cumulative Timesteps: 1,050,334,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1050334246...
Checkpoint 1050334246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,392.90402
Policy Entropy: 1.67791
Value Function Loss: 0.06450

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.30579
Value Function Update Magnitude: 0.32014

Collected Steps per Second: 21,141.57038
Overall Steps per Second: 10,252.62551

Timestep Collection Time: 2.36501
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.87680

Cumulative Model Updates: 125,848
Cumulative Timesteps: 1,050,384,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,007.28359
Policy Entropy: 1.68369
Value Function Loss: 0.06325

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.31344
Value Function Update Magnitude: 0.31926

Collected Steps per Second: 21,305.77337
Overall Steps per Second: 10,361.75264

Timestep Collection Time: 2.34791
Timestep Consumption Time: 2.47985
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.82775

Cumulative Model Updates: 125,854
Cumulative Timesteps: 1,050,434,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1050434270...
Checkpoint 1050434270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,068.90522
Policy Entropy: 1.69858
Value Function Loss: 0.06333

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.31233
Value Function Update Magnitude: 0.31519

Collected Steps per Second: 21,099.71570
Overall Steps per Second: 10,339.43985

Timestep Collection Time: 2.37188
Timestep Consumption Time: 2.46842
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.84030

Cumulative Model Updates: 125,860
Cumulative Timesteps: 1,050,484,316

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,481.06959
Policy Entropy: 1.66737
Value Function Loss: 0.06498

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.31471
Value Function Update Magnitude: 0.31946

Collected Steps per Second: 21,084.79851
Overall Steps per Second: 10,181.45018

Timestep Collection Time: 2.37223
Timestep Consumption Time: 2.54043
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.91266

Cumulative Model Updates: 125,866
Cumulative Timesteps: 1,050,534,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1050534334...
Checkpoint 1050534334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,329.75834
Policy Entropy: 1.67962
Value Function Loss: 0.06172

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07652
Policy Update Magnitude: 0.31510
Value Function Update Magnitude: 0.32691

Collected Steps per Second: 20,867.01356
Overall Steps per Second: 10,132.11138

Timestep Collection Time: 2.39613
Timestep Consumption Time: 2.53868
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.93481

Cumulative Model Updates: 125,872
Cumulative Timesteps: 1,050,584,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,617.96032
Policy Entropy: 1.66577
Value Function Loss: 0.05649

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.30670
Value Function Update Magnitude: 0.30911

Collected Steps per Second: 21,149.43707
Overall Steps per Second: 10,291.00859

Timestep Collection Time: 2.36526
Timestep Consumption Time: 2.49568
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.86094

Cumulative Model Updates: 125,878
Cumulative Timesteps: 1,050,634,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1050634358...
Checkpoint 1050634358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,643.32869
Policy Entropy: 1.68747
Value Function Loss: 0.05780

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.30378
Value Function Update Magnitude: 0.27180

Collected Steps per Second: 20,921.71187
Overall Steps per Second: 10,249.43980

Timestep Collection Time: 2.38986
Timestep Consumption Time: 2.48845
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.87832

Cumulative Model Updates: 125,884
Cumulative Timesteps: 1,050,684,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,236.77051
Policy Entropy: 1.68489
Value Function Loss: 0.05920

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.30376
Value Function Update Magnitude: 0.25322

Collected Steps per Second: 21,283.76629
Overall Steps per Second: 10,370.33868

Timestep Collection Time: 2.35034
Timestep Consumption Time: 2.47342
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.82376

Cumulative Model Updates: 125,890
Cumulative Timesteps: 1,050,734,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1050734382...
Checkpoint 1050734382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,893.19121
Policy Entropy: 1.69978
Value Function Loss: 0.06045

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.30457
Value Function Update Magnitude: 0.28694

Collected Steps per Second: 21,009.03093
Overall Steps per Second: 10,310.45407

Timestep Collection Time: 2.38012
Timestep Consumption Time: 2.46972
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.84983

Cumulative Model Updates: 125,896
Cumulative Timesteps: 1,050,784,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,709.71726
Policy Entropy: 1.68374
Value Function Loss: 0.05867

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07886
Policy Update Magnitude: 0.30596
Value Function Update Magnitude: 0.31865

Collected Steps per Second: 21,375.00750
Overall Steps per Second: 10,357.05751

Timestep Collection Time: 2.33937
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.82801

Cumulative Model Updates: 125,902
Cumulative Timesteps: 1,050,834,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1050834390...
Checkpoint 1050834390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,251.33679
Policy Entropy: 1.67480
Value Function Loss: 0.06251

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07751
Policy Update Magnitude: 0.31116
Value Function Update Magnitude: 0.32432

Collected Steps per Second: 21,016.30276
Overall Steps per Second: 10,322.25433

Timestep Collection Time: 2.38025
Timestep Consumption Time: 2.46598
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.84623

Cumulative Model Updates: 125,908
Cumulative Timesteps: 1,050,884,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,319.66746
Policy Entropy: 1.67611
Value Function Loss: 0.06846

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.31821
Value Function Update Magnitude: 0.33545

Collected Steps per Second: 21,327.07061
Overall Steps per Second: 10,370.15656

Timestep Collection Time: 2.34463
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.82191

Cumulative Model Updates: 125,914
Cumulative Timesteps: 1,050,934,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1050934418...
Checkpoint 1050934418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,891.44209
Policy Entropy: 1.67558
Value Function Loss: 0.06876

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.32050
Value Function Update Magnitude: 0.35373

Collected Steps per Second: 20,158.17293
Overall Steps per Second: 10,229.37612

Timestep Collection Time: 2.48217
Timestep Consumption Time: 2.40923
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.89140

Cumulative Model Updates: 125,920
Cumulative Timesteps: 1,050,984,454

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,350.62295
Policy Entropy: 1.67967
Value Function Loss: 0.06487

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.32000
Value Function Update Magnitude: 0.35307

Collected Steps per Second: 20,537.46809
Overall Steps per Second: 10,218.17042

Timestep Collection Time: 2.43623
Timestep Consumption Time: 2.46034
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.89657

Cumulative Model Updates: 125,926
Cumulative Timesteps: 1,051,034,488

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1051034488...
Checkpoint 1051034488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,097.18118
Policy Entropy: 1.65580
Value Function Loss: 0.06237

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08060
Policy Update Magnitude: 0.31773
Value Function Update Magnitude: 0.34411

Collected Steps per Second: 20,126.38154
Overall Steps per Second: 10,087.57773

Timestep Collection Time: 2.48539
Timestep Consumption Time: 2.47338
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.95877

Cumulative Model Updates: 125,932
Cumulative Timesteps: 1,051,084,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,886.92165
Policy Entropy: 1.65900
Value Function Loss: 0.06249

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.31412
Value Function Update Magnitude: 0.33781

Collected Steps per Second: 20,642.81977
Overall Steps per Second: 10,358.59697

Timestep Collection Time: 2.42225
Timestep Consumption Time: 2.40485
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.82710

Cumulative Model Updates: 125,938
Cumulative Timesteps: 1,051,134,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1051134512...
Checkpoint 1051134512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,850.09594
Policy Entropy: 1.66743
Value Function Loss: 0.06672

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.31558
Value Function Update Magnitude: 0.34715

Collected Steps per Second: 20,222.16904
Overall Steps per Second: 10,246.09110

Timestep Collection Time: 2.47431
Timestep Consumption Time: 2.40911
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.88342

Cumulative Model Updates: 125,944
Cumulative Timesteps: 1,051,184,548

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,999.00692
Policy Entropy: 1.67001
Value Function Loss: 0.06054

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.31262
Value Function Update Magnitude: 0.35172

Collected Steps per Second: 20,582.05129
Overall Steps per Second: 10,048.51883

Timestep Collection Time: 2.43037
Timestep Consumption Time: 2.54768
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.97805

Cumulative Model Updates: 125,950
Cumulative Timesteps: 1,051,234,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1051234570...
Checkpoint 1051234570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,434.57013
Policy Entropy: 1.66231
Value Function Loss: 0.06228

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.31111
Value Function Update Magnitude: 0.32926

Collected Steps per Second: 20,702.29477
Overall Steps per Second: 10,247.68370

Timestep Collection Time: 2.41654
Timestep Consumption Time: 2.46534
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.88188

Cumulative Model Updates: 125,956
Cumulative Timesteps: 1,051,284,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,858.11752
Policy Entropy: 1.66994
Value Function Loss: 0.05995

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.31273
Value Function Update Magnitude: 0.31202

Collected Steps per Second: 21,199.83363
Overall Steps per Second: 10,346.76513

Timestep Collection Time: 2.35974
Timestep Consumption Time: 2.47521
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.83494

Cumulative Model Updates: 125,962
Cumulative Timesteps: 1,051,334,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1051334624...
Checkpoint 1051334624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,670.55857
Policy Entropy: 1.67795
Value Function Loss: 0.05960

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.30048
Value Function Update Magnitude: 0.30776

Collected Steps per Second: 20,634.74546
Overall Steps per Second: 10,235.64591

Timestep Collection Time: 2.42475
Timestep Consumption Time: 2.46347
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.88821

Cumulative Model Updates: 125,968
Cumulative Timesteps: 1,051,384,658

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,528.07259
Policy Entropy: 1.67679
Value Function Loss: 0.05911

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.27860
Value Function Update Magnitude: 0.30355

Collected Steps per Second: 21,287.37229
Overall Steps per Second: 10,217.34399

Timestep Collection Time: 2.34947
Timestep Consumption Time: 2.54554
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.89501

Cumulative Model Updates: 125,974
Cumulative Timesteps: 1,051,434,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1051434672...
Checkpoint 1051434672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,293.90773
Policy Entropy: 1.66087
Value Function Loss: 0.06052

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.27722
Value Function Update Magnitude: 0.31507

Collected Steps per Second: 20,902.62132
Overall Steps per Second: 10,077.49944

Timestep Collection Time: 2.39300
Timestep Consumption Time: 2.57053
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 4.96353

Cumulative Model Updates: 125,980
Cumulative Timesteps: 1,051,484,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,647.75786
Policy Entropy: 1.67303
Value Function Loss: 0.06437

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.30458
Value Function Update Magnitude: 0.32396

Collected Steps per Second: 21,059.54898
Overall Steps per Second: 10,194.63971

Timestep Collection Time: 2.37479
Timestep Consumption Time: 2.53093
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.90572

Cumulative Model Updates: 125,986
Cumulative Timesteps: 1,051,534,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1051534704...
Checkpoint 1051534704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,803.64372
Policy Entropy: 1.67410
Value Function Loss: 0.06313

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.31078
Value Function Update Magnitude: 0.33947

Collected Steps per Second: 20,928.80003
Overall Steps per Second: 10,114.89515

Timestep Collection Time: 2.38982
Timestep Consumption Time: 2.55497
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 4.94479

Cumulative Model Updates: 125,992
Cumulative Timesteps: 1,051,584,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,447.13408
Policy Entropy: 1.68448
Value Function Loss: 0.06419

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.29557
Value Function Update Magnitude: 0.34385

Collected Steps per Second: 20,963.21720
Overall Steps per Second: 10,284.70361

Timestep Collection Time: 2.38542
Timestep Consumption Time: 2.47676
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.86217

Cumulative Model Updates: 125,998
Cumulative Timesteps: 1,051,634,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1051634726...
Checkpoint 1051634726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,097.47149
Policy Entropy: 1.68252
Value Function Loss: 0.06241

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.30147
Value Function Update Magnitude: 0.33630

Collected Steps per Second: 20,899.99381
Overall Steps per Second: 10,228.48750

Timestep Collection Time: 2.39244
Timestep Consumption Time: 2.49606
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.88850

Cumulative Model Updates: 126,004
Cumulative Timesteps: 1,051,684,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,469.08383
Policy Entropy: 1.68698
Value Function Loss: 0.06110

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.31281
Value Function Update Magnitude: 0.33266

Collected Steps per Second: 21,069.37771
Overall Steps per Second: 10,150.38168

Timestep Collection Time: 2.37378
Timestep Consumption Time: 2.55353
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.92730

Cumulative Model Updates: 126,010
Cumulative Timesteps: 1,051,734,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1051734742...
Checkpoint 1051734742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,872.41468
Policy Entropy: 1.69182
Value Function Loss: 0.06206

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.31558
Value Function Update Magnitude: 0.34106

Collected Steps per Second: 20,920.41544
Overall Steps per Second: 10,152.67651

Timestep Collection Time: 2.39030
Timestep Consumption Time: 2.53510
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.92540

Cumulative Model Updates: 126,016
Cumulative Timesteps: 1,051,784,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,514.37205
Policy Entropy: 1.67457
Value Function Loss: 0.06470

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.32126
Value Function Update Magnitude: 0.35573

Collected Steps per Second: 21,146.97115
Overall Steps per Second: 10,173.21957

Timestep Collection Time: 2.36478
Timestep Consumption Time: 2.55087
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.91565

Cumulative Model Updates: 126,022
Cumulative Timesteps: 1,051,834,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1051834756...
Checkpoint 1051834756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,844.68884
Policy Entropy: 1.68457
Value Function Loss: 0.06702

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.32535
Value Function Update Magnitude: 0.36198

Collected Steps per Second: 21,054.35308
Overall Steps per Second: 10,144.22469

Timestep Collection Time: 2.37614
Timestep Consumption Time: 2.55554
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.93167

Cumulative Model Updates: 126,028
Cumulative Timesteps: 1,051,884,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,140.16414
Policy Entropy: 1.68539
Value Function Loss: 0.06820

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.32537
Value Function Update Magnitude: 0.37079

Collected Steps per Second: 21,508.84690
Overall Steps per Second: 10,375.49265

Timestep Collection Time: 2.32555
Timestep Consumption Time: 2.49542
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.82098

Cumulative Model Updates: 126,034
Cumulative Timesteps: 1,051,934,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1051934804...
Checkpoint 1051934804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,029.83043
Policy Entropy: 1.68794
Value Function Loss: 0.06769

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.32348
Value Function Update Magnitude: 0.36225

Collected Steps per Second: 20,764.50741
Overall Steps per Second: 10,219.90870

Timestep Collection Time: 2.40834
Timestep Consumption Time: 2.48485
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.89319

Cumulative Model Updates: 126,040
Cumulative Timesteps: 1,051,984,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,349.25286
Policy Entropy: 1.67472
Value Function Loss: 0.06593

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.32053
Value Function Update Magnitude: 0.34242

Collected Steps per Second: 21,291.77295
Overall Steps per Second: 10,384.76899

Timestep Collection Time: 2.35011
Timestep Consumption Time: 2.46829
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.81840

Cumulative Model Updates: 126,046
Cumulative Timesteps: 1,052,034,850

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1052034850...
Checkpoint 1052034850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,183.05457
Policy Entropy: 1.67748
Value Function Loss: 0.06331

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.31816
Value Function Update Magnitude: 0.33651

Collected Steps per Second: 21,042.56087
Overall Steps per Second: 10,256.12333

Timestep Collection Time: 2.37813
Timestep Consumption Time: 2.50110
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.87923

Cumulative Model Updates: 126,052
Cumulative Timesteps: 1,052,084,892

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,733.81269
Policy Entropy: 1.67631
Value Function Loss: 0.06134

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.31625
Value Function Update Magnitude: 0.31396

Collected Steps per Second: 21,176.62529
Overall Steps per Second: 10,181.58662

Timestep Collection Time: 2.36204
Timestep Consumption Time: 2.55075
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.91279

Cumulative Model Updates: 126,058
Cumulative Timesteps: 1,052,134,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1052134912...
Checkpoint 1052134912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,655.76956
Policy Entropy: 1.67565
Value Function Loss: 0.06269

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.31514
Value Function Update Magnitude: 0.30460

Collected Steps per Second: 20,955.61089
Overall Steps per Second: 10,145.99507

Timestep Collection Time: 2.38619
Timestep Consumption Time: 2.54226
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.92845

Cumulative Model Updates: 126,064
Cumulative Timesteps: 1,052,184,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,265.44080
Policy Entropy: 1.67504
Value Function Loss: 0.06144

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.31316
Value Function Update Magnitude: 0.31843

Collected Steps per Second: 21,339.56806
Overall Steps per Second: 10,345.35949

Timestep Collection Time: 2.34335
Timestep Consumption Time: 2.49032
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.83366

Cumulative Model Updates: 126,070
Cumulative Timesteps: 1,052,234,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1052234922...
Checkpoint 1052234922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,707.70426
Policy Entropy: 1.67050
Value Function Loss: 0.06113

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07861
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.31468

Collected Steps per Second: 21,093.68016
Overall Steps per Second: 10,331.20854

Timestep Collection Time: 2.37152
Timestep Consumption Time: 2.47051
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.84203

Cumulative Model Updates: 126,076
Cumulative Timesteps: 1,052,284,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,620.60703
Policy Entropy: 1.67579
Value Function Loss: 0.05960

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08018
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.31978

Collected Steps per Second: 21,343.77102
Overall Steps per Second: 10,371.29196

Timestep Collection Time: 2.34392
Timestep Consumption Time: 2.47978
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.82370

Cumulative Model Updates: 126,082
Cumulative Timesteps: 1,052,334,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1052334974...
Checkpoint 1052334974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,528.30248
Policy Entropy: 1.68448
Value Function Loss: 0.06232

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.30983
Value Function Update Magnitude: 0.32552

Collected Steps per Second: 20,847.87617
Overall Steps per Second: 10,255.86017

Timestep Collection Time: 2.39852
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.87565

Cumulative Model Updates: 126,088
Cumulative Timesteps: 1,052,384,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,807.40019
Policy Entropy: 1.67174
Value Function Loss: 0.06182

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.30864
Value Function Update Magnitude: 0.33614

Collected Steps per Second: 21,229.25473
Overall Steps per Second: 10,331.07112

Timestep Collection Time: 2.35647
Timestep Consumption Time: 2.48582
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.84229

Cumulative Model Updates: 126,094
Cumulative Timesteps: 1,052,435,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1052435004...
Checkpoint 1052435004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,571.95478
Policy Entropy: 1.67677
Value Function Loss: 0.06000

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.28893
Value Function Update Magnitude: 0.33609

Collected Steps per Second: 20,994.91972
Overall Steps per Second: 10,287.00776

Timestep Collection Time: 2.38353
Timestep Consumption Time: 2.48105
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.86458

Cumulative Model Updates: 126,100
Cumulative Timesteps: 1,052,485,046

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,845.16944
Policy Entropy: 1.67421
Value Function Loss: 0.06078

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.29179
Value Function Update Magnitude: 0.33347

Collected Steps per Second: 21,344.02925
Overall Steps per Second: 10,401.69040

Timestep Collection Time: 2.34258
Timestep Consumption Time: 2.46434
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.80691

Cumulative Model Updates: 126,106
Cumulative Timesteps: 1,052,535,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1052535046...
Checkpoint 1052535046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,367.59573
Policy Entropy: 1.69028
Value Function Loss: 0.06100

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.30695
Value Function Update Magnitude: 0.32905

Collected Steps per Second: 20,928.79647
Overall Steps per Second: 10,281.77736

Timestep Collection Time: 2.39135
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.86764

Cumulative Model Updates: 126,112
Cumulative Timesteps: 1,052,585,094

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,862.31852
Policy Entropy: 1.68539
Value Function Loss: 0.05779

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.30440
Value Function Update Magnitude: 0.32141

Collected Steps per Second: 21,244.31278
Overall Steps per Second: 10,349.86522

Timestep Collection Time: 2.35385
Timestep Consumption Time: 2.47771
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.83156

Cumulative Model Updates: 126,118
Cumulative Timesteps: 1,052,635,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1052635100...
Checkpoint 1052635100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,781.71217
Policy Entropy: 1.68524
Value Function Loss: 0.05747

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.29822
Value Function Update Magnitude: 0.33248

Collected Steps per Second: 20,455.29310
Overall Steps per Second: 10,287.98456

Timestep Collection Time: 2.44436
Timestep Consumption Time: 2.41568
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.86004

Cumulative Model Updates: 126,124
Cumulative Timesteps: 1,052,685,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,696.28979
Policy Entropy: 1.66848
Value Function Loss: 0.05572

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.30063
Value Function Update Magnitude: 0.33262

Collected Steps per Second: 20,489.75805
Overall Steps per Second: 10,175.09626

Timestep Collection Time: 2.44171
Timestep Consumption Time: 2.47520
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.91691

Cumulative Model Updates: 126,130
Cumulative Timesteps: 1,052,735,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1052735130...
Checkpoint 1052735130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,767.13443
Policy Entropy: 1.67439
Value Function Loss: 0.05949

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.30701
Value Function Update Magnitude: 0.32854

Collected Steps per Second: 20,612.37387
Overall Steps per Second: 10,191.86605

Timestep Collection Time: 2.42641
Timestep Consumption Time: 2.48084
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.90725

Cumulative Model Updates: 126,136
Cumulative Timesteps: 1,052,785,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,851.89610
Policy Entropy: 1.65540
Value Function Loss: 0.06112

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.31201
Value Function Update Magnitude: 0.30381

Collected Steps per Second: 20,555.66285
Overall Steps per Second: 10,346.87044

Timestep Collection Time: 2.43349
Timestep Consumption Time: 2.40102
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.83451

Cumulative Model Updates: 126,142
Cumulative Timesteps: 1,052,835,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1052835166...
Checkpoint 1052835166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,149.23431
Policy Entropy: 1.66336
Value Function Loss: 0.06575

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.31635
Value Function Update Magnitude: 0.31108

Collected Steps per Second: 20,484.70112
Overall Steps per Second: 10,174.00456

Timestep Collection Time: 2.44182
Timestep Consumption Time: 2.47463
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.91645

Cumulative Model Updates: 126,148
Cumulative Timesteps: 1,052,885,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,126.66447
Policy Entropy: 1.66963
Value Function Loss: 0.06518

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.31700
Value Function Update Magnitude: 0.34538

Collected Steps per Second: 20,762.49949
Overall Steps per Second: 10,129.85953

Timestep Collection Time: 2.40925
Timestep Consumption Time: 2.52883
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.93807

Cumulative Model Updates: 126,154
Cumulative Timesteps: 1,052,935,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1052935208...
Checkpoint 1052935208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,544.79912
Policy Entropy: 1.71541
Value Function Loss: 0.06602

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.31537
Value Function Update Magnitude: 0.33943

Collected Steps per Second: 20,976.56199
Overall Steps per Second: 10,153.23670

Timestep Collection Time: 2.38571
Timestep Consumption Time: 2.54316
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.92887

Cumulative Model Updates: 126,160
Cumulative Timesteps: 1,052,985,252

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,515.10968
Policy Entropy: 1.72298
Value Function Loss: 0.06913

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.31962
Value Function Update Magnitude: 0.34132

Collected Steps per Second: 21,192.83061
Overall Steps per Second: 10,389.37781

Timestep Collection Time: 2.36070
Timestep Consumption Time: 2.45479
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.81550

Cumulative Model Updates: 126,166
Cumulative Timesteps: 1,053,035,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1053035282...
Checkpoint 1053035282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,899.78839
Policy Entropy: 1.71661
Value Function Loss: 0.07059

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.31461
Value Function Update Magnitude: 0.34598

Collected Steps per Second: 20,882.06459
Overall Steps per Second: 10,342.92214

Timestep Collection Time: 2.39584
Timestep Consumption Time: 2.44129
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.83712

Cumulative Model Updates: 126,172
Cumulative Timesteps: 1,053,085,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,352.25007
Policy Entropy: 1.69899
Value Function Loss: 0.06637

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.31709
Value Function Update Magnitude: 0.36091

Collected Steps per Second: 21,035.42494
Overall Steps per Second: 10,288.00449

Timestep Collection Time: 2.37827
Timestep Consumption Time: 2.48448
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.86275

Cumulative Model Updates: 126,178
Cumulative Timesteps: 1,053,135,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1053135340...
Checkpoint 1053135340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,364.94813
Policy Entropy: 1.68058
Value Function Loss: 0.06185

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.31567
Value Function Update Magnitude: 0.36777

Collected Steps per Second: 21,207.45479
Overall Steps per Second: 10,352.59263

Timestep Collection Time: 2.35889
Timestep Consumption Time: 2.47333
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.83222

Cumulative Model Updates: 126,184
Cumulative Timesteps: 1,053,185,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,850.65036
Policy Entropy: 1.70599
Value Function Loss: 0.06236

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.35754

Collected Steps per Second: 21,076.35916
Overall Steps per Second: 10,328.71621

Timestep Collection Time: 2.37432
Timestep Consumption Time: 2.47062
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.84494

Cumulative Model Updates: 126,190
Cumulative Timesteps: 1,053,235,408

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1053235408...
Checkpoint 1053235408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,636.71565
Policy Entropy: 1.69973
Value Function Loss: 0.06599

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.31619
Value Function Update Magnitude: 0.34053

Collected Steps per Second: 21,182.36112
Overall Steps per Second: 10,365.61183

Timestep Collection Time: 2.36140
Timestep Consumption Time: 2.46417
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.82557

Cumulative Model Updates: 126,196
Cumulative Timesteps: 1,053,285,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,202.27737
Policy Entropy: 1.72032
Value Function Loss: 0.06349

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.29738
Value Function Update Magnitude: 0.32027

Collected Steps per Second: 20,909.31444
Overall Steps per Second: 10,134.88095

Timestep Collection Time: 2.39262
Timestep Consumption Time: 2.54360
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.93622

Cumulative Model Updates: 126,202
Cumulative Timesteps: 1,053,335,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1053335456...
Checkpoint 1053335456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,835.57861
Policy Entropy: 1.70418
Value Function Loss: 0.06167

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.29680
Value Function Update Magnitude: 0.32817

Collected Steps per Second: 21,229.52583
Overall Steps per Second: 10,379.95417

Timestep Collection Time: 2.35634
Timestep Consumption Time: 2.46295
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.81929

Cumulative Model Updates: 126,208
Cumulative Timesteps: 1,053,385,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,021.93528
Policy Entropy: 1.71248
Value Function Loss: 0.06368

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.31348
Value Function Update Magnitude: 0.33756

Collected Steps per Second: 21,018.83494
Overall Steps per Second: 10,138.07529

Timestep Collection Time: 2.38006
Timestep Consumption Time: 2.55441
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.93447

Cumulative Model Updates: 126,214
Cumulative Timesteps: 1,053,435,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1053435506...
Checkpoint 1053435506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,934.06721
Policy Entropy: 1.72117
Value Function Loss: 0.06619

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.32290
Value Function Update Magnitude: 0.34655

Collected Steps per Second: 20,945.39676
Overall Steps per Second: 10,202.48124

Timestep Collection Time: 2.38831
Timestep Consumption Time: 2.51482
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.90312

Cumulative Model Updates: 126,220
Cumulative Timesteps: 1,053,485,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,574.90363
Policy Entropy: 1.71647
Value Function Loss: 0.06561

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.31309
Value Function Update Magnitude: 0.33875

Collected Steps per Second: 20,779.16338
Overall Steps per Second: 10,022.85225

Timestep Collection Time: 2.40751
Timestep Consumption Time: 2.58369
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.99119

Cumulative Model Updates: 126,226
Cumulative Timesteps: 1,053,535,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1053535556...
Checkpoint 1053535556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,428.49194
Policy Entropy: 1.71519
Value Function Loss: 0.06658

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.30662
Value Function Update Magnitude: 0.32810

Collected Steps per Second: 21,194.71437
Overall Steps per Second: 10,243.92850

Timestep Collection Time: 2.35917
Timestep Consumption Time: 2.52196
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.88114

Cumulative Model Updates: 126,232
Cumulative Timesteps: 1,053,585,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,996.85118
Policy Entropy: 1.68973
Value Function Loss: 0.06633

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.32280
Value Function Update Magnitude: 0.33341

Collected Steps per Second: 21,128.11125
Overall Steps per Second: 10,333.24584

Timestep Collection Time: 2.36812
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.84204

Cumulative Model Updates: 126,238
Cumulative Timesteps: 1,053,635,592

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1053635592...
Checkpoint 1053635592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,186.75682
Policy Entropy: 1.68358
Value Function Loss: 0.07054

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.32443
Value Function Update Magnitude: 0.34966

Collected Steps per Second: 21,029.18125
Overall Steps per Second: 10,171.03649

Timestep Collection Time: 2.37860
Timestep Consumption Time: 2.53929
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.91789

Cumulative Model Updates: 126,244
Cumulative Timesteps: 1,053,685,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,476.31279
Policy Entropy: 1.68050
Value Function Loss: 0.06926

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.32916
Value Function Update Magnitude: 0.36074

Collected Steps per Second: 19,688.39850
Overall Steps per Second: 10,039.11252

Timestep Collection Time: 2.54038
Timestep Consumption Time: 2.44173
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.98211

Cumulative Model Updates: 126,250
Cumulative Timesteps: 1,053,735,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1053735628...
Checkpoint 1053735628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,616.90281
Policy Entropy: 1.70260
Value Function Loss: 0.07195

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.32887
Value Function Update Magnitude: 0.35797

Collected Steps per Second: 21,309.01381
Overall Steps per Second: 10,374.27616

Timestep Collection Time: 2.34680
Timestep Consumption Time: 2.47358
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.82038

Cumulative Model Updates: 126,256
Cumulative Timesteps: 1,053,785,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,956.62988
Policy Entropy: 1.70858
Value Function Loss: 0.06977

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.32796
Value Function Update Magnitude: 0.36036

Collected Steps per Second: 21,319.37869
Overall Steps per Second: 10,365.05013

Timestep Collection Time: 2.34688
Timestep Consumption Time: 2.48030
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.82718

Cumulative Model Updates: 126,262
Cumulative Timesteps: 1,053,835,670

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1053835670...
Checkpoint 1053835670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,014.48535
Policy Entropy: 1.70244
Value Function Loss: 0.06678

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.32277
Value Function Update Magnitude: 0.35175

Collected Steps per Second: 20,757.58289
Overall Steps per Second: 10,210.81328

Timestep Collection Time: 2.40972
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.89873

Cumulative Model Updates: 126,268
Cumulative Timesteps: 1,053,885,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,437.10426
Policy Entropy: 1.67446
Value Function Loss: 0.06235

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.31899
Value Function Update Magnitude: 0.32684

Collected Steps per Second: 21,127.38997
Overall Steps per Second: 10,159.91796

Timestep Collection Time: 2.36754
Timestep Consumption Time: 2.55573
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.92327

Cumulative Model Updates: 126,274
Cumulative Timesteps: 1,053,935,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1053935710...
Checkpoint 1053935710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,278.28259
Policy Entropy: 1.67497
Value Function Loss: 0.06496

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.31967
Value Function Update Magnitude: 0.31106

Collected Steps per Second: 21,155.38248
Overall Steps per Second: 10,192.49387

Timestep Collection Time: 2.36441
Timestep Consumption Time: 2.54312
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.90753

Cumulative Model Updates: 126,280
Cumulative Timesteps: 1,053,985,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,548.94945
Policy Entropy: 1.69027
Value Function Loss: 0.06583

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.32460
Value Function Update Magnitude: 0.31341

Collected Steps per Second: 21,130.36377
Overall Steps per Second: 10,332.52527

Timestep Collection Time: 2.36702
Timestep Consumption Time: 2.47362
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.84064

Cumulative Model Updates: 126,286
Cumulative Timesteps: 1,054,035,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1054035746...
Checkpoint 1054035746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,744.97247
Policy Entropy: 1.70195
Value Function Loss: 0.06306

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.31896
Value Function Update Magnitude: 0.33562

Collected Steps per Second: 21,078.62598
Overall Steps per Second: 10,322.04210

Timestep Collection Time: 2.37330
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.84652

Cumulative Model Updates: 126,292
Cumulative Timesteps: 1,054,085,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,971.38393
Policy Entropy: 1.69117
Value Function Loss: 0.06241

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.31293
Value Function Update Magnitude: 0.35169

Collected Steps per Second: 20,979.65200
Overall Steps per Second: 10,169.23221

Timestep Collection Time: 2.38374
Timestep Consumption Time: 2.53404
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.91778

Cumulative Model Updates: 126,298
Cumulative Timesteps: 1,054,135,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1054135782...
Checkpoint 1054135782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,201.78137
Policy Entropy: 1.69112
Value Function Loss: 0.06376

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.31836
Value Function Update Magnitude: 0.36623

Collected Steps per Second: 21,254.32661
Overall Steps per Second: 10,419.06612

Timestep Collection Time: 2.35265
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.79928

Cumulative Model Updates: 126,304
Cumulative Timesteps: 1,054,185,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,830.32571
Policy Entropy: 1.67109
Value Function Loss: 0.06136

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.31228
Value Function Update Magnitude: 0.36008

Collected Steps per Second: 21,295.31194
Overall Steps per Second: 10,377.65578

Timestep Collection Time: 2.34840
Timestep Consumption Time: 2.47060
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.81901

Cumulative Model Updates: 126,310
Cumulative Timesteps: 1,054,235,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1054235796...
Checkpoint 1054235796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,980.52981
Policy Entropy: 1.68383
Value Function Loss: 0.06178

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.31624
Value Function Update Magnitude: 0.32442

Collected Steps per Second: 20,956.24679
Overall Steps per Second: 10,375.81563

Timestep Collection Time: 2.38716
Timestep Consumption Time: 2.43424
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.82140

Cumulative Model Updates: 126,316
Cumulative Timesteps: 1,054,285,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,579.19200
Policy Entropy: 1.66628
Value Function Loss: 0.06348

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.32226
Value Function Update Magnitude: 0.33383

Collected Steps per Second: 21,273.15693
Overall Steps per Second: 10,317.81473

Timestep Collection Time: 2.35113
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.84754

Cumulative Model Updates: 126,322
Cumulative Timesteps: 1,054,335,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1054335838...
Checkpoint 1054335838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,028.09173
Policy Entropy: 1.67361
Value Function Loss: 0.06114

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.32273
Value Function Update Magnitude: 0.35620

Collected Steps per Second: 20,917.32536
Overall Steps per Second: 10,245.71962

Timestep Collection Time: 2.39055
Timestep Consumption Time: 2.48992
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.88048

Cumulative Model Updates: 126,328
Cumulative Timesteps: 1,054,385,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,151.84174
Policy Entropy: 1.66776
Value Function Loss: 0.05650

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.31511
Value Function Update Magnitude: 0.34667

Collected Steps per Second: 21,071.16044
Overall Steps per Second: 10,173.47105

Timestep Collection Time: 2.37320
Timestep Consumption Time: 2.54214
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.91533

Cumulative Model Updates: 126,334
Cumulative Timesteps: 1,054,435,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1054435848...
Checkpoint 1054435848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,816.16465
Policy Entropy: 1.66091
Value Function Loss: 0.05570

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.31119
Value Function Update Magnitude: 0.34359

Collected Steps per Second: 20,937.84619
Overall Steps per Second: 10,135.36308

Timestep Collection Time: 2.38840
Timestep Consumption Time: 2.54561
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.93401

Cumulative Model Updates: 126,340
Cumulative Timesteps: 1,054,485,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,642.29262
Policy Entropy: 1.66829
Value Function Loss: 0.05838

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.30245
Value Function Update Magnitude: 0.32887

Collected Steps per Second: 21,135.04103
Overall Steps per Second: 10,302.27320

Timestep Collection Time: 2.36659
Timestep Consumption Time: 2.48845
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.85505

Cumulative Model Updates: 126,346
Cumulative Timesteps: 1,054,535,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1054535874...
Checkpoint 1054535874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,587.56552
Policy Entropy: 1.65607
Value Function Loss: 0.06181

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07568
Policy Update Magnitude: 0.31192
Value Function Update Magnitude: 0.32538

Collected Steps per Second: 20,950.29001
Overall Steps per Second: 10,258.56461

Timestep Collection Time: 2.38689
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.87456

Cumulative Model Updates: 126,352
Cumulative Timesteps: 1,054,585,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,265.10048
Policy Entropy: 1.66314
Value Function Loss: 0.06437

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.31405
Value Function Update Magnitude: 0.32737

Collected Steps per Second: 21,336.24559
Overall Steps per Second: 10,229.68378

Timestep Collection Time: 2.34521
Timestep Consumption Time: 2.54624
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.89145

Cumulative Model Updates: 126,358
Cumulative Timesteps: 1,054,635,918

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1054635918...
Checkpoint 1054635918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,787.64295
Policy Entropy: 1.67720
Value Function Loss: 0.06691

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.32057
Value Function Update Magnitude: 0.29044

Collected Steps per Second: 20,856.85060
Overall Steps per Second: 10,113.38861

Timestep Collection Time: 2.39806
Timestep Consumption Time: 2.54746
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.94552

Cumulative Model Updates: 126,364
Cumulative Timesteps: 1,054,685,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,343.21575
Policy Entropy: 1.68716
Value Function Loss: 0.06867

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08009
Policy Update Magnitude: 0.32402
Value Function Update Magnitude: 0.25962

Collected Steps per Second: 21,029.44290
Overall Steps per Second: 10,325.59756

Timestep Collection Time: 2.37847
Timestep Consumption Time: 2.46560
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.84408

Cumulative Model Updates: 126,370
Cumulative Timesteps: 1,054,735,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1054735952...
Checkpoint 1054735952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,726.46727
Policy Entropy: 1.69054
Value Function Loss: 0.06716

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08502
Policy Update Magnitude: 0.31643
Value Function Update Magnitude: 0.25020

Collected Steps per Second: 20,898.67566
Overall Steps per Second: 10,252.84626

Timestep Collection Time: 2.39250
Timestep Consumption Time: 2.48420
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.87669

Cumulative Model Updates: 126,376
Cumulative Timesteps: 1,054,785,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,287.52569
Policy Entropy: 1.67493
Value Function Loss: 0.06511

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.31387
Value Function Update Magnitude: 0.24670

Collected Steps per Second: 21,006.29210
Overall Steps per Second: 10,141.37692

Timestep Collection Time: 2.38119
Timestep Consumption Time: 2.55108
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.93227

Cumulative Model Updates: 126,382
Cumulative Timesteps: 1,054,835,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1054835972...
Checkpoint 1054835972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,314.82868
Policy Entropy: 1.66482
Value Function Loss: 0.06217

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.30920
Value Function Update Magnitude: 0.30369

Collected Steps per Second: 21,017.48249
Overall Steps per Second: 10,160.89995

Timestep Collection Time: 2.37964
Timestep Consumption Time: 2.54256
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.92220

Cumulative Model Updates: 126,388
Cumulative Timesteps: 1,054,885,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,961.62156
Policy Entropy: 1.65545
Value Function Loss: 0.06067

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.29347
Value Function Update Magnitude: 0.30883

Collected Steps per Second: 21,104.61282
Overall Steps per Second: 10,327.77505

Timestep Collection Time: 2.37057
Timestep Consumption Time: 2.47365
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.84422

Cumulative Model Updates: 126,394
Cumulative Timesteps: 1,054,936,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1054936016...
Checkpoint 1054936016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,443.35020
Policy Entropy: 1.65642
Value Function Loss: 0.06282

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.29466
Value Function Update Magnitude: 0.29988

Collected Steps per Second: 20,854.71657
Overall Steps per Second: 10,260.20836

Timestep Collection Time: 2.39898
Timestep Consumption Time: 2.47714
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.87612

Cumulative Model Updates: 126,400
Cumulative Timesteps: 1,054,986,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,107.45759
Policy Entropy: 1.64739
Value Function Loss: 0.06311

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.30651
Value Function Update Magnitude: 0.30785

Collected Steps per Second: 21,028.75810
Overall Steps per Second: 10,151.60328

Timestep Collection Time: 2.37789
Timestep Consumption Time: 2.54784
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.92572

Cumulative Model Updates: 126,406
Cumulative Timesteps: 1,055,036,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1055036050...
Checkpoint 1055036050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,450.66932
Policy Entropy: 1.65991
Value Function Loss: 0.06431

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.29610
Value Function Update Magnitude: 0.33060

Collected Steps per Second: 19,898.33048
Overall Steps per Second: 10,176.01131

Timestep Collection Time: 2.51438
Timestep Consumption Time: 2.40228
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.91666

Cumulative Model Updates: 126,412
Cumulative Timesteps: 1,055,086,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,361.37938
Policy Entropy: 1.65605
Value Function Loss: 0.06154

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.30167
Value Function Update Magnitude: 0.35410

Collected Steps per Second: 20,340.13074
Overall Steps per Second: 10,187.15299

Timestep Collection Time: 2.45918
Timestep Consumption Time: 2.45093
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.91011

Cumulative Model Updates: 126,418
Cumulative Timesteps: 1,055,136,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1055136102...
Checkpoint 1055136102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,658.19635
Policy Entropy: 1.66133
Value Function Loss: 0.06300

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.29544
Value Function Update Magnitude: 0.34912

Collected Steps per Second: 20,315.41300
Overall Steps per Second: 10,151.20781

Timestep Collection Time: 2.46138
Timestep Consumption Time: 2.46453
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.92592

Cumulative Model Updates: 126,424
Cumulative Timesteps: 1,055,186,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,483.19827
Policy Entropy: 1.65824
Value Function Loss: 0.05672

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.29186
Value Function Update Magnitude: 0.34086

Collected Steps per Second: 20,635.81724
Overall Steps per Second: 10,297.64765

Timestep Collection Time: 2.42326
Timestep Consumption Time: 2.43280
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.85606

Cumulative Model Updates: 126,430
Cumulative Timesteps: 1,055,236,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1055236112...
Checkpoint 1055236112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,572.24406
Policy Entropy: 1.66215
Value Function Loss: 0.05463

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.30102
Value Function Update Magnitude: 0.32297

Collected Steps per Second: 20,407.59201
Overall Steps per Second: 10,177.07488

Timestep Collection Time: 2.45075
Timestep Consumption Time: 2.46362
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.91438

Cumulative Model Updates: 126,436
Cumulative Timesteps: 1,055,286,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,478.99528
Policy Entropy: 1.66464
Value Function Loss: 0.05162

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.30178
Value Function Update Magnitude: 0.30729

Collected Steps per Second: 21,056.63037
Overall Steps per Second: 10,253.15269

Timestep Collection Time: 2.37493
Timestep Consumption Time: 2.50240
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.87733

Cumulative Model Updates: 126,442
Cumulative Timesteps: 1,055,336,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1055336134...
Checkpoint 1055336134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,410.19852
Policy Entropy: 1.65580
Value Function Loss: 0.05488

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.30362
Value Function Update Magnitude: 0.30846

Collected Steps per Second: 20,962.20527
Overall Steps per Second: 10,346.73365

Timestep Collection Time: 2.38696
Timestep Consumption Time: 2.44896
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.83592

Cumulative Model Updates: 126,448
Cumulative Timesteps: 1,055,386,170

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,694.77754
Policy Entropy: 1.64596
Value Function Loss: 0.05948

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.31225
Value Function Update Magnitude: 0.31628

Collected Steps per Second: 20,864.45264
Overall Steps per Second: 10,161.70075

Timestep Collection Time: 2.39709
Timestep Consumption Time: 2.52472
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.92181

Cumulative Model Updates: 126,454
Cumulative Timesteps: 1,055,436,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1055436184...
Checkpoint 1055436184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,062.07503
Policy Entropy: 1.62985
Value Function Loss: 0.06204

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.31621
Value Function Update Magnitude: 0.34104

Collected Steps per Second: 21,031.45347
Overall Steps per Second: 10,191.33484

Timestep Collection Time: 2.37872
Timestep Consumption Time: 2.53015
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.90888

Cumulative Model Updates: 126,460
Cumulative Timesteps: 1,055,486,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,975.17883
Policy Entropy: 1.64110
Value Function Loss: 0.06396

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07844
Policy Update Magnitude: 0.31802
Value Function Update Magnitude: 0.35148

Collected Steps per Second: 21,350.05586
Overall Steps per Second: 10,357.50523

Timestep Collection Time: 2.34210
Timestep Consumption Time: 2.48570
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.82780

Cumulative Model Updates: 126,466
Cumulative Timesteps: 1,055,536,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1055536216...
Checkpoint 1055536216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,665.28976
Policy Entropy: 1.64794
Value Function Loss: 0.05848

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.31464
Value Function Update Magnitude: 0.34621

Collected Steps per Second: 21,039.82635
Overall Steps per Second: 10,258.46856

Timestep Collection Time: 2.37683
Timestep Consumption Time: 2.49798
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.87480

Cumulative Model Updates: 126,472
Cumulative Timesteps: 1,055,586,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,794.64103
Policy Entropy: 1.66171
Value Function Loss: 0.05976

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08396
Policy Update Magnitude: 0.31457
Value Function Update Magnitude: 0.33909

Collected Steps per Second: 21,289.04227
Overall Steps per Second: 10,198.27856

Timestep Collection Time: 2.34928
Timestep Consumption Time: 2.55488
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.90416

Cumulative Model Updates: 126,478
Cumulative Timesteps: 1,055,636,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1055636238...
Checkpoint 1055636238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,266.45146
Policy Entropy: 1.67064
Value Function Loss: 0.06049

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.31835
Value Function Update Magnitude: 0.34792

Collected Steps per Second: 20,952.15875
Overall Steps per Second: 10,192.38504

Timestep Collection Time: 2.38734
Timestep Consumption Time: 2.52024
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.90759

Cumulative Model Updates: 126,484
Cumulative Timesteps: 1,055,686,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,313.32336
Policy Entropy: 1.65679
Value Function Loss: 0.06413

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.35940

Collected Steps per Second: 21,083.49188
Overall Steps per Second: 10,283.05980

Timestep Collection Time: 2.37266
Timestep Consumption Time: 2.49204
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.86470

Cumulative Model Updates: 126,490
Cumulative Timesteps: 1,055,736,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1055736282...
Checkpoint 1055736282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,540.93074
Policy Entropy: 1.65261
Value Function Loss: 0.06339

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.30170
Value Function Update Magnitude: 0.34965

Collected Steps per Second: 20,966.87114
Overall Steps per Second: 10,255.40078

Timestep Collection Time: 2.38491
Timestep Consumption Time: 2.49096
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.87587

Cumulative Model Updates: 126,496
Cumulative Timesteps: 1,055,786,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,007.37912
Policy Entropy: 1.65641
Value Function Loss: 0.06486

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.30594
Value Function Update Magnitude: 0.33647

Collected Steps per Second: 21,088.31602
Overall Steps per Second: 10,213.22377

Timestep Collection Time: 2.37108
Timestep Consumption Time: 2.52473
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.89581

Cumulative Model Updates: 126,502
Cumulative Timesteps: 1,055,836,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1055836288...
Checkpoint 1055836288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,896.42794
Policy Entropy: 1.66442
Value Function Loss: 0.06627

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.31137
Value Function Update Magnitude: 0.33924

Collected Steps per Second: 21,021.95859
Overall Steps per Second: 10,176.19626

Timestep Collection Time: 2.37885
Timestep Consumption Time: 2.53537
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.91421

Cumulative Model Updates: 126,508
Cumulative Timesteps: 1,055,886,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,131.12749
Policy Entropy: 1.68835
Value Function Loss: 0.06327

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.31510
Value Function Update Magnitude: 0.34347

Collected Steps per Second: 21,181.80927
Overall Steps per Second: 10,325.37311

Timestep Collection Time: 2.36137
Timestep Consumption Time: 2.48282
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.84418

Cumulative Model Updates: 126,514
Cumulative Timesteps: 1,055,936,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1055936314...
Checkpoint 1055936314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,787.94032
Policy Entropy: 1.68716
Value Function Loss: 0.06063

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.30981
Value Function Update Magnitude: 0.32697

Collected Steps per Second: 21,235.92470
Overall Steps per Second: 10,192.18365

Timestep Collection Time: 2.35554
Timestep Consumption Time: 2.55234
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.90788

Cumulative Model Updates: 126,520
Cumulative Timesteps: 1,055,986,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,538.25081
Policy Entropy: 1.69748
Value Function Loss: 0.05954

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.33304

Collected Steps per Second: 21,188.49431
Overall Steps per Second: 10,351.40767

Timestep Collection Time: 2.36043
Timestep Consumption Time: 2.47118
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.83161

Cumulative Model Updates: 126,526
Cumulative Timesteps: 1,056,036,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1056036350...
Checkpoint 1056036350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,218.12483
Policy Entropy: 1.68737
Value Function Loss: 0.06259

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.31583
Value Function Update Magnitude: 0.35493

Collected Steps per Second: 21,122.84804
Overall Steps per Second: 10,341.26676

Timestep Collection Time: 2.36853
Timestep Consumption Time: 2.46937
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.83790

Cumulative Model Updates: 126,532
Cumulative Timesteps: 1,056,086,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,282.27066
Policy Entropy: 1.68373
Value Function Loss: 0.06616

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.32180
Value Function Update Magnitude: 0.38241

Collected Steps per Second: 20,683.04601
Overall Steps per Second: 10,060.35489

Timestep Collection Time: 2.41744
Timestep Consumption Time: 2.55256
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.97000

Cumulative Model Updates: 126,538
Cumulative Timesteps: 1,056,136,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1056136380...
Checkpoint 1056136380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,573.37556
Policy Entropy: 1.67521
Value Function Loss: 0.06547

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.32606
Value Function Update Magnitude: 0.39481

Collected Steps per Second: 21,008.52075
Overall Steps per Second: 10,137.66332

Timestep Collection Time: 2.38018
Timestep Consumption Time: 2.55232
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 4.93250

Cumulative Model Updates: 126,544
Cumulative Timesteps: 1,056,186,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,809.30111
Policy Entropy: 1.66607
Value Function Loss: 0.06236

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.32205
Value Function Update Magnitude: 0.38345

Collected Steps per Second: 20,889.05300
Overall Steps per Second: 10,134.05633

Timestep Collection Time: 2.39465
Timestep Consumption Time: 2.54138
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.93603

Cumulative Model Updates: 126,550
Cumulative Timesteps: 1,056,236,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1056236406...
Checkpoint 1056236406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,096.94314
Policy Entropy: 1.65841
Value Function Loss: 0.05839

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.31842
Value Function Update Magnitude: 0.35029

Collected Steps per Second: 21,303.72275
Overall Steps per Second: 10,248.41495

Timestep Collection Time: 2.34766
Timestep Consumption Time: 2.53250
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.88017

Cumulative Model Updates: 126,556
Cumulative Timesteps: 1,056,286,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,723.31297
Policy Entropy: 1.64695
Value Function Loss: 0.06055

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.31478
Value Function Update Magnitude: 0.31588

Collected Steps per Second: 21,060.47306
Overall Steps per Second: 10,268.29187

Timestep Collection Time: 2.37469
Timestep Consumption Time: 2.49584
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.87053

Cumulative Model Updates: 126,562
Cumulative Timesteps: 1,056,336,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1056336432...
Checkpoint 1056336432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,763.61345
Policy Entropy: 1.66673
Value Function Loss: 0.06288

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.31417
Value Function Update Magnitude: 0.29830

Collected Steps per Second: 21,062.93940
Overall Steps per Second: 10,276.15064

Timestep Collection Time: 2.37469
Timestep Consumption Time: 2.49269
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.86739

Cumulative Model Updates: 126,568
Cumulative Timesteps: 1,056,386,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,825.07457
Policy Entropy: 1.67462
Value Function Loss: 0.06487

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.31267
Value Function Update Magnitude: 0.29987

Collected Steps per Second: 21,060.62925
Overall Steps per Second: 10,341.08827

Timestep Collection Time: 2.37543
Timestep Consumption Time: 2.46236
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.83779

Cumulative Model Updates: 126,574
Cumulative Timesteps: 1,056,436,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1056436478...
Checkpoint 1056436478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,787.90778
Policy Entropy: 1.68220
Value Function Loss: 0.06448

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.31619
Value Function Update Magnitude: 0.32156

Collected Steps per Second: 20,524.76540
Overall Steps per Second: 10,273.97310

Timestep Collection Time: 2.43735
Timestep Consumption Time: 2.43185
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.86920

Cumulative Model Updates: 126,580
Cumulative Timesteps: 1,056,486,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,005.56587
Policy Entropy: 1.69653
Value Function Loss: 0.06334

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07562
Policy Update Magnitude: 0.31335
Value Function Update Magnitude: 0.28180

Collected Steps per Second: 20,390.06648
Overall Steps per Second: 10,165.75805

Timestep Collection Time: 2.45404
Timestep Consumption Time: 2.46817
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.92221

Cumulative Model Updates: 126,586
Cumulative Timesteps: 1,056,536,542

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1056536542...
Checkpoint 1056536542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,072.63764
Policy Entropy: 1.70056
Value Function Loss: 0.06348

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07408
Policy Update Magnitude: 0.31107
Value Function Update Magnitude: 0.23096

Collected Steps per Second: 20,780.39491
Overall Steps per Second: 10,405.49789

Timestep Collection Time: 2.40775
Timestep Consumption Time: 2.40067
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.80842

Cumulative Model Updates: 126,592
Cumulative Timesteps: 1,056,586,576

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,924.68362
Policy Entropy: 1.70379
Value Function Loss: 0.06010

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07523
Policy Update Magnitude: 0.30891
Value Function Update Magnitude: 0.25629

Collected Steps per Second: 20,283.93041
Overall Steps per Second: 10,124.24743

Timestep Collection Time: 2.46570
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.94002

Cumulative Model Updates: 126,598
Cumulative Timesteps: 1,056,636,590

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1056636590...
Checkpoint 1056636590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,545.26972
Policy Entropy: 1.66533
Value Function Loss: 0.05980

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.30885
Value Function Update Magnitude: 0.28410

Collected Steps per Second: 20,671.42485
Overall Steps per Second: 10,279.12294

Timestep Collection Time: 2.41889
Timestep Consumption Time: 2.44553
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.86442

Cumulative Model Updates: 126,604
Cumulative Timesteps: 1,056,686,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,037.12934
Policy Entropy: 1.67360
Value Function Loss: 0.05914

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.31029
Value Function Update Magnitude: 0.30036

Collected Steps per Second: 20,537.01839
Overall Steps per Second: 10,044.37000

Timestep Collection Time: 2.43463
Timestep Consumption Time: 2.54329
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.97791

Cumulative Model Updates: 126,610
Cumulative Timesteps: 1,056,736,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1056736592...
Checkpoint 1056736592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,419.34189
Policy Entropy: 1.67316
Value Function Loss: 0.06021

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.31282
Value Function Update Magnitude: 0.31604

Collected Steps per Second: 21,214.42871
Overall Steps per Second: 10,307.25010

Timestep Collection Time: 2.35792
Timestep Consumption Time: 2.49517
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.85309

Cumulative Model Updates: 126,616
Cumulative Timesteps: 1,056,786,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,601.30665
Policy Entropy: 1.68969
Value Function Loss: 0.06052

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.31288
Value Function Update Magnitude: 0.31801

Collected Steps per Second: 20,958.79728
Overall Steps per Second: 10,262.94649

Timestep Collection Time: 2.38573
Timestep Consumption Time: 2.48636
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.87209

Cumulative Model Updates: 126,622
Cumulative Timesteps: 1,056,836,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1056836616...
Checkpoint 1056836616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,329.04179
Policy Entropy: 1.68897
Value Function Loss: 0.06077

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.31322
Value Function Update Magnitude: 0.30304

Collected Steps per Second: 20,900.27378
Overall Steps per Second: 10,285.51348

Timestep Collection Time: 2.39308
Timestep Consumption Time: 2.46968
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.86276

Cumulative Model Updates: 126,628
Cumulative Timesteps: 1,056,886,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,975.78514
Policy Entropy: 1.69048
Value Function Loss: 0.06427

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.31568
Value Function Update Magnitude: 0.27647

Collected Steps per Second: 20,684.21281
Overall Steps per Second: 10,059.98898

Timestep Collection Time: 2.41769
Timestep Consumption Time: 2.55329
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.97098

Cumulative Model Updates: 126,634
Cumulative Timesteps: 1,056,936,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1056936640...
Checkpoint 1056936640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,604.54220
Policy Entropy: 1.68924
Value Function Loss: 0.07100

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.32224
Value Function Update Magnitude: 0.24408

Collected Steps per Second: 21,180.53497
Overall Steps per Second: 10,184.84533

Timestep Collection Time: 2.36198
Timestep Consumption Time: 2.55002
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.91200

Cumulative Model Updates: 126,640
Cumulative Timesteps: 1,056,986,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,405.74447
Policy Entropy: 1.68174
Value Function Loss: 0.07041

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.32845
Value Function Update Magnitude: 0.23420

Collected Steps per Second: 21,003.57811
Overall Steps per Second: 10,288.80155

Timestep Collection Time: 2.38112
Timestep Consumption Time: 2.47970
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.86082

Cumulative Model Updates: 126,646
Cumulative Timesteps: 1,057,036,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1057036680...
Checkpoint 1057036680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,465.85445
Policy Entropy: 1.70293
Value Function Loss: 0.07120

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.32734
Value Function Update Magnitude: 0.24577

Collected Steps per Second: 21,159.97318
Overall Steps per Second: 10,352.17299

Timestep Collection Time: 2.36371
Timestep Consumption Time: 2.46774
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.83145

Cumulative Model Updates: 126,652
Cumulative Timesteps: 1,057,086,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,186.75402
Policy Entropy: 1.71939
Value Function Loss: 0.07150

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.32530
Value Function Update Magnitude: 0.25059

Collected Steps per Second: 20,610.53464
Overall Steps per Second: 10,099.47769

Timestep Collection Time: 2.42604
Timestep Consumption Time: 2.52491
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.95095

Cumulative Model Updates: 126,658
Cumulative Timesteps: 1,057,136,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1057136698...
Checkpoint 1057136698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,261.93702
Policy Entropy: 1.71901
Value Function Loss: 0.07292

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.32460
Value Function Update Magnitude: 0.29608

Collected Steps per Second: 21,347.89149
Overall Steps per Second: 10,264.29303

Timestep Collection Time: 2.34271
Timestep Consumption Time: 2.52971
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.87243

Cumulative Model Updates: 126,664
Cumulative Timesteps: 1,057,186,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,171.43172
Policy Entropy: 1.70243
Value Function Loss: 0.07038

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.32755
Value Function Update Magnitude: 0.33187

Collected Steps per Second: 21,149.56410
Overall Steps per Second: 10,338.78784

Timestep Collection Time: 2.36497
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.83790

Cumulative Model Updates: 126,670
Cumulative Timesteps: 1,057,236,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1057236728...
Checkpoint 1057236728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,621.71643
Policy Entropy: 1.68844
Value Function Loss: 0.06450

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.32192
Value Function Update Magnitude: 0.35447

Collected Steps per Second: 21,374.16990
Overall Steps per Second: 10,238.65675

Timestep Collection Time: 2.34002
Timestep Consumption Time: 2.54500
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.88502

Cumulative Model Updates: 126,676
Cumulative Timesteps: 1,057,286,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,368.74266
Policy Entropy: 1.69412
Value Function Loss: 0.05816

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.31496
Value Function Update Magnitude: 0.35940

Collected Steps per Second: 19,017.48830
Overall Steps per Second: 9,610.60622

Timestep Collection Time: 2.63095
Timestep Consumption Time: 2.57518
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 5.20612

Cumulative Model Updates: 126,682
Cumulative Timesteps: 1,057,336,778

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1057336778...
Checkpoint 1057336778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,605.03062
Policy Entropy: 1.69732
Value Function Loss: 0.05894

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.31324
Value Function Update Magnitude: 0.34512

Collected Steps per Second: 20,684.31092
Overall Steps per Second: 10,134.89998

Timestep Collection Time: 2.41806
Timestep Consumption Time: 2.51696
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.93503

Cumulative Model Updates: 126,688
Cumulative Timesteps: 1,057,386,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,437.66851
Policy Entropy: 1.70328
Value Function Loss: 0.06285

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31681
Value Function Update Magnitude: 0.33316

Collected Steps per Second: 21,325.58652
Overall Steps per Second: 10,230.79193

Timestep Collection Time: 2.34460
Timestep Consumption Time: 2.54261
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.88721

Cumulative Model Updates: 126,694
Cumulative Timesteps: 1,057,436,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1057436794...
Checkpoint 1057436794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,851.26628
Policy Entropy: 1.71841
Value Function Loss: 0.07178

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.32669
Value Function Update Magnitude: 0.31317

Collected Steps per Second: 21,250.83697
Overall Steps per Second: 10,367.29523

Timestep Collection Time: 2.35417
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.82556

Cumulative Model Updates: 126,700
Cumulative Timesteps: 1,057,486,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,482.81638
Policy Entropy: 1.70888
Value Function Loss: 0.07240

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.32700
Value Function Update Magnitude: 0.30157

Collected Steps per Second: 20,705.74887
Overall Steps per Second: 9,958.74026

Timestep Collection Time: 2.41701
Timestep Consumption Time: 2.60832
PPO Batch Consumption Time: 0.30365
Total Iteration Time: 5.02533

Cumulative Model Updates: 126,706
Cumulative Timesteps: 1,057,536,868

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1057536868...
Checkpoint 1057536868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,287.12034
Policy Entropy: 1.71864
Value Function Loss: 0.07157

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.32090
Value Function Update Magnitude: 0.31568

Collected Steps per Second: 21,050.10954
Overall Steps per Second: 10,240.54891

Timestep Collection Time: 2.37652
Timestep Consumption Time: 2.50857
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.88509

Cumulative Model Updates: 126,712
Cumulative Timesteps: 1,057,586,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,119.85254
Policy Entropy: 1.70771
Value Function Loss: 0.06677

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.32012
Value Function Update Magnitude: 0.30662

Collected Steps per Second: 21,042.38193
Overall Steps per Second: 10,461.96952

Timestep Collection Time: 2.37749
Timestep Consumption Time: 2.40440
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.78189

Cumulative Model Updates: 126,718
Cumulative Timesteps: 1,057,636,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1057636922...
Checkpoint 1057636922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,116.96608
Policy Entropy: 1.69901
Value Function Loss: 0.06756

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.31742
Value Function Update Magnitude: 0.32595

Collected Steps per Second: 21,103.60131
Overall Steps per Second: 10,310.61612

Timestep Collection Time: 2.37012
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.85112

Cumulative Model Updates: 126,724
Cumulative Timesteps: 1,057,686,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,060.55504
Policy Entropy: 1.68902
Value Function Loss: 0.06554

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.32028
Value Function Update Magnitude: 0.32722

Collected Steps per Second: 21,085.51992
Overall Steps per Second: 10,167.57002

Timestep Collection Time: 2.37281
Timestep Consumption Time: 2.54793
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.92074

Cumulative Model Updates: 126,730
Cumulative Timesteps: 1,057,736,972

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1057736972...
Checkpoint 1057736972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,875.52840
Policy Entropy: 1.69023
Value Function Loss: 0.06459

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.32215
Value Function Update Magnitude: 0.33632

Collected Steps per Second: 21,155.02422
Overall Steps per Second: 10,185.21747

Timestep Collection Time: 2.36388
Timestep Consumption Time: 2.54598
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.90986

Cumulative Model Updates: 126,736
Cumulative Timesteps: 1,057,786,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,379.89208
Policy Entropy: 1.71567
Value Function Loss: 0.06274

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.31833
Value Function Update Magnitude: 0.35357

Collected Steps per Second: 21,395.73492
Overall Steps per Second: 10,296.89850

Timestep Collection Time: 2.33832
Timestep Consumption Time: 2.52043
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.85874

Cumulative Model Updates: 126,742
Cumulative Timesteps: 1,057,837,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1057837010...
Checkpoint 1057837010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,132.72915
Policy Entropy: 1.71485
Value Function Loss: 0.06655

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.31767
Value Function Update Magnitude: 0.37042

Collected Steps per Second: 21,109.87795
Overall Steps per Second: 10,305.28830

Timestep Collection Time: 2.36989
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.85459

Cumulative Model Updates: 126,748
Cumulative Timesteps: 1,057,887,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,615.39820
Policy Entropy: 1.70146
Value Function Loss: 0.06220

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.32041
Value Function Update Magnitude: 0.35127

Collected Steps per Second: 20,556.67593
Overall Steps per Second: 10,331.17187

Timestep Collection Time: 2.43425
Timestep Consumption Time: 2.40935
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.84359

Cumulative Model Updates: 126,754
Cumulative Timesteps: 1,057,937,078

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1057937078...
Checkpoint 1057937078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,889.32839
Policy Entropy: 1.68282
Value Function Loss: 0.06276

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.31859
Value Function Update Magnitude: 0.33366

Collected Steps per Second: 20,297.65072
Overall Steps per Second: 10,258.77335

Timestep Collection Time: 2.46432
Timestep Consumption Time: 2.41150
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.87583

Cumulative Model Updates: 126,760
Cumulative Timesteps: 1,057,987,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,818.60347
Policy Entropy: 1.68126
Value Function Loss: 0.06061

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.31676
Value Function Update Magnitude: 0.33440

Collected Steps per Second: 20,554.21551
Overall Steps per Second: 10,205.08726

Timestep Collection Time: 2.43483
Timestep Consumption Time: 2.46920
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.90402

Cumulative Model Updates: 126,766
Cumulative Timesteps: 1,058,037,144

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1058037144...
Checkpoint 1058037144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,393.41839
Policy Entropy: 1.71074
Value Function Loss: 0.06899

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.32013
Value Function Update Magnitude: 0.32442

Collected Steps per Second: 20,371.06979
Overall Steps per Second: 10,165.79145

Timestep Collection Time: 2.45574
Timestep Consumption Time: 2.46528
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.92101

Cumulative Model Updates: 126,772
Cumulative Timesteps: 1,058,087,170

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,549.14419
Policy Entropy: 1.72459
Value Function Loss: 0.06734

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.32027
Value Function Update Magnitude: 0.32977

Collected Steps per Second: 20,382.00519
Overall Steps per Second: 10,284.57061

Timestep Collection Time: 2.45540
Timestep Consumption Time: 2.41072
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.86612

Cumulative Model Updates: 126,778
Cumulative Timesteps: 1,058,137,216

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1058137216...
Checkpoint 1058137216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,166.89775
Policy Entropy: 1.72178
Value Function Loss: 0.06660

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.31420
Value Function Update Magnitude: 0.33782

Collected Steps per Second: 20,205.66375
Overall Steps per Second: 10,017.90500

Timestep Collection Time: 2.47455
Timestep Consumption Time: 2.51651
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.99106

Cumulative Model Updates: 126,784
Cumulative Timesteps: 1,058,187,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,268.33064
Policy Entropy: 1.70964
Value Function Loss: 0.06450

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.30925
Value Function Update Magnitude: 0.33179

Collected Steps per Second: 21,451.05982
Overall Steps per Second: 10,329.07296

Timestep Collection Time: 2.33098
Timestep Consumption Time: 2.50992
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.84090

Cumulative Model Updates: 126,790
Cumulative Timesteps: 1,058,237,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1058237218...
Checkpoint 1058237218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,971.10402
Policy Entropy: 1.71084
Value Function Loss: 0.06020

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.30868
Value Function Update Magnitude: 0.33137

Collected Steps per Second: 20,624.13953
Overall Steps per Second: 10,150.49630

Timestep Collection Time: 2.42570
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.92863

Cumulative Model Updates: 126,796
Cumulative Timesteps: 1,058,287,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,539.18937
Policy Entropy: 1.72265
Value Function Loss: 0.06375

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.30911
Value Function Update Magnitude: 0.29702

Collected Steps per Second: 21,351.06177
Overall Steps per Second: 10,404.40157

Timestep Collection Time: 2.34386
Timestep Consumption Time: 2.46602
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.80989

Cumulative Model Updates: 126,802
Cumulative Timesteps: 1,058,337,290

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1058337290...
Checkpoint 1058337290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,055.62905
Policy Entropy: 1.72535
Value Function Loss: 0.07102

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.31839
Value Function Update Magnitude: 0.30227

Collected Steps per Second: 20,665.27625
Overall Steps per Second: 10,207.59228

Timestep Collection Time: 2.41961
Timestep Consumption Time: 2.47890
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.89851

Cumulative Model Updates: 126,808
Cumulative Timesteps: 1,058,387,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,871.82557
Policy Entropy: 1.70975
Value Function Loss: 0.06657

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.31935
Value Function Update Magnitude: 0.33166

Collected Steps per Second: 21,359.78630
Overall Steps per Second: 10,231.60592

Timestep Collection Time: 2.34253
Timestep Consumption Time: 2.54780
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.89034

Cumulative Model Updates: 126,814
Cumulative Timesteps: 1,058,437,328

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1058437328...
Checkpoint 1058437328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,804.07939
Policy Entropy: 1.70081
Value Function Loss: 0.06750

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.30929
Value Function Update Magnitude: 0.32203

Collected Steps per Second: 20,642.58505
Overall Steps per Second: 10,090.08035

Timestep Collection Time: 2.42334
Timestep Consumption Time: 2.53440
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.95774

Cumulative Model Updates: 126,820
Cumulative Timesteps: 1,058,487,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,763.27767
Policy Entropy: 1.70385
Value Function Loss: 0.06826

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.29438
Value Function Update Magnitude: 0.33503

Collected Steps per Second: 21,184.70841
Overall Steps per Second: 10,230.93527

Timestep Collection Time: 2.36170
Timestep Consumption Time: 2.52856
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.89027

Cumulative Model Updates: 126,826
Cumulative Timesteps: 1,058,537,384

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1058537384...
Checkpoint 1058537384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,064.79752
Policy Entropy: 1.72951
Value Function Loss: 0.07628

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.29841
Value Function Update Magnitude: 0.37924

Collected Steps per Second: 20,843.38860
Overall Steps per Second: 10,111.19770

Timestep Collection Time: 2.39903
Timestep Consumption Time: 2.54637
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.94541

Cumulative Model Updates: 126,832
Cumulative Timesteps: 1,058,587,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,359.23652
Policy Entropy: 1.72847
Value Function Loss: 0.07583

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.29278
Value Function Update Magnitude: 0.38069

Collected Steps per Second: 21,168.04350
Overall Steps per Second: 10,307.81820

Timestep Collection Time: 2.36300
Timestep Consumption Time: 2.48963
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.85263

Cumulative Model Updates: 126,838
Cumulative Timesteps: 1,058,637,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1058637408...
Checkpoint 1058637408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,357.70251
Policy Entropy: 1.71638
Value Function Loss: 0.07308

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.29087
Value Function Update Magnitude: 0.37460

Collected Steps per Second: 20,685.82957
Overall Steps per Second: 10,202.88872

Timestep Collection Time: 2.41837
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.90312

Cumulative Model Updates: 126,844
Cumulative Timesteps: 1,058,687,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,718.05576
Policy Entropy: 1.68698
Value Function Loss: 0.06677

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.29769
Value Function Update Magnitude: 0.36557

Collected Steps per Second: 21,203.22764
Overall Steps per Second: 10,218.45179

Timestep Collection Time: 2.35907
Timestep Consumption Time: 2.53599
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.89507

Cumulative Model Updates: 126,850
Cumulative Timesteps: 1,058,737,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1058737454...
Checkpoint 1058737454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,410.61473
Policy Entropy: 1.71013
Value Function Loss: 0.06649

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31200
Value Function Update Magnitude: 0.35548

Collected Steps per Second: 20,756.97814
Overall Steps per Second: 10,058.46280

Timestep Collection Time: 2.40960
Timestep Consumption Time: 2.56293
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.97253

Cumulative Model Updates: 126,856
Cumulative Timesteps: 1,058,787,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,681.35533
Policy Entropy: 1.75351
Value Function Loss: 0.07376

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.31604
Value Function Update Magnitude: 0.35837

Collected Steps per Second: 21,319.86065
Overall Steps per Second: 10,405.06538

Timestep Collection Time: 2.34636
Timestep Consumption Time: 2.46130
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.80766

Cumulative Model Updates: 126,862
Cumulative Timesteps: 1,058,837,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1058837494...
Checkpoint 1058837494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,982.15486
Policy Entropy: 1.80540
Value Function Loss: 0.08489

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.32077
Value Function Update Magnitude: 0.30695

Collected Steps per Second: 20,506.55362
Overall Steps per Second: 10,191.52759

Timestep Collection Time: 2.43854
Timestep Consumption Time: 2.46809
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.90662

Cumulative Model Updates: 126,868
Cumulative Timesteps: 1,058,887,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,302.62347
Policy Entropy: 1.78431
Value Function Loss: 0.08725

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.31841
Value Function Update Magnitude: 0.22319

Collected Steps per Second: 21,237.89640
Overall Steps per Second: 10,226.70636

Timestep Collection Time: 2.35635
Timestep Consumption Time: 2.53711
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.89346

Cumulative Model Updates: 126,874
Cumulative Timesteps: 1,058,937,544

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1058937544...
Checkpoint 1058937544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,022.11809
Policy Entropy: 1.76260
Value Function Loss: 0.08328

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.31878
Value Function Update Magnitude: 0.18450

Collected Steps per Second: 20,834.73052
Overall Steps per Second: 10,075.79982

Timestep Collection Time: 2.40214
Timestep Consumption Time: 2.56501
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.96715

Cumulative Model Updates: 126,880
Cumulative Timesteps: 1,058,987,592

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,472.37464
Policy Entropy: 1.73363
Value Function Loss: 0.07305

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.21514

Collected Steps per Second: 21,148.03306
Overall Steps per Second: 10,205.51403

Timestep Collection Time: 2.36552
Timestep Consumption Time: 2.53634
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.90186

Cumulative Model Updates: 126,886
Cumulative Timesteps: 1,059,037,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1059037618...
Checkpoint 1059037618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,206.56999
Policy Entropy: 1.73933
Value Function Loss: 0.06580

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.30909
Value Function Update Magnitude: 0.27826

Collected Steps per Second: 20,729.81019
Overall Steps per Second: 10,053.28874

Timestep Collection Time: 2.41256
Timestep Consumption Time: 2.56213
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.97469

Cumulative Model Updates: 126,892
Cumulative Timesteps: 1,059,087,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,862.72438
Policy Entropy: 1.72362
Value Function Loss: 0.06154

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.30215
Value Function Update Magnitude: 0.30488

Collected Steps per Second: 21,182.97366
Overall Steps per Second: 10,228.33849

Timestep Collection Time: 2.36124
Timestep Consumption Time: 2.52890
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.89014

Cumulative Model Updates: 126,898
Cumulative Timesteps: 1,059,137,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1059137648...
Checkpoint 1059137648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,345.92797
Policy Entropy: 1.72440
Value Function Loss: 0.06011

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07648
Policy Update Magnitude: 0.30576
Value Function Update Magnitude: 0.31609

Collected Steps per Second: 20,395.53635
Overall Steps per Second: 10,008.17468

Timestep Collection Time: 2.45152
Timestep Consumption Time: 2.54440
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.99592

Cumulative Model Updates: 126,904
Cumulative Timesteps: 1,059,187,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,985.32989
Policy Entropy: 1.73728
Value Function Loss: 0.06279

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07736
Policy Update Magnitude: 0.30687
Value Function Update Magnitude: 0.31371

Collected Steps per Second: 21,422.21366
Overall Steps per Second: 10,408.73155

Timestep Collection Time: 2.33505
Timestep Consumption Time: 2.47072
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.80577

Cumulative Model Updates: 126,910
Cumulative Timesteps: 1,059,237,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1059237670...
Checkpoint 1059237670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,807.50689
Policy Entropy: 1.76998
Value Function Loss: 0.07257

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.30922
Value Function Update Magnitude: 0.29206

Collected Steps per Second: 20,758.23064
Overall Steps per Second: 10,230.42570

Timestep Collection Time: 2.40984
Timestep Consumption Time: 2.47989
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.88973

Cumulative Model Updates: 126,916
Cumulative Timesteps: 1,059,287,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,194.90183
Policy Entropy: 1.77200
Value Function Loss: 0.07612

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.31360
Value Function Update Magnitude: 0.27270

Collected Steps per Second: 21,099.60655
Overall Steps per Second: 10,191.97523

Timestep Collection Time: 2.37000
Timestep Consumption Time: 2.53641
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.90641

Cumulative Model Updates: 126,922
Cumulative Timesteps: 1,059,337,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1059337700...
Checkpoint 1059337700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,896.30071
Policy Entropy: 1.79507
Value Function Loss: 0.08212

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.31656
Value Function Update Magnitude: 0.29685

Collected Steps per Second: 20,700.20805
Overall Steps per Second: 10,069.25228

Timestep Collection Time: 2.41621
Timestep Consumption Time: 2.55099
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.96720

Cumulative Model Updates: 126,928
Cumulative Timesteps: 1,059,387,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,492.79753
Policy Entropy: 1.75067
Value Function Loss: 0.07507

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.32026
Value Function Update Magnitude: 0.29123

Collected Steps per Second: 20,581.72241
Overall Steps per Second: 10,364.11407

Timestep Collection Time: 2.42944
Timestep Consumption Time: 2.39509
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.82453

Cumulative Model Updates: 126,934
Cumulative Timesteps: 1,059,437,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1059437718...
Checkpoint 1059437718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,443.46582
Policy Entropy: 1.73721
Value Function Loss: 0.07532

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.31850
Value Function Update Magnitude: 0.24110

Collected Steps per Second: 20,231.59572
Overall Steps per Second: 10,275.82755

Timestep Collection Time: 2.47277
Timestep Consumption Time: 2.39575
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.86851

Cumulative Model Updates: 126,940
Cumulative Timesteps: 1,059,487,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,885.48701
Policy Entropy: 1.69857
Value Function Loss: 0.06737

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.31588
Value Function Update Magnitude: 0.26064

Collected Steps per Second: 20,811.16700
Overall Steps per Second: 10,398.91058

Timestep Collection Time: 2.40333
Timestep Consumption Time: 2.40641
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.80973

Cumulative Model Updates: 126,946
Cumulative Timesteps: 1,059,537,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1059537762...
Checkpoint 1059537762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,857.24190
Policy Entropy: 1.71823
Value Function Loss: 0.06206

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.31200
Value Function Update Magnitude: 0.30578

Collected Steps per Second: 19,946.01904
Overall Steps per Second: 10,210.62428

Timestep Collection Time: 2.50807
Timestep Consumption Time: 2.39134
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.89941

Cumulative Model Updates: 126,952
Cumulative Timesteps: 1,059,587,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,123.07998
Policy Entropy: 1.71437
Value Function Loss: 0.06297

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.31099
Value Function Update Magnitude: 0.31772

Collected Steps per Second: 20,570.56284
Overall Steps per Second: 10,225.32641

Timestep Collection Time: 2.43270
Timestep Consumption Time: 2.46123
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.89393

Cumulative Model Updates: 126,958
Cumulative Timesteps: 1,059,637,830

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1059637830...
Checkpoint 1059637830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,195.08708
Policy Entropy: 1.73410
Value Function Loss: 0.06791

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07757
Policy Update Magnitude: 0.30748
Value Function Update Magnitude: 0.32746

Collected Steps per Second: 19,958.25865
Overall Steps per Second: 10,063.26727

Timestep Collection Time: 2.50653
Timestep Consumption Time: 2.46462
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.97115

Cumulative Model Updates: 126,964
Cumulative Timesteps: 1,059,687,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,183.16252
Policy Entropy: 1.74009
Value Function Loss: 0.07637

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.31446
Value Function Update Magnitude: 0.33003

Collected Steps per Second: 21,333.38431
Overall Steps per Second: 10,279.65324

Timestep Collection Time: 2.34374
Timestep Consumption Time: 2.52023
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.86398

Cumulative Model Updates: 126,970
Cumulative Timesteps: 1,059,737,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1059737856...
Checkpoint 1059737856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,638.86730
Policy Entropy: 1.74138
Value Function Loss: 0.07297

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.33243

Collected Steps per Second: 21,013.43955
Overall Steps per Second: 10,329.14364

Timestep Collection Time: 2.38067
Timestep Consumption Time: 2.46252
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.84319

Cumulative Model Updates: 126,976
Cumulative Timesteps: 1,059,787,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,665.22496
Policy Entropy: 1.74269
Value Function Loss: 0.06998

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.30945
Value Function Update Magnitude: 0.33401

Collected Steps per Second: 21,309.57192
Overall Steps per Second: 10,281.09527

Timestep Collection Time: 2.34702
Timestep Consumption Time: 2.51764
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.86466

Cumulative Model Updates: 126,982
Cumulative Timesteps: 1,059,837,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1059837896...
Checkpoint 1059837896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,666.97754
Policy Entropy: 1.72548
Value Function Loss: 0.06320

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.30470
Value Function Update Magnitude: 0.32445

Collected Steps per Second: 20,997.22636
Overall Steps per Second: 10,224.68195

Timestep Collection Time: 2.38203
Timestep Consumption Time: 2.50966
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.89169

Cumulative Model Updates: 126,988
Cumulative Timesteps: 1,059,887,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,450.75738
Policy Entropy: 1.72939
Value Function Loss: 0.06894

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.31026
Value Function Update Magnitude: 0.32857

Collected Steps per Second: 21,119.96974
Overall Steps per Second: 10,281.27563

Timestep Collection Time: 2.36856
Timestep Consumption Time: 2.49698
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.86554

Cumulative Model Updates: 126,994
Cumulative Timesteps: 1,059,937,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1059937936...
Checkpoint 1059937936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,221.49427
Policy Entropy: 1.72780
Value Function Loss: 0.06853

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.31271
Value Function Update Magnitude: 0.34016

Collected Steps per Second: 20,670.97581
Overall Steps per Second: 10,169.89153

Timestep Collection Time: 2.41904
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.91687

Cumulative Model Updates: 127,000
Cumulative Timesteps: 1,059,987,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,649.81092
Policy Entropy: 1.73818
Value Function Loss: 0.07104

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.31330
Value Function Update Magnitude: 0.34958

Collected Steps per Second: 21,238.92934
Overall Steps per Second: 10,231.06896

Timestep Collection Time: 2.35511
Timestep Consumption Time: 2.53392
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.88903

Cumulative Model Updates: 127,006
Cumulative Timesteps: 1,060,037,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1060037960...
Checkpoint 1060037960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,198.21436
Policy Entropy: 1.72670
Value Function Loss: 0.06900

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.31220
Value Function Update Magnitude: 0.33100

Collected Steps per Second: 20,768.37938
Overall Steps per Second: 10,057.11497

Timestep Collection Time: 2.40857
Timestep Consumption Time: 2.56523
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.97379

Cumulative Model Updates: 127,012
Cumulative Timesteps: 1,060,087,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,274.62271
Policy Entropy: 1.69462
Value Function Loss: 0.06219

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.30547
Value Function Update Magnitude: 0.31840

Collected Steps per Second: 21,262.77665
Overall Steps per Second: 10,367.08704

Timestep Collection Time: 2.35228
Timestep Consumption Time: 2.47222
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.82450

Cumulative Model Updates: 127,018
Cumulative Timesteps: 1,060,137,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1060137998...
Checkpoint 1060137998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,963.10828
Policy Entropy: 1.67523
Value Function Loss: 0.05889

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.29066
Value Function Update Magnitude: 0.29829

Collected Steps per Second: 20,879.95093
Overall Steps per Second: 10,235.76704

Timestep Collection Time: 2.39560
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.88679

Cumulative Model Updates: 127,024
Cumulative Timesteps: 1,060,188,018

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,592.34195
Policy Entropy: 1.68309
Value Function Loss: 0.05447

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.28060
Value Function Update Magnitude: 0.30163

Collected Steps per Second: 21,113.63915
Overall Steps per Second: 10,245.92955

Timestep Collection Time: 2.36899
Timestep Consumption Time: 2.51275
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.88174

Cumulative Model Updates: 127,030
Cumulative Timesteps: 1,060,238,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1060238036...
Checkpoint 1060238036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,955.92383
Policy Entropy: 1.69742
Value Function Loss: 0.05779

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.29643
Value Function Update Magnitude: 0.29756

Collected Steps per Second: 21,016.95730
Overall Steps per Second: 10,144.09344

Timestep Collection Time: 2.38084
Timestep Consumption Time: 2.55188
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.93272

Cumulative Model Updates: 127,036
Cumulative Timesteps: 1,060,288,074

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,679.09649
Policy Entropy: 1.70849
Value Function Loss: 0.06326

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.30702
Value Function Update Magnitude: 0.30677

Collected Steps per Second: 21,156.27877
Overall Steps per Second: 10,318.11663

Timestep Collection Time: 2.36450
Timestep Consumption Time: 2.48367
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.84817

Cumulative Model Updates: 127,042
Cumulative Timesteps: 1,060,338,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1060338098...
Checkpoint 1060338098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,216.74684
Policy Entropy: 1.72015
Value Function Loss: 0.07002

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.31881
Value Function Update Magnitude: 0.32995

Collected Steps per Second: 21,001.31828
Overall Steps per Second: 10,151.77617

Timestep Collection Time: 2.38280
Timestep Consumption Time: 2.54658
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.92938

Cumulative Model Updates: 127,048
Cumulative Timesteps: 1,060,388,140

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,583.03861
Policy Entropy: 1.72561
Value Function Loss: 0.07089

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.32065
Value Function Update Magnitude: 0.35342

Collected Steps per Second: 21,009.01561
Overall Steps per Second: 10,176.56451

Timestep Collection Time: 2.38136
Timestep Consumption Time: 2.53484
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.91620

Cumulative Model Updates: 127,054
Cumulative Timesteps: 1,060,438,170

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1060438170...
Checkpoint 1060438170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,347.97601
Policy Entropy: 1.72897
Value Function Loss: 0.06677

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.31814
Value Function Update Magnitude: 0.36094

Collected Steps per Second: 20,860.48217
Overall Steps per Second: 10,190.58869

Timestep Collection Time: 2.39851
Timestep Consumption Time: 2.51132
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.90982

Cumulative Model Updates: 127,060
Cumulative Timesteps: 1,060,488,204

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,634.24770
Policy Entropy: 1.69984
Value Function Loss: 0.06303

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08270
Policy Update Magnitude: 0.31326
Value Function Update Magnitude: 0.34155

Collected Steps per Second: 21,282.89995
Overall Steps per Second: 10,356.53460

Timestep Collection Time: 2.35034
Timestep Consumption Time: 2.47966
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.82999

Cumulative Model Updates: 127,066
Cumulative Timesteps: 1,060,538,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1060538226...
Checkpoint 1060538226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,044.37925
Policy Entropy: 1.70193
Value Function Loss: 0.06844

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.31994
Value Function Update Magnitude: 0.34014

Collected Steps per Second: 21,153.83794
Overall Steps per Second: 10,332.55481

Timestep Collection Time: 2.36430
Timestep Consumption Time: 2.47613
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.84043

Cumulative Model Updates: 127,072
Cumulative Timesteps: 1,060,588,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,912.15349
Policy Entropy: 1.68320
Value Function Loss: 0.06764

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.32506
Value Function Update Magnitude: 0.34365

Collected Steps per Second: 20,869.71032
Overall Steps per Second: 10,105.65445

Timestep Collection Time: 2.39706
Timestep Consumption Time: 2.55324
PPO Batch Consumption Time: 0.29895
Total Iteration Time: 4.95030

Cumulative Model Updates: 127,078
Cumulative Timesteps: 1,060,638,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1060638266...
Checkpoint 1060638266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,887.04363
Policy Entropy: 1.70273
Value Function Loss: 0.06695

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.31806
Value Function Update Magnitude: 0.36460

Collected Steps per Second: 20,749.04535
Overall Steps per Second: 10,129.17636

Timestep Collection Time: 2.41091
Timestep Consumption Time: 2.52770
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.93860

Cumulative Model Updates: 127,084
Cumulative Timesteps: 1,060,688,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,619.87950
Policy Entropy: 1.70678
Value Function Loss: 0.05791

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.30721
Value Function Update Magnitude: 0.36007

Collected Steps per Second: 20,951.50326
Overall Steps per Second: 10,126.31584

Timestep Collection Time: 2.38809
Timestep Consumption Time: 2.55290
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.94099

Cumulative Model Updates: 127,090
Cumulative Timesteps: 1,060,738,324

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1060738324...
Checkpoint 1060738324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,388.94721
Policy Entropy: 1.70846
Value Function Loss: 0.05713

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.30318
Value Function Update Magnitude: 0.33971

Collected Steps per Second: 21,117.22924
Overall Steps per Second: 10,172.27745

Timestep Collection Time: 2.36906
Timestep Consumption Time: 2.54901
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.91807

Cumulative Model Updates: 127,096
Cumulative Timesteps: 1,060,788,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,748.34848
Policy Entropy: 1.69456
Value Function Loss: 0.05801

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.30925
Value Function Update Magnitude: 0.33864

Collected Steps per Second: 21,169.29471
Overall Steps per Second: 10,318.68829

Timestep Collection Time: 2.36219
Timestep Consumption Time: 2.48396
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.84616

Cumulative Model Updates: 127,102
Cumulative Timesteps: 1,060,838,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1060838358...
Checkpoint 1060838358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,003.69059
Policy Entropy: 1.68792
Value Function Loss: 0.05687

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.30703
Value Function Update Magnitude: 0.34042

Collected Steps per Second: 21,172.13924
Overall Steps per Second: 10,291.64091

Timestep Collection Time: 2.36405
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.86336

Cumulative Model Updates: 127,108
Cumulative Timesteps: 1,060,888,410

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,997.92142
Policy Entropy: 1.70744
Value Function Loss: 0.06183

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.30658
Value Function Update Magnitude: 0.33276

Collected Steps per Second: 20,984.28164
Overall Steps per Second: 10,284.27215

Timestep Collection Time: 2.38331
Timestep Consumption Time: 2.47965
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.86296

Cumulative Model Updates: 127,114
Cumulative Timesteps: 1,060,938,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1060938422...
Checkpoint 1060938422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,649.81855
Policy Entropy: 1.71005
Value Function Loss: 0.06516

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.31410
Value Function Update Magnitude: 0.33636

Collected Steps per Second: 21,503.82524
Overall Steps per Second: 10,389.15665

Timestep Collection Time: 2.32647
Timestep Consumption Time: 2.48894
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.81541

Cumulative Model Updates: 127,120
Cumulative Timesteps: 1,060,988,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,099.74961
Policy Entropy: 1.70794
Value Function Loss: 0.06808

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.31891
Value Function Update Magnitude: 0.35855

Collected Steps per Second: 21,084.50409
Overall Steps per Second: 10,217.96883

Timestep Collection Time: 2.37188
Timestep Consumption Time: 2.52243
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.89432

Cumulative Model Updates: 127,126
Cumulative Timesteps: 1,061,038,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1061038460...
Checkpoint 1061038460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,527.09075
Policy Entropy: 1.68404
Value Function Loss: 0.07023

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.32477
Value Function Update Magnitude: 0.37273

Collected Steps per Second: 20,987.83669
Overall Steps per Second: 10,335.79748

Timestep Collection Time: 2.38290
Timestep Consumption Time: 2.45581
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.83872

Cumulative Model Updates: 127,132
Cumulative Timesteps: 1,061,088,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,742.75733
Policy Entropy: 1.68141
Value Function Loss: 0.06747

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.32782
Value Function Update Magnitude: 0.39118

Collected Steps per Second: 20,672.93606
Overall Steps per Second: 10,231.72823

Timestep Collection Time: 2.41920
Timestep Consumption Time: 2.46873
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.88793

Cumulative Model Updates: 127,138
Cumulative Timesteps: 1,061,138,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1061138484...
Checkpoint 1061138484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,173.70919
Policy Entropy: 1.68950
Value Function Loss: 0.06293

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.32141
Value Function Update Magnitude: 0.37593

Collected Steps per Second: 20,583.95902
Overall Steps per Second: 10,252.65242

Timestep Collection Time: 2.42976
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.87815

Cumulative Model Updates: 127,144
Cumulative Timesteps: 1,061,188,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,079.71437
Policy Entropy: 1.68055
Value Function Loss: 0.05862

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.31708
Value Function Update Magnitude: 0.35360

Collected Steps per Second: 20,307.26624
Overall Steps per Second: 10,271.03029

Timestep Collection Time: 2.46345
Timestep Consumption Time: 2.40714
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.87059

Cumulative Model Updates: 127,150
Cumulative Timesteps: 1,061,238,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1061238524...
Checkpoint 1061238524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,741.19159
Policy Entropy: 1.68530
Value Function Loss: 0.06052

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.31194
Value Function Update Magnitude: 0.34480

Collected Steps per Second: 20,369.03945
Overall Steps per Second: 10,233.53104

Timestep Collection Time: 2.45500
Timestep Consumption Time: 2.43148
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.88649

Cumulative Model Updates: 127,156
Cumulative Timesteps: 1,061,288,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,743.70254
Policy Entropy: 1.66822
Value Function Loss: 0.06329

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.31248
Value Function Update Magnitude: 0.35268

Collected Steps per Second: 20,617.44808
Overall Steps per Second: 10,071.25876

Timestep Collection Time: 2.42523
Timestep Consumption Time: 2.53959
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.96482

Cumulative Model Updates: 127,162
Cumulative Timesteps: 1,061,338,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1061338532...
Checkpoint 1061338532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,393.73624
Policy Entropy: 1.68579
Value Function Loss: 0.06707

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.31735
Value Function Update Magnitude: 0.37751

Collected Steps per Second: 21,151.86340
Overall Steps per Second: 10,179.31533

Timestep Collection Time: 2.36433
Timestep Consumption Time: 2.54857
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.91290

Cumulative Model Updates: 127,168
Cumulative Timesteps: 1,061,388,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,771.29563
Policy Entropy: 1.68791
Value Function Loss: 0.06127

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.31720
Value Function Update Magnitude: 0.38879

Collected Steps per Second: 21,187.62277
Overall Steps per Second: 10,386.02465

Timestep Collection Time: 2.36043
Timestep Consumption Time: 2.45488
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.81532

Cumulative Model Updates: 127,174
Cumulative Timesteps: 1,061,438,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1061438554...
Checkpoint 1061438554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,766.05714
Policy Entropy: 1.68694
Value Function Loss: 0.05807

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.31728
Value Function Update Magnitude: 0.36874

Collected Steps per Second: 20,950.03501
Overall Steps per Second: 10,288.98491

Timestep Collection Time: 2.38816
Timestep Consumption Time: 2.47452
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.86268

Cumulative Model Updates: 127,180
Cumulative Timesteps: 1,061,488,586

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,538.54381
Policy Entropy: 1.68334
Value Function Loss: 0.05786

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.30362
Value Function Update Magnitude: 0.33374

Collected Steps per Second: 20,511.38678
Overall Steps per Second: 9,987.52568

Timestep Collection Time: 2.43796
Timestep Consumption Time: 2.56888
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 5.00685

Cumulative Model Updates: 127,186
Cumulative Timesteps: 1,061,538,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1061538592...
Checkpoint 1061538592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,984.45157
Policy Entropy: 1.68198
Value Function Loss: 0.06172

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.28987
Value Function Update Magnitude: 0.30991

Collected Steps per Second: 21,111.88947
Overall Steps per Second: 10,320.63674

Timestep Collection Time: 2.36852
Timestep Consumption Time: 2.47653
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.84505

Cumulative Model Updates: 127,192
Cumulative Timesteps: 1,061,588,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,629.65015
Policy Entropy: 1.69838
Value Function Loss: 0.06466

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.30860
Value Function Update Magnitude: 0.32260

Collected Steps per Second: 21,272.01440
Overall Steps per Second: 10,323.79171

Timestep Collection Time: 2.35088
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.84396

Cumulative Model Updates: 127,198
Cumulative Timesteps: 1,061,638,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1061638604...
Checkpoint 1061638604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,759.78938
Policy Entropy: 1.69145
Value Function Loss: 0.05926

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08584
Policy Update Magnitude: 0.30896
Value Function Update Magnitude: 0.32520

Collected Steps per Second: 21,031.70688
Overall Steps per Second: 10,317.52798

Timestep Collection Time: 2.37765
Timestep Consumption Time: 2.46906
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.84670

Cumulative Model Updates: 127,204
Cumulative Timesteps: 1,061,688,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,353.23117
Policy Entropy: 1.69354
Value Function Loss: 0.06271

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.30786
Value Function Update Magnitude: 0.31998

Collected Steps per Second: 20,360.85180
Overall Steps per Second: 10,027.82036

Timestep Collection Time: 2.45697
Timestep Consumption Time: 2.53175
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.98872

Cumulative Model Updates: 127,210
Cumulative Timesteps: 1,061,738,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1061738636...
Checkpoint 1061738636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,062.01100
Policy Entropy: 1.68888
Value Function Loss: 0.05866

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.30544
Value Function Update Magnitude: 0.32741

Collected Steps per Second: 20,507.09328
Overall Steps per Second: 10,101.59752

Timestep Collection Time: 2.43945
Timestep Consumption Time: 2.51284
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.95229

Cumulative Model Updates: 127,216
Cumulative Timesteps: 1,061,788,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,723.78942
Policy Entropy: 1.68485
Value Function Loss: 0.05907

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.29507
Value Function Update Magnitude: 0.32163

Collected Steps per Second: 21,153.32827
Overall Steps per Second: 9,856.50790

Timestep Collection Time: 2.36502
Timestep Consumption Time: 2.71061
PPO Batch Consumption Time: 0.32303
Total Iteration Time: 5.07563

Cumulative Model Updates: 127,222
Cumulative Timesteps: 1,061,838,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1061838690...
Checkpoint 1061838690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,693.50157
Policy Entropy: 1.70044
Value Function Loss: 0.05893

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.28525
Value Function Update Magnitude: 0.30524

Collected Steps per Second: 20,169.99131
Overall Steps per Second: 10,077.10371

Timestep Collection Time: 2.47933
Timestep Consumption Time: 2.48321
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.96254

Cumulative Model Updates: 127,228
Cumulative Timesteps: 1,061,888,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,353.80238
Policy Entropy: 1.68950
Value Function Loss: 0.05734

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.29023
Value Function Update Magnitude: 0.30400

Collected Steps per Second: 20,500.28632
Overall Steps per Second: 9,991.64194

Timestep Collection Time: 2.44026
Timestep Consumption Time: 2.56653
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 5.00678

Cumulative Model Updates: 127,234
Cumulative Timesteps: 1,061,938,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1061938724...
Checkpoint 1061938724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,647.34673
Policy Entropy: 1.70157
Value Function Loss: 0.05615

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.29823
Value Function Update Magnitude: 0.30003

Collected Steps per Second: 19,158.97874
Overall Steps per Second: 9,724.97099

Timestep Collection Time: 2.61120
Timestep Consumption Time: 2.53308
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 5.14428

Cumulative Model Updates: 127,240
Cumulative Timesteps: 1,061,988,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,852.98091
Policy Entropy: 1.68771
Value Function Loss: 0.05380

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.30535
Value Function Update Magnitude: 0.30409

Collected Steps per Second: 20,783.71607
Overall Steps per Second: 10,179.70632

Timestep Collection Time: 2.40621
Timestep Consumption Time: 2.50650
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.91272

Cumulative Model Updates: 127,246
Cumulative Timesteps: 1,062,038,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1062038762...
Checkpoint 1062038762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,028.82432
Policy Entropy: 1.70158
Value Function Loss: 0.06002

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.30703
Value Function Update Magnitude: 0.32565

Collected Steps per Second: 20,123.54076
Overall Steps per Second: 9,952.59774

Timestep Collection Time: 2.48614
Timestep Consumption Time: 2.54069
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 5.02683

Cumulative Model Updates: 127,252
Cumulative Timesteps: 1,062,088,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,260.40049
Policy Entropy: 1.69952
Value Function Loss: 0.06514

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.31249
Value Function Update Magnitude: 0.32046

Collected Steps per Second: 20,931.61238
Overall Steps per Second: 10,168.99098

Timestep Collection Time: 2.39026
Timestep Consumption Time: 2.52980
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.92006

Cumulative Model Updates: 127,258
Cumulative Timesteps: 1,062,138,824

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1062138824...
Checkpoint 1062138824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,014.40263
Policy Entropy: 1.70583
Value Function Loss: 0.06123

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.31222
Value Function Update Magnitude: 0.32373

Collected Steps per Second: 20,859.50275
Overall Steps per Second: 10,254.27490

Timestep Collection Time: 2.39824
Timestep Consumption Time: 2.48032
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.87855

Cumulative Model Updates: 127,264
Cumulative Timesteps: 1,062,188,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,801.02438
Policy Entropy: 1.69350
Value Function Loss: 0.05649

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.30666
Value Function Update Magnitude: 0.32039

Collected Steps per Second: 20,487.44542
Overall Steps per Second: 10,215.41377

Timestep Collection Time: 2.44189
Timestep Consumption Time: 2.45542
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.89731

Cumulative Model Updates: 127,270
Cumulative Timesteps: 1,062,238,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1062238878...
Checkpoint 1062238878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,454.01883
Policy Entropy: 1.71454
Value Function Loss: 0.05739

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.30605
Value Function Update Magnitude: 0.32190

Collected Steps per Second: 19,873.56912
Overall Steps per Second: 10,015.98832

Timestep Collection Time: 2.51590
Timestep Consumption Time: 2.47611
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.99202

Cumulative Model Updates: 127,276
Cumulative Timesteps: 1,062,288,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,402.60148
Policy Entropy: 1.70189
Value Function Loss: 0.06236

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08286
Policy Update Magnitude: 0.31398
Value Function Update Magnitude: 0.33671

Collected Steps per Second: 20,246.52016
Overall Steps per Second: 10,042.66910

Timestep Collection Time: 2.47114
Timestep Consumption Time: 2.51080
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.98194

Cumulative Model Updates: 127,282
Cumulative Timesteps: 1,062,338,910

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1062338910...
Checkpoint 1062338910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,537.13311
Policy Entropy: 1.71872
Value Function Loss: 0.06727

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.31550
Value Function Update Magnitude: 0.34540

Collected Steps per Second: 19,971.78419
Overall Steps per Second: 9,994.44371

Timestep Collection Time: 2.50363
Timestep Consumption Time: 2.49935
PPO Batch Consumption Time: 0.30113
Total Iteration Time: 5.00298

Cumulative Model Updates: 127,288
Cumulative Timesteps: 1,062,388,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,125.26163
Policy Entropy: 1.70389
Value Function Loss: 0.06368

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.31677
Value Function Update Magnitude: 0.37866

Collected Steps per Second: 20,374.89979
Overall Steps per Second: 10,214.00693

Timestep Collection Time: 2.45498
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.89720

Cumulative Model Updates: 127,294
Cumulative Timesteps: 1,062,438,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1062438932...
Checkpoint 1062438932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,606.94544
Policy Entropy: 1.72425
Value Function Loss: 0.06073

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.31517
Value Function Update Magnitude: 0.36803

Collected Steps per Second: 20,330.51478
Overall Steps per Second: 10,301.71874

Timestep Collection Time: 2.45975
Timestep Consumption Time: 2.39458
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.85434

Cumulative Model Updates: 127,300
Cumulative Timesteps: 1,062,488,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,103.17030
Policy Entropy: 1.72686
Value Function Loss: 0.06072

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.30945
Value Function Update Magnitude: 0.37060

Collected Steps per Second: 20,136.75228
Overall Steps per Second: 10,035.27556

Timestep Collection Time: 2.48372
Timestep Consumption Time: 2.50010
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.98382

Cumulative Model Updates: 127,306
Cumulative Timesteps: 1,062,538,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1062538954...
Checkpoint 1062538954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,071.75037
Policy Entropy: 1.73714
Value Function Loss: 0.06080

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.30579
Value Function Update Magnitude: 0.35726

Collected Steps per Second: 19,909.37585
Overall Steps per Second: 10,096.91920

Timestep Collection Time: 2.51269
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.95458

Cumulative Model Updates: 127,312
Cumulative Timesteps: 1,062,588,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,660.56873
Policy Entropy: 1.72386
Value Function Loss: 0.05798

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.30995
Value Function Update Magnitude: 0.35122

Collected Steps per Second: 20,477.45298
Overall Steps per Second: 10,084.79880

Timestep Collection Time: 2.44269
Timestep Consumption Time: 2.51725
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.95994

Cumulative Model Updates: 127,318
Cumulative Timesteps: 1,062,639,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1062639000...
Checkpoint 1062639000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,233.36947
Policy Entropy: 1.71794
Value Function Loss: 0.05460

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.30264
Value Function Update Magnitude: 0.35597

Collected Steps per Second: 20,505.16472
Overall Steps per Second: 10,274.58090

Timestep Collection Time: 2.43958
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.86871

Cumulative Model Updates: 127,324
Cumulative Timesteps: 1,062,689,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,861.03504
Policy Entropy: 1.72043
Value Function Loss: 0.05638

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.36556

Collected Steps per Second: 21,278.69569
Overall Steps per Second: 10,190.19615

Timestep Collection Time: 2.35061
Timestep Consumption Time: 2.55783
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.90844

Cumulative Model Updates: 127,330
Cumulative Timesteps: 1,062,739,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1062739042...
Checkpoint 1062739042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,862.07916
Policy Entropy: 1.71981
Value Function Loss: 0.05839

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.30972
Value Function Update Magnitude: 0.37028

Collected Steps per Second: 20,762.68214
Overall Steps per Second: 10,135.43432

Timestep Collection Time: 2.40884
Timestep Consumption Time: 2.52573
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.93457

Cumulative Model Updates: 127,336
Cumulative Timesteps: 1,062,789,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,660.78369
Policy Entropy: 1.71019
Value Function Loss: 0.06110

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.30976
Value Function Update Magnitude: 0.35826

Collected Steps per Second: 21,122.39344
Overall Steps per Second: 9,801.67042

Timestep Collection Time: 2.36772
Timestep Consumption Time: 2.73467
PPO Batch Consumption Time: 0.32253
Total Iteration Time: 5.10240

Cumulative Model Updates: 127,342
Cumulative Timesteps: 1,062,839,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1062839068...
Checkpoint 1062839068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,969.18685
Policy Entropy: 1.70122
Value Function Loss: 0.05943

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.31367
Value Function Update Magnitude: 0.36145

Collected Steps per Second: 17,043.11611
Overall Steps per Second: 8,854.94580

Timestep Collection Time: 2.93514
Timestep Consumption Time: 2.71413
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 5.64927

Cumulative Model Updates: 127,348
Cumulative Timesteps: 1,062,889,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,924.52238
Policy Entropy: 1.70713
Value Function Loss: 0.05458

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.31236
Value Function Update Magnitude: 0.35511

Collected Steps per Second: 20,179.90792
Overall Steps per Second: 9,848.85591

Timestep Collection Time: 2.47771
Timestep Consumption Time: 2.59902
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 5.07673

Cumulative Model Updates: 127,354
Cumulative Timesteps: 1,062,939,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1062939092...
Checkpoint 1062939092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,170.12069
Policy Entropy: 1.71812
Value Function Loss: 0.05714

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.31093
Value Function Update Magnitude: 0.30993

Collected Steps per Second: 20,739.14051
Overall Steps per Second: 10,216.18875

Timestep Collection Time: 2.41225
Timestep Consumption Time: 2.48468
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.89693

Cumulative Model Updates: 127,360
Cumulative Timesteps: 1,062,989,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,073.09549
Policy Entropy: 1.72837
Value Function Loss: 0.05866

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.31028
Value Function Update Magnitude: 0.24262

Collected Steps per Second: 21,362.00417
Overall Steps per Second: 10,410.48541

Timestep Collection Time: 2.34117
Timestep Consumption Time: 2.46284
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.80400

Cumulative Model Updates: 127,366
Cumulative Timesteps: 1,063,039,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1063039132...
Checkpoint 1063039132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,259.04877
Policy Entropy: 1.72357
Value Function Loss: 0.06071

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.30828
Value Function Update Magnitude: 0.26583

Collected Steps per Second: 22,037.62132
Overall Steps per Second: 10,587.45316

Timestep Collection Time: 2.26985
Timestep Consumption Time: 2.45480
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.72465

Cumulative Model Updates: 127,372
Cumulative Timesteps: 1,063,089,154

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,918.24215
Policy Entropy: 1.70642
Value Function Loss: 0.05497

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.30307
Value Function Update Magnitude: 0.31835

Collected Steps per Second: 21,958.07130
Overall Steps per Second: 10,418.85032

Timestep Collection Time: 2.27770
Timestep Consumption Time: 2.52263
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.80034

Cumulative Model Updates: 127,378
Cumulative Timesteps: 1,063,139,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1063139168...
Checkpoint 1063139168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,976.46086
Policy Entropy: 1.69560
Value Function Loss: 0.05686

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08004
Policy Update Magnitude: 0.30436
Value Function Update Magnitude: 0.31981

Collected Steps per Second: 21,945.25203
Overall Steps per Second: 10,496.88657

Timestep Collection Time: 2.27849
Timestep Consumption Time: 2.48502
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.76351

Cumulative Model Updates: 127,384
Cumulative Timesteps: 1,063,189,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,339.27795
Policy Entropy: 1.68894
Value Function Loss: 0.05885

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.30724
Value Function Update Magnitude: 0.31363

Collected Steps per Second: 21,832.87949
Overall Steps per Second: 10,399.39593

Timestep Collection Time: 2.29122
Timestep Consumption Time: 2.51906
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.81028

Cumulative Model Updates: 127,390
Cumulative Timesteps: 1,063,239,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1063239194...
Checkpoint 1063239194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,749.94216
Policy Entropy: 1.69257
Value Function Loss: 0.06654

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.31635
Value Function Update Magnitude: 0.32440

Collected Steps per Second: 22,024.46017
Overall Steps per Second: 10,275.56631

Timestep Collection Time: 2.27129
Timestep Consumption Time: 2.59695
PPO Batch Consumption Time: 0.30800
Total Iteration Time: 4.86825

Cumulative Model Updates: 127,396
Cumulative Timesteps: 1,063,289,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,983.35288
Policy Entropy: 1.68338
Value Function Loss: 0.05994

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.31181
Value Function Update Magnitude: 0.31652

Collected Steps per Second: 19,224.85871
Overall Steps per Second: 9,803.32306

Timestep Collection Time: 2.60194
Timestep Consumption Time: 2.50061
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 5.10256

Cumulative Model Updates: 127,402
Cumulative Timesteps: 1,063,339,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1063339240...
Checkpoint 1063339240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,839.46514
Policy Entropy: 1.68126
Value Function Loss: 0.05959

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.30795
Value Function Update Magnitude: 0.26036

Collected Steps per Second: 21,353.25074
Overall Steps per Second: 10,300.95577

Timestep Collection Time: 2.34269
Timestep Consumption Time: 2.51356
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.85625

Cumulative Model Updates: 127,408
Cumulative Timesteps: 1,063,389,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,734.18195
Policy Entropy: 1.68081
Value Function Loss: 0.05366

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.30688
Value Function Update Magnitude: 0.21993

Collected Steps per Second: 20,955.99894
Overall Steps per Second: 10,397.84408

Timestep Collection Time: 2.38786
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.81254

Cumulative Model Updates: 127,414
Cumulative Timesteps: 1,063,439,304

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1063439304...
Checkpoint 1063439304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,955.59516
Policy Entropy: 1.68770
Value Function Loss: 0.05778

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.30548
Value Function Update Magnitude: 0.26537

Collected Steps per Second: 21,007.30485
Overall Steps per Second: 10,558.78559

Timestep Collection Time: 2.38098
Timestep Consumption Time: 2.35612
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.73710

Cumulative Model Updates: 127,420
Cumulative Timesteps: 1,063,489,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,890.88102
Policy Entropy: 1.72200
Value Function Loss: 0.05076

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.29807
Value Function Update Magnitude: 0.29994

Collected Steps per Second: 21,367.34715
Overall Steps per Second: 10,583.16732

Timestep Collection Time: 2.34255
Timestep Consumption Time: 2.38704
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.72959

Cumulative Model Updates: 127,426
Cumulative Timesteps: 1,063,539,376

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1063539376...
Checkpoint 1063539376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,593.94912
Policy Entropy: 1.71455
Value Function Loss: 0.04630

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.28761
Value Function Update Magnitude: 0.29301

Collected Steps per Second: 21,217.29975
Overall Steps per Second: 10,488.41712

Timestep Collection Time: 2.35845
Timestep Consumption Time: 2.41252
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.77098

Cumulative Model Updates: 127,432
Cumulative Timesteps: 1,063,589,416

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,785.97081
Policy Entropy: 1.71782
Value Function Loss: 0.04736

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.28915
Value Function Update Magnitude: 0.29124

Collected Steps per Second: 20,915.85528
Overall Steps per Second: 10,271.81293

Timestep Collection Time: 2.39063
Timestep Consumption Time: 2.47726
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.86788

Cumulative Model Updates: 127,438
Cumulative Timesteps: 1,063,639,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1063639418...
Checkpoint 1063639418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,224.54658
Policy Entropy: 1.68606
Value Function Loss: 0.05036

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.29635
Value Function Update Magnitude: 0.30313

Collected Steps per Second: 21,927.11766
Overall Steps per Second: 10,465.90918

Timestep Collection Time: 2.28056
Timestep Consumption Time: 2.49743
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.77799

Cumulative Model Updates: 127,444
Cumulative Timesteps: 1,063,689,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,734.64940
Policy Entropy: 1.68685
Value Function Loss: 0.05172

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.29976
Value Function Update Magnitude: 0.31178

Collected Steps per Second: 21,808.29107
Overall Steps per Second: 10,427.12090

Timestep Collection Time: 2.29371
Timestep Consumption Time: 2.50358
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.79730

Cumulative Model Updates: 127,450
Cumulative Timesteps: 1,063,739,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1063739446...
Checkpoint 1063739446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,790.20575
Policy Entropy: 1.69247
Value Function Loss: 0.05131

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07356
Policy Update Magnitude: 0.30051
Value Function Update Magnitude: 0.31584

Collected Steps per Second: 21,464.52515
Overall Steps per Second: 10,362.23146

Timestep Collection Time: 2.33036
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.82715

Cumulative Model Updates: 127,456
Cumulative Timesteps: 1,063,789,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,682.91293
Policy Entropy: 1.71079
Value Function Loss: 0.05178

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.30028
Value Function Update Magnitude: 0.29162

Collected Steps per Second: 21,877.66290
Overall Steps per Second: 10,421.28046

Timestep Collection Time: 2.28662
Timestep Consumption Time: 2.51375
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.80037

Cumulative Model Updates: 127,462
Cumulative Timesteps: 1,063,839,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1063839492...
Checkpoint 1063839492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,239.04394
Policy Entropy: 1.70149
Value Function Loss: 0.05030

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.29859
Value Function Update Magnitude: 0.28343

Collected Steps per Second: 21,304.06945
Overall Steps per Second: 10,487.01141

Timestep Collection Time: 2.34716
Timestep Consumption Time: 2.42103
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.76818

Cumulative Model Updates: 127,468
Cumulative Timesteps: 1,063,889,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,015.07326
Policy Entropy: 1.70860
Value Function Loss: 0.05470

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.29194
Value Function Update Magnitude: 0.29590

Collected Steps per Second: 21,261.50913
Overall Steps per Second: 10,433.64550

Timestep Collection Time: 2.35308
Timestep Consumption Time: 2.44199
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.79506

Cumulative Model Updates: 127,474
Cumulative Timesteps: 1,063,939,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1063939526...
Checkpoint 1063939526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,486.67419
Policy Entropy: 1.68853
Value Function Loss: 0.05092

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.29008
Value Function Update Magnitude: 0.30661

Collected Steps per Second: 21,163.20405
Overall Steps per Second: 10,261.19694

Timestep Collection Time: 2.36476
Timestep Consumption Time: 2.51244
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.87721

Cumulative Model Updates: 127,480
Cumulative Timesteps: 1,063,989,572

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,993.52908
Policy Entropy: 1.68979
Value Function Loss: 0.05525

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07678
Policy Update Magnitude: 0.29677
Value Function Update Magnitude: 0.31958

Collected Steps per Second: 21,402.96280
Overall Steps per Second: 10,454.59159

Timestep Collection Time: 2.33641
Timestep Consumption Time: 2.44676
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.78316

Cumulative Model Updates: 127,486
Cumulative Timesteps: 1,064,039,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1064039578...
Checkpoint 1064039578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,972.82586
Policy Entropy: 1.66409
Value Function Loss: 0.05008

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07705
Policy Update Magnitude: 0.29973
Value Function Update Magnitude: 0.31702

Collected Steps per Second: 21,024.35895
Overall Steps per Second: 10,207.65128

Timestep Collection Time: 2.37924
Timestep Consumption Time: 2.52120
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.90044

Cumulative Model Updates: 127,492
Cumulative Timesteps: 1,064,089,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,198.81765
Policy Entropy: 1.67683
Value Function Loss: 0.05360

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.29680
Value Function Update Magnitude: 0.29138

Collected Steps per Second: 21,720.30289
Overall Steps per Second: 10,445.16740

Timestep Collection Time: 2.30236
Timestep Consumption Time: 2.48531
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.78767

Cumulative Model Updates: 127,498
Cumulative Timesteps: 1,064,139,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1064139608...
Checkpoint 1064139608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,116.07321
Policy Entropy: 1.68939
Value Function Loss: 0.05079

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.29505
Value Function Update Magnitude: 0.29351

Collected Steps per Second: 21,814.62264
Overall Steps per Second: 10,408.30574

Timestep Collection Time: 2.29287
Timestep Consumption Time: 2.51272
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.80559

Cumulative Model Updates: 127,504
Cumulative Timesteps: 1,064,189,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,454.30929
Policy Entropy: 1.70187
Value Function Loss: 0.06529

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.30925
Value Function Update Magnitude: 0.28979

Collected Steps per Second: 21,829.30921
Overall Steps per Second: 10,392.04310

Timestep Collection Time: 2.29096
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.81234

Cumulative Model Updates: 127,510
Cumulative Timesteps: 1,064,239,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1064239636...
Checkpoint 1064239636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.83119
Policy Entropy: 1.70271
Value Function Loss: 0.06720

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.31929
Value Function Update Magnitude: 0.32813

Collected Steps per Second: 21,151.55128
Overall Steps per Second: 10,575.71929

Timestep Collection Time: 2.36455
Timestep Consumption Time: 2.36458
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.72913

Cumulative Model Updates: 127,516
Cumulative Timesteps: 1,064,289,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,941.17713
Policy Entropy: 1.69561
Value Function Loss: 0.06461

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.30117
Value Function Update Magnitude: 0.36269

Collected Steps per Second: 21,313.13724
Overall Steps per Second: 10,390.93191

Timestep Collection Time: 2.34691
Timestep Consumption Time: 2.46690
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.81381

Cumulative Model Updates: 127,522
Cumulative Timesteps: 1,064,339,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1064339670...
Checkpoint 1064339670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,841.44117
Policy Entropy: 1.69247
Value Function Loss: 0.05396

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.29152
Value Function Update Magnitude: 0.35379

Collected Steps per Second: 20,970.28387
Overall Steps per Second: 10,378.10340

Timestep Collection Time: 2.38585
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.82092

Cumulative Model Updates: 127,528
Cumulative Timesteps: 1,064,389,702

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,385.80453
Policy Entropy: 1.68481
Value Function Loss: 0.05003

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.29534
Value Function Update Magnitude: 0.33145

Collected Steps per Second: 21,260.25500
Overall Steps per Second: 10,292.83142

Timestep Collection Time: 2.35256
Timestep Consumption Time: 2.50675
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.85930

Cumulative Model Updates: 127,534
Cumulative Timesteps: 1,064,439,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1064439718...
Checkpoint 1064439718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,065.94750
Policy Entropy: 1.68834
Value Function Loss: 0.05258

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07755
Policy Update Magnitude: 0.29448
Value Function Update Magnitude: 0.31544

Collected Steps per Second: 21,596.51471
Overall Steps per Second: 10,563.35127

Timestep Collection Time: 2.31537
Timestep Consumption Time: 2.41835
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.73373

Cumulative Model Updates: 127,540
Cumulative Timesteps: 1,064,489,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,085.35612
Policy Entropy: 1.68591
Value Function Loss: 0.05285

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.29830
Value Function Update Magnitude: 0.31124

Collected Steps per Second: 21,251.38888
Overall Steps per Second: 10,443.82693

Timestep Collection Time: 2.35279
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.78752

Cumulative Model Updates: 127,546
Cumulative Timesteps: 1,064,539,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1064539722...
Checkpoint 1064539722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,560.16259
Policy Entropy: 1.70124
Value Function Loss: 0.05247

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.29894
Value Function Update Magnitude: 0.32001

Collected Steps per Second: 21,075.12380
Overall Steps per Second: 10,253.88295

Timestep Collection Time: 2.37275
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.87679

Cumulative Model Updates: 127,552
Cumulative Timesteps: 1,064,589,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,362.24581
Policy Entropy: 1.69609
Value Function Loss: 0.05511

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.30134
Value Function Update Magnitude: 0.33307

Collected Steps per Second: 21,408.85201
Overall Steps per Second: 10,533.36682

Timestep Collection Time: 2.33772
Timestep Consumption Time: 2.41365
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.75138

Cumulative Model Updates: 127,558
Cumulative Timesteps: 1,064,639,776

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1064639776...
Checkpoint 1064639776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,632.95046
Policy Entropy: 1.69220
Value Function Loss: 0.05494

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.30684
Value Function Update Magnitude: 0.33795

Collected Steps per Second: 21,078.34987
Overall Steps per Second: 10,218.28811

Timestep Collection Time: 2.37267
Timestep Consumption Time: 2.52169
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.89436

Cumulative Model Updates: 127,564
Cumulative Timesteps: 1,064,689,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,189.66862
Policy Entropy: 1.67353
Value Function Loss: 0.05650

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.30945
Value Function Update Magnitude: 0.33138

Collected Steps per Second: 21,406.56293
Overall Steps per Second: 10,437.93286

Timestep Collection Time: 2.33676
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.79233

Cumulative Model Updates: 127,570
Cumulative Timesteps: 1,064,739,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1064739810...
Checkpoint 1064739810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,720.08471
Policy Entropy: 1.67413
Value Function Loss: 0.05930

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.30905
Value Function Update Magnitude: 0.32471

Collected Steps per Second: 21,698.73921
Overall Steps per Second: 10,483.29371

Timestep Collection Time: 2.30603
Timestep Consumption Time: 2.46709
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.77312

Cumulative Model Updates: 127,576
Cumulative Timesteps: 1,064,789,848

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,539.30043
Policy Entropy: 1.66974
Value Function Loss: 0.05982

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.31031
Value Function Update Magnitude: 0.34044

Collected Steps per Second: 21,848.69018
Overall Steps per Second: 10,522.84265

Timestep Collection Time: 2.29011
Timestep Consumption Time: 2.46487
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.75499

Cumulative Model Updates: 127,582
Cumulative Timesteps: 1,064,839,884

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1064839884...
Checkpoint 1064839884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,120.76555
Policy Entropy: 1.68590
Value Function Loss: 0.06043

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.31025
Value Function Update Magnitude: 0.32679

Collected Steps per Second: 21,359.79202
Overall Steps per Second: 10,156.24914

Timestep Collection Time: 2.34150
Timestep Consumption Time: 2.58295
PPO Batch Consumption Time: 0.30658
Total Iteration Time: 4.92446

Cumulative Model Updates: 127,588
Cumulative Timesteps: 1,064,889,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,220.79676
Policy Entropy: 1.68203
Value Function Loss: 0.05675

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.30537
Value Function Update Magnitude: 0.30710

Collected Steps per Second: 21,884.39648
Overall Steps per Second: 10,531.55050

Timestep Collection Time: 2.28620
Timestep Consumption Time: 2.46448
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.75068

Cumulative Model Updates: 127,594
Cumulative Timesteps: 1,064,939,930

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1064939930...
Checkpoint 1064939930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,052.41480
Policy Entropy: 1.68042
Value Function Loss: 0.05681

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.30892
Value Function Update Magnitude: 0.31425

Collected Steps per Second: 21,706.06740
Overall Steps per Second: 10,390.40083

Timestep Collection Time: 2.30535
Timestep Consumption Time: 2.51064
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.81598

Cumulative Model Updates: 127,600
Cumulative Timesteps: 1,064,989,970

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,035.70732
Policy Entropy: 1.67170
Value Function Loss: 0.05227

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.30618
Value Function Update Magnitude: 0.32594

Collected Steps per Second: 21,975.78095
Overall Steps per Second: 10,484.86078

Timestep Collection Time: 2.27623
Timestep Consumption Time: 2.49465
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.77088

Cumulative Model Updates: 127,606
Cumulative Timesteps: 1,065,039,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1065039992...
Checkpoint 1065039992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,594.18150
Policy Entropy: 1.66579
Value Function Loss: 0.05263

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.30479
Value Function Update Magnitude: 0.31331

Collected Steps per Second: 21,816.63404
Overall Steps per Second: 10,430.51597

Timestep Collection Time: 2.29302
Timestep Consumption Time: 2.50310
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.79612

Cumulative Model Updates: 127,612
Cumulative Timesteps: 1,065,090,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,442.70672
Policy Entropy: 1.66919
Value Function Loss: 0.04997

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07755
Policy Update Magnitude: 0.30366
Value Function Update Magnitude: 0.31114

Collected Steps per Second: 22,010.40313
Overall Steps per Second: 10,472.84169

Timestep Collection Time: 2.27347
Timestep Consumption Time: 2.50460
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.77807

Cumulative Model Updates: 127,618
Cumulative Timesteps: 1,065,140,058

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1065140058...
Checkpoint 1065140058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,624.61203
Policy Entropy: 1.67334
Value Function Loss: 0.05063

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.30265
Value Function Update Magnitude: 0.30581

Collected Steps per Second: 20,766.24504
Overall Steps per Second: 10,261.00019

Timestep Collection Time: 2.40833
Timestep Consumption Time: 2.46566
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.87399

Cumulative Model Updates: 127,624
Cumulative Timesteps: 1,065,190,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,790.29175
Policy Entropy: 1.66533
Value Function Loss: 0.05440

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08756
Policy Update Magnitude: 0.30973
Value Function Update Magnitude: 0.29579

Collected Steps per Second: 21,500.83904
Overall Steps per Second: 10,389.97902

Timestep Collection Time: 2.32623
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.81387

Cumulative Model Updates: 127,630
Cumulative Timesteps: 1,065,240,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1065240086...
Checkpoint 1065240086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,459.73683
Policy Entropy: 1.67584
Value Function Loss: 0.06197

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.31684
Value Function Update Magnitude: 0.31131

Collected Steps per Second: 21,183.73178
Overall Steps per Second: 10,213.95104

Timestep Collection Time: 2.36040
Timestep Consumption Time: 2.53506
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.89546

Cumulative Model Updates: 127,636
Cumulative Timesteps: 1,065,290,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,041.86309
Policy Entropy: 1.67417
Value Function Loss: 0.06433

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.31971
Value Function Update Magnitude: 0.30647

Collected Steps per Second: 21,329.33132
Overall Steps per Second: 10,429.49017

Timestep Collection Time: 2.34522
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.79621

Cumulative Model Updates: 127,642
Cumulative Timesteps: 1,065,340,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1065340110...
Checkpoint 1065340110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,966.61242
Policy Entropy: 1.68862
Value Function Loss: 0.05970

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.30017
Value Function Update Magnitude: 0.28106

Collected Steps per Second: 21,104.92778
Overall Steps per Second: 10,225.07533

Timestep Collection Time: 2.37006
Timestep Consumption Time: 2.52183
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.89190

Cumulative Model Updates: 127,648
Cumulative Timesteps: 1,065,390,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,026.27190
Policy Entropy: 1.66523
Value Function Loss: 0.05375

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.29777
Value Function Update Magnitude: 0.30209

Collected Steps per Second: 21,835.10140
Overall Steps per Second: 10,455.08803

Timestep Collection Time: 2.28989
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.78236

Cumulative Model Updates: 127,654
Cumulative Timesteps: 1,065,440,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1065440130...
Checkpoint 1065440130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,550.19665
Policy Entropy: 1.65100
Value Function Loss: 0.05392

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.30248
Value Function Update Magnitude: 0.29684

Collected Steps per Second: 21,557.66151
Overall Steps per Second: 10,261.86908

Timestep Collection Time: 2.32020
Timestep Consumption Time: 2.55396
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.87416

Cumulative Model Updates: 127,660
Cumulative Timesteps: 1,065,490,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,600.27856
Policy Entropy: 1.66169
Value Function Loss: 0.06124

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.31192
Value Function Update Magnitude: 0.31896

Collected Steps per Second: 21,057.53388
Overall Steps per Second: 10,188.10944

Timestep Collection Time: 2.37483
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.30586
Total Iteration Time: 4.90847

Cumulative Model Updates: 127,666
Cumulative Timesteps: 1,065,540,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1065540156...
Checkpoint 1065540156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,610.82365
Policy Entropy: 1.67166
Value Function Loss: 0.06060

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.32094
Value Function Update Magnitude: 0.36914

Collected Steps per Second: 21,113.20041
Overall Steps per Second: 10,383.74020

Timestep Collection Time: 2.36894
Timestep Consumption Time: 2.44782
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.81676

Cumulative Model Updates: 127,672
Cumulative Timesteps: 1,065,590,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,865.38972
Policy Entropy: 1.68256
Value Function Loss: 0.06086

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.32051
Value Function Update Magnitude: 0.35297

Collected Steps per Second: 21,274.40184
Overall Steps per Second: 10,479.19938

Timestep Collection Time: 2.35081
Timestep Consumption Time: 2.42170
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.77250

Cumulative Model Updates: 127,678
Cumulative Timesteps: 1,065,640,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1065640184...
Checkpoint 1065640184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,362.15204
Policy Entropy: 1.68330
Value Function Loss: 0.05993

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.31601
Value Function Update Magnitude: 0.36167

Collected Steps per Second: 20,840.64865
Overall Steps per Second: 10,368.24814

Timestep Collection Time: 2.40050
Timestep Consumption Time: 2.42461
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.82512

Cumulative Model Updates: 127,684
Cumulative Timesteps: 1,065,690,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,469.44406
Policy Entropy: 1.68757
Value Function Loss: 0.06018

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.31572
Value Function Update Magnitude: 0.37640

Collected Steps per Second: 21,473.03621
Overall Steps per Second: 10,665.19905

Timestep Collection Time: 2.32981
Timestep Consumption Time: 2.36096
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.69077

Cumulative Model Updates: 127,690
Cumulative Timesteps: 1,065,740,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1065740240...
Checkpoint 1065740240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,571.51144
Policy Entropy: 1.69590
Value Function Loss: 0.05472

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.31147
Value Function Update Magnitude: 0.35211

Collected Steps per Second: 20,938.10183
Overall Steps per Second: 10,241.53800

Timestep Collection Time: 2.38818
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.88247

Cumulative Model Updates: 127,696
Cumulative Timesteps: 1,065,790,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,196.87293
Policy Entropy: 1.67218
Value Function Loss: 0.05313

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.30640
Value Function Update Magnitude: 0.31911

Collected Steps per Second: 21,703.55549
Overall Steps per Second: 10,467.46316

Timestep Collection Time: 2.30395
Timestep Consumption Time: 2.47313
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.77709

Cumulative Model Updates: 127,702
Cumulative Timesteps: 1,065,840,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1065840248...
Checkpoint 1065840248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,747.35659
Policy Entropy: 1.65579
Value Function Loss: 0.05478

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07709
Policy Update Magnitude: 0.31108
Value Function Update Magnitude: 0.33353

Collected Steps per Second: 21,179.89327
Overall Steps per Second: 10,327.00169

Timestep Collection Time: 2.36120
Timestep Consumption Time: 2.48144
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.84264

Cumulative Model Updates: 127,708
Cumulative Timesteps: 1,065,890,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,907.84028
Policy Entropy: 1.66068
Value Function Loss: 0.06006

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07824
Policy Update Magnitude: 0.31943
Value Function Update Magnitude: 0.35631

Collected Steps per Second: 21,782.11025
Overall Steps per Second: 10,434.27316

Timestep Collection Time: 2.29592
Timestep Consumption Time: 2.49694
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.79286

Cumulative Model Updates: 127,714
Cumulative Timesteps: 1,065,940,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1065940268...
Checkpoint 1065940268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,929.26496
Policy Entropy: 1.66418
Value Function Loss: 0.06249

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.31951
Value Function Update Magnitude: 0.37169

Collected Steps per Second: 21,284.14965
Overall Steps per Second: 10,439.81765

Timestep Collection Time: 2.35020
Timestep Consumption Time: 2.44126
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.79146

Cumulative Model Updates: 127,720
Cumulative Timesteps: 1,065,990,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,617.00898
Policy Entropy: 1.67124
Value Function Loss: 0.05754

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.31087
Value Function Update Magnitude: 0.36615

Collected Steps per Second: 21,080.12525
Overall Steps per Second: 10,278.37868

Timestep Collection Time: 2.37276
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.86633

Cumulative Model Updates: 127,726
Cumulative Timesteps: 1,066,040,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1066040308...
Checkpoint 1066040308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,821.98602
Policy Entropy: 1.65924
Value Function Loss: 0.05618

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.30660
Value Function Update Magnitude: 0.34545

Collected Steps per Second: 21,166.33819
Overall Steps per Second: 10,417.37916

Timestep Collection Time: 2.36300
Timestep Consumption Time: 2.43821
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.80121

Cumulative Model Updates: 127,732
Cumulative Timesteps: 1,066,090,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,708.54552
Policy Entropy: 1.66934
Value Function Loss: 0.05332

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.30707
Value Function Update Magnitude: 0.31916

Collected Steps per Second: 22,023.30329
Overall Steps per Second: 10,439.06580

Timestep Collection Time: 2.27205
Timestep Consumption Time: 2.52129
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.79334

Cumulative Model Updates: 127,738
Cumulative Timesteps: 1,066,140,362

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1066140362...
Checkpoint 1066140362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,593.10707
Policy Entropy: 1.67075
Value Function Loss: 0.05319

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.30390
Value Function Update Magnitude: 0.31157

Collected Steps per Second: 21,552.04262
Overall Steps per Second: 10,138.39998

Timestep Collection Time: 2.32108
Timestep Consumption Time: 2.61303
PPO Batch Consumption Time: 0.30760
Total Iteration Time: 4.93411

Cumulative Model Updates: 127,744
Cumulative Timesteps: 1,066,190,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,707.28217
Policy Entropy: 1.68369
Value Function Loss: 0.05416

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.30337
Value Function Update Magnitude: 0.31210

Collected Steps per Second: 21,950.58240
Overall Steps per Second: 10,578.23788

Timestep Collection Time: 2.27857
Timestep Consumption Time: 2.44962
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.72820

Cumulative Model Updates: 127,750
Cumulative Timesteps: 1,066,240,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1066240402...
Checkpoint 1066240402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,334.24556
Policy Entropy: 1.68880
Value Function Loss: 0.05093

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.29901
Value Function Update Magnitude: 0.30657

Collected Steps per Second: 21,615.52055
Overall Steps per Second: 10,376.78483

Timestep Collection Time: 2.31417
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.82057

Cumulative Model Updates: 127,756
Cumulative Timesteps: 1,066,290,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,376.30045
Policy Entropy: 1.68921
Value Function Loss: 0.05466

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.29874
Value Function Update Magnitude: 0.28659

Collected Steps per Second: 22,000.32872
Overall Steps per Second: 10,460.80207

Timestep Collection Time: 2.27369
Timestep Consumption Time: 2.50816
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.78185

Cumulative Model Updates: 127,762
Cumulative Timesteps: 1,066,340,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1066340446...
Checkpoint 1066340446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,113.02519
Policy Entropy: 1.69152
Value Function Loss: 0.05440

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07660
Policy Update Magnitude: 0.30432
Value Function Update Magnitude: 0.27590

Collected Steps per Second: 21,491.16245
Overall Steps per Second: 10,469.93655

Timestep Collection Time: 2.32682
Timestep Consumption Time: 2.44933
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.77615

Cumulative Model Updates: 127,768
Cumulative Timesteps: 1,066,390,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,386.85817
Policy Entropy: 1.68712
Value Function Loss: 0.05324

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.30089
Value Function Update Magnitude: 0.30138

Collected Steps per Second: 22,013.34859
Overall Steps per Second: 10,478.01947

Timestep Collection Time: 2.27199
Timestep Consumption Time: 2.50125
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.77323

Cumulative Model Updates: 127,774
Cumulative Timesteps: 1,066,440,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1066440466...
Checkpoint 1066440466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,453.84380
Policy Entropy: 1.68845
Value Function Loss: 0.05241

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07454
Policy Update Magnitude: 0.30129
Value Function Update Magnitude: 0.30012

Collected Steps per Second: 21,703.26445
Overall Steps per Second: 10,572.25300

Timestep Collection Time: 2.30417
Timestep Consumption Time: 2.42595
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.73012

Cumulative Model Updates: 127,780
Cumulative Timesteps: 1,066,490,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,943.21738
Policy Entropy: 1.67396
Value Function Loss: 0.05433

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.30480
Value Function Update Magnitude: 0.29568

Collected Steps per Second: 21,396.06250
Overall Steps per Second: 10,465.57106

Timestep Collection Time: 2.33828
Timestep Consumption Time: 2.44216
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.78044

Cumulative Model Updates: 127,786
Cumulative Timesteps: 1,066,540,504

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1066540504...
Checkpoint 1066540504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,250.51370
Policy Entropy: 1.66120
Value Function Loss: 0.05884

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.31071
Value Function Update Magnitude: 0.30288

Collected Steps per Second: 21,141.46228
Overall Steps per Second: 10,253.67798

Timestep Collection Time: 2.36587
Timestep Consumption Time: 2.51218
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.87805

Cumulative Model Updates: 127,792
Cumulative Timesteps: 1,066,590,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,316.55305
Policy Entropy: 1.67153
Value Function Loss: 0.06227

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.31747
Value Function Update Magnitude: 0.28788

Collected Steps per Second: 21,599.41058
Overall Steps per Second: 10,450.57685

Timestep Collection Time: 2.31645
Timestep Consumption Time: 2.47123
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.78768

Cumulative Model Updates: 127,798
Cumulative Timesteps: 1,066,640,556

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1066640556...
Checkpoint 1066640556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,509.98634
Policy Entropy: 1.66444
Value Function Loss: 0.06111

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07626
Policy Update Magnitude: 0.31734
Value Function Update Magnitude: 0.31154

Collected Steps per Second: 20,317.56339
Overall Steps per Second: 10,187.81868

Timestep Collection Time: 2.46142
Timestep Consumption Time: 2.44739
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.90880

Cumulative Model Updates: 127,804
Cumulative Timesteps: 1,066,690,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,852.75824
Policy Entropy: 1.67660
Value Function Loss: 0.05763

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.31335
Value Function Update Magnitude: 0.32819

Collected Steps per Second: 20,927.99690
Overall Steps per Second: 10,456.07196

Timestep Collection Time: 2.39106
Timestep Consumption Time: 2.39468
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.78574

Cumulative Model Updates: 127,810
Cumulative Timesteps: 1,066,740,606

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1066740606...
Checkpoint 1066740606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,772.99524
Policy Entropy: 1.67017
Value Function Loss: 0.05696

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.31113
Value Function Update Magnitude: 0.34094

Collected Steps per Second: 20,869.92386
Overall Steps per Second: 10,227.89539

Timestep Collection Time: 2.39742
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.30119
Total Iteration Time: 4.89192

Cumulative Model Updates: 127,816
Cumulative Timesteps: 1,066,790,640

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,535.35821
Policy Entropy: 1.69666
Value Function Loss: 0.05971

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.31359
Value Function Update Magnitude: 0.34793

Collected Steps per Second: 21,145.76065
Overall Steps per Second: 10,302.47113

Timestep Collection Time: 2.36530
Timestep Consumption Time: 2.48946
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.85476

Cumulative Model Updates: 127,822
Cumulative Timesteps: 1,066,840,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1066840656...
Checkpoint 1066840656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,655.73380
Policy Entropy: 1.70352
Value Function Loss: 0.06542

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.30590
Value Function Update Magnitude: 0.35286

Collected Steps per Second: 20,772.70218
Overall Steps per Second: 10,344.68302

Timestep Collection Time: 2.40893
Timestep Consumption Time: 2.42834
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.83727

Cumulative Model Updates: 127,828
Cumulative Timesteps: 1,066,890,696

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,926.20932
Policy Entropy: 1.70333
Value Function Loss: 0.06199

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.30714
Value Function Update Magnitude: 0.36129

Collected Steps per Second: 21,231.84624
Overall Steps per Second: 10,441.31535

Timestep Collection Time: 2.35495
Timestep Consumption Time: 2.43372
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.78867

Cumulative Model Updates: 127,834
Cumulative Timesteps: 1,066,940,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1066940696...
Checkpoint 1066940696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,779.20993
Policy Entropy: 1.69912
Value Function Loss: 0.06727

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.31592
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 21,756.26246
Overall Steps per Second: 10,584.57142

Timestep Collection Time: 2.29966
Timestep Consumption Time: 2.42722
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.72688

Cumulative Model Updates: 127,840
Cumulative Timesteps: 1,066,990,728

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,074.15820
Policy Entropy: 1.70741
Value Function Loss: 0.06363

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.31812
Value Function Update Magnitude: 0.31389

Collected Steps per Second: 21,801.35907
Overall Steps per Second: 10,630.53960

Timestep Collection Time: 2.29564
Timestep Consumption Time: 2.41231
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.70795

Cumulative Model Updates: 127,846
Cumulative Timesteps: 1,067,040,776

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1067040776...
Checkpoint 1067040776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,033.10747
Policy Entropy: 1.70759
Value Function Loss: 0.06108

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.30709
Value Function Update Magnitude: 0.35903

Collected Steps per Second: 21,397.06643
Overall Steps per Second: 10,529.77651

Timestep Collection Time: 2.33686
Timestep Consumption Time: 2.41177
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.74863

Cumulative Model Updates: 127,852
Cumulative Timesteps: 1,067,090,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,346.03377
Policy Entropy: 1.69084
Value Function Loss: 0.05728

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.29983
Value Function Update Magnitude: 0.37865

Collected Steps per Second: 21,466.74085
Overall Steps per Second: 10,520.21480

Timestep Collection Time: 2.32946
Timestep Consumption Time: 2.42386
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.75333

Cumulative Model Updates: 127,858
Cumulative Timesteps: 1,067,140,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1067140784...
Checkpoint 1067140784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,485.11678
Policy Entropy: 1.68250
Value Function Loss: 0.05903

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.31400
Value Function Update Magnitude: 0.37095

Collected Steps per Second: 21,136.96556
Overall Steps per Second: 10,223.76192

Timestep Collection Time: 2.36628
Timestep Consumption Time: 2.52585
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.89213

Cumulative Model Updates: 127,864
Cumulative Timesteps: 1,067,190,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,973.16124
Policy Entropy: 1.68457
Value Function Loss: 0.05919

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.31575
Value Function Update Magnitude: 0.36577

Collected Steps per Second: 21,502.84603
Overall Steps per Second: 10,422.08876

Timestep Collection Time: 2.32620
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.79942

Cumulative Model Updates: 127,870
Cumulative Timesteps: 1,067,240,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1067240820...
Checkpoint 1067240820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,560.35191
Policy Entropy: 1.69430
Value Function Loss: 0.05653

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.30369
Value Function Update Magnitude: 0.37097

Collected Steps per Second: 21,380.88342
Overall Steps per Second: 10,343.41550

Timestep Collection Time: 2.33919
Timestep Consumption Time: 2.49615
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.83535

Cumulative Model Updates: 127,876
Cumulative Timesteps: 1,067,290,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,907.23920
Policy Entropy: 1.70093
Value Function Loss: 0.05633

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.28164
Value Function Update Magnitude: 0.36275

Collected Steps per Second: 21,869.19739
Overall Steps per Second: 10,401.06081

Timestep Collection Time: 2.28760
Timestep Consumption Time: 2.52229
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.80989

Cumulative Model Updates: 127,882
Cumulative Timesteps: 1,067,340,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1067340862...
Checkpoint 1067340862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,003.67534
Policy Entropy: 1.70605
Value Function Loss: 0.06086

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.29616
Value Function Update Magnitude: 0.36084

Collected Steps per Second: 21,922.77171
Overall Steps per Second: 10,523.41382

Timestep Collection Time: 2.28165
Timestep Consumption Time: 2.47156
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.75321

Cumulative Model Updates: 127,888
Cumulative Timesteps: 1,067,390,882

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,904.96593
Policy Entropy: 1.69707
Value Function Loss: 0.05995

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.31262
Value Function Update Magnitude: 0.35122

Collected Steps per Second: 21,934.64614
Overall Steps per Second: 10,353.63870

Timestep Collection Time: 2.28005
Timestep Consumption Time: 2.55033
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.83038

Cumulative Model Updates: 127,894
Cumulative Timesteps: 1,067,440,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1067440894...
Checkpoint 1067440894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,513.93469
Policy Entropy: 1.68754
Value Function Loss: 0.05707

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.31147
Value Function Update Magnitude: 0.35183

Collected Steps per Second: 21,661.42403
Overall Steps per Second: 10,251.38689

Timestep Collection Time: 2.30908
Timestep Consumption Time: 2.57006
PPO Batch Consumption Time: 0.30084
Total Iteration Time: 4.87914

Cumulative Model Updates: 127,900
Cumulative Timesteps: 1,067,490,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,345.02707
Policy Entropy: 1.67588
Value Function Loss: 0.05468

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.30792
Value Function Update Magnitude: 0.32686

Collected Steps per Second: 21,936.13552
Overall Steps per Second: 10,589.73628

Timestep Collection Time: 2.28126
Timestep Consumption Time: 2.44426
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.72552

Cumulative Model Updates: 127,906
Cumulative Timesteps: 1,067,540,954

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1067540954...
Checkpoint 1067540954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,033.24095
Policy Entropy: 1.67619
Value Function Loss: 0.05633

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.31193
Value Function Update Magnitude: 0.32294

Collected Steps per Second: 21,753.35918
Overall Steps per Second: 10,538.11797

Timestep Collection Time: 2.30015
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.74810

Cumulative Model Updates: 127,912
Cumulative Timesteps: 1,067,590,990

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,025.18916
Policy Entropy: 1.67941
Value Function Loss: 0.06299

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.31582
Value Function Update Magnitude: 0.34271

Collected Steps per Second: 21,997.96069
Overall Steps per Second: 10,484.05101

Timestep Collection Time: 2.27312
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.76953

Cumulative Model Updates: 127,918
Cumulative Timesteps: 1,067,640,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1067640994...
Checkpoint 1067640994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,341.24558
Policy Entropy: 1.68906
Value Function Loss: 0.06205

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.31585
Value Function Update Magnitude: 0.36092

Collected Steps per Second: 21,656.44340
Overall Steps per Second: 10,596.30867

Timestep Collection Time: 2.30952
Timestep Consumption Time: 2.41061
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.72013

Cumulative Model Updates: 127,924
Cumulative Timesteps: 1,067,691,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,598.18466
Policy Entropy: 1.70110
Value Function Loss: 0.05980

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.31360
Value Function Update Magnitude: 0.37636

Collected Steps per Second: 21,224.71846
Overall Steps per Second: 10,414.27924

Timestep Collection Time: 2.35621
Timestep Consumption Time: 2.44585
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.80206

Cumulative Model Updates: 127,930
Cumulative Timesteps: 1,067,741,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1067741020...
Checkpoint 1067741020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,848.65232
Policy Entropy: 1.68932
Value Function Loss: 0.05679

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.31183
Value Function Update Magnitude: 0.37024

Collected Steps per Second: 20,997.44188
Overall Steps per Second: 10,244.61292

Timestep Collection Time: 2.38210
Timestep Consumption Time: 2.50027
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.88237

Cumulative Model Updates: 127,936
Cumulative Timesteps: 1,067,791,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,816.21570
Policy Entropy: 1.67552
Value Function Loss: 0.05402

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.31006
Value Function Update Magnitude: 0.33948

Collected Steps per Second: 21,464.36673
Overall Steps per Second: 10,481.71116

Timestep Collection Time: 2.32954
Timestep Consumption Time: 2.44087
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.77040

Cumulative Model Updates: 127,942
Cumulative Timesteps: 1,067,841,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1067841040...
Checkpoint 1067841040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,113.78880
Policy Entropy: 1.66421
Value Function Loss: 0.05540

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.30610
Value Function Update Magnitude: 0.28381

Collected Steps per Second: 21,476.21672
Overall Steps per Second: 10,344.05485

Timestep Collection Time: 2.32816
Timestep Consumption Time: 2.50554
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.83369

Cumulative Model Updates: 127,948
Cumulative Timesteps: 1,067,891,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,137.64526
Policy Entropy: 1.66173
Value Function Loss: 0.05713

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.31545
Value Function Update Magnitude: 0.24404

Collected Steps per Second: 22,002.00472
Overall Steps per Second: 10,343.85929

Timestep Collection Time: 2.27343
Timestep Consumption Time: 2.56229
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.83572

Cumulative Model Updates: 127,954
Cumulative Timesteps: 1,067,941,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1067941060...
Checkpoint 1067941060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,331.88407
Policy Entropy: 1.66347
Value Function Loss: 0.06054

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.25085

Collected Steps per Second: 21,733.13187
Overall Steps per Second: 10,502.88059

Timestep Collection Time: 2.30091
Timestep Consumption Time: 2.46026
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.76117

Cumulative Model Updates: 127,960
Cumulative Timesteps: 1,067,991,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,551.26119
Policy Entropy: 1.66024
Value Function Loss: 0.05751

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08812
Policy Update Magnitude: 0.31171
Value Function Update Magnitude: 0.28241

Collected Steps per Second: 21,967.89295
Overall Steps per Second: 10,598.46288

Timestep Collection Time: 2.27678
Timestep Consumption Time: 2.44240
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.71917

Cumulative Model Updates: 127,966
Cumulative Timesteps: 1,068,041,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1068041082...
Checkpoint 1068041082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,058.48755
Policy Entropy: 1.67244
Value Function Loss: 0.06138

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.31158
Value Function Update Magnitude: 0.33371

Collected Steps per Second: 21,863.51714
Overall Steps per Second: 10,480.53182

Timestep Collection Time: 2.28792
Timestep Consumption Time: 2.48493
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.77285

Cumulative Model Updates: 127,972
Cumulative Timesteps: 1,068,091,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,962.83197
Policy Entropy: 1.67793
Value Function Loss: 0.06260

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.31850
Value Function Update Magnitude: 0.37248

Collected Steps per Second: 22,105.90411
Overall Steps per Second: 10,492.72367

Timestep Collection Time: 2.26211
Timestep Consumption Time: 2.50367
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.76578

Cumulative Model Updates: 127,978
Cumulative Timesteps: 1,068,141,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1068141110...
Checkpoint 1068141110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,649.71463
Policy Entropy: 1.66044
Value Function Loss: 0.06135

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.32120
Value Function Update Magnitude: 0.36576

Collected Steps per Second: 21,650.25404
Overall Steps per Second: 10,355.17441

Timestep Collection Time: 2.31037
Timestep Consumption Time: 2.52007
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.83044

Cumulative Model Updates: 127,984
Cumulative Timesteps: 1,068,191,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,619.96079
Policy Entropy: 1.63588
Value Function Loss: 0.05934

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.31588
Value Function Update Magnitude: 0.33826

Collected Steps per Second: 22,106.40725
Overall Steps per Second: 10,475.38089

Timestep Collection Time: 2.26242
Timestep Consumption Time: 2.51201
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.77443

Cumulative Model Updates: 127,990
Cumulative Timesteps: 1,068,241,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1068241144...
Checkpoint 1068241144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,953.91323
Policy Entropy: 1.63795
Value Function Loss: 0.05673

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.31334
Value Function Update Magnitude: 0.31221

Collected Steps per Second: 21,488.26337
Overall Steps per Second: 10,535.38931

Timestep Collection Time: 2.32685
Timestep Consumption Time: 2.41906
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.74591

Cumulative Model Updates: 127,996
Cumulative Timesteps: 1,068,291,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,457.24696
Policy Entropy: 1.64996
Value Function Loss: 0.06000

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.31668
Value Function Update Magnitude: 0.31183

Collected Steps per Second: 21,099.18795
Overall Steps per Second: 10,487.00753

Timestep Collection Time: 2.37023
Timestep Consumption Time: 2.39852
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.76876

Cumulative Model Updates: 128,002
Cumulative Timesteps: 1,068,341,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1068341154...
Checkpoint 1068341154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,824.93543
Policy Entropy: 1.65258
Value Function Loss: 0.06067

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.31876
Value Function Update Magnitude: 0.32815

Collected Steps per Second: 20,514.54725
Overall Steps per Second: 10,234.60826

Timestep Collection Time: 2.43768
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.88617

Cumulative Model Updates: 128,008
Cumulative Timesteps: 1,068,391,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,858.07965
Policy Entropy: 1.65137
Value Function Loss: 0.06110

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.31821
Value Function Update Magnitude: 0.33368

Collected Steps per Second: 21,058.78508
Overall Steps per Second: 10,411.25173

Timestep Collection Time: 2.37469
Timestep Consumption Time: 2.42858
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.80326

Cumulative Model Updates: 128,014
Cumulative Timesteps: 1,068,441,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1068441170...
Checkpoint 1068441170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,079.25373
Policy Entropy: 1.64447
Value Function Loss: 0.06106

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.30971
Value Function Update Magnitude: 0.34145

Collected Steps per Second: 20,748.39195
Overall Steps per Second: 10,293.44236

Timestep Collection Time: 2.40992
Timestep Consumption Time: 2.44773
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.85766

Cumulative Model Updates: 128,020
Cumulative Timesteps: 1,068,491,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,931.21152
Policy Entropy: 1.66618
Value Function Loss: 0.05966

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.29091
Value Function Update Magnitude: 0.35176

Collected Steps per Second: 21,167.31510
Overall Steps per Second: 10,374.26388

Timestep Collection Time: 2.36317
Timestep Consumption Time: 2.45857
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.82174

Cumulative Model Updates: 128,026
Cumulative Timesteps: 1,068,541,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1068541194...
Checkpoint 1068541194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,750.71966
Policy Entropy: 1.65805
Value Function Loss: 0.05897

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.31073
Value Function Update Magnitude: 0.35902

Collected Steps per Second: 20,621.08910
Overall Steps per Second: 10,236.80722

Timestep Collection Time: 2.42548
Timestep Consumption Time: 2.46042
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.88590

Cumulative Model Updates: 128,032
Cumulative Timesteps: 1,068,591,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,235.29806
Policy Entropy: 1.66331
Value Function Loss: 0.05973

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.30303
Value Function Update Magnitude: 0.35493

Collected Steps per Second: 21,939.64846
Overall Steps per Second: 10,467.21812

Timestep Collection Time: 2.27962
Timestep Consumption Time: 2.49854
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.77816

Cumulative Model Updates: 128,038
Cumulative Timesteps: 1,068,641,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1068641224...
Checkpoint 1068641224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,209.43902
Policy Entropy: 1.63629
Value Function Loss: 0.05987

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.29848
Value Function Update Magnitude: 0.34888

Collected Steps per Second: 21,456.48921
Overall Steps per Second: 10,540.21267

Timestep Collection Time: 2.33067
Timestep Consumption Time: 2.41383
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.74450

Cumulative Model Updates: 128,044
Cumulative Timesteps: 1,068,691,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,958.91194
Policy Entropy: 1.64262
Value Function Loss: 0.06235

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.30143
Value Function Update Magnitude: 0.33844

Collected Steps per Second: 21,711.18317
Overall Steps per Second: 10,339.45706

Timestep Collection Time: 2.30333
Timestep Consumption Time: 2.53329
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.83662

Cumulative Model Updates: 128,050
Cumulative Timesteps: 1,068,741,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1068741240...
Checkpoint 1068741240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,043.46303
Policy Entropy: 1.64920
Value Function Loss: 0.06288

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.30439
Value Function Update Magnitude: 0.33310

Collected Steps per Second: 21,559.86164
Overall Steps per Second: 10,267.90815

Timestep Collection Time: 2.31977
Timestep Consumption Time: 2.55113
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.87090

Cumulative Model Updates: 128,056
Cumulative Timesteps: 1,068,791,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,188.22152
Policy Entropy: 1.64946
Value Function Loss: 0.06037

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.31686
Value Function Update Magnitude: 0.34110

Collected Steps per Second: 22,058.83099
Overall Steps per Second: 10,631.88382

Timestep Collection Time: 2.26775
Timestep Consumption Time: 2.43734
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.70509

Cumulative Model Updates: 128,062
Cumulative Timesteps: 1,068,841,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1068841278...
Checkpoint 1068841278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,742.50645
Policy Entropy: 1.65027
Value Function Loss: 0.05566

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.31314
Value Function Update Magnitude: 0.34925

Collected Steps per Second: 21,518.88465
Overall Steps per Second: 10,492.23151

Timestep Collection Time: 2.32466
Timestep Consumption Time: 2.44306
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.76772

Cumulative Model Updates: 128,068
Cumulative Timesteps: 1,068,891,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,360.53057
Policy Entropy: 1.64504
Value Function Loss: 0.05931

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10429
Policy Update Magnitude: 0.30594
Value Function Update Magnitude: 0.32180

Collected Steps per Second: 20,564.24335
Overall Steps per Second: 10,033.31361

Timestep Collection Time: 2.43140
Timestep Consumption Time: 2.55199
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.98340

Cumulative Model Updates: 128,074
Cumulative Timesteps: 1,068,941,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1068941302...
Checkpoint 1068941302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,565.08906
Policy Entropy: 1.65746
Value Function Loss: 0.05888

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.30726
Value Function Update Magnitude: 0.30229

Collected Steps per Second: 20,896.95196
Overall Steps per Second: 10,333.10664

Timestep Collection Time: 2.39336
Timestep Consumption Time: 2.44681
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.84017

Cumulative Model Updates: 128,080
Cumulative Timesteps: 1,068,991,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,282.69990
Policy Entropy: 1.65808
Value Function Loss: 0.06484

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.31964
Value Function Update Magnitude: 0.32615

Collected Steps per Second: 21,336.86150
Overall Steps per Second: 10,469.70299

Timestep Collection Time: 2.34486
Timestep Consumption Time: 2.43388
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.77874

Cumulative Model Updates: 128,086
Cumulative Timesteps: 1,069,041,348

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1069041348...
Checkpoint 1069041348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,047.53811
Policy Entropy: 1.64830
Value Function Loss: 0.06387

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08753
Policy Update Magnitude: 0.31845
Value Function Update Magnitude: 0.30779

Collected Steps per Second: 21,461.43427
Overall Steps per Second: 10,504.13352

Timestep Collection Time: 2.33088
Timestep Consumption Time: 2.43144
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.76232

Cumulative Model Updates: 128,092
Cumulative Timesteps: 1,069,091,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,267.45095
Policy Entropy: 1.65636
Value Function Loss: 0.06494

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.32446
Value Function Update Magnitude: 0.28065

Collected Steps per Second: 22,000.22963
Overall Steps per Second: 10,546.71134

Timestep Collection Time: 2.27325
Timestep Consumption Time: 2.46870
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.74195

Cumulative Model Updates: 128,098
Cumulative Timesteps: 1,069,141,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1069141384...
Checkpoint 1069141384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,454.45132
Policy Entropy: 1.65328
Value Function Loss: 0.05948

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.32156
Value Function Update Magnitude: 0.29312

Collected Steps per Second: 21,795.18279
Overall Steps per Second: 10,542.80260

Timestep Collection Time: 2.29537
Timestep Consumption Time: 2.44986
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.74523

Cumulative Model Updates: 128,104
Cumulative Timesteps: 1,069,191,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,858.72274
Policy Entropy: 1.66912
Value Function Loss: 0.06017

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.32073
Value Function Update Magnitude: 0.30361

Collected Steps per Second: 22,040.04978
Overall Steps per Second: 10,525.12443

Timestep Collection Time: 2.26960
Timestep Consumption Time: 2.48303
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.75263

Cumulative Model Updates: 128,110
Cumulative Timesteps: 1,069,241,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1069241434...
Checkpoint 1069241434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,543.99132
Policy Entropy: 1.66331
Value Function Loss: 0.05926

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.31991
Value Function Update Magnitude: 0.29723

Collected Steps per Second: 21,601.59510
Overall Steps per Second: 10,557.67901

Timestep Collection Time: 2.31650
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.73968

Cumulative Model Updates: 128,116
Cumulative Timesteps: 1,069,291,474

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,907.07153
Policy Entropy: 1.65034
Value Function Loss: 0.05878

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.32036
Value Function Update Magnitude: 0.32204

Collected Steps per Second: 21,657.27143
Overall Steps per Second: 10,501.12623

Timestep Collection Time: 2.30943
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.76292

Cumulative Model Updates: 128,122
Cumulative Timesteps: 1,069,341,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1069341490...
Checkpoint 1069341490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,672.82844
Policy Entropy: 1.65152
Value Function Loss: 0.05837

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.32000
Value Function Update Magnitude: 0.33711

Collected Steps per Second: 20,900.80026
Overall Steps per Second: 10,199.89635

Timestep Collection Time: 2.39321
Timestep Consumption Time: 2.51076
PPO Batch Consumption Time: 0.30513
Total Iteration Time: 4.90397

Cumulative Model Updates: 128,128
Cumulative Timesteps: 1,069,391,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,698.01852
Policy Entropy: 1.65888
Value Function Loss: 0.05644

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.31998
Value Function Update Magnitude: 0.34332

Collected Steps per Second: 21,495.95959
Overall Steps per Second: 10,433.01998

Timestep Collection Time: 2.32667
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.79382

Cumulative Model Updates: 128,134
Cumulative Timesteps: 1,069,441,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1069441524...
Checkpoint 1069441524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,308.72193
Policy Entropy: 1.66013
Value Function Loss: 0.06229

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08455
Policy Update Magnitude: 0.32116
Value Function Update Magnitude: 0.34598

Collected Steps per Second: 20,419.69121
Overall Steps per Second: 10,263.45500

Timestep Collection Time: 2.45048
Timestep Consumption Time: 2.42488
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.87536

Cumulative Model Updates: 128,140
Cumulative Timesteps: 1,069,491,562

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,638.07577
Policy Entropy: 1.66871
Value Function Loss: 0.05951

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.31653
Value Function Update Magnitude: 0.30707

Collected Steps per Second: 20,962.99838
Overall Steps per Second: 10,524.19880

Timestep Collection Time: 2.38544
Timestep Consumption Time: 2.36608
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.75153

Cumulative Model Updates: 128,146
Cumulative Timesteps: 1,069,541,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1069541568...
Checkpoint 1069541568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,286.80935
Policy Entropy: 1.65342
Value Function Loss: 0.06208

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.31642
Value Function Update Magnitude: 0.27008

Collected Steps per Second: 20,963.34187
Overall Steps per Second: 10,253.77730

Timestep Collection Time: 2.38512
Timestep Consumption Time: 2.49114
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.87625

Cumulative Model Updates: 128,152
Cumulative Timesteps: 1,069,591,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,197.61018
Policy Entropy: 1.65543
Value Function Loss: 0.05734

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.31390
Value Function Update Magnitude: 0.26936

Collected Steps per Second: 21,590.91552
Overall Steps per Second: 10,371.32366

Timestep Collection Time: 2.31672
Timestep Consumption Time: 2.50620
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.82291

Cumulative Model Updates: 128,158
Cumulative Timesteps: 1,069,641,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1069641588...
Checkpoint 1069641588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,431.43987
Policy Entropy: 1.62324
Value Function Loss: 0.05652

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.30336
Value Function Update Magnitude: 0.29333

Collected Steps per Second: 21,278.36307
Overall Steps per Second: 10,372.47309

Timestep Collection Time: 2.34999
Timestep Consumption Time: 2.47084
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.82084

Cumulative Model Updates: 128,164
Cumulative Timesteps: 1,069,691,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,288.26416
Policy Entropy: 1.63385
Value Function Loss: 0.05600

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.29736
Value Function Update Magnitude: 0.31960

Collected Steps per Second: 21,998.99769
Overall Steps per Second: 10,595.68266

Timestep Collection Time: 2.27474
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.72287

Cumulative Model Updates: 128,170
Cumulative Timesteps: 1,069,741,634

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1069741634...
Checkpoint 1069741634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,442.77115
Policy Entropy: 1.63302
Value Function Loss: 0.05263

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.30864
Value Function Update Magnitude: 0.33184

Collected Steps per Second: 21,434.83263
Overall Steps per Second: 10,263.83941

Timestep Collection Time: 2.33330
Timestep Consumption Time: 2.53953
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.87284

Cumulative Model Updates: 128,176
Cumulative Timesteps: 1,069,791,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,022.50275
Policy Entropy: 1.65735
Value Function Loss: 0.05074

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.29867
Value Function Update Magnitude: 0.32135

Collected Steps per Second: 21,838.54137
Overall Steps per Second: 10,431.97080

Timestep Collection Time: 2.28953
Timestep Consumption Time: 2.50343
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.79296

Cumulative Model Updates: 128,182
Cumulative Timesteps: 1,069,841,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1069841648...
Checkpoint 1069841648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,752.22975
Policy Entropy: 1.66376
Value Function Loss: 0.05452

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.29552
Value Function Update Magnitude: 0.30582

Collected Steps per Second: 21,420.44893
Overall Steps per Second: 10,309.14256

Timestep Collection Time: 2.33487
Timestep Consumption Time: 2.51655
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.85142

Cumulative Model Updates: 128,188
Cumulative Timesteps: 1,069,891,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,688.46033
Policy Entropy: 1.66716
Value Function Loss: 0.05913

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.31426
Value Function Update Magnitude: 0.31681

Collected Steps per Second: 21,666.65779
Overall Steps per Second: 10,395.87104

Timestep Collection Time: 2.30825
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.81076

Cumulative Model Updates: 128,194
Cumulative Timesteps: 1,069,941,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1069941674...
Checkpoint 1069941674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,155.34088
Policy Entropy: 1.65822
Value Function Loss: 0.05950

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.31740
Value Function Update Magnitude: 0.32422

Collected Steps per Second: 21,586.98098
Overall Steps per Second: 10,380.71639

Timestep Collection Time: 2.31742
Timestep Consumption Time: 2.50171
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.81913

Cumulative Model Updates: 128,200
Cumulative Timesteps: 1,069,991,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,414.72567
Policy Entropy: 1.64488
Value Function Loss: 0.06192

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.32125
Value Function Update Magnitude: 0.31764

Collected Steps per Second: 22,000.94495
Overall Steps per Second: 10,312.73275

Timestep Collection Time: 2.27336
Timestep Consumption Time: 2.57657
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 4.84993

Cumulative Model Updates: 128,206
Cumulative Timesteps: 1,070,041,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1070041716...
Checkpoint 1070041716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,696.30081
Policy Entropy: 1.63009
Value Function Loss: 0.05408

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.31517
Value Function Update Magnitude: 0.31860

Collected Steps per Second: 21,819.17348
Overall Steps per Second: 10,517.39432

Timestep Collection Time: 2.29257
Timestep Consumption Time: 2.46355
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.75612

Cumulative Model Updates: 128,212
Cumulative Timesteps: 1,070,091,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,441.18181
Policy Entropy: 1.64045
Value Function Loss: 0.05696

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.31139
Value Function Update Magnitude: 0.27904

Collected Steps per Second: 21,315.11735
Overall Steps per Second: 10,315.38589

Timestep Collection Time: 2.34707
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.84984

Cumulative Model Updates: 128,218
Cumulative Timesteps: 1,070,141,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1070141766...
Checkpoint 1070141766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,083.10476
Policy Entropy: 1.64286
Value Function Loss: 0.05538

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.31421
Value Function Update Magnitude: 0.23532

Collected Steps per Second: 21,523.01609
Overall Steps per Second: 10,424.54435

Timestep Collection Time: 2.32393
Timestep Consumption Time: 2.47417
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.79810

Cumulative Model Updates: 128,224
Cumulative Timesteps: 1,070,191,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,352.72232
Policy Entropy: 1.66251
Value Function Loss: 0.05550

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.28871

Collected Steps per Second: 21,454.62991
Overall Steps per Second: 10,471.88897

Timestep Collection Time: 2.33236
Timestep Consumption Time: 2.44614
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.77851

Cumulative Model Updates: 128,230
Cumulative Timesteps: 1,070,241,824

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1070241824...
Checkpoint 1070241824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,468.14799
Policy Entropy: 1.65778
Value Function Loss: 0.05615

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.32113

Collected Steps per Second: 21,358.83144
Overall Steps per Second: 10,273.93906

Timestep Collection Time: 2.34282
Timestep Consumption Time: 2.52775
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.87058

Cumulative Model Updates: 128,236
Cumulative Timesteps: 1,070,291,864

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,962.99245
Policy Entropy: 1.66969
Value Function Loss: 0.05720

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.30931
Value Function Update Magnitude: 0.33017

Collected Steps per Second: 21,992.81796
Overall Steps per Second: 10,372.72954

Timestep Collection Time: 2.27356
Timestep Consumption Time: 2.54696
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.82052

Cumulative Model Updates: 128,242
Cumulative Timesteps: 1,070,341,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1070341866...
Checkpoint 1070341866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,016.06875
Policy Entropy: 1.65741
Value Function Loss: 0.06465

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.31846
Value Function Update Magnitude: 0.34265

Collected Steps per Second: 21,560.42429
Overall Steps per Second: 10,342.31389

Timestep Collection Time: 2.32036
Timestep Consumption Time: 2.51685
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.83722

Cumulative Model Updates: 128,248
Cumulative Timesteps: 1,070,391,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,278.72528
Policy Entropy: 1.66137
Value Function Loss: 0.06683

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.32180
Value Function Update Magnitude: 0.35527

Collected Steps per Second: 22,037.53050
Overall Steps per Second: 10,479.89365

Timestep Collection Time: 2.26976
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.77295

Cumulative Model Updates: 128,254
Cumulative Timesteps: 1,070,441,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1070441914...
Checkpoint 1070441914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,396.38164
Policy Entropy: 1.65031
Value Function Loss: 0.06470

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.31752
Value Function Update Magnitude: 0.36377

Collected Steps per Second: 21,960.31396
Overall Steps per Second: 10,484.82377

Timestep Collection Time: 2.27847
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.77223

Cumulative Model Updates: 128,260
Cumulative Timesteps: 1,070,491,950

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,541.46497
Policy Entropy: 1.65514
Value Function Loss: 0.06354

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.31230
Value Function Update Magnitude: 0.35600

Collected Steps per Second: 21,978.07993
Overall Steps per Second: 10,432.89984

Timestep Collection Time: 2.27563
Timestep Consumption Time: 2.51824
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.79387

Cumulative Model Updates: 128,266
Cumulative Timesteps: 1,070,541,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1070541964...
Checkpoint 1070541964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,141.88660
Policy Entropy: 1.65625
Value Function Loss: 0.05618

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.30685
Value Function Update Magnitude: 0.34654

Collected Steps per Second: 20,860.70206
Overall Steps per Second: 10,365.82578

Timestep Collection Time: 2.39781
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.82547

Cumulative Model Updates: 128,272
Cumulative Timesteps: 1,070,591,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,970.71584
Policy Entropy: 1.67204
Value Function Loss: 0.05705

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.29923
Value Function Update Magnitude: 0.34230

Collected Steps per Second: 21,478.51326
Overall Steps per Second: 10,672.14608

Timestep Collection Time: 2.32809
Timestep Consumption Time: 2.35737
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.68547

Cumulative Model Updates: 128,278
Cumulative Timesteps: 1,070,641,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1070641988...
Checkpoint 1070641988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,679.00776
Policy Entropy: 1.66839
Value Function Loss: 0.05453

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.30394
Value Function Update Magnitude: 0.34651

Collected Steps per Second: 20,968.07402
Overall Steps per Second: 10,208.25064

Timestep Collection Time: 2.38525
Timestep Consumption Time: 2.51412
PPO Batch Consumption Time: 0.30715
Total Iteration Time: 4.89937

Cumulative Model Updates: 128,284
Cumulative Timesteps: 1,070,692,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,567.33263
Policy Entropy: 1.67700
Value Function Loss: 0.05550

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.30564
Value Function Update Magnitude: 0.34660

Collected Steps per Second: 20,865.22257
Overall Steps per Second: 10,458.55255

Timestep Collection Time: 2.39854
Timestep Consumption Time: 2.38664
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.78517

Cumulative Model Updates: 128,290
Cumulative Timesteps: 1,070,742,048

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1070742048...
Checkpoint 1070742048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,014.65394
Policy Entropy: 1.67218
Value Function Loss: 0.05268

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.28859
Value Function Update Magnitude: 0.32631

Collected Steps per Second: 20,483.14446
Overall Steps per Second: 10,218.85041

Timestep Collection Time: 2.44113
Timestep Consumption Time: 2.45198
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.89311

Cumulative Model Updates: 128,296
Cumulative Timesteps: 1,070,792,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,888.65333
Policy Entropy: 1.67015
Value Function Loss: 0.05848

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.29042
Value Function Update Magnitude: 0.30733

Collected Steps per Second: 21,229.44165
Overall Steps per Second: 10,463.15234

Timestep Collection Time: 2.35588
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.78001

Cumulative Model Updates: 128,302
Cumulative Timesteps: 1,070,842,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1070842064...
Checkpoint 1070842064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,730.95899
Policy Entropy: 1.67191
Value Function Loss: 0.06133

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.31303
Value Function Update Magnitude: 0.30122

Collected Steps per Second: 21,259.03849
Overall Steps per Second: 10,331.57175

Timestep Collection Time: 2.35194
Timestep Consumption Time: 2.48759
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.83953

Cumulative Model Updates: 128,308
Cumulative Timesteps: 1,070,892,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,034.15401
Policy Entropy: 1.65041
Value Function Loss: 0.06584

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.32011
Value Function Update Magnitude: 0.33090

Collected Steps per Second: 21,454.69821
Overall Steps per Second: 10,370.89770

Timestep Collection Time: 2.33105
Timestep Consumption Time: 2.49129
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.82234

Cumulative Model Updates: 128,314
Cumulative Timesteps: 1,070,942,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1070942076...
Checkpoint 1070942076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,145.62971
Policy Entropy: 1.66603
Value Function Loss: 0.05713

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.32139
Value Function Update Magnitude: 0.34581

Collected Steps per Second: 22,102.34556
Overall Steps per Second: 10,583.02786

Timestep Collection Time: 2.26329
Timestep Consumption Time: 2.46352
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72681

Cumulative Model Updates: 128,320
Cumulative Timesteps: 1,070,992,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,172.51618
Policy Entropy: 1.64617
Value Function Loss: 0.05490

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.31589
Value Function Update Magnitude: 0.34090

Collected Steps per Second: 21,951.37932
Overall Steps per Second: 10,461.31776

Timestep Collection Time: 2.27867
Timestep Consumption Time: 2.50275
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.78142

Cumulative Model Updates: 128,326
Cumulative Timesteps: 1,071,042,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1071042120...
Checkpoint 1071042120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,257.16127
Policy Entropy: 1.65741
Value Function Loss: 0.05409

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.31026
Value Function Update Magnitude: 0.33731

Collected Steps per Second: 21,502.37550
Overall Steps per Second: 10,337.97085

Timestep Collection Time: 2.32551
Timestep Consumption Time: 2.51142
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.83693

Cumulative Model Updates: 128,332
Cumulative Timesteps: 1,071,092,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,042.05731
Policy Entropy: 1.65050
Value Function Loss: 0.05541

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.31305
Value Function Update Magnitude: 0.33454

Collected Steps per Second: 21,968.99947
Overall Steps per Second: 10,405.04303

Timestep Collection Time: 2.27684
Timestep Consumption Time: 2.53044
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.80728

Cumulative Model Updates: 128,338
Cumulative Timesteps: 1,071,142,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1071142144...
Checkpoint 1071142144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,216.42712
Policy Entropy: 1.66416
Value Function Loss: 0.05865

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.32780

Collected Steps per Second: 21,757.08352
Overall Steps per Second: 10,548.02554

Timestep Collection Time: 2.29875
Timestep Consumption Time: 2.44281
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.74155

Cumulative Model Updates: 128,344
Cumulative Timesteps: 1,071,192,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,137.76539
Policy Entropy: 1.67906
Value Function Loss: 0.06262

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.31795
Value Function Update Magnitude: 0.32823

Collected Steps per Second: 21,891.93584
Overall Steps per Second: 10,595.18354

Timestep Collection Time: 2.28532
Timestep Consumption Time: 2.43664
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.72196

Cumulative Model Updates: 128,350
Cumulative Timesteps: 1,071,242,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1071242188...
Checkpoint 1071242188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,461.67650
Policy Entropy: 1.67358
Value Function Loss: 0.06207

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.31886
Value Function Update Magnitude: 0.34848

Collected Steps per Second: 21,770.13015
Overall Steps per Second: 10,560.64255

Timestep Collection Time: 2.29672
Timestep Consumption Time: 2.43784
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.73456

Cumulative Model Updates: 128,356
Cumulative Timesteps: 1,071,292,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,478.52559
Policy Entropy: 1.65133
Value Function Loss: 0.06354

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.31553
Value Function Update Magnitude: 0.34049

Collected Steps per Second: 21,333.53620
Overall Steps per Second: 10,245.61836

Timestep Collection Time: 2.34504
Timestep Consumption Time: 2.53783
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.88287

Cumulative Model Updates: 128,362
Cumulative Timesteps: 1,071,342,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1071342216...
Checkpoint 1071342216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,277.38567
Policy Entropy: 1.63738
Value Function Loss: 0.06290

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.32405
Value Function Update Magnitude: 0.34018

Collected Steps per Second: 21,066.56230
Overall Steps per Second: 10,397.07417

Timestep Collection Time: 2.37476
Timestep Consumption Time: 2.43698
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.81174

Cumulative Model Updates: 128,368
Cumulative Timesteps: 1,071,392,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,649.25443
Policy Entropy: 1.66166
Value Function Loss: 0.06123

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.30727
Value Function Update Magnitude: 0.34866

Collected Steps per Second: 21,653.73145
Overall Steps per Second: 10,531.05404

Timestep Collection Time: 2.31018
Timestep Consumption Time: 2.43996
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.75014

Cumulative Model Updates: 128,374
Cumulative Timesteps: 1,071,442,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1071442268...
Checkpoint 1071442268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,639.03220
Policy Entropy: 1.68211
Value Function Loss: 0.05879

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.29246
Value Function Update Magnitude: 0.33994

Collected Steps per Second: 21,481.85468
Overall Steps per Second: 10,325.91457

Timestep Collection Time: 2.32904
Timestep Consumption Time: 2.51625
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.84529

Cumulative Model Updates: 128,380
Cumulative Timesteps: 1,071,492,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,413.64209
Policy Entropy: 1.68762
Value Function Loss: 0.05780

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.30259
Value Function Update Magnitude: 0.31287

Collected Steps per Second: 22,087.46610
Overall Steps per Second: 10,466.28208

Timestep Collection Time: 2.26373
Timestep Consumption Time: 2.51352
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.77725

Cumulative Model Updates: 128,386
Cumulative Timesteps: 1,071,542,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1071542300...
Checkpoint 1071542300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,036.06767
Policy Entropy: 1.66827
Value Function Loss: 0.06144

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.31950
Value Function Update Magnitude: 0.27643

Collected Steps per Second: 21,822.50425
Overall Steps per Second: 10,407.92089

Timestep Collection Time: 2.29130
Timestep Consumption Time: 2.51292
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.80423

Cumulative Model Updates: 128,392
Cumulative Timesteps: 1,071,592,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,475.60973
Policy Entropy: 1.66311
Value Function Loss: 0.06419

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.32845
Value Function Update Magnitude: 0.31311

Collected Steps per Second: 22,218.66527
Overall Steps per Second: 10,498.33771

Timestep Collection Time: 2.25099
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.76399

Cumulative Model Updates: 128,398
Cumulative Timesteps: 1,071,642,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1071642316...
Checkpoint 1071642316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,517.58225
Policy Entropy: 1.67086
Value Function Loss: 0.06032

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.32692
Value Function Update Magnitude: 0.34532

Collected Steps per Second: 21,310.56163
Overall Steps per Second: 10,598.03792

Timestep Collection Time: 2.34747
Timestep Consumption Time: 2.37283
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.72031

Cumulative Model Updates: 128,404
Cumulative Timesteps: 1,071,692,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,178.76434
Policy Entropy: 1.67184
Value Function Loss: 0.05815

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.31770
Value Function Update Magnitude: 0.31000

Collected Steps per Second: 21,330.55054
Overall Steps per Second: 10,478.00105

Timestep Collection Time: 2.34546
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.77477

Cumulative Model Updates: 128,410
Cumulative Timesteps: 1,071,742,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1071742372...
Checkpoint 1071742372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,971.80627
Policy Entropy: 1.66460
Value Function Loss: 0.05815

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.31600
Value Function Update Magnitude: 0.26595

Collected Steps per Second: 21,280.54621
Overall Steps per Second: 10,603.51822

Timestep Collection Time: 2.34985
Timestep Consumption Time: 2.36614
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.71598

Cumulative Model Updates: 128,416
Cumulative Timesteps: 1,071,792,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,400.94143
Policy Entropy: 1.65304
Value Function Loss: 0.05781

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.31403
Value Function Update Magnitude: 0.25582

Collected Steps per Second: 21,167.97758
Overall Steps per Second: 10,613.17466

Timestep Collection Time: 2.36225
Timestep Consumption Time: 2.34926
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.71150

Cumulative Model Updates: 128,422
Cumulative Timesteps: 1,071,842,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1071842382...
Checkpoint 1071842382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,410.02940
Policy Entropy: 1.65598
Value Function Loss: 0.05529

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.30915
Value Function Update Magnitude: 0.32058

Collected Steps per Second: 20,466.17368
Overall Steps per Second: 10,119.60089

Timestep Collection Time: 2.44354
Timestep Consumption Time: 2.49835
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.94189

Cumulative Model Updates: 128,428
Cumulative Timesteps: 1,071,892,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,943.05114
Policy Entropy: 1.65655
Value Function Loss: 0.05289

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.31018
Value Function Update Magnitude: 0.32641

Collected Steps per Second: 21,397.17365
Overall Steps per Second: 10,506.01478

Timestep Collection Time: 2.33713
Timestep Consumption Time: 2.42281
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.75994

Cumulative Model Updates: 128,434
Cumulative Timesteps: 1,071,942,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1071942400...
Checkpoint 1071942400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,838.21902
Policy Entropy: 1.66545
Value Function Loss: 0.05723

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.31405
Value Function Update Magnitude: 0.33471

Collected Steps per Second: 21,600.69736
Overall Steps per Second: 10,565.05022

Timestep Collection Time: 2.31548
Timestep Consumption Time: 2.41862
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.73410

Cumulative Model Updates: 128,440
Cumulative Timesteps: 1,071,992,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,726.90012
Policy Entropy: 1.66137
Value Function Loss: 0.05831

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.31500
Value Function Update Magnitude: 0.35221

Collected Steps per Second: 21,530.47524
Overall Steps per Second: 10,447.80045

Timestep Collection Time: 2.32294
Timestep Consumption Time: 2.46410
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.78704

Cumulative Model Updates: 128,446
Cumulative Timesteps: 1,072,042,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1072042430...
Checkpoint 1072042430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,875.70958
Policy Entropy: 1.68083
Value Function Loss: 0.05879

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.31411
Value Function Update Magnitude: 0.36100

Collected Steps per Second: 21,390.43747
Overall Steps per Second: 10,286.59902

Timestep Collection Time: 2.33777
Timestep Consumption Time: 2.52350
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.86128

Cumulative Model Updates: 128,452
Cumulative Timesteps: 1,072,092,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,596.21591
Policy Entropy: 1.67182
Value Function Loss: 0.05840

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.31274
Value Function Update Magnitude: 0.37068

Collected Steps per Second: 22,128.12782
Overall Steps per Second: 10,380.30595

Timestep Collection Time: 2.25993
Timestep Consumption Time: 2.55766
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.81758

Cumulative Model Updates: 128,458
Cumulative Timesteps: 1,072,142,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1072142444...
Checkpoint 1072142444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,965.11751
Policy Entropy: 1.67279
Value Function Loss: 0.05905

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.29912
Value Function Update Magnitude: 0.36282

Collected Steps per Second: 21,875.38725
Overall Steps per Second: 10,554.66485

Timestep Collection Time: 2.28695
Timestep Consumption Time: 2.45294
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.73989

Cumulative Model Updates: 128,464
Cumulative Timesteps: 1,072,192,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,736.66997
Policy Entropy: 1.64636
Value Function Loss: 0.05719

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.28100
Value Function Update Magnitude: 0.34849

Collected Steps per Second: 21,723.94742
Overall Steps per Second: 10,538.96271

Timestep Collection Time: 2.30234
Timestep Consumption Time: 2.44347
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.74582

Cumulative Model Updates: 128,470
Cumulative Timesteps: 1,072,242,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1072242488...
Checkpoint 1072242488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,851.91176
Policy Entropy: 1.64927
Value Function Loss: 0.05638

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.28050
Value Function Update Magnitude: 0.33962

Collected Steps per Second: 22,294.01919
Overall Steps per Second: 10,708.64282

Timestep Collection Time: 2.24392
Timestep Consumption Time: 2.42763
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.67155

Cumulative Model Updates: 128,476
Cumulative Timesteps: 1,072,292,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,870.21679
Policy Entropy: 1.65038
Value Function Loss: 0.05680

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.09180
Policy Update Magnitude: 0.29924
Value Function Update Magnitude: 0.34926

Collected Steps per Second: 22,063.15803
Overall Steps per Second: 10,435.58218

Timestep Collection Time: 2.26704
Timestep Consumption Time: 2.52599
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.79302

Cumulative Model Updates: 128,482
Cumulative Timesteps: 1,072,342,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1072342532...
Checkpoint 1072342532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,778.81483
Policy Entropy: 1.66113
Value Function Loss: 0.05890

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.30397
Value Function Update Magnitude: 0.35732

Collected Steps per Second: 21,720.10675
Overall Steps per Second: 10,551.18035

Timestep Collection Time: 2.30376
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.74241

Cumulative Model Updates: 128,488
Cumulative Timesteps: 1,072,392,570

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,652.25090
Policy Entropy: 1.66445
Value Function Loss: 0.06045

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.31559
Value Function Update Magnitude: 0.34032

Collected Steps per Second: 21,685.56341
Overall Steps per Second: 10,518.41710

Timestep Collection Time: 2.30706
Timestep Consumption Time: 2.44935
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.75642

Cumulative Model Updates: 128,494
Cumulative Timesteps: 1,072,442,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1072442600...
Checkpoint 1072442600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,337.99083
Policy Entropy: 1.66290
Value Function Loss: 0.06020

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.32317
Value Function Update Magnitude: 0.33439

Collected Steps per Second: 21,568.82629
Overall Steps per Second: 10,546.76021

Timestep Collection Time: 2.31835
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.74117

Cumulative Model Updates: 128,500
Cumulative Timesteps: 1,072,492,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,108.81540
Policy Entropy: 1.66725
Value Function Loss: 0.06169

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.31905
Value Function Update Magnitude: 0.33716

Collected Steps per Second: 21,425.54019
Overall Steps per Second: 10,469.42199

Timestep Collection Time: 2.33497
Timestep Consumption Time: 2.44352
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.77849

Cumulative Model Updates: 128,506
Cumulative Timesteps: 1,072,542,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1072542632...
Checkpoint 1072542632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,547.28679
Policy Entropy: 1.65845
Value Function Loss: 0.06058

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.29879
Value Function Update Magnitude: 0.35366

Collected Steps per Second: 21,535.29095
Overall Steps per Second: 10,366.85301

Timestep Collection Time: 2.32288
Timestep Consumption Time: 2.50249
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.82538

Cumulative Model Updates: 128,512
Cumulative Timesteps: 1,072,592,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,066.55059
Policy Entropy: 1.64262
Value Function Loss: 0.06287

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.30582
Value Function Update Magnitude: 0.36816

Collected Steps per Second: 21,622.04979
Overall Steps per Second: 10,364.59184

Timestep Collection Time: 2.31282
Timestep Consumption Time: 2.51206
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.82489

Cumulative Model Updates: 128,518
Cumulative Timesteps: 1,072,642,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1072642664...
Checkpoint 1072642664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,236.93706
Policy Entropy: 1.64578
Value Function Loss: 0.06478

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.32502
Value Function Update Magnitude: 0.38465

Collected Steps per Second: 20,721.53811
Overall Steps per Second: 10,176.64596

Timestep Collection Time: 2.41353
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.91439

Cumulative Model Updates: 128,524
Cumulative Timesteps: 1,072,692,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,337.82660
Policy Entropy: 1.65110
Value Function Loss: 0.06365

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.33026
Value Function Update Magnitude: 0.37817

Collected Steps per Second: 21,728.32782
Overall Steps per Second: 10,430.30164

Timestep Collection Time: 2.30298
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.79756

Cumulative Model Updates: 128,530
Cumulative Timesteps: 1,072,742,716

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1072742716...
Checkpoint 1072742716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,549.32507
Policy Entropy: 1.66338
Value Function Loss: 0.06265

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.32542
Value Function Update Magnitude: 0.37082

Collected Steps per Second: 20,838.08181
Overall Steps per Second: 10,351.86700

Timestep Collection Time: 2.39945
Timestep Consumption Time: 2.43059
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.83005

Cumulative Model Updates: 128,536
Cumulative Timesteps: 1,072,792,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,022.99834
Policy Entropy: 1.66828
Value Function Loss: 0.05636

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.31644
Value Function Update Magnitude: 0.35431

Collected Steps per Second: 21,148.93805
Overall Steps per Second: 10,426.34970

Timestep Collection Time: 2.36418
Timestep Consumption Time: 2.43136
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.79554

Cumulative Model Updates: 128,542
Cumulative Timesteps: 1,072,842,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1072842716...
Checkpoint 1072842716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,998.72088
Policy Entropy: 1.66222
Value Function Loss: 0.05521

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.31668
Value Function Update Magnitude: 0.35395

Collected Steps per Second: 21,484.44163
Overall Steps per Second: 10,627.43594

Timestep Collection Time: 2.32736
Timestep Consumption Time: 2.37763
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.70499

Cumulative Model Updates: 128,548
Cumulative Timesteps: 1,072,892,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,424.66888
Policy Entropy: 1.66028
Value Function Loss: 0.05674

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.32083
Value Function Update Magnitude: 0.34954

Collected Steps per Second: 21,353.59620
Overall Steps per Second: 10,451.76121

Timestep Collection Time: 2.34265
Timestep Consumption Time: 2.44353
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.78618

Cumulative Model Updates: 128,554
Cumulative Timesteps: 1,072,942,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1072942742...
Checkpoint 1072942742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,732.25504
Policy Entropy: 1.64976
Value Function Loss: 0.05838

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.32090
Value Function Update Magnitude: 0.36247

Collected Steps per Second: 21,399.47647
Overall Steps per Second: 10,503.71683

Timestep Collection Time: 2.33735
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.76193

Cumulative Model Updates: 128,560
Cumulative Timesteps: 1,072,992,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,633.20206
Policy Entropy: 1.66206
Value Function Loss: 0.05921

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.31777
Value Function Update Magnitude: 0.35469

Collected Steps per Second: 21,953.16360
Overall Steps per Second: 10,507.97296

Timestep Collection Time: 2.27858
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.76039

Cumulative Model Updates: 128,566
Cumulative Timesteps: 1,073,042,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1073042782...
Checkpoint 1073042782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,732.21840
Policy Entropy: 1.67587
Value Function Loss: 0.05746

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.31393
Value Function Update Magnitude: 0.33796

Collected Steps per Second: 21,899.19595
Overall Steps per Second: 10,678.17371

Timestep Collection Time: 2.28502
Timestep Consumption Time: 2.40118
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.68619

Cumulative Model Updates: 128,572
Cumulative Timesteps: 1,073,092,822

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,732.21840
Policy Entropy: 1.66597
Value Function Loss: 0.05458

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.30797
Value Function Update Magnitude: 0.32809

Collected Steps per Second: 21,739.13988
Overall Steps per Second: 10,398.19862

Timestep Collection Time: 2.30092
Timestep Consumption Time: 2.50953
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.81045

Cumulative Model Updates: 128,578
Cumulative Timesteps: 1,073,142,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1073142842...
Checkpoint 1073142842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,797.51706
Policy Entropy: 1.66411
Value Function Loss: 0.05763

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08036
Policy Update Magnitude: 0.30937
Value Function Update Magnitude: 0.32796

Collected Steps per Second: 22,138.59873
Overall Steps per Second: 10,652.03048

Timestep Collection Time: 2.25904
Timestep Consumption Time: 2.43603
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.69507

Cumulative Model Updates: 128,584
Cumulative Timesteps: 1,073,192,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.80702
Policy Entropy: 1.66572
Value Function Loss: 0.05744

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.31763
Value Function Update Magnitude: 0.33881

Collected Steps per Second: 21,382.08627
Overall Steps per Second: 10,521.47403

Timestep Collection Time: 2.33878
Timestep Consumption Time: 2.41417
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.75295

Cumulative Model Updates: 128,590
Cumulative Timesteps: 1,073,242,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1073242862...
Checkpoint 1073242862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,278.46828
Policy Entropy: 1.68818
Value Function Loss: 0.05603

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.31472
Value Function Update Magnitude: 0.34299

Collected Steps per Second: 21,371.36105
Overall Steps per Second: 10,487.32971

Timestep Collection Time: 2.34005
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.76861

Cumulative Model Updates: 128,596
Cumulative Timesteps: 1,073,292,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,597.25820
Policy Entropy: 1.68300
Value Function Loss: 0.05354

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08171
Policy Update Magnitude: 0.30847
Value Function Update Magnitude: 0.32059

Collected Steps per Second: 21,452.33602
Overall Steps per Second: 10,445.69438

Timestep Collection Time: 2.33075
Timestep Consumption Time: 2.45591
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.78666

Cumulative Model Updates: 128,602
Cumulative Timesteps: 1,073,342,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1073342872...
Checkpoint 1073342872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,583.61036
Policy Entropy: 1.67382
Value Function Loss: 0.05473

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.30693
Value Function Update Magnitude: 0.30581

Collected Steps per Second: 21,489.12597
Overall Steps per Second: 10,298.51063

Timestep Collection Time: 2.32769
Timestep Consumption Time: 2.52932
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.85701

Cumulative Model Updates: 128,608
Cumulative Timesteps: 1,073,392,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,666.02914
Policy Entropy: 1.65690
Value Function Loss: 0.05548

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.31135
Value Function Update Magnitude: 0.32580

Collected Steps per Second: 21,662.18378
Overall Steps per Second: 10,429.93627

Timestep Collection Time: 2.30826
Timestep Consumption Time: 2.48582
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.79408

Cumulative Model Updates: 128,614
Cumulative Timesteps: 1,073,442,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1073442894...
Checkpoint 1073442894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,301.51866
Policy Entropy: 1.66450
Value Function Loss: 0.05819

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.31660
Value Function Update Magnitude: 0.33202

Collected Steps per Second: 21,992.33786
Overall Steps per Second: 10,396.41800

Timestep Collection Time: 2.27443
Timestep Consumption Time: 2.53684
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.81127

Cumulative Model Updates: 128,620
Cumulative Timesteps: 1,073,492,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,638.32186
Policy Entropy: 1.67515
Value Function Loss: 0.06067

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.31984
Value Function Update Magnitude: 0.33642

Collected Steps per Second: 22,048.34076
Overall Steps per Second: 10,599.45523

Timestep Collection Time: 2.26829
Timestep Consumption Time: 2.45007
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.71836

Cumulative Model Updates: 128,626
Cumulative Timesteps: 1,073,542,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1073542926...
Checkpoint 1073542926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,640.85518
Policy Entropy: 1.68317
Value Function Loss: 0.06209

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.32449
Value Function Update Magnitude: 0.32819

Collected Steps per Second: 21,979.29319
Overall Steps per Second: 10,473.45008

Timestep Collection Time: 2.27523
Timestep Consumption Time: 2.49951
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.77474

Cumulative Model Updates: 128,632
Cumulative Timesteps: 1,073,592,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,899.24328
Policy Entropy: 1.68794
Value Function Loss: 0.06500

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.32495
Value Function Update Magnitude: 0.33444

Collected Steps per Second: 22,445.11789
Overall Steps per Second: 10,713.85865

Timestep Collection Time: 2.22864
Timestep Consumption Time: 2.44027
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.66891

Cumulative Model Updates: 128,638
Cumulative Timesteps: 1,073,642,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1073642956...
Checkpoint 1073642956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,460.79850
Policy Entropy: 1.68430
Value Function Loss: 0.06132

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.31862
Value Function Update Magnitude: 0.33704

Collected Steps per Second: 21,794.36685
Overall Steps per Second: 10,578.29955

Timestep Collection Time: 2.29500
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.72836

Cumulative Model Updates: 128,644
Cumulative Timesteps: 1,073,692,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,307.68162
Policy Entropy: 1.66826
Value Function Loss: 0.05485

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07939
Policy Update Magnitude: 0.31080
Value Function Update Magnitude: 0.34340

Collected Steps per Second: 22,027.09733
Overall Steps per Second: 10,537.29833

Timestep Collection Time: 2.27011
Timestep Consumption Time: 2.47532
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.74543

Cumulative Model Updates: 128,650
Cumulative Timesteps: 1,073,742,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1073742978...
Checkpoint 1073742978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,698.27793
Policy Entropy: 1.67846
Value Function Loss: 0.05452

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07741
Policy Update Magnitude: 0.30854
Value Function Update Magnitude: 0.33577

Collected Steps per Second: 21,675.89911
Overall Steps per Second: 10,553.67011

Timestep Collection Time: 2.30726
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.73883

Cumulative Model Updates: 128,656
Cumulative Timesteps: 1,073,792,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,387.71980
Policy Entropy: 1.68019
Value Function Loss: 0.05723

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08126
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.32435

Collected Steps per Second: 21,535.62935
Overall Steps per Second: 10,512.73894

Timestep Collection Time: 2.32406
Timestep Consumption Time: 2.43683
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.76089

Cumulative Model Updates: 128,662
Cumulative Timesteps: 1,073,843,040

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1073843040...
Checkpoint 1073843040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,370.74937
Policy Entropy: 1.69594
Value Function Loss: 0.06183

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.30328
Value Function Update Magnitude: 0.32657

Collected Steps per Second: 21,534.10318
Overall Steps per Second: 10,377.38147

Timestep Collection Time: 2.32311
Timestep Consumption Time: 2.49757
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.82068

Cumulative Model Updates: 128,668
Cumulative Timesteps: 1,073,893,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,027.48322
Policy Entropy: 1.67582
Value Function Loss: 0.05986

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.28099
Value Function Update Magnitude: 0.35608

Collected Steps per Second: 21,102.50903
Overall Steps per Second: 10,415.33676

Timestep Collection Time: 2.36939
Timestep Consumption Time: 2.43123
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.80061

Cumulative Model Updates: 128,674
Cumulative Timesteps: 1,073,943,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1073943066...
Checkpoint 1073943066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,328.32949
Policy Entropy: 1.67968
Value Function Loss: 0.05906

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.28909
Value Function Update Magnitude: 0.36792

Collected Steps per Second: 20,893.11621
Overall Steps per Second: 10,475.55783

Timestep Collection Time: 2.39495
Timestep Consumption Time: 2.38169
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.77664

Cumulative Model Updates: 128,680
Cumulative Timesteps: 1,073,993,104

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,932.23688
Policy Entropy: 1.68622
Value Function Loss: 0.05900

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.30552
Value Function Update Magnitude: 0.38390

Collected Steps per Second: 21,064.05449
Overall Steps per Second: 10,530.89067

Timestep Collection Time: 2.37381
Timestep Consumption Time: 2.37432
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.74813

Cumulative Model Updates: 128,686
Cumulative Timesteps: 1,074,043,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1074043106...
Checkpoint 1074043106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,988.05537
Policy Entropy: 1.68294
Value Function Loss: 0.05725

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.30668
Value Function Update Magnitude: 0.38590

Collected Steps per Second: 21,115.17103
Overall Steps per Second: 10,380.39750

Timestep Collection Time: 2.36967
Timestep Consumption Time: 2.45057
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.82024

Cumulative Model Updates: 128,692
Cumulative Timesteps: 1,074,093,142

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,762.70706
Policy Entropy: 1.68348
Value Function Loss: 0.05670

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.30526
Value Function Update Magnitude: 0.39222

Collected Steps per Second: 21,761.99763
Overall Steps per Second: 10,702.68921

Timestep Collection Time: 2.29777
Timestep Consumption Time: 2.37433
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.67210

Cumulative Model Updates: 128,698
Cumulative Timesteps: 1,074,143,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1074143146...
Checkpoint 1074143146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,899.04756
Policy Entropy: 1.66402
Value Function Loss: 0.05297

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.30371
Value Function Update Magnitude: 0.37278

Collected Steps per Second: 21,300.45273
Overall Steps per Second: 10,354.56937

Timestep Collection Time: 2.34821
Timestep Consumption Time: 2.48231
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.83052

Cumulative Model Updates: 128,704
Cumulative Timesteps: 1,074,193,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,626.84059
Policy Entropy: 1.67364
Value Function Loss: 0.05532

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.30920
Value Function Update Magnitude: 0.34398

Collected Steps per Second: 22,223.38744
Overall Steps per Second: 10,721.53794

Timestep Collection Time: 2.25042
Timestep Consumption Time: 2.41421
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.66463

Cumulative Model Updates: 128,710
Cumulative Timesteps: 1,074,243,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1074243176...
Checkpoint 1074243176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,551.76420
Policy Entropy: 1.65922
Value Function Loss: 0.05422

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.31085
Value Function Update Magnitude: 0.34275

Collected Steps per Second: 21,793.56017
Overall Steps per Second: 10,608.58159

Timestep Collection Time: 2.29554
Timestep Consumption Time: 2.42026
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.71580

Cumulative Model Updates: 128,716
Cumulative Timesteps: 1,074,293,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,740.17979
Policy Entropy: 1.66338
Value Function Loss: 0.05593

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.31286
Value Function Update Magnitude: 0.34753

Collected Steps per Second: 22,236.76402
Overall Steps per Second: 10,559.15032

Timestep Collection Time: 2.24961
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.73750

Cumulative Model Updates: 128,722
Cumulative Timesteps: 1,074,343,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1074343228...
Checkpoint 1074343228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,886.46769
Policy Entropy: 1.64380
Value Function Loss: 0.05596

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08552
Policy Update Magnitude: 0.31224
Value Function Update Magnitude: 0.34661

Collected Steps per Second: 21,488.96575
Overall Steps per Second: 10,347.01287

Timestep Collection Time: 2.32724
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.83328

Cumulative Model Updates: 128,728
Cumulative Timesteps: 1,074,393,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,850.08257
Policy Entropy: 1.65146
Value Function Loss: 0.05868

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.31011
Value Function Update Magnitude: 0.33314

Collected Steps per Second: 21,780.79509
Overall Steps per Second: 10,384.47661

Timestep Collection Time: 2.29670
Timestep Consumption Time: 2.52049
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.81719

Cumulative Model Updates: 128,734
Cumulative Timesteps: 1,074,443,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1074443262...
Checkpoint 1074443262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,645.44405
Policy Entropy: 1.63606
Value Function Loss: 0.05882

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.31702
Value Function Update Magnitude: 0.30070

Collected Steps per Second: 21,599.00597
Overall Steps per Second: 10,525.93819

Timestep Collection Time: 2.31631
Timestep Consumption Time: 2.43671
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.75302

Cumulative Model Updates: 128,740
Cumulative Timesteps: 1,074,493,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,043.80439
Policy Entropy: 1.65892
Value Function Loss: 0.05869

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.31990
Value Function Update Magnitude: 0.33688

Collected Steps per Second: 21,858.20523
Overall Steps per Second: 10,460.31600

Timestep Collection Time: 2.28875
Timestep Consumption Time: 2.49390
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.78265

Cumulative Model Updates: 128,746
Cumulative Timesteps: 1,074,543,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1074543320...
Checkpoint 1074543320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,674.91373
Policy Entropy: 1.66434
Value Function Loss: 0.06360

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.32794
Value Function Update Magnitude: 0.36143

Collected Steps per Second: 21,131.75430
Overall Steps per Second: 10,222.98385

Timestep Collection Time: 2.36677
Timestep Consumption Time: 2.52554
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.89231

Cumulative Model Updates: 128,752
Cumulative Timesteps: 1,074,593,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,466.88760
Policy Entropy: 1.66109
Value Function Loss: 0.06164

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.32763
Value Function Update Magnitude: 0.36463

Collected Steps per Second: 21,689.74763
Overall Steps per Second: 10,506.63193

Timestep Collection Time: 2.30625
Timestep Consumption Time: 2.45474
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.76099

Cumulative Model Updates: 128,758
Cumulative Timesteps: 1,074,643,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1074643356...
Checkpoint 1074643356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,174.17279
Policy Entropy: 1.66362
Value Function Loss: 0.06680

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.33211
Value Function Update Magnitude: 0.38062

Collected Steps per Second: 21,730.33306
Overall Steps per Second: 10,356.78497

Timestep Collection Time: 2.30158
Timestep Consumption Time: 2.52753
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.82910

Cumulative Model Updates: 128,764
Cumulative Timesteps: 1,074,693,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,092.16650
Policy Entropy: 1.64164
Value Function Loss: 0.05862

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.32499
Value Function Update Magnitude: 0.38049

Collected Steps per Second: 22,493.23806
Overall Steps per Second: 10,664.40361

Timestep Collection Time: 2.22307
Timestep Consumption Time: 2.46580
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.68887

Cumulative Model Updates: 128,770
Cumulative Timesteps: 1,074,743,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1074743374...
Checkpoint 1074743374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,856.67423
Policy Entropy: 1.65836
Value Function Loss: 0.05812

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08888
Policy Update Magnitude: 0.31905
Value Function Update Magnitude: 0.36499

Collected Steps per Second: 21,823.67821
Overall Steps per Second: 10,551.01227

Timestep Collection Time: 2.29109
Timestep Consumption Time: 2.44779
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.73888

Cumulative Model Updates: 128,776
Cumulative Timesteps: 1,074,793,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,688.73995
Policy Entropy: 1.66060
Value Function Loss: 0.05531

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.31190
Value Function Update Magnitude: 0.35243

Collected Steps per Second: 22,121.35900
Overall Steps per Second: 10,522.71336

Timestep Collection Time: 2.26143
Timestep Consumption Time: 2.49266
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.75410

Cumulative Model Updates: 128,782
Cumulative Timesteps: 1,074,843,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1074843400...
Checkpoint 1074843400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,743.02659
Policy Entropy: 1.66310
Value Function Loss: 0.05649

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.31311
Value Function Update Magnitude: 0.35217

Collected Steps per Second: 21,962.73720
Overall Steps per Second: 10,610.20763

Timestep Collection Time: 2.27749
Timestep Consumption Time: 2.43683
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.71433

Cumulative Model Updates: 128,788
Cumulative Timesteps: 1,074,893,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,631.71323
Policy Entropy: 1.64730
Value Function Loss: 0.06086

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.32011
Value Function Update Magnitude: 0.36953

Collected Steps per Second: 22,274.18156
Overall Steps per Second: 10,504.83634

Timestep Collection Time: 2.24646
Timestep Consumption Time: 2.51687
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.76333

Cumulative Model Updates: 128,794
Cumulative Timesteps: 1,074,943,458

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1074943458...
Checkpoint 1074943458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,412.30587
Policy Entropy: 1.65079
Value Function Loss: 0.05982

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.32157
Value Function Update Magnitude: 0.37040

Collected Steps per Second: 21,808.80676
Overall Steps per Second: 10,598.53777

Timestep Collection Time: 2.29421
Timestep Consumption Time: 2.42663
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.72084

Cumulative Model Updates: 128,800
Cumulative Timesteps: 1,074,993,492

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,842.18393
Policy Entropy: 1.66361
Value Function Loss: 0.06202

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.32241
Value Function Update Magnitude: 0.38808

Collected Steps per Second: 21,582.25617
Overall Steps per Second: 10,514.42366

Timestep Collection Time: 2.31802
Timestep Consumption Time: 2.44002
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.75804

Cumulative Model Updates: 128,806
Cumulative Timesteps: 1,075,043,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1075043520...
Checkpoint 1075043520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,719.08355
Policy Entropy: 1.66162
Value Function Loss: 0.05594

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.31755
Value Function Update Magnitude: 0.38626

Collected Steps per Second: 21,416.19654
Overall Steps per Second: 10,356.25968

Timestep Collection Time: 2.33468
Timestep Consumption Time: 2.49332
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.82800

Cumulative Model Updates: 128,812
Cumulative Timesteps: 1,075,093,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,980.08814
Policy Entropy: 1.64338
Value Function Loss: 0.05542

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.30774
Value Function Update Magnitude: 0.34291

Collected Steps per Second: 21,905.07015
Overall Steps per Second: 10,458.74354

Timestep Collection Time: 2.28331
Timestep Consumption Time: 2.49891
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.78222

Cumulative Model Updates: 128,818
Cumulative Timesteps: 1,075,143,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1075143536...
Checkpoint 1075143536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,321.27545
Policy Entropy: 1.63651
Value Function Loss: 0.05291

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.30793
Value Function Update Magnitude: 0.33226

Collected Steps per Second: 21,462.39226
Overall Steps per Second: 10,466.51907

Timestep Collection Time: 2.33050
Timestep Consumption Time: 2.44836
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.77886

Cumulative Model Updates: 128,824
Cumulative Timesteps: 1,075,193,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,220.91564
Policy Entropy: 1.64611
Value Function Loss: 0.05467

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.31103
Value Function Update Magnitude: 0.33928

Collected Steps per Second: 21,770.66762
Overall Steps per Second: 10,555.69185

Timestep Collection Time: 2.29777
Timestep Consumption Time: 2.44128
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.73905

Cumulative Model Updates: 128,830
Cumulative Timesteps: 1,075,243,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1075243578...
Checkpoint 1075243578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,978.52404
Policy Entropy: 1.65410
Value Function Loss: 0.05346

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07883
Policy Update Magnitude: 0.31195
Value Function Update Magnitude: 0.33765

Collected Steps per Second: 21,779.44252
Overall Steps per Second: 10,448.77621

Timestep Collection Time: 2.29767
Timestep Consumption Time: 2.49160
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.78927

Cumulative Model Updates: 128,836
Cumulative Timesteps: 1,075,293,620

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,476.72849
Policy Entropy: 1.65477
Value Function Loss: 0.05579

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.31088
Value Function Update Magnitude: 0.33068

Collected Steps per Second: 21,845.88424
Overall Steps per Second: 10,527.06751

Timestep Collection Time: 2.29087
Timestep Consumption Time: 2.46316
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.75403

Cumulative Model Updates: 128,842
Cumulative Timesteps: 1,075,343,666

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1075343666...
Checkpoint 1075343666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,657.44648
Policy Entropy: 1.66083
Value Function Loss: 0.05707

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.31263
Value Function Update Magnitude: 0.32247

Collected Steps per Second: 21,390.32036
Overall Steps per Second: 10,298.93262

Timestep Collection Time: 2.33816
Timestep Consumption Time: 2.51807
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.85623

Cumulative Model Updates: 128,848
Cumulative Timesteps: 1,075,393,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,521.02419
Policy Entropy: 1.65658
Value Function Loss: 0.05470

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.31230
Value Function Update Magnitude: 0.31664

Collected Steps per Second: 21,834.36710
Overall Steps per Second: 10,400.38250

Timestep Collection Time: 2.29070
Timestep Consumption Time: 2.51835
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.80905

Cumulative Model Updates: 128,854
Cumulative Timesteps: 1,075,443,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1075443696...
Checkpoint 1075443696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,008.70148
Policy Entropy: 1.65660
Value Function Loss: 0.05264

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07939
Policy Update Magnitude: 0.30252
Value Function Update Magnitude: 0.31469

Collected Steps per Second: 21,552.24893
Overall Steps per Second: 10,546.09733

Timestep Collection Time: 2.32031
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.74185

Cumulative Model Updates: 128,860
Cumulative Timesteps: 1,075,493,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,092.14326
Policy Entropy: 1.65347
Value Function Loss: 0.05636

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.30738
Value Function Update Magnitude: 0.31475

Collected Steps per Second: 22,017.47449
Overall Steps per Second: 10,498.45887

Timestep Collection Time: 2.27120
Timestep Consumption Time: 2.49198
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.76318

Cumulative Model Updates: 128,866
Cumulative Timesteps: 1,075,543,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1075543710...
Checkpoint 1075543710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,507.67385
Policy Entropy: 1.65586
Value Function Loss: 0.06013

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.31269
Value Function Update Magnitude: 0.33843

Collected Steps per Second: 21,599.53303
Overall Steps per Second: 10,400.78797

Timestep Collection Time: 2.31588
Timestep Consumption Time: 2.49356
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.80944

Cumulative Model Updates: 128,872
Cumulative Timesteps: 1,075,593,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,488.60492
Policy Entropy: 1.65082
Value Function Loss: 0.05965

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.31665
Value Function Update Magnitude: 0.36789

Collected Steps per Second: 21,124.95181
Overall Steps per Second: 10,435.92206

Timestep Collection Time: 2.36876
Timestep Consumption Time: 2.42621
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.79498

Cumulative Model Updates: 128,878
Cumulative Timesteps: 1,075,643,772

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1075643772...
Checkpoint 1075643772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,060.54056
Policy Entropy: 1.65525
Value Function Loss: 0.06072

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07913
Policy Update Magnitude: 0.32103
Value Function Update Magnitude: 0.35466

Collected Steps per Second: 21,001.71979
Overall Steps per Second: 10,580.52031

Timestep Collection Time: 2.38104
Timestep Consumption Time: 2.34519
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.72623

Cumulative Model Updates: 128,884
Cumulative Timesteps: 1,075,693,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,674.42166
Policy Entropy: 1.66020
Value Function Loss: 0.05728

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.32274
Value Function Update Magnitude: 0.34880

Collected Steps per Second: 21,369.20855
Overall Steps per Second: 10,454.78001

Timestep Collection Time: 2.34169
Timestep Consumption Time: 2.44464
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.78633

Cumulative Model Updates: 128,890
Cumulative Timesteps: 1,075,743,818

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1075743818...
Checkpoint 1075743818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,654.73448
Policy Entropy: 1.67925
Value Function Loss: 0.05764

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.31872
Value Function Update Magnitude: 0.34426

Collected Steps per Second: 20,902.47272
Overall Steps per Second: 10,306.46408

Timestep Collection Time: 2.39254
Timestep Consumption Time: 2.45975
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.85229

Cumulative Model Updates: 128,896
Cumulative Timesteps: 1,075,793,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,637.97741
Policy Entropy: 1.67247
Value Function Loss: 0.05527

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.31782
Value Function Update Magnitude: 0.32331

Collected Steps per Second: 21,139.52943
Overall Steps per Second: 10,292.04093

Timestep Collection Time: 2.36590
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.85948

Cumulative Model Updates: 128,902
Cumulative Timesteps: 1,075,843,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1075843842...
Checkpoint 1075843842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,684.76874
Policy Entropy: 1.67159
Value Function Loss: 0.05853

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.31725
Value Function Update Magnitude: 0.29973

Collected Steps per Second: 21,761.01182
Overall Steps per Second: 10,592.55165

Timestep Collection Time: 2.29796
Timestep Consumption Time: 2.42290
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.72086

Cumulative Model Updates: 128,908
Cumulative Timesteps: 1,075,893,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,900.79192
Policy Entropy: 1.67787
Value Function Loss: 0.05802

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.31645
Value Function Update Magnitude: 0.30647

Collected Steps per Second: 22,109.51985
Overall Steps per Second: 10,524.52189

Timestep Collection Time: 2.26165
Timestep Consumption Time: 2.48954
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.75119

Cumulative Model Updates: 128,914
Cumulative Timesteps: 1,075,943,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1075943852...
Checkpoint 1075943852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,073.49479
Policy Entropy: 1.67690
Value Function Loss: 0.05967

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.31360
Value Function Update Magnitude: 0.31686

Collected Steps per Second: 21,668.32684
Overall Steps per Second: 10,594.06795

Timestep Collection Time: 2.30788
Timestep Consumption Time: 2.41249
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.72038

Cumulative Model Updates: 128,920
Cumulative Timesteps: 1,075,993,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,290.20044
Policy Entropy: 1.65961
Value Function Loss: 0.05582

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.10230
Policy Update Magnitude: 0.28962
Value Function Update Magnitude: 0.32207

Collected Steps per Second: 22,243.92187
Overall Steps per Second: 10,532.88183

Timestep Collection Time: 2.24888
Timestep Consumption Time: 2.50043
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.74932

Cumulative Model Updates: 128,926
Cumulative Timesteps: 1,076,043,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1076043884...
Checkpoint 1076043884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,798.18044
Policy Entropy: 1.66326
Value Function Loss: 0.05498

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.27536
Value Function Update Magnitude: 0.31495

Collected Steps per Second: 22,096.35953
Overall Steps per Second: 10,568.43955

Timestep Collection Time: 2.26363
Timestep Consumption Time: 2.46914
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.73277

Cumulative Model Updates: 128,932
Cumulative Timesteps: 1,076,093,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,769.71938
Policy Entropy: 1.68233
Value Function Loss: 0.05267

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.27238
Value Function Update Magnitude: 0.27171

Collected Steps per Second: 21,896.58054
Overall Steps per Second: 10,418.48563

Timestep Collection Time: 2.28474
Timestep Consumption Time: 2.51711
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.80185

Cumulative Model Updates: 128,938
Cumulative Timesteps: 1,076,143,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1076143930...
Checkpoint 1076143930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,464.12425
Policy Entropy: 1.70033
Value Function Loss: 0.05296

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.29377
Value Function Update Magnitude: 0.25644

Collected Steps per Second: 21,121.78108
Overall Steps per Second: 10,226.29497

Timestep Collection Time: 2.36732
Timestep Consumption Time: 2.52223
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.88955

Cumulative Model Updates: 128,944
Cumulative Timesteps: 1,076,193,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,352.59154
Policy Entropy: 1.69441
Value Function Loss: 0.05547

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.30238
Value Function Update Magnitude: 0.27870

Collected Steps per Second: 21,836.40861
Overall Steps per Second: 10,446.50585

Timestep Collection Time: 2.29085
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.78859

Cumulative Model Updates: 128,950
Cumulative Timesteps: 1,076,243,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1076243956...
Checkpoint 1076243956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,177.41839
Policy Entropy: 1.69590
Value Function Loss: 0.05221

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.30267
Value Function Update Magnitude: 0.31247

Collected Steps per Second: 21,562.61454
Overall Steps per Second: 10,543.52633

Timestep Collection Time: 2.31994
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.74452

Cumulative Model Updates: 128,956
Cumulative Timesteps: 1,076,293,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,572.87439
Policy Entropy: 1.70008
Value Function Loss: 0.05480

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.30279
Value Function Update Magnitude: 0.31935

Collected Steps per Second: 21,715.50021
Overall Steps per Second: 10,536.44123

Timestep Collection Time: 2.30416
Timestep Consumption Time: 2.44469
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.74885

Cumulative Model Updates: 128,962
Cumulative Timesteps: 1,076,344,016

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1076344016...
Checkpoint 1076344016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,295.41807
Policy Entropy: 1.70469
Value Function Loss: 0.06088

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.32703

Collected Steps per Second: 21,511.54817
Overall Steps per Second: 10,331.87978

Timestep Collection Time: 2.32517
Timestep Consumption Time: 2.51596
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.84113

Cumulative Model Updates: 128,968
Cumulative Timesteps: 1,076,394,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,603.31270
Policy Entropy: 1.69432
Value Function Loss: 0.06408

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.31881
Value Function Update Magnitude: 0.34593

Collected Steps per Second: 20,635.59549
Overall Steps per Second: 10,279.45239

Timestep Collection Time: 2.42309
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.86427

Cumulative Model Updates: 128,974
Cumulative Timesteps: 1,076,444,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1076444036...
Checkpoint 1076444036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,351.39204
Policy Entropy: 1.68287
Value Function Loss: 0.06465

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08621
Policy Update Magnitude: 0.31742
Value Function Update Magnitude: 0.35822

Collected Steps per Second: 21,463.72051
Overall Steps per Second: 10,358.50050

Timestep Collection Time: 2.33026
Timestep Consumption Time: 2.49824
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.82850

Cumulative Model Updates: 128,980
Cumulative Timesteps: 1,076,494,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,768.87607
Policy Entropy: 1.67736
Value Function Loss: 0.06060

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.31472
Value Function Update Magnitude: 0.35730

Collected Steps per Second: 21,933.79110
Overall Steps per Second: 10,483.63549

Timestep Collection Time: 2.28059
Timestep Consumption Time: 2.49085
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.77144

Cumulative Model Updates: 128,986
Cumulative Timesteps: 1,076,544,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1076544074...
Checkpoint 1076544074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,032.26806
Policy Entropy: 1.68313
Value Function Loss: 0.05850

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 20,886.64445
Overall Steps per Second: 10,484.04016

Timestep Collection Time: 2.39416
Timestep Consumption Time: 2.37556
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.76973

Cumulative Model Updates: 128,992
Cumulative Timesteps: 1,076,594,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,237.15098
Policy Entropy: 1.69418
Value Function Loss: 0.05766

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.31839
Value Function Update Magnitude: 0.32251

Collected Steps per Second: 21,783.90852
Overall Steps per Second: 10,523.75597

Timestep Collection Time: 2.29766
Timestep Consumption Time: 2.45844
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.75610

Cumulative Model Updates: 128,998
Cumulative Timesteps: 1,076,644,132

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1076644132...
Checkpoint 1076644132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,103.78839
Policy Entropy: 1.69288
Value Function Loss: 0.06203

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.31813
Value Function Update Magnitude: 0.31280

Collected Steps per Second: 20,845.48448
Overall Steps per Second: 10,494.65520

Timestep Collection Time: 2.39946
Timestep Consumption Time: 2.36658
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.76605

Cumulative Model Updates: 129,004
Cumulative Timesteps: 1,076,694,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,369.00320
Policy Entropy: 1.68753
Value Function Loss: 0.06821

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.32441
Value Function Update Magnitude: 0.29315

Collected Steps per Second: 21,385.67513
Overall Steps per Second: 10,565.65942

Timestep Collection Time: 2.33923
Timestep Consumption Time: 2.39554
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.73477

Cumulative Model Updates: 129,010
Cumulative Timesteps: 1,076,744,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1076744176...
Checkpoint 1076744176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,506.37854
Policy Entropy: 1.67592
Value Function Loss: 0.06640

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.32245
Value Function Update Magnitude: 0.27046

Collected Steps per Second: 21,187.96589
Overall Steps per Second: 10,587.12433

Timestep Collection Time: 2.36143
Timestep Consumption Time: 2.36449
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.72593

Cumulative Model Updates: 129,016
Cumulative Timesteps: 1,076,794,210

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,786.70252
Policy Entropy: 1.67762
Value Function Loss: 0.06183

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.31841
Value Function Update Magnitude: 0.23460

Collected Steps per Second: 21,392.18031
Overall Steps per Second: 10,546.67368

Timestep Collection Time: 2.33805
Timestep Consumption Time: 2.40430
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.74235

Cumulative Model Updates: 129,022
Cumulative Timesteps: 1,076,844,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1076844226...
Checkpoint 1076844226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,039.00581
Policy Entropy: 1.67889
Value Function Loss: 0.05618

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.31222
Value Function Update Magnitude: 0.27274

Collected Steps per Second: 21,899.24081
Overall Steps per Second: 10,670.19936

Timestep Collection Time: 2.28328
Timestep Consumption Time: 2.40286
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.68614

Cumulative Model Updates: 129,028
Cumulative Timesteps: 1,076,894,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,677.54724
Policy Entropy: 1.69275
Value Function Loss: 0.05370

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.30833
Value Function Update Magnitude: 0.30026

Collected Steps per Second: 21,764.05690
Overall Steps per Second: 10,458.62361

Timestep Collection Time: 2.29737
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.78074

Cumulative Model Updates: 129,034
Cumulative Timesteps: 1,076,944,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1076944228...
Checkpoint 1076944228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,987.89350
Policy Entropy: 1.70768
Value Function Loss: 0.05605

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.30619
Value Function Update Magnitude: 0.31243

Collected Steps per Second: 21,366.35453
Overall Steps per Second: 10,493.61170

Timestep Collection Time: 2.34031
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.76518

Cumulative Model Updates: 129,040
Cumulative Timesteps: 1,076,994,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,705.33346
Policy Entropy: 1.70554
Value Function Loss: 0.05616

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.30944
Value Function Update Magnitude: 0.32221

Collected Steps per Second: 21,614.76092
Overall Steps per Second: 10,517.60627

Timestep Collection Time: 2.31416
Timestep Consumption Time: 2.44168
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.75583

Cumulative Model Updates: 129,046
Cumulative Timesteps: 1,077,044,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1077044252...
Checkpoint 1077044252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,114.76946
Policy Entropy: 1.69257
Value Function Loss: 0.05975

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.32792

Collected Steps per Second: 21,713.60246
Overall Steps per Second: 10,546.25204

Timestep Collection Time: 2.30344
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.74254

Cumulative Model Updates: 129,052
Cumulative Timesteps: 1,077,094,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,805.78165
Policy Entropy: 1.69652
Value Function Loss: 0.05976

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.33265

Collected Steps per Second: 22,125.64316
Overall Steps per Second: 10,489.21346

Timestep Collection Time: 2.26127
Timestep Consumption Time: 2.50858
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.76985

Cumulative Model Updates: 129,058
Cumulative Timesteps: 1,077,144,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1077144300...
Checkpoint 1077144300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,286.75803
Policy Entropy: 1.70170
Value Function Loss: 0.05692

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.34411

Collected Steps per Second: 21,976.59196
Overall Steps per Second: 10,615.95907

Timestep Collection Time: 2.27615
Timestep Consumption Time: 2.43581
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.71196

Cumulative Model Updates: 129,064
Cumulative Timesteps: 1,077,194,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,118.14538
Policy Entropy: 1.69733
Value Function Loss: 0.05151

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.33134

Collected Steps per Second: 22,035.54504
Overall Steps per Second: 10,532.09856

Timestep Collection Time: 2.27024
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.74986

Cumulative Model Updates: 129,070
Cumulative Timesteps: 1,077,244,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1077244348...
Checkpoint 1077244348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,164.14392
Policy Entropy: 1.68742
Value Function Loss: 0.05378

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.30206
Value Function Update Magnitude: 0.30717

Collected Steps per Second: 22,084.84349
Overall Steps per Second: 10,633.15330

Timestep Collection Time: 2.26472
Timestep Consumption Time: 2.43906
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.70378

Cumulative Model Updates: 129,076
Cumulative Timesteps: 1,077,294,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,175.31921
Policy Entropy: 1.70723
Value Function Loss: 0.06719

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.31363
Value Function Update Magnitude: 0.33721

Collected Steps per Second: 21,969.59444
Overall Steps per Second: 10,509.88449

Timestep Collection Time: 2.27642
Timestep Consumption Time: 2.48215
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.75857

Cumulative Model Updates: 129,082
Cumulative Timesteps: 1,077,344,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1077344376...
Checkpoint 1077344376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,608.44943
Policy Entropy: 1.72800
Value Function Loss: 0.07251

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.31365
Value Function Update Magnitude: 0.35438

Collected Steps per Second: 22,088.45815
Overall Steps per Second: 10,522.45022

Timestep Collection Time: 2.26417
Timestep Consumption Time: 2.48872
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.75289

Cumulative Model Updates: 129,088
Cumulative Timesteps: 1,077,394,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,941.38056
Policy Entropy: 1.71449
Value Function Loss: 0.07057

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.28937
Value Function Update Magnitude: 0.35243

Collected Steps per Second: 21,095.44569
Overall Steps per Second: 10,440.06552

Timestep Collection Time: 2.37103
Timestep Consumption Time: 2.41993
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.79097

Cumulative Model Updates: 129,094
Cumulative Timesteps: 1,077,444,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1077444406...
Checkpoint 1077444406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,554.80099
Policy Entropy: 1.70384
Value Function Loss: 0.06249

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.28409
Value Function Update Magnitude: 0.35147

Collected Steps per Second: 21,321.18424
Overall Steps per Second: 10,297.45793

Timestep Collection Time: 2.34509
Timestep Consumption Time: 2.51048
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.85557

Cumulative Model Updates: 129,100
Cumulative Timesteps: 1,077,494,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,105.24837
Policy Entropy: 1.67693
Value Function Loss: 0.05744

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.28910
Value Function Update Magnitude: 0.33192

Collected Steps per Second: 21,521.08892
Overall Steps per Second: 10,496.64023

Timestep Collection Time: 2.32442
Timestep Consumption Time: 2.44130
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.76572

Cumulative Model Updates: 129,106
Cumulative Timesteps: 1,077,544,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1077544430...
Checkpoint 1077544430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,223.75186
Policy Entropy: 1.69399
Value Function Loss: 0.05680

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.29871
Value Function Update Magnitude: 0.30531

Collected Steps per Second: 21,763.18134
Overall Steps per Second: 10,521.27545

Timestep Collection Time: 2.29893
Timestep Consumption Time: 2.45639
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.75532

Cumulative Model Updates: 129,112
Cumulative Timesteps: 1,077,594,462

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,160.55193
Policy Entropy: 1.68653
Value Function Loss: 0.06158

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.30300
Value Function Update Magnitude: 0.29897

Collected Steps per Second: 21,838.63243
Overall Steps per Second: 10,549.50440

Timestep Collection Time: 2.29025
Timestep Consumption Time: 2.45082
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.74108

Cumulative Model Updates: 129,118
Cumulative Timesteps: 1,077,644,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1077644478...
Checkpoint 1077644478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,587.51857
Policy Entropy: 1.68515
Value Function Loss: 0.05634

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.30581
Value Function Update Magnitude: 0.29979

Collected Steps per Second: 22,164.63985
Overall Steps per Second: 10,528.42373

Timestep Collection Time: 2.25675
Timestep Consumption Time: 2.49420
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.75095

Cumulative Model Updates: 129,124
Cumulative Timesteps: 1,077,694,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,377.36072
Policy Entropy: 1.67345
Value Function Loss: 0.05339

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.30588
Value Function Update Magnitude: 0.30369

Collected Steps per Second: 22,006.78811
Overall Steps per Second: 10,468.29544

Timestep Collection Time: 2.27221
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.77671

Cumulative Model Updates: 129,130
Cumulative Timesteps: 1,077,744,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1077744502...
Checkpoint 1077744502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,321.12277
Policy Entropy: 1.66660
Value Function Loss: 0.05331

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.30938
Value Function Update Magnitude: 0.28458

Collected Steps per Second: 22,005.09139
Overall Steps per Second: 10,605.74468

Timestep Collection Time: 2.27238
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.71480

Cumulative Model Updates: 129,136
Cumulative Timesteps: 1,077,794,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,434.00023
Policy Entropy: 1.67381
Value Function Loss: 0.05862

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.31337
Value Function Update Magnitude: 0.30815

Collected Steps per Second: 21,746.97920
Overall Steps per Second: 10,572.18237

Timestep Collection Time: 2.29917
Timestep Consumption Time: 2.43022
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.72939

Cumulative Model Updates: 129,142
Cumulative Timesteps: 1,077,844,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1077844506...
Checkpoint 1077844506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,730.91610
Policy Entropy: 1.68615
Value Function Loss: 0.06245

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.31576
Value Function Update Magnitude: 0.31668

Collected Steps per Second: 22,009.72144
Overall Steps per Second: 10,557.31805

Timestep Collection Time: 2.27300
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.73870

Cumulative Model Updates: 129,148
Cumulative Timesteps: 1,077,894,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,714.07498
Policy Entropy: 1.69280
Value Function Loss: 0.05891

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.31454
Value Function Update Magnitude: 0.30213

Collected Steps per Second: 21,749.13929
Overall Steps per Second: 10,431.66308

Timestep Collection Time: 2.30014
Timestep Consumption Time: 2.49545
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.79559

Cumulative Model Updates: 129,154
Cumulative Timesteps: 1,077,944,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1077944560...
Checkpoint 1077944560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,339.30478
Policy Entropy: 1.70505
Value Function Loss: 0.05453

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.30712

Collected Steps per Second: 21,384.44890
Overall Steps per Second: 10,303.50117

Timestep Collection Time: 2.33815
Timestep Consumption Time: 2.51457
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.85272

Cumulative Model Updates: 129,160
Cumulative Timesteps: 1,077,994,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,366.16387
Policy Entropy: 1.69930
Value Function Loss: 0.05531

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.30844
Value Function Update Magnitude: 0.32667

Collected Steps per Second: 21,383.73881
Overall Steps per Second: 10,376.37001

Timestep Collection Time: 2.33841
Timestep Consumption Time: 2.48061
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.81903

Cumulative Model Updates: 129,166
Cumulative Timesteps: 1,078,044,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1078044564...
Checkpoint 1078044564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,101.49295
Policy Entropy: 1.69336
Value Function Loss: 0.05587

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.31024
Value Function Update Magnitude: 0.33538

Collected Steps per Second: 21,790.15867
Overall Steps per Second: 10,587.73009

Timestep Collection Time: 2.29672
Timestep Consumption Time: 2.43007
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.72679

Cumulative Model Updates: 129,172
Cumulative Timesteps: 1,078,094,610

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,002.54619
Policy Entropy: 1.66971
Value Function Loss: 0.06161

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.31181
Value Function Update Magnitude: 0.34857

Collected Steps per Second: 22,229.86304
Overall Steps per Second: 10,511.06691

Timestep Collection Time: 2.25049
Timestep Consumption Time: 2.50907
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.75955

Cumulative Model Updates: 129,178
Cumulative Timesteps: 1,078,144,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1078144638...
Checkpoint 1078144638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,331.92032
Policy Entropy: 1.65531
Value Function Loss: 0.05578

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.30792
Value Function Update Magnitude: 0.34848

Collected Steps per Second: 22,029.62320
Overall Steps per Second: 10,623.65052

Timestep Collection Time: 2.26994
Timestep Consumption Time: 2.43710
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.70704

Cumulative Model Updates: 129,184
Cumulative Timesteps: 1,078,194,644

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,868.42813
Policy Entropy: 1.67492
Value Function Loss: 0.06192

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07678
Policy Update Magnitude: 0.31629
Value Function Update Magnitude: 0.32961

Collected Steps per Second: 22,230.26602
Overall Steps per Second: 10,506.69357

Timestep Collection Time: 2.24991
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.76039

Cumulative Model Updates: 129,190
Cumulative Timesteps: 1,078,244,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1078244660...
Checkpoint 1078244660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,749.25520
Policy Entropy: 1.69487
Value Function Loss: 0.05782

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.31747
Value Function Update Magnitude: 0.32594

Collected Steps per Second: 21,567.15151
Overall Steps per Second: 10,587.11624

Timestep Collection Time: 2.31982
Timestep Consumption Time: 2.40592
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.72574

Cumulative Model Updates: 129,196
Cumulative Timesteps: 1,078,294,692

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,368.84622
Policy Entropy: 1.70000
Value Function Loss: 0.06313

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.31038
Value Function Update Magnitude: 0.33086

Collected Steps per Second: 21,140.60093
Overall Steps per Second: 10,449.46683

Timestep Collection Time: 2.36606
Timestep Consumption Time: 2.42078
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.78685

Cumulative Model Updates: 129,202
Cumulative Timesteps: 1,078,344,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1078344712...
Checkpoint 1078344712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,577.08737
Policy Entropy: 1.68167
Value Function Loss: 0.05747

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.30178
Value Function Update Magnitude: 0.33626

Collected Steps per Second: 21,337.54585
Overall Steps per Second: 10,633.63575

Timestep Collection Time: 2.34451
Timestep Consumption Time: 2.36000
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.70451

Cumulative Model Updates: 129,208
Cumulative Timesteps: 1,078,394,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,207.68808
Policy Entropy: 1.67024
Value Function Loss: 0.06018

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.27236
Value Function Update Magnitude: 0.33302

Collected Steps per Second: 20,415.35001
Overall Steps per Second: 10,425.53997

Timestep Collection Time: 2.44924
Timestep Consumption Time: 2.34687
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.79611

Cumulative Model Updates: 129,214
Cumulative Timesteps: 1,078,444,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1078444740...
Checkpoint 1078444740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,496.71661
Policy Entropy: 1.66548
Value Function Loss: 0.05818

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.27901
Value Function Update Magnitude: 0.32451

Collected Steps per Second: 20,548.31500
Overall Steps per Second: 10,266.84855

Timestep Collection Time: 2.43378
Timestep Consumption Time: 2.43724
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.87102

Cumulative Model Updates: 129,220
Cumulative Timesteps: 1,078,494,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,253.53294
Policy Entropy: 1.66557
Value Function Loss: 0.05785

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.29083
Value Function Update Magnitude: 0.32825

Collected Steps per Second: 21,308.07119
Overall Steps per Second: 10,509.43065

Timestep Collection Time: 2.34719
Timestep Consumption Time: 2.41178
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.75896

Cumulative Model Updates: 129,226
Cumulative Timesteps: 1,078,544,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1078544764...
Checkpoint 1078544764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,948.00854
Policy Entropy: 1.65808
Value Function Loss: 0.05715

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.29586
Value Function Update Magnitude: 0.30867

Collected Steps per Second: 21,414.65513
Overall Steps per Second: 10,517.67679

Timestep Collection Time: 2.33560
Timestep Consumption Time: 2.41983
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.75542

Cumulative Model Updates: 129,232
Cumulative Timesteps: 1,078,594,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,774.88776
Policy Entropy: 1.65731
Value Function Loss: 0.05671

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.28335
Value Function Update Magnitude: 0.28886

Collected Steps per Second: 21,330.92502
Overall Steps per Second: 10,497.26776

Timestep Collection Time: 2.34476
Timestep Consumption Time: 2.41990
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.76467

Cumulative Model Updates: 129,238
Cumulative Timesteps: 1,078,644,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1078644796...
Checkpoint 1078644796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,247.25734
Policy Entropy: 1.66400
Value Function Loss: 0.05772

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.29520
Value Function Update Magnitude: 0.30536

Collected Steps per Second: 21,968.58424
Overall Steps per Second: 10,591.44162

Timestep Collection Time: 2.27634
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.72155

Cumulative Model Updates: 129,244
Cumulative Timesteps: 1,078,694,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,108.63776
Policy Entropy: 1.66761
Value Function Loss: 0.05663

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.31187
Value Function Update Magnitude: 0.28644

Collected Steps per Second: 22,247.34170
Overall Steps per Second: 10,481.26390

Timestep Collection Time: 2.24881
Timestep Consumption Time: 2.52447
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.77328

Cumulative Model Updates: 129,250
Cumulative Timesteps: 1,078,744,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1078744834...
Checkpoint 1078744834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,281.74078
Policy Entropy: 1.65635
Value Function Loss: 0.05692

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.31648
Value Function Update Magnitude: 0.24806

Collected Steps per Second: 21,648.15079
Overall Steps per Second: 10,416.74241

Timestep Collection Time: 2.30967
Timestep Consumption Time: 2.49030
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.79997

Cumulative Model Updates: 129,256
Cumulative Timesteps: 1,078,794,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,134.75118
Policy Entropy: 1.65949
Value Function Loss: 0.05929

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.31837
Value Function Update Magnitude: 0.23915

Collected Steps per Second: 21,972.76015
Overall Steps per Second: 10,627.38423

Timestep Collection Time: 2.27682
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.70746

Cumulative Model Updates: 129,262
Cumulative Timesteps: 1,078,844,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1078844862...
Checkpoint 1078844862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,329.70414
Policy Entropy: 1.65184
Value Function Loss: 0.05803

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07752
Policy Update Magnitude: 0.31703
Value Function Update Magnitude: 0.22096

Collected Steps per Second: 21,909.40452
Overall Steps per Second: 10,486.33359

Timestep Collection Time: 2.28340
Timestep Consumption Time: 2.48738
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.77078

Cumulative Model Updates: 129,268
Cumulative Timesteps: 1,078,894,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,784.88729
Policy Entropy: 1.68482
Value Function Loss: 0.06087

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.31869
Value Function Update Magnitude: 0.24966

Collected Steps per Second: 22,259.61884
Overall Steps per Second: 10,666.83550

Timestep Collection Time: 2.24649
Timestep Consumption Time: 2.44150
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.68799

Cumulative Model Updates: 129,274
Cumulative Timesteps: 1,078,944,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1078944896...
Checkpoint 1078944896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,394.94904
Policy Entropy: 1.66320
Value Function Loss: 0.05663

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.31852
Value Function Update Magnitude: 0.30930

Collected Steps per Second: 21,810.45625
Overall Steps per Second: 10,589.50129

Timestep Collection Time: 2.29321
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.72317

Cumulative Model Updates: 129,280
Cumulative Timesteps: 1,078,994,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,364.95163
Policy Entropy: 1.67189
Value Function Loss: 0.05737

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.31509
Value Function Update Magnitude: 0.33335

Collected Steps per Second: 21,775.05708
Overall Steps per Second: 10,554.63047

Timestep Collection Time: 2.29786
Timestep Consumption Time: 2.44281
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.74067

Cumulative Model Updates: 129,286
Cumulative Timesteps: 1,079,044,948

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1079044948...
Checkpoint 1079044948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,279.27300
Policy Entropy: 1.68333
Value Function Loss: 0.05916

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08276
Policy Update Magnitude: 0.31937
Value Function Update Magnitude: 0.34119

Collected Steps per Second: 21,174.29585
Overall Steps per Second: 10,280.23242

Timestep Collection Time: 2.36220
Timestep Consumption Time: 2.50325
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.86545

Cumulative Model Updates: 129,292
Cumulative Timesteps: 1,079,094,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,859.21673
Policy Entropy: 1.69633
Value Function Loss: 0.06331

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.32719
Value Function Update Magnitude: 0.35234

Collected Steps per Second: 21,687.95427
Overall Steps per Second: 10,368.78069

Timestep Collection Time: 2.30589
Timestep Consumption Time: 2.51724
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.82313

Cumulative Model Updates: 129,298
Cumulative Timesteps: 1,079,144,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1079144976...
Checkpoint 1079144976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,654.81562
Policy Entropy: 1.70353
Value Function Loss: 0.06088

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07939
Policy Update Magnitude: 0.32599
Value Function Update Magnitude: 0.36122

Collected Steps per Second: 21,659.00589
Overall Steps per Second: 10,534.07561

Timestep Collection Time: 2.30934
Timestep Consumption Time: 2.43887
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.74821

Cumulative Model Updates: 129,304
Cumulative Timesteps: 1,079,194,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,955.98916
Policy Entropy: 1.68940
Value Function Loss: 0.06004

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.31720
Value Function Update Magnitude: 0.34010

Collected Steps per Second: 22,069.12127
Overall Steps per Second: 10,582.21739

Timestep Collection Time: 2.26706
Timestep Consumption Time: 2.46087
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.72793

Cumulative Model Updates: 129,310
Cumulative Timesteps: 1,079,245,026

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1079245026...
Checkpoint 1079245026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,353.59943
Policy Entropy: 1.69059
Value Function Loss: 0.05482

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.30976
Value Function Update Magnitude: 0.29924

Collected Steps per Second: 22,184.80942
Overall Steps per Second: 10,522.24924

Timestep Collection Time: 2.25461
Timestep Consumption Time: 2.49894
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.75355

Cumulative Model Updates: 129,316
Cumulative Timesteps: 1,079,295,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,868.96962
Policy Entropy: 1.68304
Value Function Loss: 0.05267

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.30563
Value Function Update Magnitude: 0.29976

Collected Steps per Second: 21,458.97892
Overall Steps per Second: 10,537.31479

Timestep Collection Time: 2.33115
Timestep Consumption Time: 2.41617
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.74732

Cumulative Model Updates: 129,322
Cumulative Timesteps: 1,079,345,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1079345068...
Checkpoint 1079345068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,036.89270
Policy Entropy: 1.67469
Value Function Loss: 0.05127

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.30670
Value Function Update Magnitude: 0.28467

Collected Steps per Second: 21,234.40272
Overall Steps per Second: 10,571.27364

Timestep Collection Time: 2.35523
Timestep Consumption Time: 2.37570
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.73093

Cumulative Model Updates: 129,328
Cumulative Timesteps: 1,079,395,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,152.63056
Policy Entropy: 1.66435
Value Function Loss: 0.05901

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07458
Policy Update Magnitude: 0.31285
Value Function Update Magnitude: 0.26238

Collected Steps per Second: 21,350.27511
Overall Steps per Second: 10,532.49815

Timestep Collection Time: 2.34226
Timestep Consumption Time: 2.40571
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.74797

Cumulative Model Updates: 129,334
Cumulative Timesteps: 1,079,445,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1079445088...
Checkpoint 1079445088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,711.04410
Policy Entropy: 1.66723
Value Function Loss: 0.06306

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.32201
Value Function Update Magnitude: 0.26910

Collected Steps per Second: 21,278.76768
Overall Steps per Second: 10,619.42484

Timestep Collection Time: 2.35108
Timestep Consumption Time: 2.35991
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.71099

Cumulative Model Updates: 129,340
Cumulative Timesteps: 1,079,495,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,577.59095
Policy Entropy: 1.66727
Value Function Loss: 0.06434

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07874
Policy Update Magnitude: 0.32531
Value Function Update Magnitude: 0.29417

Collected Steps per Second: 21,511.56926
Overall Steps per Second: 10,496.22118

Timestep Collection Time: 2.32489
Timestep Consumption Time: 2.43987
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.76476

Cumulative Model Updates: 129,346
Cumulative Timesteps: 1,079,545,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1079545128...
Checkpoint 1079545128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,858.93361
Policy Entropy: 1.67350
Value Function Loss: 0.05965

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.32244
Value Function Update Magnitude: 0.32366

Collected Steps per Second: 20,955.86552
Overall Steps per Second: 10,269.41117

Timestep Collection Time: 2.38663
Timestep Consumption Time: 2.48356
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.87019

Cumulative Model Updates: 129,352
Cumulative Timesteps: 1,079,595,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,661.41529
Policy Entropy: 1.65926
Value Function Loss: 0.05546

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.31255
Value Function Update Magnitude: 0.31626

Collected Steps per Second: 21,639.27646
Overall Steps per Second: 10,439.64868

Timestep Collection Time: 2.31061
Timestep Consumption Time: 2.47882
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.78943

Cumulative Model Updates: 129,358
Cumulative Timesteps: 1,079,645,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1079645142...
Checkpoint 1079645142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,720.17070
Policy Entropy: 1.67797
Value Function Loss: 0.05815

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.31038
Value Function Update Magnitude: 0.27174

Collected Steps per Second: 21,433.34808
Overall Steps per Second: 10,587.56991

Timestep Collection Time: 2.33337
Timestep Consumption Time: 2.39028
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.72365

Cumulative Model Updates: 129,364
Cumulative Timesteps: 1,079,695,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,898.70308
Policy Entropy: 1.68847
Value Function Loss: 0.05706

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.31169
Value Function Update Magnitude: 0.30986

Collected Steps per Second: 21,633.72809
Overall Steps per Second: 10,407.04145

Timestep Collection Time: 2.31121
Timestep Consumption Time: 2.49323
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.80444

Cumulative Model Updates: 129,370
Cumulative Timesteps: 1,079,745,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1079745154...
Checkpoint 1079745154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,282.26956
Policy Entropy: 1.71540
Value Function Loss: 0.06300

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.30837
Value Function Update Magnitude: 0.34509

Collected Steps per Second: 21,777.66494
Overall Steps per Second: 10,614.92497

Timestep Collection Time: 2.29602
Timestep Consumption Time: 2.41452
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.71054

Cumulative Model Updates: 129,376
Cumulative Timesteps: 1,079,795,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,815.04854
Policy Entropy: 1.72022
Value Function Loss: 0.06091

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.30305
Value Function Update Magnitude: 0.35337

Collected Steps per Second: 22,218.90441
Overall Steps per Second: 10,452.59323

Timestep Collection Time: 2.25115
Timestep Consumption Time: 2.53408
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.78522

Cumulative Model Updates: 129,382
Cumulative Timesteps: 1,079,845,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1079845174...
Checkpoint 1079845174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,799.80324
Policy Entropy: 1.70146
Value Function Loss: 0.06084

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09395
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.36504

Collected Steps per Second: 21,783.70128
Overall Steps per Second: 10,555.68634

Timestep Collection Time: 2.29566
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.73754

Cumulative Model Updates: 129,388
Cumulative Timesteps: 1,079,895,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,161.48172
Policy Entropy: 1.67493
Value Function Loss: 0.05713

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.31303
Value Function Update Magnitude: 0.36307

Collected Steps per Second: 22,086.65597
Overall Steps per Second: 10,524.69987

Timestep Collection Time: 2.26444
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.75206

Cumulative Model Updates: 129,394
Cumulative Timesteps: 1,079,945,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1079945196...
Checkpoint 1079945196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,376.50512
Policy Entropy: 1.65809
Value Function Loss: 0.06020

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.32254
Value Function Update Magnitude: 0.37470

Collected Steps per Second: 21,912.47089
Overall Steps per Second: 10,582.05940

Timestep Collection Time: 2.28199
Timestep Consumption Time: 2.44337
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.72536

Cumulative Model Updates: 129,400
Cumulative Timesteps: 1,079,995,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,216.56359
Policy Entropy: 1.67395
Value Function Loss: 0.06436

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.33020
Value Function Update Magnitude: 0.35532

Collected Steps per Second: 22,027.30840
Overall Steps per Second: 10,617.26797

Timestep Collection Time: 2.27127
Timestep Consumption Time: 2.44086
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.71213

Cumulative Model Updates: 129,406
Cumulative Timesteps: 1,080,045,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1080045230...
Checkpoint 1080045230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,361.03227
Policy Entropy: 1.68638
Value Function Loss: 0.06579

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.32948
Value Function Update Magnitude: 0.34420

Collected Steps per Second: 22,156.90491
Overall Steps per Second: 10,554.48909

Timestep Collection Time: 2.25708
Timestep Consumption Time: 2.48118
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.73827

Cumulative Model Updates: 129,412
Cumulative Timesteps: 1,080,095,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,579.70375
Policy Entropy: 1.69381
Value Function Loss: 0.06565

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.33170
Value Function Update Magnitude: 0.36135

Collected Steps per Second: 22,015.06841
Overall Steps per Second: 10,445.78955

Timestep Collection Time: 2.27217
Timestep Consumption Time: 2.51655
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.78872

Cumulative Model Updates: 129,418
Cumulative Timesteps: 1,080,145,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1080145262...
Checkpoint 1080145262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,697.69690
Policy Entropy: 1.68045
Value Function Loss: 0.05718

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07881
Policy Update Magnitude: 0.32401
Value Function Update Magnitude: 0.36627

Collected Steps per Second: 20,713.08440
Overall Steps per Second: 10,269.24986

Timestep Collection Time: 2.41461
Timestep Consumption Time: 2.45566
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.87027

Cumulative Model Updates: 129,424
Cumulative Timesteps: 1,080,195,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,645.26290
Policy Entropy: 1.67851
Value Function Loss: 0.06200

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07998
Policy Update Magnitude: 0.32113
Value Function Update Magnitude: 0.35370

Collected Steps per Second: 21,862.36329
Overall Steps per Second: 10,416.33881

Timestep Collection Time: 2.28731
Timestep Consumption Time: 2.51342
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.80073

Cumulative Model Updates: 129,430
Cumulative Timesteps: 1,080,245,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1080245282...
Checkpoint 1080245282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,131.51294
Policy Entropy: 1.67925
Value Function Loss: 0.05835

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.32275
Value Function Update Magnitude: 0.34142

Collected Steps per Second: 21,636.76457
Overall Steps per Second: 10,551.05578

Timestep Collection Time: 2.31181
Timestep Consumption Time: 2.42895
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.74076

Cumulative Model Updates: 129,436
Cumulative Timesteps: 1,080,295,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,801.66705
Policy Entropy: 1.69139
Value Function Loss: 0.06371

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.32524
Value Function Update Magnitude: 0.35503

Collected Steps per Second: 21,734.80135
Overall Steps per Second: 10,549.64316

Timestep Collection Time: 2.30092
Timestep Consumption Time: 2.43953
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.74044

Cumulative Model Updates: 129,442
Cumulative Timesteps: 1,080,345,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1080345312...
Checkpoint 1080345312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,236.34676
Policy Entropy: 1.68841
Value Function Loss: 0.05890

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.32481
Value Function Update Magnitude: 0.38709

Collected Steps per Second: 21,846.49411
Overall Steps per Second: 10,537.96563

Timestep Collection Time: 2.29071
Timestep Consumption Time: 2.45821
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.74892

Cumulative Model Updates: 129,448
Cumulative Timesteps: 1,080,395,356

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,897.07470
Policy Entropy: 1.68003
Value Function Loss: 0.05977

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.32680
Value Function Update Magnitude: 0.39035

Collected Steps per Second: 22,078.32291
Overall Steps per Second: 10,487.13024

Timestep Collection Time: 2.26512
Timestep Consumption Time: 2.50358
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.76870

Cumulative Model Updates: 129,454
Cumulative Timesteps: 1,080,445,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1080445366...
Checkpoint 1080445366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,697.36560
Policy Entropy: 1.68527
Value Function Loss: 0.06016

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.33226
Value Function Update Magnitude: 0.40015

Collected Steps per Second: 21,832.37160
Overall Steps per Second: 10,613.52997

Timestep Collection Time: 2.29256
Timestep Consumption Time: 2.42331
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.71587

Cumulative Model Updates: 129,460
Cumulative Timesteps: 1,080,495,418

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,031.82380
Policy Entropy: 1.69410
Value Function Loss: 0.06088

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.33180
Value Function Update Magnitude: 0.39930

Collected Steps per Second: 22,179.00008
Overall Steps per Second: 10,488.49392

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.51385
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.76923

Cumulative Model Updates: 129,466
Cumulative Timesteps: 1,080,545,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1080545440...
Checkpoint 1080545440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,661.33008
Policy Entropy: 1.70122
Value Function Loss: 0.06006

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.32337
Value Function Update Magnitude: 0.38378

Collected Steps per Second: 21,832.03874
Overall Steps per Second: 10,584.56753

Timestep Collection Time: 2.29095
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.72537

Cumulative Model Updates: 129,472
Cumulative Timesteps: 1,080,595,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,728.62934
Policy Entropy: 1.68987
Value Function Loss: 0.05741

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08163
Policy Update Magnitude: 0.31676
Value Function Update Magnitude: 0.37609

Collected Steps per Second: 22,057.71911
Overall Steps per Second: 10,501.35463

Timestep Collection Time: 2.26696
Timestep Consumption Time: 2.49471
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.76167

Cumulative Model Updates: 129,478
Cumulative Timesteps: 1,080,645,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1080645460...
Checkpoint 1080645460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,758.39928
Policy Entropy: 1.68525
Value Function Loss: 0.05764

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.31766
Value Function Update Magnitude: 0.36715

Collected Steps per Second: 21,391.79134
Overall Steps per Second: 10,317.43033

Timestep Collection Time: 2.33828
Timestep Consumption Time: 2.50983
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.84811

Cumulative Model Updates: 129,484
Cumulative Timesteps: 1,080,695,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,018.00186
Policy Entropy: 1.66507
Value Function Loss: 0.05805

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.31915
Value Function Update Magnitude: 0.37087

Collected Steps per Second: 22,089.52880
Overall Steps per Second: 10,503.06586

Timestep Collection Time: 2.26415
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.76185

Cumulative Model Updates: 129,490
Cumulative Timesteps: 1,080,745,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1080745494...
Checkpoint 1080745494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,732.27516
Policy Entropy: 1.67467
Value Function Loss: 0.05986

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.32189
Value Function Update Magnitude: 0.35695

Collected Steps per Second: 21,835.24105
Overall Steps per Second: 10,493.16755

Timestep Collection Time: 2.29088
Timestep Consumption Time: 2.47622
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.76710

Cumulative Model Updates: 129,496
Cumulative Timesteps: 1,080,795,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,023.06069
Policy Entropy: 1.67258
Value Function Loss: 0.06104

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.32196
Value Function Update Magnitude: 0.35142

Collected Steps per Second: 21,805.67805
Overall Steps per Second: 10,460.46430

Timestep Collection Time: 2.29417
Timestep Consumption Time: 2.48821
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.78239

Cumulative Model Updates: 129,502
Cumulative Timesteps: 1,080,845,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1080845542...
Checkpoint 1080845542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,980.45210
Policy Entropy: 1.67970
Value Function Loss: 0.06238

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.32345
Value Function Update Magnitude: 0.36483

Collected Steps per Second: 21,334.73648
Overall Steps per Second: 10,289.16437

Timestep Collection Time: 2.34369
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.85968

Cumulative Model Updates: 129,508
Cumulative Timesteps: 1,080,895,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,826.57410
Policy Entropy: 1.66264
Value Function Loss: 0.06182

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.32635
Value Function Update Magnitude: 0.39594

Collected Steps per Second: 21,846.54951
Overall Steps per Second: 10,418.42156

Timestep Collection Time: 2.29034
Timestep Consumption Time: 2.51231
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.80265

Cumulative Model Updates: 129,514
Cumulative Timesteps: 1,080,945,580

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1080945580...
Checkpoint 1080945580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,816.21773
Policy Entropy: 1.65653
Value Function Loss: 0.05921

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.32641
Value Function Update Magnitude: 0.40859

Collected Steps per Second: 21,271.98494
Overall Steps per Second: 10,265.14109

Timestep Collection Time: 2.35201
Timestep Consumption Time: 2.52196
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.87397

Cumulative Model Updates: 129,520
Cumulative Timesteps: 1,080,995,612

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.31278
Policy Entropy: 1.65668
Value Function Loss: 0.06064

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.31068
Value Function Update Magnitude: 0.40204

Collected Steps per Second: 22,200.40257
Overall Steps per Second: 10,431.09425

Timestep Collection Time: 2.25230
Timestep Consumption Time: 2.54125
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.79355

Cumulative Model Updates: 129,526
Cumulative Timesteps: 1,081,045,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1081045614...
Checkpoint 1081045614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,218.27479
Policy Entropy: 1.65484
Value Function Loss: 0.05744

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.29020
Value Function Update Magnitude: 0.35490

Collected Steps per Second: 21,859.58408
Overall Steps per Second: 10,574.71553

Timestep Collection Time: 2.28769
Timestep Consumption Time: 2.44132
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.72902

Cumulative Model Updates: 129,532
Cumulative Timesteps: 1,081,095,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,953.87571
Policy Entropy: 1.65823
Value Function Loss: 0.06202

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.30591
Value Function Update Magnitude: 0.30823

Collected Steps per Second: 22,144.47045
Overall Steps per Second: 10,479.75903

Timestep Collection Time: 2.25898
Timestep Consumption Time: 2.51441
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.77339

Cumulative Model Updates: 129,538
Cumulative Timesteps: 1,081,145,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1081145646...
Checkpoint 1081145646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,521.63197
Policy Entropy: 1.68150
Value Function Loss: 0.06118

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.32408
Value Function Update Magnitude: 0.32107

Collected Steps per Second: 22,015.99294
Overall Steps per Second: 10,611.53199

Timestep Collection Time: 2.27317
Timestep Consumption Time: 2.44302
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.71619

Cumulative Model Updates: 129,544
Cumulative Timesteps: 1,081,195,692

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,508.93331
Policy Entropy: 1.68544
Value Function Loss: 0.06161

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.32480
Value Function Update Magnitude: 0.36642

Collected Steps per Second: 22,375.83857
Overall Steps per Second: 10,589.73456

Timestep Collection Time: 2.23518
Timestep Consumption Time: 2.48770
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.72288

Cumulative Model Updates: 129,550
Cumulative Timesteps: 1,081,245,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1081245706...
Checkpoint 1081245706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,589.45425
Policy Entropy: 1.68036
Value Function Loss: 0.05290

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.31480
Value Function Update Magnitude: 0.34686

Collected Steps per Second: 21,883.14124
Overall Steps per Second: 10,470.75967

Timestep Collection Time: 2.28697
Timestep Consumption Time: 2.49263
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.77960

Cumulative Model Updates: 129,556
Cumulative Timesteps: 1,081,295,752

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,799.18425
Policy Entropy: 1.67100
Value Function Loss: 0.05141

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.30088
Value Function Update Magnitude: 0.31951

Collected Steps per Second: 22,014.25551
Overall Steps per Second: 10,460.16330

Timestep Collection Time: 2.27153
Timestep Consumption Time: 2.50909
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.78061

Cumulative Model Updates: 129,562
Cumulative Timesteps: 1,081,345,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1081345758...
Checkpoint 1081345758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,872.35514
Policy Entropy: 1.66683
Value Function Loss: 0.04928

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.30067
Value Function Update Magnitude: 0.30315

Collected Steps per Second: 21,223.81594
Overall Steps per Second: 10,276.22262

Timestep Collection Time: 2.35745
Timestep Consumption Time: 2.51146
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.86891

Cumulative Model Updates: 129,568
Cumulative Timesteps: 1,081,395,792

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,777.30454
Policy Entropy: 1.67316
Value Function Loss: 0.05794

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07721
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.30985

Collected Steps per Second: 21,910.01262
Overall Steps per Second: 10,452.96488

Timestep Collection Time: 2.28243
Timestep Consumption Time: 2.50167
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.78410

Cumulative Model Updates: 129,574
Cumulative Timesteps: 1,081,445,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1081445800...
Checkpoint 1081445800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,594.91783
Policy Entropy: 1.69280
Value Function Loss: 0.05902

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.31946
Value Function Update Magnitude: 0.35611

Collected Steps per Second: 21,576.26032
Overall Steps per Second: 10,527.28451

Timestep Collection Time: 2.31792
Timestep Consumption Time: 2.43278
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.75070

Cumulative Model Updates: 129,580
Cumulative Timesteps: 1,081,495,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,195.45036
Policy Entropy: 1.70565
Value Function Loss: 0.05939

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07994
Policy Update Magnitude: 0.32156
Value Function Update Magnitude: 0.35464

Collected Steps per Second: 21,611.63694
Overall Steps per Second: 10,493.37209

Timestep Collection Time: 2.31403
Timestep Consumption Time: 2.45183
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.76587

Cumulative Model Updates: 129,586
Cumulative Timesteps: 1,081,545,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1081545822...
Checkpoint 1081545822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,422.54973
Policy Entropy: 1.70514
Value Function Loss: 0.06470

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.32224
Value Function Update Magnitude: 0.35045

Collected Steps per Second: 21,472.31031
Overall Steps per Second: 10,340.07968

Timestep Collection Time: 2.32867
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.83575

Cumulative Model Updates: 129,592
Cumulative Timesteps: 1,081,595,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,801.90583
Policy Entropy: 1.68574
Value Function Loss: 0.06535

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.30696
Value Function Update Magnitude: 0.35960

Collected Steps per Second: 22,267.68738
Overall Steps per Second: 10,466.74907

Timestep Collection Time: 2.24568
Timestep Consumption Time: 2.53193
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.77761

Cumulative Model Updates: 129,598
Cumulative Timesteps: 1,081,645,830

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1081645830...
Checkpoint 1081645830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,152.69948
Policy Entropy: 1.68264
Value Function Loss: 0.06451

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.31941
Value Function Update Magnitude: 0.35938

Collected Steps per Second: 21,570.38341
Overall Steps per Second: 10,513.71817

Timestep Collection Time: 2.31938
Timestep Consumption Time: 2.43916
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.75854

Cumulative Model Updates: 129,604
Cumulative Timesteps: 1,081,695,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,994.57066
Policy Entropy: 1.67390
Value Function Loss: 0.05867

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.32251
Value Function Update Magnitude: 0.33408

Collected Steps per Second: 22,132.16552
Overall Steps per Second: 10,513.53461

Timestep Collection Time: 2.26114
Timestep Consumption Time: 2.49882
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.75996

Cumulative Model Updates: 129,610
Cumulative Timesteps: 1,081,745,904

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1081745904...
Checkpoint 1081745904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,321.30727
Policy Entropy: 1.68534
Value Function Loss: 0.05577

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.31489
Value Function Update Magnitude: 0.32712

Collected Steps per Second: 21,796.08698
Overall Steps per Second: 10,599.97710

Timestep Collection Time: 2.29500
Timestep Consumption Time: 2.42407
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.71907

Cumulative Model Updates: 129,616
Cumulative Timesteps: 1,081,795,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,549.83448
Policy Entropy: 1.68869
Value Function Loss: 0.05691

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.31403
Value Function Update Magnitude: 0.33373

Collected Steps per Second: 22,062.66954
Overall Steps per Second: 10,456.34451

Timestep Collection Time: 2.26763
Timestep Consumption Time: 2.51702
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.78465

Cumulative Model Updates: 129,622
Cumulative Timesteps: 1,081,845,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1081845956...
Checkpoint 1081845956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,456.59435
Policy Entropy: 1.68970
Value Function Loss: 0.05704

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.31639
Value Function Update Magnitude: 0.36258

Collected Steps per Second: 21,855.21249
Overall Steps per Second: 10,584.69617

Timestep Collection Time: 2.28980
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.72796

Cumulative Model Updates: 129,628
Cumulative Timesteps: 1,081,896,000

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,224.84235
Policy Entropy: 1.68927
Value Function Loss: 0.05542

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.31428
Value Function Update Magnitude: 0.37460

Collected Steps per Second: 21,709.36112
Overall Steps per Second: 10,436.09382

Timestep Collection Time: 2.30417
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.79317

Cumulative Model Updates: 129,634
Cumulative Timesteps: 1,081,946,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1081946022...
Checkpoint 1081946022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,829.63086
Policy Entropy: 1.69187
Value Function Loss: 0.05586

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.30911
Value Function Update Magnitude: 0.36139

Collected Steps per Second: 21,368.19518
Overall Steps per Second: 10,297.60783

Timestep Collection Time: 2.34030
Timestep Consumption Time: 2.51597
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.85627

Cumulative Model Updates: 129,640
Cumulative Timesteps: 1,081,996,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,508.74996
Policy Entropy: 1.69725
Value Function Loss: 0.05490

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.30994
Value Function Update Magnitude: 0.35560

Collected Steps per Second: 21,634.53959
Overall Steps per Second: 10,373.33212

Timestep Collection Time: 2.31214
Timestep Consumption Time: 2.51004
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.82217

Cumulative Model Updates: 129,646
Cumulative Timesteps: 1,082,046,052

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1082046052...
Checkpoint 1082046052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,509.14782
Policy Entropy: 1.68424
Value Function Loss: 0.05531

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.31316
Value Function Update Magnitude: 0.33935

Collected Steps per Second: 21,157.77544
Overall Steps per Second: 10,249.93957

Timestep Collection Time: 2.36386
Timestep Consumption Time: 2.51558
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.87944

Cumulative Model Updates: 129,652
Cumulative Timesteps: 1,082,096,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,832.93661
Policy Entropy: 1.68239
Value Function Loss: 0.05667

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.30426
Value Function Update Magnitude: 0.34218

Collected Steps per Second: 21,642.05093
Overall Steps per Second: 10,392.15201

Timestep Collection Time: 2.31189
Timestep Consumption Time: 2.50271
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.81459

Cumulative Model Updates: 129,658
Cumulative Timesteps: 1,082,146,100

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1082146100...
Checkpoint 1082146100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,220.59524
Policy Entropy: 1.70822
Value Function Loss: 0.06466

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.31626
Value Function Update Magnitude: 0.37545

Collected Steps per Second: 21,206.53146
Overall Steps per Second: 10,273.18124

Timestep Collection Time: 2.35805
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.86763

Cumulative Model Updates: 129,664
Cumulative Timesteps: 1,082,196,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,995.44818
Policy Entropy: 1.71669
Value Function Loss: 0.06387

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09739
Policy Update Magnitude: 0.32566
Value Function Update Magnitude: 0.39727

Collected Steps per Second: 21,748.55096
Overall Steps per Second: 10,411.03929

Timestep Collection Time: 2.29910
Timestep Consumption Time: 2.50369
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.80279

Cumulative Model Updates: 129,670
Cumulative Timesteps: 1,082,246,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1082246108...
Checkpoint 1082246108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,756.66821
Policy Entropy: 1.71562
Value Function Loss: 0.06492

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.32603
Value Function Update Magnitude: 0.38435

Collected Steps per Second: 22,077.82555
Overall Steps per Second: 10,588.43453

Timestep Collection Time: 2.26698
Timestep Consumption Time: 2.45987
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.72686

Cumulative Model Updates: 129,676
Cumulative Timesteps: 1,082,296,158

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,270.25827
Policy Entropy: 1.68849
Value Function Loss: 0.06449

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.32514
Value Function Update Magnitude: 0.38754

Collected Steps per Second: 22,021.95054
Overall Steps per Second: 10,481.40406

Timestep Collection Time: 2.27137
Timestep Consumption Time: 2.50089
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.77226

Cumulative Model Updates: 129,682
Cumulative Timesteps: 1,082,346,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1082346178...
Checkpoint 1082346178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,633.79110
Policy Entropy: 1.68770
Value Function Loss: 0.06313

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.32557
Value Function Update Magnitude: 0.38322

Collected Steps per Second: 22,030.63366
Overall Steps per Second: 10,603.97184

Timestep Collection Time: 2.27029
Timestep Consumption Time: 2.44643
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.71672

Cumulative Model Updates: 129,688
Cumulative Timesteps: 1,082,396,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,400.86524
Policy Entropy: 1.68474
Value Function Loss: 0.06235

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.32234
Value Function Update Magnitude: 0.38798

Collected Steps per Second: 22,271.09689
Overall Steps per Second: 10,505.31290

Timestep Collection Time: 2.24506
Timestep Consumption Time: 2.51443
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.75950

Cumulative Model Updates: 129,694
Cumulative Timesteps: 1,082,446,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1082446194...
Checkpoint 1082446194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,735.54282
Policy Entropy: 1.68977
Value Function Loss: 0.05610

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.32111
Value Function Update Magnitude: 0.38093

Collected Steps per Second: 22,198.70133
Overall Steps per Second: 10,620.68547

Timestep Collection Time: 2.25265
Timestep Consumption Time: 2.45570
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.70836

Cumulative Model Updates: 129,700
Cumulative Timesteps: 1,082,496,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,817.50669
Policy Entropy: 1.68266
Value Function Loss: 0.06089

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.32362
Value Function Update Magnitude: 0.37092

Collected Steps per Second: 21,270.68249
Overall Steps per Second: 10,438.14533

Timestep Collection Time: 2.35065
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.79012

Cumulative Model Updates: 129,706
Cumulative Timesteps: 1,082,546,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1082546200...
Checkpoint 1082546200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,068.43193
Policy Entropy: 1.68246
Value Function Loss: 0.05654

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.31778
Value Function Update Magnitude: 0.36175

Collected Steps per Second: 21,285.97285
Overall Steps per Second: 10,605.22435

Timestep Collection Time: 2.35000
Timestep Consumption Time: 2.36673
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.71673

Cumulative Model Updates: 129,712
Cumulative Timesteps: 1,082,596,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,631.95232
Policy Entropy: 1.68934
Value Function Loss: 0.05725

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07944
Policy Update Magnitude: 0.31219
Value Function Update Magnitude: 0.36489

Collected Steps per Second: 20,807.72525
Overall Steps per Second: 10,491.02187

Timestep Collection Time: 2.40305
Timestep Consumption Time: 2.36312
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.76617

Cumulative Model Updates: 129,718
Cumulative Timesteps: 1,082,646,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1082646224...
Checkpoint 1082646224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,906.20572
Policy Entropy: 1.68600
Value Function Loss: 0.05396

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.30909
Value Function Update Magnitude: 0.33155

Collected Steps per Second: 20,792.20495
Overall Steps per Second: 10,355.86144

Timestep Collection Time: 2.40629
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.83127

Cumulative Model Updates: 129,724
Cumulative Timesteps: 1,082,696,256

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,162.10328
Policy Entropy: 1.68001
Value Function Loss: 0.05842

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.30863
Value Function Update Magnitude: 0.27393

Collected Steps per Second: 21,059.53467
Overall Steps per Second: 10,328.10276

Timestep Collection Time: 2.37422
Timestep Consumption Time: 2.46694
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.84116

Cumulative Model Updates: 129,730
Cumulative Timesteps: 1,082,746,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1082746256...
Checkpoint 1082746256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,810.07259
Policy Entropy: 1.67364
Value Function Loss: 0.05737

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.29337
Value Function Update Magnitude: 0.32579

Collected Steps per Second: 21,517.68928
Overall Steps per Second: 10,556.80932

Timestep Collection Time: 2.32451
Timestep Consumption Time: 2.41348
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.73798

Cumulative Model Updates: 129,736
Cumulative Timesteps: 1,082,796,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,904.64478
Policy Entropy: 1.67888
Value Function Loss: 0.05867

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.29783
Value Function Update Magnitude: 0.36398

Collected Steps per Second: 21,464.52919
Overall Steps per Second: 10,524.66911

Timestep Collection Time: 2.32980
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.75150

Cumulative Model Updates: 129,742
Cumulative Timesteps: 1,082,846,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1082846282...
Checkpoint 1082846282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,547.99101
Policy Entropy: 1.67677
Value Function Loss: 0.05281

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.30371
Value Function Update Magnitude: 0.35897

Collected Steps per Second: 21,947.85117
Overall Steps per Second: 10,582.69477

Timestep Collection Time: 2.27904
Timestep Consumption Time: 2.44755
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.72658

Cumulative Model Updates: 129,748
Cumulative Timesteps: 1,082,896,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,966.26165
Policy Entropy: 1.67452
Value Function Loss: 0.05327

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.30434
Value Function Update Magnitude: 0.34729

Collected Steps per Second: 22,191.44046
Overall Steps per Second: 10,515.03688

Timestep Collection Time: 2.25393
Timestep Consumption Time: 2.50287
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.75681

Cumulative Model Updates: 129,754
Cumulative Timesteps: 1,082,946,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1082946320...
Checkpoint 1082946320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,096.95337
Policy Entropy: 1.68291
Value Function Loss: 0.05378

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.30654
Value Function Update Magnitude: 0.32981

Collected Steps per Second: 21,778.63783
Overall Steps per Second: 10,545.91788

Timestep Collection Time: 2.29583
Timestep Consumption Time: 2.44534
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.74117

Cumulative Model Updates: 129,760
Cumulative Timesteps: 1,082,996,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,305.68077
Policy Entropy: 1.67256
Value Function Loss: 0.05727

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.30837
Value Function Update Magnitude: 0.30714

Collected Steps per Second: 21,901.18798
Overall Steps per Second: 10,559.33562

Timestep Collection Time: 2.28307
Timestep Consumption Time: 2.45226
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.73534

Cumulative Model Updates: 129,766
Cumulative Timesteps: 1,083,046,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1083046322...
Checkpoint 1083046322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,347.53526
Policy Entropy: 1.68164
Value Function Loss: 0.05878

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.31140
Value Function Update Magnitude: 0.31558

Collected Steps per Second: 22,279.12828
Overall Steps per Second: 10,631.63768

Timestep Collection Time: 2.24569
Timestep Consumption Time: 2.46026
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.70595

Cumulative Model Updates: 129,772
Cumulative Timesteps: 1,083,096,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,118.18411
Policy Entropy: 1.69720
Value Function Loss: 0.05613

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.30814
Value Function Update Magnitude: 0.32199

Collected Steps per Second: 21,892.84009
Overall Steps per Second: 10,425.40947

Timestep Collection Time: 2.28504
Timestep Consumption Time: 2.51343
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.79847

Cumulative Model Updates: 129,778
Cumulative Timesteps: 1,083,146,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1083146380...
Checkpoint 1083146380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,695.61977
Policy Entropy: 1.70952
Value Function Loss: 0.05379

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07371
Policy Update Magnitude: 0.30397
Value Function Update Magnitude: 0.32138

Collected Steps per Second: 21,758.22932
Overall Steps per Second: 10,600.25608

Timestep Collection Time: 2.29936
Timestep Consumption Time: 2.42034
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.71970

Cumulative Model Updates: 129,784
Cumulative Timesteps: 1,083,196,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,935.32842
Policy Entropy: 1.70897
Value Function Loss: 0.05019

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.29858
Value Function Update Magnitude: 0.29939

Collected Steps per Second: 21,516.81873
Overall Steps per Second: 10,505.14750

Timestep Collection Time: 2.32506
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.76224

Cumulative Model Updates: 129,790
Cumulative Timesteps: 1,083,246,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1083246438...
Checkpoint 1083246438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,201.46568
Policy Entropy: 1.68774
Value Function Loss: 0.05064

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.29935
Value Function Update Magnitude: 0.30307

Collected Steps per Second: 21,247.05281
Overall Steps per Second: 10,291.83153

Timestep Collection Time: 2.35402
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.85978

Cumulative Model Updates: 129,796
Cumulative Timesteps: 1,083,296,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,705.37275
Policy Entropy: 1.67829
Value Function Loss: 0.05419

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.30093
Value Function Update Magnitude: 0.31522

Collected Steps per Second: 21,455.78340
Overall Steps per Second: 10,363.73816

Timestep Collection Time: 2.33093
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.82567

Cumulative Model Updates: 129,802
Cumulative Timesteps: 1,083,346,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1083346466...
Checkpoint 1083346466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,494.88742
Policy Entropy: 1.66305
Value Function Loss: 0.05450

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.30532
Value Function Update Magnitude: 0.32448

Collected Steps per Second: 21,978.69792
Overall Steps per Second: 10,582.30809

Timestep Collection Time: 2.27602
Timestep Consumption Time: 2.45111
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.72714

Cumulative Model Updates: 129,808
Cumulative Timesteps: 1,083,396,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,371.20208
Policy Entropy: 1.67838
Value Function Loss: 0.06046

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.30989
Value Function Update Magnitude: 0.32904

Collected Steps per Second: 22,156.36467
Overall Steps per Second: 10,502.44494

Timestep Collection Time: 2.25696
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.76137

Cumulative Model Updates: 129,814
Cumulative Timesteps: 1,083,446,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1083446496...
Checkpoint 1083446496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,325.09294
Policy Entropy: 1.67307
Value Function Loss: 0.05920

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.31170
Value Function Update Magnitude: 0.33864

Collected Steps per Second: 22,032.50667
Overall Steps per Second: 10,629.56945

Timestep Collection Time: 2.26974
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.70461

Cumulative Model Updates: 129,820
Cumulative Timesteps: 1,083,496,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,064.22665
Policy Entropy: 1.67973
Value Function Loss: 0.05768

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.30830
Value Function Update Magnitude: 0.34511

Collected Steps per Second: 21,987.05384
Overall Steps per Second: 10,484.64770

Timestep Collection Time: 2.27498
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.77078

Cumulative Model Updates: 129,826
Cumulative Timesteps: 1,083,546,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1083546524...
Checkpoint 1083546524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,336.49060
Policy Entropy: 1.66381
Value Function Loss: 0.05632

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.31202
Value Function Update Magnitude: 0.34504

Collected Steps per Second: 22,072.67004
Overall Steps per Second: 10,626.42398

Timestep Collection Time: 2.26660
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.70807

Cumulative Model Updates: 129,832
Cumulative Timesteps: 1,083,596,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,238.28805
Policy Entropy: 1.66651
Value Function Loss: 0.05601

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.31601
Value Function Update Magnitude: 0.35373

Collected Steps per Second: 22,204.20719
Overall Steps per Second: 10,510.32751

Timestep Collection Time: 2.25417
Timestep Consumption Time: 2.50801
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.76217

Cumulative Model Updates: 129,838
Cumulative Timesteps: 1,083,646,606

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1083646606...
Checkpoint 1083646606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,323.33965
Policy Entropy: 1.66308
Value Function Loss: 0.05322

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.30927
Value Function Update Magnitude: 0.35358

Collected Steps per Second: 22,085.99307
Overall Steps per Second: 10,664.20229

Timestep Collection Time: 2.26424
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.68933

Cumulative Model Updates: 129,844
Cumulative Timesteps: 1,083,696,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,394.50254
Policy Entropy: 1.66664
Value Function Loss: 0.05441

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.30570
Value Function Update Magnitude: 0.35279

Collected Steps per Second: 21,767.37826
Overall Steps per Second: 10,380.65638

Timestep Collection Time: 2.29729
Timestep Consumption Time: 2.51994
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.81723

Cumulative Model Updates: 129,850
Cumulative Timesteps: 1,083,746,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1083746620...
Checkpoint 1083746620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,258.97833
Policy Entropy: 1.69802
Value Function Loss: 0.05797

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.31396
Value Function Update Magnitude: 0.35332

Collected Steps per Second: 21,142.97378
Overall Steps per Second: 10,337.15657

Timestep Collection Time: 2.36674
Timestep Consumption Time: 2.47405
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.84079

Cumulative Model Updates: 129,856
Cumulative Timesteps: 1,083,796,660

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,472.67058
Policy Entropy: 1.70136
Value Function Loss: 0.06098

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.31903
Value Function Update Magnitude: 0.35723

Collected Steps per Second: 21,797.87050
Overall Steps per Second: 10,402.16576

Timestep Collection Time: 2.29389
Timestep Consumption Time: 2.51299
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.80688

Cumulative Model Updates: 129,862
Cumulative Timesteps: 1,083,846,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1083846662...
Checkpoint 1083846662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,735.07552
Policy Entropy: 1.70979
Value Function Loss: 0.06044

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.31238
Value Function Update Magnitude: 0.35290

Collected Steps per Second: 21,843.38184
Overall Steps per Second: 10,559.58543

Timestep Collection Time: 2.29076
Timestep Consumption Time: 2.44787
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.73863

Cumulative Model Updates: 129,868
Cumulative Timesteps: 1,083,896,700

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,140.83939
Policy Entropy: 1.69242
Value Function Loss: 0.05942

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.30936
Value Function Update Magnitude: 0.35999

Collected Steps per Second: 21,600.22556
Overall Steps per Second: 10,398.66949

Timestep Collection Time: 2.31636
Timestep Consumption Time: 2.49521
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.81158

Cumulative Model Updates: 129,874
Cumulative Timesteps: 1,083,946,734

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1083946734...
Checkpoint 1083946734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,371.97052
Policy Entropy: 1.69885
Value Function Loss: 0.05727

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.30929
Value Function Update Magnitude: 0.36591

Collected Steps per Second: 21,712.50065
Overall Steps per Second: 10,422.45676

Timestep Collection Time: 2.30291
Timestep Consumption Time: 2.49461
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.79753

Cumulative Model Updates: 129,880
Cumulative Timesteps: 1,083,996,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,217.06214
Policy Entropy: 1.68608
Value Function Loss: 0.05582

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.30900
Value Function Update Magnitude: 0.36181

Collected Steps per Second: 22,287.74862
Overall Steps per Second: 10,672.96948

Timestep Collection Time: 2.24374
Timestep Consumption Time: 2.44174
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.68548

Cumulative Model Updates: 129,886
Cumulative Timesteps: 1,084,046,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1084046744...
Checkpoint 1084046744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,159.18956
Policy Entropy: 1.68434
Value Function Loss: 0.05586

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08502
Policy Update Magnitude: 0.31140
Value Function Update Magnitude: 0.35727

Collected Steps per Second: 21,856.10628
Overall Steps per Second: 10,646.67823

Timestep Collection Time: 2.28897
Timestep Consumption Time: 2.40996
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.69893

Cumulative Model Updates: 129,892
Cumulative Timesteps: 1,084,096,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,180.20702
Policy Entropy: 1.68033
Value Function Loss: 0.05354

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08396
Policy Update Magnitude: 0.30950
Value Function Update Magnitude: 0.35397

Collected Steps per Second: 21,816.01588
Overall Steps per Second: 10,443.53156

Timestep Collection Time: 2.29336
Timestep Consumption Time: 2.49736
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.79072

Cumulative Model Updates: 129,898
Cumulative Timesteps: 1,084,146,804

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1084146804...
Checkpoint 1084146804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,694.56936
Policy Entropy: 1.69696
Value Function Loss: 0.05690

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.30666
Value Function Update Magnitude: 0.32104

Collected Steps per Second: 21,614.90264
Overall Steps per Second: 10,381.20489

Timestep Collection Time: 2.31470
Timestep Consumption Time: 2.50478
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.81948

Cumulative Model Updates: 129,904
Cumulative Timesteps: 1,084,196,836

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,401.12172
Policy Entropy: 1.68992
Value Function Loss: 0.05432

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.30545
Value Function Update Magnitude: 0.32308

Collected Steps per Second: 21,974.79258
Overall Steps per Second: 10,452.21321

Timestep Collection Time: 2.27715
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.78750

Cumulative Model Updates: 129,910
Cumulative Timesteps: 1,084,246,876

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1084246876...
Checkpoint 1084246876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,683.39478
Policy Entropy: 1.68451
Value Function Loss: 0.05378

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.30456
Value Function Update Magnitude: 0.33548

Collected Steps per Second: 21,342.94723
Overall Steps per Second: 10,486.15698

Timestep Collection Time: 2.34316
Timestep Consumption Time: 2.42598
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.76914

Cumulative Model Updates: 129,916
Cumulative Timesteps: 1,084,296,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,987.84718
Policy Entropy: 1.67777
Value Function Loss: 0.05091

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.29880
Value Function Update Magnitude: 0.33085

Collected Steps per Second: 21,720.58928
Overall Steps per Second: 10,560.81915

Timestep Collection Time: 2.30252
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.73562

Cumulative Model Updates: 129,922
Cumulative Timesteps: 1,084,346,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1084346898...
Checkpoint 1084346898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,110.04778
Policy Entropy: 1.68862
Value Function Loss: 0.05803

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.30547
Value Function Update Magnitude: 0.32436

Collected Steps per Second: 21,624.95698
Overall Steps per Second: 10,521.46172

Timestep Collection Time: 2.31298
Timestep Consumption Time: 2.44093
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.75390

Cumulative Model Updates: 129,928
Cumulative Timesteps: 1,084,396,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,676.09201
Policy Entropy: 1.69867
Value Function Loss: 0.06419

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.32338
Value Function Update Magnitude: 0.36257

Collected Steps per Second: 21,655.43094
Overall Steps per Second: 10,486.36228

Timestep Collection Time: 2.31000
Timestep Consumption Time: 2.46039
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.77039

Cumulative Model Updates: 129,934
Cumulative Timesteps: 1,084,446,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1084446940...
Checkpoint 1084446940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,605.66681
Policy Entropy: 1.70123
Value Function Loss: 0.06898

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.33065
Value Function Update Magnitude: 0.37403

Collected Steps per Second: 21,608.06841
Overall Steps per Second: 10,343.00651

Timestep Collection Time: 2.31432
Timestep Consumption Time: 2.52064
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.83496

Cumulative Model Updates: 129,940
Cumulative Timesteps: 1,084,496,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,929.73869
Policy Entropy: 1.70472
Value Function Loss: 0.06551

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.31777
Value Function Update Magnitude: 0.37563

Collected Steps per Second: 22,427.28886
Overall Steps per Second: 10,750.89576

Timestep Collection Time: 2.23041
Timestep Consumption Time: 2.42241
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.65282

Cumulative Model Updates: 129,946
Cumulative Timesteps: 1,084,546,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1084546970...
Checkpoint 1084546970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,928.08707
Policy Entropy: 1.72232
Value Function Loss: 0.05870

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.31737
Value Function Update Magnitude: 0.36362

Collected Steps per Second: 21,972.63597
Overall Steps per Second: 10,608.97656

Timestep Collection Time: 2.27574
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.71337

Cumulative Model Updates: 129,952
Cumulative Timesteps: 1,084,596,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,901.73127
Policy Entropy: 1.71599
Value Function Loss: 0.05257

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.30782
Value Function Update Magnitude: 0.34199

Collected Steps per Second: 22,188.14124
Overall Steps per Second: 10,595.91354

Timestep Collection Time: 2.25346
Timestep Consumption Time: 2.46534
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.71880

Cumulative Model Updates: 129,958
Cumulative Timesteps: 1,084,646,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1084646974...
Checkpoint 1084646974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,983.40800
Policy Entropy: 1.71782
Value Function Loss: 0.05211

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.30112
Value Function Update Magnitude: 0.33913

Collected Steps per Second: 22,024.90865
Overall Steps per Second: 10,503.72600

Timestep Collection Time: 2.27052
Timestep Consumption Time: 2.49046
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.76098

Cumulative Model Updates: 129,964
Cumulative Timesteps: 1,084,696,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,878.19160
Policy Entropy: 1.69563
Value Function Loss: 0.05472

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.30831
Value Function Update Magnitude: 0.35776

Collected Steps per Second: 22,110.23311
Overall Steps per Second: 10,466.86784

Timestep Collection Time: 2.26248
Timestep Consumption Time: 2.51679
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.77927

Cumulative Model Updates: 129,970
Cumulative Timesteps: 1,084,747,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1084747006...
Checkpoint 1084747006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,896.32558
Policy Entropy: 1.69851
Value Function Loss: 0.05735

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.31791
Value Function Update Magnitude: 0.37455

Collected Steps per Second: 21,439.28366
Overall Steps per Second: 10,308.40036

Timestep Collection Time: 2.33338
Timestep Consumption Time: 2.51956
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.85294

Cumulative Model Updates: 129,976
Cumulative Timesteps: 1,084,797,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,833.56336
Policy Entropy: 1.70822
Value Function Loss: 0.05723

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.31536
Value Function Update Magnitude: 0.36711

Collected Steps per Second: 21,906.65323
Overall Steps per Second: 10,436.77400

Timestep Collection Time: 2.28305
Timestep Consumption Time: 2.50904
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.79209

Cumulative Model Updates: 129,982
Cumulative Timesteps: 1,084,847,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1084847046...
Checkpoint 1084847046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,696.64920
Policy Entropy: 1.71791
Value Function Loss: 0.05679

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07773
Policy Update Magnitude: 0.31503
Value Function Update Magnitude: 0.36311

Collected Steps per Second: 21,601.31515
Overall Steps per Second: 10,526.61679

Timestep Collection Time: 2.31597
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.75252

Cumulative Model Updates: 129,988
Cumulative Timesteps: 1,084,897,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,759.49254
Policy Entropy: 1.71160
Value Function Loss: 0.05761

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.31701
Value Function Update Magnitude: 0.37214

Collected Steps per Second: 21,656.20532
Overall Steps per Second: 10,545.45048

Timestep Collection Time: 2.30992
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.74366

Cumulative Model Updates: 129,994
Cumulative Timesteps: 1,084,947,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1084947098...
Checkpoint 1084947098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,834.20265
Policy Entropy: 1.71361
Value Function Loss: 0.05799

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.31830
Value Function Update Magnitude: 0.37371

Collected Steps per Second: 21,586.96893
Overall Steps per Second: 10,523.82088

Timestep Collection Time: 2.31705
Timestep Consumption Time: 2.43579
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.75284

Cumulative Model Updates: 130,000
Cumulative Timesteps: 1,084,997,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,716.15414
Policy Entropy: 1.72147
Value Function Loss: 0.06638

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07966
Policy Update Magnitude: 0.32286
Value Function Update Magnitude: 0.35874

Collected Steps per Second: 21,864.57526
Overall Steps per Second: 10,479.00995

Timestep Collection Time: 2.28708
Timestep Consumption Time: 2.48494
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.77202

Cumulative Model Updates: 130,006
Cumulative Timesteps: 1,085,047,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1085047122...
Checkpoint 1085047122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,480.66047
Policy Entropy: 1.73679
Value Function Loss: 0.06776

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.32523
Value Function Update Magnitude: 0.34971

Collected Steps per Second: 21,984.70936
Overall Steps per Second: 10,646.79186

Timestep Collection Time: 2.27458
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.69681

Cumulative Model Updates: 130,012
Cumulative Timesteps: 1,085,097,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,388.73961
Policy Entropy: 1.72949
Value Function Loss: 0.06944

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.32633
Value Function Update Magnitude: 0.38068

Collected Steps per Second: 22,232.34036
Overall Steps per Second: 10,454.57259

Timestep Collection Time: 2.24943
Timestep Consumption Time: 2.53413
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.78355

Cumulative Model Updates: 130,018
Cumulative Timesteps: 1,085,147,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1085147138...
Checkpoint 1085147138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,256.88668
Policy Entropy: 1.71674
Value Function Loss: 0.06261

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.32291
Value Function Update Magnitude: 0.38736

Collected Steps per Second: 21,802.17191
Overall Steps per Second: 10,587.57326

Timestep Collection Time: 2.29362
Timestep Consumption Time: 2.42946
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.72308

Cumulative Model Updates: 130,024
Cumulative Timesteps: 1,085,197,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,254.07302
Policy Entropy: 1.72049
Value Function Loss: 0.06168

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.30739
Value Function Update Magnitude: 0.37495

Collected Steps per Second: 21,938.49169
Overall Steps per Second: 10,628.56754

Timestep Collection Time: 2.27974
Timestep Consumption Time: 2.42588
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.70562

Cumulative Model Updates: 130,030
Cumulative Timesteps: 1,085,247,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1085247158...
Checkpoint 1085247158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,585.88661
Policy Entropy: 1.70028
Value Function Loss: 0.05584

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.30832
Value Function Update Magnitude: 0.33890

Collected Steps per Second: 21,547.24230
Overall Steps per Second: 10,506.23677

Timestep Collection Time: 2.32067
Timestep Consumption Time: 2.43879
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.75946

Cumulative Model Updates: 130,036
Cumulative Timesteps: 1,085,297,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,516.45201
Policy Entropy: 1.70517
Value Function Loss: 0.05245

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.30950
Value Function Update Magnitude: 0.32091

Collected Steps per Second: 22,096.02696
Overall Steps per Second: 10,460.47444

Timestep Collection Time: 2.26321
Timestep Consumption Time: 2.51745
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.78066

Cumulative Model Updates: 130,042
Cumulative Timesteps: 1,085,347,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1085347170...
Checkpoint 1085347170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,719.56229
Policy Entropy: 1.69814
Value Function Loss: 0.04908

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07490
Policy Update Magnitude: 0.30652
Value Function Update Magnitude: 0.33141

Collected Steps per Second: 21,327.94182
Overall Steps per Second: 10,320.02862

Timestep Collection Time: 2.34462
Timestep Consumption Time: 2.50091
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.84553

Cumulative Model Updates: 130,048
Cumulative Timesteps: 1,085,397,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,165.46981
Policy Entropy: 1.70509
Value Function Loss: 0.04969

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07498
Policy Update Magnitude: 0.30338
Value Function Update Magnitude: 0.32933

Collected Steps per Second: 21,768.13377
Overall Steps per Second: 10,404.36472

Timestep Collection Time: 2.29749
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.80683

Cumulative Model Updates: 130,054
Cumulative Timesteps: 1,085,447,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1085447188...
Checkpoint 1085447188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,695.56919
Policy Entropy: 1.70267
Value Function Loss: 0.05010

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07315
Policy Update Magnitude: 0.30180
Value Function Update Magnitude: 0.32986

Collected Steps per Second: 21,578.02478
Overall Steps per Second: 10,536.02018

Timestep Collection Time: 2.31745
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.74619

Cumulative Model Updates: 130,060
Cumulative Timesteps: 1,085,497,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,190.55828
Policy Entropy: 1.69630
Value Function Loss: 0.05202

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.30200
Value Function Update Magnitude: 0.33732

Collected Steps per Second: 21,893.10848
Overall Steps per Second: 10,568.56376

Timestep Collection Time: 2.28538
Timestep Consumption Time: 2.44885
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.73423

Cumulative Model Updates: 130,066
Cumulative Timesteps: 1,085,547,228

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1085547228...
Checkpoint 1085547228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,727.54473
Policy Entropy: 1.69325
Value Function Loss: 0.05159

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.29997
Value Function Update Magnitude: 0.32748

Collected Steps per Second: 21,737.42479
Overall Steps per Second: 10,504.79038

Timestep Collection Time: 2.30055
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.76049

Cumulative Model Updates: 130,072
Cumulative Timesteps: 1,085,597,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,879.27893
Policy Entropy: 1.69487
Value Function Loss: 0.05203

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.29803
Value Function Update Magnitude: 0.32017

Collected Steps per Second: 22,313.71090
Overall Steps per Second: 10,502.72118

Timestep Collection Time: 2.24149
Timestep Consumption Time: 2.52070
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.76219

Cumulative Model Updates: 130,078
Cumulative Timesteps: 1,085,647,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1085647252...
Checkpoint 1085647252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,918.63232
Policy Entropy: 1.69126
Value Function Loss: 0.05106

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.29986
Value Function Update Magnitude: 0.32379

Collected Steps per Second: 22,072.65221
Overall Steps per Second: 10,623.06650

Timestep Collection Time: 2.26724
Timestep Consumption Time: 2.44364
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.71088

Cumulative Model Updates: 130,084
Cumulative Timesteps: 1,085,697,296

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,403.69969
Policy Entropy: 1.68509
Value Function Loss: 0.04985

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.29919
Value Function Update Magnitude: 0.32555

Collected Steps per Second: 22,158.14856
Overall Steps per Second: 10,494.59162

Timestep Collection Time: 2.25723
Timestep Consumption Time: 2.50866
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.76588

Cumulative Model Updates: 130,090
Cumulative Timesteps: 1,085,747,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1085747312...
Checkpoint 1085747312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,657.42469
Policy Entropy: 1.69320
Value Function Loss: 0.05500

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.30344
Value Function Update Magnitude: 0.33098

Collected Steps per Second: 21,816.10295
Overall Steps per Second: 10,566.33655

Timestep Collection Time: 2.29390
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.73617

Cumulative Model Updates: 130,096
Cumulative Timesteps: 1,085,797,356

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,552.99852
Policy Entropy: 1.70022
Value Function Loss: 0.05386

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.30729
Value Function Update Magnitude: 0.33827

Collected Steps per Second: 20,631.86765
Overall Steps per Second: 10,196.06903

Timestep Collection Time: 2.42402
Timestep Consumption Time: 2.48101
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.90503

Cumulative Model Updates: 130,102
Cumulative Timesteps: 1,085,847,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1085847368...
Checkpoint 1085847368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,386.28321
Policy Entropy: 1.68784
Value Function Loss: 0.05977

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.35370

Collected Steps per Second: 21,427.86988
Overall Steps per Second: 10,504.85937

Timestep Collection Time: 2.33565
Timestep Consumption Time: 2.42862
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.76427

Cumulative Model Updates: 130,108
Cumulative Timesteps: 1,085,897,416

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,095.27309
Policy Entropy: 1.69015
Value Function Loss: 0.05761

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.31635
Value Function Update Magnitude: 0.35972

Collected Steps per Second: 21,750.41039
Overall Steps per Second: 10,547.41239

Timestep Collection Time: 2.29881
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.74050

Cumulative Model Updates: 130,114
Cumulative Timesteps: 1,085,947,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1085947416...
Checkpoint 1085947416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,045.78981
Policy Entropy: 1.67434
Value Function Loss: 0.05434

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.31051
Value Function Update Magnitude: 0.34774

Collected Steps per Second: 21,626.50344
Overall Steps per Second: 10,512.10872

Timestep Collection Time: 2.31327
Timestep Consumption Time: 2.44581
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.75908

Cumulative Model Updates: 130,120
Cumulative Timesteps: 1,085,997,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,153.22430
Policy Entropy: 1.69709
Value Function Loss: 0.05455

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.31028
Value Function Update Magnitude: 0.32147

Collected Steps per Second: 22,155.64032
Overall Steps per Second: 10,613.30412

Timestep Collection Time: 2.25730
Timestep Consumption Time: 2.45490
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.71220

Cumulative Model Updates: 130,126
Cumulative Timesteps: 1,086,047,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1086047456...
Checkpoint 1086047456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,576.14469
Policy Entropy: 1.68232
Value Function Loss: 0.05107

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.30515
Value Function Update Magnitude: 0.33787

Collected Steps per Second: 21,824.39175
Overall Steps per Second: 10,562.55866

Timestep Collection Time: 2.29193
Timestep Consumption Time: 2.44366
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.73560

Cumulative Model Updates: 130,132
Cumulative Timesteps: 1,086,097,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,355.21620
Policy Entropy: 1.70148
Value Function Loss: 0.05522

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.30270
Value Function Update Magnitude: 0.33508

Collected Steps per Second: 21,959.77372
Overall Steps per Second: 10,420.30313

Timestep Collection Time: 2.27798
Timestep Consumption Time: 2.52264
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.80063

Cumulative Model Updates: 130,138
Cumulative Timesteps: 1,086,147,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1086147500...
Checkpoint 1086147500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,437.17163
Policy Entropy: 1.68632
Value Function Loss: 0.05190

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07509
Policy Update Magnitude: 0.30142
Value Function Update Magnitude: 0.31328

Collected Steps per Second: 21,744.93686
Overall Steps per Second: 10,598.67672

Timestep Collection Time: 2.30067
Timestep Consumption Time: 2.41954
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.72021

Cumulative Model Updates: 130,144
Cumulative Timesteps: 1,086,197,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,907.22088
Policy Entropy: 1.69430
Value Function Loss: 0.05115

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.29861
Value Function Update Magnitude: 0.31656

Collected Steps per Second: 22,146.44559
Overall Steps per Second: 10,550.66805

Timestep Collection Time: 2.25842
Timestep Consumption Time: 2.48213
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.74055

Cumulative Model Updates: 130,150
Cumulative Timesteps: 1,086,247,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1086247544...
Checkpoint 1086247544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,348.15523
Policy Entropy: 1.68799
Value Function Loss: 0.04908

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.30000
Value Function Update Magnitude: 0.32543

Collected Steps per Second: 21,856.08020
Overall Steps per Second: 10,577.44407

Timestep Collection Time: 2.28861
Timestep Consumption Time: 2.44032
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.72893

Cumulative Model Updates: 130,156
Cumulative Timesteps: 1,086,297,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,770.43648
Policy Entropy: 1.70175
Value Function Loss: 0.05559

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.29954
Value Function Update Magnitude: 0.33848

Collected Steps per Second: 21,245.53092
Overall Steps per Second: 10,447.52769

Timestep Collection Time: 2.35588
Timestep Consumption Time: 2.43491
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.79080

Cumulative Model Updates: 130,162
Cumulative Timesteps: 1,086,347,616

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1086347616...
Checkpoint 1086347616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,584.32257
Policy Entropy: 1.71654
Value Function Loss: 0.06153

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.31377
Value Function Update Magnitude: 0.35612

Collected Steps per Second: 21,312.24821
Overall Steps per Second: 10,330.75133

Timestep Collection Time: 2.34701
Timestep Consumption Time: 2.49485
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.84185

Cumulative Model Updates: 130,168
Cumulative Timesteps: 1,086,397,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,930.50952
Policy Entropy: 1.71414
Value Function Loss: 0.05732

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.31326
Value Function Update Magnitude: 0.35584

Collected Steps per Second: 21,636.31173
Overall Steps per Second: 10,372.72880

Timestep Collection Time: 2.31139
Timestep Consumption Time: 2.50990
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.82130

Cumulative Model Updates: 130,174
Cumulative Timesteps: 1,086,447,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1086447646...
Checkpoint 1086447646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,986.06274
Policy Entropy: 1.69587
Value Function Loss: 0.05340

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.30515
Value Function Update Magnitude: 0.33429

Collected Steps per Second: 21,584.31794
Overall Steps per Second: 10,408.31231

Timestep Collection Time: 2.31705
Timestep Consumption Time: 2.48795
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.80501

Cumulative Model Updates: 130,180
Cumulative Timesteps: 1,086,497,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,592.76440
Policy Entropy: 1.68781
Value Function Loss: 0.05016

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.30462
Value Function Update Magnitude: 0.31023

Collected Steps per Second: 22,278.91463
Overall Steps per Second: 10,662.93811

Timestep Collection Time: 2.24427
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.68914

Cumulative Model Updates: 130,186
Cumulative Timesteps: 1,086,547,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1086547658...
Checkpoint 1086547658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,330.13075
Policy Entropy: 1.69502
Value Function Loss: 0.05356

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07435
Policy Update Magnitude: 0.30770
Value Function Update Magnitude: 0.31541

Collected Steps per Second: 21,922.42013
Overall Steps per Second: 10,592.51945

Timestep Collection Time: 2.28141
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.72163

Cumulative Model Updates: 130,192
Cumulative Timesteps: 1,086,597,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,196.34014
Policy Entropy: 1.71480
Value Function Loss: 0.05264

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.30229
Value Function Update Magnitude: 0.31658

Collected Steps per Second: 21,587.10219
Overall Steps per Second: 10,539.55176

Timestep Collection Time: 2.31685
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.74536

Cumulative Model Updates: 130,198
Cumulative Timesteps: 1,086,647,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1086647686...
Checkpoint 1086647686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,024.16821
Policy Entropy: 1.69523
Value Function Loss: 0.05095

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.30096
Value Function Update Magnitude: 0.30288

Collected Steps per Second: 21,888.43837
Overall Steps per Second: 10,558.37152

Timestep Collection Time: 2.28522
Timestep Consumption Time: 2.45225
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.73747

Cumulative Model Updates: 130,204
Cumulative Timesteps: 1,086,697,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,514.25292
Policy Entropy: 1.69387
Value Function Loss: 0.05617

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.30630
Value Function Update Magnitude: 0.29450

Collected Steps per Second: 21,987.24949
Overall Steps per Second: 10,489.40956

Timestep Collection Time: 2.27414
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.76690

Cumulative Model Updates: 130,210
Cumulative Timesteps: 1,086,747,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1086747708...
Checkpoint 1086747708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,952.93114
Policy Entropy: 1.68453
Value Function Loss: 0.05579

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.30894
Value Function Update Magnitude: 0.31070

Collected Steps per Second: 22,087.89845
Overall Steps per Second: 10,643.38757

Timestep Collection Time: 2.26504
Timestep Consumption Time: 2.43553
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.70057

Cumulative Model Updates: 130,216
Cumulative Timesteps: 1,086,797,738

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,149.16854
Policy Entropy: 1.69538
Value Function Loss: 0.05430

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.30776
Value Function Update Magnitude: 0.31243

Collected Steps per Second: 21,771.77769
Overall Steps per Second: 10,488.42827

Timestep Collection Time: 2.29655
Timestep Consumption Time: 2.47061
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.76716

Cumulative Model Updates: 130,222
Cumulative Timesteps: 1,086,847,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1086847738...
Checkpoint 1086847738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,611.21550
Policy Entropy: 1.68875
Value Function Loss: 0.05373

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.30712
Value Function Update Magnitude: 0.31153

Collected Steps per Second: 21,367.72859
Overall Steps per Second: 10,371.50191

Timestep Collection Time: 2.34063
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.82225

Cumulative Model Updates: 130,228
Cumulative Timesteps: 1,086,897,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,612.77339
Policy Entropy: 1.69572
Value Function Loss: 0.05593

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.30907
Value Function Update Magnitude: 0.33805

Collected Steps per Second: 21,710.38986
Overall Steps per Second: 10,436.09028

Timestep Collection Time: 2.30314
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.79126

Cumulative Model Updates: 130,234
Cumulative Timesteps: 1,086,947,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1086947754...
Checkpoint 1086947754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,332.69662
Policy Entropy: 1.70982
Value Function Loss: 0.05696

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08333
Policy Update Magnitude: 0.30534
Value Function Update Magnitude: 0.35562

Collected Steps per Second: 21,900.57111
Overall Steps per Second: 10,449.54643

Timestep Collection Time: 2.28478
Timestep Consumption Time: 2.50375
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.78853

Cumulative Model Updates: 130,240
Cumulative Timesteps: 1,086,997,792

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,441.48632
Policy Entropy: 1.71782
Value Function Loss: 0.05868

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.30747
Value Function Update Magnitude: 0.35029

Collected Steps per Second: 21,529.81791
Overall Steps per Second: 10,479.66343

Timestep Collection Time: 2.32338
Timestep Consumption Time: 2.44986
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.77324

Cumulative Model Updates: 130,246
Cumulative Timesteps: 1,087,047,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1087047814...
Checkpoint 1087047814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,496.71890
Policy Entropy: 1.70037
Value Function Loss: 0.05948

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.31164
Value Function Update Magnitude: 0.35410

Collected Steps per Second: 21,463.98785
Overall Steps per Second: 10,672.64241

Timestep Collection Time: 2.32967
Timestep Consumption Time: 2.35558
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.68525

Cumulative Model Updates: 130,252
Cumulative Timesteps: 1,087,097,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,767.69195
Policy Entropy: 1.69449
Value Function Loss: 0.05633

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.36181

Collected Steps per Second: 21,505.43458
Overall Steps per Second: 10,507.51036

Timestep Collection Time: 2.32630
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.76117

Cumulative Model Updates: 130,258
Cumulative Timesteps: 1,087,147,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1087147846...
Checkpoint 1087147846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,122.23270
Policy Entropy: 1.68397
Value Function Loss: 0.05345

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.30061
Value Function Update Magnitude: 0.34057

Collected Steps per Second: 21,263.73354
Overall Steps per Second: 10,515.36048

Timestep Collection Time: 2.35293
Timestep Consumption Time: 2.40507
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.75799

Cumulative Model Updates: 130,264
Cumulative Timesteps: 1,087,197,878

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,762.89391
Policy Entropy: 1.68408
Value Function Loss: 0.05245

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.30386
Value Function Update Magnitude: 0.33381

Collected Steps per Second: 21,541.97984
Overall Steps per Second: 10,472.83208

Timestep Collection Time: 2.32253
Timestep Consumption Time: 2.45478
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.77731

Cumulative Model Updates: 130,270
Cumulative Timesteps: 1,087,247,910

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1087247910...
Checkpoint 1087247910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,452.50073
Policy Entropy: 1.67710
Value Function Loss: 0.05596

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.30989
Value Function Update Magnitude: 0.34570

Collected Steps per Second: 21,856.87105
Overall Steps per Second: 10,658.91479

Timestep Collection Time: 2.28871
Timestep Consumption Time: 2.40445
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.69316

Cumulative Model Updates: 130,276
Cumulative Timesteps: 1,087,297,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,767.95855
Policy Entropy: 1.68604
Value Function Loss: 0.05714

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.31089
Value Function Update Magnitude: 0.34452

Collected Steps per Second: 21,878.39978
Overall Steps per Second: 10,483.60460

Timestep Collection Time: 2.28728
Timestep Consumption Time: 2.48608
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.77336

Cumulative Model Updates: 130,282
Cumulative Timesteps: 1,087,347,976

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1087347976...
Checkpoint 1087347976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,444.44104
Policy Entropy: 1.69147
Value Function Loss: 0.06049

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.31487
Value Function Update Magnitude: 0.33776

Collected Steps per Second: 21,481.16096
Overall Steps per Second: 10,566.38248

Timestep Collection Time: 2.32883
Timestep Consumption Time: 2.40562
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.73445

Cumulative Model Updates: 130,288
Cumulative Timesteps: 1,087,398,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,762.93946
Policy Entropy: 1.68931
Value Function Loss: 0.05965

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.31925
Value Function Update Magnitude: 0.33218

Collected Steps per Second: 21,674.42167
Overall Steps per Second: 10,489.77826

Timestep Collection Time: 2.30733
Timestep Consumption Time: 2.46017
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.76750

Cumulative Model Updates: 130,294
Cumulative Timesteps: 1,087,448,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1087448012...
Checkpoint 1087448012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,266.23721
Policy Entropy: 1.68761
Value Function Loss: 0.05875

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.31856
Value Function Update Magnitude: 0.34162

Collected Steps per Second: 21,519.77274
Overall Steps per Second: 10,370.77092

Timestep Collection Time: 2.32391
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.82221

Cumulative Model Updates: 130,300
Cumulative Timesteps: 1,087,498,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,907.68321
Policy Entropy: 1.68737
Value Function Loss: 0.05631

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.31222
Value Function Update Magnitude: 0.34032

Collected Steps per Second: 22,339.88454
Overall Steps per Second: 10,626.61875

Timestep Collection Time: 2.23940
Timestep Consumption Time: 2.46840
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.70780

Cumulative Model Updates: 130,306
Cumulative Timesteps: 1,087,548,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1087548050...
Checkpoint 1087548050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,652.49021
Policy Entropy: 1.69851
Value Function Loss: 0.05985

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.31942
Value Function Update Magnitude: 0.33654

Collected Steps per Second: 21,746.67257
Overall Steps per Second: 10,452.16348

Timestep Collection Time: 2.30012
Timestep Consumption Time: 2.48549
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.78561

Cumulative Model Updates: 130,312
Cumulative Timesteps: 1,087,598,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,919.85372
Policy Entropy: 1.69647
Value Function Loss: 0.05779

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.31916
Value Function Update Magnitude: 0.32138

Collected Steps per Second: 21,984.72805
Overall Steps per Second: 10,637.37004

Timestep Collection Time: 2.27512
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.70210

Cumulative Model Updates: 130,318
Cumulative Timesteps: 1,087,648,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1087648088...
Checkpoint 1087648088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,053.09446
Policy Entropy: 1.70656
Value Function Loss: 0.05862

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.31435
Value Function Update Magnitude: 0.30665

Collected Steps per Second: 21,762.29119
Overall Steps per Second: 10,443.71109

Timestep Collection Time: 2.29755
Timestep Consumption Time: 2.49002
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.78757

Cumulative Model Updates: 130,324
Cumulative Timesteps: 1,087,698,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,582.43823
Policy Entropy: 1.70362
Value Function Loss: 0.05506

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.31039
Value Function Update Magnitude: 0.32872

Collected Steps per Second: 21,798.85003
Overall Steps per Second: 10,387.00361

Timestep Collection Time: 2.29489
Timestep Consumption Time: 2.52132
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.81621

Cumulative Model Updates: 130,330
Cumulative Timesteps: 1,087,748,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1087748114...
Checkpoint 1087748114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,366.56973
Policy Entropy: 1.70346
Value Function Loss: 0.05459

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.31058
Value Function Update Magnitude: 0.34060

Collected Steps per Second: 21,613.55340
Overall Steps per Second: 10,530.39294

Timestep Collection Time: 2.31512
Timestep Consumption Time: 2.43665
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.75177

Cumulative Model Updates: 130,336
Cumulative Timesteps: 1,087,798,152

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,513.96165
Policy Entropy: 1.69901
Value Function Loss: 0.05047

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.31051
Value Function Update Magnitude: 0.33626

Collected Steps per Second: 21,672.57690
Overall Steps per Second: 10,558.92278

Timestep Collection Time: 2.30752
Timestep Consumption Time: 2.42875
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.73628

Cumulative Model Updates: 130,342
Cumulative Timesteps: 1,087,848,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1087848162...
Checkpoint 1087848162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,620.95388
Policy Entropy: 1.69373
Value Function Loss: 0.05333

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.31306
Value Function Update Magnitude: 0.31187

Collected Steps per Second: 21,771.66855
Overall Steps per Second: 10,556.87104

Timestep Collection Time: 2.29757
Timestep Consumption Time: 2.44076
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.73834

Cumulative Model Updates: 130,348
Cumulative Timesteps: 1,087,898,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,086.25688
Policy Entropy: 1.69062
Value Function Loss: 0.05271

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07736
Policy Update Magnitude: 0.31095
Value Function Update Magnitude: 0.31576

Collected Steps per Second: 21,653.27145
Overall Steps per Second: 10,492.58445

Timestep Collection Time: 2.30912
Timestep Consumption Time: 2.45615
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.76527

Cumulative Model Updates: 130,354
Cumulative Timesteps: 1,087,948,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1087948184...
Checkpoint 1087948184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,243.04948
Policy Entropy: 1.68589
Value Function Loss: 0.05523

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.33196

Collected Steps per Second: 21,977.48400
Overall Steps per Second: 10,533.34046

Timestep Collection Time: 2.27551
Timestep Consumption Time: 2.47227
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.74778

Cumulative Model Updates: 130,360
Cumulative Timesteps: 1,087,998,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,045.51204
Policy Entropy: 1.69405
Value Function Loss: 0.05839

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.30351
Value Function Update Magnitude: 0.34379

Collected Steps per Second: 22,128.26225
Overall Steps per Second: 10,514.51122

Timestep Collection Time: 2.26028
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.75685

Cumulative Model Updates: 130,366
Cumulative Timesteps: 1,088,048,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1088048210...
Checkpoint 1088048210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,079.86571
Policy Entropy: 1.70251
Value Function Loss: 0.06167

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.30937
Value Function Update Magnitude: 0.36225

Collected Steps per Second: 22,010.17464
Overall Steps per Second: 10,713.16710

Timestep Collection Time: 2.27322
Timestep Consumption Time: 2.39711
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.67033

Cumulative Model Updates: 130,372
Cumulative Timesteps: 1,088,098,244

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,154.11073
Policy Entropy: 1.68274
Value Function Loss: 0.05873

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.30992
Value Function Update Magnitude: 0.37692

Collected Steps per Second: 22,091.51703
Overall Steps per Second: 10,445.18245

Timestep Collection Time: 2.26331
Timestep Consumption Time: 2.52358
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.78690

Cumulative Model Updates: 130,378
Cumulative Timesteps: 1,088,148,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1088148244...
Checkpoint 1088148244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,834.37623
Policy Entropy: 1.67048
Value Function Loss: 0.05340

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 0.30758
Value Function Update Magnitude: 0.35959

Collected Steps per Second: 21,838.02726
Overall Steps per Second: 10,629.20493

Timestep Collection Time: 2.28958
Timestep Consumption Time: 2.41444
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.70402

Cumulative Model Updates: 130,384
Cumulative Timesteps: 1,088,198,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,164.49808
Policy Entropy: 1.64934
Value Function Loss: 0.05256

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.30957
Value Function Update Magnitude: 0.33787

Collected Steps per Second: 21,861.08501
Overall Steps per Second: 10,417.75059

Timestep Collection Time: 2.28845
Timestep Consumption Time: 2.51374
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.80219

Cumulative Model Updates: 130,390
Cumulative Timesteps: 1,088,248,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1088248272...
Checkpoint 1088248272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,423.55511
Policy Entropy: 1.66254
Value Function Loss: 0.05641

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.30903
Value Function Update Magnitude: 0.32604

Collected Steps per Second: 21,524.67572
Overall Steps per Second: 10,547.15051

Timestep Collection Time: 2.32366
Timestep Consumption Time: 2.41848
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.74213

Cumulative Model Updates: 130,396
Cumulative Timesteps: 1,088,298,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,183.94923
Policy Entropy: 1.68096
Value Function Loss: 0.05652

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.30589
Value Function Update Magnitude: 0.32621

Collected Steps per Second: 21,583.37552
Overall Steps per Second: 10,558.07699

Timestep Collection Time: 2.31734
Timestep Consumption Time: 2.41989
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.73723

Cumulative Model Updates: 130,402
Cumulative Timesteps: 1,088,348,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1088348304...
Checkpoint 1088348304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,084.75386
Policy Entropy: 1.68379
Value Function Loss: 0.05771

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.30888
Value Function Update Magnitude: 0.33800

Collected Steps per Second: 21,510.62103
Overall Steps per Second: 10,521.86312

Timestep Collection Time: 2.32453
Timestep Consumption Time: 2.42767
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.75220

Cumulative Model Updates: 130,408
Cumulative Timesteps: 1,088,398,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,619.37069
Policy Entropy: 1.70738
Value Function Loss: 0.05658

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.31605
Value Function Update Magnitude: 0.34430

Collected Steps per Second: 21,634.76282
Overall Steps per Second: 10,529.34282

Timestep Collection Time: 2.31202
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.75053

Cumulative Model Updates: 130,414
Cumulative Timesteps: 1,088,448,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1088448326...
Checkpoint 1088448326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,693.87959
Policy Entropy: 1.69485
Value Function Loss: 0.05463

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.31504
Value Function Update Magnitude: 0.35557

Collected Steps per Second: 21,326.78346
Overall Steps per Second: 10,360.07988

Timestep Collection Time: 2.34541
Timestep Consumption Time: 2.48274
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.82815

Cumulative Model Updates: 130,420
Cumulative Timesteps: 1,088,498,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,753.92820
Policy Entropy: 1.69909
Value Function Loss: 0.05209

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07939
Policy Update Magnitude: 0.31049
Value Function Update Magnitude: 0.34806

Collected Steps per Second: 22,165.75706
Overall Steps per Second: 10,440.64292

Timestep Collection Time: 2.25709
Timestep Consumption Time: 2.53477
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.79185

Cumulative Model Updates: 130,426
Cumulative Timesteps: 1,088,548,376

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1088548376...
Checkpoint 1088548376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,010.31812
Policy Entropy: 1.70591
Value Function Loss: 0.05659

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.31147
Value Function Update Magnitude: 0.35088

Collected Steps per Second: 21,086.06062
Overall Steps per Second: 10,558.50326

Timestep Collection Time: 2.37361
Timestep Consumption Time: 2.36665
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.74026

Cumulative Model Updates: 130,432
Cumulative Timesteps: 1,088,598,426

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,993.43458
Policy Entropy: 1.70822
Value Function Loss: 0.05433

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.30959
Value Function Update Magnitude: 0.35337

Collected Steps per Second: 21,548.00930
Overall Steps per Second: 10,530.09126

Timestep Collection Time: 2.32235
Timestep Consumption Time: 2.42994
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.75229

Cumulative Model Updates: 130,438
Cumulative Timesteps: 1,088,648,468

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1088648468...
Checkpoint 1088648468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,579.35422
Policy Entropy: 1.71244
Value Function Loss: 0.05328

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.30305
Value Function Update Magnitude: 0.34473

Collected Steps per Second: 21,131.66708
Overall Steps per Second: 10,491.82579

Timestep Collection Time: 2.36621
Timestep Consumption Time: 2.39959
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.76581

Cumulative Model Updates: 130,444
Cumulative Timesteps: 1,088,698,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,723.07657
Policy Entropy: 1.70159
Value Function Loss: 0.05140

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.29787
Value Function Update Magnitude: 0.32682

Collected Steps per Second: 21,543.32856
Overall Steps per Second: 10,489.11712

Timestep Collection Time: 2.32137
Timestep Consumption Time: 2.44643
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.76780

Cumulative Model Updates: 130,450
Cumulative Timesteps: 1,088,748,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1088748480...
Checkpoint 1088748480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,825.15570
Policy Entropy: 1.71424
Value Function Loss: 0.05269

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.29626
Value Function Update Magnitude: 0.34104

Collected Steps per Second: 21,097.38454
Overall Steps per Second: 10,298.22526

Timestep Collection Time: 2.37100
Timestep Consumption Time: 2.48634
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.85734

Cumulative Model Updates: 130,456
Cumulative Timesteps: 1,088,798,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,780.27172
Policy Entropy: 1.72578
Value Function Loss: 0.05698

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.30418
Value Function Update Magnitude: 0.35957

Collected Steps per Second: 22,188.39120
Overall Steps per Second: 10,712.06807

Timestep Collection Time: 2.25388
Timestep Consumption Time: 2.41468
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.66857

Cumulative Model Updates: 130,462
Cumulative Timesteps: 1,088,848,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1088848512...
Checkpoint 1088848512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,862.17627
Policy Entropy: 1.72070
Value Function Loss: 0.05776

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.31445
Value Function Update Magnitude: 0.35613

Collected Steps per Second: 21,216.53215
Overall Steps per Second: 10,327.13680

Timestep Collection Time: 2.35750
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.84336

Cumulative Model Updates: 130,468
Cumulative Timesteps: 1,088,898,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,224.19536
Policy Entropy: 1.71816
Value Function Loss: 0.05797

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.31441
Value Function Update Magnitude: 0.34973

Collected Steps per Second: 21,195.79340
Overall Steps per Second: 10,301.78532

Timestep Collection Time: 2.35905
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.85372

Cumulative Model Updates: 130,474
Cumulative Timesteps: 1,088,948,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1088948532...
Checkpoint 1088948532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,592.55196
Policy Entropy: 1.71102
Value Function Loss: 0.05384

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.31484
Value Function Update Magnitude: 0.34204

Collected Steps per Second: 21,291.72947
Overall Steps per Second: 10,348.31001

Timestep Collection Time: 2.34927
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.83364

Cumulative Model Updates: 130,480
Cumulative Timesteps: 1,088,998,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,389.58030
Policy Entropy: 1.70382
Value Function Loss: 0.05320

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.32968

Collected Steps per Second: 22,029.97924
Overall Steps per Second: 10,418.30946

Timestep Collection Time: 2.27000
Timestep Consumption Time: 2.53001
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.80001

Cumulative Model Updates: 130,486
Cumulative Timesteps: 1,089,048,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1089048560...
Checkpoint 1089048560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,948.76501
Policy Entropy: 1.69586
Value Function Loss: 0.05348

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.31131
Value Function Update Magnitude: 0.33705

Collected Steps per Second: 21,786.95659
Overall Steps per Second: 10,526.20765

Timestep Collection Time: 2.29495
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.75005

Cumulative Model Updates: 130,492
Cumulative Timesteps: 1,089,098,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,871.41103
Policy Entropy: 1.69021
Value Function Loss: 0.05168

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.30885
Value Function Update Magnitude: 0.34380

Collected Steps per Second: 22,132.81129
Overall Steps per Second: 10,496.80608

Timestep Collection Time: 2.25990
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.76507

Cumulative Model Updates: 130,498
Cumulative Timesteps: 1,089,148,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1089148578...
Checkpoint 1089148578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,604.83131
Policy Entropy: 1.69077
Value Function Loss: 0.05384

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.30881
Value Function Update Magnitude: 0.32377

Collected Steps per Second: 22,138.48490
Overall Steps per Second: 10,635.48715

Timestep Collection Time: 2.26014
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.70463

Cumulative Model Updates: 130,504
Cumulative Timesteps: 1,089,198,614

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,440.36379
Policy Entropy: 1.70355
Value Function Loss: 0.05669

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07542
Policy Update Magnitude: 0.31706
Value Function Update Magnitude: 0.32235

Collected Steps per Second: 22,146.40432
Overall Steps per Second: 10,491.42952

Timestep Collection Time: 2.25833
Timestep Consumption Time: 2.50879
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.76713

Cumulative Model Updates: 130,510
Cumulative Timesteps: 1,089,248,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1089248628...
Checkpoint 1089248628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,671.56030
Policy Entropy: 1.71010
Value Function Loss: 0.06221

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.32364
Value Function Update Magnitude: 0.32402

Collected Steps per Second: 21,583.86627
Overall Steps per Second: 10,370.84581

Timestep Collection Time: 2.31877
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.82584

Cumulative Model Updates: 130,516
Cumulative Timesteps: 1,089,298,676

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,720.03805
Policy Entropy: 1.72181
Value Function Loss: 0.06199

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.32291
Value Function Update Magnitude: 0.30527

Collected Steps per Second: 22,213.41801
Overall Steps per Second: 10,686.54142

Timestep Collection Time: 2.25296
Timestep Consumption Time: 2.43012
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.68309

Cumulative Model Updates: 130,522
Cumulative Timesteps: 1,089,348,722

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1089348722...
Checkpoint 1089348722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,122.96736
Policy Entropy: 1.72147
Value Function Loss: 0.05622

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.31453
Value Function Update Magnitude: 0.33083

Collected Steps per Second: 21,845.11936
Overall Steps per Second: 10,603.06265

Timestep Collection Time: 2.28939
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.71675

Cumulative Model Updates: 130,528
Cumulative Timesteps: 1,089,398,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,070.69606
Policy Entropy: 1.71625
Value Function Loss: 0.05246

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.30463
Value Function Update Magnitude: 0.34382

Collected Steps per Second: 21,680.16606
Overall Steps per Second: 10,536.04787

Timestep Collection Time: 2.30718
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.74751

Cumulative Model Updates: 130,534
Cumulative Timesteps: 1,089,448,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1089448754...
Checkpoint 1089448754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,443.25628
Policy Entropy: 1.70155
Value Function Loss: 0.05182

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.30731
Value Function Update Magnitude: 0.33740

Collected Steps per Second: 21,241.84686
Overall Steps per Second: 10,291.34441

Timestep Collection Time: 2.35403
Timestep Consumption Time: 2.50481
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.85884

Cumulative Model Updates: 130,540
Cumulative Timesteps: 1,089,498,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,461.00245
Policy Entropy: 1.69097
Value Function Loss: 0.05556

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.30882
Value Function Update Magnitude: 0.33472

Collected Steps per Second: 21,760.00033
Overall Steps per Second: 10,393.14491

Timestep Collection Time: 2.29871
Timestep Consumption Time: 2.51407
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.81279

Cumulative Model Updates: 130,546
Cumulative Timesteps: 1,089,548,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1089548778...
Checkpoint 1089548778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,311.48813
Policy Entropy: 1.68873
Value Function Loss: 0.05700

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.31111
Value Function Update Magnitude: 0.34814

Collected Steps per Second: 21,079.39959
Overall Steps per Second: 10,192.05211

Timestep Collection Time: 2.37322
Timestep Consumption Time: 2.53512
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.90833

Cumulative Model Updates: 130,552
Cumulative Timesteps: 1,089,598,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,957.24546
Policy Entropy: 1.69144
Value Function Loss: 0.05725

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.29732
Value Function Update Magnitude: 0.35849

Collected Steps per Second: 22,096.78244
Overall Steps per Second: 10,448.39132

Timestep Collection Time: 2.26295
Timestep Consumption Time: 2.52285
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.78581

Cumulative Model Updates: 130,558
Cumulative Timesteps: 1,089,648,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1089648808...
Checkpoint 1089648808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,465.48525
Policy Entropy: 1.69397
Value Function Loss: 0.05463

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.27096
Value Function Update Magnitude: 0.36377

Collected Steps per Second: 21,540.89952
Overall Steps per Second: 10,370.49495

Timestep Collection Time: 2.32209
Timestep Consumption Time: 2.50120
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.82330

Cumulative Model Updates: 130,564
Cumulative Timesteps: 1,089,698,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,611.16715
Policy Entropy: 1.68932
Value Function Loss: 0.05389

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.28971
Value Function Update Magnitude: 0.32749

Collected Steps per Second: 21,729.48731
Overall Steps per Second: 10,717.92387

Timestep Collection Time: 2.30148
Timestep Consumption Time: 2.36453
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.66602

Cumulative Model Updates: 130,570
Cumulative Timesteps: 1,089,748,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1089748838...
Checkpoint 1089748838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,527.62774
Policy Entropy: 1.68998
Value Function Loss: 0.05328

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.30483
Value Function Update Magnitude: 0.30734

Collected Steps per Second: 21,185.46618
Overall Steps per Second: 10,595.75782

Timestep Collection Time: 2.36105
Timestep Consumption Time: 2.35970
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.72076

Cumulative Model Updates: 130,576
Cumulative Timesteps: 1,089,798,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,437.10743
Policy Entropy: 1.70733
Value Function Loss: 0.05843

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.31473
Value Function Update Magnitude: 0.32944

Collected Steps per Second: 21,362.43902
Overall Steps per Second: 10,528.79354

Timestep Collection Time: 2.34093
Timestep Consumption Time: 2.40871
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.74964

Cumulative Model Updates: 130,582
Cumulative Timesteps: 1,089,848,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1089848866...
Checkpoint 1089848866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,849.27367
Policy Entropy: 1.70530
Value Function Loss: 0.05657

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.31852
Value Function Update Magnitude: 0.35365

Collected Steps per Second: 21,130.59678
Overall Steps per Second: 10,587.19942

Timestep Collection Time: 2.36680
Timestep Consumption Time: 2.35701
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.72382

Cumulative Model Updates: 130,588
Cumulative Timesteps: 1,089,898,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,898.62191
Policy Entropy: 1.71154
Value Function Loss: 0.06268

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.32233
Value Function Update Magnitude: 0.36382

Collected Steps per Second: 21,073.40536
Overall Steps per Second: 10,468.63041

Timestep Collection Time: 2.37313
Timestep Consumption Time: 2.40400
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.77713

Cumulative Model Updates: 130,594
Cumulative Timesteps: 1,089,948,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1089948888...
Checkpoint 1089948888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,493.51999
Policy Entropy: 1.70073
Value Function Loss: 0.05922

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.31908
Value Function Update Magnitude: 0.30842

Collected Steps per Second: 20,761.51403
Overall Steps per Second: 10,219.33769

Timestep Collection Time: 2.40859
Timestep Consumption Time: 2.48468
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.89327

Cumulative Model Updates: 130,600
Cumulative Timesteps: 1,089,998,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,276.45577
Policy Entropy: 1.69388
Value Function Loss: 0.05780

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.28401

Collected Steps per Second: 21,462.25160
Overall Steps per Second: 10,491.33532

Timestep Collection Time: 2.33032
Timestep Consumption Time: 2.43685
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.76717

Cumulative Model Updates: 130,606
Cumulative Timesteps: 1,090,048,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1090048908...
Checkpoint 1090048908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,289.75072
Policy Entropy: 1.70167
Value Function Loss: 0.05352

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.30145
Value Function Update Magnitude: 0.27842

Collected Steps per Second: 21,261.19873
Overall Steps per Second: 10,387.77898

Timestep Collection Time: 2.35180
Timestep Consumption Time: 2.46175
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.81354

Cumulative Model Updates: 130,612
Cumulative Timesteps: 1,090,098,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,267.13819
Policy Entropy: 1.70001
Value Function Loss: 0.05626

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.30383
Value Function Update Magnitude: 0.28059

Collected Steps per Second: 21,787.05890
Overall Steps per Second: 10,624.95713

Timestep Collection Time: 2.29586
Timestep Consumption Time: 2.41193
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.70778

Cumulative Model Updates: 130,618
Cumulative Timesteps: 1,090,148,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1090148930...
Checkpoint 1090148930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,180.89958
Policy Entropy: 1.71751
Value Function Loss: 0.05858

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.31071
Value Function Update Magnitude: 0.29513

Collected Steps per Second: 22,118.66355
Overall Steps per Second: 10,642.56287

Timestep Collection Time: 2.26135
Timestep Consumption Time: 2.43846
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.69981

Cumulative Model Updates: 130,624
Cumulative Timesteps: 1,090,198,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,114.49041
Policy Entropy: 1.69049
Value Function Loss: 0.05994

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.31487
Value Function Update Magnitude: 0.31431

Collected Steps per Second: 22,152.14548
Overall Steps per Second: 10,448.55110

Timestep Collection Time: 2.25721
Timestep Consumption Time: 2.52834
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.78554

Cumulative Model Updates: 130,630
Cumulative Timesteps: 1,090,248,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1090248950...
Checkpoint 1090248950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,969.83942
Policy Entropy: 1.68024
Value Function Loss: 0.05382

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.31006
Value Function Update Magnitude: 0.30497

Collected Steps per Second: 21,567.66806
Overall Steps per Second: 10,367.06982

Timestep Collection Time: 2.31847
Timestep Consumption Time: 2.50488
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.82335

Cumulative Model Updates: 130,636
Cumulative Timesteps: 1,090,298,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,910.10593
Policy Entropy: 1.65488
Value Function Loss: 0.05117

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.30757
Value Function Update Magnitude: 0.30508

Collected Steps per Second: 22,248.24372
Overall Steps per Second: 10,521.80688

Timestep Collection Time: 2.24746
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.75223

Cumulative Model Updates: 130,642
Cumulative Timesteps: 1,090,348,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1090348956...
Checkpoint 1090348956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,541.78825
Policy Entropy: 1.67499
Value Function Loss: 0.05476

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.31068

Collected Steps per Second: 22,027.99155
Overall Steps per Second: 10,432.59194

Timestep Collection Time: 2.27066
Timestep Consumption Time: 2.52374
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.79440

Cumulative Model Updates: 130,648
Cumulative Timesteps: 1,090,398,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,780.84354
Policy Entropy: 1.67724
Value Function Loss: 0.05796

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.31898
Value Function Update Magnitude: 0.33062

Collected Steps per Second: 22,416.86995
Overall Steps per Second: 10,545.82567

Timestep Collection Time: 2.23073
Timestep Consumption Time: 2.51105
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.74178

Cumulative Model Updates: 130,654
Cumulative Timesteps: 1,090,448,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1090448980...
Checkpoint 1090448980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,824.92926
Policy Entropy: 1.68826
Value Function Loss: 0.05548

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.31783
Value Function Update Magnitude: 0.33598

Collected Steps per Second: 21,768.31108
Overall Steps per Second: 10,556.94690

Timestep Collection Time: 2.29820
Timestep Consumption Time: 2.44067
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.73887

Cumulative Model Updates: 130,660
Cumulative Timesteps: 1,090,499,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,616.56441
Policy Entropy: 1.69057
Value Function Loss: 0.05662

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.31617
Value Function Update Magnitude: 0.34162

Collected Steps per Second: 21,440.84870
Overall Steps per Second: 10,455.62907

Timestep Collection Time: 2.33218
Timestep Consumption Time: 2.45031
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.78250

Cumulative Model Updates: 130,666
Cumulative Timesteps: 1,090,549,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1090549012...
Checkpoint 1090549012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,701.25697
Policy Entropy: 1.68563
Value Function Loss: 0.05688

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.32228
Value Function Update Magnitude: 0.35697

Collected Steps per Second: 21,349.96835
Overall Steps per Second: 10,320.82952

Timestep Collection Time: 2.34211
Timestep Consumption Time: 2.50285
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.84496

Cumulative Model Updates: 130,672
Cumulative Timesteps: 1,090,599,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,154.46145
Policy Entropy: 1.70217
Value Function Loss: 0.06055

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.32451
Value Function Update Magnitude: 0.37130

Collected Steps per Second: 21,763.02509
Overall Steps per Second: 10,378.55748

Timestep Collection Time: 2.29940
Timestep Consumption Time: 2.52227
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.82167

Cumulative Model Updates: 130,678
Cumulative Timesteps: 1,090,649,058

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1090649058...
Checkpoint 1090649058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,283.43939
Policy Entropy: 1.69925
Value Function Loss: 0.05769

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.32429
Value Function Update Magnitude: 0.36756

Collected Steps per Second: 20,760.88132
Overall Steps per Second: 10,328.88968

Timestep Collection Time: 2.41030
Timestep Consumption Time: 2.43436
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.84466

Cumulative Model Updates: 130,684
Cumulative Timesteps: 1,090,699,098

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,919.78379
Policy Entropy: 1.69460
Value Function Loss: 0.05506

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.31555
Value Function Update Magnitude: 0.35933

Collected Steps per Second: 21,259.52304
Overall Steps per Second: 10,418.05876

Timestep Collection Time: 2.35302
Timestep Consumption Time: 2.44865
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.80166

Cumulative Model Updates: 130,690
Cumulative Timesteps: 1,090,749,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1090749122...
Checkpoint 1090749122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,087.15949
Policy Entropy: 1.68633
Value Function Loss: 0.05364

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.30834
Value Function Update Magnitude: 0.34874

Collected Steps per Second: 21,469.83253
Overall Steps per Second: 10,518.10988

Timestep Collection Time: 2.32904
Timestep Consumption Time: 2.42505
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.75409

Cumulative Model Updates: 130,696
Cumulative Timesteps: 1,090,799,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,489.39448
Policy Entropy: 1.68905
Value Function Loss: 0.04929

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.30128
Value Function Update Magnitude: 0.31598

Collected Steps per Second: 21,583.91080
Overall Steps per Second: 10,514.89681

Timestep Collection Time: 2.31784
Timestep Consumption Time: 2.43998
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.75782

Cumulative Model Updates: 130,702
Cumulative Timesteps: 1,090,849,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1090849154...
Checkpoint 1090849154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,592.62563
Policy Entropy: 1.69919
Value Function Loss: 0.05221

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.30225
Value Function Update Magnitude: 0.30248

Collected Steps per Second: 21,428.83009
Overall Steps per Second: 10,539.77132

Timestep Collection Time: 2.33340
Timestep Consumption Time: 2.41073
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.74413

Cumulative Model Updates: 130,708
Cumulative Timesteps: 1,090,899,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,844.19191
Policy Entropy: 1.69564
Value Function Loss: 0.05579

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.31102
Value Function Update Magnitude: 0.30844

Collected Steps per Second: 21,910.38499
Overall Steps per Second: 10,497.69877

Timestep Collection Time: 2.28339
Timestep Consumption Time: 2.48241
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.76581

Cumulative Model Updates: 130,714
Cumulative Timesteps: 1,090,949,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1090949186...
Checkpoint 1090949186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,970.60473
Policy Entropy: 1.69205
Value Function Loss: 0.06066

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.31537
Value Function Update Magnitude: 0.33387

Collected Steps per Second: 21,538.35975
Overall Steps per Second: 10,579.77537

Timestep Collection Time: 2.32153
Timestep Consumption Time: 2.40465
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.72619

Cumulative Model Updates: 130,720
Cumulative Timesteps: 1,090,999,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,273.10302
Policy Entropy: 1.69953
Value Function Loss: 0.05989

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.31859
Value Function Update Magnitude: 0.35834

Collected Steps per Second: 21,947.54376
Overall Steps per Second: 10,548.88400

Timestep Collection Time: 2.27934
Timestep Consumption Time: 2.46296
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.74230

Cumulative Model Updates: 130,726
Cumulative Timesteps: 1,091,049,214

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1091049214...
Checkpoint 1091049214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,378.78019
Policy Entropy: 1.69250
Value Function Loss: 0.05813

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.32306
Value Function Update Magnitude: 0.36603

Collected Steps per Second: 21,222.58057
Overall Steps per Second: 10,275.40836

Timestep Collection Time: 2.35608
Timestep Consumption Time: 2.51011
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.86618

Cumulative Model Updates: 130,732
Cumulative Timesteps: 1,091,099,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,382.27219
Policy Entropy: 1.69279
Value Function Loss: 0.05712

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.32420
Value Function Update Magnitude: 0.37543

Collected Steps per Second: 21,655.58482
Overall Steps per Second: 10,374.22622

Timestep Collection Time: 2.31118
Timestep Consumption Time: 2.51327
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.82446

Cumulative Model Updates: 130,738
Cumulative Timesteps: 1,091,149,266

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1091149266...
Checkpoint 1091149266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,470.36297
Policy Entropy: 1.68922
Value Function Loss: 0.05995

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.32444
Value Function Update Magnitude: 0.37247

Collected Steps per Second: 21,439.09404
Overall Steps per Second: 10,339.99688

Timestep Collection Time: 2.33219
Timestep Consumption Time: 2.50340
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.83559

Cumulative Model Updates: 130,744
Cumulative Timesteps: 1,091,199,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,530.81496
Policy Entropy: 1.70404
Value Function Loss: 0.05734

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.32259
Value Function Update Magnitude: 0.37919

Collected Steps per Second: 21,575.23550
Overall Steps per Second: 10,355.26519

Timestep Collection Time: 2.31803
Timestep Consumption Time: 2.51159
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.82962

Cumulative Model Updates: 130,750
Cumulative Timesteps: 1,091,249,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1091249278...
Checkpoint 1091249278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,991.29999
Policy Entropy: 1.71945
Value Function Loss: 0.05865

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.32142
Value Function Update Magnitude: 0.39916

Collected Steps per Second: 21,393.77116
Overall Steps per Second: 10,500.23649

Timestep Collection Time: 2.33750
Timestep Consumption Time: 2.42506
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.76256

Cumulative Model Updates: 130,756
Cumulative Timesteps: 1,091,299,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,018.30022
Policy Entropy: 1.74092
Value Function Loss: 0.05613

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08782
Policy Update Magnitude: 0.31711
Value Function Update Magnitude: 0.40312

Collected Steps per Second: 21,738.50224
Overall Steps per Second: 10,474.87825

Timestep Collection Time: 2.30126
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.77581

Cumulative Model Updates: 130,762
Cumulative Timesteps: 1,091,349,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1091349312...
Checkpoint 1091349312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,091.50399
Policy Entropy: 1.73308
Value Function Loss: 0.05417

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.29450
Value Function Update Magnitude: 0.38529

Collected Steps per Second: 21,812.65568
Overall Steps per Second: 10,391.87812

Timestep Collection Time: 2.29271
Timestep Consumption Time: 2.51971
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.81241

Cumulative Model Updates: 130,768
Cumulative Timesteps: 1,091,399,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,031.93111
Policy Entropy: 1.71996
Value Function Loss: 0.05215

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.27991
Value Function Update Magnitude: 0.35418

Collected Steps per Second: 22,149.99605
Overall Steps per Second: 10,515.74235

Timestep Collection Time: 2.25797
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.75611

Cumulative Model Updates: 130,774
Cumulative Timesteps: 1,091,449,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1091449336...
Checkpoint 1091449336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,422.86668
Policy Entropy: 1.70683
Value Function Loss: 0.05471

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.30120
Value Function Update Magnitude: 0.34565

Collected Steps per Second: 21,732.87059
Overall Steps per Second: 10,463.12090

Timestep Collection Time: 2.30177
Timestep Consumption Time: 2.47922
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.78098

Cumulative Model Updates: 130,780
Cumulative Timesteps: 1,091,499,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,474.15398
Policy Entropy: 1.71048
Value Function Loss: 0.05881

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.31376
Value Function Update Magnitude: 0.33734

Collected Steps per Second: 22,092.89501
Overall Steps per Second: 10,487.58331

Timestep Collection Time: 2.26408
Timestep Consumption Time: 2.50537
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.76945

Cumulative Model Updates: 130,786
Cumulative Timesteps: 1,091,549,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1091549380...
Checkpoint 1091549380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,765.44554
Policy Entropy: 1.71395
Value Function Loss: 0.06411

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.31944
Value Function Update Magnitude: 0.31686

Collected Steps per Second: 22,033.05337
Overall Steps per Second: 10,619.84055

Timestep Collection Time: 2.27095
Timestep Consumption Time: 2.44061
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.71156

Cumulative Model Updates: 130,792
Cumulative Timesteps: 1,091,599,416

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,787.29173
Policy Entropy: 1.72329
Value Function Loss: 0.06289

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.32608
Value Function Update Magnitude: 0.33764

Collected Steps per Second: 21,939.28392
Overall Steps per Second: 10,537.32566

Timestep Collection Time: 2.27984
Timestep Consumption Time: 2.46691
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.74675

Cumulative Model Updates: 130,798
Cumulative Timesteps: 1,091,649,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1091649434...
Checkpoint 1091649434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,917.25884
Policy Entropy: 1.71719
Value Function Loss: 0.05603

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.32180
Value Function Update Magnitude: 0.36863

Collected Steps per Second: 21,996.22828
Overall Steps per Second: 10,535.82262

Timestep Collection Time: 2.27466
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.74894

Cumulative Model Updates: 130,804
Cumulative Timesteps: 1,091,699,468

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,861.13321
Policy Entropy: 1.71036
Value Function Loss: 0.04964

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.31000
Value Function Update Magnitude: 0.36827

Collected Steps per Second: 21,463.86474
Overall Steps per Second: 10,449.30988

Timestep Collection Time: 2.33136
Timestep Consumption Time: 2.45747
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.78883

Cumulative Model Updates: 130,810
Cumulative Timesteps: 1,091,749,508

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1091749508...
Checkpoint 1091749508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,940.17259
Policy Entropy: 1.68724
Value Function Loss: 0.04896

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.30654
Value Function Update Magnitude: 0.34516

Collected Steps per Second: 21,434.50107
Overall Steps per Second: 10,364.71719

Timestep Collection Time: 2.33343
Timestep Consumption Time: 2.49217
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.82560

Cumulative Model Updates: 130,816
Cumulative Timesteps: 1,091,799,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,311.01719
Policy Entropy: 1.68762
Value Function Loss: 0.05488

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08057
Policy Update Magnitude: 0.31251
Value Function Update Magnitude: 0.34322

Collected Steps per Second: 21,506.44452
Overall Steps per Second: 10,342.81884

Timestep Collection Time: 2.32535
Timestep Consumption Time: 2.50989
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.83524

Cumulative Model Updates: 130,822
Cumulative Timesteps: 1,091,849,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1091849534...
Checkpoint 1091849534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,364.53512
Policy Entropy: 1.68243
Value Function Loss: 0.05372

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.31053
Value Function Update Magnitude: 0.35173

Collected Steps per Second: 21,598.86452
Overall Steps per Second: 10,541.08952

Timestep Collection Time: 2.31521
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.74391

Cumulative Model Updates: 130,828
Cumulative Timesteps: 1,091,899,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,187.53502
Policy Entropy: 1.70725
Value Function Loss: 0.05820

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.31562
Value Function Update Magnitude: 0.33990

Collected Steps per Second: 21,699.66350
Overall Steps per Second: 10,506.67921

Timestep Collection Time: 2.30474
Timestep Consumption Time: 2.45528
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.76002

Cumulative Model Updates: 130,834
Cumulative Timesteps: 1,091,949,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1091949552...
Checkpoint 1091949552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,921.32971
Policy Entropy: 1.72124
Value Function Loss: 0.06043

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07621
Policy Update Magnitude: 0.31928
Value Function Update Magnitude: 0.32991

Collected Steps per Second: 21,909.97243
Overall Steps per Second: 10,563.48186

Timestep Collection Time: 2.28289
Timestep Consumption Time: 2.45210
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.73499

Cumulative Model Updates: 130,840
Cumulative Timesteps: 1,091,999,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,057.24870
Policy Entropy: 1.72124
Value Function Loss: 0.06227

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07730
Policy Update Magnitude: 0.32380
Value Function Update Magnitude: 0.35165

Collected Steps per Second: 22,114.53833
Overall Steps per Second: 10,513.92147

Timestep Collection Time: 2.26123
Timestep Consumption Time: 2.49494
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.75617

Cumulative Model Updates: 130,846
Cumulative Timesteps: 1,092,049,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1092049576...
Checkpoint 1092049576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,396.16861
Policy Entropy: 1.69600
Value Function Loss: 0.06118

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.32524
Value Function Update Magnitude: 0.37592

Collected Steps per Second: 22,152.19099
Overall Steps per Second: 10,649.17939

Timestep Collection Time: 2.25874
Timestep Consumption Time: 2.43984
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.69858

Cumulative Model Updates: 130,852
Cumulative Timesteps: 1,092,099,612

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,447.50489
Policy Entropy: 1.67601
Value Function Loss: 0.05569

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.32031
Value Function Update Magnitude: 0.38117

Collected Steps per Second: 21,883.25039
Overall Steps per Second: 10,428.91102

Timestep Collection Time: 2.28531
Timestep Consumption Time: 2.51001
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.79532

Cumulative Model Updates: 130,858
Cumulative Timesteps: 1,092,149,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1092149622...
Checkpoint 1092149622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,531.05590
Policy Entropy: 1.69851
Value Function Loss: 0.05778

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.30522
Value Function Update Magnitude: 0.37201

Collected Steps per Second: 21,918.73016
Overall Steps per Second: 10,610.29539

Timestep Collection Time: 2.28225
Timestep Consumption Time: 2.43242
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.71467

Cumulative Model Updates: 130,864
Cumulative Timesteps: 1,092,199,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,575.42498
Policy Entropy: 1.69984
Value Function Loss: 0.05211

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.28857
Value Function Update Magnitude: 0.36216

Collected Steps per Second: 22,104.15193
Overall Steps per Second: 10,543.06969

Timestep Collection Time: 2.26283
Timestep Consumption Time: 2.48133
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.74416

Cumulative Model Updates: 130,870
Cumulative Timesteps: 1,092,249,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1092249664...
Checkpoint 1092249664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,491.35704
Policy Entropy: 1.70487
Value Function Loss: 0.06071

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.30330
Value Function Update Magnitude: 0.36375

Collected Steps per Second: 21,776.86240
Overall Steps per Second: 10,586.75955

Timestep Collection Time: 2.29675
Timestep Consumption Time: 2.42764
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.72439

Cumulative Model Updates: 130,876
Cumulative Timesteps: 1,092,299,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,648.88583
Policy Entropy: 1.70144
Value Function Loss: 0.05839

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.31855
Value Function Update Magnitude: 0.36653

Collected Steps per Second: 21,561.52685
Overall Steps per Second: 10,506.94078

Timestep Collection Time: 2.31969
Timestep Consumption Time: 2.44059
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.76028

Cumulative Model Updates: 130,882
Cumulative Timesteps: 1,092,349,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1092349696...
Checkpoint 1092349696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,761.66386
Policy Entropy: 1.70236
Value Function Loss: 0.06212

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.32215
Value Function Update Magnitude: 0.37080

Collected Steps per Second: 21,771.27740
Overall Steps per Second: 10,575.91716

Timestep Collection Time: 2.29807
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.73075

Cumulative Model Updates: 130,888
Cumulative Timesteps: 1,092,399,728

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,441.11263
Policy Entropy: 1.68382
Value Function Loss: 0.05432

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.31682
Value Function Update Magnitude: 0.35567

Collected Steps per Second: 21,660.48847
Overall Steps per Second: 10,530.64594

Timestep Collection Time: 2.30909
Timestep Consumption Time: 2.44048
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.74957

Cumulative Model Updates: 130,894
Cumulative Timesteps: 1,092,449,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1092449744...
Checkpoint 1092449744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,602.45470
Policy Entropy: 1.67443
Value Function Loss: 0.05357

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.31234
Value Function Update Magnitude: 0.35224

Collected Steps per Second: 22,057.35972
Overall Steps per Second: 10,569.55140

Timestep Collection Time: 2.26745
Timestep Consumption Time: 2.46444
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.73189

Cumulative Model Updates: 130,900
Cumulative Timesteps: 1,092,499,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,036.84011
Policy Entropy: 1.66958
Value Function Loss: 0.05385

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.30917
Value Function Update Magnitude: 0.36343

Collected Steps per Second: 21,859.61576
Overall Steps per Second: 10,424.50327

Timestep Collection Time: 2.28879
Timestep Consumption Time: 2.51067
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.79946

Cumulative Model Updates: 130,906
Cumulative Timesteps: 1,092,549,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1092549790...
Checkpoint 1092549790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,146.77540
Policy Entropy: 1.68301
Value Function Loss: 0.05708

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.30259
Value Function Update Magnitude: 0.37773

Collected Steps per Second: 21,949.31659
Overall Steps per Second: 10,632.03004

Timestep Collection Time: 2.27916
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.70522

Cumulative Model Updates: 130,912
Cumulative Timesteps: 1,092,599,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,910.47850
Policy Entropy: 1.67712
Value Function Loss: 0.05698

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09703
Policy Update Magnitude: 0.30884
Value Function Update Magnitude: 0.39808

Collected Steps per Second: 21,931.73551
Overall Steps per Second: 10,613.00536

Timestep Collection Time: 2.28026
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.71214

Cumulative Model Updates: 130,918
Cumulative Timesteps: 1,092,649,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1092649826...
Checkpoint 1092649826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,840.24992
Policy Entropy: 1.69476
Value Function Loss: 0.05772

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.30736
Value Function Update Magnitude: 0.39990

Collected Steps per Second: 22,096.13724
Overall Steps per Second: 10,665.66505

Timestep Collection Time: 2.26383
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.69000

Cumulative Model Updates: 130,924
Cumulative Timesteps: 1,092,699,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,191.07356
Policy Entropy: 1.68509
Value Function Loss: 0.06043

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.32494
Value Function Update Magnitude: 0.39596

Collected Steps per Second: 21,976.21601
Overall Steps per Second: 10,447.36803

Timestep Collection Time: 2.27573
Timestep Consumption Time: 2.51131
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.78704

Cumulative Model Updates: 130,930
Cumulative Timesteps: 1,092,749,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1092749860...
Checkpoint 1092749860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,292.79092
Policy Entropy: 1.69484
Value Function Loss: 0.05901

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.32530
Value Function Update Magnitude: 0.38204

Collected Steps per Second: 21,960.16008
Overall Steps per Second: 10,639.76178

Timestep Collection Time: 2.27767
Timestep Consumption Time: 2.42337
PPO Batch Consumption Time: 0.27663
Total Iteration Time: 4.70105

Cumulative Model Updates: 130,936
Cumulative Timesteps: 1,092,799,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,377.55413
Policy Entropy: 1.68587
Value Function Loss: 0.05701

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.32112
Value Function Update Magnitude: 0.35893

Collected Steps per Second: 21,764.02500
Overall Steps per Second: 10,400.57451

Timestep Collection Time: 2.29856
Timestep Consumption Time: 2.51136
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.80993

Cumulative Model Updates: 130,942
Cumulative Timesteps: 1,092,849,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1092849904...
Checkpoint 1092849904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,922.47636
Policy Entropy: 1.69078
Value Function Loss: 0.05640

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.31772
Value Function Update Magnitude: 0.34009

Collected Steps per Second: 21,310.13395
Overall Steps per Second: 10,323.41364

Timestep Collection Time: 2.34696
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.84472

Cumulative Model Updates: 130,948
Cumulative Timesteps: 1,092,899,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,297.34584
Policy Entropy: 1.68904
Value Function Loss: 0.05889

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.31934
Value Function Update Magnitude: 0.33964

Collected Steps per Second: 21,468.60950
Overall Steps per Second: 10,328.69340

Timestep Collection Time: 2.32935
Timestep Consumption Time: 2.51230
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.84166

Cumulative Model Updates: 130,954
Cumulative Timesteps: 1,092,949,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1092949926...
Checkpoint 1092949926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,010.60365
Policy Entropy: 1.67615
Value Function Loss: 0.06198

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.32066
Value Function Update Magnitude: 0.34555

Collected Steps per Second: 21,272.54659
Overall Steps per Second: 10,294.79997

Timestep Collection Time: 2.35195
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.85993

Cumulative Model Updates: 130,960
Cumulative Timesteps: 1,092,999,958

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,050.11332
Policy Entropy: 1.68881
Value Function Loss: 0.05969

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.32207
Value Function Update Magnitude: 0.33827

Collected Steps per Second: 21,957.57883
Overall Steps per Second: 10,390.32421

Timestep Collection Time: 2.27766
Timestep Consumption Time: 2.53566
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.81332

Cumulative Model Updates: 130,966
Cumulative Timesteps: 1,093,049,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1093049970...
Checkpoint 1093049970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,621.71350
Policy Entropy: 1.67357
Value Function Loss: 0.05536

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.36434

Collected Steps per Second: 21,946.90278
Overall Steps per Second: 10,527.83073

Timestep Collection Time: 2.27950
Timestep Consumption Time: 2.47247
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.75198

Cumulative Model Updates: 130,972
Cumulative Timesteps: 1,093,099,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,754.12412
Policy Entropy: 1.67825
Value Function Loss: 0.06001

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.31922
Value Function Update Magnitude: 0.32852

Collected Steps per Second: 21,828.68425
Overall Steps per Second: 10,555.63239

Timestep Collection Time: 2.29066
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.73700

Cumulative Model Updates: 130,978
Cumulative Timesteps: 1,093,150,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1093150000...
Checkpoint 1093150000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,688.23868
Policy Entropy: 1.67377
Value Function Loss: 0.06095

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.32601
Value Function Update Magnitude: 0.32960

Collected Steps per Second: 21,920.25786
Overall Steps per Second: 10,570.73121

Timestep Collection Time: 2.28337
Timestep Consumption Time: 2.45159
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73496

Cumulative Model Updates: 130,984
Cumulative Timesteps: 1,093,200,052

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,017.46158
Policy Entropy: 1.69669
Value Function Loss: 0.06345

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.32667
Value Function Update Magnitude: 0.37541

Collected Steps per Second: 21,851.66927
Overall Steps per Second: 10,501.53732

Timestep Collection Time: 2.28916
Timestep Consumption Time: 2.47414
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.76330

Cumulative Model Updates: 130,990
Cumulative Timesteps: 1,093,250,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1093250074...
Checkpoint 1093250074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,255.49808
Policy Entropy: 1.69941
Value Function Loss: 0.05720

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.31803
Value Function Update Magnitude: 0.36920

Collected Steps per Second: 21,793.12653
Overall Steps per Second: 10,570.98741

Timestep Collection Time: 2.29485
Timestep Consumption Time: 2.43621
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.73106

Cumulative Model Updates: 130,996
Cumulative Timesteps: 1,093,300,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,340.48656
Policy Entropy: 1.70398
Value Function Loss: 0.06506

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.32266
Value Function Update Magnitude: 0.30151

Collected Steps per Second: 21,861.47223
Overall Steps per Second: 10,511.98186

Timestep Collection Time: 2.28759
Timestep Consumption Time: 2.46984
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.75743

Cumulative Model Updates: 131,002
Cumulative Timesteps: 1,093,350,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1093350096...
Checkpoint 1093350096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,271.23741
Policy Entropy: 1.70040
Value Function Loss: 0.06292

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.32551
Value Function Update Magnitude: 0.33390

Collected Steps per Second: 21,810.79002
Overall Steps per Second: 10,576.61340

Timestep Collection Time: 2.29345
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.72949

Cumulative Model Updates: 131,008
Cumulative Timesteps: 1,093,400,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,880.41746
Policy Entropy: 1.70540
Value Function Loss: 0.06197

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.32552
Value Function Update Magnitude: 0.37018

Collected Steps per Second: 21,736.81612
Overall Steps per Second: 10,515.93595

Timestep Collection Time: 2.30043
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.75507

Cumulative Model Updates: 131,014
Cumulative Timesteps: 1,093,450,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1093450122...
Checkpoint 1093450122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,658.87453
Policy Entropy: 1.71127
Value Function Loss: 0.06118

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.32477
Value Function Update Magnitude: 0.34686

Collected Steps per Second: 21,394.33895
Overall Steps per Second: 10,580.45913

Timestep Collection Time: 2.33725
Timestep Consumption Time: 2.38882
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.72607

Cumulative Model Updates: 131,020
Cumulative Timesteps: 1,093,500,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,692.63672
Policy Entropy: 1.70507
Value Function Loss: 0.06094

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.32883
Value Function Update Magnitude: 0.36631

Collected Steps per Second: 21,654.24705
Overall Steps per Second: 10,525.48800

Timestep Collection Time: 2.31105
Timestep Consumption Time: 2.44351
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.75455

Cumulative Model Updates: 131,026
Cumulative Timesteps: 1,093,550,170

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1093550170...
Checkpoint 1093550170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,309.68512
Policy Entropy: 1.68902
Value Function Loss: 0.06164

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.32802
Value Function Update Magnitude: 0.38314

Collected Steps per Second: 21,288.09262
Overall Steps per Second: 10,278.53443

Timestep Collection Time: 2.34939
Timestep Consumption Time: 2.51648
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.86587

Cumulative Model Updates: 131,032
Cumulative Timesteps: 1,093,600,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,166.06085
Policy Entropy: 1.69493
Value Function Loss: 0.06328

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.32814
Value Function Update Magnitude: 0.37813

Collected Steps per Second: 21,853.99740
Overall Steps per Second: 10,383.14744

Timestep Collection Time: 2.28873
Timestep Consumption Time: 2.52849
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.81723

Cumulative Model Updates: 131,038
Cumulative Timesteps: 1,093,650,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1093650202...
Checkpoint 1093650202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,445.11297
Policy Entropy: 1.69766
Value Function Loss: 0.06197

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.32123
Value Function Update Magnitude: 0.38964

Collected Steps per Second: 22,016.08014
Overall Steps per Second: 10,571.81927

Timestep Collection Time: 2.27125
Timestep Consumption Time: 2.45868
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.72993

Cumulative Model Updates: 131,044
Cumulative Timesteps: 1,093,700,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,670.33618
Policy Entropy: 1.70828
Value Function Loss: 0.06279

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.29710
Value Function Update Magnitude: 0.39589

Collected Steps per Second: 22,217.37208
Overall Steps per Second: 10,428.29736

Timestep Collection Time: 2.25148
Timestep Consumption Time: 2.54527
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.79676

Cumulative Model Updates: 131,050
Cumulative Timesteps: 1,093,750,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1093750228...
Checkpoint 1093750228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,230.04066
Policy Entropy: 1.69903
Value Function Loss: 0.05606

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.29242
Value Function Update Magnitude: 0.36319

Collected Steps per Second: 21,699.83109
Overall Steps per Second: 10,374.20511

Timestep Collection Time: 2.30527
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.82196

Cumulative Model Updates: 131,056
Cumulative Timesteps: 1,093,800,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,209.90004
Policy Entropy: 1.68241
Value Function Loss: 0.06029

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.30984
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 22,018.58354
Overall Steps per Second: 10,485.16444

Timestep Collection Time: 2.27135
Timestep Consumption Time: 2.49843
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.76979

Cumulative Model Updates: 131,062
Cumulative Timesteps: 1,093,850,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1093850264...
Checkpoint 1093850264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,985.83089
Policy Entropy: 1.68121
Value Function Loss: 0.05602

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.31482
Value Function Update Magnitude: 0.34392

Collected Steps per Second: 21,797.30882
Overall Steps per Second: 10,591.84821

Timestep Collection Time: 2.29478
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.72250

Cumulative Model Updates: 131,068
Cumulative Timesteps: 1,093,900,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,934.97522
Policy Entropy: 1.68220
Value Function Loss: 0.05567

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.31098
Value Function Update Magnitude: 0.34236

Collected Steps per Second: 22,176.95842
Overall Steps per Second: 10,490.04012

Timestep Collection Time: 2.25522
Timestep Consumption Time: 2.51254
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.76776

Cumulative Model Updates: 131,074
Cumulative Timesteps: 1,093,950,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1093950298...
Checkpoint 1093950298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,185.71254
Policy Entropy: 1.69470
Value Function Loss: 0.05678

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.31620
Value Function Update Magnitude: 0.33911

Collected Steps per Second: 21,830.99105
Overall Steps per Second: 10,475.35350

Timestep Collection Time: 2.29215
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.77693

Cumulative Model Updates: 131,080
Cumulative Timesteps: 1,094,000,338

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,323.45703
Policy Entropy: 1.69583
Value Function Loss: 0.05892

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.32246
Value Function Update Magnitude: 0.34552

Collected Steps per Second: 21,544.70457
Overall Steps per Second: 10,506.48311

Timestep Collection Time: 2.32141
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.76030

Cumulative Model Updates: 131,086
Cumulative Timesteps: 1,094,050,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1094050352...
Checkpoint 1094050352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,255.83881
Policy Entropy: 1.69917
Value Function Loss: 0.05860

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.32296
Value Function Update Magnitude: 0.35855

Collected Steps per Second: 21,299.39322
Overall Steps per Second: 10,287.96517

Timestep Collection Time: 2.34964
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.86452

Cumulative Model Updates: 131,092
Cumulative Timesteps: 1,094,100,398

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,228.18501
Policy Entropy: 1.70008
Value Function Loss: 0.05622

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.31996
Value Function Update Magnitude: 0.36048

Collected Steps per Second: 21,263.56177
Overall Steps per Second: 10,293.18280

Timestep Collection Time: 2.35163
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.85797

Cumulative Model Updates: 131,098
Cumulative Timesteps: 1,094,150,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1094150402...
Checkpoint 1094150402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,558.59050
Policy Entropy: 1.70011
Value Function Loss: 0.05914

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.32119
Value Function Update Magnitude: 0.36544

Collected Steps per Second: 21,329.12238
Overall Steps per Second: 10,272.93547

Timestep Collection Time: 2.34487
Timestep Consumption Time: 2.52365
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.86852

Cumulative Model Updates: 131,104
Cumulative Timesteps: 1,094,200,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,464.84329
Policy Entropy: 1.69686
Value Function Loss: 0.06039

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.32575
Value Function Update Magnitude: 0.36976

Collected Steps per Second: 22,088.48151
Overall Steps per Second: 10,459.49882

Timestep Collection Time: 2.26516
Timestep Consumption Time: 2.51843
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.78359

Cumulative Model Updates: 131,110
Cumulative Timesteps: 1,094,250,450

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1094250450...
Checkpoint 1094250450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,060.36910
Policy Entropy: 1.68256
Value Function Loss: 0.06025

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.32960
Value Function Update Magnitude: 0.37612

Collected Steps per Second: 21,288.98640
Overall Steps per Second: 10,617.07973

Timestep Collection Time: 2.35061
Timestep Consumption Time: 2.36274
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.71335

Cumulative Model Updates: 131,116
Cumulative Timesteps: 1,094,300,492

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,542.78210
Policy Entropy: 1.67080
Value Function Loss: 0.06214

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.33420
Value Function Update Magnitude: 0.38561

Collected Steps per Second: 21,447.03363
Overall Steps per Second: 10,468.53158

Timestep Collection Time: 2.33179
Timestep Consumption Time: 2.44538
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.77717

Cumulative Model Updates: 131,122
Cumulative Timesteps: 1,094,350,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1094350502...
Checkpoint 1094350502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,677.85800
Policy Entropy: 1.68707
Value Function Loss: 0.06363

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.32800
Value Function Update Magnitude: 0.38650

Collected Steps per Second: 21,155.29966
Overall Steps per Second: 10,582.48147

Timestep Collection Time: 2.36404
Timestep Consumption Time: 2.36188
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.72592

Cumulative Model Updates: 131,128
Cumulative Timesteps: 1,094,400,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,483.81572
Policy Entropy: 1.68605
Value Function Loss: 0.06237

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.32527
Value Function Update Magnitude: 0.37563

Collected Steps per Second: 21,417.88121
Overall Steps per Second: 10,491.72332

Timestep Collection Time: 2.33478
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.76623

Cumulative Model Updates: 131,134
Cumulative Timesteps: 1,094,450,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1094450520...
Checkpoint 1094450520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,174.41367
Policy Entropy: 1.70937
Value Function Loss: 0.05760

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.32126
Value Function Update Magnitude: 0.37979

Collected Steps per Second: 21,291.80534
Overall Steps per Second: 10,619.41655

Timestep Collection Time: 2.34832
Timestep Consumption Time: 2.36004
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.70836

Cumulative Model Updates: 131,140
Cumulative Timesteps: 1,094,500,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,496.49486
Policy Entropy: 1.68793
Value Function Loss: 0.06007

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.32569
Value Function Update Magnitude: 0.36800

Collected Steps per Second: 21,126.33067
Overall Steps per Second: 10,438.74020

Timestep Collection Time: 2.36709
Timestep Consumption Time: 2.42352
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.79062

Cumulative Model Updates: 131,146
Cumulative Timesteps: 1,094,550,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1094550528...
Checkpoint 1094550528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,586.96954
Policy Entropy: 1.69885
Value Function Loss: 0.06064

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.32871
Value Function Update Magnitude: 0.34573

Collected Steps per Second: 21,414.96936
Overall Steps per Second: 10,442.67472

Timestep Collection Time: 2.33594
Timestep Consumption Time: 2.45441
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.79034

Cumulative Model Updates: 131,152
Cumulative Timesteps: 1,094,600,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,785.98052
Policy Entropy: 1.68872
Value Function Loss: 0.06674

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.33161
Value Function Update Magnitude: 0.34548

Collected Steps per Second: 21,761.21479
Overall Steps per Second: 10,624.01563

Timestep Collection Time: 2.29840
Timestep Consumption Time: 2.40942
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.70782

Cumulative Model Updates: 131,158
Cumulative Timesteps: 1,094,650,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1094650568...
Checkpoint 1094650568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,944.96448
Policy Entropy: 1.67751
Value Function Loss: 0.06341

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.33175
Value Function Update Magnitude: 0.35648

Collected Steps per Second: 21,351.56007
Overall Steps per Second: 10,386.34939

Timestep Collection Time: 2.34194
Timestep Consumption Time: 2.47246
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.81440

Cumulative Model Updates: 131,164
Cumulative Timesteps: 1,094,700,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,753.63578
Policy Entropy: 1.67991
Value Function Loss: 0.06438

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.33291
Value Function Update Magnitude: 0.35110

Collected Steps per Second: 21,902.97426
Overall Steps per Second: 10,539.14608

Timestep Collection Time: 2.28362
Timestep Consumption Time: 2.46231
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.74593

Cumulative Model Updates: 131,170
Cumulative Timesteps: 1,094,750,590

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1094750590...
Checkpoint 1094750590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,251.79493
Policy Entropy: 1.66657
Value Function Loss: 0.05754

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07944
Policy Update Magnitude: 0.32296
Value Function Update Magnitude: 0.35421

Collected Steps per Second: 21,477.90774
Overall Steps per Second: 10,486.23655

Timestep Collection Time: 2.32946
Timestep Consumption Time: 2.44174
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.77121

Cumulative Model Updates: 131,176
Cumulative Timesteps: 1,094,800,622

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,781.15737
Policy Entropy: 1.68505
Value Function Loss: 0.05514

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.31451
Value Function Update Magnitude: 0.34007

Collected Steps per Second: 22,175.62171
Overall Steps per Second: 10,407.35455

Timestep Collection Time: 2.25653
Timestep Consumption Time: 2.55161
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.80814

Cumulative Model Updates: 131,182
Cumulative Timesteps: 1,094,850,662

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1094850662...
Checkpoint 1094850662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,192.96845
Policy Entropy: 1.67537
Value Function Loss: 0.05326

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.31141
Value Function Update Magnitude: 0.33332

Collected Steps per Second: 22,022.70129
Overall Steps per Second: 10,619.19903

Timestep Collection Time: 2.27147
Timestep Consumption Time: 2.43924
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.71071

Cumulative Model Updates: 131,188
Cumulative Timesteps: 1,094,900,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,275.87049
Policy Entropy: 1.68095
Value Function Loss: 0.05933

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.32089
Value Function Update Magnitude: 0.34094

Collected Steps per Second: 21,984.11351
Overall Steps per Second: 10,458.77572

Timestep Collection Time: 2.27446
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.78087

Cumulative Model Updates: 131,194
Cumulative Timesteps: 1,094,950,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1094950688...
Checkpoint 1094950688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,276.76268
Policy Entropy: 1.67873
Value Function Loss: 0.05993

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.32189
Value Function Update Magnitude: 0.37293

Collected Steps per Second: 22,076.65141
Overall Steps per Second: 10,625.18337

Timestep Collection Time: 2.26529
Timestep Consumption Time: 2.44145
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.70674

Cumulative Model Updates: 131,200
Cumulative Timesteps: 1,095,000,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,676.81610
Policy Entropy: 1.68086
Value Function Loss: 0.06274

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.32812
Value Function Update Magnitude: 0.36084

Collected Steps per Second: 22,141.77446
Overall Steps per Second: 10,497.21435

Timestep Collection Time: 2.25908
Timestep Consumption Time: 2.50600
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.76507

Cumulative Model Updates: 131,206
Cumulative Timesteps: 1,095,050,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1095050718...
Checkpoint 1095050718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,111.78495
Policy Entropy: 1.68409
Value Function Loss: 0.06100

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.32106
Value Function Update Magnitude: 0.33011

Collected Steps per Second: 21,852.20621
Overall Steps per Second: 10,664.91023

Timestep Collection Time: 2.28929
Timestep Consumption Time: 2.40142
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.69071

Cumulative Model Updates: 131,212
Cumulative Timesteps: 1,095,100,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,470.97348
Policy Entropy: 1.67157
Value Function Loss: 0.06092

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.32610
Value Function Update Magnitude: 0.33458

Collected Steps per Second: 21,743.88287
Overall Steps per Second: 10,401.85738

Timestep Collection Time: 2.30134
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.81068

Cumulative Model Updates: 131,218
Cumulative Timesteps: 1,095,150,784

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1095150784...
Checkpoint 1095150784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,579.61723
Policy Entropy: 1.66829
Value Function Loss: 0.05841

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08259
Policy Update Magnitude: 0.32649
Value Function Update Magnitude: 0.36287

Collected Steps per Second: 21,459.56081
Overall Steps per Second: 10,332.82310

Timestep Collection Time: 2.33043
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.83992

Cumulative Model Updates: 131,224
Cumulative Timesteps: 1,095,200,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,371.23487
Policy Entropy: 1.66941
Value Function Loss: 0.05687

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.31876
Value Function Update Magnitude: 0.37177

Collected Steps per Second: 20,556.88560
Overall Steps per Second: 10,279.48155

Timestep Collection Time: 2.43393
Timestep Consumption Time: 2.43344
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.86737

Cumulative Model Updates: 131,230
Cumulative Timesteps: 1,095,250,828

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1095250828...
Checkpoint 1095250828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,857.54773
Policy Entropy: 1.67226
Value Function Loss: 0.05797

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.30357
Value Function Update Magnitude: 0.37616

Collected Steps per Second: 21,399.56510
Overall Steps per Second: 10,317.54028

Timestep Collection Time: 2.33715
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.84747

Cumulative Model Updates: 131,236
Cumulative Timesteps: 1,095,300,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,407.83229
Policy Entropy: 1.68033
Value Function Loss: 0.05929

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.30458
Value Function Update Magnitude: 0.37744

Collected Steps per Second: 21,636.82798
Overall Steps per Second: 10,401.63990

Timestep Collection Time: 2.31226
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.80982

Cumulative Model Updates: 131,242
Cumulative Timesteps: 1,095,350,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1095350872...
Checkpoint 1095350872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,947.91462
Policy Entropy: 1.67505
Value Function Loss: 0.06280

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.32345
Value Function Update Magnitude: 0.39725

Collected Steps per Second: 21,890.43718
Overall Steps per Second: 10,561.08002

Timestep Collection Time: 2.28511
Timestep Consumption Time: 2.45134
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.73645

Cumulative Model Updates: 131,248
Cumulative Timesteps: 1,095,400,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,561.50454
Policy Entropy: 1.67395
Value Function Loss: 0.06030

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.32293
Value Function Update Magnitude: 0.40382

Collected Steps per Second: 22,053.22527
Overall Steps per Second: 10,558.91932

Timestep Collection Time: 2.26869
Timestep Consumption Time: 2.46967
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.73836

Cumulative Model Updates: 131,254
Cumulative Timesteps: 1,095,450,926

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1095450926...
Checkpoint 1095450926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,184.46812
Policy Entropy: 1.67918
Value Function Loss: 0.06331

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.32989
Value Function Update Magnitude: 0.39828

Collected Steps per Second: 21,909.20479
Overall Steps per Second: 10,679.38208

Timestep Collection Time: 2.28224
Timestep Consumption Time: 2.39987
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.68211

Cumulative Model Updates: 131,260
Cumulative Timesteps: 1,095,500,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,616.25629
Policy Entropy: 1.68493
Value Function Loss: 0.06493

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.33114
Value Function Update Magnitude: 0.40643

Collected Steps per Second: 22,325.42717
Overall Steps per Second: 10,530.24469

Timestep Collection Time: 2.24130
Timestep Consumption Time: 2.51054
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.75184

Cumulative Model Updates: 131,266
Cumulative Timesteps: 1,095,550,966

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1095550966...
Checkpoint 1095550966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,517.27810
Policy Entropy: 1.69874
Value Function Loss: 0.06892

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.33453
Value Function Update Magnitude: 0.40824

Collected Steps per Second: 22,168.98969
Overall Steps per Second: 10,497.88345

Timestep Collection Time: 2.25576
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.76363

Cumulative Model Updates: 131,272
Cumulative Timesteps: 1,095,600,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,676.83640
Policy Entropy: 1.70549
Value Function Loss: 0.06643

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08937
Policy Update Magnitude: 0.33084
Value Function Update Magnitude: 0.39342

Collected Steps per Second: 21,995.32348
Overall Steps per Second: 10,455.39318

Timestep Collection Time: 2.27421
Timestep Consumption Time: 2.51011
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.78433

Cumulative Model Updates: 131,278
Cumulative Timesteps: 1,095,650,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1095650996...
Checkpoint 1095650996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,056.34109
Policy Entropy: 1.71103
Value Function Loss: 0.06963

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.32914
Value Function Update Magnitude: 0.34824

Collected Steps per Second: 21,740.83539
Overall Steps per Second: 10,577.58707

Timestep Collection Time: 2.30148
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.73038

Cumulative Model Updates: 131,284
Cumulative Timesteps: 1,095,701,032

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,735.82863
Policy Entropy: 1.71412
Value Function Loss: 0.06744

Mean KL Divergence: 0.04518
SB3 Clip Fraction: 0.09180
Policy Update Magnitude: 0.32377
Value Function Update Magnitude: 0.36292

Collected Steps per Second: 21,535.95191
Overall Steps per Second: 10,494.93595

Timestep Collection Time: 2.32226
Timestep Consumption Time: 2.44309
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.76535

Cumulative Model Updates: 131,290
Cumulative Timesteps: 1,095,751,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1095751044...
Checkpoint 1095751044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,169.99626
Policy Entropy: 1.68756
Value Function Loss: 0.06316

Mean KL Divergence: 0.07172
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.30205
Value Function Update Magnitude: 0.37970

Collected Steps per Second: 21,698.84464
Overall Steps per Second: 10,585.42899

Timestep Collection Time: 2.30538
Timestep Consumption Time: 2.42037
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.72574

Cumulative Model Updates: 131,296
Cumulative Timesteps: 1,095,801,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,291.51438
Policy Entropy: 1.67424
Value Function Loss: 0.06364

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.29987
Value Function Update Magnitude: 0.37962

Collected Steps per Second: 21,662.93018
Overall Steps per Second: 10,518.94212

Timestep Collection Time: 2.30948
Timestep Consumption Time: 2.44671
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.75618

Cumulative Model Updates: 131,302
Cumulative Timesteps: 1,095,851,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1095851098...
Checkpoint 1095851098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,736.20698
Policy Entropy: 1.65933
Value Function Loss: 0.05958

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.32568
Value Function Update Magnitude: 0.37651

Collected Steps per Second: 21,810.06725
Overall Steps per Second: 10,572.63239

Timestep Collection Time: 2.29307
Timestep Consumption Time: 2.43726
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.73033

Cumulative Model Updates: 131,308
Cumulative Timesteps: 1,095,901,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,305.06293
Policy Entropy: 1.68039
Value Function Loss: 0.06039

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.32111
Value Function Update Magnitude: 0.36798

Collected Steps per Second: 21,932.55382
Overall Steps per Second: 10,574.89573

Timestep Collection Time: 2.28035
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.72950

Cumulative Model Updates: 131,314
Cumulative Timesteps: 1,095,951,124

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1095951124...
Checkpoint 1095951124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,636.98483
Policy Entropy: 1.69277
Value Function Loss: 0.05883

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.30932
Value Function Update Magnitude: 0.34403

Collected Steps per Second: 21,901.64523
Overall Steps per Second: 10,569.80844

Timestep Collection Time: 2.28494
Timestep Consumption Time: 2.44968
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.73462

Cumulative Model Updates: 131,320
Cumulative Timesteps: 1,096,001,168

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,011.30559
Policy Entropy: 1.71217
Value Function Loss: 0.06710

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.30767
Value Function Update Magnitude: 0.32605

Collected Steps per Second: 22,236.33192
Overall Steps per Second: 10,489.63486

Timestep Collection Time: 2.24920
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.76794

Cumulative Model Updates: 131,326
Cumulative Timesteps: 1,096,051,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1096051182...
Checkpoint 1096051182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,474.84229
Policy Entropy: 1.71902
Value Function Loss: 0.06903

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.32306
Value Function Update Magnitude: 0.34604

Collected Steps per Second: 21,966.25332
Overall Steps per Second: 10,601.37053

Timestep Collection Time: 2.27667
Timestep Consumption Time: 2.44064
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.71731

Cumulative Model Updates: 131,332
Cumulative Timesteps: 1,096,101,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,288.40561
Policy Entropy: 1.70161
Value Function Loss: 0.06371

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.30586
Value Function Update Magnitude: 0.34177

Collected Steps per Second: 22,097.85197
Overall Steps per Second: 10,466.08044

Timestep Collection Time: 2.26321
Timestep Consumption Time: 2.51528
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.77848

Cumulative Model Updates: 131,338
Cumulative Timesteps: 1,096,151,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1096151204...
Checkpoint 1096151204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,711.53195
Policy Entropy: 1.68677
Value Function Loss: 0.06100

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.31470
Value Function Update Magnitude: 0.32543

Collected Steps per Second: 22,046.90230
Overall Steps per Second: 10,622.65513

Timestep Collection Time: 2.26962
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.71050

Cumulative Model Updates: 131,344
Cumulative Timesteps: 1,096,201,242

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,121.09454
Policy Entropy: 1.69138
Value Function Loss: 0.06697

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.32514
Value Function Update Magnitude: 0.34746

Collected Steps per Second: 21,124.02235
Overall Steps per Second: 10,439.98633

Timestep Collection Time: 2.36764
Timestep Consumption Time: 2.42298
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.79062

Cumulative Model Updates: 131,350
Cumulative Timesteps: 1,096,251,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1096251256...
Checkpoint 1096251256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,716.95888
Policy Entropy: 1.69208
Value Function Loss: 0.06473

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.32879
Value Function Update Magnitude: 0.37163

Collected Steps per Second: 21,319.67828
Overall Steps per Second: 10,299.48963

Timestep Collection Time: 2.34572
Timestep Consumption Time: 2.50986
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.85558

Cumulative Model Updates: 131,356
Cumulative Timesteps: 1,096,301,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,240.01056
Policy Entropy: 1.69149
Value Function Loss: 0.06325

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.32080
Value Function Update Magnitude: 0.36782

Collected Steps per Second: 21,752.97035
Overall Steps per Second: 10,393.30631

Timestep Collection Time: 2.29927
Timestep Consumption Time: 2.51306
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.81233

Cumulative Model Updates: 131,362
Cumulative Timesteps: 1,096,351,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1096351282...
Checkpoint 1096351282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,523.57871
Policy Entropy: 1.68847
Value Function Loss: 0.05740

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.31567
Value Function Update Magnitude: 0.35785

Collected Steps per Second: 21,446.80128
Overall Steps per Second: 10,351.78686

Timestep Collection Time: 2.33154
Timestep Consumption Time: 2.49893
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.83047

Cumulative Model Updates: 131,368
Cumulative Timesteps: 1,096,401,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,956.71754
Policy Entropy: 1.68866
Value Function Loss: 0.05987

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.31957
Value Function Update Magnitude: 0.35594

Collected Steps per Second: 22,034.63080
Overall Steps per Second: 10,424.53253

Timestep Collection Time: 2.26925
Timestep Consumption Time: 2.52732
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.79657

Cumulative Model Updates: 131,374
Cumulative Timesteps: 1,096,451,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1096451288...
Checkpoint 1096451288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,002.13094
Policy Entropy: 1.68764
Value Function Loss: 0.05550

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.31933
Value Function Update Magnitude: 0.32541

Collected Steps per Second: 22,009.93474
Overall Steps per Second: 10,480.98260

Timestep Collection Time: 2.27261
Timestep Consumption Time: 2.49984
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.77245

Cumulative Model Updates: 131,380
Cumulative Timesteps: 1,096,501,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,153.84239
Policy Entropy: 1.69219
Value Function Loss: 0.06023

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.29487
Value Function Update Magnitude: 0.32311

Collected Steps per Second: 22,109.00260
Overall Steps per Second: 10,460.86401

Timestep Collection Time: 2.26243
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.78163

Cumulative Model Updates: 131,386
Cumulative Timesteps: 1,096,551,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1096551328...
Checkpoint 1096551328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,703.31261
Policy Entropy: 1.71067
Value Function Loss: 0.05496

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.29291
Value Function Update Magnitude: 0.32565

Collected Steps per Second: 22,197.04900
Overall Steps per Second: 10,696.96249

Timestep Collection Time: 2.25345
Timestep Consumption Time: 2.42264
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.67609

Cumulative Model Updates: 131,392
Cumulative Timesteps: 1,096,601,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,614.86437
Policy Entropy: 1.71269
Value Function Loss: 0.05873

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.31247
Value Function Update Magnitude: 0.33949

Collected Steps per Second: 22,172.33449
Overall Steps per Second: 10,497.99664

Timestep Collection Time: 2.25515
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.76300

Cumulative Model Updates: 131,398
Cumulative Timesteps: 1,096,651,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1096651350...
Checkpoint 1096651350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,635.76636
Policy Entropy: 1.67584
Value Function Loss: 0.05657

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.31186
Value Function Update Magnitude: 0.34122

Collected Steps per Second: 21,928.90231
Overall Steps per Second: 10,510.61482

Timestep Collection Time: 2.28037
Timestep Consumption Time: 2.47730
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.75767

Cumulative Model Updates: 131,404
Cumulative Timesteps: 1,096,701,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,657.34277
Policy Entropy: 1.64776
Value Function Loss: 0.05649

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.31763
Value Function Update Magnitude: 0.35543

Collected Steps per Second: 22,161.30745
Overall Steps per Second: 10,489.37667

Timestep Collection Time: 2.25700
Timestep Consumption Time: 2.51145
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.76844

Cumulative Model Updates: 131,410
Cumulative Timesteps: 1,096,751,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1096751374...
Checkpoint 1096751374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,202.83942
Policy Entropy: 1.65349
Value Function Loss: 0.06318

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08439
Policy Update Magnitude: 0.32213
Value Function Update Magnitude: 0.37511

Collected Steps per Second: 21,484.21823
Overall Steps per Second: 10,412.38506

Timestep Collection Time: 2.32850
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.80447

Cumulative Model Updates: 131,416
Cumulative Timesteps: 1,096,801,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,055.28908
Policy Entropy: 1.68451
Value Function Loss: 0.06741

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.32263
Value Function Update Magnitude: 0.38398

Collected Steps per Second: 20,950.67214
Overall Steps per Second: 10,407.57084

Timestep Collection Time: 2.38751
Timestep Consumption Time: 2.41860
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.80612

Cumulative Model Updates: 131,422
Cumulative Timesteps: 1,096,851,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1096851420...
Checkpoint 1096851420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,243.85019
Policy Entropy: 1.69376
Value Function Loss: 0.06698

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.32247
Value Function Update Magnitude: 0.37937

Collected Steps per Second: 21,133.97162
Overall Steps per Second: 10,498.49120

Timestep Collection Time: 2.36794
Timestep Consumption Time: 2.39884
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.76678

Cumulative Model Updates: 131,428
Cumulative Timesteps: 1,096,901,464

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,463.33229
Policy Entropy: 1.68244
Value Function Loss: 0.06475

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.32321
Value Function Update Magnitude: 0.37272

Collected Steps per Second: 20,788.70197
Overall Steps per Second: 10,509.84532

Timestep Collection Time: 2.40717
Timestep Consumption Time: 2.35427
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.76144

Cumulative Model Updates: 131,434
Cumulative Timesteps: 1,096,951,506

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1096951506...
Checkpoint 1096951506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,541.74717
Policy Entropy: 1.67423
Value Function Loss: 0.05962

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.32235
Value Function Update Magnitude: 0.37103

Collected Steps per Second: 20,895.30592
Overall Steps per Second: 10,528.53201

Timestep Collection Time: 2.39393
Timestep Consumption Time: 2.35715
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.75109

Cumulative Model Updates: 131,440
Cumulative Timesteps: 1,097,001,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,954.04551
Policy Entropy: 1.68554
Value Function Loss: 0.06455

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.32437
Value Function Update Magnitude: 0.35000

Collected Steps per Second: 21,521.05791
Overall Steps per Second: 10,508.86864

Timestep Collection Time: 2.32572
Timestep Consumption Time: 2.43711
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.76283

Cumulative Model Updates: 131,446
Cumulative Timesteps: 1,097,051,580

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1097051580...
Checkpoint 1097051580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,104.54581
Policy Entropy: 1.68906
Value Function Loss: 0.06684

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.32688
Value Function Update Magnitude: 0.30651

Collected Steps per Second: 21,271.39960
Overall Steps per Second: 10,567.61830

Timestep Collection Time: 2.35076
Timestep Consumption Time: 2.38105
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.73181

Cumulative Model Updates: 131,452
Cumulative Timesteps: 1,097,101,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,225.92018
Policy Entropy: 1.68430
Value Function Loss: 0.07197

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.33314
Value Function Update Magnitude: 0.30270

Collected Steps per Second: 21,324.82353
Overall Steps per Second: 10,503.67731

Timestep Collection Time: 2.34534
Timestep Consumption Time: 2.41623
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.76157

Cumulative Model Updates: 131,458
Cumulative Timesteps: 1,097,151,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1097151598...
Checkpoint 1097151598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,775.77693
Policy Entropy: 1.66590
Value Function Loss: 0.07235

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.33842
Value Function Update Magnitude: 0.34557

Collected Steps per Second: 21,521.46925
Overall Steps per Second: 10,570.45166

Timestep Collection Time: 2.32400
Timestep Consumption Time: 2.40768
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.73168

Cumulative Model Updates: 131,464
Cumulative Timesteps: 1,097,201,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,194.73182
Policy Entropy: 1.64283
Value Function Loss: 0.06773

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.33778
Value Function Update Magnitude: 0.38949

Collected Steps per Second: 21,217.87713
Overall Steps per Second: 10,472.38089

Timestep Collection Time: 2.35726
Timestep Consumption Time: 2.41873
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.77599

Cumulative Model Updates: 131,470
Cumulative Timesteps: 1,097,251,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1097251630...
Checkpoint 1097251630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,555.70066
Policy Entropy: 1.64666
Value Function Loss: 0.06280

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.33437
Value Function Update Magnitude: 0.36996

Collected Steps per Second: 21,512.81750
Overall Steps per Second: 10,443.30717

Timestep Collection Time: 2.32447
Timestep Consumption Time: 2.46386
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.78833

Cumulative Model Updates: 131,476
Cumulative Timesteps: 1,097,301,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,768.66946
Policy Entropy: 1.65817
Value Function Loss: 0.06537

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.33417
Value Function Update Magnitude: 0.35604

Collected Steps per Second: 21,652.56489
Overall Steps per Second: 10,623.49655

Timestep Collection Time: 2.31049
Timestep Consumption Time: 2.39870
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.70918

Cumulative Model Updates: 131,482
Cumulative Timesteps: 1,097,351,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1097351664...
Checkpoint 1097351664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,639.93374
Policy Entropy: 1.67298
Value Function Loss: 0.06592

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.33564
Value Function Update Magnitude: 0.38360

Collected Steps per Second: 21,340.41507
Overall Steps per Second: 10,258.80537

Timestep Collection Time: 2.34428
Timestep Consumption Time: 2.53231
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.87659

Cumulative Model Updates: 131,488
Cumulative Timesteps: 1,097,401,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,154.26726
Policy Entropy: 1.66587
Value Function Loss: 0.06532

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.32897
Value Function Update Magnitude: 0.37408

Collected Steps per Second: 21,500.33589
Overall Steps per Second: 10,479.51838

Timestep Collection Time: 2.32741
Timestep Consumption Time: 2.44762
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.77503

Cumulative Model Updates: 131,494
Cumulative Timesteps: 1,097,451,732

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1097451732...
Checkpoint 1097451732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,456.04081
Policy Entropy: 1.65118
Value Function Loss: 0.05983

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.31968
Value Function Update Magnitude: 0.35674

Collected Steps per Second: 21,468.65449
Overall Steps per Second: 10,361.23762

Timestep Collection Time: 2.32916
Timestep Consumption Time: 2.49690
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.82606

Cumulative Model Updates: 131,500
Cumulative Timesteps: 1,097,501,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,751.64177
Policy Entropy: 1.67090
Value Function Loss: 0.06705

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.30892
Value Function Update Magnitude: 0.35192

Collected Steps per Second: 22,105.76480
Overall Steps per Second: 10,481.59094

Timestep Collection Time: 2.26267
Timestep Consumption Time: 2.50932
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.77199

Cumulative Model Updates: 131,506
Cumulative Timesteps: 1,097,551,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1097551754...
Checkpoint 1097551754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,672.61281
Policy Entropy: 1.68282
Value Function Loss: 0.06700

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.28954
Value Function Update Magnitude: 0.37925

Collected Steps per Second: 22,213.88168
Overall Steps per Second: 10,517.34985

Timestep Collection Time: 2.25138
Timestep Consumption Time: 2.50381
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.75519

Cumulative Model Updates: 131,512
Cumulative Timesteps: 1,097,601,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,168.26564
Policy Entropy: 1.69755
Value Function Loss: 0.07060

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.30443
Value Function Update Magnitude: 0.39949

Collected Steps per Second: 21,894.74804
Overall Steps per Second: 10,404.43217

Timestep Collection Time: 2.28548
Timestep Consumption Time: 2.52401
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.80949

Cumulative Model Updates: 131,518
Cumulative Timesteps: 1,097,651,806

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1097651806...
Checkpoint 1097651806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,359.33786
Policy Entropy: 1.69405
Value Function Loss: 0.06891

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.10314
Policy Update Magnitude: 0.31053
Value Function Update Magnitude: 0.42422

Collected Steps per Second: 21,814.89340
Overall Steps per Second: 10,572.79332

Timestep Collection Time: 2.29256
Timestep Consumption Time: 2.43769
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.73025

Cumulative Model Updates: 131,524
Cumulative Timesteps: 1,097,701,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,394.07229
Policy Entropy: 1.68783
Value Function Loss: 0.06914

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.29970
Value Function Update Magnitude: 0.40950

Collected Steps per Second: 21,794.18514
Overall Steps per Second: 10,455.26148

Timestep Collection Time: 2.29483
Timestep Consumption Time: 2.48879
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.78362

Cumulative Model Updates: 131,530
Cumulative Timesteps: 1,097,751,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1097751832...
Checkpoint 1097751832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,499.41152
Policy Entropy: 1.68519
Value Function Loss: 0.06456

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.29956
Value Function Update Magnitude: 0.39342

Collected Steps per Second: 21,759.05784
Overall Steps per Second: 10,579.01094

Timestep Collection Time: 2.29900
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.72861

Cumulative Model Updates: 131,536
Cumulative Timesteps: 1,097,801,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,918.66447
Policy Entropy: 1.65680
Value Function Loss: 0.06171

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.28483
Value Function Update Magnitude: 0.36337

Collected Steps per Second: 22,105.82121
Overall Steps per Second: 10,551.29593

Timestep Collection Time: 2.26275
Timestep Consumption Time: 2.47790
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.74065

Cumulative Model Updates: 131,542
Cumulative Timesteps: 1,097,851,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1097851876...
Checkpoint 1097851876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,296.16912
Policy Entropy: 1.65705
Value Function Loss: 0.06017

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.29365
Value Function Update Magnitude: 0.33073

Collected Steps per Second: 21,590.94766
Overall Steps per Second: 10,565.88754

Timestep Collection Time: 2.31597
Timestep Consumption Time: 2.41662
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.73259

Cumulative Model Updates: 131,548
Cumulative Timesteps: 1,097,901,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,828.71140
Policy Entropy: 1.65857
Value Function Loss: 0.06052

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.31955
Value Function Update Magnitude: 0.33596

Collected Steps per Second: 20,856.51163
Overall Steps per Second: 10,514.12623

Timestep Collection Time: 2.39915
Timestep Consumption Time: 2.35997
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.75912

Cumulative Model Updates: 131,554
Cumulative Timesteps: 1,097,951,918

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1097951918...
Checkpoint 1097951918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,109.22735
Policy Entropy: 1.67383
Value Function Loss: 0.06935

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.33544
Value Function Update Magnitude: 0.35535

Collected Steps per Second: 20,603.43200
Overall Steps per Second: 10,303.90059

Timestep Collection Time: 2.42765
Timestep Consumption Time: 2.42662
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.85428

Cumulative Model Updates: 131,560
Cumulative Timesteps: 1,098,001,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,762.39928
Policy Entropy: 1.65839
Value Function Loss: 0.06222

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.33745
Value Function Update Magnitude: 0.38483

Collected Steps per Second: 21,133.56271
Overall Steps per Second: 10,431.31503

Timestep Collection Time: 2.36742
Timestep Consumption Time: 2.42891
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.79633

Cumulative Model Updates: 131,566
Cumulative Timesteps: 1,098,051,968

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1098051968...
Checkpoint 1098051968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,945.55832
Policy Entropy: 1.64395
Value Function Loss: 0.06101

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.32649
Value Function Update Magnitude: 0.36029

Collected Steps per Second: 20,912.38606
Overall Steps per Second: 10,515.30570

Timestep Collection Time: 2.39131
Timestep Consumption Time: 2.36442
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.75573

Cumulative Model Updates: 131,572
Cumulative Timesteps: 1,098,101,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,722.71096
Policy Entropy: 1.64814
Value Function Loss: 0.05417

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.32102
Value Function Update Magnitude: 0.34192

Collected Steps per Second: 21,582.27234
Overall Steps per Second: 10,501.31589

Timestep Collection Time: 2.31820
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.76436

Cumulative Model Updates: 131,578
Cumulative Timesteps: 1,098,152,008

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1098152008...
Checkpoint 1098152008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,879.97399
Policy Entropy: 1.66151
Value Function Loss: 0.06286

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.32681
Value Function Update Magnitude: 0.34243

Collected Steps per Second: 21,367.04133
Overall Steps per Second: 10,612.45183

Timestep Collection Time: 2.34136
Timestep Consumption Time: 2.37272
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.71409

Cumulative Model Updates: 131,584
Cumulative Timesteps: 1,098,202,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,311.66798
Policy Entropy: 1.67119
Value Function Loss: 0.06422

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.32993
Value Function Update Magnitude: 0.36837

Collected Steps per Second: 21,634.24702
Overall Steps per Second: 10,449.28826

Timestep Collection Time: 2.31143
Timestep Consumption Time: 2.47416
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.78559

Cumulative Model Updates: 131,590
Cumulative Timesteps: 1,098,252,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1098252042...
Checkpoint 1098252042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,657.60394
Policy Entropy: 1.66672
Value Function Loss: 0.05932

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.31798
Value Function Update Magnitude: 0.37788

Collected Steps per Second: 21,638.09294
Overall Steps per Second: 10,606.34876

Timestep Collection Time: 2.31111
Timestep Consumption Time: 2.40380
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.71491

Cumulative Model Updates: 131,596
Cumulative Timesteps: 1,098,302,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,152.52641
Policy Entropy: 1.67300
Value Function Loss: 0.06058

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.37581

Collected Steps per Second: 22,013.65732
Overall Steps per Second: 10,457.91380

Timestep Collection Time: 2.27241
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.78336

Cumulative Model Updates: 131,602
Cumulative Timesteps: 1,098,352,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1098352074...
Checkpoint 1098352074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,794.17027
Policy Entropy: 1.68621
Value Function Loss: 0.05979

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.31886
Value Function Update Magnitude: 0.38310

Collected Steps per Second: 21,801.63182
Overall Steps per Second: 10,632.54077

Timestep Collection Time: 2.29515
Timestep Consumption Time: 2.41097
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.70612

Cumulative Model Updates: 131,608
Cumulative Timesteps: 1,098,402,112

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,625.79267
Policy Entropy: 1.70471
Value Function Loss: 0.05649

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.31046
Value Function Update Magnitude: 0.36846

Collected Steps per Second: 22,122.66531
Overall Steps per Second: 10,520.03721

Timestep Collection Time: 2.26013
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.75283

Cumulative Model Updates: 131,614
Cumulative Timesteps: 1,098,452,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1098452112...
Checkpoint 1098452112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,649.31404
Policy Entropy: 1.69348
Value Function Loss: 0.05224

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.30293
Value Function Update Magnitude: 0.34779

Collected Steps per Second: 21,501.98360
Overall Steps per Second: 10,394.77897

Timestep Collection Time: 2.32565
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.81068

Cumulative Model Updates: 131,620
Cumulative Timesteps: 1,098,502,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,503.92541
Policy Entropy: 1.67747
Value Function Loss: 0.05474

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.30509
Value Function Update Magnitude: 0.35165

Collected Steps per Second: 21,771.64236
Overall Steps per Second: 10,429.28814

Timestep Collection Time: 2.29675
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.79457

Cumulative Model Updates: 131,626
Cumulative Timesteps: 1,098,552,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1098552122...
Checkpoint 1098552122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,265.29582
Policy Entropy: 1.67119
Value Function Loss: 0.06283

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.29622
Value Function Update Magnitude: 0.35439

Collected Steps per Second: 21,297.43628
Overall Steps per Second: 10,429.87482

Timestep Collection Time: 2.34986
Timestep Consumption Time: 2.44847
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.79833

Cumulative Model Updates: 131,632
Cumulative Timesteps: 1,098,602,168

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,905.97074
Policy Entropy: 1.68337
Value Function Loss: 0.06787

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.29011
Value Function Update Magnitude: 0.32877

Collected Steps per Second: 21,893.92666
Overall Steps per Second: 10,565.03345

Timestep Collection Time: 2.28420
Timestep Consumption Time: 2.44934
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.73354

Cumulative Model Updates: 131,638
Cumulative Timesteps: 1,098,652,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1098652178...
Checkpoint 1098652178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,501.61593
Policy Entropy: 1.68142
Value Function Loss: 0.06722

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.30960
Value Function Update Magnitude: 0.27713

Collected Steps per Second: 22,237.72216
Overall Steps per Second: 10,525.66236

Timestep Collection Time: 2.24861
Timestep Consumption Time: 2.50206
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.75067

Cumulative Model Updates: 131,644
Cumulative Timesteps: 1,098,702,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,101.99267
Policy Entropy: 1.66491
Value Function Loss: 0.06027

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.31265
Value Function Update Magnitude: 0.25709

Collected Steps per Second: 22,037.12852
Overall Steps per Second: 10,478.00837

Timestep Collection Time: 2.26899
Timestep Consumption Time: 2.50310
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.77209

Cumulative Model Updates: 131,650
Cumulative Timesteps: 1,098,752,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1098752184...
Checkpoint 1098752184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,465.30213
Policy Entropy: 1.66558
Value Function Loss: 0.05632

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.30364
Value Function Update Magnitude: 0.29501

Collected Steps per Second: 21,870.26531
Overall Steps per Second: 10,594.44238

Timestep Collection Time: 2.28731
Timestep Consumption Time: 2.43441
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.72172

Cumulative Model Updates: 131,656
Cumulative Timesteps: 1,098,802,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,883.74652
Policy Entropy: 1.67440
Value Function Loss: 0.05928

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.31194
Value Function Update Magnitude: 0.31837

Collected Steps per Second: 22,327.90362
Overall Steps per Second: 10,531.59604

Timestep Collection Time: 2.23971
Timestep Consumption Time: 2.50867
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.74838

Cumulative Model Updates: 131,662
Cumulative Timesteps: 1,098,852,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1098852216...
Checkpoint 1098852216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,579.28609
Policy Entropy: 1.69246
Value Function Loss: 0.06272

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.32368
Value Function Update Magnitude: 0.33437

Collected Steps per Second: 21,567.70324
Overall Steps per Second: 10,545.45369

Timestep Collection Time: 2.31930
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.74347

Cumulative Model Updates: 131,668
Cumulative Timesteps: 1,098,902,238

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,715.87030
Policy Entropy: 1.68666
Value Function Loss: 0.06159

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.32396
Value Function Update Magnitude: 0.34845

Collected Steps per Second: 22,052.90467
Overall Steps per Second: 10,495.77252

Timestep Collection Time: 2.26854
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.76649

Cumulative Model Updates: 131,674
Cumulative Timesteps: 1,098,952,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1098952266...
Checkpoint 1098952266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,788.13825
Policy Entropy: 1.69012
Value Function Loss: 0.06245

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.31952
Value Function Update Magnitude: 0.34967

Collected Steps per Second: 20,329.93840
Overall Steps per Second: 10,173.63292

Timestep Collection Time: 2.46041
Timestep Consumption Time: 2.45622
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.91663

Cumulative Model Updates: 131,680
Cumulative Timesteps: 1,099,002,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,918.91628
Policy Entropy: 1.67644
Value Function Loss: 0.06097

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.31857
Value Function Update Magnitude: 0.33773

Collected Steps per Second: 21,391.87141
Overall Steps per Second: 10,463.11679

Timestep Collection Time: 2.33752
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.77907

Cumulative Model Updates: 131,686
Cumulative Timesteps: 1,099,052,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1099052290...
Checkpoint 1099052290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,671.51960
Policy Entropy: 1.68074
Value Function Loss: 0.05887

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.30051
Value Function Update Magnitude: 0.32835

Collected Steps per Second: 21,401.32787
Overall Steps per Second: 10,324.78698

Timestep Collection Time: 2.33714
Timestep Consumption Time: 2.50731
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.84446

Cumulative Model Updates: 131,692
Cumulative Timesteps: 1,099,102,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,824.81781
Policy Entropy: 1.68630
Value Function Loss: 0.06262

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.29110
Value Function Update Magnitude: 0.33071

Collected Steps per Second: 22,145.64239
Overall Steps per Second: 10,523.09712

Timestep Collection Time: 2.25923
Timestep Consumption Time: 2.49527
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.75449

Cumulative Model Updates: 131,698
Cumulative Timesteps: 1,099,152,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1099152340...
Checkpoint 1099152340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,981.90222
Policy Entropy: 1.70199
Value Function Loss: 0.05902

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.30962
Value Function Update Magnitude: 0.34314

Collected Steps per Second: 21,710.25790
Overall Steps per Second: 10,543.80396

Timestep Collection Time: 2.30398
Timestep Consumption Time: 2.44004
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.74402

Cumulative Model Updates: 131,704
Cumulative Timesteps: 1,099,202,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,701.21172
Policy Entropy: 1.69926
Value Function Loss: 0.05607

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.29809
Value Function Update Magnitude: 0.33452

Collected Steps per Second: 22,449.07039
Overall Steps per Second: 10,598.06924

Timestep Collection Time: 2.22744
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.71822

Cumulative Model Updates: 131,710
Cumulative Timesteps: 1,099,252,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1099252364...
Checkpoint 1099252364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,029.53073
Policy Entropy: 1.69301
Value Function Loss: 0.05170

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.29594
Value Function Update Magnitude: 0.30783

Collected Steps per Second: 21,200.58981
Overall Steps per Second: 10,359.48584

Timestep Collection Time: 2.35880
Timestep Consumption Time: 2.46846
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.82727

Cumulative Model Updates: 131,716
Cumulative Timesteps: 1,099,302,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,348.62270
Policy Entropy: 1.66227
Value Function Loss: 0.05196

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.30666
Value Function Update Magnitude: 0.30602

Collected Steps per Second: 21,725.61657
Overall Steps per Second: 10,527.24706

Timestep Collection Time: 2.30198
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.75072

Cumulative Model Updates: 131,722
Cumulative Timesteps: 1,099,352,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1099352384...
Checkpoint 1099352384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,897.55278
Policy Entropy: 1.65915
Value Function Loss: 0.05711

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.31984
Value Function Update Magnitude: 0.33604

Collected Steps per Second: 21,342.27979
Overall Steps per Second: 10,627.93492

Timestep Collection Time: 2.34342
Timestep Consumption Time: 2.36248
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.70590

Cumulative Model Updates: 131,728
Cumulative Timesteps: 1,099,402,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,566.92979
Policy Entropy: 1.65700
Value Function Loss: 0.05957

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.32742
Value Function Update Magnitude: 0.33765

Collected Steps per Second: 21,446.79676
Overall Steps per Second: 10,479.08605

Timestep Collection Time: 2.33172
Timestep Consumption Time: 2.44045
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.77217

Cumulative Model Updates: 131,734
Cumulative Timesteps: 1,099,452,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1099452406...
Checkpoint 1099452406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,838.53944
Policy Entropy: 1.66700
Value Function Loss: 0.06062

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.32620
Value Function Update Magnitude: 0.33122

Collected Steps per Second: 21,049.92353
Overall Steps per Second: 10,272.28432

Timestep Collection Time: 2.37654
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.87000

Cumulative Model Updates: 131,740
Cumulative Timesteps: 1,099,502,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,097.16645
Policy Entropy: 1.66458
Value Function Loss: 0.05844

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.31906
Value Function Update Magnitude: 0.32275

Collected Steps per Second: 22,190.03013
Overall Steps per Second: 10,599.10796

Timestep Collection Time: 2.25362
Timestep Consumption Time: 2.46451
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.71813

Cumulative Model Updates: 131,746
Cumulative Timesteps: 1,099,552,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1099552440...
Checkpoint 1099552440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,331.13930
Policy Entropy: 1.65353
Value Function Loss: 0.05547

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.30664
Value Function Update Magnitude: 0.32887

Collected Steps per Second: 21,552.60090
Overall Steps per Second: 10,406.58619

Timestep Collection Time: 2.32046
Timestep Consumption Time: 2.48534
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.80580

Cumulative Model Updates: 131,752
Cumulative Timesteps: 1,099,602,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,176.08647
Policy Entropy: 1.66028
Value Function Loss: 0.05453

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.30109
Value Function Update Magnitude: 0.34424

Collected Steps per Second: 21,645.45438
Overall Steps per Second: 10,470.84865

Timestep Collection Time: 2.31088
Timestep Consumption Time: 2.46619
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.77707

Cumulative Model Updates: 131,758
Cumulative Timesteps: 1,099,652,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1099652472...
Checkpoint 1099652472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,163.89417
Policy Entropy: 1.66375
Value Function Loss: 0.05538

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.30277
Value Function Update Magnitude: 0.34523

Collected Steps per Second: 21,412.35511
Overall Steps per Second: 10,577.47280

Timestep Collection Time: 2.33631
Timestep Consumption Time: 2.39317
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.72949

Cumulative Model Updates: 131,764
Cumulative Timesteps: 1,099,702,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,175.62347
Policy Entropy: 1.67246
Value Function Loss: 0.05677

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.30311
Value Function Update Magnitude: 0.33651

Collected Steps per Second: 21,578.80619
Overall Steps per Second: 10,504.28505

Timestep Collection Time: 2.31839
Timestep Consumption Time: 2.44424
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.76263

Cumulative Model Updates: 131,770
Cumulative Timesteps: 1,099,752,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1099752526...
Checkpoint 1099752526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,478.14147
Policy Entropy: 1.68796
Value Function Loss: 0.05555

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.30907
Value Function Update Magnitude: 0.32031

Collected Steps per Second: 21,776.61904
Overall Steps per Second: 10,582.56612

Timestep Collection Time: 2.29751
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.72778

Cumulative Model Updates: 131,776
Cumulative Timesteps: 1,099,802,558

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,301.03630
Policy Entropy: 1.67778
Value Function Loss: 0.05995

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.31361
Value Function Update Magnitude: 0.31465

Collected Steps per Second: 21,798.69579
Overall Steps per Second: 10,520.59439

Timestep Collection Time: 2.29408
Timestep Consumption Time: 2.45926
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.75334

Cumulative Model Updates: 131,782
Cumulative Timesteps: 1,099,852,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1099852566...
Checkpoint 1099852566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,395.18267
Policy Entropy: 1.68079
Value Function Loss: 0.05723

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.31659
Value Function Update Magnitude: 0.31009

Collected Steps per Second: 21,918.34284
Overall Steps per Second: 10,573.00592

Timestep Collection Time: 2.28147
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.72959

Cumulative Model Updates: 131,788
Cumulative Timesteps: 1,099,902,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,600.36295
Policy Entropy: 1.67610
Value Function Loss: 0.06485

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.32242
Value Function Update Magnitude: 0.30324

Collected Steps per Second: 21,989.96423
Overall Steps per Second: 10,493.02706

Timestep Collection Time: 2.27395
Timestep Consumption Time: 2.49150
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.76545

Cumulative Model Updates: 131,794
Cumulative Timesteps: 1,099,952,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1099952576...
Checkpoint 1099952576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,472.03749
Policy Entropy: 1.67692
Value Function Loss: 0.06426

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.32348
Value Function Update Magnitude: 0.31778

Collected Steps per Second: 22,301.66881
Overall Steps per Second: 10,633.16967

Timestep Collection Time: 2.24324
Timestep Consumption Time: 2.46166
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.70490

Cumulative Model Updates: 131,800
Cumulative Timesteps: 1,100,002,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,908.70271
Policy Entropy: 1.68766
Value Function Loss: 0.06545

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.31693
Value Function Update Magnitude: 0.34675

Collected Steps per Second: 21,720.20139
Overall Steps per Second: 10,486.30271

Timestep Collection Time: 2.30311
Timestep Consumption Time: 2.46730
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.77041

Cumulative Model Updates: 131,806
Cumulative Timesteps: 1,100,052,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1100052628...
Checkpoint 1100052628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,728.50955
Policy Entropy: 1.69853
Value Function Loss: 0.06167

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.31295
Value Function Update Magnitude: 0.33972

Collected Steps per Second: 21,901.76932
Overall Steps per Second: 10,605.54812

Timestep Collection Time: 2.28301
Timestep Consumption Time: 2.43169
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.71470

Cumulative Model Updates: 131,812
Cumulative Timesteps: 1,100,102,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,081.17016
Policy Entropy: 1.69367
Value Function Loss: 0.06580

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.32339
Value Function Update Magnitude: 0.31995

Collected Steps per Second: 21,911.71760
Overall Steps per Second: 10,470.99258

Timestep Collection Time: 2.28188
Timestep Consumption Time: 2.49321
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.77510

Cumulative Model Updates: 131,818
Cumulative Timesteps: 1,100,152,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1100152630...
Checkpoint 1100152630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,131.51888
Policy Entropy: 1.69147
Value Function Loss: 0.06444

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.32880
Value Function Update Magnitude: 0.32521

Collected Steps per Second: 20,664.96967
Overall Steps per Second: 10,163.25862

Timestep Collection Time: 2.42071
Timestep Consumption Time: 2.50133
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.92204

Cumulative Model Updates: 131,824
Cumulative Timesteps: 1,100,202,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,382.56267
Policy Entropy: 1.67464
Value Function Loss: 0.06265

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.32129
Value Function Update Magnitude: 0.35909

Collected Steps per Second: 20,338.92322
Overall Steps per Second: 10,023.50818

Timestep Collection Time: 2.45873
Timestep Consumption Time: 2.53034
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.98907

Cumulative Model Updates: 131,830
Cumulative Timesteps: 1,100,252,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1100252662...
Checkpoint 1100252662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,084.22795
Policy Entropy: 1.70428
Value Function Loss: 0.06692

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.31794
Value Function Update Magnitude: 0.35841

Collected Steps per Second: 21,737.69715
Overall Steps per Second: 10,460.02201

Timestep Collection Time: 2.30089
Timestep Consumption Time: 2.48075
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.78163

Cumulative Model Updates: 131,836
Cumulative Timesteps: 1,100,302,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,327.36123
Policy Entropy: 1.70149
Value Function Loss: 0.06341

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.28796
Value Function Update Magnitude: 0.35454

Collected Steps per Second: 21,645.26900
Overall Steps per Second: 10,325.18787

Timestep Collection Time: 2.31016
Timestep Consumption Time: 2.53276
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.84291

Cumulative Model Updates: 131,842
Cumulative Timesteps: 1,100,352,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1100352682...
Checkpoint 1100352682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,891.27895
Policy Entropy: 1.71586
Value Function Loss: 0.06263

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.27616
Value Function Update Magnitude: 0.33811

Collected Steps per Second: 21,920.78297
Overall Steps per Second: 10,509.01359

Timestep Collection Time: 2.28185
Timestep Consumption Time: 2.47787
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.75972

Cumulative Model Updates: 131,848
Cumulative Timesteps: 1,100,402,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,740.62579
Policy Entropy: 1.68073
Value Function Loss: 0.05739

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.28356
Value Function Update Magnitude: 0.32753

Collected Steps per Second: 21,954.64842
Overall Steps per Second: 10,464.43668

Timestep Collection Time: 2.27833
Timestep Consumption Time: 2.50167
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.78000

Cumulative Model Updates: 131,854
Cumulative Timesteps: 1,100,452,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1100452722...
Checkpoint 1100452722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,329.88218
Policy Entropy: 1.67844
Value Function Loss: 0.06077

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.29065
Value Function Update Magnitude: 0.33569

Collected Steps per Second: 22,029.32732
Overall Steps per Second: 10,650.67637

Timestep Collection Time: 2.26988
Timestep Consumption Time: 2.42503
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.69491

Cumulative Model Updates: 131,860
Cumulative Timesteps: 1,100,502,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,577.17344
Policy Entropy: 1.67827
Value Function Loss: 0.06210

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.30334
Value Function Update Magnitude: 0.33460

Collected Steps per Second: 22,120.28444
Overall Steps per Second: 10,479.60203

Timestep Collection Time: 2.26182
Timestep Consumption Time: 2.51241
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.77423

Cumulative Model Updates: 131,866
Cumulative Timesteps: 1,100,552,758

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1100552758...
Checkpoint 1100552758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,192.19075
Policy Entropy: 1.68443
Value Function Loss: 0.06163

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.29699
Value Function Update Magnitude: 0.32276

Collected Steps per Second: 22,002.27666
Overall Steps per Second: 10,609.22865

Timestep Collection Time: 2.27386
Timestep Consumption Time: 2.44185
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.71571

Cumulative Model Updates: 131,872
Cumulative Timesteps: 1,100,602,788

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,020.61568
Policy Entropy: 1.68737
Value Function Loss: 0.06209

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.28943
Value Function Update Magnitude: 0.32085

Collected Steps per Second: 22,189.07660
Overall Steps per Second: 10,518.92723

Timestep Collection Time: 2.25543
Timestep Consumption Time: 2.50228
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.75771

Cumulative Model Updates: 131,878
Cumulative Timesteps: 1,100,652,834

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1100652834...
Checkpoint 1100652834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,556.55937
Policy Entropy: 1.69943
Value Function Loss: 0.05701

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.30466
Value Function Update Magnitude: 0.32057

Collected Steps per Second: 21,823.83674
Overall Steps per Second: 10,613.07161

Timestep Collection Time: 2.29116
Timestep Consumption Time: 2.42020
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.71136

Cumulative Model Updates: 131,884
Cumulative Timesteps: 1,100,702,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,978.47771
Policy Entropy: 1.69227
Value Function Loss: 0.05761

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.31205
Value Function Update Magnitude: 0.33232

Collected Steps per Second: 21,449.95577
Overall Steps per Second: 10,500.00429

Timestep Collection Time: 2.33185
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.76362

Cumulative Model Updates: 131,890
Cumulative Timesteps: 1,100,752,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1100752854...
Checkpoint 1100752854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,258.41741
Policy Entropy: 1.68559
Value Function Loss: 0.05681

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07997
Policy Update Magnitude: 0.31441
Value Function Update Magnitude: 0.32649

Collected Steps per Second: 21,719.30045
Overall Steps per Second: 10,543.96718

Timestep Collection Time: 2.30284
Timestep Consumption Time: 2.44073
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.74357

Cumulative Model Updates: 131,896
Cumulative Timesteps: 1,100,802,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,176.16213
Policy Entropy: 1.66996
Value Function Loss: 0.05624

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.31451
Value Function Update Magnitude: 0.32502

Collected Steps per Second: 21,579.16774
Overall Steps per Second: 10,474.61908

Timestep Collection Time: 2.31761
Timestep Consumption Time: 2.45698
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.77459

Cumulative Model Updates: 131,902
Cumulative Timesteps: 1,100,852,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1100852882...
Checkpoint 1100852882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,220.98430
Policy Entropy: 1.68109
Value Function Loss: 0.05493

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.31602
Value Function Update Magnitude: 0.32313

Collected Steps per Second: 21,580.85012
Overall Steps per Second: 10,273.41724

Timestep Collection Time: 2.31789
Timestep Consumption Time: 2.55118
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.86907

Cumulative Model Updates: 131,908
Cumulative Timesteps: 1,100,902,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,294.10527
Policy Entropy: 1.68216
Value Function Loss: 0.05141

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.30520
Value Function Update Magnitude: 0.31791

Collected Steps per Second: 22,129.46436
Overall Steps per Second: 10,435.26622

Timestep Collection Time: 2.25943
Timestep Consumption Time: 2.53201
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.79144

Cumulative Model Updates: 131,914
Cumulative Timesteps: 1,100,952,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1100952904...
Checkpoint 1100952904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,190.07376
Policy Entropy: 1.68562
Value Function Loss: 0.05503

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.30751
Value Function Update Magnitude: 0.32013

Collected Steps per Second: 21,896.43496
Overall Steps per Second: 10,595.85092

Timestep Collection Time: 2.28384
Timestep Consumption Time: 2.43574
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.71958

Cumulative Model Updates: 131,920
Cumulative Timesteps: 1,101,002,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,218.83191
Policy Entropy: 1.67815
Value Function Loss: 0.05399

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.31609
Value Function Update Magnitude: 0.31986

Collected Steps per Second: 21,891.01624
Overall Steps per Second: 10,525.82433

Timestep Collection Time: 2.28422
Timestep Consumption Time: 2.46638
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.75060

Cumulative Model Updates: 131,926
Cumulative Timesteps: 1,101,052,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1101052916...
Checkpoint 1101052916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,256.42903
Policy Entropy: 1.68168
Value Function Loss: 0.05714

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.31382
Value Function Update Magnitude: 0.32040

Collected Steps per Second: 21,534.29460
Overall Steps per Second: 10,528.18602

Timestep Collection Time: 2.32327
Timestep Consumption Time: 2.42873
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.75201

Cumulative Model Updates: 131,932
Cumulative Timesteps: 1,101,102,946

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,274.69953
Policy Entropy: 1.66956
Value Function Loss: 0.05418

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.31369
Value Function Update Magnitude: 0.32304

Collected Steps per Second: 22,126.89198
Overall Steps per Second: 10,541.77980

Timestep Collection Time: 2.26096
Timestep Consumption Time: 2.48473
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.74569

Cumulative Model Updates: 131,938
Cumulative Timesteps: 1,101,152,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1101152974...
Checkpoint 1101152974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,477.33306
Policy Entropy: 1.67405
Value Function Loss: 0.05846

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.31773
Value Function Update Magnitude: 0.32654

Collected Steps per Second: 21,732.25359
Overall Steps per Second: 10,552.97238

Timestep Collection Time: 2.30073
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.73800

Cumulative Model Updates: 131,944
Cumulative Timesteps: 1,101,202,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,390.44613
Policy Entropy: 1.67193
Value Function Loss: 0.05677

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.31859
Value Function Update Magnitude: 0.32138

Collected Steps per Second: 21,572.33214
Overall Steps per Second: 10,526.52337

Timestep Collection Time: 2.31853
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.75143

Cumulative Model Updates: 131,950
Cumulative Timesteps: 1,101,252,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1101252990...
Checkpoint 1101252990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,545.98354
Policy Entropy: 1.67692
Value Function Loss: 0.05559

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.31143
Value Function Update Magnitude: 0.32164

Collected Steps per Second: 21,468.60195
Overall Steps per Second: 10,346.28394

Timestep Collection Time: 2.32917
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.83304

Cumulative Model Updates: 131,956
Cumulative Timesteps: 1,101,302,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,930.77986
Policy Entropy: 1.67371
Value Function Loss: 0.05688

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.30899
Value Function Update Magnitude: 0.32790

Collected Steps per Second: 21,412.87930
Overall Steps per Second: 10,298.73327

Timestep Collection Time: 2.33588
Timestep Consumption Time: 2.52083
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.85671

Cumulative Model Updates: 131,962
Cumulative Timesteps: 1,101,353,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1101353012...
Checkpoint 1101353012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,317.19832
Policy Entropy: 1.65227
Value Function Loss: 0.05680

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.30999
Value Function Update Magnitude: 0.33989

Collected Steps per Second: 21,301.53313
Overall Steps per Second: 10,284.98865

Timestep Collection Time: 2.34809
Timestep Consumption Time: 2.51511
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.86320

Cumulative Model Updates: 131,968
Cumulative Timesteps: 1,101,403,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,198.08829
Policy Entropy: 1.66325
Value Function Loss: 0.06006

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.31325
Value Function Update Magnitude: 0.33426

Collected Steps per Second: 21,595.05024
Overall Steps per Second: 10,383.38731

Timestep Collection Time: 2.31609
Timestep Consumption Time: 2.50084
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.81693

Cumulative Model Updates: 131,974
Cumulative Timesteps: 1,101,453,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1101453046...
Checkpoint 1101453046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,222.43639
Policy Entropy: 1.67663
Value Function Loss: 0.06210

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.32277
Value Function Update Magnitude: 0.32688

Collected Steps per Second: 21,850.68674
Overall Steps per Second: 10,574.22482

Timestep Collection Time: 2.28826
Timestep Consumption Time: 2.44022
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.72848

Cumulative Model Updates: 131,980
Cumulative Timesteps: 1,101,503,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,467.19469
Policy Entropy: 1.71143
Value Function Loss: 0.06705

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.32481
Value Function Update Magnitude: 0.33375

Collected Steps per Second: 22,211.42574
Overall Steps per Second: 10,483.61149

Timestep Collection Time: 2.25217
Timestep Consumption Time: 2.51946
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.77164

Cumulative Model Updates: 131,986
Cumulative Timesteps: 1,101,553,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1101553070...
Checkpoint 1101553070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,756.07969
Policy Entropy: 1.70616
Value Function Loss: 0.06386

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.32068
Value Function Update Magnitude: 0.37069

Collected Steps per Second: 22,000.46342
Overall Steps per Second: 10,624.44705

Timestep Collection Time: 2.27395
Timestep Consumption Time: 2.43481
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.70876

Cumulative Model Updates: 131,992
Cumulative Timesteps: 1,101,603,098

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,533.81067
Policy Entropy: 1.69120
Value Function Loss: 0.06434

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.32511
Value Function Update Magnitude: 0.35239

Collected Steps per Second: 22,139.55250
Overall Steps per Second: 10,485.64855

Timestep Collection Time: 2.25849
Timestep Consumption Time: 2.51012
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.76861

Cumulative Model Updates: 131,998
Cumulative Timesteps: 1,101,653,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1101653100...
Checkpoint 1101653100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,887.37264
Policy Entropy: 1.68609
Value Function Loss: 0.06231

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.32659
Value Function Update Magnitude: 0.39372

Collected Steps per Second: 21,244.41682
Overall Steps per Second: 10,588.99989

Timestep Collection Time: 2.35412
Timestep Consumption Time: 2.36889
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.72301

Cumulative Model Updates: 132,004
Cumulative Timesteps: 1,101,703,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,715.80723
Policy Entropy: 1.69737
Value Function Loss: 0.06236

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.32711
Value Function Update Magnitude: 0.41292

Collected Steps per Second: 21,211.36113
Overall Steps per Second: 10,498.88120

Timestep Collection Time: 2.35742
Timestep Consumption Time: 2.40538
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.76279

Cumulative Model Updates: 132,010
Cumulative Timesteps: 1,101,753,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1101753116...
Checkpoint 1101753116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,166.96323
Policy Entropy: 1.70391
Value Function Loss: 0.05890

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.32294
Value Function Update Magnitude: 0.38742

Collected Steps per Second: 21,409.54109
Overall Steps per Second: 10,655.82803

Timestep Collection Time: 2.33559
Timestep Consumption Time: 2.35705
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.69264

Cumulative Model Updates: 132,016
Cumulative Timesteps: 1,101,803,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,790.98545
Policy Entropy: 1.69737
Value Function Loss: 0.05490

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.31617
Value Function Update Magnitude: 0.34728

Collected Steps per Second: 20,932.32322
Overall Steps per Second: 10,427.18785

Timestep Collection Time: 2.38970
Timestep Consumption Time: 2.40757
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.79727

Cumulative Model Updates: 132,022
Cumulative Timesteps: 1,101,853,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1101853142...
Checkpoint 1101853142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,727.58563
Policy Entropy: 1.68929
Value Function Loss: 0.05252

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.31196
Value Function Update Magnitude: 0.33829

Collected Steps per Second: 20,797.51737
Overall Steps per Second: 10,356.56760

Timestep Collection Time: 2.40442
Timestep Consumption Time: 2.42401
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.82843

Cumulative Model Updates: 132,028
Cumulative Timesteps: 1,101,903,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,494.35730
Policy Entropy: 1.68680
Value Function Loss: 0.05620

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.31622
Value Function Update Magnitude: 0.33593

Collected Steps per Second: 20,978.55685
Overall Steps per Second: 10,304.28256

Timestep Collection Time: 2.38510
Timestep Consumption Time: 2.47074
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.85585

Cumulative Model Updates: 132,034
Cumulative Timesteps: 1,101,953,184

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1101953184...
Checkpoint 1101953184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,653.64005
Policy Entropy: 1.68534
Value Function Loss: 0.05761

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.32060
Value Function Update Magnitude: 0.35683

Collected Steps per Second: 21,401.18400
Overall Steps per Second: 10,543.79991

Timestep Collection Time: 2.33679
Timestep Consumption Time: 2.40629
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74307

Cumulative Model Updates: 132,040
Cumulative Timesteps: 1,102,003,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,336.33710
Policy Entropy: 1.70325
Value Function Loss: 0.06713

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.32119
Value Function Update Magnitude: 0.35591

Collected Steps per Second: 21,544.66737
Overall Steps per Second: 10,558.76869

Timestep Collection Time: 2.32169
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.73729

Cumulative Model Updates: 132,046
Cumulative Timesteps: 1,102,053,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1102053214...
Checkpoint 1102053214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,718.80735
Policy Entropy: 1.70980
Value Function Loss: 0.06777

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.30589
Value Function Update Magnitude: 0.31495

Collected Steps per Second: 22,111.41768
Overall Steps per Second: 10,640.92906

Timestep Collection Time: 2.26308
Timestep Consumption Time: 2.43951
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.70260

Cumulative Model Updates: 132,052
Cumulative Timesteps: 1,102,103,254

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,106.72101
Policy Entropy: 1.71149
Value Function Loss: 0.06714

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.32215
Value Function Update Magnitude: 0.32764

Collected Steps per Second: 21,881.68874
Overall Steps per Second: 10,466.61628

Timestep Collection Time: 2.28593
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.77900

Cumulative Model Updates: 132,058
Cumulative Timesteps: 1,102,153,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1102153274...
Checkpoint 1102153274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,923.65252
Policy Entropy: 1.70723
Value Function Loss: 0.06346

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.32637
Value Function Update Magnitude: 0.28540

Collected Steps per Second: 22,119.76043
Overall Steps per Second: 10,651.81664

Timestep Collection Time: 2.26250
Timestep Consumption Time: 2.43585
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.69835

Cumulative Model Updates: 132,064
Cumulative Timesteps: 1,102,203,320

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,365.78331
Policy Entropy: 1.71630
Value Function Loss: 0.06540

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.32516
Value Function Update Magnitude: 0.32162

Collected Steps per Second: 21,986.30700
Overall Steps per Second: 10,433.83373

Timestep Collection Time: 2.27605
Timestep Consumption Time: 2.52007
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.79613

Cumulative Model Updates: 132,070
Cumulative Timesteps: 1,102,253,362

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1102253362...
Checkpoint 1102253362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,387.17679
Policy Entropy: 1.71543
Value Function Loss: 0.06661

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.33195
Value Function Update Magnitude: 0.32964

Collected Steps per Second: 22,014.57387
Overall Steps per Second: 10,629.97141

Timestep Collection Time: 2.27159
Timestep Consumption Time: 2.43285
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.70443

Cumulative Model Updates: 132,076
Cumulative Timesteps: 1,102,303,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,050.92864
Policy Entropy: 1.71097
Value Function Loss: 0.06305

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.32753
Value Function Update Magnitude: 0.29849

Collected Steps per Second: 21,970.94309
Overall Steps per Second: 10,467.81386

Timestep Collection Time: 2.27701
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.77922

Cumulative Model Updates: 132,082
Cumulative Timesteps: 1,102,353,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1102353398...
Checkpoint 1102353398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,416.30789
Policy Entropy: 1.69481
Value Function Loss: 0.06341

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.32294
Value Function Update Magnitude: 0.26281

Collected Steps per Second: 21,885.02119
Overall Steps per Second: 10,584.84687

Timestep Collection Time: 2.28503
Timestep Consumption Time: 2.43946
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.72449

Cumulative Model Updates: 132,088
Cumulative Timesteps: 1,102,403,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,040.04965
Policy Entropy: 1.69368
Value Function Loss: 0.05911

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.31892
Value Function Update Magnitude: 0.28775

Collected Steps per Second: 21,401.24131
Overall Steps per Second: 10,477.59688

Timestep Collection Time: 2.33706
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.77361

Cumulative Model Updates: 132,094
Cumulative Timesteps: 1,102,453,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1102453422...
Checkpoint 1102453422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,503.52819
Policy Entropy: 1.71040
Value Function Loss: 0.06101

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.31872
Value Function Update Magnitude: 0.33848

Collected Steps per Second: 21,529.39835
Overall Steps per Second: 10,391.90727

Timestep Collection Time: 2.32287
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.81240

Cumulative Model Updates: 132,100
Cumulative Timesteps: 1,102,503,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,312.84575
Policy Entropy: 1.70392
Value Function Loss: 0.06814

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.32478
Value Function Update Magnitude: 0.36034

Collected Steps per Second: 21,470.30043
Overall Steps per Second: 10,327.69907

Timestep Collection Time: 2.32926
Timestep Consumption Time: 2.51305
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.84232

Cumulative Model Updates: 132,106
Cumulative Timesteps: 1,102,553,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1102553442...
Checkpoint 1102553442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,038.85668
Policy Entropy: 1.71033
Value Function Loss: 0.06464

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.32597
Value Function Update Magnitude: 0.38013

Collected Steps per Second: 21,788.07409
Overall Steps per Second: 10,536.33944

Timestep Collection Time: 2.29612
Timestep Consumption Time: 2.45202
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.74814

Cumulative Model Updates: 132,112
Cumulative Timesteps: 1,102,603,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,065.08516
Policy Entropy: 1.69128
Value Function Loss: 0.06329

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08252
Policy Update Magnitude: 0.32395
Value Function Update Magnitude: 0.38901

Collected Steps per Second: 21,548.42195
Overall Steps per Second: 10,457.60195

Timestep Collection Time: 2.32082
Timestep Consumption Time: 2.46135
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.78217

Cumulative Model Updates: 132,118
Cumulative Timesteps: 1,102,653,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1102653480...
Checkpoint 1102653480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,326.25484
Policy Entropy: 1.70785
Value Function Loss: 0.05841

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07569
Policy Update Magnitude: 0.32077
Value Function Update Magnitude: 0.39550

Collected Steps per Second: 22,000.14784
Overall Steps per Second: 10,421.82743

Timestep Collection Time: 2.27271
Timestep Consumption Time: 2.52491
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.79762

Cumulative Model Updates: 132,124
Cumulative Timesteps: 1,102,703,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,048.80184
Policy Entropy: 1.70622
Value Function Loss: 0.05963

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.32221
Value Function Update Magnitude: 0.39285

Collected Steps per Second: 21,233.96517
Overall Steps per Second: 10,155.68441

Timestep Collection Time: 2.35472
Timestep Consumption Time: 2.56863
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.92335

Cumulative Model Updates: 132,130
Cumulative Timesteps: 1,102,753,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1102753480...
Checkpoint 1102753480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,239.66917
Policy Entropy: 1.70755
Value Function Loss: 0.05981

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.32132
Value Function Update Magnitude: 0.37974

Collected Steps per Second: 21,609.26499
Overall Steps per Second: 10,306.07099

Timestep Collection Time: 2.31586
Timestep Consumption Time: 2.53992
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.85578

Cumulative Model Updates: 132,136
Cumulative Timesteps: 1,102,803,524

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,948.11337
Policy Entropy: 1.69007
Value Function Loss: 0.05812

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.31887
Value Function Update Magnitude: 0.36887

Collected Steps per Second: 22,161.21879
Overall Steps per Second: 10,478.28488

Timestep Collection Time: 2.25619
Timestep Consumption Time: 2.51558
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.77177

Cumulative Model Updates: 132,142
Cumulative Timesteps: 1,102,853,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1102853524...
Checkpoint 1102853524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,570.40829
Policy Entropy: 1.68224
Value Function Loss: 0.05957

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.35929

Collected Steps per Second: 21,860.42946
Overall Steps per Second: 10,580.82676

Timestep Collection Time: 2.28788
Timestep Consumption Time: 2.43897
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72685

Cumulative Model Updates: 132,148
Cumulative Timesteps: 1,102,903,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,307.24824
Policy Entropy: 1.68898
Value Function Loss: 0.06197

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.31970
Value Function Update Magnitude: 0.35809

Collected Steps per Second: 21,990.18761
Overall Steps per Second: 10,491.96199

Timestep Collection Time: 2.27411
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.76632

Cumulative Model Updates: 132,154
Cumulative Timesteps: 1,102,953,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1102953546...
Checkpoint 1102953546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,890.02590
Policy Entropy: 1.68684
Value Function Loss: 0.06260

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.32187
Value Function Update Magnitude: 0.37039

Collected Steps per Second: 21,735.27712
Overall Steps per Second: 10,583.75846

Timestep Collection Time: 2.30124
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.72592

Cumulative Model Updates: 132,160
Cumulative Timesteps: 1,103,003,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,342.13557
Policy Entropy: 1.68837
Value Function Loss: 0.05755

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.31757
Value Function Update Magnitude: 0.38053

Collected Steps per Second: 21,544.37775
Overall Steps per Second: 10,483.49418

Timestep Collection Time: 2.32228
Timestep Consumption Time: 2.45018
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.77245

Cumulative Model Updates: 132,166
Cumulative Timesteps: 1,103,053,596

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1103053596...
Checkpoint 1103053596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,338.29784
Policy Entropy: 1.66701
Value Function Loss: 0.05368

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.31280
Value Function Update Magnitude: 0.33596

Collected Steps per Second: 21,413.18731
Overall Steps per Second: 10,333.53766

Timestep Collection Time: 2.33585
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.84036

Cumulative Model Updates: 132,172
Cumulative Timesteps: 1,103,103,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,114.23171
Policy Entropy: 1.66108
Value Function Loss: 0.05606

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.31611
Value Function Update Magnitude: 0.27452

Collected Steps per Second: 21,892.40521
Overall Steps per Second: 10,428.42298

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.51129
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.79574

Cumulative Model Updates: 132,178
Cumulative Timesteps: 1,103,153,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1103153626...
Checkpoint 1103153626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,791.52989
Policy Entropy: 1.66200
Value Function Loss: 0.05490

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.31516
Value Function Update Magnitude: 0.25918

Collected Steps per Second: 21,384.79687
Overall Steps per Second: 10,491.84851

Timestep Collection Time: 2.33867
Timestep Consumption Time: 2.42808
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.76675

Cumulative Model Updates: 132,184
Cumulative Timesteps: 1,103,203,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,112.71744
Policy Entropy: 1.69250
Value Function Loss: 0.05849

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.31417
Value Function Update Magnitude: 0.26903

Collected Steps per Second: 22,038.28148
Overall Steps per Second: 10,611.75325

Timestep Collection Time: 2.26923
Timestep Consumption Time: 2.44347
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.71270

Cumulative Model Updates: 132,190
Cumulative Timesteps: 1,103,253,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1103253648...
Checkpoint 1103253648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,685.40201
Policy Entropy: 1.71531
Value Function Loss: 0.06294

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.32054
Value Function Update Magnitude: 0.28232

Collected Steps per Second: 21,670.65579
Overall Steps per Second: 10,553.55554

Timestep Collection Time: 2.30736
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.73793

Cumulative Model Updates: 132,196
Cumulative Timesteps: 1,103,303,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,706.22140
Policy Entropy: 1.71279
Value Function Loss: 0.06496

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.32504
Value Function Update Magnitude: 0.29677

Collected Steps per Second: 22,086.28728
Overall Steps per Second: 10,462.49942

Timestep Collection Time: 2.26448
Timestep Consumption Time: 2.51583
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.78031

Cumulative Model Updates: 132,202
Cumulative Timesteps: 1,103,353,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1103353664...
Checkpoint 1103353664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,354.35662
Policy Entropy: 1.69281
Value Function Loss: 0.06070

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.32095
Value Function Update Magnitude: 0.35109

Collected Steps per Second: 21,840.84147
Overall Steps per Second: 10,582.67615

Timestep Collection Time: 2.28956
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.72527

Cumulative Model Updates: 132,208
Cumulative Timesteps: 1,103,403,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,324.03236
Policy Entropy: 1.67120
Value Function Loss: 0.05578

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.31817
Value Function Update Magnitude: 0.36378

Collected Steps per Second: 22,136.75014
Overall Steps per Second: 10,509.77428

Timestep Collection Time: 2.25914
Timestep Consumption Time: 2.49929
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.75843

Cumulative Model Updates: 132,214
Cumulative Timesteps: 1,103,453,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1103453680...
Checkpoint 1103453680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,284.39806
Policy Entropy: 1.65463
Value Function Loss: 0.05392

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.35350

Collected Steps per Second: 21,601.63106
Overall Steps per Second: 10,548.25730

Timestep Collection Time: 2.31677
Timestep Consumption Time: 2.42771
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.74448

Cumulative Model Updates: 132,220
Cumulative Timesteps: 1,103,503,726

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,502.56098
Policy Entropy: 1.64639
Value Function Loss: 0.05730

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.31562
Value Function Update Magnitude: 0.35817

Collected Steps per Second: 21,620.05794
Overall Steps per Second: 10,513.43721

Timestep Collection Time: 2.31470
Timestep Consumption Time: 2.44530
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.76000

Cumulative Model Updates: 132,226
Cumulative Timesteps: 1,103,553,770

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1103553770...
Checkpoint 1103553770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,879.99726
Policy Entropy: 1.63711
Value Function Loss: 0.06008

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.31914
Value Function Update Magnitude: 0.36819

Collected Steps per Second: 21,158.92178
Overall Steps per Second: 10,239.61728

Timestep Collection Time: 2.36401
Timestep Consumption Time: 2.52093
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.88495

Cumulative Model Updates: 132,232
Cumulative Timesteps: 1,103,603,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,387.08148
Policy Entropy: 1.65127
Value Function Loss: 0.06003

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.31409
Value Function Update Magnitude: 0.37347

Collected Steps per Second: 21,831.64527
Overall Steps per Second: 10,459.25187

Timestep Collection Time: 2.29108
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.78218

Cumulative Model Updates: 132,238
Cumulative Timesteps: 1,103,653,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1103653808...
Checkpoint 1103653808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,890.24935
Policy Entropy: 1.66043
Value Function Loss: 0.06045

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.31596
Value Function Update Magnitude: 0.34836

Collected Steps per Second: 21,277.16778
Overall Steps per Second: 10,266.80220

Timestep Collection Time: 2.35069
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.87162

Cumulative Model Updates: 132,244
Cumulative Timesteps: 1,103,703,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,583.43353
Policy Entropy: 1.67430
Value Function Loss: 0.05603

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.31278
Value Function Update Magnitude: 0.33889

Collected Steps per Second: 21,677.90503
Overall Steps per Second: 10,377.26003

Timestep Collection Time: 2.30797
Timestep Consumption Time: 2.51334
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.82131

Cumulative Model Updates: 132,250
Cumulative Timesteps: 1,103,753,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1103753856...
Checkpoint 1103753856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,746.39222
Policy Entropy: 1.66787
Value Function Loss: 0.05052

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.32893

Collected Steps per Second: 21,334.29085
Overall Steps per Second: 10,268.87915

Timestep Collection Time: 2.34383
Timestep Consumption Time: 2.52564
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.86947

Cumulative Model Updates: 132,256
Cumulative Timesteps: 1,103,803,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,159.75906
Policy Entropy: 1.66210
Value Function Loss: 0.04671

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.29950
Value Function Update Magnitude: 0.30627

Collected Steps per Second: 21,907.98681
Overall Steps per Second: 10,407.72545

Timestep Collection Time: 2.28319
Timestep Consumption Time: 2.52286
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.80605

Cumulative Model Updates: 132,262
Cumulative Timesteps: 1,103,853,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1103853880...
Checkpoint 1103853880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,280.30311
Policy Entropy: 1.64790
Value Function Loss: 0.04914

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.30205
Value Function Update Magnitude: 0.29121

Collected Steps per Second: 21,792.86918
Overall Steps per Second: 10,540.74871

Timestep Collection Time: 2.29488
Timestep Consumption Time: 2.44976
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.74463

Cumulative Model Updates: 132,268
Cumulative Timesteps: 1,103,903,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,407.21767
Policy Entropy: 1.65055
Value Function Loss: 0.05320

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07484
Policy Update Magnitude: 0.30835
Value Function Update Magnitude: 0.29564

Collected Steps per Second: 21,917.35677
Overall Steps per Second: 10,587.83955

Timestep Collection Time: 2.28184
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.72353

Cumulative Model Updates: 132,274
Cumulative Timesteps: 1,103,953,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1103953904...
Checkpoint 1103953904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,948.55566
Policy Entropy: 1.66127
Value Function Loss: 0.05324

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.31228
Value Function Update Magnitude: 0.30972

Collected Steps per Second: 21,727.46419
Overall Steps per Second: 10,550.88841

Timestep Collection Time: 2.30151
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.73951

Cumulative Model Updates: 132,280
Cumulative Timesteps: 1,104,003,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,079.35948
Policy Entropy: 1.66276
Value Function Loss: 0.05109

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.30728
Value Function Update Magnitude: 0.31287

Collected Steps per Second: 22,178.83688
Overall Steps per Second: 10,494.30681

Timestep Collection Time: 2.25575
Timestep Consumption Time: 2.51159
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.76735

Cumulative Model Updates: 132,286
Cumulative Timesteps: 1,104,053,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1104053940...
Checkpoint 1104053940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,723.19290
Policy Entropy: 1.67456
Value Function Loss: 0.04954

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.30204
Value Function Update Magnitude: 0.31243

Collected Steps per Second: 22,039.81220
Overall Steps per Second: 10,624.25820

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.43895
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.70885

Cumulative Model Updates: 132,292
Cumulative Timesteps: 1,104,103,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,779.27800
Policy Entropy: 1.66103
Value Function Loss: 0.04741

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.29864
Value Function Update Magnitude: 0.29811

Collected Steps per Second: 21,621.37116
Overall Steps per Second: 10,507.61935

Timestep Collection Time: 2.31354
Timestep Consumption Time: 2.44700
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.76055

Cumulative Model Updates: 132,298
Cumulative Timesteps: 1,104,153,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1104153990...
Checkpoint 1104153990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,521.64941
Policy Entropy: 1.67427
Value Function Loss: 0.05430

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.30189
Value Function Update Magnitude: 0.30226

Collected Steps per Second: 21,006.69296
Overall Steps per Second: 10,560.07020

Timestep Collection Time: 2.38162
Timestep Consumption Time: 2.35604
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.73766

Cumulative Model Updates: 132,304
Cumulative Timesteps: 1,104,204,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,951.27494
Policy Entropy: 1.66879
Value Function Loss: 0.05184

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.30975
Value Function Update Magnitude: 0.31950

Collected Steps per Second: 20,963.92394
Overall Steps per Second: 10,545.89556

Timestep Collection Time: 2.38619
Timestep Consumption Time: 2.35726
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.74346

Cumulative Model Updates: 132,310
Cumulative Timesteps: 1,104,254,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1104254044...
Checkpoint 1104254044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,890.26212
Policy Entropy: 1.66767
Value Function Loss: 0.05579

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.30995
Value Function Update Magnitude: 0.32460

Collected Steps per Second: 20,751.55990
Overall Steps per Second: 10,508.16096

Timestep Collection Time: 2.41177
Timestep Consumption Time: 2.35100
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.76277

Cumulative Model Updates: 132,316
Cumulative Timesteps: 1,104,304,092

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,563.47017
Policy Entropy: 1.66842
Value Function Loss: 0.05755

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.31190
Value Function Update Magnitude: 0.33232

Collected Steps per Second: 21,113.84817
Overall Steps per Second: 10,535.06439

Timestep Collection Time: 2.36840
Timestep Consumption Time: 2.37823
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.74662

Cumulative Model Updates: 132,322
Cumulative Timesteps: 1,104,354,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1104354098...
Checkpoint 1104354098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,502.13340
Policy Entropy: 1.66586
Value Function Loss: 0.05882

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.31648
Value Function Update Magnitude: 0.34930

Collected Steps per Second: 20,952.60021
Overall Steps per Second: 10,200.84031

Timestep Collection Time: 2.38729
Timestep Consumption Time: 2.51622
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.90352

Cumulative Model Updates: 132,328
Cumulative Timesteps: 1,104,404,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,560.08234
Policy Entropy: 1.67445
Value Function Loss: 0.05466

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.31127
Value Function Update Magnitude: 0.34661

Collected Steps per Second: 22,184.14856
Overall Steps per Second: 10,544.21191

Timestep Collection Time: 2.25539
Timestep Consumption Time: 2.48977
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.74516

Cumulative Model Updates: 132,334
Cumulative Timesteps: 1,104,454,152

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1104454152...
Checkpoint 1104454152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,791.89273
Policy Entropy: 1.64721
Value Function Loss: 0.05347

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.31223
Value Function Update Magnitude: 0.36069

Collected Steps per Second: 21,811.80440
Overall Steps per Second: 10,548.48516

Timestep Collection Time: 2.29252
Timestep Consumption Time: 2.44788
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.74040

Cumulative Model Updates: 132,340
Cumulative Timesteps: 1,104,504,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,344.02277
Policy Entropy: 1.66425
Value Function Loss: 0.05276

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.31141
Value Function Update Magnitude: 0.37900

Collected Steps per Second: 21,814.15266
Overall Steps per Second: 10,446.11030

Timestep Collection Time: 2.29347
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.78934

Cumulative Model Updates: 132,346
Cumulative Timesteps: 1,104,554,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1104554186...
Checkpoint 1104554186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,583.79138
Policy Entropy: 1.65738
Value Function Loss: 0.05471

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.31205
Value Function Update Magnitude: 0.36541

Collected Steps per Second: 21,920.96853
Overall Steps per Second: 10,597.02934

Timestep Collection Time: 2.28138
Timestep Consumption Time: 2.43787
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.71925

Cumulative Model Updates: 132,352
Cumulative Timesteps: 1,104,604,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,563.62443
Policy Entropy: 1.67235
Value Function Loss: 0.05510

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.34061

Collected Steps per Second: 21,426.65566
Overall Steps per Second: 10,480.56587

Timestep Collection Time: 2.33364
Timestep Consumption Time: 2.43729
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.77093

Cumulative Model Updates: 132,358
Cumulative Timesteps: 1,104,654,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1104654198...
Checkpoint 1104654198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,873.43359
Policy Entropy: 1.67750
Value Function Loss: 0.05590

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.30677
Value Function Update Magnitude: 0.34794

Collected Steps per Second: 21,432.81306
Overall Steps per Second: 10,367.84512

Timestep Collection Time: 2.33502
Timestep Consumption Time: 2.49202
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.82704

Cumulative Model Updates: 132,364
Cumulative Timesteps: 1,104,704,244

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,896.04453
Policy Entropy: 1.67086
Value Function Loss: 0.05426

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.30969
Value Function Update Magnitude: 0.34456

Collected Steps per Second: 21,758.00468
Overall Steps per Second: 10,394.32680

Timestep Collection Time: 2.29920
Timestep Consumption Time: 2.51362
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.81282

Cumulative Model Updates: 132,370
Cumulative Timesteps: 1,104,754,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1104754270...
Checkpoint 1104754270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,714.12515
Policy Entropy: 1.67866
Value Function Loss: 0.05603

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.30728
Value Function Update Magnitude: 0.30309

Collected Steps per Second: 21,669.55982
Overall Steps per Second: 10,518.25947

Timestep Collection Time: 2.30941
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.75782

Cumulative Model Updates: 132,376
Cumulative Timesteps: 1,104,804,314

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,375.29272
Policy Entropy: 1.66471
Value Function Loss: 0.05922

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.31385
Value Function Update Magnitude: 0.28009

Collected Steps per Second: 21,839.49165
Overall Steps per Second: 10,512.53404

Timestep Collection Time: 2.29135
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.76022

Cumulative Model Updates: 132,382
Cumulative Timesteps: 1,104,854,356

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1104854356...
Checkpoint 1104854356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,648.23594
Policy Entropy: 1.66785
Value Function Loss: 0.05617

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.31151
Value Function Update Magnitude: 0.29536

Collected Steps per Second: 22,127.67606
Overall Steps per Second: 10,667.20549

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.42891
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.68970

Cumulative Model Updates: 132,388
Cumulative Timesteps: 1,104,904,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,915.87358
Policy Entropy: 1.65717
Value Function Loss: 0.05328

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.30775
Value Function Update Magnitude: 0.31771

Collected Steps per Second: 22,173.39438
Overall Steps per Second: 10,489.84026

Timestep Collection Time: 2.25523
Timestep Consumption Time: 2.51186
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.76709

Cumulative Model Updates: 132,394
Cumulative Timesteps: 1,104,954,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1104954388...
Checkpoint 1104954388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,567.39668
Policy Entropy: 1.65721
Value Function Loss: 0.05274

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07510
Policy Update Magnitude: 0.31243
Value Function Update Magnitude: 0.32955

Collected Steps per Second: 21,813.04962
Overall Steps per Second: 10,609.82575

Timestep Collection Time: 2.29340
Timestep Consumption Time: 2.42167
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.71506

Cumulative Model Updates: 132,400
Cumulative Timesteps: 1,105,004,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,444.17711
Policy Entropy: 1.65514
Value Function Loss: 0.05366

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.30958
Value Function Update Magnitude: 0.33294

Collected Steps per Second: 22,194.50952
Overall Steps per Second: 10,549.73214

Timestep Collection Time: 2.25416
Timestep Consumption Time: 2.48814
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.74230

Cumulative Model Updates: 132,406
Cumulative Timesteps: 1,105,054,444

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1105054444...
Checkpoint 1105054444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,294.16239
Policy Entropy: 1.67132
Value Function Loss: 0.05338

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07327
Policy Update Magnitude: 0.30567
Value Function Update Magnitude: 0.31869

Collected Steps per Second: 21,501.01338
Overall Steps per Second: 10,501.73040

Timestep Collection Time: 2.32603
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.76226

Cumulative Model Updates: 132,412
Cumulative Timesteps: 1,105,104,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,672.93039
Policy Entropy: 1.68423
Value Function Loss: 0.05413

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.30416
Value Function Update Magnitude: 0.30664

Collected Steps per Second: 21,325.76918
Overall Steps per Second: 10,438.00695

Timestep Collection Time: 2.34580
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.79268

Cumulative Model Updates: 132,418
Cumulative Timesteps: 1,105,154,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1105154482...
Checkpoint 1105154482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,818.46998
Policy Entropy: 1.68145
Value Function Loss: 0.05124

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.30192
Value Function Update Magnitude: 0.28413

Collected Steps per Second: 20,869.37312
Overall Steps per Second: 10,563.20483

Timestep Collection Time: 2.39729
Timestep Consumption Time: 2.33896
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.73625

Cumulative Model Updates: 132,424
Cumulative Timesteps: 1,105,204,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,370.28229
Policy Entropy: 1.67985
Value Function Loss: 0.05321

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.30367
Value Function Update Magnitude: 0.27469

Collected Steps per Second: 21,044.45034
Overall Steps per Second: 10,288.65736

Timestep Collection Time: 2.37668
Timestep Consumption Time: 2.48459
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.86128

Cumulative Model Updates: 132,430
Cumulative Timesteps: 1,105,254,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1105254528...
Checkpoint 1105254528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,892.13495
Policy Entropy: 1.68267
Value Function Loss: 0.05538

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.30732
Value Function Update Magnitude: 0.27734

Collected Steps per Second: 21,496.81912
Overall Steps per Second: 10,462.63962

Timestep Collection Time: 2.32816
Timestep Consumption Time: 2.45534
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.78350

Cumulative Model Updates: 132,436
Cumulative Timesteps: 1,105,304,576

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,512.08797
Policy Entropy: 1.69358
Value Function Loss: 0.05668

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07677
Policy Update Magnitude: 0.31074
Value Function Update Magnitude: 0.27751

Collected Steps per Second: 22,013.54011
Overall Steps per Second: 10,444.00509

Timestep Collection Time: 2.27242
Timestep Consumption Time: 2.51731
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.78973

Cumulative Model Updates: 132,442
Cumulative Timesteps: 1,105,354,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1105354600...
Checkpoint 1105354600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,457.73045
Policy Entropy: 1.69471
Value Function Loss: 0.05744

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.31078
Value Function Update Magnitude: 0.31614

Collected Steps per Second: 22,132.13719
Overall Steps per Second: 10,551.75684

Timestep Collection Time: 2.25979
Timestep Consumption Time: 2.48008
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.73987

Cumulative Model Updates: 132,448
Cumulative Timesteps: 1,105,404,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,996.25019
Policy Entropy: 1.67822
Value Function Loss: 0.05604

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07063
Policy Update Magnitude: 0.31062
Value Function Update Magnitude: 0.34528

Collected Steps per Second: 21,842.09561
Overall Steps per Second: 10,580.70910

Timestep Collection Time: 2.29035
Timestep Consumption Time: 2.43769
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.72804

Cumulative Model Updates: 132,454
Cumulative Timesteps: 1,105,454,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1105454640...
Checkpoint 1105454640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,326.67286
Policy Entropy: 1.67473
Value Function Loss: 0.05876

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.31668
Value Function Update Magnitude: 0.34328

Collected Steps per Second: 21,893.02590
Overall Steps per Second: 10,572.51158

Timestep Collection Time: 2.28484
Timestep Consumption Time: 2.44649
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.73133

Cumulative Model Updates: 132,460
Cumulative Timesteps: 1,105,504,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,180.11429
Policy Entropy: 1.67103
Value Function Loss: 0.05298

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.30428
Value Function Update Magnitude: 0.30671

Collected Steps per Second: 21,898.15053
Overall Steps per Second: 10,451.39815

Timestep Collection Time: 2.28430
Timestep Consumption Time: 2.50185
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.78615

Cumulative Model Updates: 132,466
Cumulative Timesteps: 1,105,554,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1105554684...
Checkpoint 1105554684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,336.94840
Policy Entropy: 1.68638
Value Function Loss: 0.05222

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.29576
Value Function Update Magnitude: 0.29418

Collected Steps per Second: 21,861.44243
Overall Steps per Second: 10,585.22346

Timestep Collection Time: 2.28832
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.72602

Cumulative Model Updates: 132,472
Cumulative Timesteps: 1,105,604,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,468.71220
Policy Entropy: 1.68006
Value Function Loss: 0.05718

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.29309
Value Function Update Magnitude: 0.29853

Collected Steps per Second: 21,747.98152
Overall Steps per Second: 10,538.83229

Timestep Collection Time: 2.30063
Timestep Consumption Time: 2.44696
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.74758

Cumulative Model Updates: 132,478
Cumulative Timesteps: 1,105,654,744

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1105654744...
Checkpoint 1105654744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,866.87687
Policy Entropy: 1.68322
Value Function Loss: 0.06229

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.30625
Value Function Update Magnitude: 0.33352

Collected Steps per Second: 21,622.19853
Overall Steps per Second: 10,570.76195

Timestep Collection Time: 2.31244
Timestep Consumption Time: 2.41759
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.73003

Cumulative Model Updates: 132,484
Cumulative Timesteps: 1,105,704,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,280.46731
Policy Entropy: 1.67633
Value Function Loss: 0.05965

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.30300
Value Function Update Magnitude: 0.36517

Collected Steps per Second: 21,738.29172
Overall Steps per Second: 10,561.56745

Timestep Collection Time: 2.30165
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.73737

Cumulative Model Updates: 132,490
Cumulative Timesteps: 1,105,754,778

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1105754778...
Checkpoint 1105754778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,491.03769
Policy Entropy: 1.66810
Value Function Loss: 0.05445

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09669
Policy Update Magnitude: 0.30755
Value Function Update Magnitude: 0.34546

Collected Steps per Second: 21,466.55344
Overall Steps per Second: 10,499.77364

Timestep Collection Time: 2.32930
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.76220

Cumulative Model Updates: 132,496
Cumulative Timesteps: 1,105,804,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,763.94035
Policy Entropy: 1.66844
Value Function Loss: 0.05113

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.30976
Value Function Update Magnitude: 0.31623

Collected Steps per Second: 21,718.17146
Overall Steps per Second: 10,535.62063

Timestep Collection Time: 2.30222
Timestep Consumption Time: 2.44359
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.74580

Cumulative Model Updates: 132,502
Cumulative Timesteps: 1,105,854,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1105854780...
Checkpoint 1105854780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,164.52969
Policy Entropy: 1.68338
Value Function Loss: 0.05302

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.31077
Value Function Update Magnitude: 0.31588

Collected Steps per Second: 21,901.98609
Overall Steps per Second: 10,599.10232

Timestep Collection Time: 2.28354
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.71870

Cumulative Model Updates: 132,508
Cumulative Timesteps: 1,105,904,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,722.33479
Policy Entropy: 1.69756
Value Function Loss: 0.04955

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.30627
Value Function Update Magnitude: 0.31493

Collected Steps per Second: 22,038.80393
Overall Steps per Second: 10,483.35536

Timestep Collection Time: 2.26972
Timestep Consumption Time: 2.50184
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.77156

Cumulative Model Updates: 132,514
Cumulative Timesteps: 1,105,954,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1105954816...
Checkpoint 1105954816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,022.25702
Policy Entropy: 1.68426
Value Function Loss: 0.05013

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08103
Policy Update Magnitude: 0.30187
Value Function Update Magnitude: 0.30537

Collected Steps per Second: 21,794.33867
Overall Steps per Second: 10,571.59724

Timestep Collection Time: 2.29463
Timestep Consumption Time: 2.43597
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.73060

Cumulative Model Updates: 132,520
Cumulative Timesteps: 1,106,004,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,688.98828
Policy Entropy: 1.67130
Value Function Loss: 0.05087

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.30487
Value Function Update Magnitude: 0.30932

Collected Steps per Second: 22,044.22747
Overall Steps per Second: 10,505.72496

Timestep Collection Time: 2.26889
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.76083

Cumulative Model Updates: 132,526
Cumulative Timesteps: 1,106,054,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1106054842...
Checkpoint 1106054842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,483.27705
Policy Entropy: 1.65482
Value Function Loss: 0.05037

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.30599
Value Function Update Magnitude: 0.31329

Collected Steps per Second: 21,772.58520
Overall Steps per Second: 10,603.63446

Timestep Collection Time: 2.29674
Timestep Consumption Time: 2.41919
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.71593

Cumulative Model Updates: 132,532
Cumulative Timesteps: 1,106,104,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,681.73792
Policy Entropy: 1.66945
Value Function Loss: 0.05203

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.30531
Value Function Update Magnitude: 0.31211

Collected Steps per Second: 22,057.44851
Overall Steps per Second: 10,519.44768

Timestep Collection Time: 2.26735
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.75424

Cumulative Model Updates: 132,538
Cumulative Timesteps: 1,106,154,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1106154860...
Checkpoint 1106154860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,215.70470
Policy Entropy: 1.66618
Value Function Loss: 0.05233

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.31265
Value Function Update Magnitude: 0.32290

Collected Steps per Second: 21,845.11954
Overall Steps per Second: 10,598.06254

Timestep Collection Time: 2.29113
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.72256

Cumulative Model Updates: 132,544
Cumulative Timesteps: 1,106,204,910

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,890.19071
Policy Entropy: 1.66757
Value Function Loss: 0.05267

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.31375
Value Function Update Magnitude: 0.33860

Collected Steps per Second: 21,270.29351
Overall Steps per Second: 10,455.10415

Timestep Collection Time: 2.35107
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.78312

Cumulative Model Updates: 132,550
Cumulative Timesteps: 1,106,254,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1106254918...
Checkpoint 1106254918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,902.43069
Policy Entropy: 1.65888
Value Function Loss: 0.05389

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.31398
Value Function Update Magnitude: 0.33564

Collected Steps per Second: 20,717.48176
Overall Steps per Second: 10,343.88260

Timestep Collection Time: 2.41439
Timestep Consumption Time: 2.42132
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.83571

Cumulative Model Updates: 132,556
Cumulative Timesteps: 1,106,304,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,391.78821
Policy Entropy: 1.66009
Value Function Loss: 0.05220

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.31210
Value Function Update Magnitude: 0.34378

Collected Steps per Second: 21,196.74878
Overall Steps per Second: 10,445.95960

Timestep Collection Time: 2.36074
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.79037

Cumulative Model Updates: 132,562
Cumulative Timesteps: 1,106,354,978

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1106354978...
Checkpoint 1106354978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,411.03888
Policy Entropy: 1.66355
Value Function Loss: 0.05278

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.31082
Value Function Update Magnitude: 0.34725

Collected Steps per Second: 20,959.85569
Overall Steps per Second: 10,515.67153

Timestep Collection Time: 2.38780
Timestep Consumption Time: 2.37157
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.75937

Cumulative Model Updates: 132,568
Cumulative Timesteps: 1,106,405,026

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,210.22350
Policy Entropy: 1.67156
Value Function Loss: 0.05160

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07932
Policy Update Magnitude: 0.30939
Value Function Update Magnitude: 0.34000

Collected Steps per Second: 21,439.91744
Overall Steps per Second: 10,504.01479

Timestep Collection Time: 2.33229
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.76047

Cumulative Model Updates: 132,574
Cumulative Timesteps: 1,106,455,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1106455030...
Checkpoint 1106455030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,766.29974
Policy Entropy: 1.68954
Value Function Loss: 0.05300

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.30868
Value Function Update Magnitude: 0.31381

Collected Steps per Second: 21,511.85307
Overall Steps per Second: 10,362.19212

Timestep Collection Time: 2.32495
Timestep Consumption Time: 2.50163
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.82658

Cumulative Model Updates: 132,580
Cumulative Timesteps: 1,106,505,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,321.90719
Policy Entropy: 1.68637
Value Function Loss: 0.05083

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.29945
Value Function Update Magnitude: 0.28218

Collected Steps per Second: 22,138.40313
Overall Steps per Second: 10,690.62795

Timestep Collection Time: 2.25915
Timestep Consumption Time: 2.41915
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.67830

Cumulative Model Updates: 132,586
Cumulative Timesteps: 1,106,555,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1106555058...
Checkpoint 1106555058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,435.83337
Policy Entropy: 1.67499
Value Function Loss: 0.05068

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.28519
Value Function Update Magnitude: 0.28687

Collected Steps per Second: 21,972.29602
Overall Steps per Second: 10,681.14941

Timestep Collection Time: 2.27650
Timestep Consumption Time: 2.40651
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.68302

Cumulative Model Updates: 132,592
Cumulative Timesteps: 1,106,605,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,778.40874
Policy Entropy: 1.65186
Value Function Loss: 0.05411

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.30489
Value Function Update Magnitude: 0.28903

Collected Steps per Second: 21,841.69917
Overall Steps per Second: 10,439.59573

Timestep Collection Time: 2.29002
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.79118

Cumulative Model Updates: 132,598
Cumulative Timesteps: 1,106,655,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1106655096...
Checkpoint 1106655096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,915.76333
Policy Entropy: 1.66323
Value Function Loss: 0.05528

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.31501
Value Function Update Magnitude: 0.32375

Collected Steps per Second: 21,963.75077
Overall Steps per Second: 10,594.39670

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.44397
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.72136

Cumulative Model Updates: 132,604
Cumulative Timesteps: 1,106,705,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,493.64553
Policy Entropy: 1.66177
Value Function Loss: 0.05220

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.31066
Value Function Update Magnitude: 0.33173

Collected Steps per Second: 21,627.99035
Overall Steps per Second: 10,479.82395

Timestep Collection Time: 2.31265
Timestep Consumption Time: 2.46014
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.77279

Cumulative Model Updates: 132,610
Cumulative Timesteps: 1,106,755,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1106755134...
Checkpoint 1106755134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,698.79943
Policy Entropy: 1.68053
Value Function Loss: 0.04856

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.30425
Value Function Update Magnitude: 0.29632

Collected Steps per Second: 21,523.12547
Overall Steps per Second: 10,381.18898

Timestep Collection Time: 2.32476
Timestep Consumption Time: 2.49512
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.81987

Cumulative Model Updates: 132,616
Cumulative Timesteps: 1,106,805,170

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,025.35747
Policy Entropy: 1.68964
Value Function Loss: 0.05380

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.30972
Value Function Update Magnitude: 0.29172

Collected Steps per Second: 21,601.02710
Overall Steps per Second: 10,352.96425

Timestep Collection Time: 2.31665
Timestep Consumption Time: 2.51694
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.83359

Cumulative Model Updates: 132,622
Cumulative Timesteps: 1,106,855,212

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1106855212...
Checkpoint 1106855212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,362.88755
Policy Entropy: 1.68955
Value Function Loss: 0.05557

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.31467
Value Function Update Magnitude: 0.30530

Collected Steps per Second: 21,871.18900
Overall Steps per Second: 10,595.52107

Timestep Collection Time: 2.28721
Timestep Consumption Time: 2.43403
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.72124

Cumulative Model Updates: 132,628
Cumulative Timesteps: 1,106,905,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,019.29196
Policy Entropy: 1.69630
Value Function Loss: 0.06170

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.31851
Value Function Update Magnitude: 0.31697

Collected Steps per Second: 21,851.53004
Overall Steps per Second: 10,445.98716

Timestep Collection Time: 2.28991
Timestep Consumption Time: 2.50026
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.79016

Cumulative Model Updates: 132,634
Cumulative Timesteps: 1,106,955,274

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1106955274...
Checkpoint 1106955274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,068.79651
Policy Entropy: 1.69093
Value Function Loss: 0.05973

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.32531
Value Function Update Magnitude: 0.33297

Collected Steps per Second: 22,021.08681
Overall Steps per Second: 10,393.67752

Timestep Collection Time: 2.27191
Timestep Consumption Time: 2.54159
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.81350

Cumulative Model Updates: 132,640
Cumulative Timesteps: 1,107,005,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,390.70518
Policy Entropy: 1.69611
Value Function Loss: 0.06633

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.32877
Value Function Update Magnitude: 0.34068

Collected Steps per Second: 22,179.98182
Overall Steps per Second: 10,633.82700

Timestep Collection Time: 2.25456
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.70254

Cumulative Model Updates: 132,646
Cumulative Timesteps: 1,107,055,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1107055310...
Checkpoint 1107055310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,849.58271
Policy Entropy: 1.69953
Value Function Loss: 0.06323

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.32858
Value Function Update Magnitude: 0.32589

Collected Steps per Second: 21,869.11422
Overall Steps per Second: 10,481.96945

Timestep Collection Time: 2.28761
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.77277

Cumulative Model Updates: 132,652
Cumulative Timesteps: 1,107,105,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,928.65199
Policy Entropy: 1.68676
Value Function Loss: 0.06100

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.30903
Value Function Update Magnitude: 0.33065

Collected Steps per Second: 21,970.90386
Overall Steps per Second: 10,612.46170

Timestep Collection Time: 2.27619
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.71238

Cumulative Model Updates: 132,658
Cumulative Timesteps: 1,107,155,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1107155348...
Checkpoint 1107155348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,235.95735
Policy Entropy: 1.67784
Value Function Loss: 0.05697

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09739
Policy Update Magnitude: 0.28740
Value Function Update Magnitude: 0.32716

Collected Steps per Second: 21,924.10199
Overall Steps per Second: 10,627.32235

Timestep Collection Time: 2.28205
Timestep Consumption Time: 2.42581
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.70787

Cumulative Model Updates: 132,664
Cumulative Timesteps: 1,107,205,380

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,628.69124
Policy Entropy: 1.67561
Value Function Loss: 0.05782

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.29854
Value Function Update Magnitude: 0.31481

Collected Steps per Second: 22,162.13565
Overall Steps per Second: 10,594.98958

Timestep Collection Time: 2.25700
Timestep Consumption Time: 2.46410
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.72110

Cumulative Model Updates: 132,670
Cumulative Timesteps: 1,107,255,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1107255400...
Checkpoint 1107255400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,001.18034
Policy Entropy: 1.69447
Value Function Loss: 0.05522

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.31101
Value Function Update Magnitude: 0.33009

Collected Steps per Second: 21,888.42287
Overall Steps per Second: 10,607.06790

Timestep Collection Time: 2.28495
Timestep Consumption Time: 2.43021
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.71516

Cumulative Model Updates: 132,676
Cumulative Timesteps: 1,107,305,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,030.30778
Policy Entropy: 1.69373
Value Function Loss: 0.05468

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.30728
Value Function Update Magnitude: 0.32596

Collected Steps per Second: 21,520.86176
Overall Steps per Second: 10,511.26372

Timestep Collection Time: 2.32491
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.76004

Cumulative Model Updates: 132,682
Cumulative Timesteps: 1,107,355,448

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1107355448...
Checkpoint 1107355448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,514.86908
Policy Entropy: 1.69599
Value Function Loss: 0.05763

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.30551
Value Function Update Magnitude: 0.34592

Collected Steps per Second: 21,626.71306
Overall Steps per Second: 10,549.00456

Timestep Collection Time: 2.31316
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.74225

Cumulative Model Updates: 132,688
Cumulative Timesteps: 1,107,405,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,906.53117
Policy Entropy: 1.70263
Value Function Loss: 0.06563

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.31736
Value Function Update Magnitude: 0.37791

Collected Steps per Second: 21,789.03714
Overall Steps per Second: 10,491.43803

Timestep Collection Time: 2.29528
Timestep Consumption Time: 2.47165
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.76693

Cumulative Model Updates: 132,694
Cumulative Timesteps: 1,107,455,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1107455486...
Checkpoint 1107455486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,707.85803
Policy Entropy: 1.70496
Value Function Loss: 0.06356

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.32397
Value Function Update Magnitude: 0.39584

Collected Steps per Second: 21,100.75240
Overall Steps per Second: 10,599.79726

Timestep Collection Time: 2.37044
Timestep Consumption Time: 2.34833
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.71877

Cumulative Model Updates: 132,700
Cumulative Timesteps: 1,107,505,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,952.64545
Policy Entropy: 1.68757
Value Function Loss: 0.06021

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.30836
Value Function Update Magnitude: 0.38635

Collected Steps per Second: 21,327.12982
Overall Steps per Second: 10,440.31984

Timestep Collection Time: 2.34499
Timestep Consumption Time: 2.44528
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.79027

Cumulative Model Updates: 132,706
Cumulative Timesteps: 1,107,555,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1107555516...
Checkpoint 1107555516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,288.75028
Policy Entropy: 1.68304
Value Function Loss: 0.05522

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.30932
Value Function Update Magnitude: 0.35033

Collected Steps per Second: 21,361.49240
Overall Steps per Second: 10,603.36064

Timestep Collection Time: 2.34197
Timestep Consumption Time: 2.37616
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.71813

Cumulative Model Updates: 132,712
Cumulative Timesteps: 1,107,605,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,153.05652
Policy Entropy: 1.68166
Value Function Loss: 0.05427

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.29171
Value Function Update Magnitude: 0.30989

Collected Steps per Second: 21,341.17515
Overall Steps per Second: 10,562.37357

Timestep Collection Time: 2.34476
Timestep Consumption Time: 2.39281
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.73757

Cumulative Model Updates: 132,718
Cumulative Timesteps: 1,107,655,584

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1107655584...
Checkpoint 1107655584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,781.16125
Policy Entropy: 1.68701
Value Function Loss: 0.05568

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.30029
Value Function Update Magnitude: 0.30869

Collected Steps per Second: 21,094.48926
Overall Steps per Second: 10,568.12708

Timestep Collection Time: 2.37029
Timestep Consumption Time: 2.36092
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.73121

Cumulative Model Updates: 132,724
Cumulative Timesteps: 1,107,705,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,729.01462
Policy Entropy: 1.69002
Value Function Loss: 0.05766

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.31055
Value Function Update Magnitude: 0.32576

Collected Steps per Second: 21,569.07149
Overall Steps per Second: 10,575.57334

Timestep Collection Time: 2.31962
Timestep Consumption Time: 2.41128
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.73090

Cumulative Model Updates: 132,730
Cumulative Timesteps: 1,107,755,616

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1107755616...
Checkpoint 1107755616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,382.79577
Policy Entropy: 1.70453
Value Function Loss: 0.06174

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.31224
Value Function Update Magnitude: 0.34336

Collected Steps per Second: 21,942.83708
Overall Steps per Second: 10,539.77259

Timestep Collection Time: 2.27901
Timestep Consumption Time: 2.46568
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.74469

Cumulative Model Updates: 132,736
Cumulative Timesteps: 1,107,805,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,641.41645
Policy Entropy: 1.68911
Value Function Loss: 0.05844

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.30283
Value Function Update Magnitude: 0.34375

Collected Steps per Second: 22,135.24417
Overall Steps per Second: 10,542.56851

Timestep Collection Time: 2.25929
Timestep Consumption Time: 2.48433
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.74363

Cumulative Model Updates: 132,742
Cumulative Timesteps: 1,107,855,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1107855634...
Checkpoint 1107855634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,566.42462
Policy Entropy: 1.70051
Value Function Loss: 0.06336

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.31709
Value Function Update Magnitude: 0.32485

Collected Steps per Second: 21,309.40598
Overall Steps per Second: 10,508.50055

Timestep Collection Time: 2.34657
Timestep Consumption Time: 2.41186
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.75843

Cumulative Model Updates: 132,748
Cumulative Timesteps: 1,107,905,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,186.25361
Policy Entropy: 1.67777
Value Function Loss: 0.06551

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.31654
Value Function Update Magnitude: 0.33644

Collected Steps per Second: 21,717.42004
Overall Steps per Second: 10,503.37246

Timestep Collection Time: 2.30294
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.76171

Cumulative Model Updates: 132,754
Cumulative Timesteps: 1,107,955,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1107955652...
Checkpoint 1107955652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,296.95442
Policy Entropy: 1.70102
Value Function Loss: 0.06863

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.30276
Value Function Update Magnitude: 0.36868

Collected Steps per Second: 21,510.75292
Overall Steps per Second: 10,573.11748

Timestep Collection Time: 2.32470
Timestep Consumption Time: 2.40484
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.72954

Cumulative Model Updates: 132,760
Cumulative Timesteps: 1,108,005,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,323.13276
Policy Entropy: 1.71094
Value Function Loss: 0.06369

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.30801
Value Function Update Magnitude: 0.36450

Collected Steps per Second: 21,976.06514
Overall Steps per Second: 10,614.05061

Timestep Collection Time: 2.27548
Timestep Consumption Time: 2.43583
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.71130

Cumulative Model Updates: 132,766
Cumulative Timesteps: 1,108,055,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1108055664...
Checkpoint 1108055664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,581.24678
Policy Entropy: 1.72648
Value Function Loss: 0.06701

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.29913
Value Function Update Magnitude: 0.30624

Collected Steps per Second: 21,604.21676
Overall Steps per Second: 10,508.04560

Timestep Collection Time: 2.31510
Timestep Consumption Time: 2.44468
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.75978

Cumulative Model Updates: 132,772
Cumulative Timesteps: 1,108,105,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,544.05160
Policy Entropy: 1.72098
Value Function Loss: 0.06856

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.31545
Value Function Update Magnitude: 0.27538

Collected Steps per Second: 22,111.72599
Overall Steps per Second: 10,458.63899

Timestep Collection Time: 2.26133
Timestep Consumption Time: 2.51959
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.78093

Cumulative Model Updates: 132,778
Cumulative Timesteps: 1,108,155,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1108155682...
Checkpoint 1108155682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,695.13406
Policy Entropy: 1.74753
Value Function Loss: 0.08626

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.33316
Value Function Update Magnitude: 0.26696

Collected Steps per Second: 21,672.61021
Overall Steps per Second: 10,409.85820

Timestep Collection Time: 2.30780
Timestep Consumption Time: 2.49688
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.80468

Cumulative Model Updates: 132,784
Cumulative Timesteps: 1,108,205,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,254.00594
Policy Entropy: 1.76785
Value Function Loss: 0.08907

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.33039
Value Function Update Magnitude: 0.30356

Collected Steps per Second: 22,247.57630
Overall Steps per Second: 10,732.10668

Timestep Collection Time: 2.24833
Timestep Consumption Time: 2.41245
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.66078

Cumulative Model Updates: 132,790
Cumulative Timesteps: 1,108,255,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1108255718...
Checkpoint 1108255718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,896.21537
Policy Entropy: 1.77347
Value Function Loss: 0.08702

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.29921
Value Function Update Magnitude: 0.29095

Collected Steps per Second: 21,682.98658
Overall Steps per Second: 10,598.92220

Timestep Collection Time: 2.30596
Timestep Consumption Time: 2.41151
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.71746

Cumulative Model Updates: 132,796
Cumulative Timesteps: 1,108,305,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,881.34471
Policy Entropy: 1.75169
Value Function Loss: 0.07768

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.28656
Value Function Update Magnitude: 0.26174

Collected Steps per Second: 22,155.62611
Overall Steps per Second: 10,483.96222

Timestep Collection Time: 2.25776
Timestep Consumption Time: 2.51353
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.77129

Cumulative Model Updates: 132,802
Cumulative Timesteps: 1,108,355,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1108355740...
Checkpoint 1108355740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,132.87571
Policy Entropy: 1.71680
Value Function Loss: 0.06798

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.28426
Value Function Update Magnitude: 0.27077

Collected Steps per Second: 20,318.04007
Overall Steps per Second: 10,171.27095

Timestep Collection Time: 2.46234
Timestep Consumption Time: 2.45641
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.91876

Cumulative Model Updates: 132,808
Cumulative Timesteps: 1,108,405,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,928.75842
Policy Entropy: 1.68589
Value Function Loss: 0.06260

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.30379
Value Function Update Magnitude: 0.32232

Collected Steps per Second: 22,034.31911
Overall Steps per Second: 10,503.05764

Timestep Collection Time: 2.26928
Timestep Consumption Time: 2.49143
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.76071

Cumulative Model Updates: 132,814
Cumulative Timesteps: 1,108,455,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1108455772...
Checkpoint 1108455772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,783.12729
Policy Entropy: 1.68114
Value Function Loss: 0.06101

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.31085
Value Function Update Magnitude: 0.32291

Collected Steps per Second: 21,189.48483
Overall Steps per Second: 10,273.13140

Timestep Collection Time: 2.36004
Timestep Consumption Time: 2.50781
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.86784

Cumulative Model Updates: 132,820
Cumulative Timesteps: 1,108,505,780

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,530.66095
Policy Entropy: 1.68807
Value Function Loss: 0.05999

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.31613
Value Function Update Magnitude: 0.32472

Collected Steps per Second: 21,718.33403
Overall Steps per Second: 10,377.86523

Timestep Collection Time: 2.30349
Timestep Consumption Time: 2.51715
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.82064

Cumulative Model Updates: 132,826
Cumulative Timesteps: 1,108,555,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1108555808...
Checkpoint 1108555808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,599.84115
Policy Entropy: 1.73355
Value Function Loss: 0.06634

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.31679
Value Function Update Magnitude: 0.29797

Collected Steps per Second: 21,293.29674
Overall Steps per Second: 10,323.93545

Timestep Collection Time: 2.35022
Timestep Consumption Time: 2.49715
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.84738

Cumulative Model Updates: 132,832
Cumulative Timesteps: 1,108,605,852

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,120.44072
Policy Entropy: 1.70384
Value Function Loss: 0.06440

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.31759
Value Function Update Magnitude: 0.28272

Collected Steps per Second: 21,508.25579
Overall Steps per Second: 10,336.83667

Timestep Collection Time: 2.32497
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.83765

Cumulative Model Updates: 132,838
Cumulative Timesteps: 1,108,655,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1108655858...
Checkpoint 1108655858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,071.93830
Policy Entropy: 1.71156
Value Function Loss: 0.06559

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.31699
Value Function Update Magnitude: 0.30568

Collected Steps per Second: 21,311.98153
Overall Steps per Second: 10,340.90251

Timestep Collection Time: 2.34732
Timestep Consumption Time: 2.49036
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.83768

Cumulative Model Updates: 132,844
Cumulative Timesteps: 1,108,705,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,816.08691
Policy Entropy: 1.68941
Value Function Loss: 0.06185

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.31960
Value Function Update Magnitude: 0.28086

Collected Steps per Second: 22,413.54054
Overall Steps per Second: 10,672.33581

Timestep Collection Time: 2.23088
Timestep Consumption Time: 2.45431
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.68520

Cumulative Model Updates: 132,850
Cumulative Timesteps: 1,108,755,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1108755886...
Checkpoint 1108755886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,067.08290
Policy Entropy: 1.71493
Value Function Loss: 0.06294

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.31737
Value Function Update Magnitude: 0.31080

Collected Steps per Second: 21,175.63771
Overall Steps per Second: 10,444.39012

Timestep Collection Time: 2.36262
Timestep Consumption Time: 2.42751
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.79013

Cumulative Model Updates: 132,856
Cumulative Timesteps: 1,108,805,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,606.07838
Policy Entropy: 1.71378
Value Function Loss: 0.06046

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.31530
Value Function Update Magnitude: 0.33927

Collected Steps per Second: 21,715.34557
Overall Steps per Second: 10,758.14922

Timestep Collection Time: 2.30307
Timestep Consumption Time: 2.34568
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.64876

Cumulative Model Updates: 132,862
Cumulative Timesteps: 1,108,855,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1108855928...
Checkpoint 1108855928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,127.16372
Policy Entropy: 1.71184
Value Function Loss: 0.06191

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.31830
Value Function Update Magnitude: 0.36212

Collected Steps per Second: 21,115.69322
Overall Steps per Second: 10,572.90637

Timestep Collection Time: 2.36904
Timestep Consumption Time: 2.36229
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.73134

Cumulative Model Updates: 132,868
Cumulative Timesteps: 1,108,905,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,655.03709
Policy Entropy: 1.69840
Value Function Loss: 0.05789

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.31542
Value Function Update Magnitude: 0.37390

Collected Steps per Second: 21,351.13500
Overall Steps per Second: 10,467.50094

Timestep Collection Time: 2.34273
Timestep Consumption Time: 2.43587
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.77860

Cumulative Model Updates: 132,874
Cumulative Timesteps: 1,108,955,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1108955972...
Checkpoint 1108955972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,262.91309
Policy Entropy: 1.72161
Value Function Loss: 0.06405

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.36347

Collected Steps per Second: 21,514.43852
Overall Steps per Second: 10,565.43301

Timestep Collection Time: 2.32421
Timestep Consumption Time: 2.40859
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.73279

Cumulative Model Updates: 132,880
Cumulative Timesteps: 1,109,005,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,319.55168
Policy Entropy: 1.72584
Value Function Loss: 0.05964

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.31129
Value Function Update Magnitude: 0.34423

Collected Steps per Second: 21,993.90029
Overall Steps per Second: 10,529.17855

Timestep Collection Time: 2.27499
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.75213

Cumulative Model Updates: 132,886
Cumulative Timesteps: 1,109,056,012

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1109056012...
Checkpoint 1109056012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,212.32687
Policy Entropy: 1.72612
Value Function Loss: 0.05981

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.30067
Value Function Update Magnitude: 0.34829

Collected Steps per Second: 21,329.78391
Overall Steps per Second: 10,559.07974

Timestep Collection Time: 2.34555
Timestep Consumption Time: 2.39256
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73810

Cumulative Model Updates: 132,892
Cumulative Timesteps: 1,109,106,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,467.92428
Policy Entropy: 1.68161
Value Function Loss: 0.05556

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.29770
Value Function Update Magnitude: 0.35190

Collected Steps per Second: 21,623.29011
Overall Steps per Second: 10,624.00537

Timestep Collection Time: 2.31315
Timestep Consumption Time: 2.39486
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.70802

Cumulative Model Updates: 132,898
Cumulative Timesteps: 1,109,156,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1109156060...
Checkpoint 1109156060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,731.07204
Policy Entropy: 1.68938
Value Function Loss: 0.05825

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.30279
Value Function Update Magnitude: 0.36526

Collected Steps per Second: 21,245.79567
Overall Steps per Second: 10,297.33684

Timestep Collection Time: 2.35341
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.85562

Cumulative Model Updates: 132,904
Cumulative Timesteps: 1,109,206,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,801.87566
Policy Entropy: 1.68905
Value Function Loss: 0.05589

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.31382
Value Function Update Magnitude: 0.37645

Collected Steps per Second: 21,904.33513
Overall Steps per Second: 10,499.33678

Timestep Collection Time: 2.28311
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.76316

Cumulative Model Updates: 132,910
Cumulative Timesteps: 1,109,256,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1109256070...
Checkpoint 1109256070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,560.08440
Policy Entropy: 1.71894
Value Function Loss: 0.05620

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.31714
Value Function Update Magnitude: 0.37552

Collected Steps per Second: 21,476.40423
Overall Steps per Second: 10,409.75142

Timestep Collection Time: 2.32860
Timestep Consumption Time: 2.47555
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.80415

Cumulative Model Updates: 132,916
Cumulative Timesteps: 1,109,306,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,490.01675
Policy Entropy: 1.69676
Value Function Loss: 0.05376

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.31972
Value Function Update Magnitude: 0.36415

Collected Steps per Second: 22,151.66481
Overall Steps per Second: 10,455.22585

Timestep Collection Time: 2.25780
Timestep Consumption Time: 2.52584
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.78364

Cumulative Model Updates: 132,922
Cumulative Timesteps: 1,109,356,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1109356094...
Checkpoint 1109356094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,413.87546
Policy Entropy: 1.69589
Value Function Loss: 0.05380

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.31864
Value Function Update Magnitude: 0.32998

Collected Steps per Second: 21,764.39221
Overall Steps per Second: 10,549.83521

Timestep Collection Time: 2.29742
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.73960

Cumulative Model Updates: 132,928
Cumulative Timesteps: 1,109,406,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,566.63659
Policy Entropy: 1.68134
Value Function Loss: 0.05583

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07523
Policy Update Magnitude: 0.31783
Value Function Update Magnitude: 0.33529

Collected Steps per Second: 22,104.40823
Overall Steps per Second: 10,551.32631

Timestep Collection Time: 2.26353
Timestep Consumption Time: 2.47843
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.74196

Cumulative Model Updates: 132,934
Cumulative Timesteps: 1,109,456,130

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1109456130...
Checkpoint 1109456130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,705.05467
Policy Entropy: 1.69065
Value Function Loss: 0.06658

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.32580
Value Function Update Magnitude: 0.31747

Collected Steps per Second: 21,665.71822
Overall Steps per Second: 10,570.50771

Timestep Collection Time: 2.30835
Timestep Consumption Time: 2.42293
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.73128

Cumulative Model Updates: 132,940
Cumulative Timesteps: 1,109,506,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,627.11712
Policy Entropy: 1.70454
Value Function Loss: 0.07432

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.33239
Value Function Update Magnitude: 0.28466

Collected Steps per Second: 21,714.45398
Overall Steps per Second: 10,539.80629

Timestep Collection Time: 2.30390
Timestep Consumption Time: 2.44267
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.74658

Cumulative Model Updates: 132,946
Cumulative Timesteps: 1,109,556,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1109556170...
Checkpoint 1109556170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,035.96899
Policy Entropy: 1.72846
Value Function Loss: 0.07647

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.32443
Value Function Update Magnitude: 0.25840

Collected Steps per Second: 22,008.71370
Overall Steps per Second: 10,618.43125

Timestep Collection Time: 2.27201
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.70917

Cumulative Model Updates: 132,952
Cumulative Timesteps: 1,109,606,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,724.32962
Policy Entropy: 1.73822
Value Function Loss: 0.07421

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.31509
Value Function Update Magnitude: 0.23817

Collected Steps per Second: 21,988.29404
Overall Steps per Second: 10,455.51487

Timestep Collection Time: 2.27503
Timestep Consumption Time: 2.50943
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.78446

Cumulative Model Updates: 132,958
Cumulative Timesteps: 1,109,656,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1109656198...
Checkpoint 1109656198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,684.86873
Policy Entropy: 1.73977
Value Function Loss: 0.07404

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.32498
Value Function Update Magnitude: 0.24126

Collected Steps per Second: 21,018.25425
Overall Steps per Second: 10,255.60072

Timestep Collection Time: 2.38003
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.87772

Cumulative Model Updates: 132,964
Cumulative Timesteps: 1,109,706,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,182.94831
Policy Entropy: 1.73502
Value Function Loss: 0.07957

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.33953
Value Function Update Magnitude: 0.29401

Collected Steps per Second: 21,527.48568
Overall Steps per Second: 10,379.08865

Timestep Collection Time: 2.32345
Timestep Consumption Time: 2.49566
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.81911

Cumulative Model Updates: 132,970
Cumulative Timesteps: 1,109,756,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1109756240...
Checkpoint 1109756240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,241.53074
Policy Entropy: 1.73211
Value Function Loss: 0.07502

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.34021
Value Function Update Magnitude: 0.31842

Collected Steps per Second: 21,510.71250
Overall Steps per Second: 10,375.48027

Timestep Collection Time: 2.32498
Timestep Consumption Time: 2.49523
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.82021

Cumulative Model Updates: 132,976
Cumulative Timesteps: 1,109,806,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,092.10150
Policy Entropy: 1.72303
Value Function Loss: 0.07422

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.33914
Value Function Update Magnitude: 0.33013

Collected Steps per Second: 21,429.62399
Overall Steps per Second: 10,312.75162

Timestep Collection Time: 2.33443
Timestep Consumption Time: 2.51646
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.85089

Cumulative Model Updates: 132,982
Cumulative Timesteps: 1,109,856,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1109856278...
Checkpoint 1109856278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,045.94274
Policy Entropy: 1.72106
Value Function Loss: 0.06849

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.33663
Value Function Update Magnitude: 0.36421

Collected Steps per Second: 21,458.54503
Overall Steps per Second: 10,343.78950

Timestep Collection Time: 2.33007
Timestep Consumption Time: 2.50374
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.83382

Cumulative Model Updates: 132,988
Cumulative Timesteps: 1,109,906,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,547.26079
Policy Entropy: 1.72918
Value Function Loss: 0.07094

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.33432
Value Function Update Magnitude: 0.39602

Collected Steps per Second: 22,010.87595
Overall Steps per Second: 10,432.75271

Timestep Collection Time: 2.27206
Timestep Consumption Time: 2.52150
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.79356

Cumulative Model Updates: 132,994
Cumulative Timesteps: 1,109,956,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1109956288...
Checkpoint 1109956288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,577.23011
Policy Entropy: 1.74091
Value Function Loss: 0.06840

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.33178
Value Function Update Magnitude: 0.38311

Collected Steps per Second: 22,020.78825
Overall Steps per Second: 10,489.10321

Timestep Collection Time: 2.27076
Timestep Consumption Time: 2.49647
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.76723

Cumulative Model Updates: 133,000
Cumulative Timesteps: 1,110,006,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,445.81656
Policy Entropy: 1.72436
Value Function Loss: 0.06335

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.32651
Value Function Update Magnitude: 0.32619

Collected Steps per Second: 22,270.90413
Overall Steps per Second: 10,504.28591

Timestep Collection Time: 2.24697
Timestep Consumption Time: 2.51699
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.76396

Cumulative Model Updates: 133,006
Cumulative Timesteps: 1,110,056,334

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1110056334...
Checkpoint 1110056334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,129.90941
Policy Entropy: 1.72327
Value Function Loss: 0.05862

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.31767
Value Function Update Magnitude: 0.32283

Collected Steps per Second: 21,972.09167
Overall Steps per Second: 10,652.92598

Timestep Collection Time: 2.27589
Timestep Consumption Time: 2.41822
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.69411

Cumulative Model Updates: 133,012
Cumulative Timesteps: 1,110,106,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,886.94362
Policy Entropy: 1.71851
Value Function Loss: 0.05668

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07420
Policy Update Magnitude: 0.31470
Value Function Update Magnitude: 0.33361

Collected Steps per Second: 22,230.85995
Overall Steps per Second: 10,524.51945

Timestep Collection Time: 2.24931
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.75119

Cumulative Model Updates: 133,018
Cumulative Timesteps: 1,110,156,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1110156344...
Checkpoint 1110156344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,795.35866
Policy Entropy: 1.72414
Value Function Loss: 0.06093

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.31846
Value Function Update Magnitude: 0.35170

Collected Steps per Second: 22,269.11426
Overall Steps per Second: 10,493.88785

Timestep Collection Time: 2.24544
Timestep Consumption Time: 2.51962
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.76506

Cumulative Model Updates: 133,024
Cumulative Timesteps: 1,110,206,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,083.83821
Policy Entropy: 1.71944
Value Function Loss: 0.05989

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.32269
Value Function Update Magnitude: 0.34201

Collected Steps per Second: 21,387.56741
Overall Steps per Second: 10,481.55584

Timestep Collection Time: 2.33799
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.77067

Cumulative Model Updates: 133,030
Cumulative Timesteps: 1,110,256,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1110256352...
Checkpoint 1110256352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,642.30432
Policy Entropy: 1.72327
Value Function Loss: 0.06500

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.31794
Value Function Update Magnitude: 0.32929

Collected Steps per Second: 21,131.37641
Overall Steps per Second: 10,593.28606

Timestep Collection Time: 2.36738
Timestep Consumption Time: 2.35505
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.72243

Cumulative Model Updates: 133,036
Cumulative Timesteps: 1,110,306,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,745.95648
Policy Entropy: 1.73099
Value Function Loss: 0.06350

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09180
Policy Update Magnitude: 0.31147
Value Function Update Magnitude: 0.34480

Collected Steps per Second: 21,190.42264
Overall Steps per Second: 10,488.13246

Timestep Collection Time: 2.36022
Timestep Consumption Time: 2.40841
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.76863

Cumulative Model Updates: 133,042
Cumulative Timesteps: 1,110,356,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1110356392...
Checkpoint 1110356392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,351.63826
Policy Entropy: 1.73586
Value Function Loss: 0.06546

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.31512
Value Function Update Magnitude: 0.35972

Collected Steps per Second: 20,987.81755
Overall Steps per Second: 10,569.68184

Timestep Collection Time: 2.38252
Timestep Consumption Time: 2.34836
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.73089

Cumulative Model Updates: 133,048
Cumulative Timesteps: 1,110,406,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,257.11663
Policy Entropy: 1.72291
Value Function Loss: 0.05620

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.30852
Value Function Update Magnitude: 0.35167

Collected Steps per Second: 20,851.37369
Overall Steps per Second: 10,505.06516

Timestep Collection Time: 2.39821
Timestep Consumption Time: 2.36197
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.76018

Cumulative Model Updates: 133,054
Cumulative Timesteps: 1,110,456,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1110456402...
Checkpoint 1110456402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,550.24675
Policy Entropy: 1.70385
Value Function Loss: 0.05329

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.29848
Value Function Update Magnitude: 0.33451

Collected Steps per Second: 21,148.60781
Overall Steps per Second: 10,250.70111

Timestep Collection Time: 2.36488
Timestep Consumption Time: 2.51420
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.87908

Cumulative Model Updates: 133,060
Cumulative Timesteps: 1,110,506,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,691.26441
Policy Entropy: 1.69709
Value Function Loss: 0.05344

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.30195
Value Function Update Magnitude: 0.33254

Collected Steps per Second: 21,852.59789
Overall Steps per Second: 10,433.05242

Timestep Collection Time: 2.28815
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.79265

Cumulative Model Updates: 133,066
Cumulative Timesteps: 1,110,556,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1110556418...
Checkpoint 1110556418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,619.42263
Policy Entropy: 1.70691
Value Function Loss: 0.06257

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.32167
Value Function Update Magnitude: 0.34586

Collected Steps per Second: 22,011.02777
Overall Steps per Second: 10,720.36964

Timestep Collection Time: 2.27386
Timestep Consumption Time: 2.39482
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.66868

Cumulative Model Updates: 133,072
Cumulative Timesteps: 1,110,606,468

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,329.78107
Policy Entropy: 1.72352
Value Function Loss: 0.06379

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.32554
Value Function Update Magnitude: 0.36145

Collected Steps per Second: 22,160.52492
Overall Steps per Second: 10,618.40006

Timestep Collection Time: 2.25726
Timestep Consumption Time: 2.45362
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.71088

Cumulative Model Updates: 133,078
Cumulative Timesteps: 1,110,656,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1110656490...
Checkpoint 1110656490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,160.27620
Policy Entropy: 1.72601
Value Function Loss: 0.06298

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.32104
Value Function Update Magnitude: 0.36650

Collected Steps per Second: 21,860.19246
Overall Steps per Second: 10,482.83407

Timestep Collection Time: 2.28891
Timestep Consumption Time: 2.48423
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.77314

Cumulative Model Updates: 133,084
Cumulative Timesteps: 1,110,706,526

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,755.87995
Policy Entropy: 1.71152
Value Function Loss: 0.05960

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.31280
Value Function Update Magnitude: 0.35493

Collected Steps per Second: 22,168.28736
Overall Steps per Second: 10,504.12977

Timestep Collection Time: 2.25647
Timestep Consumption Time: 2.50566
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.76213

Cumulative Model Updates: 133,090
Cumulative Timesteps: 1,110,756,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1110756548...
Checkpoint 1110756548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,412.03560
Policy Entropy: 1.71019
Value Function Loss: 0.06179

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.31706
Value Function Update Magnitude: 0.32408

Collected Steps per Second: 21,921.69114
Overall Steps per Second: 10,508.49400

Timestep Collection Time: 2.28158
Timestep Consumption Time: 2.47800
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.75958

Cumulative Model Updates: 133,096
Cumulative Timesteps: 1,110,806,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,128.19606
Policy Entropy: 1.71336
Value Function Loss: 0.06251

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.32119
Value Function Update Magnitude: 0.33617

Collected Steps per Second: 21,808.52137
Overall Steps per Second: 10,465.71468

Timestep Collection Time: 2.29397
Timestep Consumption Time: 2.48621
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.78018

Cumulative Model Updates: 133,102
Cumulative Timesteps: 1,110,856,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1110856592...
Checkpoint 1110856592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,258.93062
Policy Entropy: 1.71796
Value Function Loss: 0.06245

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.31645
Value Function Update Magnitude: 0.37589

Collected Steps per Second: 21,608.42548
Overall Steps per Second: 10,545.31684

Timestep Collection Time: 2.31419
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.74201

Cumulative Model Updates: 133,108
Cumulative Timesteps: 1,110,906,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,274.66103
Policy Entropy: 1.70975
Value Function Loss: 0.06192

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.32048
Value Function Update Magnitude: 0.37555

Collected Steps per Second: 21,541.66205
Overall Steps per Second: 10,454.20321

Timestep Collection Time: 2.32136
Timestep Consumption Time: 2.46198
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.78334

Cumulative Model Updates: 133,114
Cumulative Timesteps: 1,110,956,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1110956604...
Checkpoint 1110956604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,858.15961
Policy Entropy: 1.70505
Value Function Loss: 0.06316

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.32259
Value Function Update Magnitude: 0.36668

Collected Steps per Second: 21,465.46184
Overall Steps per Second: 10,312.31725

Timestep Collection Time: 2.32960
Timestep Consumption Time: 2.51955
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.84915

Cumulative Model Updates: 133,120
Cumulative Timesteps: 1,111,006,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,071.73960
Policy Entropy: 1.71748
Value Function Loss: 0.06331

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.31436
Value Function Update Magnitude: 0.36593

Collected Steps per Second: 21,875.77583
Overall Steps per Second: 10,429.37543

Timestep Collection Time: 2.28627
Timestep Consumption Time: 2.50922
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.79549

Cumulative Model Updates: 133,126
Cumulative Timesteps: 1,111,056,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1111056624...
Checkpoint 1111056624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,489.31257
Policy Entropy: 1.70303
Value Function Loss: 0.05645

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.30244
Value Function Update Magnitude: 0.35758

Collected Steps per Second: 21,918.58936
Overall Steps per Second: 10,528.01557

Timestep Collection Time: 2.28117
Timestep Consumption Time: 2.46806
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.74923

Cumulative Model Updates: 133,132
Cumulative Timesteps: 1,111,106,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,285.23122
Policy Entropy: 1.69328
Value Function Loss: 0.06011

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.30900
Value Function Update Magnitude: 0.34786

Collected Steps per Second: 21,756.86677
Overall Steps per Second: 10,526.77374

Timestep Collection Time: 2.29877
Timestep Consumption Time: 2.45235
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.75112

Cumulative Model Updates: 133,138
Cumulative Timesteps: 1,111,156,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1111156638...
Checkpoint 1111156638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,142.98964
Policy Entropy: 1.67131
Value Function Loss: 0.05594

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.29239
Value Function Update Magnitude: 0.34641

Collected Steps per Second: 21,847.38249
Overall Steps per Second: 10,568.74992

Timestep Collection Time: 2.28989
Timestep Consumption Time: 2.44369
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.73358

Cumulative Model Updates: 133,144
Cumulative Timesteps: 1,111,206,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,381.93252
Policy Entropy: 1.69084
Value Function Loss: 0.05664

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.30776
Value Function Update Magnitude: 0.35241

Collected Steps per Second: 21,843.91035
Overall Steps per Second: 10,570.35687

Timestep Collection Time: 2.29043
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.73324

Cumulative Model Updates: 133,150
Cumulative Timesteps: 1,111,256,698

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1111256698...
Checkpoint 1111256698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,320.37052
Policy Entropy: 1.69261
Value Function Loss: 0.05651

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.29909
Value Function Update Magnitude: 0.35657

Collected Steps per Second: 22,022.81623
Overall Steps per Second: 10,685.58114

Timestep Collection Time: 2.27119
Timestep Consumption Time: 2.40970
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.68089

Cumulative Model Updates: 133,156
Cumulative Timesteps: 1,111,306,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,077.60100
Policy Entropy: 1.69575
Value Function Loss: 0.05939

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.30874
Value Function Update Magnitude: 0.37214

Collected Steps per Second: 22,092.89592
Overall Steps per Second: 10,476.14643

Timestep Collection Time: 2.26371
Timestep Consumption Time: 2.51018
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.77389

Cumulative Model Updates: 133,162
Cumulative Timesteps: 1,111,356,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1111356728...
Checkpoint 1111356728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,963.58607
Policy Entropy: 1.70317
Value Function Loss: 0.06299

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.32139
Value Function Update Magnitude: 0.36125

Collected Steps per Second: 22,222.06422
Overall Steps per Second: 10,590.30723

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.47158
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.72186

Cumulative Model Updates: 133,168
Cumulative Timesteps: 1,111,406,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,043.40391
Policy Entropy: 1.69519
Value Function Loss: 0.05876

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.32402
Value Function Update Magnitude: 0.36877

Collected Steps per Second: 21,629.77776
Overall Steps per Second: 10,436.69772

Timestep Collection Time: 2.31191
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.79136

Cumulative Model Updates: 133,174
Cumulative Timesteps: 1,111,456,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1111456740...
Checkpoint 1111456740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,634.72648
Policy Entropy: 1.70211
Value Function Loss: 0.05835

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.32157
Value Function Update Magnitude: 0.36397

Collected Steps per Second: 21,526.54320
Overall Steps per Second: 10,535.25663

Timestep Collection Time: 2.32327
Timestep Consumption Time: 2.42384
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74711

Cumulative Model Updates: 133,180
Cumulative Timesteps: 1,111,506,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,146.71162
Policy Entropy: 1.69358
Value Function Loss: 0.05480

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08072
Policy Update Magnitude: 0.31874
Value Function Update Magnitude: 0.34587

Collected Steps per Second: 21,516.27541
Overall Steps per Second: 10,479.38449

Timestep Collection Time: 2.32475
Timestep Consumption Time: 2.44843
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.77318

Cumulative Model Updates: 133,186
Cumulative Timesteps: 1,111,556,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1111556772...
Checkpoint 1111556772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,037.08584
Policy Entropy: 1.70281
Value Function Loss: 0.05808

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07886
Policy Update Magnitude: 0.31687
Value Function Update Magnitude: 0.34694

Collected Steps per Second: 21,618.07514
Overall Steps per Second: 10,434.31708

Timestep Collection Time: 2.31306
Timestep Consumption Time: 2.47920
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.79226

Cumulative Model Updates: 133,192
Cumulative Timesteps: 1,111,606,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,732.81381
Policy Entropy: 1.70883
Value Function Loss: 0.06084

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.32152
Value Function Update Magnitude: 0.36342

Collected Steps per Second: 21,725.54241
Overall Steps per Second: 10,374.88908

Timestep Collection Time: 2.30190
Timestep Consumption Time: 2.51839
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.82029

Cumulative Model Updates: 133,198
Cumulative Timesteps: 1,111,656,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1111656786...
Checkpoint 1111656786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,145.48121
Policy Entropy: 1.69824
Value Function Loss: 0.05863

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.32227
Value Function Update Magnitude: 0.37000

Collected Steps per Second: 21,965.34452
Overall Steps per Second: 10,542.47721

Timestep Collection Time: 2.27695
Timestep Consumption Time: 2.46710
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.74405

Cumulative Model Updates: 133,204
Cumulative Timesteps: 1,111,706,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,877.68086
Policy Entropy: 1.68857
Value Function Loss: 0.05882

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08284
Policy Update Magnitude: 0.32449
Value Function Update Magnitude: 0.35451

Collected Steps per Second: 22,229.50403
Overall Steps per Second: 10,513.36149

Timestep Collection Time: 2.24944
Timestep Consumption Time: 2.50679
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.75623

Cumulative Model Updates: 133,210
Cumulative Timesteps: 1,111,756,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1111756804...
Checkpoint 1111756804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,687.92160
Policy Entropy: 1.69226
Value Function Loss: 0.05834

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.32174
Value Function Update Magnitude: 0.36318

Collected Steps per Second: 21,920.93106
Overall Steps per Second: 10,536.52064

Timestep Collection Time: 2.28138
Timestep Consumption Time: 2.46497
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.74635

Cumulative Model Updates: 133,216
Cumulative Timesteps: 1,111,806,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,287.91686
Policy Entropy: 1.70266
Value Function Loss: 0.05433

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.31782
Value Function Update Magnitude: 0.37186

Collected Steps per Second: 22,157.51420
Overall Steps per Second: 10,477.52008

Timestep Collection Time: 2.25783
Timestep Consumption Time: 2.51696
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.77479

Cumulative Model Updates: 133,222
Cumulative Timesteps: 1,111,856,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1111856842...
Checkpoint 1111856842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,738.81232
Policy Entropy: 1.70188
Value Function Loss: 0.05295

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.30890
Value Function Update Magnitude: 0.35371

Collected Steps per Second: 22,037.58548
Overall Steps per Second: 10,656.40730

Timestep Collection Time: 2.27003
Timestep Consumption Time: 2.42442
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.69445

Cumulative Model Updates: 133,228
Cumulative Timesteps: 1,111,906,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,326.74104
Policy Entropy: 1.70547
Value Function Loss: 0.05706

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07842
Policy Update Magnitude: 0.31260
Value Function Update Magnitude: 0.34166

Collected Steps per Second: 21,390.95877
Overall Steps per Second: 10,491.59590

Timestep Collection Time: 2.33875
Timestep Consumption Time: 2.42964
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.76839

Cumulative Model Updates: 133,234
Cumulative Timesteps: 1,111,956,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1111956896...
Checkpoint 1111956896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,758.90991
Policy Entropy: 1.71881
Value Function Loss: 0.06270

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.32421
Value Function Update Magnitude: 0.32862

Collected Steps per Second: 21,061.91544
Overall Steps per Second: 10,563.33662

Timestep Collection Time: 2.37424
Timestep Consumption Time: 2.35968
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.73392

Cumulative Model Updates: 133,240
Cumulative Timesteps: 1,112,006,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,761.97613
Policy Entropy: 1.72399
Value Function Loss: 0.06264

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.32307
Value Function Update Magnitude: 0.33957

Collected Steps per Second: 20,646.40724
Overall Steps per Second: 10,462.21723

Timestep Collection Time: 2.42250
Timestep Consumption Time: 2.35813
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.78063

Cumulative Model Updates: 133,246
Cumulative Timesteps: 1,112,056,918

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1112056918...
Checkpoint 1112056918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,399.06126
Policy Entropy: 1.71735
Value Function Loss: 0.05896

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.31696
Value Function Update Magnitude: 0.32574

Collected Steps per Second: 20,743.80235
Overall Steps per Second: 10,349.31964

Timestep Collection Time: 2.41180
Timestep Consumption Time: 2.42233
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.83413

Cumulative Model Updates: 133,252
Cumulative Timesteps: 1,112,106,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,521.90018
Policy Entropy: 1.70914
Value Function Loss: 0.05741

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.31490
Value Function Update Magnitude: 0.31920

Collected Steps per Second: 20,869.27850
Overall Steps per Second: 10,299.41134

Timestep Collection Time: 2.39711
Timestep Consumption Time: 2.46006
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.85717

Cumulative Model Updates: 133,258
Cumulative Timesteps: 1,112,156,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1112156974...
Checkpoint 1112156974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,547.85715
Policy Entropy: 1.70471
Value Function Loss: 0.06145

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.32074
Value Function Update Magnitude: 0.33659

Collected Steps per Second: 21,906.19370
Overall Steps per Second: 10,584.95464

Timestep Collection Time: 2.28264
Timestep Consumption Time: 2.44142
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.72406

Cumulative Model Updates: 133,264
Cumulative Timesteps: 1,112,206,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,720.72620
Policy Entropy: 1.69833
Value Function Loss: 0.05996

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.32371
Value Function Update Magnitude: 0.37359

Collected Steps per Second: 21,985.97140
Overall Steps per Second: 10,534.31401

Timestep Collection Time: 2.27427
Timestep Consumption Time: 2.47232
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.74658

Cumulative Model Updates: 133,270
Cumulative Timesteps: 1,112,256,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1112256980...
Checkpoint 1112256980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,002.41306
Policy Entropy: 1.68343
Value Function Loss: 0.05726

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.32071
Value Function Update Magnitude: 0.37617

Collected Steps per Second: 21,783.05592
Overall Steps per Second: 10,641.77000

Timestep Collection Time: 2.29628
Timestep Consumption Time: 2.40407
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.70035

Cumulative Model Updates: 133,276
Cumulative Timesteps: 1,112,307,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,120.12292
Policy Entropy: 1.66533
Value Function Loss: 0.06054

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.31943
Value Function Update Magnitude: 0.35276

Collected Steps per Second: 22,023.61109
Overall Steps per Second: 10,551.87197

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.74134

Cumulative Model Updates: 133,282
Cumulative Timesteps: 1,112,357,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1112357030...
Checkpoint 1112357030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,334.83576
Policy Entropy: 1.67545
Value Function Loss: 0.06316

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.30862
Value Function Update Magnitude: 0.34361

Collected Steps per Second: 21,613.28827
Overall Steps per Second: 10,520.79979

Timestep Collection Time: 2.31385
Timestep Consumption Time: 2.43959
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.75344

Cumulative Model Updates: 133,288
Cumulative Timesteps: 1,112,407,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,838.42740
Policy Entropy: 1.67140
Value Function Loss: 0.06052

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.30458
Value Function Update Magnitude: 0.35799

Collected Steps per Second: 21,686.37046
Overall Steps per Second: 10,563.81294

Timestep Collection Time: 2.30643
Timestep Consumption Time: 2.42842
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.73484

Cumulative Model Updates: 133,294
Cumulative Timesteps: 1,112,457,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1112457058...
Checkpoint 1112457058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,231.46768
Policy Entropy: 1.67927
Value Function Loss: 0.05677

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.31466
Value Function Update Magnitude: 0.34540

Collected Steps per Second: 21,127.08874
Overall Steps per Second: 10,284.41574

Timestep Collection Time: 2.36691
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.86231

Cumulative Model Updates: 133,300
Cumulative Timesteps: 1,112,507,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,347.33041
Policy Entropy: 1.66690
Value Function Loss: 0.05139

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.31283
Value Function Update Magnitude: 0.32497

Collected Steps per Second: 21,354.85436
Overall Steps per Second: 10,304.69665

Timestep Collection Time: 2.34289
Timestep Consumption Time: 2.51238
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.85526

Cumulative Model Updates: 133,306
Cumulative Timesteps: 1,112,557,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1112557096...
Checkpoint 1112557096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,626.32040
Policy Entropy: 1.68105
Value Function Loss: 0.05358

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08236
Policy Update Magnitude: 0.31058
Value Function Update Magnitude: 0.31862

Collected Steps per Second: 21,297.17524
Overall Steps per Second: 10,310.21431

Timestep Collection Time: 2.34782
Timestep Consumption Time: 2.50193
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.84975

Cumulative Model Updates: 133,312
Cumulative Timesteps: 1,112,607,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,758.50221
Policy Entropy: 1.69449
Value Function Loss: 0.05435

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.31119
Value Function Update Magnitude: 0.32909

Collected Steps per Second: 21,936.90691
Overall Steps per Second: 10,363.31782

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.54545
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.82471

Cumulative Model Updates: 133,318
Cumulative Timesteps: 1,112,657,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1112657098...
Checkpoint 1112657098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,261.29371
Policy Entropy: 1.70513
Value Function Loss: 0.05685

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.31542
Value Function Update Magnitude: 0.32776

Collected Steps per Second: 21,606.93171
Overall Steps per Second: 10,540.33999

Timestep Collection Time: 2.31407
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.74368

Cumulative Model Updates: 133,324
Cumulative Timesteps: 1,112,707,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,165.84800
Policy Entropy: 1.70112
Value Function Loss: 0.06380

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.32373
Value Function Update Magnitude: 0.33749

Collected Steps per Second: 21,942.96732
Overall Steps per Second: 10,455.22909

Timestep Collection Time: 2.27945
Timestep Consumption Time: 2.50456
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.78402

Cumulative Model Updates: 133,330
Cumulative Timesteps: 1,112,757,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1112757116...
Checkpoint 1112757116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,764.22425
Policy Entropy: 1.68627
Value Function Loss: 0.06570

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.32700
Value Function Update Magnitude: 0.35240

Collected Steps per Second: 21,678.26008
Overall Steps per Second: 10,352.86634

Timestep Collection Time: 2.30683
Timestep Consumption Time: 2.52353
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.83035

Cumulative Model Updates: 133,336
Cumulative Timesteps: 1,112,807,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,681.44470
Policy Entropy: 1.69422
Value Function Loss: 0.07093

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.32851
Value Function Update Magnitude: 0.35417

Collected Steps per Second: 22,447.87688
Overall Steps per Second: 10,741.94366

Timestep Collection Time: 2.22809
Timestep Consumption Time: 2.42805
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.65614

Cumulative Model Updates: 133,342
Cumulative Timesteps: 1,112,857,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1112857140...
Checkpoint 1112857140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,545.15967
Policy Entropy: 1.70197
Value Function Loss: 0.06530

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.32462
Value Function Update Magnitude: 0.35873

Collected Steps per Second: 21,275.06787
Overall Steps per Second: 10,620.34968

Timestep Collection Time: 2.35064
Timestep Consumption Time: 2.35825
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.70888

Cumulative Model Updates: 133,348
Cumulative Timesteps: 1,112,907,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,311.95686
Policy Entropy: 1.70905
Value Function Loss: 0.06502

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.32433
Value Function Update Magnitude: 0.34219

Collected Steps per Second: 21,704.99290
Overall Steps per Second: 10,565.44325

Timestep Collection Time: 2.30417
Timestep Consumption Time: 2.42937
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.73354

Cumulative Model Updates: 133,354
Cumulative Timesteps: 1,112,957,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1112957162...
Checkpoint 1112957162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,930.00969
Policy Entropy: 1.68726
Value Function Loss: 0.06438

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.32901
Value Function Update Magnitude: 0.34763

Collected Steps per Second: 20,533.83538
Overall Steps per Second: 10,309.07034

Timestep Collection Time: 2.43598
Timestep Consumption Time: 2.41606
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.85204

Cumulative Model Updates: 133,360
Cumulative Timesteps: 1,113,007,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,252.86983
Policy Entropy: 1.69000
Value Function Loss: 0.06307

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.32239
Value Function Update Magnitude: 0.36901

Collected Steps per Second: 20,919.86505
Overall Steps per Second: 10,378.38181

Timestep Collection Time: 2.39074
Timestep Consumption Time: 2.42831
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.81906

Cumulative Model Updates: 133,366
Cumulative Timesteps: 1,113,057,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1113057196...
Checkpoint 1113057196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,799.32657
Policy Entropy: 1.69100
Value Function Loss: 0.06078

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.30802
Value Function Update Magnitude: 0.36842

Collected Steps per Second: 21,001.03359
Overall Steps per Second: 10,552.82271

Timestep Collection Time: 2.38169
Timestep Consumption Time: 2.35808
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.73977

Cumulative Model Updates: 133,372
Cumulative Timesteps: 1,113,107,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,401.00034
Policy Entropy: 1.70396
Value Function Loss: 0.06150

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.31118
Value Function Update Magnitude: 0.32331

Collected Steps per Second: 21,375.80745
Overall Steps per Second: 10,512.85687

Timestep Collection Time: 2.33993
Timestep Consumption Time: 2.41786
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.75779

Cumulative Model Updates: 133,378
Cumulative Timesteps: 1,113,157,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1113157232...
Checkpoint 1113157232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,850.93936
Policy Entropy: 1.68167
Value Function Loss: 0.06052

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.31236
Value Function Update Magnitude: 0.30602

Collected Steps per Second: 21,579.44672
Overall Steps per Second: 10,549.39403

Timestep Collection Time: 2.31776
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.74113

Cumulative Model Updates: 133,384
Cumulative Timesteps: 1,113,207,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,052.98016
Policy Entropy: 1.66435
Value Function Loss: 0.05318

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.30442
Value Function Update Magnitude: 0.33167

Collected Steps per Second: 22,076.48229
Overall Steps per Second: 10,490.29638

Timestep Collection Time: 2.26612
Timestep Consumption Time: 2.50286
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.76898

Cumulative Model Updates: 133,390
Cumulative Timesteps: 1,113,257,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1113257276...
Checkpoint 1113257276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,319.68854
Policy Entropy: 1.67594
Value Function Loss: 0.05943

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.30161
Value Function Update Magnitude: 0.34061

Collected Steps per Second: 21,376.90598
Overall Steps per Second: 10,530.90339

Timestep Collection Time: 2.33925
Timestep Consumption Time: 2.40925
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.74850

Cumulative Model Updates: 133,396
Cumulative Timesteps: 1,113,307,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,005.22341
Policy Entropy: 1.69612
Value Function Loss: 0.05860

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.30979
Value Function Update Magnitude: 0.35644

Collected Steps per Second: 22,031.76574
Overall Steps per Second: 10,544.41609

Timestep Collection Time: 2.27036
Timestep Consumption Time: 2.47338
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.74374

Cumulative Model Updates: 133,402
Cumulative Timesteps: 1,113,357,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1113357302...
Checkpoint 1113357302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,689.17018
Policy Entropy: 1.70849
Value Function Loss: 0.06222

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.31940
Value Function Update Magnitude: 0.34728

Collected Steps per Second: 21,641.07910
Overall Steps per Second: 10,551.35559

Timestep Collection Time: 2.31079
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.73949

Cumulative Model Updates: 133,408
Cumulative Timesteps: 1,113,407,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,694.29012
Policy Entropy: 1.70442
Value Function Loss: 0.05817

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.32309
Value Function Update Magnitude: 0.32966

Collected Steps per Second: 22,227.02845
Overall Steps per Second: 10,547.41813

Timestep Collection Time: 2.25032
Timestep Consumption Time: 2.49188
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.74220

Cumulative Model Updates: 133,414
Cumulative Timesteps: 1,113,457,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1113457328...
Checkpoint 1113457328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,427.17031
Policy Entropy: 1.71229
Value Function Loss: 0.06105

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.31264
Value Function Update Magnitude: 0.32951

Collected Steps per Second: 21,669.23708
Overall Steps per Second: 10,559.15675

Timestep Collection Time: 2.30936
Timestep Consumption Time: 2.42985
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.73920

Cumulative Model Updates: 133,420
Cumulative Timesteps: 1,113,507,370

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,663.47291
Policy Entropy: 1.72308
Value Function Loss: 0.06046

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.31009
Value Function Update Magnitude: 0.29823

Collected Steps per Second: 21,924.95146
Overall Steps per Second: 10,488.40907

Timestep Collection Time: 2.28069
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.76755

Cumulative Model Updates: 133,426
Cumulative Timesteps: 1,113,557,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1113557374...
Checkpoint 1113557374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,453.95591
Policy Entropy: 1.73909
Value Function Loss: 0.06408

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.31996
Value Function Update Magnitude: 0.29254

Collected Steps per Second: 21,050.53504
Overall Steps per Second: 10,237.32553

Timestep Collection Time: 2.37685
Timestep Consumption Time: 2.51056
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.88741

Cumulative Model Updates: 133,432
Cumulative Timesteps: 1,113,607,408

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,468.28201
Policy Entropy: 1.74317
Value Function Loss: 0.06323

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.31182
Value Function Update Magnitude: 0.31499

Collected Steps per Second: 21,650.19846
Overall Steps per Second: 10,490.83812

Timestep Collection Time: 2.31176
Timestep Consumption Time: 2.45907
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.77083

Cumulative Model Updates: 133,438
Cumulative Timesteps: 1,113,657,458

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1113657458...
Checkpoint 1113657458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,200.70111
Policy Entropy: 1.73851
Value Function Loss: 0.06909

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.31755
Value Function Update Magnitude: 0.34688

Collected Steps per Second: 21,213.12928
Overall Steps per Second: 10,282.62269

Timestep Collection Time: 2.35826
Timestep Consumption Time: 2.50684
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.86510

Cumulative Model Updates: 133,444
Cumulative Timesteps: 1,113,707,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,867.49412
Policy Entropy: 1.71609
Value Function Loss: 0.06697

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.32612
Value Function Update Magnitude: 0.38115

Collected Steps per Second: 21,771.56386
Overall Steps per Second: 10,397.39150

Timestep Collection Time: 2.29795
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.81178

Cumulative Model Updates: 133,450
Cumulative Timesteps: 1,113,757,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1113757514...
Checkpoint 1113757514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,171.83857
Policy Entropy: 1.72223
Value Function Loss: 0.06512

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.33151
Value Function Update Magnitude: 0.39347

Collected Steps per Second: 21,287.98434
Overall Steps per Second: 10,319.76670

Timestep Collection Time: 2.34968
Timestep Consumption Time: 2.49733
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.84701

Cumulative Model Updates: 133,456
Cumulative Timesteps: 1,113,807,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,333.88954
Policy Entropy: 1.72986
Value Function Loss: 0.06402

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.33260
Value Function Update Magnitude: 0.37585

Collected Steps per Second: 22,137.25354
Overall Steps per Second: 10,445.16857

Timestep Collection Time: 2.25963
Timestep Consumption Time: 2.52938
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.78901

Cumulative Model Updates: 133,462
Cumulative Timesteps: 1,113,857,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1113857556...
Checkpoint 1113857556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,467.30178
Policy Entropy: 1.73794
Value Function Loss: 0.06363

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.32758
Value Function Update Magnitude: 0.34361

Collected Steps per Second: 22,145.45278
Overall Steps per Second: 10,453.33720

Timestep Collection Time: 2.25816
Timestep Consumption Time: 2.52577
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.78393

Cumulative Model Updates: 133,468
Cumulative Timesteps: 1,113,907,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,786.92101
Policy Entropy: 1.72948
Value Function Loss: 0.06516

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.32393
Value Function Update Magnitude: 0.34489

Collected Steps per Second: 22,164.71581
Overall Steps per Second: 10,490.90639

Timestep Collection Time: 2.25710
Timestep Consumption Time: 2.51160
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.76870

Cumulative Model Updates: 133,474
Cumulative Timesteps: 1,113,957,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1113957592...
Checkpoint 1113957592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,853.73951
Policy Entropy: 1.72206
Value Function Loss: 0.06753

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.32599
Value Function Update Magnitude: 0.36245

Collected Steps per Second: 22,074.51457
Overall Steps per Second: 10,654.49562

Timestep Collection Time: 2.26623
Timestep Consumption Time: 2.42906
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.69530

Cumulative Model Updates: 133,480
Cumulative Timesteps: 1,114,007,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,345.08973
Policy Entropy: 1.71203
Value Function Loss: 0.06438

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.33297
Value Function Update Magnitude: 0.38755

Collected Steps per Second: 21,573.90059
Overall Steps per Second: 10,404.31628

Timestep Collection Time: 2.31956
Timestep Consumption Time: 2.49017
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.80973

Cumulative Model Updates: 133,486
Cumulative Timesteps: 1,114,057,660

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1114057660...
Checkpoint 1114057660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,517.54663
Policy Entropy: 1.69835
Value Function Loss: 0.05920

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.32615
Value Function Update Magnitude: 0.39097

Collected Steps per Second: 20,715.33380
Overall Steps per Second: 10,344.91880

Timestep Collection Time: 2.41454
Timestep Consumption Time: 2.42049
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.83503

Cumulative Model Updates: 133,492
Cumulative Timesteps: 1,114,107,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,595.15182
Policy Entropy: 1.70011
Value Function Loss: 0.05936

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.32158
Value Function Update Magnitude: 0.38348

Collected Steps per Second: 21,496.79514
Overall Steps per Second: 10,694.02906

Timestep Collection Time: 2.32742
Timestep Consumption Time: 2.35108
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.67850

Cumulative Model Updates: 133,498
Cumulative Timesteps: 1,114,157,710

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1114157710...
Checkpoint 1114157710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,797.84647
Policy Entropy: 1.69789
Value Function Loss: 0.06209

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.32998
Value Function Update Magnitude: 0.36776

Collected Steps per Second: 20,864.36237
Overall Steps per Second: 10,349.17490

Timestep Collection Time: 2.39749
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.83343

Cumulative Model Updates: 133,504
Cumulative Timesteps: 1,114,207,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,943.76883
Policy Entropy: 1.70460
Value Function Loss: 0.06451

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.32967
Value Function Update Magnitude: 0.35220

Collected Steps per Second: 21,595.55170
Overall Steps per Second: 10,503.10900

Timestep Collection Time: 2.31668
Timestep Consumption Time: 2.44667
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.76335

Cumulative Model Updates: 133,510
Cumulative Timesteps: 1,114,257,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1114257762...
Checkpoint 1114257762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,891.44528
Policy Entropy: 1.69340
Value Function Loss: 0.06182

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.32582
Value Function Update Magnitude: 0.33287

Collected Steps per Second: 21,302.78427
Overall Steps per Second: 10,513.72768

Timestep Collection Time: 2.34852
Timestep Consumption Time: 2.41002
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.75854

Cumulative Model Updates: 133,516
Cumulative Timesteps: 1,114,307,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,798.54865
Policy Entropy: 1.69597
Value Function Loss: 0.05678

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.31937
Value Function Update Magnitude: 0.33598

Collected Steps per Second: 22,175.68198
Overall Steps per Second: 10,527.23192

Timestep Collection Time: 2.25707
Timestep Consumption Time: 2.49746
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.75453

Cumulative Model Updates: 133,522
Cumulative Timesteps: 1,114,357,844

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1114357844...
Checkpoint 1114357844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,527.45887
Policy Entropy: 1.69147
Value Function Loss: 0.05264

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.31707
Value Function Update Magnitude: 0.35602

Collected Steps per Second: 21,979.26050
Overall Steps per Second: 10,577.45496

Timestep Collection Time: 2.27496
Timestep Consumption Time: 2.45226
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.72722

Cumulative Model Updates: 133,528
Cumulative Timesteps: 1,114,407,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,362.50434
Policy Entropy: 1.71184
Value Function Loss: 0.05344

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.31333
Value Function Update Magnitude: 0.35417

Collected Steps per Second: 21,850.80094
Overall Steps per Second: 10,456.58038

Timestep Collection Time: 2.28843
Timestep Consumption Time: 2.49363
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.78206

Cumulative Model Updates: 133,534
Cumulative Timesteps: 1,114,457,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1114457850...
Checkpoint 1114457850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,839.21228
Policy Entropy: 1.69937
Value Function Loss: 0.05439

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.31285
Value Function Update Magnitude: 0.36145

Collected Steps per Second: 21,900.77236
Overall Steps per Second: 10,610.32508

Timestep Collection Time: 2.28430
Timestep Consumption Time: 2.43073
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.71503

Cumulative Model Updates: 133,540
Cumulative Timesteps: 1,114,507,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,480.24855
Policy Entropy: 1.71599
Value Function Loss: 0.06065

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.31729
Value Function Update Magnitude: 0.34229

Collected Steps per Second: 21,745.91555
Overall Steps per Second: 10,454.98302

Timestep Collection Time: 2.30011
Timestep Consumption Time: 2.48402
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.78413

Cumulative Model Updates: 133,546
Cumulative Timesteps: 1,114,557,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1114557896...
Checkpoint 1114557896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,438.58555
Policy Entropy: 1.71304
Value Function Loss: 0.05799

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07844
Policy Update Magnitude: 0.31687
Value Function Update Magnitude: 0.31718

Collected Steps per Second: 21,252.51558
Overall Steps per Second: 10,277.19998

Timestep Collection Time: 2.35313
Timestep Consumption Time: 2.51298
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.86611

Cumulative Model Updates: 133,552
Cumulative Timesteps: 1,114,607,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,704.71516
Policy Entropy: 1.72853
Value Function Loss: 0.05649

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07604
Policy Update Magnitude: 0.31135
Value Function Update Magnitude: 0.29216

Collected Steps per Second: 21,835.54034
Overall Steps per Second: 10,391.26622

Timestep Collection Time: 2.29085
Timestep Consumption Time: 2.52300
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.81385

Cumulative Model Updates: 133,558
Cumulative Timesteps: 1,114,657,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1114657928...
Checkpoint 1114657928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,134.74965
Policy Entropy: 1.71433
Value Function Loss: 0.05786

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.31407
Value Function Update Magnitude: 0.25977

Collected Steps per Second: 21,552.54113
Overall Steps per Second: 10,375.18599

Timestep Collection Time: 2.32140
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.82228

Cumulative Model Updates: 133,564
Cumulative Timesteps: 1,114,707,960

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,381.50907
Policy Entropy: 1.70730
Value Function Loss: 0.06078

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.32256
Value Function Update Magnitude: 0.31324

Collected Steps per Second: 22,206.37110
Overall Steps per Second: 10,464.65680

Timestep Collection Time: 2.25179
Timestep Consumption Time: 2.52658
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.77837

Cumulative Model Updates: 133,570
Cumulative Timesteps: 1,114,757,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1114757964...
Checkpoint 1114757964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,419.89248
Policy Entropy: 1.70381
Value Function Loss: 0.06052

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.32315
Value Function Update Magnitude: 0.37319

Collected Steps per Second: 22,020.98773
Overall Steps per Second: 10,460.22677

Timestep Collection Time: 2.27183
Timestep Consumption Time: 2.51086
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.78269

Cumulative Model Updates: 133,576
Cumulative Timesteps: 1,114,807,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,348.51499
Policy Entropy: 1.70697
Value Function Loss: 0.06116

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.32171
Value Function Update Magnitude: 0.38816

Collected Steps per Second: 22,019.53720
Overall Steps per Second: 10,461.11118

Timestep Collection Time: 2.27116
Timestep Consumption Time: 2.50940
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.78056

Cumulative Model Updates: 133,582
Cumulative Timesteps: 1,114,858,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1114858002...
Checkpoint 1114858002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,624.78514
Policy Entropy: 1.70314
Value Function Loss: 0.06034

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.31899
Value Function Update Magnitude: 0.39077

Collected Steps per Second: 21,548.22831
Overall Steps per Second: 10,545.10671

Timestep Collection Time: 2.32112
Timestep Consumption Time: 2.42193
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.74305

Cumulative Model Updates: 133,588
Cumulative Timesteps: 1,114,908,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,382.18195
Policy Entropy: 1.70731
Value Function Loss: 0.05980

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.31654
Value Function Update Magnitude: 0.37649

Collected Steps per Second: 22,209.30242
Overall Steps per Second: 10,521.14819

Timestep Collection Time: 2.25167
Timestep Consumption Time: 2.50142
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.75309

Cumulative Model Updates: 133,594
Cumulative Timesteps: 1,114,958,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1114958026...
Checkpoint 1114958026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,932.28506
Policy Entropy: 1.70178
Value Function Loss: 0.05560

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.31546
Value Function Update Magnitude: 0.35982

Collected Steps per Second: 22,050.98108
Overall Steps per Second: 10,639.75958

Timestep Collection Time: 2.26820
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.70086

Cumulative Model Updates: 133,600
Cumulative Timesteps: 1,115,008,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,844.06885
Policy Entropy: 1.71508
Value Function Loss: 0.06028

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.31838
Value Function Update Magnitude: 0.35056

Collected Steps per Second: 21,841.06027
Overall Steps per Second: 10,499.30002

Timestep Collection Time: 2.29037
Timestep Consumption Time: 2.47414
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.76451

Cumulative Model Updates: 133,606
Cumulative Timesteps: 1,115,058,066

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1115058066...
Checkpoint 1115058066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,450.49962
Policy Entropy: 1.70848
Value Function Loss: 0.06041

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07804
Policy Update Magnitude: 0.32400
Value Function Update Magnitude: 0.34636

Collected Steps per Second: 21,885.39717
Overall Steps per Second: 10,598.55966

Timestep Collection Time: 2.28527
Timestep Consumption Time: 2.43367
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.71894

Cumulative Model Updates: 133,612
Cumulative Timesteps: 1,115,108,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,804.47245
Policy Entropy: 1.70406
Value Function Loss: 0.06148

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.32603
Value Function Update Magnitude: 0.36920

Collected Steps per Second: 21,665.54846
Overall Steps per Second: 10,538.60391

Timestep Collection Time: 2.30846
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.74579

Cumulative Model Updates: 133,618
Cumulative Timesteps: 1,115,158,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1115158094...
Checkpoint 1115158094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,980.24490
Policy Entropy: 1.70182
Value Function Loss: 0.05763

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.31793
Value Function Update Magnitude: 0.34951

Collected Steps per Second: 21,811.61134
Overall Steps per Second: 10,576.13158

Timestep Collection Time: 2.29401
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.73103

Cumulative Model Updates: 133,624
Cumulative Timesteps: 1,115,208,130

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,882.61131
Policy Entropy: 1.70728
Value Function Loss: 0.06099

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.32151
Value Function Update Magnitude: 0.35065

Collected Steps per Second: 21,519.79021
Overall Steps per Second: 10,524.61315

Timestep Collection Time: 2.32363
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.75115

Cumulative Model Updates: 133,630
Cumulative Timesteps: 1,115,258,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1115258134...
Checkpoint 1115258134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,539.32693
Policy Entropy: 1.70343
Value Function Loss: 0.06312

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.32347
Value Function Update Magnitude: 0.36334

Collected Steps per Second: 21,682.64821
Overall Steps per Second: 10,564.64876

Timestep Collection Time: 2.30765
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.73617

Cumulative Model Updates: 133,636
Cumulative Timesteps: 1,115,308,170

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,037.79107
Policy Entropy: 1.69164
Value Function Loss: 0.05962

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.32144
Value Function Update Magnitude: 0.38156

Collected Steps per Second: 22,110.68173
Overall Steps per Second: 10,454.39551

Timestep Collection Time: 2.26144
Timestep Consumption Time: 2.52143
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.78287

Cumulative Model Updates: 133,642
Cumulative Timesteps: 1,115,358,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1115358172...
Checkpoint 1115358172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,193.09341
Policy Entropy: 1.68624
Value Function Loss: 0.05524

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.31389
Value Function Update Magnitude: 0.37430

Collected Steps per Second: 21,854.95898
Overall Steps per Second: 10,565.37002

Timestep Collection Time: 2.28863
Timestep Consumption Time: 2.44551
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.73415

Cumulative Model Updates: 133,648
Cumulative Timesteps: 1,115,408,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,401.35278
Policy Entropy: 1.68696
Value Function Loss: 0.04995

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.30734
Value Function Update Magnitude: 0.36772

Collected Steps per Second: 22,055.07931
Overall Steps per Second: 10,579.45580

Timestep Collection Time: 2.26741
Timestep Consumption Time: 2.45948
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.72690

Cumulative Model Updates: 133,654
Cumulative Timesteps: 1,115,458,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1115458198...
Checkpoint 1115458198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,359.77637
Policy Entropy: 1.68499
Value Function Loss: 0.04852

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.30210
Value Function Update Magnitude: 0.35909

Collected Steps per Second: 22,118.81846
Overall Steps per Second: 10,650.73177

Timestep Collection Time: 2.26106
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.69564

Cumulative Model Updates: 133,660
Cumulative Timesteps: 1,115,508,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,265.36654
Policy Entropy: 1.68466
Value Function Loss: 0.05097

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.30464
Value Function Update Magnitude: 0.35144

Collected Steps per Second: 22,141.99346
Overall Steps per Second: 10,487.87736

Timestep Collection Time: 2.25851
Timestep Consumption Time: 2.50966
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.76817

Cumulative Model Updates: 133,666
Cumulative Timesteps: 1,115,558,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1115558218...
Checkpoint 1115558218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,990.68598
Policy Entropy: 1.68917
Value Function Loss: 0.05668

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.31438
Value Function Update Magnitude: 0.34054

Collected Steps per Second: 22,096.95685
Overall Steps per Second: 10,535.06952

Timestep Collection Time: 2.26348
Timestep Consumption Time: 2.48409
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.74757

Cumulative Model Updates: 133,672
Cumulative Timesteps: 1,115,608,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,439.50173
Policy Entropy: 1.70154
Value Function Loss: 0.05873

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.31700
Value Function Update Magnitude: 0.30564

Collected Steps per Second: 21,157.50603
Overall Steps per Second: 10,428.47556

Timestep Collection Time: 2.36389
Timestep Consumption Time: 2.43202
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.79591

Cumulative Model Updates: 133,678
Cumulative Timesteps: 1,115,658,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1115658248...
Checkpoint 1115658248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,759.78122
Policy Entropy: 1.72003
Value Function Loss: 0.05964

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.31665
Value Function Update Magnitude: 0.29615

Collected Steps per Second: 21,022.38092
Overall Steps per Second: 10,309.31470

Timestep Collection Time: 2.37851
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.85018

Cumulative Model Updates: 133,684
Cumulative Timesteps: 1,115,708,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,027.99557
Policy Entropy: 1.71551
Value Function Loss: 0.05653

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.31609
Value Function Update Magnitude: 0.28733

Collected Steps per Second: 21,569.98823
Overall Steps per Second: 10,400.15555

Timestep Collection Time: 2.31989
Timestep Consumption Time: 2.49158
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.81147

Cumulative Model Updates: 133,690
Cumulative Timesteps: 1,115,758,290

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1115758290...
Checkpoint 1115758290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,912.70991
Policy Entropy: 1.70286
Value Function Loss: 0.05190

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.31060
Value Function Update Magnitude: 0.30819

Collected Steps per Second: 21,588.91962
Overall Steps per Second: 10,394.15990

Timestep Collection Time: 2.31674
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.81193

Cumulative Model Updates: 133,696
Cumulative Timesteps: 1,115,808,306

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,824.50997
Policy Entropy: 1.68374
Value Function Loss: 0.05205

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.30709
Value Function Update Magnitude: 0.32718

Collected Steps per Second: 22,129.02472
Overall Steps per Second: 10,446.32660

Timestep Collection Time: 2.26029
Timestep Consumption Time: 2.52781
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.78809

Cumulative Model Updates: 133,702
Cumulative Timesteps: 1,115,858,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1115858324...
Checkpoint 1115858324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,061.31133
Policy Entropy: 1.69533
Value Function Loss: 0.05851

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.31345
Value Function Update Magnitude: 0.35432

Collected Steps per Second: 21,783.42194
Overall Steps per Second: 10,365.69454

Timestep Collection Time: 2.29542
Timestep Consumption Time: 2.52838
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.82380

Cumulative Model Updates: 133,708
Cumulative Timesteps: 1,115,908,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,584.46978
Policy Entropy: 1.69841
Value Function Loss: 0.05966

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.32336
Value Function Update Magnitude: 0.37336

Collected Steps per Second: 21,994.55405
Overall Steps per Second: 10,495.18000

Timestep Collection Time: 2.27556
Timestep Consumption Time: 2.49329
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.76886

Cumulative Model Updates: 133,714
Cumulative Timesteps: 1,115,958,376

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1115958376...
Checkpoint 1115958376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,872.75103
Policy Entropy: 1.70696
Value Function Loss: 0.05984

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.32241
Value Function Update Magnitude: 0.39521

Collected Steps per Second: 21,784.19708
Overall Steps per Second: 10,572.84828

Timestep Collection Time: 2.29607
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.73080

Cumulative Model Updates: 133,720
Cumulative Timesteps: 1,116,008,394

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,279.97840
Policy Entropy: 1.67946
Value Function Loss: 0.05572

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.32337
Value Function Update Magnitude: 0.38300

Collected Steps per Second: 21,899.70000
Overall Steps per Second: 10,595.53684

Timestep Collection Time: 2.28350
Timestep Consumption Time: 2.43622
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.71972

Cumulative Model Updates: 133,726
Cumulative Timesteps: 1,116,058,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1116058402...
Checkpoint 1116058402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,176.93367
Policy Entropy: 1.67896
Value Function Loss: 0.06223

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.33079
Value Function Update Magnitude: 0.34399

Collected Steps per Second: 21,860.83534
Overall Steps per Second: 10,684.58065

Timestep Collection Time: 2.28875
Timestep Consumption Time: 2.39407
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.68282

Cumulative Model Updates: 133,732
Cumulative Timesteps: 1,116,108,436

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,325.57542
Policy Entropy: 1.68662
Value Function Loss: 0.06395

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.32094
Value Function Update Magnitude: 0.33205

Collected Steps per Second: 21,418.25055
Overall Steps per Second: 10,362.20728

Timestep Collection Time: 2.33577
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.82793

Cumulative Model Updates: 133,738
Cumulative Timesteps: 1,116,158,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1116158464...
Checkpoint 1116158464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,621.25289
Policy Entropy: 1.69396
Value Function Loss: 0.06482

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.29530
Value Function Update Magnitude: 0.37591

Collected Steps per Second: 21,642.54151
Overall Steps per Second: 10,391.24915

Timestep Collection Time: 2.31100
Timestep Consumption Time: 2.50228
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.81328

Cumulative Model Updates: 133,744
Cumulative Timesteps: 1,116,208,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,938.87702
Policy Entropy: 1.69265
Value Function Loss: 0.06051

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.28346
Value Function Update Magnitude: 0.37884

Collected Steps per Second: 21,643.18461
Overall Steps per Second: 10,402.53232

Timestep Collection Time: 2.31057
Timestep Consumption Time: 2.49673
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.80729

Cumulative Model Updates: 133,750
Cumulative Timesteps: 1,116,258,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1116258488...
Checkpoint 1116258488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,922.99742
Policy Entropy: 1.68215
Value Function Loss: 0.06161

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.30342
Value Function Update Magnitude: 0.35422

Collected Steps per Second: 21,675.84360
Overall Steps per Second: 10,566.03346

Timestep Collection Time: 2.30847
Timestep Consumption Time: 2.42727
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.73574

Cumulative Model Updates: 133,756
Cumulative Timesteps: 1,116,308,526

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,677.92062
Policy Entropy: 1.68053
Value Function Loss: 0.06237

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.32380
Value Function Update Magnitude: 0.34897

Collected Steps per Second: 21,738.02705
Overall Steps per Second: 10,393.05588

Timestep Collection Time: 2.30122
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.81321

Cumulative Model Updates: 133,762
Cumulative Timesteps: 1,116,358,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1116358550...
Checkpoint 1116358550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,299.56235
Policy Entropy: 1.68769
Value Function Loss: 0.06229

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.31773
Value Function Update Magnitude: 0.33723

Collected Steps per Second: 21,844.17450
Overall Steps per Second: 10,368.96586

Timestep Collection Time: 2.28976
Timestep Consumption Time: 2.53405
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.82382

Cumulative Model Updates: 133,768
Cumulative Timesteps: 1,116,408,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,379.34072
Policy Entropy: 1.69947
Value Function Loss: 0.06161

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.30820
Value Function Update Magnitude: 0.33750

Collected Steps per Second: 22,130.00184
Overall Steps per Second: 10,660.85788

Timestep Collection Time: 2.26019
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.69174

Cumulative Model Updates: 133,774
Cumulative Timesteps: 1,116,458,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1116458586...
Checkpoint 1116458586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,681.19272
Policy Entropy: 1.70225
Value Function Loss: 0.05749

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.31738
Value Function Update Magnitude: 0.35044

Collected Steps per Second: 21,759.13261
Overall Steps per Second: 10,426.53521

Timestep Collection Time: 2.29899
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.79776

Cumulative Model Updates: 133,780
Cumulative Timesteps: 1,116,508,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,037.37421
Policy Entropy: 1.69422
Value Function Loss: 0.05535

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.31933
Value Function Update Magnitude: 0.34301

Collected Steps per Second: 22,039.26955
Overall Steps per Second: 10,646.84818

Timestep Collection Time: 2.26959
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.69810

Cumulative Model Updates: 133,786
Cumulative Timesteps: 1,116,558,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1116558630...
Checkpoint 1116558630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,937.22970
Policy Entropy: 1.68141
Value Function Loss: 0.05432

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.31902
Value Function Update Magnitude: 0.34184

Collected Steps per Second: 21,912.05532
Overall Steps per Second: 10,620.96160

Timestep Collection Time: 2.28231
Timestep Consumption Time: 2.42631
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.70861

Cumulative Model Updates: 133,792
Cumulative Timesteps: 1,116,608,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,067.84606
Policy Entropy: 1.67719
Value Function Loss: 0.05351

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.31752
Value Function Update Magnitude: 0.35171

Collected Steps per Second: 21,682.82031
Overall Steps per Second: 10,550.43563

Timestep Collection Time: 2.30625
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.73971

Cumulative Model Updates: 133,798
Cumulative Timesteps: 1,116,658,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1116658646...
Checkpoint 1116658646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,822.59958
Policy Entropy: 1.66200
Value Function Loss: 0.05330

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.31307
Value Function Update Magnitude: 0.35041

Collected Steps per Second: 21,609.59664
Overall Steps per Second: 10,556.92985

Timestep Collection Time: 2.31536
Timestep Consumption Time: 2.42409
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.73945

Cumulative Model Updates: 133,804
Cumulative Timesteps: 1,116,708,680

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,109.21407
Policy Entropy: 1.67859
Value Function Loss: 0.05616

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.31486
Value Function Update Magnitude: 0.34413

Collected Steps per Second: 21,615.08638
Overall Steps per Second: 10,510.75777

Timestep Collection Time: 2.31394
Timestep Consumption Time: 2.44461
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.75855

Cumulative Model Updates: 133,810
Cumulative Timesteps: 1,116,758,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1116758696...
Checkpoint 1116758696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,914.41147
Policy Entropy: 1.68575
Value Function Loss: 0.06054

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.31767
Value Function Update Magnitude: 0.34759

Collected Steps per Second: 21,451.53653
Overall Steps per Second: 10,373.34737

Timestep Collection Time: 2.33121
Timestep Consumption Time: 2.48961
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.82082

Cumulative Model Updates: 133,816
Cumulative Timesteps: 1,116,808,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,765.92720
Policy Entropy: 1.70351
Value Function Loss: 0.05399

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.31253
Value Function Update Magnitude: 0.33520

Collected Steps per Second: 21,042.80078
Overall Steps per Second: 10,406.94892

Timestep Collection Time: 2.37620
Timestep Consumption Time: 2.42847
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.80467

Cumulative Model Updates: 133,822
Cumulative Timesteps: 1,116,858,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1116858706...
Checkpoint 1116858706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,170.62073
Policy Entropy: 1.70349
Value Function Loss: 0.05457

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08087
Policy Update Magnitude: 0.30383
Value Function Update Magnitude: 0.32188

Collected Steps per Second: 20,822.58493
Overall Steps per Second: 10,485.65178

Timestep Collection Time: 2.40230
Timestep Consumption Time: 2.36822
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.77052

Cumulative Model Updates: 133,828
Cumulative Timesteps: 1,116,908,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,169.36646
Policy Entropy: 1.69810
Value Function Loss: 0.05368

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.28427
Value Function Update Magnitude: 0.31942

Collected Steps per Second: 21,006.34575
Overall Steps per Second: 10,487.91779

Timestep Collection Time: 2.38099
Timestep Consumption Time: 2.38792
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.76892

Cumulative Model Updates: 133,834
Cumulative Timesteps: 1,116,958,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1116958744...
Checkpoint 1116958744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,263.05004
Policy Entropy: 1.71389
Value Function Loss: 0.05997

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.28966
Value Function Update Magnitude: 0.32755

Collected Steps per Second: 21,240.90162
Overall Steps per Second: 10,564.35997

Timestep Collection Time: 2.35583
Timestep Consumption Time: 2.38085
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.73668

Cumulative Model Updates: 133,840
Cumulative Timesteps: 1,117,008,784

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,873.08528
Policy Entropy: 1.70289
Value Function Loss: 0.05829

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.28911
Value Function Update Magnitude: 0.34541

Collected Steps per Second: 21,506.59941
Overall Steps per Second: 10,522.02162

Timestep Collection Time: 2.32626
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.75479

Cumulative Model Updates: 133,846
Cumulative Timesteps: 1,117,058,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1117058814...
Checkpoint 1117058814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,679.33889
Policy Entropy: 1.70419
Value Function Loss: 0.05882

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.29850
Value Function Update Magnitude: 0.33483

Collected Steps per Second: 21,393.04379
Overall Steps per Second: 10,635.25078

Timestep Collection Time: 2.33740
Timestep Consumption Time: 2.36433
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.70172

Cumulative Model Updates: 133,852
Cumulative Timesteps: 1,117,108,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,793.39868
Policy Entropy: 1.69791
Value Function Loss: 0.05937

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.31204
Value Function Update Magnitude: 0.31763

Collected Steps per Second: 21,247.87195
Overall Steps per Second: 10,470.69522

Timestep Collection Time: 2.35515
Timestep Consumption Time: 2.42409
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.77924

Cumulative Model Updates: 133,858
Cumulative Timesteps: 1,117,158,860

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1117158860...
Checkpoint 1117158860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,995.47930
Policy Entropy: 1.71338
Value Function Loss: 0.06082

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.31786
Value Function Update Magnitude: 0.32583

Collected Steps per Second: 21,795.92631
Overall Steps per Second: 10,607.08980

Timestep Collection Time: 2.29575
Timestep Consumption Time: 2.42166
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.71741

Cumulative Model Updates: 133,864
Cumulative Timesteps: 1,117,208,898

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,482.78508
Policy Entropy: 1.71448
Value Function Loss: 0.05986

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.30393
Value Function Update Magnitude: 0.33148

Collected Steps per Second: 22,074.98114
Overall Steps per Second: 10,522.62644

Timestep Collection Time: 2.26582
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.75338

Cumulative Model Updates: 133,870
Cumulative Timesteps: 1,117,258,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1117258916...
Checkpoint 1117258916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,146.38944
Policy Entropy: 1.70402
Value Function Loss: 0.05585

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.28376
Value Function Update Magnitude: 0.33095

Collected Steps per Second: 21,672.45510
Overall Steps per Second: 10,607.85008

Timestep Collection Time: 2.30791
Timestep Consumption Time: 2.40728
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.71519

Cumulative Model Updates: 133,876
Cumulative Timesteps: 1,117,308,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,162.63445
Policy Entropy: 1.72368
Value Function Loss: 0.06050

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.29460
Value Function Update Magnitude: 0.31588

Collected Steps per Second: 21,897.53285
Overall Steps per Second: 10,472.99562

Timestep Collection Time: 2.28428
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.77609

Cumulative Model Updates: 133,882
Cumulative Timesteps: 1,117,358,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1117358954...
Checkpoint 1117358954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,117.31829
Policy Entropy: 1.74621
Value Function Loss: 0.05739

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.30694
Value Function Update Magnitude: 0.32606

Collected Steps per Second: 21,647.06404
Overall Steps per Second: 10,434.02668

Timestep Collection Time: 2.31034
Timestep Consumption Time: 2.48283
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.79316

Cumulative Model Updates: 133,888
Cumulative Timesteps: 1,117,408,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,366.41078
Policy Entropy: 1.75607
Value Function Loss: 0.05791

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.30935
Value Function Update Magnitude: 0.35886

Collected Steps per Second: 21,878.28099
Overall Steps per Second: 10,602.78191

Timestep Collection Time: 2.28656
Timestep Consumption Time: 2.43164
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.71820

Cumulative Model Updates: 133,894
Cumulative Timesteps: 1,117,458,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1117458992...
Checkpoint 1117458992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,284.33230
Policy Entropy: 1.74348
Value Function Loss: 0.04968

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.35558

Collected Steps per Second: 21,323.48963
Overall Steps per Second: 10,309.09285

Timestep Collection Time: 2.34568
Timestep Consumption Time: 2.50616
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.85183

Cumulative Model Updates: 133,900
Cumulative Timesteps: 1,117,509,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,454.90286
Policy Entropy: 1.71738
Value Function Loss: 0.04969

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.29536
Value Function Update Magnitude: 0.34095

Collected Steps per Second: 21,578.65550
Overall Steps per Second: 10,546.89757

Timestep Collection Time: 2.31775
Timestep Consumption Time: 2.42430
PPO Batch Consumption Time: 0.27459
Total Iteration Time: 4.74206

Cumulative Model Updates: 133,906
Cumulative Timesteps: 1,117,559,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1117559024...
Checkpoint 1117559024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,062.65142
Policy Entropy: 1.72688
Value Function Loss: 0.05644

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.30246
Value Function Update Magnitude: 0.31925

Collected Steps per Second: 21,930.92329
Overall Steps per Second: 10,585.52877

Timestep Collection Time: 2.28134
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.72645

Cumulative Model Updates: 133,912
Cumulative Timesteps: 1,117,609,056

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,866.89816
Policy Entropy: 1.71535
Value Function Loss: 0.06141

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.30886
Value Function Update Magnitude: 0.30329

Collected Steps per Second: 22,234.86001
Overall Steps per Second: 10,528.95369

Timestep Collection Time: 2.24881
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.74900

Cumulative Model Updates: 133,918
Cumulative Timesteps: 1,117,659,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1117659058...
Checkpoint 1117659058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,822.91599
Policy Entropy: 1.72971
Value Function Loss: 0.06116

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.29707
Value Function Update Magnitude: 0.33890

Collected Steps per Second: 21,899.68666
Overall Steps per Second: 10,491.89677

Timestep Collection Time: 2.28496
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.76940

Cumulative Model Updates: 133,924
Cumulative Timesteps: 1,117,709,098

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,920.06600
Policy Entropy: 1.70899
Value Function Loss: 0.05501

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.30142
Value Function Update Magnitude: 0.34152

Collected Steps per Second: 22,099.20442
Overall Steps per Second: 10,457.17925

Timestep Collection Time: 2.26361
Timestep Consumption Time: 2.52009
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.78370

Cumulative Model Updates: 133,930
Cumulative Timesteps: 1,117,759,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1117759122...
Checkpoint 1117759122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,278.54340
Policy Entropy: 1.70875
Value Function Loss: 0.05471

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.30730
Value Function Update Magnitude: 0.30327

Collected Steps per Second: 20,457.00533
Overall Steps per Second: 10,184.66614

Timestep Collection Time: 2.44562
Timestep Consumption Time: 2.46667
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.91229

Cumulative Model Updates: 133,936
Cumulative Timesteps: 1,117,809,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,077.54351
Policy Entropy: 1.71630
Value Function Loss: 0.05537

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.30924
Value Function Update Magnitude: 0.27809

Collected Steps per Second: 22,051.01129
Overall Steps per Second: 10,466.35476

Timestep Collection Time: 2.26765
Timestep Consumption Time: 2.50994
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.77759

Cumulative Model Updates: 133,942
Cumulative Timesteps: 1,117,859,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1117859156...
Checkpoint 1117859156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,168.04266
Policy Entropy: 1.72936
Value Function Loss: 0.05731

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.31019
Value Function Update Magnitude: 0.24375

Collected Steps per Second: 21,749.73221
Overall Steps per Second: 10,586.46492

Timestep Collection Time: 2.29925
Timestep Consumption Time: 2.42452
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.72377

Cumulative Model Updates: 133,948
Cumulative Timesteps: 1,117,909,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,893.05963
Policy Entropy: 1.74019
Value Function Loss: 0.05740

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.31253
Value Function Update Magnitude: 0.23898

Collected Steps per Second: 21,691.21843
Overall Steps per Second: 10,551.68754

Timestep Collection Time: 2.30545
Timestep Consumption Time: 2.43389
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.73934

Cumulative Model Updates: 133,954
Cumulative Timesteps: 1,117,959,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1117959172...
Checkpoint 1117959172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,906.35556
Policy Entropy: 1.73339
Value Function Loss: 0.06069

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.31766
Value Function Update Magnitude: 0.26824

Collected Steps per Second: 21,395.10769
Overall Steps per Second: 10,499.34676

Timestep Collection Time: 2.33726
Timestep Consumption Time: 2.42551
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.76277

Cumulative Model Updates: 133,960
Cumulative Timesteps: 1,118,009,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,525.45981
Policy Entropy: 1.74685
Value Function Loss: 0.05812

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.31404
Value Function Update Magnitude: 0.29663

Collected Steps per Second: 21,614.46103
Overall Steps per Second: 10,538.09991

Timestep Collection Time: 2.31447
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.74716

Cumulative Model Updates: 133,966
Cumulative Timesteps: 1,118,059,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1118059204...
Checkpoint 1118059204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,222.57602
Policy Entropy: 1.73176
Value Function Loss: 0.05749

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07932
Policy Update Magnitude: 0.31162
Value Function Update Magnitude: 0.30634

Collected Steps per Second: 20,819.47665
Overall Steps per Second: 10,368.80062

Timestep Collection Time: 2.40227
Timestep Consumption Time: 2.42124
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.82351

Cumulative Model Updates: 133,972
Cumulative Timesteps: 1,118,109,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,127.79527
Policy Entropy: 1.73111
Value Function Loss: 0.05850

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.31438
Value Function Update Magnitude: 0.31190

Collected Steps per Second: 21,202.27982
Overall Steps per Second: 10,444.46529

Timestep Collection Time: 2.35899
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.78876

Cumulative Model Updates: 133,978
Cumulative Timesteps: 1,118,159,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1118159234...
Checkpoint 1118159234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,361.93906
Policy Entropy: 1.72587
Value Function Loss: 0.06422

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.32157
Value Function Update Magnitude: 0.34798

Collected Steps per Second: 21,262.35171
Overall Steps per Second: 10,482.13395

Timestep Collection Time: 2.35261
Timestep Consumption Time: 2.41951
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.77212

Cumulative Model Updates: 133,984
Cumulative Timesteps: 1,118,209,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,266.67897
Policy Entropy: 1.73229
Value Function Loss: 0.06608

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.32725
Value Function Update Magnitude: 0.34384

Collected Steps per Second: 21,635.85164
Overall Steps per Second: 10,544.36312

Timestep Collection Time: 2.31274
Timestep Consumption Time: 2.43274
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74547

Cumulative Model Updates: 133,990
Cumulative Timesteps: 1,118,259,294

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1118259294...
Checkpoint 1118259294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,357.52651
Policy Entropy: 1.73721
Value Function Loss: 0.06320

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.32509
Value Function Update Magnitude: 0.30944

Collected Steps per Second: 21,094.36777
Overall Steps per Second: 10,586.53641

Timestep Collection Time: 2.37068
Timestep Consumption Time: 2.35306
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.72374

Cumulative Model Updates: 133,996
Cumulative Timesteps: 1,118,309,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,550.93716
Policy Entropy: 1.73941
Value Function Loss: 0.06155

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.32039
Value Function Update Magnitude: 0.32173

Collected Steps per Second: 21,665.66522
Overall Steps per Second: 10,405.07439

Timestep Collection Time: 2.30798
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.80573

Cumulative Model Updates: 134,002
Cumulative Timesteps: 1,118,359,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1118359306...
Checkpoint 1118359306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,067.99161
Policy Entropy: 1.73112
Value Function Loss: 0.05915

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.31863
Value Function Update Magnitude: 0.32596

Collected Steps per Second: 21,934.70999
Overall Steps per Second: 10,670.55620

Timestep Collection Time: 2.28077
Timestep Consumption Time: 2.40765
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.68842

Cumulative Model Updates: 134,008
Cumulative Timesteps: 1,118,409,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,197.67303
Policy Entropy: 1.71795
Value Function Loss: 0.05816

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.32033
Value Function Update Magnitude: 0.33457

Collected Steps per Second: 22,178.34221
Overall Steps per Second: 10,559.36607

Timestep Collection Time: 2.25544
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.73722

Cumulative Model Updates: 134,014
Cumulative Timesteps: 1,118,459,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1118459356...
Checkpoint 1118459356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,387.90546
Policy Entropy: 1.71805
Value Function Loss: 0.05413

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.31999
Value Function Update Magnitude: 0.34620

Collected Steps per Second: 21,791.25321
Overall Steps per Second: 10,546.82161

Timestep Collection Time: 2.29588
Timestep Consumption Time: 2.44773
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.74361

Cumulative Model Updates: 134,020
Cumulative Timesteps: 1,118,509,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,270.16838
Policy Entropy: 1.72374
Value Function Loss: 0.05410

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.31837
Value Function Update Magnitude: 0.35378

Collected Steps per Second: 21,645.93436
Overall Steps per Second: 10,437.41224

Timestep Collection Time: 2.31221
Timestep Consumption Time: 2.48304
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.79525

Cumulative Model Updates: 134,026
Cumulative Timesteps: 1,118,559,436

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1118559436...
Checkpoint 1118559436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,161.50939
Policy Entropy: 1.75091
Value Function Loss: 0.05569

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.31158
Value Function Update Magnitude: 0.35441

Collected Steps per Second: 21,213.71251
Overall Steps per Second: 10,331.48322

Timestep Collection Time: 2.35847
Timestep Consumption Time: 2.48420
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.84267

Cumulative Model Updates: 134,032
Cumulative Timesteps: 1,118,609,468

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,234.17669
Policy Entropy: 1.73721
Value Function Loss: 0.05594

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.29438
Value Function Update Magnitude: 0.35747

Collected Steps per Second: 21,942.47796
Overall Steps per Second: 10,474.99191

Timestep Collection Time: 2.27905
Timestep Consumption Time: 2.49499
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.77404

Cumulative Model Updates: 134,038
Cumulative Timesteps: 1,118,659,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1118659476...
Checkpoint 1118659476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,682.79875
Policy Entropy: 1.73741
Value Function Loss: 0.05673

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.08881
Policy Update Magnitude: 0.29721
Value Function Update Magnitude: 0.34773

Collected Steps per Second: 21,296.08724
Overall Steps per Second: 10,433.67367

Timestep Collection Time: 2.34963
Timestep Consumption Time: 2.44618
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.79582

Cumulative Model Updates: 134,044
Cumulative Timesteps: 1,118,709,514

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,005.61159
Policy Entropy: 1.70647
Value Function Loss: 0.05570

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.30066
Value Function Update Magnitude: 0.33820

Collected Steps per Second: 21,853.39635
Overall Steps per Second: 10,571.99425

Timestep Collection Time: 2.28953
Timestep Consumption Time: 2.44316
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.73269

Cumulative Model Updates: 134,050
Cumulative Timesteps: 1,118,759,548

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1118759548...
Checkpoint 1118759548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,205.79992
Policy Entropy: 1.72192
Value Function Loss: 0.05981

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.29565
Value Function Update Magnitude: 0.32669

Collected Steps per Second: 21,660.42536
Overall Steps per Second: 10,494.98632

Timestep Collection Time: 2.30956
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.76666

Cumulative Model Updates: 134,056
Cumulative Timesteps: 1,118,809,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,153.72185
Policy Entropy: 1.71091
Value Function Loss: 0.06389

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.28682
Value Function Update Magnitude: 0.30953

Collected Steps per Second: 21,737.54971
Overall Steps per Second: 10,508.54672

Timestep Collection Time: 2.30081
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.75936

Cumulative Model Updates: 134,062
Cumulative Timesteps: 1,118,859,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1118859588...
Checkpoint 1118859588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,343.26430
Policy Entropy: 1.73004
Value Function Loss: 0.06314

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.31677
Value Function Update Magnitude: 0.31779

Collected Steps per Second: 21,956.08195
Overall Steps per Second: 10,616.34047

Timestep Collection Time: 2.27764
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.71047

Cumulative Model Updates: 134,068
Cumulative Timesteps: 1,118,909,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,897.55125
Policy Entropy: 1.73350
Value Function Loss: 0.05899

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.32508
Value Function Update Magnitude: 0.35068

Collected Steps per Second: 22,163.65100
Overall Steps per Second: 10,509.81908

Timestep Collection Time: 2.25712
Timestep Consumption Time: 2.50281
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.75993

Cumulative Model Updates: 134,074
Cumulative Timesteps: 1,118,959,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1118959622...
Checkpoint 1118959622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,710.66647
Policy Entropy: 1.74425
Value Function Loss: 0.05470

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.32037
Value Function Update Magnitude: 0.34966

Collected Steps per Second: 21,902.90187
Overall Steps per Second: 10,585.05040

Timestep Collection Time: 2.28326
Timestep Consumption Time: 2.44133
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.72459

Cumulative Model Updates: 134,080
Cumulative Timesteps: 1,119,009,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,507.41537
Policy Entropy: 1.72514
Value Function Loss: 0.05293

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.31868
Value Function Update Magnitude: 0.31348

Collected Steps per Second: 21,908.76032
Overall Steps per Second: 10,487.43127

Timestep Collection Time: 2.28228
Timestep Consumption Time: 2.48552
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.76780

Cumulative Model Updates: 134,086
Cumulative Timesteps: 1,119,059,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1119059634...
Checkpoint 1119059634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,270.60712
Policy Entropy: 1.71860
Value Function Loss: 0.05386

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.31758
Value Function Update Magnitude: 0.28285

Collected Steps per Second: 21,756.91882
Overall Steps per Second: 10,595.80013

Timestep Collection Time: 2.29913
Timestep Consumption Time: 2.42180
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.72093

Cumulative Model Updates: 134,092
Cumulative Timesteps: 1,119,109,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,636.54248
Policy Entropy: 1.71089
Value Function Loss: 0.05125

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.31233
Value Function Update Magnitude: 0.29831

Collected Steps per Second: 21,391.23357
Overall Steps per Second: 10,463.62190

Timestep Collection Time: 2.33759
Timestep Consumption Time: 2.44125
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.77884

Cumulative Model Updates: 134,098
Cumulative Timesteps: 1,119,159,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1119159660...
Checkpoint 1119159660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,449.68361
Policy Entropy: 1.72057
Value Function Loss: 0.04827

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.30726
Value Function Update Magnitude: 0.31041

Collected Steps per Second: 21,653.99258
Overall Steps per Second: 10,429.76754

Timestep Collection Time: 2.30904
Timestep Consumption Time: 2.48493
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.79397

Cumulative Model Updates: 134,104
Cumulative Timesteps: 1,119,209,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,721.03026
Policy Entropy: 1.70400
Value Function Loss: 0.05023

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.30202
Value Function Update Magnitude: 0.27096

Collected Steps per Second: 21,572.84084
Overall Steps per Second: 10,383.94324

Timestep Collection Time: 2.31819
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.81609

Cumulative Model Updates: 134,110
Cumulative Timesteps: 1,119,259,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1119259670...
Checkpoint 1119259670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,425.82446
Policy Entropy: 1.70403
Value Function Loss: 0.05384

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.30541
Value Function Update Magnitude: 0.24268

Collected Steps per Second: 21,531.10625
Overall Steps per Second: 10,531.60487

Timestep Collection Time: 2.32222
Timestep Consumption Time: 2.42539
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.74761

Cumulative Model Updates: 134,116
Cumulative Timesteps: 1,119,309,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,522.77159
Policy Entropy: 1.72696
Value Function Loss: 0.05701

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.30905
Value Function Update Magnitude: 0.29071

Collected Steps per Second: 21,671.85506
Overall Steps per Second: 10,499.96506

Timestep Collection Time: 2.30797
Timestep Consumption Time: 2.45566
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.76363

Cumulative Model Updates: 134,122
Cumulative Timesteps: 1,119,359,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1119359688...
Checkpoint 1119359688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,075.54785
Policy Entropy: 1.74588
Value Function Loss: 0.05636

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.30914
Value Function Update Magnitude: 0.32615

Collected Steps per Second: 22,023.72194
Overall Steps per Second: 10,636.70645

Timestep Collection Time: 2.27191
Timestep Consumption Time: 2.43217
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.70409

Cumulative Model Updates: 134,128
Cumulative Timesteps: 1,119,409,724

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,307.19743
Policy Entropy: 1.78356
Value Function Loss: 0.06004

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08252
Policy Update Magnitude: 0.31175
Value Function Update Magnitude: 0.31916

Collected Steps per Second: 22,141.70657
Overall Steps per Second: 10,505.47733

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.50214
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.76114

Cumulative Model Updates: 134,134
Cumulative Timesteps: 1,119,459,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1119459742...
Checkpoint 1119459742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,470.45800
Policy Entropy: 1.76596
Value Function Loss: 0.06252

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.31379
Value Function Update Magnitude: 0.32617

Collected Steps per Second: 21,479.24188
Overall Steps per Second: 10,544.49005

Timestep Collection Time: 2.32783
Timestep Consumption Time: 2.41398
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.74181

Cumulative Model Updates: 134,140
Cumulative Timesteps: 1,119,509,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,434.30171
Policy Entropy: 1.76058
Value Function Loss: 0.06388

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.32344
Value Function Update Magnitude: 0.32707

Collected Steps per Second: 21,264.25639
Overall Steps per Second: 10,475.21408

Timestep Collection Time: 2.35193
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.77432

Cumulative Model Updates: 134,146
Cumulative Timesteps: 1,119,559,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1119559754...
Checkpoint 1119559754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,813.49607
Policy Entropy: 1.73935
Value Function Loss: 0.06146

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08259
Policy Update Magnitude: 0.32436
Value Function Update Magnitude: 0.31916

Collected Steps per Second: 21,233.18136
Overall Steps per Second: 10,612.85086

Timestep Collection Time: 2.35509
Timestep Consumption Time: 2.35675
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.71183

Cumulative Model Updates: 134,152
Cumulative Timesteps: 1,119,609,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,739.67804
Policy Entropy: 1.75424
Value Function Loss: 0.06156

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.32247
Value Function Update Magnitude: 0.34067

Collected Steps per Second: 21,140.50592
Overall Steps per Second: 10,464.33648

Timestep Collection Time: 2.36730
Timestep Consumption Time: 2.41523
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.78253

Cumulative Model Updates: 134,158
Cumulative Timesteps: 1,119,659,806

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1119659806...
Checkpoint 1119659806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,945.58631
Policy Entropy: 1.74934
Value Function Loss: 0.06534

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.32543
Value Function Update Magnitude: 0.35683

Collected Steps per Second: 21,019.25566
Overall Steps per Second: 10,587.64366

Timestep Collection Time: 2.37877
Timestep Consumption Time: 2.34371
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.72249

Cumulative Model Updates: 134,164
Cumulative Timesteps: 1,119,709,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,668.90124
Policy Entropy: 1.74662
Value Function Loss: 0.06483

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.33071
Value Function Update Magnitude: 0.34900

Collected Steps per Second: 20,793.33416
Overall Steps per Second: 10,475.80954

Timestep Collection Time: 2.40567
Timestep Consumption Time: 2.36933
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.77500

Cumulative Model Updates: 134,170
Cumulative Timesteps: 1,119,759,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1119759828...
Checkpoint 1119759828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,281.85580
Policy Entropy: 1.74218
Value Function Loss: 0.05983

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.32094
Value Function Update Magnitude: 0.31771

Collected Steps per Second: 21,063.68183
Overall Steps per Second: 10,259.58935

Timestep Collection Time: 2.37518
Timestep Consumption Time: 2.50124
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.87641

Cumulative Model Updates: 134,176
Cumulative Timesteps: 1,119,809,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,721.83519
Policy Entropy: 1.74426
Value Function Loss: 0.05621

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08185
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.32557

Collected Steps per Second: 21,677.72674
Overall Steps per Second: 10,456.78352

Timestep Collection Time: 2.30771
Timestep Consumption Time: 2.47636
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.78407

Cumulative Model Updates: 134,182
Cumulative Timesteps: 1,119,859,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1119859884...
Checkpoint 1119859884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,214.45788
Policy Entropy: 1.74963
Value Function Loss: 0.05932

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.32081
Value Function Update Magnitude: 0.34713

Collected Steps per Second: 21,855.16304
Overall Steps per Second: 10,576.64870

Timestep Collection Time: 2.28916
Timestep Consumption Time: 2.44107
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.73023

Cumulative Model Updates: 134,188
Cumulative Timesteps: 1,119,909,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,514.22622
Policy Entropy: 1.75585
Value Function Loss: 0.06619

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.32339
Value Function Update Magnitude: 0.35401

Collected Steps per Second: 21,759.71577
Overall Steps per Second: 10,591.38620

Timestep Collection Time: 2.29902
Timestep Consumption Time: 2.42425
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.72327

Cumulative Model Updates: 134,194
Cumulative Timesteps: 1,119,959,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1119959940...
Checkpoint 1119959940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,215.54218
Policy Entropy: 1.75823
Value Function Loss: 0.06878

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.32407
Value Function Update Magnitude: 0.35381

Collected Steps per Second: 21,819.56030
Overall Steps per Second: 10,627.21265

Timestep Collection Time: 2.29290
Timestep Consumption Time: 2.41483
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.70773

Cumulative Model Updates: 134,200
Cumulative Timesteps: 1,120,009,970

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,715.62037
Policy Entropy: 1.73367
Value Function Loss: 0.06562

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.29831
Value Function Update Magnitude: 0.35276

Collected Steps per Second: 22,197.30117
Overall Steps per Second: 10,517.05253

Timestep Collection Time: 2.25343
Timestep Consumption Time: 2.50266
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.75609

Cumulative Model Updates: 134,206
Cumulative Timesteps: 1,120,059,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1120059990...
Checkpoint 1120059990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,380.85834
Policy Entropy: 1.71968
Value Function Loss: 0.05992

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.30017
Value Function Update Magnitude: 0.35197

Collected Steps per Second: 21,849.21846
Overall Steps per Second: 10,493.59859

Timestep Collection Time: 2.28924
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.76653

Cumulative Model Updates: 134,212
Cumulative Timesteps: 1,120,110,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,485.92702
Policy Entropy: 1.71180
Value Function Loss: 0.05996

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.31658
Value Function Update Magnitude: 0.36074

Collected Steps per Second: 21,946.77998
Overall Steps per Second: 10,465.58566

Timestep Collection Time: 2.27842
Timestep Consumption Time: 2.49952
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.77795

Cumulative Model Updates: 134,218
Cumulative Timesteps: 1,120,160,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1120160012...
Checkpoint 1120160012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,235.43262
Policy Entropy: 1.71066
Value Function Loss: 0.05849

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.31816
Value Function Update Magnitude: 0.37184

Collected Steps per Second: 21,924.56360
Overall Steps per Second: 10,611.27639

Timestep Collection Time: 2.28137
Timestep Consumption Time: 2.43230
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71366

Cumulative Model Updates: 134,224
Cumulative Timesteps: 1,120,210,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,290.81515
Policy Entropy: 1.72224
Value Function Loss: 0.05390

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.31464
Value Function Update Magnitude: 0.37018

Collected Steps per Second: 21,654.61713
Overall Steps per Second: 10,494.40768

Timestep Collection Time: 2.30944
Timestep Consumption Time: 2.45596
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.76540

Cumulative Model Updates: 134,230
Cumulative Timesteps: 1,120,260,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1120260040...
Checkpoint 1120260040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,333.17353
Policy Entropy: 1.71555
Value Function Loss: 0.05257

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.31301
Value Function Update Magnitude: 0.35639

Collected Steps per Second: 21,519.73653
Overall Steps per Second: 10,563.16650

Timestep Collection Time: 2.32438
Timestep Consumption Time: 2.41094
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.73532

Cumulative Model Updates: 134,236
Cumulative Timesteps: 1,120,310,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,667.75056
Policy Entropy: 1.72513
Value Function Loss: 0.05428

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.31486
Value Function Update Magnitude: 0.35820

Collected Steps per Second: 21,714.05931
Overall Steps per Second: 10,569.22206

Timestep Collection Time: 2.30284
Timestep Consumption Time: 2.42826
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.73110

Cumulative Model Updates: 134,242
Cumulative Timesteps: 1,120,360,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1120360064...
Checkpoint 1120360064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,273.39274
Policy Entropy: 1.71200
Value Function Loss: 0.05547

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.31870
Value Function Update Magnitude: 0.36499

Collected Steps per Second: 21,226.55020
Overall Steps per Second: 10,295.98540

Timestep Collection Time: 2.35658
Timestep Consumption Time: 2.50182
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.85840

Cumulative Model Updates: 134,248
Cumulative Timesteps: 1,120,410,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,621.19129
Policy Entropy: 1.71128
Value Function Loss: 0.05736

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.32350
Value Function Update Magnitude: 0.38523

Collected Steps per Second: 22,028.89070
Overall Steps per Second: 10,685.90463

Timestep Collection Time: 2.26984
Timestep Consumption Time: 2.40941
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.67925

Cumulative Model Updates: 134,254
Cumulative Timesteps: 1,120,460,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1120460088...
Checkpoint 1120460088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,481.22201
Policy Entropy: 1.72888
Value Function Loss: 0.05888

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.32494
Value Function Update Magnitude: 0.38595

Collected Steps per Second: 21,893.36734
Overall Steps per Second: 10,413.21518

Timestep Collection Time: 2.28398
Timestep Consumption Time: 2.51800
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.80198

Cumulative Model Updates: 134,260
Cumulative Timesteps: 1,120,510,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,188.15347
Policy Entropy: 1.73401
Value Function Loss: 0.06272

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.31470
Value Function Update Magnitude: 0.33922

Collected Steps per Second: 22,202.70957
Overall Steps per Second: 10,638.84445

Timestep Collection Time: 2.25324
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.70239

Cumulative Model Updates: 134,266
Cumulative Timesteps: 1,120,560,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1120560120...
Checkpoint 1120560120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,004.41682
Policy Entropy: 1.73207
Value Function Loss: 0.06493

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.31785
Value Function Update Magnitude: 0.26970

Collected Steps per Second: 22,066.03170
Overall Steps per Second: 10,647.42858

Timestep Collection Time: 2.26683
Timestep Consumption Time: 2.43102
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.69785

Cumulative Model Updates: 134,272
Cumulative Timesteps: 1,120,610,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,093.53587
Policy Entropy: 1.71905
Value Function Loss: 0.06543

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.31267
Value Function Update Magnitude: 0.31343

Collected Steps per Second: 21,984.46869
Overall Steps per Second: 10,508.56533

Timestep Collection Time: 2.27597
Timestep Consumption Time: 2.48548
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.76145

Cumulative Model Updates: 134,278
Cumulative Timesteps: 1,120,660,176

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1120660176...
Checkpoint 1120660176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,841.08130
Policy Entropy: 1.73372
Value Function Loss: 0.06060

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.31000
Value Function Update Magnitude: 0.33612

Collected Steps per Second: 21,989.42748
Overall Steps per Second: 10,625.94465

Timestep Collection Time: 2.27382
Timestep Consumption Time: 2.43164
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.70546

Cumulative Model Updates: 134,284
Cumulative Timesteps: 1,120,710,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,722.75645
Policy Entropy: 1.73535
Value Function Loss: 0.06133

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.31034
Value Function Update Magnitude: 0.32544

Collected Steps per Second: 21,911.71140
Overall Steps per Second: 10,457.07975

Timestep Collection Time: 2.28280
Timestep Consumption Time: 2.50056
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.78336

Cumulative Model Updates: 134,290
Cumulative Timesteps: 1,120,760,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1120760196...
Checkpoint 1120760196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,450.67421
Policy Entropy: 1.74535
Value Function Loss: 0.05826

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.29117
Value Function Update Magnitude: 0.35019

Collected Steps per Second: 21,663.28883
Overall Steps per Second: 10,394.00375

Timestep Collection Time: 2.30833
Timestep Consumption Time: 2.50271
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.81104

Cumulative Model Updates: 134,296
Cumulative Timesteps: 1,120,810,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,719.07212
Policy Entropy: 1.75802
Value Function Loss: 0.06466

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.30020
Value Function Update Magnitude: 0.36792

Collected Steps per Second: 21,597.58942
Overall Steps per Second: 10,475.14393

Timestep Collection Time: 2.31572
Timestep Consumption Time: 2.45882
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.77454

Cumulative Model Updates: 134,302
Cumulative Timesteps: 1,120,860,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1120860216...
Checkpoint 1120860216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,995.64756
Policy Entropy: 1.76799
Value Function Loss: 0.06825

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.32478
Value Function Update Magnitude: 0.38879

Collected Steps per Second: 21,298.59082
Overall Steps per Second: 10,517.20973

Timestep Collection Time: 2.34908
Timestep Consumption Time: 2.40808
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.75716

Cumulative Model Updates: 134,308
Cumulative Timesteps: 1,120,910,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,876.74782
Policy Entropy: 1.75754
Value Function Loss: 0.07291

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.33892
Value Function Update Magnitude: 0.40147

Collected Steps per Second: 21,865.69265
Overall Steps per Second: 10,389.58040

Timestep Collection Time: 2.28788
Timestep Consumption Time: 2.52714
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.81502

Cumulative Model Updates: 134,314
Cumulative Timesteps: 1,120,960,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1120960274...
Checkpoint 1120960274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,715.19788
Policy Entropy: 1.75386
Value Function Loss: 0.07341

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.34140
Value Function Update Magnitude: 0.40420

Collected Steps per Second: 22,030.25328
Overall Steps per Second: 10,553.93827

Timestep Collection Time: 2.27033
Timestep Consumption Time: 2.46875
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.73908

Cumulative Model Updates: 134,320
Cumulative Timesteps: 1,121,010,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,005.50560
Policy Entropy: 1.74614
Value Function Loss: 0.06893

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.33941
Value Function Update Magnitude: 0.40611

Collected Steps per Second: 22,153.48317
Overall Steps per Second: 10,501.70261

Timestep Collection Time: 2.25752
Timestep Consumption Time: 2.50475
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.76228

Cumulative Model Updates: 134,326
Cumulative Timesteps: 1,121,060,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1121060302...
Checkpoint 1121060302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,262.12203
Policy Entropy: 1.75893
Value Function Loss: 0.06587

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.33544
Value Function Update Magnitude: 0.38770

Collected Steps per Second: 22,192.62102
Overall Steps per Second: 10,665.26635

Timestep Collection Time: 2.25426
Timestep Consumption Time: 2.43648
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.69074

Cumulative Model Updates: 134,332
Cumulative Timesteps: 1,121,110,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,256.59609
Policy Entropy: 1.74309
Value Function Loss: 0.06702

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.32172
Value Function Update Magnitude: 0.37763

Collected Steps per Second: 21,955.50236
Overall Steps per Second: 10,447.85136

Timestep Collection Time: 2.27806
Timestep Consumption Time: 2.50914
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.78720

Cumulative Model Updates: 134,338
Cumulative Timesteps: 1,121,160,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1121160346...
Checkpoint 1121160346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,530.66688
Policy Entropy: 1.73542
Value Function Loss: 0.06331

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.30336
Value Function Update Magnitude: 0.37692

Collected Steps per Second: 21,881.58926
Overall Steps per Second: 10,580.37795

Timestep Collection Time: 2.28658
Timestep Consumption Time: 2.44236
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.72894

Cumulative Model Updates: 134,344
Cumulative Timesteps: 1,121,210,380

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,191.45121
Policy Entropy: 1.71856
Value Function Loss: 0.05714

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.30725
Value Function Update Magnitude: 0.37120

Collected Steps per Second: 22,138.07650
Overall Steps per Second: 10,550.32131

Timestep Collection Time: 2.25955
Timestep Consumption Time: 2.48173
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.74128

Cumulative Model Updates: 134,350
Cumulative Timesteps: 1,121,260,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1121260402...
Checkpoint 1121260402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,108.53225
Policy Entropy: 1.71842
Value Function Loss: 0.05434

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.31488
Value Function Update Magnitude: 0.34841

Collected Steps per Second: 21,811.58171
Overall Steps per Second: 10,594.13308

Timestep Collection Time: 2.29264
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.72016

Cumulative Model Updates: 134,356
Cumulative Timesteps: 1,121,310,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,652.64861
Policy Entropy: 1.72214
Value Function Loss: 0.05797

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.31857
Value Function Update Magnitude: 0.34612

Collected Steps per Second: 21,619.57094
Overall Steps per Second: 10,535.64614

Timestep Collection Time: 2.31327
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.74693

Cumulative Model Updates: 134,362
Cumulative Timesteps: 1,121,360,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1121360420...
Checkpoint 1121360420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,380.21672
Policy Entropy: 1.74087
Value Function Loss: 0.06309

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.32174
Value Function Update Magnitude: 0.36179

Collected Steps per Second: 21,701.95048
Overall Steps per Second: 10,558.01266

Timestep Collection Time: 2.30541
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.73877

Cumulative Model Updates: 134,368
Cumulative Timesteps: 1,121,410,452

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,583.24957
Policy Entropy: 1.73158
Value Function Loss: 0.06220

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.32386
Value Function Update Magnitude: 0.37203

Collected Steps per Second: 21,575.56695
Overall Steps per Second: 10,510.73172

Timestep Collection Time: 2.31762
Timestep Consumption Time: 2.43980
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.75742

Cumulative Model Updates: 134,374
Cumulative Timesteps: 1,121,460,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1121460456...
Checkpoint 1121460456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,995.20792
Policy Entropy: 1.72501
Value Function Loss: 0.05908

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.31982
Value Function Update Magnitude: 0.36484

Collected Steps per Second: 21,543.36138
Overall Steps per Second: 10,545.80264

Timestep Collection Time: 2.32146
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.74236

Cumulative Model Updates: 134,380
Cumulative Timesteps: 1,121,510,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,305.50437
Policy Entropy: 1.72755
Value Function Loss: 0.05702

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.31136
Value Function Update Magnitude: 0.36092

Collected Steps per Second: 21,324.11205
Overall Steps per Second: 10,412.04105

Timestep Collection Time: 2.34495
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.80252

Cumulative Model Updates: 134,386
Cumulative Timesteps: 1,121,560,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1121560472...
Checkpoint 1121560472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,937.71474
Policy Entropy: 1.72336
Value Function Loss: 0.05382

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.30922
Value Function Update Magnitude: 0.36753

Collected Steps per Second: 21,179.56937
Overall Steps per Second: 10,468.97108

Timestep Collection Time: 2.36275
Timestep Consumption Time: 2.41728
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.78003

Cumulative Model Updates: 134,392
Cumulative Timesteps: 1,121,610,514

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,217.76860
Policy Entropy: 1.73017
Value Function Loss: 0.05479

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.31397
Value Function Update Magnitude: 0.37204

Collected Steps per Second: 21,287.15327
Overall Steps per Second: 10,646.67137

Timestep Collection Time: 2.34883
Timestep Consumption Time: 2.34747
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.69630

Cumulative Model Updates: 134,398
Cumulative Timesteps: 1,121,660,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1121660514...
Checkpoint 1121660514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,986.20935
Policy Entropy: 1.73515
Value Function Loss: 0.06587

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.32387
Value Function Update Magnitude: 0.37253

Collected Steps per Second: 21,069.48369
Overall Steps per Second: 10,459.48527

Timestep Collection Time: 2.37471
Timestep Consumption Time: 2.40889
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.78360

Cumulative Model Updates: 134,404
Cumulative Timesteps: 1,121,710,548

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,761.85451
Policy Entropy: 1.74693
Value Function Loss: 0.06681

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.33316
Value Function Update Magnitude: 0.36537

Collected Steps per Second: 21,725.77726
Overall Steps per Second: 10,717.52846

Timestep Collection Time: 2.30233
Timestep Consumption Time: 2.36479
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.66712

Cumulative Model Updates: 134,410
Cumulative Timesteps: 1,121,760,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1121760568...
Checkpoint 1121760568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,670.11391
Policy Entropy: 1.72865
Value Function Loss: 0.06388

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.33175
Value Function Update Magnitude: 0.34283

Collected Steps per Second: 20,668.36675
Overall Steps per Second: 10,143.01896

Timestep Collection Time: 2.41925
Timestep Consumption Time: 2.51044
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.92970

Cumulative Model Updates: 134,416
Cumulative Timesteps: 1,121,810,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,107.74392
Policy Entropy: 1.73302
Value Function Loss: 0.06658

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.33103
Value Function Update Magnitude: 0.35286

Collected Steps per Second: 21,469.38264
Overall Steps per Second: 10,540.53128

Timestep Collection Time: 2.33057
Timestep Consumption Time: 2.41643
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.74701

Cumulative Model Updates: 134,422
Cumulative Timesteps: 1,121,860,606

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1121860606...
Checkpoint 1121860606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,786.40468
Policy Entropy: 1.73690
Value Function Loss: 0.06248

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.33087
Value Function Update Magnitude: 0.37969

Collected Steps per Second: 21,099.19571
Overall Steps per Second: 10,274.40800

Timestep Collection Time: 2.37052
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.86802

Cumulative Model Updates: 134,428
Cumulative Timesteps: 1,121,910,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,751.14305
Policy Entropy: 1.76253
Value Function Loss: 0.06694

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.32905
Value Function Update Magnitude: 0.36518

Collected Steps per Second: 21,513.46888
Overall Steps per Second: 10,358.22845

Timestep Collection Time: 2.32552
Timestep Consumption Time: 2.50446
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.82998

Cumulative Model Updates: 134,434
Cumulative Timesteps: 1,121,960,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1121960652...
Checkpoint 1121960652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,003.61811
Policy Entropy: 1.73768
Value Function Loss: 0.06113

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.32404
Value Function Update Magnitude: 0.33762

Collected Steps per Second: 21,568.80637
Overall Steps per Second: 10,581.29375

Timestep Collection Time: 2.31890
Timestep Consumption Time: 2.40793
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.72683

Cumulative Model Updates: 134,440
Cumulative Timesteps: 1,122,010,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,873.33509
Policy Entropy: 1.73377
Value Function Loss: 0.06194

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.31361
Value Function Update Magnitude: 0.33841

Collected Steps per Second: 22,041.10422
Overall Steps per Second: 10,563.72380

Timestep Collection Time: 2.27012
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.73659

Cumulative Model Updates: 134,446
Cumulative Timesteps: 1,122,060,704

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1122060704...
Checkpoint 1122060704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,849.70161
Policy Entropy: 1.72120
Value Function Loss: 0.05730

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.30043
Value Function Update Magnitude: 0.29042

Collected Steps per Second: 21,894.77245
Overall Steps per Second: 10,629.80082

Timestep Collection Time: 2.28438
Timestep Consumption Time: 2.42088
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.70526

Cumulative Model Updates: 134,452
Cumulative Timesteps: 1,122,110,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,810.44434
Policy Entropy: 1.73085
Value Function Loss: 0.06207

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07834
Policy Update Magnitude: 0.31262
Value Function Update Magnitude: 0.25478

Collected Steps per Second: 22,006.02988
Overall Steps per Second: 10,440.21770

Timestep Collection Time: 2.27338
Timestep Consumption Time: 2.51848
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.79185

Cumulative Model Updates: 134,458
Cumulative Timesteps: 1,122,160,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1122160748...
Checkpoint 1122160748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,124.39659
Policy Entropy: 1.73896
Value Function Loss: 0.06378

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.32552
Value Function Update Magnitude: 0.26912

Collected Steps per Second: 21,742.98386
Overall Steps per Second: 10,535.95228

Timestep Collection Time: 2.30060
Timestep Consumption Time: 2.44714
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.74774

Cumulative Model Updates: 134,464
Cumulative Timesteps: 1,122,210,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,228.83573
Policy Entropy: 1.74920
Value Function Loss: 0.06057

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.32289
Value Function Update Magnitude: 0.31166

Collected Steps per Second: 22,273.05715
Overall Steps per Second: 10,525.91517

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.50552
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.75056

Cumulative Model Updates: 134,470
Cumulative Timesteps: 1,122,260,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1122260774...
Checkpoint 1122260774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,121.39930
Policy Entropy: 1.74521
Value Function Loss: 0.05588

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.32830

Collected Steps per Second: 21,884.90565
Overall Steps per Second: 10,602.41642

Timestep Collection Time: 2.28550
Timestep Consumption Time: 2.43210
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.71760

Cumulative Model Updates: 134,476
Cumulative Timesteps: 1,122,310,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,466.82614
Policy Entropy: 1.75279
Value Function Loss: 0.05602

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.31535
Value Function Update Magnitude: 0.34293

Collected Steps per Second: 22,038.38932
Overall Steps per Second: 10,498.29832

Timestep Collection Time: 2.26977
Timestep Consumption Time: 2.49501
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.76477

Cumulative Model Updates: 134,482
Cumulative Timesteps: 1,122,360,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1122360814...
Checkpoint 1122360814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,341.54534
Policy Entropy: 1.76039
Value Function Loss: 0.05660

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.31758
Value Function Update Magnitude: 0.34427

Collected Steps per Second: 21,426.92267
Overall Steps per Second: 10,374.26974

Timestep Collection Time: 2.33379
Timestep Consumption Time: 2.48640
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.82019

Cumulative Model Updates: 134,488
Cumulative Timesteps: 1,122,410,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,477.34562
Policy Entropy: 1.77337
Value Function Loss: 0.06077

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.31659
Value Function Update Magnitude: 0.35200

Collected Steps per Second: 21,740.45712
Overall Steps per Second: 10,413.91242

Timestep Collection Time: 2.30060
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.80281

Cumulative Model Updates: 134,494
Cumulative Timesteps: 1,122,460,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1122460836...
Checkpoint 1122460836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,040.42355
Policy Entropy: 1.74796
Value Function Loss: 0.06374

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.32279
Value Function Update Magnitude: 0.33824

Collected Steps per Second: 21,535.28117
Overall Steps per Second: 10,521.71831

Timestep Collection Time: 2.32242
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.75341

Cumulative Model Updates: 134,500
Cumulative Timesteps: 1,122,510,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,425.88235
Policy Entropy: 1.73330
Value Function Loss: 0.06384

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.32286
Value Function Update Magnitude: 0.34713

Collected Steps per Second: 21,954.04132
Overall Steps per Second: 10,432.10801

Timestep Collection Time: 2.27885
Timestep Consumption Time: 2.51692
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.79577

Cumulative Model Updates: 134,506
Cumulative Timesteps: 1,122,560,880

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1122560880...
Checkpoint 1122560880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,591.23945
Policy Entropy: 1.72304
Value Function Loss: 0.06128

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.31239
Value Function Update Magnitude: 0.35953

Collected Steps per Second: 21,997.24984
Overall Steps per Second: 10,568.92437

Timestep Collection Time: 2.27383
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.73255

Cumulative Model Updates: 134,512
Cumulative Timesteps: 1,122,610,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,250.31281
Policy Entropy: 1.74187
Value Function Loss: 0.06240

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.29126
Value Function Update Magnitude: 0.36290

Collected Steps per Second: 22,051.12101
Overall Steps per Second: 10,506.29951

Timestep Collection Time: 2.26855
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.76133

Cumulative Model Updates: 134,518
Cumulative Timesteps: 1,122,660,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1122660922...
Checkpoint 1122660922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,289.82353
Policy Entropy: 1.74809
Value Function Loss: 0.06142

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.31004
Value Function Update Magnitude: 0.36364

Collected Steps per Second: 21,781.91347
Overall Steps per Second: 10,595.61099

Timestep Collection Time: 2.29622
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.72045

Cumulative Model Updates: 134,524
Cumulative Timesteps: 1,122,710,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,738.94711
Policy Entropy: 1.75086
Value Function Loss: 0.06492

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.32024
Value Function Update Magnitude: 0.36858

Collected Steps per Second: 21,479.78390
Overall Steps per Second: 10,489.23410

Timestep Collection Time: 2.32898
Timestep Consumption Time: 2.44029
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.76927

Cumulative Model Updates: 134,530
Cumulative Timesteps: 1,122,760,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1122760964...
Checkpoint 1122760964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,218.58072
Policy Entropy: 1.73212
Value Function Loss: 0.06065

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.32155
Value Function Update Magnitude: 0.36675

Collected Steps per Second: 21,084.07178
Overall Steps per Second: 10,576.48101

Timestep Collection Time: 2.37269
Timestep Consumption Time: 2.35724
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.72993

Cumulative Model Updates: 134,536
Cumulative Timesteps: 1,122,810,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,693.59282
Policy Entropy: 1.73367
Value Function Loss: 0.06234

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08888
Policy Update Magnitude: 0.32046
Value Function Update Magnitude: 0.34474

Collected Steps per Second: 21,221.19643
Overall Steps per Second: 10,611.40802

Timestep Collection Time: 2.35670
Timestep Consumption Time: 2.35634
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.71304

Cumulative Model Updates: 134,542
Cumulative Timesteps: 1,122,861,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1122861002...
Checkpoint 1122861002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,593.47083
Policy Entropy: 1.73827
Value Function Loss: 0.06177

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.32122
Value Function Update Magnitude: 0.35245

Collected Steps per Second: 21,250.16975
Overall Steps per Second: 10,632.87544

Timestep Collection Time: 2.35415
Timestep Consumption Time: 2.35070
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.70484

Cumulative Model Updates: 134,548
Cumulative Timesteps: 1,122,911,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,773.66496
Policy Entropy: 1.75122
Value Function Loss: 0.06150

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.31724
Value Function Update Magnitude: 0.34008

Collected Steps per Second: 21,299.23730
Overall Steps per Second: 10,404.11186

Timestep Collection Time: 2.34947
Timestep Consumption Time: 2.46036
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.80983

Cumulative Model Updates: 134,554
Cumulative Timesteps: 1,122,961,070

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1122961070...
Checkpoint 1122961070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,580.97288
Policy Entropy: 1.74632
Value Function Loss: 0.05995

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.30542
Value Function Update Magnitude: 0.34179

Collected Steps per Second: 21,129.67186
Overall Steps per Second: 10,348.22850

Timestep Collection Time: 2.36814
Timestep Consumption Time: 2.46728
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.83542

Cumulative Model Updates: 134,560
Cumulative Timesteps: 1,123,011,108

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,479.78918
Policy Entropy: 1.73739
Value Function Loss: 0.05904

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.29652
Value Function Update Magnitude: 0.34641

Collected Steps per Second: 21,867.46584
Overall Steps per Second: 10,698.59309

Timestep Collection Time: 2.28650
Timestep Consumption Time: 2.38701
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.67351

Cumulative Model Updates: 134,566
Cumulative Timesteps: 1,123,061,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1123061108...
Checkpoint 1123061108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,296.44964
Policy Entropy: 1.72890
Value Function Loss: 0.05806

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.35467

Collected Steps per Second: 21,307.53130
Overall Steps per Second: 10,357.55001

Timestep Collection Time: 2.34743
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.82913

Cumulative Model Updates: 134,572
Cumulative Timesteps: 1,123,111,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,726.36170
Policy Entropy: 1.73835
Value Function Loss: 0.06061

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.31984
Value Function Update Magnitude: 0.36379

Collected Steps per Second: 21,898.97486
Overall Steps per Second: 10,393.67953

Timestep Collection Time: 2.28321
Timestep Consumption Time: 2.52740
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.81062

Cumulative Model Updates: 134,578
Cumulative Timesteps: 1,123,161,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1123161126...
Checkpoint 1123161126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,302.40768
Policy Entropy: 1.74739
Value Function Loss: 0.06511

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.32479
Value Function Update Magnitude: 0.37801

Collected Steps per Second: 21,664.87237
Overall Steps per Second: 10,315.34943

Timestep Collection Time: 2.31010
Timestep Consumption Time: 2.54170
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.85180

Cumulative Model Updates: 134,584
Cumulative Timesteps: 1,123,211,174

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,770.10628
Policy Entropy: 1.73762
Value Function Loss: 0.06020

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.31940
Value Function Update Magnitude: 0.35512

Collected Steps per Second: 22,030.31037
Overall Steps per Second: 10,492.62098

Timestep Collection Time: 2.27042
Timestep Consumption Time: 2.49655
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.76697

Cumulative Model Updates: 134,590
Cumulative Timesteps: 1,123,261,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1123261192...
Checkpoint 1123261192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,989.75893
Policy Entropy: 1.73746
Value Function Loss: 0.05849

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.31162
Value Function Update Magnitude: 0.35182

Collected Steps per Second: 21,963.99315
Overall Steps per Second: 10,445.00638

Timestep Collection Time: 2.27773
Timestep Consumption Time: 2.51193
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.78966

Cumulative Model Updates: 134,596
Cumulative Timesteps: 1,123,311,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,707.15093
Policy Entropy: 1.71103
Value Function Loss: 0.05725

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.31392
Value Function Update Magnitude: 0.34238

Collected Steps per Second: 22,053.35303
Overall Steps per Second: 10,451.10875

Timestep Collection Time: 2.26832
Timestep Consumption Time: 2.51816
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.78648

Cumulative Model Updates: 134,602
Cumulative Timesteps: 1,123,361,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1123361244...
Checkpoint 1123361244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,016.36253
Policy Entropy: 1.73071
Value Function Loss: 0.06061

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.31761
Value Function Update Magnitude: 0.35082

Collected Steps per Second: 21,913.60964
Overall Steps per Second: 10,589.31412

Timestep Collection Time: 2.28388
Timestep Consumption Time: 2.44240
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.72627

Cumulative Model Updates: 134,608
Cumulative Timesteps: 1,123,411,292

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,586.68160
Policy Entropy: 1.72098
Value Function Loss: 0.06032

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.32300
Value Function Update Magnitude: 0.37104

Collected Steps per Second: 20,745.45162
Overall Steps per Second: 10,155.71081

Timestep Collection Time: 2.41075
Timestep Consumption Time: 2.51377
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.92452

Cumulative Model Updates: 134,614
Cumulative Timesteps: 1,123,461,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1123461304...
Checkpoint 1123461304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,310.85795
Policy Entropy: 1.71838
Value Function Loss: 0.06049

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.32317
Value Function Update Magnitude: 0.37651

Collected Steps per Second: 21,304.06585
Overall Steps per Second: 10,473.28830

Timestep Collection Time: 2.34847
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.77711

Cumulative Model Updates: 134,620
Cumulative Timesteps: 1,123,511,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,828.53334
Policy Entropy: 1.70457
Value Function Loss: 0.05820

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.32019
Value Function Update Magnitude: 0.36492

Collected Steps per Second: 21,517.89039
Overall Steps per Second: 10,496.00145

Timestep Collection Time: 2.32393
Timestep Consumption Time: 2.44036
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.76429

Cumulative Model Updates: 134,626
Cumulative Timesteps: 1,123,561,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1123561342...
Checkpoint 1123561342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,849.08945
Policy Entropy: 1.70806
Value Function Loss: 0.05816

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.31459
Value Function Update Magnitude: 0.34374

Collected Steps per Second: 21,523.20082
Overall Steps per Second: 10,349.71600

Timestep Collection Time: 2.32410
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.83318

Cumulative Model Updates: 134,632
Cumulative Timesteps: 1,123,611,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,429.87398
Policy Entropy: 1.71957
Value Function Loss: 0.05448

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07334
Policy Update Magnitude: 0.31088
Value Function Update Magnitude: 0.32419

Collected Steps per Second: 22,068.82457
Overall Steps per Second: 10,414.75950

Timestep Collection Time: 2.26646
Timestep Consumption Time: 2.53615
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.80261

Cumulative Model Updates: 134,638
Cumulative Timesteps: 1,123,661,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1123661382...
Checkpoint 1123661382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,434.96946
Policy Entropy: 1.71912
Value Function Loss: 0.05377

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07347
Policy Update Magnitude: 0.31101
Value Function Update Magnitude: 0.30718

Collected Steps per Second: 21,817.52533
Overall Steps per Second: 10,566.47085

Timestep Collection Time: 2.29210
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.73271

Cumulative Model Updates: 134,644
Cumulative Timesteps: 1,123,711,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,193.02206
Policy Entropy: 1.72866
Value Function Loss: 0.05557

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.31161
Value Function Update Magnitude: 0.31086

Collected Steps per Second: 22,185.08102
Overall Steps per Second: 10,480.49603

Timestep Collection Time: 2.25476
Timestep Consumption Time: 2.51811
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.77287

Cumulative Model Updates: 134,650
Cumulative Timesteps: 1,123,761,412

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1123761412...
Checkpoint 1123761412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,576.92946
Policy Entropy: 1.72634
Value Function Loss: 0.05993

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.31835
Value Function Update Magnitude: 0.31726

Collected Steps per Second: 21,895.87347
Overall Steps per Second: 10,617.71712

Timestep Collection Time: 2.28354
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.70911

Cumulative Model Updates: 134,656
Cumulative Timesteps: 1,123,811,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,198.30888
Policy Entropy: 1.73437
Value Function Loss: 0.06219

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.32296
Value Function Update Magnitude: 0.32131

Collected Steps per Second: 21,985.06731
Overall Steps per Second: 10,466.29041

Timestep Collection Time: 2.27600
Timestep Consumption Time: 2.50487
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.78087

Cumulative Model Updates: 134,662
Cumulative Timesteps: 1,123,861,450

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1123861450...
Checkpoint 1123861450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,522.36555
Policy Entropy: 1.72350
Value Function Loss: 0.05770

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.31784
Value Function Update Magnitude: 0.35800

Collected Steps per Second: 22,235.48987
Overall Steps per Second: 10,638.69943

Timestep Collection Time: 2.24992
Timestep Consumption Time: 2.45254
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.70245

Cumulative Model Updates: 134,668
Cumulative Timesteps: 1,123,911,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,723.52301
Policy Entropy: 1.71251
Value Function Loss: 0.05115

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.31039
Value Function Update Magnitude: 0.36633

Collected Steps per Second: 21,954.19438
Overall Steps per Second: 10,429.34781

Timestep Collection Time: 2.27975
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.79896

Cumulative Model Updates: 134,674
Cumulative Timesteps: 1,123,961,528

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1123961528...
Checkpoint 1123961528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,058.28147
Policy Entropy: 1.70600
Value Function Loss: 0.05289

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.31015
Value Function Update Magnitude: 0.34204

Collected Steps per Second: 21,244.09443
Overall Steps per Second: 10,276.38441

Timestep Collection Time: 2.35454
Timestep Consumption Time: 2.51293
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.86747

Cumulative Model Updates: 134,680
Cumulative Timesteps: 1,124,011,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,728.60790
Policy Entropy: 1.72315
Value Function Loss: 0.05758

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.31357
Value Function Update Magnitude: 0.33269

Collected Steps per Second: 21,396.15105
Overall Steps per Second: 10,392.17387

Timestep Collection Time: 2.33762
Timestep Consumption Time: 2.47524
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.81285

Cumulative Model Updates: 134,686
Cumulative Timesteps: 1,124,061,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1124061564...
Checkpoint 1124061564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,623.42943
Policy Entropy: 1.74665
Value Function Loss: 0.06776

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.32680
Value Function Update Magnitude: 0.35487

Collected Steps per Second: 21,437.92623
Overall Steps per Second: 10,356.32385

Timestep Collection Time: 2.33287
Timestep Consumption Time: 2.49625
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.82913

Cumulative Model Updates: 134,692
Cumulative Timesteps: 1,124,111,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,732.45555
Policy Entropy: 1.73988
Value Function Loss: 0.06453

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.31176
Value Function Update Magnitude: 0.37816

Collected Steps per Second: 21,506.59644
Overall Steps per Second: 10,339.04628

Timestep Collection Time: 2.32487
Timestep Consumption Time: 2.51117
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.83604

Cumulative Model Updates: 134,698
Cumulative Timesteps: 1,124,161,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1124161576...
Checkpoint 1124161576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,865.19470
Policy Entropy: 1.73650
Value Function Loss: 0.06650

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.31268
Value Function Update Magnitude: 0.37872

Collected Steps per Second: 21,586.40901
Overall Steps per Second: 10,514.48163

Timestep Collection Time: 2.31711
Timestep Consumption Time: 2.43995
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.75706

Cumulative Model Updates: 134,704
Cumulative Timesteps: 1,124,211,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,626.73626
Policy Entropy: 1.73057
Value Function Loss: 0.06155

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.32044
Value Function Update Magnitude: 0.37319

Collected Steps per Second: 21,756.29350
Overall Steps per Second: 10,500.04314

Timestep Collection Time: 2.29892
Timestep Consumption Time: 2.46449
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.76341

Cumulative Model Updates: 134,710
Cumulative Timesteps: 1,124,261,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1124261610...
Checkpoint 1124261610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,947.26476
Policy Entropy: 1.75471
Value Function Loss: 0.06224

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.31961
Value Function Update Magnitude: 0.34095

Collected Steps per Second: 21,200.29629
Overall Steps per Second: 10,606.31091

Timestep Collection Time: 2.36091
Timestep Consumption Time: 2.35817
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.71908

Cumulative Model Updates: 134,716
Cumulative Timesteps: 1,124,311,662

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,731.66263
Policy Entropy: 1.75258
Value Function Loss: 0.05840

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.31096
Value Function Update Magnitude: 0.32130

Collected Steps per Second: 21,148.02080
Overall Steps per Second: 10,448.96873

Timestep Collection Time: 2.36542
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.78746

Cumulative Model Updates: 134,722
Cumulative Timesteps: 1,124,361,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1124361686...
Checkpoint 1124361686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,852.58268
Policy Entropy: 1.74112
Value Function Loss: 0.05677

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.30650
Value Function Update Magnitude: 0.32446

Collected Steps per Second: 21,349.39345
Overall Steps per Second: 10,638.19361

Timestep Collection Time: 2.34386
Timestep Consumption Time: 2.35995
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.70381

Cumulative Model Updates: 134,728
Cumulative Timesteps: 1,124,411,726

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,589.85741
Policy Entropy: 1.72946
Value Function Loss: 0.05684

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.30833
Value Function Update Magnitude: 0.33203

Collected Steps per Second: 21,188.99839
Overall Steps per Second: 10,510.33075

Timestep Collection Time: 2.36075
Timestep Consumption Time: 2.39856
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.75932

Cumulative Model Updates: 134,734
Cumulative Timesteps: 1,124,461,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1124461748...
Checkpoint 1124461748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,201.22005
Policy Entropy: 1.72693
Value Function Loss: 0.05921

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.31041
Value Function Update Magnitude: 0.31579

Collected Steps per Second: 21,576.87019
Overall Steps per Second: 10,593.86081

Timestep Collection Time: 2.31767
Timestep Consumption Time: 2.40280
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.72047

Cumulative Model Updates: 134,740
Cumulative Timesteps: 1,124,511,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,245.12769
Policy Entropy: 1.73294
Value Function Loss: 0.05473

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.32192

Collected Steps per Second: 21,841.76495
Overall Steps per Second: 10,493.78293

Timestep Collection Time: 2.28974
Timestep Consumption Time: 2.47613
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.76587

Cumulative Model Updates: 134,746
Cumulative Timesteps: 1,124,561,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1124561768...
Checkpoint 1124561768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,112.80988
Policy Entropy: 1.72164
Value Function Loss: 0.05330

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.30708
Value Function Update Magnitude: 0.32644

Collected Steps per Second: 21,473.14369
Overall Steps per Second: 10,581.40097

Timestep Collection Time: 2.32924
Timestep Consumption Time: 2.39755
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.72678

Cumulative Model Updates: 134,752
Cumulative Timesteps: 1,124,611,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,975.99432
Policy Entropy: 1.71938
Value Function Loss: 0.05427

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.30611
Value Function Update Magnitude: 0.33460

Collected Steps per Second: 21,339.46999
Overall Steps per Second: 10,499.05849

Timestep Collection Time: 2.34429
Timestep Consumption Time: 2.42051
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.76481

Cumulative Model Updates: 134,758
Cumulative Timesteps: 1,124,661,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1124661810...
Checkpoint 1124661810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,746.68083
Policy Entropy: 1.69687
Value Function Loss: 0.05632

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.30782
Value Function Update Magnitude: 0.32944

Collected Steps per Second: 21,666.85623
Overall Steps per Second: 10,577.12976

Timestep Collection Time: 2.30878
Timestep Consumption Time: 2.42067
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.72945

Cumulative Model Updates: 134,764
Cumulative Timesteps: 1,124,711,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,073.18210
Policy Entropy: 1.72609
Value Function Loss: 0.06029

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08174
Policy Update Magnitude: 0.31123
Value Function Update Magnitude: 0.32802

Collected Steps per Second: 21,924.33628
Overall Steps per Second: 10,446.09364

Timestep Collection Time: 2.28157
Timestep Consumption Time: 2.50701
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.78858

Cumulative Model Updates: 134,770
Cumulative Timesteps: 1,124,761,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1124761856...
Checkpoint 1124761856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,999.44505
Policy Entropy: 1.72322
Value Function Loss: 0.05984

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.31548
Value Function Update Magnitude: 0.33794

Collected Steps per Second: 21,660.45194
Overall Steps per Second: 10,318.11103

Timestep Collection Time: 2.30965
Timestep Consumption Time: 2.53891
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.84856

Cumulative Model Updates: 134,776
Cumulative Timesteps: 1,124,811,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,211.09062
Policy Entropy: 1.74466
Value Function Loss: 0.05680

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.31382
Value Function Update Magnitude: 0.35334

Collected Steps per Second: 22,000.53075
Overall Steps per Second: 10,440.08128

Timestep Collection Time: 2.27340
Timestep Consumption Time: 2.51737
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.79077

Cumulative Model Updates: 134,782
Cumulative Timesteps: 1,124,861,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1124861900...
Checkpoint 1124861900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,509.58661
Policy Entropy: 1.73222
Value Function Loss: 0.05897

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08209
Policy Update Magnitude: 0.31583
Value Function Update Magnitude: 0.33593

Collected Steps per Second: 22,167.72155
Overall Steps per Second: 10,617.63202

Timestep Collection Time: 2.25698
Timestep Consumption Time: 2.45519
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.71216

Cumulative Model Updates: 134,788
Cumulative Timesteps: 1,124,911,932

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,987.42195
Policy Entropy: 1.73147
Value Function Loss: 0.05643

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.31514
Value Function Update Magnitude: 0.31223

Collected Steps per Second: 21,997.02499
Overall Steps per Second: 10,463.03851

Timestep Collection Time: 2.27367
Timestep Consumption Time: 2.50639
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.78006

Cumulative Model Updates: 134,794
Cumulative Timesteps: 1,124,961,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1124961946...
Checkpoint 1124961946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,879.36946
Policy Entropy: 1.71417
Value Function Loss: 0.06086

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.31960
Value Function Update Magnitude: 0.31997

Collected Steps per Second: 21,742.32579
Overall Steps per Second: 10,559.10004

Timestep Collection Time: 2.30021
Timestep Consumption Time: 2.43617
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.73639

Cumulative Model Updates: 134,800
Cumulative Timesteps: 1,125,011,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,250.84295
Policy Entropy: 1.69337
Value Function Loss: 0.05714

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.32329
Value Function Update Magnitude: 0.33548

Collected Steps per Second: 21,866.52565
Overall Steps per Second: 10,607.65221

Timestep Collection Time: 2.28816
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.71678

Cumulative Model Updates: 134,806
Cumulative Timesteps: 1,125,061,992

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1125061992...
Checkpoint 1125061992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,241.50571
Policy Entropy: 1.71474
Value Function Loss: 0.06346

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07742
Policy Update Magnitude: 0.32804
Value Function Update Magnitude: 0.34512

Collected Steps per Second: 22,056.91490
Overall Steps per Second: 10,577.43885

Timestep Collection Time: 2.26795
Timestep Consumption Time: 2.46136
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.72931

Cumulative Model Updates: 134,812
Cumulative Timesteps: 1,125,112,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,012.72465
Policy Entropy: 1.72040
Value Function Loss: 0.06139

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07689
Policy Update Magnitude: 0.33289
Value Function Update Magnitude: 0.34443

Collected Steps per Second: 21,946.04955
Overall Steps per Second: 10,437.59669

Timestep Collection Time: 2.27841
Timestep Consumption Time: 2.51216
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.79057

Cumulative Model Updates: 134,818
Cumulative Timesteps: 1,125,162,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1125162018...
Checkpoint 1125162018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,789.97562
Policy Entropy: 1.75902
Value Function Loss: 0.06305

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.33110
Value Function Update Magnitude: 0.35345

Collected Steps per Second: 21,728.75939
Overall Steps per Second: 10,565.02162

Timestep Collection Time: 2.30156
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.73354

Cumulative Model Updates: 134,824
Cumulative Timesteps: 1,125,212,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,809.09748
Policy Entropy: 1.75938
Value Function Loss: 0.05889

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.32932
Value Function Update Magnitude: 0.34300

Collected Steps per Second: 21,394.11549
Overall Steps per Second: 10,485.18798

Timestep Collection Time: 2.33849
Timestep Consumption Time: 2.43300
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.77149

Cumulative Model Updates: 134,830
Cumulative Timesteps: 1,125,262,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1125262058...
Checkpoint 1125262058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,525.35970
Policy Entropy: 1.77120
Value Function Loss: 0.05788

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.32181
Value Function Update Magnitude: 0.30571

Collected Steps per Second: 21,342.38338
Overall Steps per Second: 10,306.00970

Timestep Collection Time: 2.34501
Timestep Consumption Time: 2.51119
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.85620

Cumulative Model Updates: 134,836
Cumulative Timesteps: 1,125,312,106

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,321.54197
Policy Entropy: 1.72999
Value Function Loss: 0.05597

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.31344
Value Function Update Magnitude: 0.31551

Collected Steps per Second: 21,341.87714
Overall Steps per Second: 10,403.78663

Timestep Collection Time: 2.34487
Timestep Consumption Time: 2.46530
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.81017

Cumulative Model Updates: 134,842
Cumulative Timesteps: 1,125,362,150

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1125362150...
Checkpoint 1125362150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,857.96577
Policy Entropy: 1.71838
Value Function Loss: 0.05809

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.29517
Value Function Update Magnitude: 0.32453

Collected Steps per Second: 21,377.34763
Overall Steps per Second: 10,618.34120

Timestep Collection Time: 2.33958
Timestep Consumption Time: 2.37057
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.71015

Cumulative Model Updates: 134,848
Cumulative Timesteps: 1,125,412,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,919.19940
Policy Entropy: 1.69162
Value Function Loss: 0.05944

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.28477
Value Function Update Magnitude: 0.32487

Collected Steps per Second: 21,367.73956
Overall Steps per Second: 10,429.30873

Timestep Collection Time: 2.34054
Timestep Consumption Time: 2.45479
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.79533

Cumulative Model Updates: 134,854
Cumulative Timesteps: 1,125,462,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1125462176...
Checkpoint 1125462176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,231.83261
Policy Entropy: 1.69286
Value Function Loss: 0.05560

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.29358
Value Function Update Magnitude: 0.33319

Collected Steps per Second: 21,092.91687
Overall Steps per Second: 10,304.29433

Timestep Collection Time: 2.37151
Timestep Consumption Time: 2.48297
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.85448

Cumulative Model Updates: 134,860
Cumulative Timesteps: 1,125,512,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,300.92359
Policy Entropy: 1.69870
Value Function Loss: 0.05493

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.29785
Value Function Update Magnitude: 0.33179

Collected Steps per Second: 21,924.54583
Overall Steps per Second: 10,474.46699

Timestep Collection Time: 2.28283
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.77829

Cumulative Model Updates: 134,866
Cumulative Timesteps: 1,125,562,248

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1125562248...
Checkpoint 1125562248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,745.85248
Policy Entropy: 1.70498
Value Function Loss: 0.05068

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.28372
Value Function Update Magnitude: 0.32046

Collected Steps per Second: 22,175.50527
Overall Steps per Second: 10,555.52730

Timestep Collection Time: 2.25609
Timestep Consumption Time: 2.48360
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.73970

Cumulative Model Updates: 134,872
Cumulative Timesteps: 1,125,612,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,207.81506
Policy Entropy: 1.70832
Value Function Loss: 0.05252

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.29395
Value Function Update Magnitude: 0.31488

Collected Steps per Second: 21,689.19874
Overall Steps per Second: 10,459.82808

Timestep Collection Time: 2.30659
Timestep Consumption Time: 2.47628
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.78287

Cumulative Model Updates: 134,878
Cumulative Timesteps: 1,125,662,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1125662306...
Checkpoint 1125662306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,178.22888
Policy Entropy: 1.71265
Value Function Loss: 0.05307

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.28180
Value Function Update Magnitude: 0.31829

Collected Steps per Second: 21,501.02100
Overall Steps per Second: 10,375.23411

Timestep Collection Time: 2.32566
Timestep Consumption Time: 2.49390
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.81955

Cumulative Model Updates: 134,884
Cumulative Timesteps: 1,125,712,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,820.73085
Policy Entropy: 1.71332
Value Function Loss: 0.05572

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.28850
Value Function Update Magnitude: 0.33150

Collected Steps per Second: 21,846.48149
Overall Steps per Second: 10,427.91999

Timestep Collection Time: 2.28952
Timestep Consumption Time: 2.50702
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.79655

Cumulative Model Updates: 134,890
Cumulative Timesteps: 1,125,762,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1125762328...
Checkpoint 1125762328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,139.05480
Policy Entropy: 1.72544
Value Function Loss: 0.05378

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.30387
Value Function Update Magnitude: 0.33408

Collected Steps per Second: 21,222.31958
Overall Steps per Second: 10,456.30021

Timestep Collection Time: 2.35733
Timestep Consumption Time: 2.42715
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.78448

Cumulative Model Updates: 134,896
Cumulative Timesteps: 1,125,812,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,708.04102
Policy Entropy: 1.72172
Value Function Loss: 0.05448

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.30924
Value Function Update Magnitude: 0.32120

Collected Steps per Second: 21,666.21269
Overall Steps per Second: 10,575.16658

Timestep Collection Time: 2.30811
Timestep Consumption Time: 2.42070
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.72881

Cumulative Model Updates: 134,902
Cumulative Timesteps: 1,125,862,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1125862364...
Checkpoint 1125862364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,888.96562
Policy Entropy: 1.74223
Value Function Loss: 0.05814

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.31314
Value Function Update Magnitude: 0.31464

Collected Steps per Second: 21,619.06711
Overall Steps per Second: 10,527.74838

Timestep Collection Time: 2.31324
Timestep Consumption Time: 2.43707
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.75030

Cumulative Model Updates: 134,908
Cumulative Timesteps: 1,125,912,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,598.10279
Policy Entropy: 1.74405
Value Function Loss: 0.05922

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.31232
Value Function Update Magnitude: 0.32394

Collected Steps per Second: 22,065.21603
Overall Steps per Second: 10,442.83876

Timestep Collection Time: 2.26782
Timestep Consumption Time: 2.52398
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.79180

Cumulative Model Updates: 134,914
Cumulative Timesteps: 1,125,962,414

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1125962414...
Checkpoint 1125962414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,625.04273
Policy Entropy: 1.73748
Value Function Loss: 0.05610

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.31262
Value Function Update Magnitude: 0.34530

Collected Steps per Second: 21,880.44306
Overall Steps per Second: 10,585.60657

Timestep Collection Time: 2.28542
Timestep Consumption Time: 2.43854
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.72396

Cumulative Model Updates: 134,920
Cumulative Timesteps: 1,126,012,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,931.26403
Policy Entropy: 1.71138
Value Function Loss: 0.05133

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08018
Policy Update Magnitude: 0.30981
Value Function Update Magnitude: 0.32970

Collected Steps per Second: 21,999.40719
Overall Steps per Second: 10,546.58757

Timestep Collection Time: 2.27424
Timestep Consumption Time: 2.46966
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.74390

Cumulative Model Updates: 134,926
Cumulative Timesteps: 1,126,062,452

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1126062452...
Checkpoint 1126062452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,372.26032
Policy Entropy: 1.71295
Value Function Loss: 0.05599

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.31343
Value Function Update Magnitude: 0.31461

Collected Steps per Second: 21,639.26216
Overall Steps per Second: 10,572.38558

Timestep Collection Time: 2.31126
Timestep Consumption Time: 2.41936
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.73063

Cumulative Model Updates: 134,932
Cumulative Timesteps: 1,126,112,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,173.65509
Policy Entropy: 1.73120
Value Function Loss: 0.06316

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.32091
Value Function Update Magnitude: 0.31880

Collected Steps per Second: 22,390.21545
Overall Steps per Second: 10,523.64269

Timestep Collection Time: 2.23526
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.75577

Cumulative Model Updates: 134,938
Cumulative Timesteps: 1,126,162,514

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1126162514...
Checkpoint 1126162514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,626.55120
Policy Entropy: 1.74888
Value Function Loss: 0.06672

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.32723
Value Function Update Magnitude: 0.33594

Collected Steps per Second: 21,907.25962
Overall Steps per Second: 10,607.06082

Timestep Collection Time: 2.28308
Timestep Consumption Time: 2.43227
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.71535

Cumulative Model Updates: 134,944
Cumulative Timesteps: 1,126,212,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,459.18522
Policy Entropy: 1.74572
Value Function Loss: 0.06385

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.32374
Value Function Update Magnitude: 0.35690

Collected Steps per Second: 21,930.31695
Overall Steps per Second: 10,480.23023

Timestep Collection Time: 2.28031
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.77165

Cumulative Model Updates: 134,950
Cumulative Timesteps: 1,126,262,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1126262538...
Checkpoint 1126262538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,525.22116
Policy Entropy: 1.74435
Value Function Loss: 0.05720

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.31545
Value Function Update Magnitude: 0.35953

Collected Steps per Second: 21,258.41142
Overall Steps per Second: 10,282.77846

Timestep Collection Time: 2.35286
Timestep Consumption Time: 2.51139
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.86425

Cumulative Model Updates: 134,956
Cumulative Timesteps: 1,126,312,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,732.85926
Policy Entropy: 1.73454
Value Function Loss: 0.05610

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.31032
Value Function Update Magnitude: 0.34021

Collected Steps per Second: 21,806.07782
Overall Steps per Second: 10,391.42467

Timestep Collection Time: 2.29340
Timestep Consumption Time: 2.51922
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.81262

Cumulative Model Updates: 134,962
Cumulative Timesteps: 1,126,362,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1126362566...
Checkpoint 1126362566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,659.61286
Policy Entropy: 1.72692
Value Function Loss: 0.05635

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07649
Policy Update Magnitude: 0.31223
Value Function Update Magnitude: 0.34998

Collected Steps per Second: 20,718.59937
Overall Steps per Second: 10,315.95500

Timestep Collection Time: 2.41406
Timestep Consumption Time: 2.43435
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.84841

Cumulative Model Updates: 134,968
Cumulative Timesteps: 1,126,412,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,043.98594
Policy Entropy: 1.71672
Value Function Loss: 0.05978

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.31648
Value Function Update Magnitude: 0.38175

Collected Steps per Second: 21,031.15295
Overall Steps per Second: 10,385.60034

Timestep Collection Time: 2.37847
Timestep Consumption Time: 2.43800
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.81648

Cumulative Model Updates: 134,974
Cumulative Timesteps: 1,126,462,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1126462604...
Checkpoint 1126462604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,300.41619
Policy Entropy: 1.71751
Value Function Loss: 0.06009

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.31982
Value Function Update Magnitude: 0.40884

Collected Steps per Second: 20,910.50357
Overall Steps per Second: 10,536.08720

Timestep Collection Time: 2.39219
Timestep Consumption Time: 2.35549
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.74768

Cumulative Model Updates: 134,980
Cumulative Timesteps: 1,126,512,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,900.16507
Policy Entropy: 1.72458
Value Function Loss: 0.05915

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.31659
Value Function Update Magnitude: 0.37848

Collected Steps per Second: 21,143.12261
Overall Steps per Second: 10,513.02012

Timestep Collection Time: 2.36588
Timestep Consumption Time: 2.39222
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.75810

Cumulative Model Updates: 134,986
Cumulative Timesteps: 1,126,562,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1126562648...
Checkpoint 1126562648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,229.26464
Policy Entropy: 1.73662
Value Function Loss: 0.05810

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.29891
Value Function Update Magnitude: 0.33988

Collected Steps per Second: 21,332.87983
Overall Steps per Second: 10,594.28819

Timestep Collection Time: 2.34502
Timestep Consumption Time: 2.37696
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.72198

Cumulative Model Updates: 134,992
Cumulative Timesteps: 1,126,612,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,378.30226
Policy Entropy: 1.74191
Value Function Loss: 0.05936

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.28264
Value Function Update Magnitude: 0.36909

Collected Steps per Second: 21,430.50300
Overall Steps per Second: 10,482.50660

Timestep Collection Time: 2.33340
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.77042

Cumulative Model Updates: 134,998
Cumulative Timesteps: 1,126,662,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1126662680...
Checkpoint 1126662680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,959.14526
Policy Entropy: 1.73590
Value Function Loss: 0.05959

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.30596
Value Function Update Magnitude: 0.38315

Collected Steps per Second: 21,054.98627
Overall Steps per Second: 10,310.64624

Timestep Collection Time: 2.37644
Timestep Consumption Time: 2.47640
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.85285

Cumulative Model Updates: 135,004
Cumulative Timesteps: 1,126,712,716

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,493.74920
Policy Entropy: 1.72437
Value Function Loss: 0.06006

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.31025
Value Function Update Magnitude: 0.37333

Collected Steps per Second: 22,138.76596
Overall Steps per Second: 10,698.88749

Timestep Collection Time: 2.25848
Timestep Consumption Time: 2.41490
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.67338

Cumulative Model Updates: 135,010
Cumulative Timesteps: 1,126,762,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1126762716...
Checkpoint 1126762716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,757.82688
Policy Entropy: 1.70957
Value Function Loss: 0.06110

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.31924
Value Function Update Magnitude: 0.38484

Collected Steps per Second: 21,843.73641
Overall Steps per Second: 10,667.39864

Timestep Collection Time: 2.29008
Timestep Consumption Time: 2.39934
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.68943

Cumulative Model Updates: 135,016
Cumulative Timesteps: 1,126,812,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,891.43386
Policy Entropy: 1.71825
Value Function Loss: 0.05862

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.31745
Value Function Update Magnitude: 0.39110

Collected Steps per Second: 22,000.35790
Overall Steps per Second: 10,521.05083

Timestep Collection Time: 2.27269
Timestep Consumption Time: 2.47969
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.75238

Cumulative Model Updates: 135,022
Cumulative Timesteps: 1,126,862,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1126862740...
Checkpoint 1126862740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,840.62615
Policy Entropy: 1.73178
Value Function Loss: 0.05674

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.31674
Value Function Update Magnitude: 0.38573

Collected Steps per Second: 21,459.56521
Overall Steps per Second: 10,566.68627

Timestep Collection Time: 2.33183
Timestep Consumption Time: 2.40381
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.73564

Cumulative Model Updates: 135,028
Cumulative Timesteps: 1,126,912,780

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,942.64600
Policy Entropy: 1.73894
Value Function Loss: 0.05580

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.31393
Value Function Update Magnitude: 0.38486

Collected Steps per Second: 21,692.67750
Overall Steps per Second: 10,575.47427

Timestep Collection Time: 2.30631
Timestep Consumption Time: 2.42445
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.73076

Cumulative Model Updates: 135,034
Cumulative Timesteps: 1,126,962,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1126962810...
Checkpoint 1126962810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,538.88217
Policy Entropy: 1.72582
Value Function Loss: 0.05601

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.31283
Value Function Update Magnitude: 0.37794

Collected Steps per Second: 21,268.30412
Overall Steps per Second: 10,301.06679

Timestep Collection Time: 2.35280
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.85775

Cumulative Model Updates: 135,040
Cumulative Timesteps: 1,127,012,850

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,541.58052
Policy Entropy: 1.72826
Value Function Loss: 0.05894

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.31399
Value Function Update Magnitude: 0.35603

Collected Steps per Second: 21,855.34287
Overall Steps per Second: 10,400.07520

Timestep Collection Time: 2.28859
Timestep Consumption Time: 2.52079
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.80939

Cumulative Model Updates: 135,046
Cumulative Timesteps: 1,127,062,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1127062868...
Checkpoint 1127062868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,658.12638
Policy Entropy: 1.73385
Value Function Loss: 0.05867

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.31016
Value Function Update Magnitude: 0.34849

Collected Steps per Second: 21,602.17670
Overall Steps per Second: 10,492.63870

Timestep Collection Time: 2.31495
Timestep Consumption Time: 2.45106
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.76601

Cumulative Model Updates: 135,052
Cumulative Timesteps: 1,127,112,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,621.55787
Policy Entropy: 1.74110
Value Function Loss: 0.05663

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.31052
Value Function Update Magnitude: 0.33497

Collected Steps per Second: 22,073.12172
Overall Steps per Second: 10,573.05179

Timestep Collection Time: 2.26520
Timestep Consumption Time: 2.46381
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.72900

Cumulative Model Updates: 135,058
Cumulative Timesteps: 1,127,162,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1127162876...
Checkpoint 1127162876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,126.92078
Policy Entropy: 1.74734
Value Function Loss: 0.05939

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.31460
Value Function Update Magnitude: 0.29493

Collected Steps per Second: 20,673.35614
Overall Steps per Second: 10,057.91181

Timestep Collection Time: 2.41973
Timestep Consumption Time: 2.55386
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.97360

Cumulative Model Updates: 135,064
Cumulative Timesteps: 1,127,212,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,282.05835
Policy Entropy: 1.74960
Value Function Loss: 0.06039

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07757
Policy Update Magnitude: 0.31871
Value Function Update Magnitude: 0.27867

Collected Steps per Second: 22,116.91201
Overall Steps per Second: 10,516.29414

Timestep Collection Time: 2.26252
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.75833

Cumulative Model Updates: 135,070
Cumulative Timesteps: 1,127,262,940

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1127262940...
Checkpoint 1127262940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,839.15386
Policy Entropy: 1.75455
Value Function Loss: 0.05916

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.31551
Value Function Update Magnitude: 0.31099

Collected Steps per Second: 21,937.77572
Overall Steps per Second: 10,609.72860

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.71284

Cumulative Model Updates: 135,076
Cumulative Timesteps: 1,127,312,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,032.59330
Policy Entropy: 1.76171
Value Function Loss: 0.05818

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.31399
Value Function Update Magnitude: 0.33507

Collected Steps per Second: 22,109.48576
Overall Steps per Second: 10,502.70779

Timestep Collection Time: 2.26229
Timestep Consumption Time: 2.50010
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.76239

Cumulative Model Updates: 135,082
Cumulative Timesteps: 1,127,362,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1127362960...
Checkpoint 1127362960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,537.82844
Policy Entropy: 1.76782
Value Function Loss: 0.05801

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.31182
Value Function Update Magnitude: 0.34334

Collected Steps per Second: 21,967.47498
Overall Steps per Second: 10,603.43838

Timestep Collection Time: 2.27782
Timestep Consumption Time: 2.44121
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.71904

Cumulative Model Updates: 135,088
Cumulative Timesteps: 1,127,412,998

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,370.37770
Policy Entropy: 1.76609
Value Function Loss: 0.05570

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.30746
Value Function Update Magnitude: 0.30113

Collected Steps per Second: 22,234.13232
Overall Steps per Second: 10,509.25033

Timestep Collection Time: 2.24888
Timestep Consumption Time: 2.50902
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.75790

Cumulative Model Updates: 135,094
Cumulative Timesteps: 1,127,463,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1127463000...
Checkpoint 1127463000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,871.40059
Policy Entropy: 1.74902
Value Function Loss: 0.05690

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.30688
Value Function Update Magnitude: 0.24464

Collected Steps per Second: 21,223.64787
Overall Steps per Second: 10,298.34234

Timestep Collection Time: 2.35728
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.85806

Cumulative Model Updates: 135,100
Cumulative Timesteps: 1,127,513,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,882.81122
Policy Entropy: 1.74558
Value Function Loss: 0.06072

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.31234
Value Function Update Magnitude: 0.21668

Collected Steps per Second: 21,764.21437
Overall Steps per Second: 10,364.65644

Timestep Collection Time: 2.29854
Timestep Consumption Time: 2.52805
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.82660

Cumulative Model Updates: 135,106
Cumulative Timesteps: 1,127,563,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1127563056...
Checkpoint 1127563056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,975.01583
Policy Entropy: 1.74443
Value Function Loss: 0.06290

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07939
Policy Update Magnitude: 0.31749
Value Function Update Magnitude: 0.25284

Collected Steps per Second: 21,315.06709
Overall Steps per Second: 10,308.45717

Timestep Collection Time: 2.34604
Timestep Consumption Time: 2.50493
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.85097

Cumulative Model Updates: 135,112
Cumulative Timesteps: 1,127,613,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,499.28730
Policy Entropy: 1.75168
Value Function Loss: 0.06294

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.31739
Value Function Update Magnitude: 0.31143

Collected Steps per Second: 21,915.58844
Overall Steps per Second: 10,476.63362

Timestep Collection Time: 2.28185
Timestep Consumption Time: 2.49144
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.77329

Cumulative Model Updates: 135,118
Cumulative Timesteps: 1,127,663,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1127663070...
Checkpoint 1127663070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,022.26068
Policy Entropy: 1.73556
Value Function Loss: 0.06205

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07478
Policy Update Magnitude: 0.31973
Value Function Update Magnitude: 0.33363

Collected Steps per Second: 21,884.36293
Overall Steps per Second: 10,530.89711

Timestep Collection Time: 2.28538
Timestep Consumption Time: 2.46389
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.74926

Cumulative Model Updates: 135,124
Cumulative Timesteps: 1,127,713,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,710.95232
Policy Entropy: 1.73719
Value Function Loss: 0.06098

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07883
Policy Update Magnitude: 0.32063
Value Function Update Magnitude: 0.34743

Collected Steps per Second: 22,237.90738
Overall Steps per Second: 10,513.25544

Timestep Collection Time: 2.24940
Timestep Consumption Time: 2.50859
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.75799

Cumulative Model Updates: 135,130
Cumulative Timesteps: 1,127,763,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1127763106...
Checkpoint 1127763106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,521.57100
Policy Entropy: 1.73333
Value Function Loss: 0.05643

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.31697
Value Function Update Magnitude: 0.35075

Collected Steps per Second: 21,912.39021
Overall Steps per Second: 10,605.00869

Timestep Collection Time: 2.28300
Timestep Consumption Time: 2.43420
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.71720

Cumulative Model Updates: 135,136
Cumulative Timesteps: 1,127,813,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,355.58947
Policy Entropy: 1.74716
Value Function Loss: 0.05637

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.30913
Value Function Update Magnitude: 0.33222

Collected Steps per Second: 22,215.85581
Overall Steps per Second: 10,591.42482

Timestep Collection Time: 2.25245
Timestep Consumption Time: 2.47213
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.72458

Cumulative Model Updates: 135,142
Cumulative Timesteps: 1,127,863,172

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1127863172...
Checkpoint 1127863172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,850.49015
Policy Entropy: 1.75796
Value Function Loss: 0.05861

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.31298
Value Function Update Magnitude: 0.33838

Collected Steps per Second: 22,034.56347
Overall Steps per Second: 10,489.90609

Timestep Collection Time: 2.26962
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.76744

Cumulative Model Updates: 135,148
Cumulative Timesteps: 1,127,913,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,751.67926
Policy Entropy: 1.75638
Value Function Loss: 0.06646

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.31232
Value Function Update Magnitude: 0.35471

Collected Steps per Second: 21,751.31487
Overall Steps per Second: 10,581.50570

Timestep Collection Time: 2.29926
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.72636

Cumulative Model Updates: 135,154
Cumulative Timesteps: 1,127,963,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1127963194...
Checkpoint 1127963194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,484.24761
Policy Entropy: 1.76549
Value Function Loss: 0.06783

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.31436
Value Function Update Magnitude: 0.37086

Collected Steps per Second: 21,312.50429
Overall Steps per Second: 10,471.01677

Timestep Collection Time: 2.34698
Timestep Consumption Time: 2.43002
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.77700

Cumulative Model Updates: 135,160
Cumulative Timesteps: 1,128,013,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,239.75749
Policy Entropy: 1.75330
Value Function Loss: 0.06490

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.31771
Value Function Update Magnitude: 0.37867

Collected Steps per Second: 20,850.31539
Overall Steps per Second: 10,521.73764

Timestep Collection Time: 2.39910
Timestep Consumption Time: 2.35506
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.75416

Cumulative Model Updates: 135,166
Cumulative Timesteps: 1,128,063,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1128063236...
Checkpoint 1128063236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,267.07032
Policy Entropy: 1.75238
Value Function Loss: 0.06400

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.31880
Value Function Update Magnitude: 0.36855

Collected Steps per Second: 20,842.10178
Overall Steps per Second: 10,539.75653

Timestep Collection Time: 2.39899
Timestep Consumption Time: 2.34495
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.74394

Cumulative Model Updates: 135,172
Cumulative Timesteps: 1,128,113,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,675.67275
Policy Entropy: 1.75976
Value Function Loss: 0.06310

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.31256
Value Function Update Magnitude: 0.39280

Collected Steps per Second: 21,033.04282
Overall Steps per Second: 10,451.57621

Timestep Collection Time: 2.37816
Timestep Consumption Time: 2.40772
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.78588

Cumulative Model Updates: 135,178
Cumulative Timesteps: 1,128,163,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1128163256...
Checkpoint 1128163256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,752.67902
Policy Entropy: 1.78633
Value Function Loss: 0.06720

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.31286
Value Function Update Magnitude: 0.37905

Collected Steps per Second: 20,756.72082
Overall Steps per Second: 10,201.68348

Timestep Collection Time: 2.40915
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.90174

Cumulative Model Updates: 135,184
Cumulative Timesteps: 1,128,213,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,763.76240
Policy Entropy: 1.81088
Value Function Loss: 0.06606

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.31978
Value Function Update Magnitude: 0.37495

Collected Steps per Second: 22,106.90109
Overall Steps per Second: 10,482.77235

Timestep Collection Time: 2.26255
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.77145

Cumulative Model Updates: 135,190
Cumulative Timesteps: 1,128,263,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1128263280...
Checkpoint 1128263280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,408.62897
Policy Entropy: 1.79065
Value Function Loss: 0.06161

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.31904
Value Function Update Magnitude: 0.36920

Collected Steps per Second: 22,073.71062
Overall Steps per Second: 10,586.40922

Timestep Collection Time: 2.26568
Timestep Consumption Time: 2.45849
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.72417

Cumulative Model Updates: 135,196
Cumulative Timesteps: 1,128,313,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,385.88675
Policy Entropy: 1.78317
Value Function Loss: 0.06179

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.31410
Value Function Update Magnitude: 0.36206

Collected Steps per Second: 21,777.95155
Overall Steps per Second: 10,459.49852

Timestep Collection Time: 2.29654
Timestep Consumption Time: 2.48514
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.78168

Cumulative Model Updates: 135,202
Cumulative Timesteps: 1,128,363,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1128363306...
Checkpoint 1128363306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,864.28061
Policy Entropy: 1.77468
Value Function Loss: 0.06229

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.31525
Value Function Update Magnitude: 0.37290

Collected Steps per Second: 21,988.74476
Overall Steps per Second: 10,658.31106

Timestep Collection Time: 2.27471
Timestep Consumption Time: 2.41815
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.69286

Cumulative Model Updates: 135,208
Cumulative Timesteps: 1,128,413,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,156.77526
Policy Entropy: 1.77342
Value Function Loss: 0.06300

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.31634
Value Function Update Magnitude: 0.39374

Collected Steps per Second: 22,165.14562
Overall Steps per Second: 10,487.14756

Timestep Collection Time: 2.25697
Timestep Consumption Time: 2.51325
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.77022

Cumulative Model Updates: 135,214
Cumulative Timesteps: 1,128,463,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1128463350...
Checkpoint 1128463350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,488.67030
Policy Entropy: 1.78133
Value Function Loss: 0.06085

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.31364
Value Function Update Magnitude: 0.37787

Collected Steps per Second: 21,701.82734
Overall Steps per Second: 10,619.51172

Timestep Collection Time: 2.30451
Timestep Consumption Time: 2.40494
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.70944

Cumulative Model Updates: 135,220
Cumulative Timesteps: 1,128,513,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,451.72341
Policy Entropy: 1.76406
Value Function Loss: 0.05992

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.30269
Value Function Update Magnitude: 0.36216

Collected Steps per Second: 21,822.96654
Overall Steps per Second: 10,450.85351

Timestep Collection Time: 2.29291
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.78793

Cumulative Model Updates: 135,226
Cumulative Timesteps: 1,128,563,400

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1128563400...
Checkpoint 1128563400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,657.33215
Policy Entropy: 1.78971
Value Function Loss: 0.06662

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07879
Policy Update Magnitude: 0.31072
Value Function Update Magnitude: 0.35377

Collected Steps per Second: 21,288.65468
Overall Steps per Second: 10,296.12705

Timestep Collection Time: 2.34998
Timestep Consumption Time: 2.50893
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.85891

Cumulative Model Updates: 135,232
Cumulative Timesteps: 1,128,613,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,292.62055
Policy Entropy: 1.77371
Value Function Loss: 0.06762

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.32155
Value Function Update Magnitude: 0.37505

Collected Steps per Second: 21,568.26398
Overall Steps per Second: 10,354.37844

Timestep Collection Time: 2.31859
Timestep Consumption Time: 2.51106
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.82965

Cumulative Model Updates: 135,238
Cumulative Timesteps: 1,128,663,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1128663436...
Checkpoint 1128663436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,206.99118
Policy Entropy: 1.77979
Value Function Loss: 0.06864

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.32471
Value Function Update Magnitude: 0.38091

Collected Steps per Second: 21,642.53673
Overall Steps per Second: 10,544.04169

Timestep Collection Time: 2.31091
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.74334

Cumulative Model Updates: 135,244
Cumulative Timesteps: 1,128,713,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,491.23050
Policy Entropy: 1.74593
Value Function Loss: 0.06332

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.32680
Value Function Update Magnitude: 0.36585

Collected Steps per Second: 21,987.29732
Overall Steps per Second: 10,528.60627

Timestep Collection Time: 2.27568
Timestep Consumption Time: 2.47671
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.75239

Cumulative Model Updates: 135,250
Cumulative Timesteps: 1,128,763,486

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1128763486...
Checkpoint 1128763486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,519.43430
Policy Entropy: 1.74277
Value Function Loss: 0.06411

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.32603
Value Function Update Magnitude: 0.36567

Collected Steps per Second: 21,743.39078
Overall Steps per Second: 10,563.48915

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.73480

Cumulative Model Updates: 135,256
Cumulative Timesteps: 1,128,813,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,370.57372
Policy Entropy: 1.75319
Value Function Loss: 0.06559

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.32993
Value Function Update Magnitude: 0.35964

Collected Steps per Second: 21,736.47670
Overall Steps per Second: 10,542.69035

Timestep Collection Time: 2.30111
Timestep Consumption Time: 2.44322
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.74433

Cumulative Model Updates: 135,262
Cumulative Timesteps: 1,128,863,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1128863520...
Checkpoint 1128863520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,284.84815
Policy Entropy: 1.75735
Value Function Loss: 0.06287

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.32773
Value Function Update Magnitude: 0.35262

Collected Steps per Second: 22,097.24085
Overall Steps per Second: 10,646.95935

Timestep Collection Time: 2.26336
Timestep Consumption Time: 2.43413
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.69749

Cumulative Model Updates: 135,268
Cumulative Timesteps: 1,128,913,534

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,033.10148
Policy Entropy: 1.76156
Value Function Loss: 0.06191

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.32330
Value Function Update Magnitude: 0.33656

Collected Steps per Second: 21,978.66514
Overall Steps per Second: 10,434.89239

Timestep Collection Time: 2.27584
Timestep Consumption Time: 2.51769
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.79353

Cumulative Model Updates: 135,274
Cumulative Timesteps: 1,128,963,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1128963554...
Checkpoint 1128963554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,326.57197
Policy Entropy: 1.75337
Value Function Loss: 0.05897

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.31814
Value Function Update Magnitude: 0.34970

Collected Steps per Second: 21,996.38663
Overall Steps per Second: 10,607.68608

Timestep Collection Time: 2.27456
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71658

Cumulative Model Updates: 135,280
Cumulative Timesteps: 1,129,013,586

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,828.93937
Policy Entropy: 1.76317
Value Function Loss: 0.05868

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.31592
Value Function Update Magnitude: 0.32368

Collected Steps per Second: 21,579.67835
Overall Steps per Second: 10,475.94522

Timestep Collection Time: 2.31829
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.77551

Cumulative Model Updates: 135,286
Cumulative Timesteps: 1,129,063,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1129063614...
Checkpoint 1129063614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,070.76469
Policy Entropy: 1.75165
Value Function Loss: 0.06087

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07567
Policy Update Magnitude: 0.31600
Value Function Update Magnitude: 0.29245

Collected Steps per Second: 21,323.44940
Overall Steps per Second: 10,295.57580

Timestep Collection Time: 2.34606
Timestep Consumption Time: 2.51292
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.85898

Cumulative Model Updates: 135,292
Cumulative Timesteps: 1,129,113,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,512.93187
Policy Entropy: 1.74524
Value Function Loss: 0.06490

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.31801
Value Function Update Magnitude: 0.26213

Collected Steps per Second: 21,428.46741
Overall Steps per Second: 10,390.31853

Timestep Collection Time: 2.33484
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.81525

Cumulative Model Updates: 135,298
Cumulative Timesteps: 1,129,163,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1129163672...
Checkpoint 1129163672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,337.94110
Policy Entropy: 1.74996
Value Function Loss: 0.06137

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.31631
Value Function Update Magnitude: 0.27377

Collected Steps per Second: 21,718.11864
Overall Steps per Second: 10,420.72321

Timestep Collection Time: 2.30305
Timestep Consumption Time: 2.49680
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.79986

Cumulative Model Updates: 135,304
Cumulative Timesteps: 1,129,213,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,401.61322
Policy Entropy: 1.76089
Value Function Loss: 0.05917

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.31409
Value Function Update Magnitude: 0.31877

Collected Steps per Second: 22,033.25623
Overall Steps per Second: 10,620.28459

Timestep Collection Time: 2.26993
Timestep Consumption Time: 2.43936
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.70929

Cumulative Model Updates: 135,310
Cumulative Timesteps: 1,129,263,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1129263704...
Checkpoint 1129263704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,421.58575
Policy Entropy: 1.76708
Value Function Loss: 0.05807

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07997
Policy Update Magnitude: 0.30989
Value Function Update Magnitude: 0.33521

Collected Steps per Second: 21,785.02757
Overall Steps per Second: 10,604.33339

Timestep Collection Time: 2.29644
Timestep Consumption Time: 2.42125
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.71769

Cumulative Model Updates: 135,316
Cumulative Timesteps: 1,129,313,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,827.14385
Policy Entropy: 1.74427
Value Function Loss: 0.05544

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.30756
Value Function Update Magnitude: 0.31941

Collected Steps per Second: 21,882.07359
Overall Steps per Second: 10,616.51617

Timestep Collection Time: 2.28562
Timestep Consumption Time: 2.42535
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.71096

Cumulative Model Updates: 135,322
Cumulative Timesteps: 1,129,363,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1129363746...
Checkpoint 1129363746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,854.77684
Policy Entropy: 1.74390
Value Function Loss: 0.05629

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.30478
Value Function Update Magnitude: 0.29721

Collected Steps per Second: 21,303.27426
Overall Steps per Second: 10,653.11077

Timestep Collection Time: 2.34837
Timestep Consumption Time: 2.34772
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.69609

Cumulative Model Updates: 135,328
Cumulative Timesteps: 1,129,413,774

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,590.36603
Policy Entropy: 1.73418
Value Function Loss: 0.05519

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.30591
Value Function Update Magnitude: 0.30806

Collected Steps per Second: 21,380.95466
Overall Steps per Second: 10,506.06393

Timestep Collection Time: 2.33872
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.75954

Cumulative Model Updates: 135,334
Cumulative Timesteps: 1,129,463,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1129463778...
Checkpoint 1129463778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,967.26923
Policy Entropy: 1.75348
Value Function Loss: 0.05416

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.30039
Value Function Update Magnitude: 0.32801

Collected Steps per Second: 21,633.89363
Overall Steps per Second: 10,538.02927

Timestep Collection Time: 2.31174
Timestep Consumption Time: 2.43412
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.74586

Cumulative Model Updates: 135,340
Cumulative Timesteps: 1,129,513,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,143.45730
Policy Entropy: 1.75346
Value Function Loss: 0.05370

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.30177
Value Function Update Magnitude: 0.32275

Collected Steps per Second: 20,970.95039
Overall Steps per Second: 10,420.02103

Timestep Collection Time: 2.38473
Timestep Consumption Time: 2.41469
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.79941

Cumulative Model Updates: 135,346
Cumulative Timesteps: 1,129,563,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1129563800...
Checkpoint 1129563800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,108.49337
Policy Entropy: 1.74786
Value Function Loss: 0.05613

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.30433
Value Function Update Magnitude: 0.32764

Collected Steps per Second: 20,945.76463
Overall Steps per Second: 10,272.54636

Timestep Collection Time: 2.38798
Timestep Consumption Time: 2.48112
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.86909

Cumulative Model Updates: 135,352
Cumulative Timesteps: 1,129,613,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,046.35686
Policy Entropy: 1.74802
Value Function Loss: 0.05603

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.29994
Value Function Update Magnitude: 0.34098

Collected Steps per Second: 21,693.15415
Overall Steps per Second: 10,403.95672

Timestep Collection Time: 2.30487
Timestep Consumption Time: 2.50099
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.80586

Cumulative Model Updates: 135,358
Cumulative Timesteps: 1,129,663,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1129663818...
Checkpoint 1129663818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,196.58460
Policy Entropy: 1.74343
Value Function Loss: 0.05823

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.29950
Value Function Update Magnitude: 0.36589

Collected Steps per Second: 21,339.36847
Overall Steps per Second: 10,543.71158

Timestep Collection Time: 2.34449
Timestep Consumption Time: 2.40052
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.74501

Cumulative Model Updates: 135,364
Cumulative Timesteps: 1,129,713,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,113.74885
Policy Entropy: 1.75339
Value Function Loss: 0.05765

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.30176
Value Function Update Magnitude: 0.37548

Collected Steps per Second: 21,915.98044
Overall Steps per Second: 10,509.05234

Timestep Collection Time: 2.28199
Timestep Consumption Time: 2.47696
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.75894

Cumulative Model Updates: 135,370
Cumulative Timesteps: 1,129,763,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1129763860...
Checkpoint 1129763860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,874.49626
Policy Entropy: 1.73770
Value Function Loss: 0.05984

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.31473
Value Function Update Magnitude: 0.35243

Collected Steps per Second: 21,748.88639
Overall Steps per Second: 10,545.63184

Timestep Collection Time: 2.29915
Timestep Consumption Time: 2.44253
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.74168

Cumulative Model Updates: 135,376
Cumulative Timesteps: 1,129,813,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,821.54621
Policy Entropy: 1.74056
Value Function Loss: 0.05836

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.32003
Value Function Update Magnitude: 0.35800

Collected Steps per Second: 22,079.52654
Overall Steps per Second: 10,644.19754

Timestep Collection Time: 2.26608
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.70059

Cumulative Model Updates: 135,382
Cumulative Timesteps: 1,129,863,898

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1129863898...
Checkpoint 1129863898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,237.21435
Policy Entropy: 1.75420
Value Function Loss: 0.05840

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.31941
Value Function Update Magnitude: 0.34881

Collected Steps per Second: 22,131.97171
Overall Steps per Second: 10,566.50537

Timestep Collection Time: 2.26089
Timestep Consumption Time: 2.47464
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.73553

Cumulative Model Updates: 135,388
Cumulative Timesteps: 1,129,913,936

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,351.24500
Policy Entropy: 1.77337
Value Function Loss: 0.05612

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.31143
Value Function Update Magnitude: 0.34176

Collected Steps per Second: 22,043.94604
Overall Steps per Second: 10,460.41832

Timestep Collection Time: 2.27001
Timestep Consumption Time: 2.51374
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.78375

Cumulative Model Updates: 135,394
Cumulative Timesteps: 1,129,963,976

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1129963976...
Checkpoint 1129963976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.70596
Policy Entropy: 1.78931
Value Function Loss: 0.05639

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.31165
Value Function Update Magnitude: 0.34565

Collected Steps per Second: 21,856.22884
Overall Steps per Second: 10,571.03143

Timestep Collection Time: 2.28813
Timestep Consumption Time: 2.44272
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.73085

Cumulative Model Updates: 135,400
Cumulative Timesteps: 1,130,013,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,345.47859
Policy Entropy: 1.78064
Value Function Loss: 0.05910

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.31484
Value Function Update Magnitude: 0.34472

Collected Steps per Second: 21,949.81353
Overall Steps per Second: 10,550.77754

Timestep Collection Time: 2.27911
Timestep Consumption Time: 2.46234
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.74145

Cumulative Model Updates: 135,406
Cumulative Timesteps: 1,130,064,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1130064012...
Checkpoint 1130064012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,920.38234
Policy Entropy: 1.78467
Value Function Loss: 0.06263

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.32049
Value Function Update Magnitude: 0.35043

Collected Steps per Second: 21,346.99951
Overall Steps per Second: 10,361.66197

Timestep Collection Time: 2.34365
Timestep Consumption Time: 2.48472
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.82838

Cumulative Model Updates: 135,412
Cumulative Timesteps: 1,130,114,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,742.34740
Policy Entropy: 1.75117
Value Function Loss: 0.05989

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.31599
Value Function Update Magnitude: 0.37567

Collected Steps per Second: 21,733.99082
Overall Steps per Second: 10,432.96687

Timestep Collection Time: 2.30054
Timestep Consumption Time: 2.49196
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.79250

Cumulative Model Updates: 135,418
Cumulative Timesteps: 1,130,164,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1130164042...
Checkpoint 1130164042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,440.64652
Policy Entropy: 1.74281
Value Function Loss: 0.05995

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.31677
Value Function Update Magnitude: 0.36669

Collected Steps per Second: 21,692.02761
Overall Steps per Second: 10,436.71850

Timestep Collection Time: 2.30509
Timestep Consumption Time: 2.48588
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.79097

Cumulative Model Updates: 135,424
Cumulative Timesteps: 1,130,214,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,054.53451
Policy Entropy: 1.75567
Value Function Loss: 0.05682

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.32008
Value Function Update Magnitude: 0.34140

Collected Steps per Second: 21,918.75160
Overall Steps per Second: 10,458.78661

Timestep Collection Time: 2.28152
Timestep Consumption Time: 2.49992
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.78143

Cumulative Model Updates: 135,430
Cumulative Timesteps: 1,130,264,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1130264052...
Checkpoint 1130264052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,126.68481
Policy Entropy: 1.77101
Value Function Loss: 0.05997

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.31794
Value Function Update Magnitude: 0.32379

Collected Steps per Second: 21,530.76670
Overall Steps per Second: 10,365.81492

Timestep Collection Time: 2.32439
Timestep Consumption Time: 2.50359
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.82799

Cumulative Model Updates: 135,436
Cumulative Timesteps: 1,130,314,098

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,997.61508
Policy Entropy: 1.78535
Value Function Loss: 0.05844

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.31160
Value Function Update Magnitude: 0.30752

Collected Steps per Second: 22,071.62366
Overall Steps per Second: 10,457.07113

Timestep Collection Time: 2.26635
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.78356

Cumulative Model Updates: 135,442
Cumulative Timesteps: 1,130,364,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1130364120...
Checkpoint 1130364120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,974.19941
Policy Entropy: 1.77914
Value Function Loss: 0.06690

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.27597

Collected Steps per Second: 21,867.09699
Overall Steps per Second: 10,435.62782

Timestep Collection Time: 2.28837
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.79511

Cumulative Model Updates: 135,448
Cumulative Timesteps: 1,130,414,160

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,586.23934
Policy Entropy: 1.77749
Value Function Loss: 0.06299

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.31234
Value Function Update Magnitude: 0.30540

Collected Steps per Second: 22,154.60710
Overall Steps per Second: 10,506.98283

Timestep Collection Time: 2.25696
Timestep Consumption Time: 2.50197
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.75893

Cumulative Model Updates: 135,454
Cumulative Timesteps: 1,130,464,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1130464162...
Checkpoint 1130464162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,504.63826
Policy Entropy: 1.77162
Value Function Loss: 0.06037

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07564
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.34766

Collected Steps per Second: 22,001.41839
Overall Steps per Second: 10,630.70931

Timestep Collection Time: 2.27385
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.70599

Cumulative Model Updates: 135,460
Cumulative Timesteps: 1,130,514,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,022.44207
Policy Entropy: 1.76182
Value Function Loss: 0.05776

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.31206
Value Function Update Magnitude: 0.33542

Collected Steps per Second: 22,126.05677
Overall Steps per Second: 10,545.23521

Timestep Collection Time: 2.26050
Timestep Consumption Time: 2.48249
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.74300

Cumulative Model Updates: 135,466
Cumulative Timesteps: 1,130,564,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1130564206...
Checkpoint 1130564206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,394.53549
Policy Entropy: 1.76773
Value Function Loss: 0.06538

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.31992
Value Function Update Magnitude: 0.34543

Collected Steps per Second: 21,746.19531
Overall Steps per Second: 10,535.33742

Timestep Collection Time: 2.29980
Timestep Consumption Time: 2.44727
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.74707

Cumulative Model Updates: 135,472
Cumulative Timesteps: 1,130,614,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,238.82587
Policy Entropy: 1.75676
Value Function Loss: 0.06570

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.32663
Value Function Update Magnitude: 0.36579

Collected Steps per Second: 22,191.11723
Overall Steps per Second: 10,517.06026

Timestep Collection Time: 2.25351
Timestep Consumption Time: 2.50143
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.75494

Cumulative Model Updates: 135,478
Cumulative Timesteps: 1,130,664,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1130664226...
Checkpoint 1130664226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,493.94342
Policy Entropy: 1.74780
Value Function Loss: 0.06536

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.32451
Value Function Update Magnitude: 0.37832

Collected Steps per Second: 21,431.85146
Overall Steps per Second: 10,515.89663

Timestep Collection Time: 2.33382
Timestep Consumption Time: 2.42260
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.75642

Cumulative Model Updates: 135,484
Cumulative Timesteps: 1,130,714,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,014.60831
Policy Entropy: 1.75844
Value Function Loss: 0.06295

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.32253
Value Function Update Magnitude: 0.37639

Collected Steps per Second: 21,577.58334
Overall Steps per Second: 10,523.79115

Timestep Collection Time: 2.31759
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.75190

Cumulative Model Updates: 135,490
Cumulative Timesteps: 1,130,764,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1130764252...
Checkpoint 1130764252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,341.59928
Policy Entropy: 1.75402
Value Function Loss: 0.05674

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.31582
Value Function Update Magnitude: 0.35526

Collected Steps per Second: 21,422.18792
Overall Steps per Second: 10,305.10271

Timestep Collection Time: 2.33459
Timestep Consumption Time: 2.51854
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.85313

Cumulative Model Updates: 135,496
Cumulative Timesteps: 1,130,814,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,759.45719
Policy Entropy: 1.76788
Value Function Loss: 0.05530

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.30695
Value Function Update Magnitude: 0.34112

Collected Steps per Second: 21,807.30943
Overall Steps per Second: 10,420.11561

Timestep Collection Time: 2.29418
Timestep Consumption Time: 2.50711
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.80129

Cumulative Model Updates: 135,502
Cumulative Timesteps: 1,130,864,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1130864294...
Checkpoint 1130864294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,889.64090
Policy Entropy: 1.76856
Value Function Loss: 0.05614

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.30493
Value Function Update Magnitude: 0.33188

Collected Steps per Second: 21,473.99157
Overall Steps per Second: 10,511.39859

Timestep Collection Time: 2.33035
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.76074

Cumulative Model Updates: 135,508
Cumulative Timesteps: 1,130,914,336

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,153.70096
Policy Entropy: 1.77878
Value Function Loss: 0.05837

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.30830
Value Function Update Magnitude: 0.34889

Collected Steps per Second: 21,363.38007
Overall Steps per Second: 10,206.85213

Timestep Collection Time: 2.34092
Timestep Consumption Time: 2.55873
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.89965

Cumulative Model Updates: 135,514
Cumulative Timesteps: 1,130,964,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1130964346...
Checkpoint 1130964346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,393.44598
Policy Entropy: 1.77614
Value Function Loss: 0.06100

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31547
Value Function Update Magnitude: 0.36770

Collected Steps per Second: 21,954.38350
Overall Steps per Second: 10,472.58602

Timestep Collection Time: 2.27800
Timestep Consumption Time: 2.49752
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.77552

Cumulative Model Updates: 135,520
Cumulative Timesteps: 1,131,014,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,791.06297
Policy Entropy: 1.77182
Value Function Loss: 0.05665

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.31420
Value Function Update Magnitude: 0.36202

Collected Steps per Second: 22,214.65967
Overall Steps per Second: 10,513.10632

Timestep Collection Time: 2.25086
Timestep Consumption Time: 2.50530
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.75616

Cumulative Model Updates: 135,526
Cumulative Timesteps: 1,131,064,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1131064360...
Checkpoint 1131064360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,763.62714
Policy Entropy: 1.77467
Value Function Loss: 0.05741

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.31010
Value Function Update Magnitude: 0.36767

Collected Steps per Second: 22,039.29674
Overall Steps per Second: 10,693.38522

Timestep Collection Time: 2.26958
Timestep Consumption Time: 2.40808
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.67766

Cumulative Model Updates: 135,532
Cumulative Timesteps: 1,131,114,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,276.86977
Policy Entropy: 1.78509
Value Function Loss: 0.05298

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 21,623.99628
Overall Steps per Second: 10,710.04837

Timestep Collection Time: 2.31271
Timestep Consumption Time: 2.35674
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.66945

Cumulative Model Updates: 135,538
Cumulative Timesteps: 1,131,164,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1131164390...
Checkpoint 1131164390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,184.87931
Policy Entropy: 1.77160
Value Function Loss: 0.05273

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.30767
Value Function Update Magnitude: 0.33093

Collected Steps per Second: 21,131.90780
Overall Steps per Second: 10,471.97610

Timestep Collection Time: 2.36760
Timestep Consumption Time: 2.41010
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.77770

Cumulative Model Updates: 135,544
Cumulative Timesteps: 1,131,214,422

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,536.03670
Policy Entropy: 1.77197
Value Function Loss: 0.05600

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.30778
Value Function Update Magnitude: 0.34156

Collected Steps per Second: 21,633.82027
Overall Steps per Second: 10,711.71890

Timestep Collection Time: 2.31341
Timestep Consumption Time: 2.35885
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.67227

Cumulative Model Updates: 135,550
Cumulative Timesteps: 1,131,264,470

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1131264470...
Checkpoint 1131264470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,272.70065
Policy Entropy: 1.77241
Value Function Loss: 0.06063

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.31483
Value Function Update Magnitude: 0.35725

Collected Steps per Second: 20,907.79527
Overall Steps per Second: 10,412.30509

Timestep Collection Time: 2.39222
Timestep Consumption Time: 2.41133
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.80355

Cumulative Model Updates: 135,556
Cumulative Timesteps: 1,131,314,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,473.66591
Policy Entropy: 1.76816
Value Function Loss: 0.06078

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.31888
Value Function Update Magnitude: 0.37153

Collected Steps per Second: 21,089.88977
Overall Steps per Second: 10,469.46936

Timestep Collection Time: 2.37099
Timestep Consumption Time: 2.40518
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.77617

Cumulative Model Updates: 135,562
Cumulative Timesteps: 1,131,364,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1131364490...
Checkpoint 1131364490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,508.99889
Policy Entropy: 1.77019
Value Function Loss: 0.05859

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.32008
Value Function Update Magnitude: 0.37831

Collected Steps per Second: 20,844.13626
Overall Steps per Second: 10,358.47441

Timestep Collection Time: 2.39981
Timestep Consumption Time: 2.42928
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.82909

Cumulative Model Updates: 135,568
Cumulative Timesteps: 1,131,414,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,739.19712
Policy Entropy: 1.78359
Value Function Loss: 0.05948

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08601
Policy Update Magnitude: 0.31947
Value Function Update Magnitude: 0.38497

Collected Steps per Second: 21,979.74268
Overall Steps per Second: 10,602.24179

Timestep Collection Time: 2.27610
Timestep Consumption Time: 2.44253
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.71862

Cumulative Model Updates: 135,574
Cumulative Timesteps: 1,131,464,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1131464540...
Checkpoint 1131464540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,059.63148
Policy Entropy: 1.78282
Value Function Loss: 0.05851

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.31866
Value Function Update Magnitude: 0.36114

Collected Steps per Second: 21,864.11044
Overall Steps per Second: 10,469.17547

Timestep Collection Time: 2.28685
Timestep Consumption Time: 2.48907
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.77593

Cumulative Model Updates: 135,580
Cumulative Timesteps: 1,131,514,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,669.84370
Policy Entropy: 1.77237
Value Function Loss: 0.06092

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.31664
Value Function Update Magnitude: 0.32933

Collected Steps per Second: 22,108.35010
Overall Steps per Second: 10,525.84401

Timestep Collection Time: 2.26267
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.75249

Cumulative Model Updates: 135,586
Cumulative Timesteps: 1,131,564,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1131564564...
Checkpoint 1131564564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,255.38668
Policy Entropy: 1.75011
Value Function Loss: 0.05877

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.31375
Value Function Update Magnitude: 0.28939

Collected Steps per Second: 21,654.23534
Overall Steps per Second: 10,580.00382

Timestep Collection Time: 2.30976
Timestep Consumption Time: 2.41765
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.72741

Cumulative Model Updates: 135,592
Cumulative Timesteps: 1,131,614,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,603.89458
Policy Entropy: 1.74374
Value Function Loss: 0.05805

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.31238
Value Function Update Magnitude: 0.32142

Collected Steps per Second: 22,085.42190
Overall Steps per Second: 10,525.60656

Timestep Collection Time: 2.26421
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.75089

Cumulative Model Updates: 135,598
Cumulative Timesteps: 1,131,664,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1131664586...
Checkpoint 1131664586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,052.94504
Policy Entropy: 1.74775
Value Function Loss: 0.05490

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.31109
Value Function Update Magnitude: 0.35190

Collected Steps per Second: 22,144.36490
Overall Steps per Second: 10,694.43543

Timestep Collection Time: 2.25918
Timestep Consumption Time: 2.41877
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.67795

Cumulative Model Updates: 135,604
Cumulative Timesteps: 1,131,714,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,576.62784
Policy Entropy: 1.75082
Value Function Loss: 0.05544

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07584
Policy Update Magnitude: 0.31236
Value Function Update Magnitude: 0.35237

Collected Steps per Second: 21,834.78642
Overall Steps per Second: 10,399.40583

Timestep Collection Time: 2.29093
Timestep Consumption Time: 2.51915
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.81008

Cumulative Model Updates: 135,610
Cumulative Timesteps: 1,131,764,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1131764636...
Checkpoint 1131764636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,182.19542
Policy Entropy: 1.74888
Value Function Loss: 0.05749

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.31687
Value Function Update Magnitude: 0.35448

Collected Steps per Second: 21,388.58625
Overall Steps per Second: 10,360.05059

Timestep Collection Time: 2.33872
Timestep Consumption Time: 2.48963
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.82835

Cumulative Model Updates: 135,616
Cumulative Timesteps: 1,131,814,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,106.71447
Policy Entropy: 1.76825
Value Function Loss: 0.05867

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.31619
Value Function Update Magnitude: 0.36486

Collected Steps per Second: 21,648.77964
Overall Steps per Second: 10,374.01232

Timestep Collection Time: 2.31080
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.82224

Cumulative Model Updates: 135,622
Cumulative Timesteps: 1,131,864,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1131864684...
Checkpoint 1131864684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,454.93752
Policy Entropy: 1.76432
Value Function Loss: 0.05527

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.31153
Value Function Update Magnitude: 0.37016

Collected Steps per Second: 21,351.56107
Overall Steps per Second: 10,471.91000

Timestep Collection Time: 2.34222
Timestep Consumption Time: 2.43342
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.77563

Cumulative Model Updates: 135,628
Cumulative Timesteps: 1,131,914,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,254.09936
Policy Entropy: 1.77901
Value Function Loss: 0.05910

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.31346
Value Function Update Magnitude: 0.35884

Collected Steps per Second: 21,733.68226
Overall Steps per Second: 10,461.54770

Timestep Collection Time: 2.30113
Timestep Consumption Time: 2.47943
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.78055

Cumulative Model Updates: 135,634
Cumulative Timesteps: 1,131,964,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1131964706...
Checkpoint 1131964706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,808.82758
Policy Entropy: 1.76937
Value Function Loss: 0.06183

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.31840
Value Function Update Magnitude: 0.35823

Collected Steps per Second: 21,889.88637
Overall Steps per Second: 10,465.20101

Timestep Collection Time: 2.28516
Timestep Consumption Time: 2.49468
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.77984

Cumulative Model Updates: 135,640
Cumulative Timesteps: 1,132,014,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,370.93385
Policy Entropy: 1.76898
Value Function Loss: 0.05924

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.31879
Value Function Update Magnitude: 0.35959

Collected Steps per Second: 22,286.33538
Overall Steps per Second: 10,678.12705

Timestep Collection Time: 2.24371
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.68284

Cumulative Model Updates: 135,646
Cumulative Timesteps: 1,132,064,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1132064732...
Checkpoint 1132064732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,301.47236
Policy Entropy: 1.75535
Value Function Loss: 0.05626

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.31425
Value Function Update Magnitude: 0.34891

Collected Steps per Second: 21,898.13523
Overall Steps per Second: 10,597.69733

Timestep Collection Time: 2.28403
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.71952

Cumulative Model Updates: 135,652
Cumulative Timesteps: 1,132,114,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,006.10278
Policy Entropy: 1.74368
Value Function Loss: 0.04998

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.31159
Value Function Update Magnitude: 0.34473

Collected Steps per Second: 22,143.78997
Overall Steps per Second: 10,509.59850

Timestep Collection Time: 2.25896
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.75965

Cumulative Model Updates: 135,658
Cumulative Timesteps: 1,132,164,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1132164770...
Checkpoint 1132164770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,006.89575
Policy Entropy: 1.76008
Value Function Loss: 0.05159

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.30285
Value Function Update Magnitude: 0.34079

Collected Steps per Second: 21,493.49957
Overall Steps per Second: 10,357.19055

Timestep Collection Time: 2.32712
Timestep Consumption Time: 2.50218
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.82930

Cumulative Model Updates: 135,664
Cumulative Timesteps: 1,132,214,788

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,164.41653
Policy Entropy: 1.76306
Value Function Loss: 0.05228

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.29581
Value Function Update Magnitude: 0.33548

Collected Steps per Second: 22,207.22562
Overall Steps per Second: 10,691.00454

Timestep Collection Time: 2.25251
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.67889

Cumulative Model Updates: 135,670
Cumulative Timesteps: 1,132,264,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1132264810...
Checkpoint 1132264810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,092.78240
Policy Entropy: 1.76624
Value Function Loss: 0.05267

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.30649
Value Function Update Magnitude: 0.33200

Collected Steps per Second: 21,260.99551
Overall Steps per Second: 10,275.67804

Timestep Collection Time: 2.35267
Timestep Consumption Time: 2.51514
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.86781

Cumulative Model Updates: 135,676
Cumulative Timesteps: 1,132,314,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,823.01093
Policy Entropy: 1.75277
Value Function Loss: 0.05408

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.30987
Value Function Update Magnitude: 0.34818

Collected Steps per Second: 21,940.54687
Overall Steps per Second: 10,412.72314

Timestep Collection Time: 2.27943
Timestep Consumption Time: 2.52354
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.80297

Cumulative Model Updates: 135,682
Cumulative Timesteps: 1,132,364,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1132364842...
Checkpoint 1132364842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,352.16852
Policy Entropy: 1.74139
Value Function Loss: 0.05715

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.30654
Value Function Update Magnitude: 0.37149

Collected Steps per Second: 21,511.58215
Overall Steps per Second: 10,360.56056

Timestep Collection Time: 2.32526
Timestep Consumption Time: 2.50267
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.82792

Cumulative Model Updates: 135,688
Cumulative Timesteps: 1,132,414,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,769.17162
Policy Entropy: 1.75612
Value Function Loss: 0.05994

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.31078
Value Function Update Magnitude: 0.36798

Collected Steps per Second: 21,939.02913
Overall Steps per Second: 10,450.19879

Timestep Collection Time: 2.28005
Timestep Consumption Time: 2.50666
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.78670

Cumulative Model Updates: 135,694
Cumulative Timesteps: 1,132,464,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1132464884...
Checkpoint 1132464884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,780.76929
Policy Entropy: 1.75882
Value Function Loss: 0.05466

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.30920
Value Function Update Magnitude: 0.36614

Collected Steps per Second: 21,403.02613
Overall Steps per Second: 10,470.82629

Timestep Collection Time: 2.33705
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.77708

Cumulative Model Updates: 135,700
Cumulative Timesteps: 1,132,514,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,629.82871
Policy Entropy: 1.77686
Value Function Loss: 0.05518

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.30549
Value Function Update Magnitude: 0.34595

Collected Steps per Second: 22,092.64224
Overall Steps per Second: 10,571.15194

Timestep Collection Time: 2.26474
Timestep Consumption Time: 2.46833
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.73307

Cumulative Model Updates: 135,706
Cumulative Timesteps: 1,132,564,938

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1132564938...
Checkpoint 1132564938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,257.98275
Policy Entropy: 1.76903
Value Function Loss: 0.05190

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.30430
Value Function Update Magnitude: 0.32340

Collected Steps per Second: 22,058.51813
Overall Steps per Second: 10,619.81551

Timestep Collection Time: 2.26797
Timestep Consumption Time: 2.44285
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.71082

Cumulative Model Updates: 135,712
Cumulative Timesteps: 1,132,614,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,035.15314
Policy Entropy: 1.77548
Value Function Loss: 0.05558

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.30748
Value Function Update Magnitude: 0.34464

Collected Steps per Second: 22,198.52403
Overall Steps per Second: 10,500.12444

Timestep Collection Time: 2.25249
Timestep Consumption Time: 2.50955
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.76204

Cumulative Model Updates: 135,718
Cumulative Timesteps: 1,132,664,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1132664968...
Checkpoint 1132664968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,223.34093
Policy Entropy: 1.77279
Value Function Loss: 0.05318

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.30764
Value Function Update Magnitude: 0.35566

Collected Steps per Second: 21,768.33597
Overall Steps per Second: 10,528.74538

Timestep Collection Time: 2.29691
Timestep Consumption Time: 2.45199
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.74890

Cumulative Model Updates: 135,724
Cumulative Timesteps: 1,132,714,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,849.25605
Policy Entropy: 1.78443
Value Function Loss: 0.05683

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.30861
Value Function Update Magnitude: 0.34872

Collected Steps per Second: 22,055.90044
Overall Steps per Second: 10,464.44249

Timestep Collection Time: 2.26769
Timestep Consumption Time: 2.51192
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.77961

Cumulative Model Updates: 135,730
Cumulative Timesteps: 1,132,764,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1132764984...
Checkpoint 1132764984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,581.30174
Policy Entropy: 1.80265
Value Function Loss: 0.06366

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.30880
Value Function Update Magnitude: 0.34292

Collected Steps per Second: 21,859.11975
Overall Steps per Second: 10,586.82796

Timestep Collection Time: 2.28765
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.72342

Cumulative Model Updates: 135,736
Cumulative Timesteps: 1,132,814,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,710.83615
Policy Entropy: 1.82555
Value Function Loss: 0.07457

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.31225
Value Function Update Magnitude: 0.35245

Collected Steps per Second: 20,778.98116
Overall Steps per Second: 10,172.96999

Timestep Collection Time: 2.40637
Timestep Consumption Time: 2.50881
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.91518

Cumulative Model Updates: 135,742
Cumulative Timesteps: 1,132,864,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1132864992...
Checkpoint 1132864992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,765.89047
Policy Entropy: 1.83835
Value Function Loss: 0.07553

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.31902
Value Function Update Magnitude: 0.35749

Collected Steps per Second: 21,269.75741
Overall Steps per Second: 10,449.73815

Timestep Collection Time: 2.35188
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.78711

Cumulative Model Updates: 135,748
Cumulative Timesteps: 1,132,915,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,984.01079
Policy Entropy: 1.81825
Value Function Loss: 0.07367

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.32506
Value Function Update Magnitude: 0.34401

Collected Steps per Second: 21,555.43083
Overall Steps per Second: 10,485.19944

Timestep Collection Time: 2.32164
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.77282

Cumulative Model Updates: 135,754
Cumulative Timesteps: 1,132,965,060

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1132965060...
Checkpoint 1132965060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,060.57043
Policy Entropy: 1.79254
Value Function Loss: 0.06372

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.32199
Value Function Update Magnitude: 0.34173

Collected Steps per Second: 21,047.93760
Overall Steps per Second: 10,255.02599

Timestep Collection Time: 2.37572
Timestep Consumption Time: 2.50033
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.87605

Cumulative Model Updates: 135,760
Cumulative Timesteps: 1,133,015,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,343.36040
Policy Entropy: 1.76718
Value Function Loss: 0.06059

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.31683
Value Function Update Magnitude: 0.33318

Collected Steps per Second: 22,027.03300
Overall Steps per Second: 10,434.63352

Timestep Collection Time: 2.27121
Timestep Consumption Time: 2.52321
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.79442

Cumulative Model Updates: 135,766
Cumulative Timesteps: 1,133,065,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1133065092...
Checkpoint 1133065092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,869.50929
Policy Entropy: 1.78971
Value Function Loss: 0.06451

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.31646
Value Function Update Magnitude: 0.33734

Collected Steps per Second: 21,715.35784
Overall Steps per Second: 10,602.01280

Timestep Collection Time: 2.30335
Timestep Consumption Time: 2.41444
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.71778

Cumulative Model Updates: 135,772
Cumulative Timesteps: 1,133,115,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,072.74007
Policy Entropy: 1.80508
Value Function Loss: 0.07075

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.31752
Value Function Update Magnitude: 0.35564

Collected Steps per Second: 21,679.98422
Overall Steps per Second: 10,501.39313

Timestep Collection Time: 2.30710
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.76299

Cumulative Model Updates: 135,778
Cumulative Timesteps: 1,133,165,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1133165128...
Checkpoint 1133165128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,839.46114
Policy Entropy: 1.81986
Value Function Loss: 0.07400

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.32200
Value Function Update Magnitude: 0.35113

Collected Steps per Second: 21,509.28330
Overall Steps per Second: 10,339.41846

Timestep Collection Time: 2.32560
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.83799

Cumulative Model Updates: 135,784
Cumulative Timesteps: 1,133,215,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,766.14694
Policy Entropy: 1.80387
Value Function Loss: 0.06841

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.32423
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 22,026.09906
Overall Steps per Second: 10,530.33423

Timestep Collection Time: 2.27112
Timestep Consumption Time: 2.47934
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.75047

Cumulative Model Updates: 135,790
Cumulative Timesteps: 1,133,265,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1133265174...
Checkpoint 1133265174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,562.43205
Policy Entropy: 1.79690
Value Function Loss: 0.06534

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.32549
Value Function Update Magnitude: 0.35848

Collected Steps per Second: 21,945.26806
Overall Steps per Second: 10,430.26861

Timestep Collection Time: 2.27840
Timestep Consumption Time: 2.51534
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.79374

Cumulative Model Updates: 135,796
Cumulative Timesteps: 1,133,315,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,708.83740
Policy Entropy: 1.79313
Value Function Loss: 0.06496

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.32351
Value Function Update Magnitude: 0.35773

Collected Steps per Second: 21,965.52592
Overall Steps per Second: 10,443.46539

Timestep Collection Time: 2.27711
Timestep Consumption Time: 2.51229
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.78941

Cumulative Model Updates: 135,802
Cumulative Timesteps: 1,133,365,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1133365192...
Checkpoint 1133365192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,303.06275
Policy Entropy: 1.82513
Value Function Loss: 0.07173

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.31907
Value Function Update Magnitude: 0.32329

Collected Steps per Second: 21,646.96769
Overall Steps per Second: 10,412.41453

Timestep Collection Time: 2.31016
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.80273

Cumulative Model Updates: 135,808
Cumulative Timesteps: 1,133,415,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,829.40959
Policy Entropy: 1.83445
Value Function Loss: 0.07209

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.31693
Value Function Update Magnitude: 0.31449

Collected Steps per Second: 21,504.64063
Overall Steps per Second: 10,345.99021

Timestep Collection Time: 2.32675
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.83627

Cumulative Model Updates: 135,814
Cumulative Timesteps: 1,133,465,236

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1133465236...
Checkpoint 1133465236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,379.43862
Policy Entropy: 1.82878
Value Function Loss: 0.06930

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.30569
Value Function Update Magnitude: 0.33891

Collected Steps per Second: 21,408.83271
Overall Steps per Second: 10,479.13600

Timestep Collection Time: 2.33576
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.77196

Cumulative Model Updates: 135,820
Cumulative Timesteps: 1,133,515,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,691.44064
Policy Entropy: 1.78492
Value Function Loss: 0.06484

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.29807
Value Function Update Magnitude: 0.35346

Collected Steps per Second: 21,481.18301
Overall Steps per Second: 10,471.64106

Timestep Collection Time: 2.32864
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.77690

Cumulative Model Updates: 135,826
Cumulative Timesteps: 1,133,565,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1133565264...
Checkpoint 1133565264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,889.66588
Policy Entropy: 1.75773
Value Function Loss: 0.06274

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.29691
Value Function Update Magnitude: 0.36487

Collected Steps per Second: 22,015.46903
Overall Steps per Second: 10,584.74907

Timestep Collection Time: 2.27122
Timestep Consumption Time: 2.45275
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.72397

Cumulative Model Updates: 135,832
Cumulative Timesteps: 1,133,615,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,045.32990
Policy Entropy: 1.75729
Value Function Loss: 0.06141

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.31296
Value Function Update Magnitude: 0.37278

Collected Steps per Second: 21,750.68913
Overall Steps per Second: 10,547.64055

Timestep Collection Time: 2.29961
Timestep Consumption Time: 2.44250
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.74210

Cumulative Model Updates: 135,838
Cumulative Timesteps: 1,133,665,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1133665284...
Checkpoint 1133665284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,727.18415
Policy Entropy: 1.76009
Value Function Loss: 0.06018

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.31995
Value Function Update Magnitude: 0.37659

Collected Steps per Second: 22,020.56585
Overall Steps per Second: 10,631.61451

Timestep Collection Time: 2.27179
Timestep Consumption Time: 2.43361
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.70540

Cumulative Model Updates: 135,844
Cumulative Timesteps: 1,133,715,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,158.95489
Policy Entropy: 1.75794
Value Function Loss: 0.06096

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.32439
Value Function Update Magnitude: 0.36896

Collected Steps per Second: 22,091.17833
Overall Steps per Second: 10,465.03081

Timestep Collection Time: 2.26335
Timestep Consumption Time: 2.51447
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.77782

Cumulative Model Updates: 135,850
Cumulative Timesteps: 1,133,765,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1133765310...
Checkpoint 1133765310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,846.45639
Policy Entropy: 1.76642
Value Function Loss: 0.06407

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08087
Policy Update Magnitude: 0.32474
Value Function Update Magnitude: 0.35693

Collected Steps per Second: 22,006.70968
Overall Steps per Second: 10,703.70530

Timestep Collection Time: 2.27367
Timestep Consumption Time: 2.40097
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.67464

Cumulative Model Updates: 135,856
Cumulative Timesteps: 1,133,815,346

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,099.17944
Policy Entropy: 1.77044
Value Function Loss: 0.06100

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07844
Policy Update Magnitude: 0.32336
Value Function Update Magnitude: 0.33306

Collected Steps per Second: 22,046.19960
Overall Steps per Second: 10,474.03841

Timestep Collection Time: 2.26851
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.77485

Cumulative Model Updates: 135,862
Cumulative Timesteps: 1,133,865,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1133865358...
Checkpoint 1133865358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,081.30600
Policy Entropy: 1.76751
Value Function Loss: 0.05679

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.31749
Value Function Update Magnitude: 0.33637

Collected Steps per Second: 22,050.87806
Overall Steps per Second: 10,556.16794

Timestep Collection Time: 2.26776
Timestep Consumption Time: 2.46938
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.73714

Cumulative Model Updates: 135,868
Cumulative Timesteps: 1,133,915,364

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,282.88728
Policy Entropy: 1.74023
Value Function Loss: 0.05168

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.30840
Value Function Update Magnitude: 0.34598

Collected Steps per Second: 21,554.71860
Overall Steps per Second: 10,530.14745

Timestep Collection Time: 2.32181
Timestep Consumption Time: 2.43083
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.75264

Cumulative Model Updates: 135,874
Cumulative Timesteps: 1,133,965,410

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1133965410...
Checkpoint 1133965410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,108.09732
Policy Entropy: 1.73066
Value Function Loss: 0.04914

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07336
Policy Update Magnitude: 0.30537
Value Function Update Magnitude: 0.33111

Collected Steps per Second: 21,710.31538
Overall Steps per Second: 10,538.79272

Timestep Collection Time: 2.30397
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74627

Cumulative Model Updates: 135,880
Cumulative Timesteps: 1,134,015,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,124.02936
Policy Entropy: 1.74113
Value Function Loss: 0.04908

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.30460
Value Function Update Magnitude: 0.33716

Collected Steps per Second: 21,523.17888
Overall Steps per Second: 10,498.48525

Timestep Collection Time: 2.32503
Timestep Consumption Time: 2.44156
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.76659

Cumulative Model Updates: 135,886
Cumulative Timesteps: 1,134,065,472

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1134065472...
Checkpoint 1134065472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,900.72088
Policy Entropy: 1.74265
Value Function Loss: 0.04899

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.30568
Value Function Update Magnitude: 0.34575

Collected Steps per Second: 21,177.51633
Overall Steps per Second: 10,269.01433

Timestep Collection Time: 2.36118
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.86941

Cumulative Model Updates: 135,892
Cumulative Timesteps: 1,134,115,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,054.91368
Policy Entropy: 1.76589
Value Function Loss: 0.05447

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07454
Policy Update Magnitude: 0.31072
Value Function Update Magnitude: 0.33831

Collected Steps per Second: 21,589.19618
Overall Steps per Second: 10,344.89213

Timestep Collection Time: 2.31690
Timestep Consumption Time: 2.51834
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.83524

Cumulative Model Updates: 135,898
Cumulative Timesteps: 1,134,165,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1134165496...
Checkpoint 1134165496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,739.14441
Policy Entropy: 1.76089
Value Function Loss: 0.05450

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.30857
Value Function Update Magnitude: 0.32970

Collected Steps per Second: 22,218.47665
Overall Steps per Second: 10,613.23837

Timestep Collection Time: 2.25155
Timestep Consumption Time: 2.46200
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.71355

Cumulative Model Updates: 135,904
Cumulative Timesteps: 1,134,215,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,722.46993
Policy Entropy: 1.76076
Value Function Loss: 0.05174

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07825
Policy Update Magnitude: 0.30048
Value Function Update Magnitude: 0.31007

Collected Steps per Second: 21,942.25974
Overall Steps per Second: 10,423.23097

Timestep Collection Time: 2.27989
Timestep Consumption Time: 2.51958
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.79947

Cumulative Model Updates: 135,910
Cumulative Timesteps: 1,134,265,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1134265548...
Checkpoint 1134265548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,539.21863
Policy Entropy: 1.74828
Value Function Loss: 0.04712

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07251
Policy Update Magnitude: 0.29606
Value Function Update Magnitude: 0.29013

Collected Steps per Second: 21,937.80301
Overall Steps per Second: 10,499.42233

Timestep Collection Time: 2.28026
Timestep Consumption Time: 2.48419
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.76445

Cumulative Model Updates: 135,916
Cumulative Timesteps: 1,134,315,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,599.39638
Policy Entropy: 1.74113
Value Function Loss: 0.04789

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07467
Policy Update Magnitude: 0.29970
Value Function Update Magnitude: 0.28926

Collected Steps per Second: 22,133.50181
Overall Steps per Second: 10,633.40359

Timestep Collection Time: 2.26028
Timestep Consumption Time: 2.44451
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.70480

Cumulative Model Updates: 135,922
Cumulative Timesteps: 1,134,365,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1134365600...
Checkpoint 1134365600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,474.91853
Policy Entropy: 1.73856
Value Function Loss: 0.04792

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07435
Policy Update Magnitude: 0.30018
Value Function Update Magnitude: 0.30209

Collected Steps per Second: 21,794.72480
Overall Steps per Second: 10,407.33623

Timestep Collection Time: 2.29551
Timestep Consumption Time: 2.51168
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.80719

Cumulative Model Updates: 135,928
Cumulative Timesteps: 1,134,415,630

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,938.90822
Policy Entropy: 1.73819
Value Function Loss: 0.04895

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07853
Policy Update Magnitude: 0.29812
Value Function Update Magnitude: 0.29989

Collected Steps per Second: 22,063.70519
Overall Steps per Second: 10,670.89149

Timestep Collection Time: 2.26644
Timestep Consumption Time: 2.41977
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.68621

Cumulative Model Updates: 135,934
Cumulative Timesteps: 1,134,465,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1134465636...
Checkpoint 1134465636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,873.34377
Policy Entropy: 1.73266
Value Function Loss: 0.04571

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.29446
Value Function Update Magnitude: 0.31051

Collected Steps per Second: 21,801.59261
Overall Steps per Second: 10,492.36363

Timestep Collection Time: 2.29534
Timestep Consumption Time: 2.47404
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.76937

Cumulative Model Updates: 135,940
Cumulative Timesteps: 1,134,515,678

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,146.44761
Policy Entropy: 1.73052
Value Function Loss: 0.04851

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.29704
Value Function Update Magnitude: 0.32594

Collected Steps per Second: 21,686.16900
Overall Steps per Second: 10,417.82856

Timestep Collection Time: 2.30672
Timestep Consumption Time: 2.49504
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.80177

Cumulative Model Updates: 135,946
Cumulative Timesteps: 1,134,565,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1134565702...
Checkpoint 1134565702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,640.57840
Policy Entropy: 1.72952
Value Function Loss: 0.04952

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.30616
Value Function Update Magnitude: 0.34008

Collected Steps per Second: 21,715.27774
Overall Steps per Second: 10,437.99256

Timestep Collection Time: 2.30363
Timestep Consumption Time: 2.48886
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.79249

Cumulative Model Updates: 135,952
Cumulative Timesteps: 1,134,615,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,176.05128
Policy Entropy: 1.73181
Value Function Loss: 0.05082

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.30742
Value Function Update Magnitude: 0.34489

Collected Steps per Second: 21,699.39730
Overall Steps per Second: 10,479.42335

Timestep Collection Time: 2.30440
Timestep Consumption Time: 2.46724
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.77164

Cumulative Model Updates: 135,958
Cumulative Timesteps: 1,134,665,730

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1134665730...
Checkpoint 1134665730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,211.27058
Policy Entropy: 1.73272
Value Function Loss: 0.05331

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.31225
Value Function Update Magnitude: 0.34134

Collected Steps per Second: 21,002.73358
Overall Steps per Second: 10,521.03367

Timestep Collection Time: 2.38179
Timestep Consumption Time: 2.37288
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.75467

Cumulative Model Updates: 135,964
Cumulative Timesteps: 1,134,715,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,458.13510
Policy Entropy: 1.74452
Value Function Loss: 0.05576

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.35301

Collected Steps per Second: 21,128.09124
Overall Steps per Second: 10,543.17588

Timestep Collection Time: 2.36775
Timestep Consumption Time: 2.37712
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.74487

Cumulative Model Updates: 135,970
Cumulative Timesteps: 1,134,765,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1134765780...
Checkpoint 1134765780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,819.49451
Policy Entropy: 1.74992
Value Function Loss: 0.05954

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.31690
Value Function Update Magnitude: 0.36025

Collected Steps per Second: 21,352.20439
Overall Steps per Second: 10,598.68860

Timestep Collection Time: 2.34252
Timestep Consumption Time: 2.37674
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.71926

Cumulative Model Updates: 135,976
Cumulative Timesteps: 1,134,815,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,111.25296
Policy Entropy: 1.74892
Value Function Loss: 0.05608

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07913
Policy Update Magnitude: 0.31669
Value Function Update Magnitude: 0.36581

Collected Steps per Second: 21,565.19367
Overall Steps per Second: 10,515.80992

Timestep Collection Time: 2.31957
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.75684

Cumulative Model Updates: 135,982
Cumulative Timesteps: 1,134,865,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1134865820...
Checkpoint 1134865820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,833.43243
Policy Entropy: 1.74230
Value Function Loss: 0.05230

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.35675

Collected Steps per Second: 21,444.20508
Overall Steps per Second: 10,574.92479

Timestep Collection Time: 2.33229
Timestep Consumption Time: 2.39720
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.72949

Cumulative Model Updates: 135,988
Cumulative Timesteps: 1,134,915,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,271.17746
Policy Entropy: 1.72947
Value Function Loss: 0.05063

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09266
Policy Update Magnitude: 0.30314
Value Function Update Magnitude: 0.33069

Collected Steps per Second: 22,138.84509
Overall Steps per Second: 10,497.48759

Timestep Collection Time: 2.25911
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.76438

Cumulative Model Updates: 135,994
Cumulative Timesteps: 1,134,965,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1134965848...
Checkpoint 1134965848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,167.36211
Policy Entropy: 1.72865
Value Function Loss: 0.05159

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.28036
Value Function Update Magnitude: 0.32192

Collected Steps per Second: 21,812.28211
Overall Steps per Second: 10,617.89426

Timestep Collection Time: 2.29238
Timestep Consumption Time: 2.41684
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.70922

Cumulative Model Updates: 136,000
Cumulative Timesteps: 1,135,015,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,044.31099
Policy Entropy: 1.70528
Value Function Loss: 0.05472

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.29935
Value Function Update Magnitude: 0.32936

Collected Steps per Second: 21,797.03875
Overall Steps per Second: 10,475.35861

Timestep Collection Time: 2.29508
Timestep Consumption Time: 2.48051
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.77559

Cumulative Model Updates: 136,006
Cumulative Timesteps: 1,135,065,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1135065876...
Checkpoint 1135065876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,088.46516
Policy Entropy: 1.72351
Value Function Loss: 0.05933

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.31914
Value Function Update Magnitude: 0.34790

Collected Steps per Second: 21,175.84249
Overall Steps per Second: 10,304.34265

Timestep Collection Time: 2.36269
Timestep Consumption Time: 2.49274
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.85543

Cumulative Model Updates: 136,012
Cumulative Timesteps: 1,135,115,908

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,632.39589
Policy Entropy: 1.72276
Value Function Loss: 0.06031

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.32386
Value Function Update Magnitude: 0.35245

Collected Steps per Second: 21,793.43663
Overall Steps per Second: 10,386.55717

Timestep Collection Time: 2.29528
Timestep Consumption Time: 2.52075
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.81603

Cumulative Model Updates: 136,018
Cumulative Timesteps: 1,135,165,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1135165930...
Checkpoint 1135165930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,506.91851
Policy Entropy: 1.74217
Value Function Loss: 0.05600

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.31910
Value Function Update Magnitude: 0.32570

Collected Steps per Second: 21,206.46381
Overall Steps per Second: 10,268.18587

Timestep Collection Time: 2.35787
Timestep Consumption Time: 2.51174
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.86960

Cumulative Model Updates: 136,024
Cumulative Timesteps: 1,135,215,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,294.22092
Policy Entropy: 1.73006
Value Function Loss: 0.05269

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.31201
Value Function Update Magnitude: 0.29832

Collected Steps per Second: 21,601.05410
Overall Steps per Second: 10,388.63755

Timestep Collection Time: 2.31591
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.81545

Cumulative Model Updates: 136,030
Cumulative Timesteps: 1,135,265,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1135265958...
Checkpoint 1135265958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,070.82296
Policy Entropy: 1.71913
Value Function Loss: 0.05058

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.30509
Value Function Update Magnitude: 0.28414

Collected Steps per Second: 21,488.26398
Overall Steps per Second: 10,303.87957

Timestep Collection Time: 2.32769
Timestep Consumption Time: 2.52660
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.85429

Cumulative Model Updates: 136,036
Cumulative Timesteps: 1,135,315,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,801.10605
Policy Entropy: 1.73085
Value Function Loss: 0.05170

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.30709
Value Function Update Magnitude: 0.30584

Collected Steps per Second: 22,069.75603
Overall Steps per Second: 10,479.90194

Timestep Collection Time: 2.26618
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.77237

Cumulative Model Updates: 136,042
Cumulative Timesteps: 1,135,365,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1135365990...
Checkpoint 1135365990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,699.61082
Policy Entropy: 1.72890
Value Function Loss: 0.05483

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.31286
Value Function Update Magnitude: 0.31425

Collected Steps per Second: 22,048.49320
Overall Steps per Second: 10,492.09212

Timestep Collection Time: 2.26909
Timestep Consumption Time: 2.49926
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.76835

Cumulative Model Updates: 136,048
Cumulative Timesteps: 1,135,416,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,644.64050
Policy Entropy: 1.74520
Value Function Loss: 0.06005

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.31900
Value Function Update Magnitude: 0.34062

Collected Steps per Second: 22,279.09434
Overall Steps per Second: 10,532.36338

Timestep Collection Time: 2.24515
Timestep Consumption Time: 2.50402
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.74917

Cumulative Model Updates: 136,054
Cumulative Timesteps: 1,135,466,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1135466040...
Checkpoint 1135466040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,639.64715
Policy Entropy: 1.75003
Value Function Loss: 0.05833

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.31530
Value Function Update Magnitude: 0.36558

Collected Steps per Second: 21,929.52643
Overall Steps per Second: 10,637.84005

Timestep Collection Time: 2.28030
Timestep Consumption Time: 2.42046
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.70077

Cumulative Model Updates: 136,060
Cumulative Timesteps: 1,135,516,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,490.64117
Policy Entropy: 1.76686
Value Function Loss: 0.05799

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.31563
Value Function Update Magnitude: 0.39145

Collected Steps per Second: 22,434.64922
Overall Steps per Second: 10,748.44204

Timestep Collection Time: 2.22959
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.65370

Cumulative Model Updates: 136,066
Cumulative Timesteps: 1,135,566,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1135566066...
Checkpoint 1135566066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,607.76769
Policy Entropy: 1.75005
Value Function Loss: 0.05637

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.31766
Value Function Update Magnitude: 0.39770

Collected Steps per Second: 21,788.75502
Overall Steps per Second: 10,469.43449

Timestep Collection Time: 2.29550
Timestep Consumption Time: 2.48184
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.77734

Cumulative Model Updates: 136,072
Cumulative Timesteps: 1,135,616,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,622.11465
Policy Entropy: 1.73590
Value Function Loss: 0.05790

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.32069
Value Function Update Magnitude: 0.39336

Collected Steps per Second: 20,999.11434
Overall Steps per Second: 10,435.39973

Timestep Collection Time: 2.38105
Timestep Consumption Time: 2.41033
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.79138

Cumulative Model Updates: 136,078
Cumulative Timesteps: 1,135,666,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1135666082...
Checkpoint 1135666082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,981.43791
Policy Entropy: 1.74122
Value Function Loss: 0.06005

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.32737
Value Function Update Magnitude: 0.38660

Collected Steps per Second: 20,775.35862
Overall Steps per Second: 10,515.84118

Timestep Collection Time: 2.40737
Timestep Consumption Time: 2.34869
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.75606

Cumulative Model Updates: 136,084
Cumulative Timesteps: 1,135,716,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,891.50053
Policy Entropy: 1.74748
Value Function Loss: 0.06151

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.32819
Value Function Update Magnitude: 0.38391

Collected Steps per Second: 21,093.96795
Overall Steps per Second: 10,388.36480

Timestep Collection Time: 2.37186
Timestep Consumption Time: 2.44429
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.81616

Cumulative Model Updates: 136,090
Cumulative Timesteps: 1,135,766,128

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1135766128...
Checkpoint 1135766128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,210.90419
Policy Entropy: 1.74289
Value Function Loss: 0.05633

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.32235
Value Function Update Magnitude: 0.36124

Collected Steps per Second: 20,939.30101
Overall Steps per Second: 10,551.92975

Timestep Collection Time: 2.38919
Timestep Consumption Time: 2.35193
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.74112

Cumulative Model Updates: 136,096
Cumulative Timesteps: 1,135,816,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,614.26912
Policy Entropy: 1.72557
Value Function Loss: 0.05664

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.32214
Value Function Update Magnitude: 0.33748

Collected Steps per Second: 21,142.24788
Overall Steps per Second: 10,466.91087

Timestep Collection Time: 2.36541
Timestep Consumption Time: 2.41251
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.77791

Cumulative Model Updates: 136,102
Cumulative Timesteps: 1,135,866,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1135866166...
Checkpoint 1135866166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,416.21080
Policy Entropy: 1.71529
Value Function Loss: 0.05039

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.31681
Value Function Update Magnitude: 0.33177

Collected Steps per Second: 21,824.19299
Overall Steps per Second: 10,614.76881

Timestep Collection Time: 2.29113
Timestep Consumption Time: 2.41948
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.71061

Cumulative Model Updates: 136,108
Cumulative Timesteps: 1,135,916,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,874.16374
Policy Entropy: 1.71458
Value Function Loss: 0.04931

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.30963
Value Function Update Magnitude: 0.31048

Collected Steps per Second: 22,063.84312
Overall Steps per Second: 10,534.73499

Timestep Collection Time: 2.26715
Timestep Consumption Time: 2.48114
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.74829

Cumulative Model Updates: 136,114
Cumulative Timesteps: 1,135,966,190

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1135966190...
Checkpoint 1135966190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,241.78346
Policy Entropy: 1.71153
Value Function Loss: 0.04893

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.30850
Value Function Update Magnitude: 0.29592

Collected Steps per Second: 22,068.80877
Overall Steps per Second: 10,642.83520

Timestep Collection Time: 2.26673
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.70025

Cumulative Model Updates: 136,120
Cumulative Timesteps: 1,136,016,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,350.05705
Policy Entropy: 1.70808
Value Function Loss: 0.04941

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07460
Policy Update Magnitude: 0.30963
Value Function Update Magnitude: 0.32207

Collected Steps per Second: 22,196.09142
Overall Steps per Second: 10,504.57872

Timestep Collection Time: 2.25328
Timestep Consumption Time: 2.50788
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.76116

Cumulative Model Updates: 136,126
Cumulative Timesteps: 1,136,066,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1136066228...
Checkpoint 1136066228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,087.10517
Policy Entropy: 1.71617
Value Function Loss: 0.05267

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07896
Policy Update Magnitude: 0.31077
Value Function Update Magnitude: 0.33929

Collected Steps per Second: 21,819.15659
Overall Steps per Second: 10,578.20866

Timestep Collection Time: 2.29276
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.72916

Cumulative Model Updates: 136,132
Cumulative Timesteps: 1,136,116,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,836.19305
Policy Entropy: 1.72230
Value Function Loss: 0.05293

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.31603
Value Function Update Magnitude: 0.34368

Collected Steps per Second: 22,084.02362
Overall Steps per Second: 10,456.56263

Timestep Collection Time: 2.26598
Timestep Consumption Time: 2.51972
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.78570

Cumulative Model Updates: 136,138
Cumulative Timesteps: 1,136,166,296

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1136166296...
Checkpoint 1136166296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,481.45309
Policy Entropy: 1.71860
Value Function Loss: 0.05498

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.31577
Value Function Update Magnitude: 0.34697

Collected Steps per Second: 21,712.85254
Overall Steps per Second: 10,565.33143

Timestep Collection Time: 2.30306
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.73303

Cumulative Model Updates: 136,144
Cumulative Timesteps: 1,136,216,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,083.20607
Policy Entropy: 1.71974
Value Function Loss: 0.05201

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.31258
Value Function Update Magnitude: 0.35574

Collected Steps per Second: 21,518.52747
Overall Steps per Second: 10,520.20102

Timestep Collection Time: 2.32451
Timestep Consumption Time: 2.43015
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.75466

Cumulative Model Updates: 136,150
Cumulative Timesteps: 1,136,266,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1136266322...
Checkpoint 1136266322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,997.53094
Policy Entropy: 1.71265
Value Function Loss: 0.05346

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.31845
Value Function Update Magnitude: 0.35120

Collected Steps per Second: 21,290.55865
Overall Steps per Second: 10,314.30286

Timestep Collection Time: 2.34893
Timestep Consumption Time: 2.49968
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.84861

Cumulative Model Updates: 136,156
Cumulative Timesteps: 1,136,316,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,400.75742
Policy Entropy: 1.71854
Value Function Loss: 0.05650

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.32149
Value Function Update Magnitude: 0.35013

Collected Steps per Second: 21,696.56107
Overall Steps per Second: 10,363.96201

Timestep Collection Time: 2.30534
Timestep Consumption Time: 2.52080
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.82615

Cumulative Model Updates: 136,162
Cumulative Timesteps: 1,136,366,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1136366350...
Checkpoint 1136366350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,966.21343
Policy Entropy: 1.71095
Value Function Loss: 0.05543

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.31313
Value Function Update Magnitude: 0.35100

Collected Steps per Second: 21,350.71088
Overall Steps per Second: 10,285.09685

Timestep Collection Time: 2.34362
Timestep Consumption Time: 2.52148
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.86510

Cumulative Model Updates: 136,168
Cumulative Timesteps: 1,136,416,388

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,442.19353
Policy Entropy: 1.72151
Value Function Loss: 0.05760

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.30349
Value Function Update Magnitude: 0.34464

Collected Steps per Second: 21,735.62438
Overall Steps per Second: 10,381.98780

Timestep Collection Time: 2.30037
Timestep Consumption Time: 2.51566
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.81603

Cumulative Model Updates: 136,174
Cumulative Timesteps: 1,136,466,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1136466388...
Checkpoint 1136466388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,075.35369
Policy Entropy: 1.72952
Value Function Loss: 0.05465

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.33111

Collected Steps per Second: 21,812.27709
Overall Steps per Second: 10,536.14094

Timestep Collection Time: 2.29375
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.74861

Cumulative Model Updates: 136,180
Cumulative Timesteps: 1,136,516,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,433.53781
Policy Entropy: 1.74819
Value Function Loss: 0.05530

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.31215
Value Function Update Magnitude: 0.32315

Collected Steps per Second: 22,132.39541
Overall Steps per Second: 10,494.61298

Timestep Collection Time: 2.25985
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.76587

Cumulative Model Updates: 136,186
Cumulative Timesteps: 1,136,566,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1136566436...
Checkpoint 1136566436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,495.04145
Policy Entropy: 1.76091
Value Function Loss: 0.05055

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.30931
Value Function Update Magnitude: 0.31512

Collected Steps per Second: 20,179.78996
Overall Steps per Second: 10,165.17351

Timestep Collection Time: 2.48011
Timestep Consumption Time: 2.44337
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.92348

Cumulative Model Updates: 136,192
Cumulative Timesteps: 1,136,616,484

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,567.11790
Policy Entropy: 1.76104
Value Function Loss: 0.04656

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.30523
Value Function Update Magnitude: 0.31188

Collected Steps per Second: 21,306.95002
Overall Steps per Second: 10,458.14224

Timestep Collection Time: 2.34872
Timestep Consumption Time: 2.43645
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.78517

Cumulative Model Updates: 136,198
Cumulative Timesteps: 1,136,666,528

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1136666528...
Checkpoint 1136666528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,438.63942
Policy Entropy: 1.73605
Value Function Loss: 0.04605

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.30154
Value Function Update Magnitude: 0.30244

Collected Steps per Second: 21,371.46787
Overall Steps per Second: 10,298.53586

Timestep Collection Time: 2.34060
Timestep Consumption Time: 2.51660
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.85720

Cumulative Model Updates: 136,204
Cumulative Timesteps: 1,136,716,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,125.21099
Policy Entropy: 1.72935
Value Function Loss: 0.04771

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.30447
Value Function Update Magnitude: 0.29900

Collected Steps per Second: 21,955.03530
Overall Steps per Second: 10,420.50945

Timestep Collection Time: 2.27738
Timestep Consumption Time: 2.52085
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.79823

Cumulative Model Updates: 136,210
Cumulative Timesteps: 1,136,766,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1136766550...
Checkpoint 1136766550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,558.10383
Policy Entropy: 1.72761
Value Function Loss: 0.05110

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.30401
Value Function Update Magnitude: 0.31480

Collected Steps per Second: 21,952.61425
Overall Steps per Second: 10,629.75094

Timestep Collection Time: 2.28000
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.70867

Cumulative Model Updates: 136,216
Cumulative Timesteps: 1,136,816,602

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,843.64553
Policy Entropy: 1.74475
Value Function Loss: 0.05197

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.30743
Value Function Update Magnitude: 0.33527

Collected Steps per Second: 21,907.15556
Overall Steps per Second: 10,554.61738

Timestep Collection Time: 2.28382
Timestep Consumption Time: 2.45647
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.74029

Cumulative Model Updates: 136,222
Cumulative Timesteps: 1,136,866,634

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1136866634...
Checkpoint 1136866634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,464.78158
Policy Entropy: 1.73817
Value Function Loss: 0.05236

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.31071
Value Function Update Magnitude: 0.34367

Collected Steps per Second: 21,600.42843
Overall Steps per Second: 10,505.36184

Timestep Collection Time: 2.31579
Timestep Consumption Time: 2.44578
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.76157

Cumulative Model Updates: 136,228
Cumulative Timesteps: 1,136,916,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,115.10650
Policy Entropy: 1.73740
Value Function Loss: 0.05185

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.31192
Value Function Update Magnitude: 0.32849

Collected Steps per Second: 22,029.06542
Overall Steps per Second: 10,487.09275

Timestep Collection Time: 2.27064
Timestep Consumption Time: 2.49904
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.76967

Cumulative Model Updates: 136,234
Cumulative Timesteps: 1,136,966,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1136966676...
Checkpoint 1136966676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,296.31035
Policy Entropy: 1.74010
Value Function Loss: 0.05193

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.30976
Value Function Update Magnitude: 0.31092

Collected Steps per Second: 22,015.36584
Overall Steps per Second: 10,622.86985

Timestep Collection Time: 2.27114
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.70683

Cumulative Model Updates: 136,240
Cumulative Timesteps: 1,137,016,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,394.17228
Policy Entropy: 1.76247
Value Function Loss: 0.05309

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07738
Policy Update Magnitude: 0.30999
Value Function Update Magnitude: 0.30243

Collected Steps per Second: 22,052.49883
Overall Steps per Second: 10,494.61656

Timestep Collection Time: 2.26795
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.76568

Cumulative Model Updates: 136,246
Cumulative Timesteps: 1,137,066,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1137066690...
Checkpoint 1137066690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,925.01669
Policy Entropy: 1.77396
Value Function Loss: 0.05028

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.30883
Value Function Update Magnitude: 0.30360

Collected Steps per Second: 21,837.16171
Overall Steps per Second: 10,594.70291

Timestep Collection Time: 2.29004
Timestep Consumption Time: 2.43005
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.72009

Cumulative Model Updates: 136,252
Cumulative Timesteps: 1,137,116,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,900.56713
Policy Entropy: 1.76063
Value Function Loss: 0.05025

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.30392
Value Function Update Magnitude: 0.29920

Collected Steps per Second: 21,515.28316
Overall Steps per Second: 10,499.98775

Timestep Collection Time: 2.32597
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.76610

Cumulative Model Updates: 136,258
Cumulative Timesteps: 1,137,166,742

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1137166742...
Checkpoint 1137166742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,865.88844
Policy Entropy: 1.73105
Value Function Loss: 0.04952

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.30409
Value Function Update Magnitude: 0.30380

Collected Steps per Second: 21,357.17234
Overall Steps per Second: 10,305.95211

Timestep Collection Time: 2.34198
Timestep Consumption Time: 2.51134
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.85331

Cumulative Model Updates: 136,264
Cumulative Timesteps: 1,137,216,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,122.27710
Policy Entropy: 1.73561
Value Function Loss: 0.05250

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.30833
Value Function Update Magnitude: 0.30192

Collected Steps per Second: 21,796.05375
Overall Steps per Second: 10,411.27470

Timestep Collection Time: 2.29454
Timestep Consumption Time: 2.50909
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.80364

Cumulative Model Updates: 136,270
Cumulative Timesteps: 1,137,266,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1137266772...
Checkpoint 1137266772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,656.94169
Policy Entropy: 1.73580
Value Function Loss: 0.04892

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.30770
Value Function Update Magnitude: 0.30080

Collected Steps per Second: 21,369.47611
Overall Steps per Second: 10,494.02206

Timestep Collection Time: 2.34035
Timestep Consumption Time: 2.42541
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.76576

Cumulative Model Updates: 136,276
Cumulative Timesteps: 1,137,316,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,223.76154
Policy Entropy: 1.75620
Value Function Loss: 0.04783

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.30485
Value Function Update Magnitude: 0.30075

Collected Steps per Second: 21,785.17925
Overall Steps per Second: 10,561.60641

Timestep Collection Time: 2.29624
Timestep Consumption Time: 2.44016
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.73640

Cumulative Model Updates: 136,282
Cumulative Timesteps: 1,137,366,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1137366808...
Checkpoint 1137366808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,175.97753
Policy Entropy: 1.74009
Value Function Loss: 0.04954

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07436
Policy Update Magnitude: 0.30701
Value Function Update Magnitude: 0.29797

Collected Steps per Second: 22,164.87296
Overall Steps per Second: 10,566.02422

Timestep Collection Time: 2.25654
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.73366

Cumulative Model Updates: 136,288
Cumulative Timesteps: 1,137,416,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,023.67430
Policy Entropy: 1.74701
Value Function Loss: 0.05286

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.30962
Value Function Update Magnitude: 0.30558

Collected Steps per Second: 21,441.07782
Overall Steps per Second: 10,458.73021

Timestep Collection Time: 2.33207
Timestep Consumption Time: 2.44882
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.78089

Cumulative Model Updates: 136,294
Cumulative Timesteps: 1,137,466,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1137466826...
Checkpoint 1137466826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,099.41405
Policy Entropy: 1.75897
Value Function Loss: 0.05601

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.31216
Value Function Update Magnitude: 0.32381

Collected Steps per Second: 21,167.22693
Overall Steps per Second: 10,600.13693

Timestep Collection Time: 2.36214
Timestep Consumption Time: 2.35478
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.71692

Cumulative Model Updates: 136,300
Cumulative Timesteps: 1,137,516,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,266.75409
Policy Entropy: 1.76851
Value Function Loss: 0.05717

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.31538
Value Function Update Magnitude: 0.35133

Collected Steps per Second: 20,193.48586
Overall Steps per Second: 10,083.55681

Timestep Collection Time: 2.47793
Timestep Consumption Time: 2.48441
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.96234

Cumulative Model Updates: 136,306
Cumulative Timesteps: 1,137,566,864

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1137566864...
Checkpoint 1137566864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,205.78486
Policy Entropy: 1.74275
Value Function Loss: 0.05526

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.31821
Value Function Update Magnitude: 0.37458

Collected Steps per Second: 21,368.71640
Overall Steps per Second: 10,634.96531

Timestep Collection Time: 2.34052
Timestep Consumption Time: 2.36226
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.70279

Cumulative Model Updates: 136,312
Cumulative Timesteps: 1,137,616,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,485.68211
Policy Entropy: 1.73320
Value Function Loss: 0.05948

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.32390
Value Function Update Magnitude: 0.37768

Collected Steps per Second: 21,445.22404
Overall Steps per Second: 10,492.83332

Timestep Collection Time: 2.33189
Timestep Consumption Time: 2.43403
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.76592

Cumulative Model Updates: 136,318
Cumulative Timesteps: 1,137,666,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1137666886...
Checkpoint 1137666886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,473.34504
Policy Entropy: 1.73982
Value Function Loss: 0.06360

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.33168
Value Function Update Magnitude: 0.35399

Collected Steps per Second: 21,178.84776
Overall Steps per Second: 10,588.22944

Timestep Collection Time: 2.36198
Timestep Consumption Time: 2.36251
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.72449

Cumulative Model Updates: 136,324
Cumulative Timesteps: 1,137,716,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,143.09050
Policy Entropy: 1.75739
Value Function Loss: 0.06518

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.33315
Value Function Update Magnitude: 0.34891

Collected Steps per Second: 20,817.34502
Overall Steps per Second: 10,477.76892

Timestep Collection Time: 2.40319
Timestep Consumption Time: 2.37149
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.77468

Cumulative Model Updates: 136,330
Cumulative Timesteps: 1,137,766,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1137766938...
Checkpoint 1137766938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,219.90260
Policy Entropy: 1.75218
Value Function Loss: 0.05948

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.32555
Value Function Update Magnitude: 0.34249

Collected Steps per Second: 21,082.62360
Overall Steps per Second: 10,315.21365

Timestep Collection Time: 2.37361
Timestep Consumption Time: 2.47767
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.85128

Cumulative Model Updates: 136,336
Cumulative Timesteps: 1,137,816,980

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,821.78506
Policy Entropy: 1.73763
Value Function Loss: 0.05380

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.31834
Value Function Update Magnitude: 0.33755

Collected Steps per Second: 21,465.50866
Overall Steps per Second: 10,397.04722

Timestep Collection Time: 2.32932
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.80906

Cumulative Model Updates: 136,342
Cumulative Timesteps: 1,137,866,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1137866980...
Checkpoint 1137866980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,222.08588
Policy Entropy: 1.73612
Value Function Loss: 0.05099

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.31508
Value Function Update Magnitude: 0.32691

Collected Steps per Second: 21,834.38038
Overall Steps per Second: 10,586.96405

Timestep Collection Time: 2.29116
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.72525

Cumulative Model Updates: 136,348
Cumulative Timesteps: 1,137,917,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,024.69980
Policy Entropy: 1.72252
Value Function Loss: 0.05063

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.31193
Value Function Update Magnitude: 0.33014

Collected Steps per Second: 21,823.48580
Overall Steps per Second: 10,414.22280

Timestep Collection Time: 2.29111
Timestep Consumption Time: 2.51002
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.80113

Cumulative Model Updates: 136,354
Cumulative Timesteps: 1,137,967,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1137967006...
Checkpoint 1137967006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,502.34988
Policy Entropy: 1.71775
Value Function Loss: 0.04862

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.31220
Value Function Update Magnitude: 0.32733

Collected Steps per Second: 21,862.06971
Overall Steps per Second: 10,362.15970

Timestep Collection Time: 2.28954
Timestep Consumption Time: 2.54092
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.83046

Cumulative Model Updates: 136,360
Cumulative Timesteps: 1,138,017,060

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,308.59755
Policy Entropy: 1.71448
Value Function Loss: 0.04747

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.30754
Value Function Update Magnitude: 0.31478

Collected Steps per Second: 22,188.89797
Overall Steps per Second: 10,526.65162

Timestep Collection Time: 2.25428
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.75175

Cumulative Model Updates: 136,366
Cumulative Timesteps: 1,138,067,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1138067080...
Checkpoint 1138067080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,795.29323
Policy Entropy: 1.74505
Value Function Loss: 0.05046

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.28844
Value Function Update Magnitude: 0.30221

Collected Steps per Second: 22,125.58772
Overall Steps per Second: 10,506.40926

Timestep Collection Time: 2.26082
Timestep Consumption Time: 2.50027
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.76109

Cumulative Model Updates: 136,372
Cumulative Timesteps: 1,138,117,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,936.14782
Policy Entropy: 1.75345
Value Function Loss: 0.05745

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.27761
Value Function Update Magnitude: 0.30373

Collected Steps per Second: 21,878.93345
Overall Steps per Second: 10,404.18828

Timestep Collection Time: 2.28640
Timestep Consumption Time: 2.52166
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.80806

Cumulative Model Updates: 136,378
Cumulative Timesteps: 1,138,167,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1138167126...
Checkpoint 1138167126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,629.84690
Policy Entropy: 1.76375
Value Function Loss: 0.05971

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.29441
Value Function Update Magnitude: 0.32836

Collected Steps per Second: 21,918.44078
Overall Steps per Second: 10,616.84078

Timestep Collection Time: 2.28164
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.71044

Cumulative Model Updates: 136,384
Cumulative Timesteps: 1,138,217,136

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,728.35585
Policy Entropy: 1.74694
Value Function Loss: 0.05634

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.31330
Value Function Update Magnitude: 0.35117

Collected Steps per Second: 22,197.92379
Overall Steps per Second: 10,484.71316

Timestep Collection Time: 2.25300
Timestep Consumption Time: 2.51699
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.76999

Cumulative Model Updates: 136,390
Cumulative Timesteps: 1,138,267,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1138267148...
Checkpoint 1138267148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,461.37926
Policy Entropy: 1.74154
Value Function Loss: 0.05730

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.31587
Value Function Update Magnitude: 0.33465

Collected Steps per Second: 22,034.21816
Overall Steps per Second: 10,655.94924

Timestep Collection Time: 2.26956
Timestep Consumption Time: 2.42340
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.69297

Cumulative Model Updates: 136,396
Cumulative Timesteps: 1,138,317,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,010.78697
Policy Entropy: 1.74394
Value Function Loss: 0.06135

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.32145
Value Function Update Magnitude: 0.33356

Collected Steps per Second: 21,510.22249
Overall Steps per Second: 10,400.42640

Timestep Collection Time: 2.32531
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.80923

Cumulative Model Updates: 136,402
Cumulative Timesteps: 1,138,367,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1138367174...
Checkpoint 1138367174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,925.90128
Policy Entropy: 1.75694
Value Function Loss: 0.05782

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.32067
Value Function Update Magnitude: 0.37126

Collected Steps per Second: 21,536.13930
Overall Steps per Second: 10,363.91497

Timestep Collection Time: 2.32335
Timestep Consumption Time: 2.50455
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.82791

Cumulative Model Updates: 136,408
Cumulative Timesteps: 1,138,417,210

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,640.77437
Policy Entropy: 1.76068
Value Function Loss: 0.05715

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.31588
Value Function Update Magnitude: 0.36604

Collected Steps per Second: 21,609.86773
Overall Steps per Second: 10,332.67946

Timestep Collection Time: 2.31394
Timestep Consumption Time: 2.52546
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.83940

Cumulative Model Updates: 136,414
Cumulative Timesteps: 1,138,467,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1138467214...
Checkpoint 1138467214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,267.43521
Policy Entropy: 1.76917
Value Function Loss: 0.05370

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.31269
Value Function Update Magnitude: 0.36797

Collected Steps per Second: 21,179.60374
Overall Steps per Second: 10,278.98659

Timestep Collection Time: 2.36161
Timestep Consumption Time: 2.50443
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.86604

Cumulative Model Updates: 136,420
Cumulative Timesteps: 1,138,517,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,585.93426
Policy Entropy: 1.76086
Value Function Loss: 0.05341

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.30725
Value Function Update Magnitude: 0.35303

Collected Steps per Second: 21,757.26423
Overall Steps per Second: 10,402.43005

Timestep Collection Time: 2.29909
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.80868

Cumulative Model Updates: 136,426
Cumulative Timesteps: 1,138,567,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1138567254...
Checkpoint 1138567254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,551.39269
Policy Entropy: 1.76017
Value Function Loss: 0.05787

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.30401
Value Function Update Magnitude: 0.30873

Collected Steps per Second: 21,867.52090
Overall Steps per Second: 10,623.78039

Timestep Collection Time: 2.28796
Timestep Consumption Time: 2.42148
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.70943

Cumulative Model Updates: 136,432
Cumulative Timesteps: 1,138,617,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,631.58345
Policy Entropy: 1.74825
Value Function Loss: 0.05722

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.31508
Value Function Update Magnitude: 0.30664

Collected Steps per Second: 21,921.01859
Overall Steps per Second: 10,406.08511

Timestep Collection Time: 2.28165
Timestep Consumption Time: 2.52477
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.80642

Cumulative Model Updates: 136,438
Cumulative Timesteps: 1,138,667,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1138667302...
Checkpoint 1138667302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,995.32531
Policy Entropy: 1.75988
Value Function Loss: 0.06161

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.31916
Value Function Update Magnitude: 0.29307

Collected Steps per Second: 22,089.32927
Overall Steps per Second: 10,615.32538

Timestep Collection Time: 2.26471
Timestep Consumption Time: 2.44791
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.71262

Cumulative Model Updates: 136,444
Cumulative Timesteps: 1,138,717,328

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,425.90584
Policy Entropy: 1.75717
Value Function Loss: 0.05389

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.30108
Value Function Update Magnitude: 0.31095

Collected Steps per Second: 22,381.56656
Overall Steps per Second: 10,549.07712

Timestep Collection Time: 2.23496
Timestep Consumption Time: 2.50687
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.74184

Cumulative Model Updates: 136,450
Cumulative Timesteps: 1,138,767,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1138767350...
Checkpoint 1138767350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,423.16425
Policy Entropy: 1.75147
Value Function Loss: 0.05239

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.31066
Value Function Update Magnitude: 0.31490

Collected Steps per Second: 21,970.12007
Overall Steps per Second: 10,606.69795

Timestep Collection Time: 2.27682
Timestep Consumption Time: 2.43926
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.71608

Cumulative Model Updates: 136,456
Cumulative Timesteps: 1,138,817,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,290.87361
Policy Entropy: 1.72454
Value Function Loss: 0.04954

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.31113
Value Function Update Magnitude: 0.31435

Collected Steps per Second: 22,091.15786
Overall Steps per Second: 10,458.65990

Timestep Collection Time: 2.26362
Timestep Consumption Time: 2.51768
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.78130

Cumulative Model Updates: 136,462
Cumulative Timesteps: 1,138,867,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1138867378...
Checkpoint 1138867378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,716.05243
Policy Entropy: 1.71699
Value Function Loss: 0.05140

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.30225
Value Function Update Magnitude: 0.31561

Collected Steps per Second: 21,774.45116
Overall Steps per Second: 10,567.73395

Timestep Collection Time: 2.29875
Timestep Consumption Time: 2.43774
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.73649

Cumulative Model Updates: 136,468
Cumulative Timesteps: 1,138,917,432

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,736.65989
Policy Entropy: 1.74464
Value Function Loss: 0.05075

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.28550
Value Function Update Magnitude: 0.33156

Collected Steps per Second: 21,457.93309
Overall Steps per Second: 10,463.57193

Timestep Collection Time: 2.33098
Timestep Consumption Time: 2.44922
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.78020

Cumulative Model Updates: 136,474
Cumulative Timesteps: 1,138,967,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1138967450...
Checkpoint 1138967450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,715.21792
Policy Entropy: 1.75751
Value Function Loss: 0.05034

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.28198
Value Function Update Magnitude: 0.33544

Collected Steps per Second: 21,472.55705
Overall Steps per Second: 10,352.35988

Timestep Collection Time: 2.33032
Timestep Consumption Time: 2.50316
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.83349

Cumulative Model Updates: 136,480
Cumulative Timesteps: 1,139,017,488

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,785.80822
Policy Entropy: 1.76419
Value Function Loss: 0.04957

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.29612
Value Function Update Magnitude: 0.33386

Collected Steps per Second: 21,653.20792
Overall Steps per Second: 10,386.68846

Timestep Collection Time: 2.30959
Timestep Consumption Time: 2.50523
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.81482

Cumulative Model Updates: 136,486
Cumulative Timesteps: 1,139,067,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1139067498...
Checkpoint 1139067498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,399.30294
Policy Entropy: 1.76257
Value Function Loss: 0.05533

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.30254
Value Function Update Magnitude: 0.33290

Collected Steps per Second: 21,773.64268
Overall Steps per Second: 10,544.09927

Timestep Collection Time: 2.29654
Timestep Consumption Time: 2.44583
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.74237

Cumulative Model Updates: 136,492
Cumulative Timesteps: 1,139,117,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,286.41675
Policy Entropy: 1.75489
Value Function Loss: 0.05830

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.28700
Value Function Update Magnitude: 0.33782

Collected Steps per Second: 21,747.24594
Overall Steps per Second: 10,473.11808

Timestep Collection Time: 2.29914
Timestep Consumption Time: 2.47499
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.77413

Cumulative Model Updates: 136,498
Cumulative Timesteps: 1,139,167,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1139167502...
Checkpoint 1139167502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,164.36387
Policy Entropy: 1.74465
Value Function Loss: 0.05645

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.27704
Value Function Update Magnitude: 0.34411

Collected Steps per Second: 22,137.84527
Overall Steps per Second: 10,606.52670

Timestep Collection Time: 2.25894
Timestep Consumption Time: 2.45590
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.71483

Cumulative Model Updates: 136,504
Cumulative Timesteps: 1,139,217,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,577.49070
Policy Entropy: 1.71347
Value Function Loss: 0.05071

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.29957
Value Function Update Magnitude: 0.33056

Collected Steps per Second: 21,942.74519
Overall Steps per Second: 10,466.75204

Timestep Collection Time: 2.28012
Timestep Consumption Time: 2.49997
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.78009

Cumulative Model Updates: 136,510
Cumulative Timesteps: 1,139,267,542

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1139267542...
Checkpoint 1139267542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,489.84068
Policy Entropy: 1.73931
Value Function Loss: 0.05575

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.32665

Collected Steps per Second: 21,904.01601
Overall Steps per Second: 10,577.83574

Timestep Collection Time: 2.28360
Timestep Consumption Time: 2.44516
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.72876

Cumulative Model Updates: 136,516
Cumulative Timesteps: 1,139,317,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,256.33503
Policy Entropy: 1.75134
Value Function Loss: 0.05787

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.32032
Value Function Update Magnitude: 0.32189

Collected Steps per Second: 21,844.66963
Overall Steps per Second: 10,509.52761

Timestep Collection Time: 2.28971
Timestep Consumption Time: 2.46959
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.75930

Cumulative Model Updates: 136,522
Cumulative Timesteps: 1,139,367,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1139367580...
Checkpoint 1139367580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,541.23626
Policy Entropy: 1.76638
Value Function Loss: 0.05534

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.32025
Value Function Update Magnitude: 0.33419

Collected Steps per Second: 22,043.15174
Overall Steps per Second: 10,623.66329

Timestep Collection Time: 2.26864
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.70723

Cumulative Model Updates: 136,528
Cumulative Timesteps: 1,139,417,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,293.06451
Policy Entropy: 1.75085
Value Function Loss: 0.05043

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.31342
Value Function Update Magnitude: 0.32463

Collected Steps per Second: 21,807.00401
Overall Steps per Second: 10,462.02533

Timestep Collection Time: 2.29468
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.78301

Cumulative Model Updates: 136,534
Cumulative Timesteps: 1,139,467,628

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1139467628...
Checkpoint 1139467628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,059.76279
Policy Entropy: 1.75090
Value Function Loss: 0.05001

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07946
Policy Update Magnitude: 0.31139
Value Function Update Magnitude: 0.31758

Collected Steps per Second: 21,189.40702
Overall Steps per Second: 10,256.55685

Timestep Collection Time: 2.36052
Timestep Consumption Time: 2.51617
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.87669

Cumulative Model Updates: 136,540
Cumulative Timesteps: 1,139,517,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,942.07939
Policy Entropy: 1.77403
Value Function Loss: 0.05727

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.31490
Value Function Update Magnitude: 0.32812

Collected Steps per Second: 21,490.29661
Overall Steps per Second: 10,332.72997

Timestep Collection Time: 2.32784
Timestep Consumption Time: 2.51367
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.84151

Cumulative Model Updates: 136,546
Cumulative Timesteps: 1,139,567,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1139567672...
Checkpoint 1139567672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,361.08653
Policy Entropy: 1.78950
Value Function Loss: 0.05948

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.31969
Value Function Update Magnitude: 0.36322

Collected Steps per Second: 21,461.63286
Overall Steps per Second: 10,318.90980

Timestep Collection Time: 2.33114
Timestep Consumption Time: 2.51724
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.84838

Cumulative Model Updates: 136,552
Cumulative Timesteps: 1,139,617,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,342.97496
Policy Entropy: 1.78499
Value Function Loss: 0.05471

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.31508
Value Function Update Magnitude: 0.35483

Collected Steps per Second: 22,350.36507
Overall Steps per Second: 10,434.55365

Timestep Collection Time: 2.23835
Timestep Consumption Time: 2.55610
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.79446

Cumulative Model Updates: 136,558
Cumulative Timesteps: 1,139,667,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1139667730...
Checkpoint 1139667730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,548.28710
Policy Entropy: 1.74624
Value Function Loss: 0.04996

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07523
Policy Update Magnitude: 0.30674
Value Function Update Magnitude: 0.30622

Collected Steps per Second: 22,004.41698
Overall Steps per Second: 10,585.45616

Timestep Collection Time: 2.27391
Timestep Consumption Time: 2.45296
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.72686

Cumulative Model Updates: 136,564
Cumulative Timesteps: 1,139,717,766

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,272.80150
Policy Entropy: 1.75349
Value Function Loss: 0.05058

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.30694
Value Function Update Magnitude: 0.29164

Collected Steps per Second: 22,040.80550
Overall Steps per Second: 10,481.55800

Timestep Collection Time: 2.26934
Timestep Consumption Time: 2.50266
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.77200

Cumulative Model Updates: 136,570
Cumulative Timesteps: 1,139,767,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1139767784...
Checkpoint 1139767784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,840.13208
Policy Entropy: 1.76409
Value Function Loss: 0.05556

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.30625
Value Function Update Magnitude: 0.31160

Collected Steps per Second: 21,618.98426
Overall Steps per Second: 10,397.70851

Timestep Collection Time: 2.31435
Timestep Consumption Time: 2.49767
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.81202

Cumulative Model Updates: 136,576
Cumulative Timesteps: 1,139,817,818

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,537.69112
Policy Entropy: 1.78179
Value Function Loss: 0.05434

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.30975
Value Function Update Magnitude: 0.33889

Collected Steps per Second: 22,232.72629
Overall Steps per Second: 10,705.44373

Timestep Collection Time: 2.25056
Timestep Consumption Time: 2.42333
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.67388

Cumulative Model Updates: 136,582
Cumulative Timesteps: 1,139,867,854

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1139867854...
Checkpoint 1139867854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,898.41288
Policy Entropy: 1.77215
Value Function Loss: 0.05188

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07652
Policy Update Magnitude: 0.30962
Value Function Update Magnitude: 0.33712

Collected Steps per Second: 22,108.69517
Overall Steps per Second: 10,694.22232

Timestep Collection Time: 2.26164
Timestep Consumption Time: 2.41396
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.67561

Cumulative Model Updates: 136,588
Cumulative Timesteps: 1,139,917,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,948.32754
Policy Entropy: 1.77511
Value Function Loss: 0.05560

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.32487

Collected Steps per Second: 22,058.67788
Overall Steps per Second: 10,469.48200

Timestep Collection Time: 2.26677
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.77598

Cumulative Model Updates: 136,594
Cumulative Timesteps: 1,139,967,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1139967858...
Checkpoint 1139967858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,058.16197
Policy Entropy: 1.76383
Value Function Loss: 0.05725

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.31265
Value Function Update Magnitude: 0.32273

Collected Steps per Second: 21,489.07536
Overall Steps per Second: 10,513.70370

Timestep Collection Time: 2.32732
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.75684

Cumulative Model Updates: 136,600
Cumulative Timesteps: 1,140,017,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,233.67592
Policy Entropy: 1.76749
Value Function Loss: 0.05716

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.31250
Value Function Update Magnitude: 0.32759

Collected Steps per Second: 21,663.23441
Overall Steps per Second: 10,580.20909

Timestep Collection Time: 2.31000
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.72977

Cumulative Model Updates: 136,606
Cumulative Timesteps: 1,140,067,912

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1140067912...
Checkpoint 1140067912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,562.58931
Policy Entropy: 1.75978
Value Function Loss: 0.05413

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.31388
Value Function Update Magnitude: 0.32088

Collected Steps per Second: 21,488.51025
Overall Steps per Second: 10,530.67515

Timestep Collection Time: 2.32878
Timestep Consumption Time: 2.42324
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.75202

Cumulative Model Updates: 136,612
Cumulative Timesteps: 1,140,117,954

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,693.16710
Policy Entropy: 1.76650
Value Function Loss: 0.05234

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.30825
Value Function Update Magnitude: 0.31196

Collected Steps per Second: 21,790.57923
Overall Steps per Second: 10,586.37954

Timestep Collection Time: 2.29494
Timestep Consumption Time: 2.42887
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.72381

Cumulative Model Updates: 136,618
Cumulative Timesteps: 1,140,167,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1140167962...
Checkpoint 1140167962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,735.47604
Policy Entropy: 1.76565
Value Function Loss: 0.05515

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.30384
Value Function Update Magnitude: 0.31520

Collected Steps per Second: 21,718.78026
Overall Steps per Second: 10,544.12304

Timestep Collection Time: 2.30326
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.74425

Cumulative Model Updates: 136,624
Cumulative Timesteps: 1,140,217,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,143.31158
Policy Entropy: 1.75885
Value Function Loss: 0.05491

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.31171
Value Function Update Magnitude: 0.32943

Collected Steps per Second: 21,505.06843
Overall Steps per Second: 10,493.40398

Timestep Collection Time: 2.32578
Timestep Consumption Time: 2.44065
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.76642

Cumulative Model Updates: 136,630
Cumulative Timesteps: 1,140,268,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1140268002...
Checkpoint 1140268002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,665.83681
Policy Entropy: 1.77039
Value Function Loss: 0.05514

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.31054
Value Function Update Magnitude: 0.33803

Collected Steps per Second: 21,314.48923
Overall Steps per Second: 10,603.41135

Timestep Collection Time: 2.34695
Timestep Consumption Time: 2.37078
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.71773

Cumulative Model Updates: 136,636
Cumulative Timesteps: 1,140,318,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,415.14872
Policy Entropy: 1.75214
Value Function Loss: 0.05271

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.31190
Value Function Update Magnitude: 0.29056

Collected Steps per Second: 20,238.63946
Overall Steps per Second: 10,169.45485

Timestep Collection Time: 2.47052
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.91668

Cumulative Model Updates: 136,642
Cumulative Timesteps: 1,140,368,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1140368026...
Checkpoint 1140368026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,050.04789
Policy Entropy: 1.76750
Value Function Loss: 0.05287

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.30963
Value Function Update Magnitude: 0.27705

Collected Steps per Second: 21,225.09500
Overall Steps per Second: 10,510.43537

Timestep Collection Time: 2.35617
Timestep Consumption Time: 2.40196
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.75813

Cumulative Model Updates: 136,648
Cumulative Timesteps: 1,140,418,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,390.29534
Policy Entropy: 1.75315
Value Function Loss: 0.05255

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.31048
Value Function Update Magnitude: 0.31387

Collected Steps per Second: 21,472.74611
Overall Steps per Second: 10,492.04931

Timestep Collection Time: 2.33012
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.76875

Cumulative Model Updates: 136,654
Cumulative Timesteps: 1,140,468,070

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1140468070...
Checkpoint 1140468070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,241.67219
Policy Entropy: 1.76438
Value Function Loss: 0.05485

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.31099
Value Function Update Magnitude: 0.32888

Collected Steps per Second: 21,305.08765
Overall Steps per Second: 10,381.79020

Timestep Collection Time: 2.34714
Timestep Consumption Time: 2.46956
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.81670

Cumulative Model Updates: 136,660
Cumulative Timesteps: 1,140,518,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,484.73489
Policy Entropy: 1.75227
Value Function Loss: 0.05478

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.31641
Value Function Update Magnitude: 0.33729

Collected Steps per Second: 21,977.48213
Overall Steps per Second: 10,664.53331

Timestep Collection Time: 2.27578
Timestep Consumption Time: 2.41415
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.68994

Cumulative Model Updates: 136,666
Cumulative Timesteps: 1,140,568,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1140568092...
Checkpoint 1140568092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,662.02232
Policy Entropy: 1.77832
Value Function Loss: 0.05647

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.31134
Value Function Update Magnitude: 0.33845

Collected Steps per Second: 21,259.58832
Overall Steps per Second: 10,357.77239

Timestep Collection Time: 2.35291
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.82942

Cumulative Model Updates: 136,672
Cumulative Timesteps: 1,140,618,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,735.60571
Policy Entropy: 1.78498
Value Function Loss: 0.05677

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.29816
Value Function Update Magnitude: 0.34190

Collected Steps per Second: 21,763.13990
Overall Steps per Second: 10,500.89535

Timestep Collection Time: 2.29755
Timestep Consumption Time: 2.46413
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.76169

Cumulative Model Updates: 136,678
Cumulative Timesteps: 1,140,668,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1140668116...
Checkpoint 1140668116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,942.23424
Policy Entropy: 1.78677
Value Function Loss: 0.05606

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.30908
Value Function Update Magnitude: 0.31649

Collected Steps per Second: 21,598.46981
Overall Steps per Second: 10,482.92244

Timestep Collection Time: 2.31637
Timestep Consumption Time: 2.45616
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.77252

Cumulative Model Updates: 136,684
Cumulative Timesteps: 1,140,718,146

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,428.93016
Policy Entropy: 1.76478
Value Function Loss: 0.05253

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.30835
Value Function Update Magnitude: 0.30689

Collected Steps per Second: 21,858.50718
Overall Steps per Second: 10,458.41718

Timestep Collection Time: 2.28808
Timestep Consumption Time: 2.49410
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.78218

Cumulative Model Updates: 136,690
Cumulative Timesteps: 1,140,768,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1140768160...
Checkpoint 1140768160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,895.52143
Policy Entropy: 1.76821
Value Function Loss: 0.04872

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.30178
Value Function Update Magnitude: 0.32633

Collected Steps per Second: 21,424.55377
Overall Steps per Second: 10,337.49601

Timestep Collection Time: 2.33452
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.83831

Cumulative Model Updates: 136,696
Cumulative Timesteps: 1,140,818,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,564.90454
Policy Entropy: 1.76386
Value Function Loss: 0.04925

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.29942
Value Function Update Magnitude: 0.31867

Collected Steps per Second: 22,262.57592
Overall Steps per Second: 10,660.74974

Timestep Collection Time: 2.24691
Timestep Consumption Time: 2.44526
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.69217

Cumulative Model Updates: 136,702
Cumulative Timesteps: 1,140,868,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1140868198...
Checkpoint 1140868198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,587.81623
Policy Entropy: 1.76101
Value Function Loss: 0.05133

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.28500
Value Function Update Magnitude: 0.32492

Collected Steps per Second: 21,913.72345
Overall Steps per Second: 10,622.08083

Timestep Collection Time: 2.28259
Timestep Consumption Time: 2.42647
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.70906

Cumulative Model Updates: 136,708
Cumulative Timesteps: 1,140,918,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,860.77788
Policy Entropy: 1.77412
Value Function Loss: 0.05236

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.29258
Value Function Update Magnitude: 0.33308

Collected Steps per Second: 22,024.05591
Overall Steps per Second: 10,466.25551

Timestep Collection Time: 2.27143
Timestep Consumption Time: 2.50832
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.77974

Cumulative Model Updates: 136,714
Cumulative Timesteps: 1,140,968,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1140968244...
Checkpoint 1140968244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,534.63177
Policy Entropy: 1.77012
Value Function Loss: 0.04867

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.29152
Value Function Update Magnitude: 0.32862

Collected Steps per Second: 21,684.74921
Overall Steps per Second: 10,394.37124

Timestep Collection Time: 2.30678
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.81241

Cumulative Model Updates: 136,720
Cumulative Timesteps: 1,141,018,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,327.43256
Policy Entropy: 1.78919
Value Function Loss: 0.05381

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.29690
Value Function Update Magnitude: 0.32748

Collected Steps per Second: 22,128.29277
Overall Steps per Second: 10,543.54444

Timestep Collection Time: 2.26018
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.74357

Cumulative Model Updates: 136,726
Cumulative Timesteps: 1,141,068,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1141068280...
Checkpoint 1141068280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,957.38659
Policy Entropy: 1.79154
Value Function Loss: 0.05766

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.31521
Value Function Update Magnitude: 0.34862

Collected Steps per Second: 22,085.61741
Overall Steps per Second: 10,516.26858

Timestep Collection Time: 2.26410
Timestep Consumption Time: 2.49082
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.75492

Cumulative Model Updates: 136,732
Cumulative Timesteps: 1,141,118,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,850.99556
Policy Entropy: 1.80885
Value Function Loss: 0.06007

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.32457
Value Function Update Magnitude: 0.37149

Collected Steps per Second: 22,183.96103
Overall Steps per Second: 10,583.36158

Timestep Collection Time: 2.25514
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.72704

Cumulative Model Updates: 136,738
Cumulative Timesteps: 1,141,168,312

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1141168312...
Checkpoint 1141168312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,624.55584
Policy Entropy: 1.80606
Value Function Loss: 0.05863

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.32130
Value Function Update Magnitude: 0.36177

Collected Steps per Second: 21,596.21612
Overall Steps per Second: 10,428.30972

Timestep Collection Time: 2.31633
Timestep Consumption Time: 2.48061
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.79694

Cumulative Model Updates: 136,744
Cumulative Timesteps: 1,141,218,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,400.81801
Policy Entropy: 1.78454
Value Function Loss: 0.05479

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.31067
Value Function Update Magnitude: 0.32018

Collected Steps per Second: 21,882.47197
Overall Steps per Second: 10,438.97839

Timestep Collection Time: 2.28521
Timestep Consumption Time: 2.50511
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.79032

Cumulative Model Updates: 136,750
Cumulative Timesteps: 1,141,268,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1141268342...
Checkpoint 1141268342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,225.40583
Policy Entropy: 1.78243
Value Function Loss: 0.05346

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.31064
Value Function Update Magnitude: 0.31476

Collected Steps per Second: 20,522.69174
Overall Steps per Second: 10,302.73471

Timestep Collection Time: 2.43837
Timestep Consumption Time: 2.41878
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.85716

Cumulative Model Updates: 136,756
Cumulative Timesteps: 1,141,318,384

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,213.58553
Policy Entropy: 1.77646
Value Function Loss: 0.05378

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.31900
Value Function Update Magnitude: 0.31495

Collected Steps per Second: 21,259.97704
Overall Steps per Second: 10,462.66683

Timestep Collection Time: 2.35315
Timestep Consumption Time: 2.42842
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.78157

Cumulative Model Updates: 136,762
Cumulative Timesteps: 1,141,368,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1141368412...
Checkpoint 1141368412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,711.77566
Policy Entropy: 1.79162
Value Function Loss: 0.06220

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.33076
Value Function Update Magnitude: 0.34470

Collected Steps per Second: 21,062.57947
Overall Steps per Second: 10,580.40834

Timestep Collection Time: 2.37511
Timestep Consumption Time: 2.35306
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.72817

Cumulative Model Updates: 136,768
Cumulative Timesteps: 1,141,418,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,814.01439
Policy Entropy: 1.78195
Value Function Loss: 0.06148

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.33159
Value Function Update Magnitude: 0.35910

Collected Steps per Second: 21,425.53560
Overall Steps per Second: 10,412.19995

Timestep Collection Time: 2.33497
Timestep Consumption Time: 2.46978
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.80475

Cumulative Model Updates: 136,774
Cumulative Timesteps: 1,141,468,466

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1141468466...
Checkpoint 1141468466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,921.75898
Policy Entropy: 1.76489
Value Function Loss: 0.05896

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.32430
Value Function Update Magnitude: 0.34430

Collected Steps per Second: 21,167.97621
Overall Steps per Second: 10,575.85208

Timestep Collection Time: 2.36253
Timestep Consumption Time: 2.36617
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.72870

Cumulative Model Updates: 136,780
Cumulative Timesteps: 1,141,518,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,729.23520
Policy Entropy: 1.74613
Value Function Loss: 0.05087

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07906
Policy Update Magnitude: 0.31536
Value Function Update Magnitude: 0.34829

Collected Steps per Second: 21,587.65566
Overall Steps per Second: 10,475.80063

Timestep Collection Time: 2.31679
Timestep Consumption Time: 2.45745
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.77424

Cumulative Model Updates: 136,786
Cumulative Timesteps: 1,141,568,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1141568490...
Checkpoint 1141568490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,766.03895
Policy Entropy: 1.75612
Value Function Loss: 0.05533

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.31483
Value Function Update Magnitude: 0.30060

Collected Steps per Second: 21,641.04353
Overall Steps per Second: 10,579.69853

Timestep Collection Time: 2.31135
Timestep Consumption Time: 2.41657
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.72792

Cumulative Model Updates: 136,792
Cumulative Timesteps: 1,141,618,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,372.30844
Policy Entropy: 1.76301
Value Function Loss: 0.06119

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.32672
Value Function Update Magnitude: 0.28162

Collected Steps per Second: 22,043.63538
Overall Steps per Second: 10,506.14807

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.49189
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.76102

Cumulative Model Updates: 136,798
Cumulative Timesteps: 1,141,668,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1141668530...
Checkpoint 1141668530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,529.13495
Policy Entropy: 1.75570
Value Function Loss: 0.05993

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.32202
Value Function Update Magnitude: 0.34040

Collected Steps per Second: 21,764.96027
Overall Steps per Second: 10,620.32645

Timestep Collection Time: 2.29874
Timestep Consumption Time: 2.41223
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.71097

Cumulative Model Updates: 136,804
Cumulative Timesteps: 1,141,718,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,158.22215
Policy Entropy: 1.74268
Value Function Loss: 0.05670

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.32104
Value Function Update Magnitude: 0.35999

Collected Steps per Second: 21,913.64471
Overall Steps per Second: 10,485.40041

Timestep Collection Time: 2.28232
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.76987

Cumulative Model Updates: 136,810
Cumulative Timesteps: 1,141,768,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1141768576...
Checkpoint 1141768576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,593.08499
Policy Entropy: 1.75230
Value Function Loss: 0.05270

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07634
Policy Update Magnitude: 0.31765
Value Function Update Magnitude: 0.33602

Collected Steps per Second: 20,511.99878
Overall Steps per Second: 10,259.46757

Timestep Collection Time: 2.43887
Timestep Consumption Time: 2.43722
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.87608

Cumulative Model Updates: 136,816
Cumulative Timesteps: 1,141,818,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,630.85294
Policy Entropy: 1.75092
Value Function Loss: 0.05496

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.31586
Value Function Update Magnitude: 0.30890

Collected Steps per Second: 21,726.88882
Overall Steps per Second: 10,412.41604

Timestep Collection Time: 2.30166
Timestep Consumption Time: 2.50106
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.80273

Cumulative Model Updates: 136,822
Cumulative Timesteps: 1,141,868,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1141868610...
Checkpoint 1141868610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,353.03299
Policy Entropy: 1.73444
Value Function Loss: 0.05265

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.31413
Value Function Update Magnitude: 0.29799

Collected Steps per Second: 21,348.18555
Overall Steps per Second: 10,336.50964

Timestep Collection Time: 2.34287
Timestep Consumption Time: 2.49590
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.83877

Cumulative Model Updates: 136,828
Cumulative Timesteps: 1,141,918,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,888.12873
Policy Entropy: 1.73485
Value Function Loss: 0.05149

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.31013
Value Function Update Magnitude: 0.29895

Collected Steps per Second: 21,757.12020
Overall Steps per Second: 10,379.68796

Timestep Collection Time: 2.29865
Timestep Consumption Time: 2.51961
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.81826

Cumulative Model Updates: 136,834
Cumulative Timesteps: 1,141,968,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1141968638...
Checkpoint 1141968638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,024.91491
Policy Entropy: 1.73142
Value Function Loss: 0.05059

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.31185
Value Function Update Magnitude: 0.30856

Collected Steps per Second: 21,776.27619
Overall Steps per Second: 10,541.95676

Timestep Collection Time: 2.29718
Timestep Consumption Time: 2.44805
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.74523

Cumulative Model Updates: 136,840
Cumulative Timesteps: 1,142,018,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,581.70932
Policy Entropy: 1.75609
Value Function Loss: 0.04684

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.30171
Value Function Update Magnitude: 0.32417

Collected Steps per Second: 22,140.11783
Overall Steps per Second: 10,467.60157

Timestep Collection Time: 2.25889
Timestep Consumption Time: 2.51890
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.77779

Cumulative Model Updates: 136,846
Cumulative Timesteps: 1,142,068,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1142068674...
Checkpoint 1142068674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,271.73181
Policy Entropy: 1.74618
Value Function Loss: 0.04892

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.28700
Value Function Update Magnitude: 0.33284

Collected Steps per Second: 21,884.61747
Overall Steps per Second: 10,564.44074

Timestep Collection Time: 2.28471
Timestep Consumption Time: 2.44815
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.73286

Cumulative Model Updates: 136,852
Cumulative Timesteps: 1,142,118,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,627.94665
Policy Entropy: 1.73721
Value Function Loss: 0.04651

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.28515
Value Function Update Magnitude: 0.33063

Collected Steps per Second: 21,962.32631
Overall Steps per Second: 10,474.35852

Timestep Collection Time: 2.27808
Timestep Consumption Time: 2.49853
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.77662

Cumulative Model Updates: 136,858
Cumulative Timesteps: 1,142,168,706

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1142168706...
Checkpoint 1142168706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,683.25490
Policy Entropy: 1.73722
Value Function Loss: 0.04832

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.29298
Value Function Update Magnitude: 0.30139

Collected Steps per Second: 21,901.51798
Overall Steps per Second: 10,592.57157

Timestep Collection Time: 2.28304
Timestep Consumption Time: 2.43744
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.72048

Cumulative Model Updates: 136,864
Cumulative Timesteps: 1,142,218,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,397.14678
Policy Entropy: 1.72332
Value Function Loss: 0.04894

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.28571
Value Function Update Magnitude: 0.28720

Collected Steps per Second: 21,095.73334
Overall Steps per Second: 10,284.14123

Timestep Collection Time: 2.37147
Timestep Consumption Time: 2.49310
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.86458

Cumulative Model Updates: 136,870
Cumulative Timesteps: 1,142,268,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1142268736...
Checkpoint 1142268736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,556.56329
Policy Entropy: 1.73220
Value Function Loss: 0.05213

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.29001
Value Function Update Magnitude: 0.31766

Collected Steps per Second: 21,599.98145
Overall Steps per Second: 10,544.01916

Timestep Collection Time: 2.31611
Timestep Consumption Time: 2.42857
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.74468

Cumulative Model Updates: 136,876
Cumulative Timesteps: 1,142,318,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,451.57265
Policy Entropy: 1.72831
Value Function Loss: 0.04914

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.28957
Value Function Update Magnitude: 0.33043

Collected Steps per Second: 21,690.12093
Overall Steps per Second: 10,395.90568

Timestep Collection Time: 2.30612
Timestep Consumption Time: 2.50539
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.81151

Cumulative Model Updates: 136,882
Cumulative Timesteps: 1,142,368,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1142368784...
Checkpoint 1142368784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,871.85229
Policy Entropy: 1.74761
Value Function Loss: 0.05475

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.30482
Value Function Update Magnitude: 0.32094

Collected Steps per Second: 21,553.77634
Overall Steps per Second: 10,519.61192

Timestep Collection Time: 2.32089
Timestep Consumption Time: 2.43442
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.75531

Cumulative Model Updates: 136,888
Cumulative Timesteps: 1,142,418,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,693.97085
Policy Entropy: 1.73819
Value Function Loss: 0.05195

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.31529
Value Function Update Magnitude: 0.32851

Collected Steps per Second: 21,280.20730
Overall Steps per Second: 10,587.65215

Timestep Collection Time: 2.35120
Timestep Consumption Time: 2.37449
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.72569

Cumulative Model Updates: 136,894
Cumulative Timesteps: 1,142,468,842

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1142468842...
Checkpoint 1142468842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,975.03071
Policy Entropy: 1.73645
Value Function Loss: 0.05354

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.31439
Value Function Update Magnitude: 0.33224

Collected Steps per Second: 21,417.48201
Overall Steps per Second: 10,579.33136

Timestep Collection Time: 2.33492
Timestep Consumption Time: 2.39204
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.72695

Cumulative Model Updates: 136,900
Cumulative Timesteps: 1,142,518,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,983.36619
Policy Entropy: 1.71679
Value Function Loss: 0.05143

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.31589
Value Function Update Magnitude: 0.33973

Collected Steps per Second: 21,361.31148
Overall Steps per Second: 10,457.26021

Timestep Collection Time: 2.34152
Timestep Consumption Time: 2.44157
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.78309

Cumulative Model Updates: 136,906
Cumulative Timesteps: 1,142,568,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1142568868...
Checkpoint 1142568868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,605.08396
Policy Entropy: 1.71405
Value Function Loss: 0.04902

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.31532
Value Function Update Magnitude: 0.32432

Collected Steps per Second: 21,491.02171
Overall Steps per Second: 10,568.69482

Timestep Collection Time: 2.32693
Timestep Consumption Time: 2.40478
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.73171

Cumulative Model Updates: 136,912
Cumulative Timesteps: 1,142,618,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,771.06236
Policy Entropy: 1.70899
Value Function Loss: 0.05340

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.31579
Value Function Update Magnitude: 0.31006

Collected Steps per Second: 21,907.41654
Overall Steps per Second: 10,527.72429

Timestep Collection Time: 2.28233
Timestep Consumption Time: 2.46703
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.74936

Cumulative Model Updates: 136,918
Cumulative Timesteps: 1,142,668,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1142668876...
Checkpoint 1142668876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,434.36053
Policy Entropy: 1.72683
Value Function Loss: 0.05444

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.31826
Value Function Update Magnitude: 0.33167

Collected Steps per Second: 21,972.14803
Overall Steps per Second: 10,681.82999

Timestep Collection Time: 2.27752
Timestep Consumption Time: 2.40726
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.68478

Cumulative Model Updates: 136,924
Cumulative Timesteps: 1,142,718,918

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,997.77621
Policy Entropy: 1.73656
Value Function Loss: 0.05584

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.31849
Value Function Update Magnitude: 0.34083

Collected Steps per Second: 21,753.22945
Overall Steps per Second: 10,461.76539

Timestep Collection Time: 2.30081
Timestep Consumption Time: 2.48328
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.78409

Cumulative Model Updates: 136,930
Cumulative Timesteps: 1,142,768,968

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1142768968...
Checkpoint 1142768968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,263.36018
Policy Entropy: 1.73599
Value Function Loss: 0.05434

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.31313
Value Function Update Magnitude: 0.33988

Collected Steps per Second: 21,589.64429
Overall Steps per Second: 10,562.21861

Timestep Collection Time: 2.31657
Timestep Consumption Time: 2.41861
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.73518

Cumulative Model Updates: 136,936
Cumulative Timesteps: 1,142,818,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,984.74447
Policy Entropy: 1.71439
Value Function Loss: 0.05401

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.32297

Collected Steps per Second: 21,823.61713
Overall Steps per Second: 10,495.01465

Timestep Collection Time: 2.29128
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.76455

Cumulative Model Updates: 136,942
Cumulative Timesteps: 1,142,868,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1142868986...
Checkpoint 1142868986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,301.97913
Policy Entropy: 1.73397
Value Function Loss: 0.05586

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08214
Policy Update Magnitude: 0.31581
Value Function Update Magnitude: 0.32277

Collected Steps per Second: 21,245.62625
Overall Steps per Second: 10,265.28954

Timestep Collection Time: 2.35427
Timestep Consumption Time: 2.51826
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.87254

Cumulative Model Updates: 136,948
Cumulative Timesteps: 1,142,919,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,435.69457
Policy Entropy: 1.75405
Value Function Loss: 0.05438

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.31918
Value Function Update Magnitude: 0.34235

Collected Steps per Second: 22,161.92582
Overall Steps per Second: 10,411.23547

Timestep Collection Time: 2.25648
Timestep Consumption Time: 2.54679
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.80327

Cumulative Model Updates: 136,954
Cumulative Timesteps: 1,142,969,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1142969012...
Checkpoint 1142969012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,809.30703
Policy Entropy: 1.76388
Value Function Loss: 0.05053

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.31264
Value Function Update Magnitude: 0.32942

Collected Steps per Second: 22,055.16252
Overall Steps per Second: 10,637.42473

Timestep Collection Time: 2.26713
Timestep Consumption Time: 2.43344
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.70057

Cumulative Model Updates: 136,960
Cumulative Timesteps: 1,143,019,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,956.38888
Policy Entropy: 1.75912
Value Function Loss: 0.05489

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07712
Policy Update Magnitude: 0.31528
Value Function Update Magnitude: 0.27680

Collected Steps per Second: 22,195.68521
Overall Steps per Second: 10,515.05098

Timestep Collection Time: 2.25287
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.75547

Cumulative Model Updates: 136,966
Cumulative Timesteps: 1,143,069,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1143069018...
Checkpoint 1143069018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,939.70953
Policy Entropy: 1.74912
Value Function Loss: 0.05644

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.31944
Value Function Update Magnitude: 0.27119

Collected Steps per Second: 22,010.39024
Overall Steps per Second: 10,514.36514

Timestep Collection Time: 2.27302
Timestep Consumption Time: 2.48523
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.75825

Cumulative Model Updates: 136,972
Cumulative Timesteps: 1,143,119,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,620.33912
Policy Entropy: 1.75918
Value Function Loss: 0.05915

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.30736
Value Function Update Magnitude: 0.28997

Collected Steps per Second: 22,105.53741
Overall Steps per Second: 10,484.20495

Timestep Collection Time: 2.26296
Timestep Consumption Time: 2.50841
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.77137

Cumulative Model Updates: 136,978
Cumulative Timesteps: 1,143,169,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1143169072...
Checkpoint 1143169072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,331.37996
Policy Entropy: 1.76469
Value Function Loss: 0.05615

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.28387
Value Function Update Magnitude: 0.31545

Collected Steps per Second: 21,665.79543
Overall Steps per Second: 10,548.31950

Timestep Collection Time: 2.30935
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.74331

Cumulative Model Updates: 136,984
Cumulative Timesteps: 1,143,219,106

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,923.03504
Policy Entropy: 1.76681
Value Function Loss: 0.05974

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.29966
Value Function Update Magnitude: 0.35186

Collected Steps per Second: 21,635.35671
Overall Steps per Second: 10,548.26232

Timestep Collection Time: 2.31233
Timestep Consumption Time: 2.43045
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.74277

Cumulative Model Updates: 136,990
Cumulative Timesteps: 1,143,269,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1143269134...
Checkpoint 1143269134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,680.60144
Policy Entropy: 1.77911
Value Function Loss: 0.06054

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.31088
Value Function Update Magnitude: 0.35017

Collected Steps per Second: 21,777.18193
Overall Steps per Second: 10,594.31511

Timestep Collection Time: 2.29672
Timestep Consumption Time: 2.42431
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.72102

Cumulative Model Updates: 136,996
Cumulative Timesteps: 1,143,319,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,036.68803
Policy Entropy: 1.78229
Value Function Loss: 0.05981

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.31425
Value Function Update Magnitude: 0.34146

Collected Steps per Second: 21,669.15108
Overall Steps per Second: 10,559.82038

Timestep Collection Time: 2.30826
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.73663

Cumulative Model Updates: 137,002
Cumulative Timesteps: 1,143,369,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1143369168...
Checkpoint 1143369168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,016.74827
Policy Entropy: 1.79370
Value Function Loss: 0.05890

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.29684
Value Function Update Magnitude: 0.33802

Collected Steps per Second: 21,725.59286
Overall Steps per Second: 10,516.40363

Timestep Collection Time: 2.30309
Timestep Consumption Time: 2.45481
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.75790

Cumulative Model Updates: 137,008
Cumulative Timesteps: 1,143,419,204

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,574.12812
Policy Entropy: 1.78246
Value Function Loss: 0.05908

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.30188
Value Function Update Magnitude: 0.35677

Collected Steps per Second: 21,562.15917
Overall Steps per Second: 10,482.06613

Timestep Collection Time: 2.32101
Timestep Consumption Time: 2.45343
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.77444

Cumulative Model Updates: 137,014
Cumulative Timesteps: 1,143,469,250

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1143469250...
Checkpoint 1143469250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,534.30916
Policy Entropy: 1.77067
Value Function Loss: 0.05639

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.31509
Value Function Update Magnitude: 0.37922

Collected Steps per Second: 21,449.42149
Overall Steps per Second: 10,294.91366

Timestep Collection Time: 2.33107
Timestep Consumption Time: 2.52570
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.85677

Cumulative Model Updates: 137,020
Cumulative Timesteps: 1,143,519,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,630.99294
Policy Entropy: 1.73733
Value Function Loss: 0.05170

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.31665
Value Function Update Magnitude: 0.38125

Collected Steps per Second: 22,118.85236
Overall Steps per Second: 10,419.27220

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.53971
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.80149

Cumulative Model Updates: 137,026
Cumulative Timesteps: 1,143,569,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1143569278...
Checkpoint 1143569278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,235.75364
Policy Entropy: 1.74307
Value Function Loss: 0.04999

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.31292
Value Function Update Magnitude: 0.36474

Collected Steps per Second: 21,876.59481
Overall Steps per Second: 10,538.00228

Timestep Collection Time: 2.28573
Timestep Consumption Time: 2.45938
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.74511

Cumulative Model Updates: 137,032
Cumulative Timesteps: 1,143,619,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,052.95453
Policy Entropy: 1.73802
Value Function Loss: 0.05625

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.32206
Value Function Update Magnitude: 0.35813

Collected Steps per Second: 21,818.60065
Overall Steps per Second: 10,505.94188

Timestep Collection Time: 2.29208
Timestep Consumption Time: 2.46808
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.76016

Cumulative Model Updates: 137,038
Cumulative Timesteps: 1,143,669,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1143669292...
Checkpoint 1143669292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,339.14828
Policy Entropy: 1.74440
Value Function Loss: 0.05531

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.32252
Value Function Update Magnitude: 0.36564

Collected Steps per Second: 21,887.10112
Overall Steps per Second: 10,586.72940

Timestep Collection Time: 2.28546
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.72497

Cumulative Model Updates: 137,044
Cumulative Timesteps: 1,143,719,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,125.00143
Policy Entropy: 1.74501
Value Function Loss: 0.05385

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.31844
Value Function Update Magnitude: 0.37331

Collected Steps per Second: 22,028.60565
Overall Steps per Second: 10,481.30365

Timestep Collection Time: 2.27059
Timestep Consumption Time: 2.50152
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.77212

Cumulative Model Updates: 137,050
Cumulative Timesteps: 1,143,769,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1143769332...
Checkpoint 1143769332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,307.01209
Policy Entropy: 1.74967
Value Function Loss: 0.05518

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.31754
Value Function Update Magnitude: 0.36520

Collected Steps per Second: 22,114.28031
Overall Steps per Second: 10,646.22016

Timestep Collection Time: 2.26153
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.69763

Cumulative Model Updates: 137,056
Cumulative Timesteps: 1,143,819,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,416.84203
Policy Entropy: 1.76496
Value Function Loss: 0.05462

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.31823
Value Function Update Magnitude: 0.36854

Collected Steps per Second: 21,830.87421
Overall Steps per Second: 10,483.41413

Timestep Collection Time: 2.29033
Timestep Consumption Time: 2.47910
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.76944

Cumulative Model Updates: 137,062
Cumulative Timesteps: 1,143,869,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1143869344...
Checkpoint 1143869344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,683.81477
Policy Entropy: 1.76597
Value Function Loss: 0.05492

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.31772
Value Function Update Magnitude: 0.36762

Collected Steps per Second: 20,791.87397
Overall Steps per Second: 10,526.44518

Timestep Collection Time: 2.40527
Timestep Consumption Time: 2.34562
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.75089

Cumulative Model Updates: 137,068
Cumulative Timesteps: 1,143,919,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,906.94299
Policy Entropy: 1.77662
Value Function Loss: 0.05573

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.36392

Collected Steps per Second: 21,012.45800
Overall Steps per Second: 10,570.81939

Timestep Collection Time: 2.38030
Timestep Consumption Time: 2.35121
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.73152

Cumulative Model Updates: 137,074
Cumulative Timesteps: 1,143,969,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1143969370...
Checkpoint 1143969370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,927.92921
Policy Entropy: 1.77407
Value Function Loss: 0.05562

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.31705
Value Function Update Magnitude: 0.37197

Collected Steps per Second: 21,292.66679
Overall Steps per Second: 10,612.19813

Timestep Collection Time: 2.34954
Timestep Consumption Time: 2.36466
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.71420

Cumulative Model Updates: 137,080
Cumulative Timesteps: 1,144,019,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,136.62342
Policy Entropy: 1.79626
Value Function Loss: 0.05988

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.32459
Value Function Update Magnitude: 0.37626

Collected Steps per Second: 21,395.96317
Overall Steps per Second: 10,438.72450

Timestep Collection Time: 2.33736
Timestep Consumption Time: 2.45346
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.79082

Cumulative Model Updates: 137,086
Cumulative Timesteps: 1,144,069,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1144069408...
Checkpoint 1144069408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,880.07486
Policy Entropy: 1.77629
Value Function Loss: 0.05956

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.32275
Value Function Update Magnitude: 0.39119

Collected Steps per Second: 21,086.48426
Overall Steps per Second: 10,227.20193

Timestep Collection Time: 2.37214
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.89088

Cumulative Model Updates: 137,092
Cumulative Timesteps: 1,144,119,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,975.22382
Policy Entropy: 1.77431
Value Function Loss: 0.05787

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.32399
Value Function Update Magnitude: 0.41342

Collected Steps per Second: 21,785.76783
Overall Steps per Second: 10,441.38445

Timestep Collection Time: 2.29728
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.79323

Cumulative Model Updates: 137,098
Cumulative Timesteps: 1,144,169,476

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1144169476...
Checkpoint 1144169476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,138.50916
Policy Entropy: 1.74792
Value Function Loss: 0.05393

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.32134
Value Function Update Magnitude: 0.40263

Collected Steps per Second: 21,937.20589
Overall Steps per Second: 10,632.90289

Timestep Collection Time: 2.28142
Timestep Consumption Time: 2.42548
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.70690

Cumulative Model Updates: 137,104
Cumulative Timesteps: 1,144,219,524

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,257.88444
Policy Entropy: 1.76330
Value Function Loss: 0.05293

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.31714
Value Function Update Magnitude: 0.37411

Collected Steps per Second: 21,835.02934
Overall Steps per Second: 10,473.59105

Timestep Collection Time: 2.29118
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.77659

Cumulative Model Updates: 137,110
Cumulative Timesteps: 1,144,269,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1144269552...
Checkpoint 1144269552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,340.52174
Policy Entropy: 1.76042
Value Function Loss: 0.05305

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.31488
Value Function Update Magnitude: 0.36869

Collected Steps per Second: 21,942.21702
Overall Steps per Second: 10,639.37672

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.70065

Cumulative Model Updates: 137,116
Cumulative Timesteps: 1,144,319,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,316.00655
Policy Entropy: 1.76071
Value Function Loss: 0.05040

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.30989
Value Function Update Magnitude: 0.36000

Collected Steps per Second: 22,080.99976
Overall Steps per Second: 10,436.40046

Timestep Collection Time: 2.26448
Timestep Consumption Time: 2.52663
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.79112

Cumulative Model Updates: 137,122
Cumulative Timesteps: 1,144,369,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1144369566...
Checkpoint 1144369566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,569.17021
Policy Entropy: 1.74917
Value Function Loss: 0.05277

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.31362
Value Function Update Magnitude: 0.35699

Collected Steps per Second: 21,268.71731
Overall Steps per Second: 10,275.29007

Timestep Collection Time: 2.35115
Timestep Consumption Time: 2.51547
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.86663

Cumulative Model Updates: 137,128
Cumulative Timesteps: 1,144,419,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,609.72124
Policy Entropy: 1.76977
Value Function Loss: 0.05234

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.31105
Value Function Update Magnitude: 0.36685

Collected Steps per Second: 21,600.24119
Overall Steps per Second: 10,377.44555

Timestep Collection Time: 2.31553
Timestep Consumption Time: 2.50415
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.81968

Cumulative Model Updates: 137,134
Cumulative Timesteps: 1,144,469,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1144469588...
Checkpoint 1144469588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,040.98731
Policy Entropy: 1.77690
Value Function Loss: 0.05349

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.31205
Value Function Update Magnitude: 0.37222

Collected Steps per Second: 21,798.56747
Overall Steps per Second: 10,572.36931

Timestep Collection Time: 2.29465
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.73120

Cumulative Model Updates: 137,140
Cumulative Timesteps: 1,144,519,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,035.84173
Policy Entropy: 1.78183
Value Function Loss: 0.04832

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.31163
Value Function Update Magnitude: 0.35734

Collected Steps per Second: 22,146.88185
Overall Steps per Second: 10,592.48488

Timestep Collection Time: 2.25820
Timestep Consumption Time: 2.46326
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.72146

Cumulative Model Updates: 137,146
Cumulative Timesteps: 1,144,569,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1144569620...
Checkpoint 1144569620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,848.83098
Policy Entropy: 1.76246
Value Function Loss: 0.04740

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.30756
Value Function Update Magnitude: 0.33800

Collected Steps per Second: 22,077.51002
Overall Steps per Second: 10,469.59339

Timestep Collection Time: 2.26611
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.77860

Cumulative Model Updates: 137,152
Cumulative Timesteps: 1,144,619,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,158.85134
Policy Entropy: 1.76007
Value Function Loss: 0.04672

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.30681
Value Function Update Magnitude: 0.34031

Collected Steps per Second: 22,089.37454
Overall Steps per Second: 10,558.16940

Timestep Collection Time: 2.26480
Timestep Consumption Time: 2.47352
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.73832

Cumulative Model Updates: 137,158
Cumulative Timesteps: 1,144,669,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1144669678...
Checkpoint 1144669678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,378.69765
Policy Entropy: 1.75093
Value Function Loss: 0.04728

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.30964
Value Function Update Magnitude: 0.34879

Collected Steps per Second: 21,743.43194
Overall Steps per Second: 10,564.32843

Timestep Collection Time: 2.30000
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.73386

Cumulative Model Updates: 137,164
Cumulative Timesteps: 1,144,719,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,112.81733
Policy Entropy: 1.76563
Value Function Loss: 0.05005

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.30256
Value Function Update Magnitude: 0.34335

Collected Steps per Second: 21,916.55222
Overall Steps per Second: 10,488.24054

Timestep Collection Time: 2.28165
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.76782

Cumulative Model Updates: 137,170
Cumulative Timesteps: 1,144,769,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1144769694...
Checkpoint 1144769694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,181.33300
Policy Entropy: 1.77034
Value Function Loss: 0.05463

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.28681
Value Function Update Magnitude: 0.33880

Collected Steps per Second: 21,970.75879
Overall Steps per Second: 10,612.96607

Timestep Collection Time: 2.27612
Timestep Consumption Time: 2.43586
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.71197

Cumulative Model Updates: 137,176
Cumulative Timesteps: 1,144,819,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,742.12393
Policy Entropy: 1.79182
Value Function Loss: 0.06033

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.30016
Value Function Update Magnitude: 0.34303

Collected Steps per Second: 21,676.21949
Overall Steps per Second: 10,584.47396

Timestep Collection Time: 2.30778
Timestep Consumption Time: 2.41839
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.72617

Cumulative Model Updates: 137,182
Cumulative Timesteps: 1,144,869,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1144869726...
Checkpoint 1144869726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,364.60235
Policy Entropy: 1.78277
Value Function Loss: 0.05673

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07915
Policy Update Magnitude: 0.30894
Value Function Update Magnitude: 0.34890

Collected Steps per Second: 21,586.80544
Overall Steps per Second: 10,510.39780

Timestep Collection Time: 2.31679
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.75834

Cumulative Model Updates: 137,188
Cumulative Timesteps: 1,144,919,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,111.41386
Policy Entropy: 1.78336
Value Function Loss: 0.05466

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.31596
Value Function Update Magnitude: 0.35454

Collected Steps per Second: 21,746.61201
Overall Steps per Second: 10,537.52369

Timestep Collection Time: 2.29985
Timestep Consumption Time: 2.44642
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.74628

Cumulative Model Updates: 137,194
Cumulative Timesteps: 1,144,969,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1144969752...
Checkpoint 1144969752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,549.37847
Policy Entropy: 1.76439
Value Function Loss: 0.05053

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.31320
Value Function Update Magnitude: 0.36268

Collected Steps per Second: 21,315.31987
Overall Steps per Second: 10,302.22029

Timestep Collection Time: 2.34704
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.85604

Cumulative Model Updates: 137,200
Cumulative Timesteps: 1,145,019,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,711.60730
Policy Entropy: 1.76200
Value Function Loss: 0.05345

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.31795
Value Function Update Magnitude: 0.36737

Collected Steps per Second: 22,258.58129
Overall Steps per Second: 10,528.98600

Timestep Collection Time: 2.24758
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.75145

Cumulative Model Updates: 137,206
Cumulative Timesteps: 1,145,069,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1145069808...
Checkpoint 1145069808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,604.49530
Policy Entropy: 1.75136
Value Function Loss: 0.05166

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.31810
Value Function Update Magnitude: 0.36078

Collected Steps per Second: 21,925.55553
Overall Steps per Second: 10,413.74109

Timestep Collection Time: 2.28081
Timestep Consumption Time: 2.52131
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.80212

Cumulative Model Updates: 137,212
Cumulative Timesteps: 1,145,119,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,263.03605
Policy Entropy: 1.75708
Value Function Loss: 0.04882

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.31042
Value Function Update Magnitude: 0.34847

Collected Steps per Second: 22,075.78804
Overall Steps per Second: 10,439.17561

Timestep Collection Time: 2.26520
Timestep Consumption Time: 2.52503
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.79023

Cumulative Model Updates: 137,218
Cumulative Timesteps: 1,145,169,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1145169822...
Checkpoint 1145169822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,241.41773
Policy Entropy: 1.76729
Value Function Loss: 0.05001

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.30556
Value Function Update Magnitude: 0.31884

Collected Steps per Second: 21,754.12182
Overall Steps per Second: 10,569.94496

Timestep Collection Time: 2.30016
Timestep Consumption Time: 2.43383
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.73399

Cumulative Model Updates: 137,224
Cumulative Timesteps: 1,145,219,860

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,059.08551
Policy Entropy: 1.77807
Value Function Loss: 0.05181

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.30913

Collected Steps per Second: 22,272.56303
Overall Steps per Second: 10,584.93895

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.72445

Cumulative Model Updates: 137,230
Cumulative Timesteps: 1,145,269,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1145269868...
Checkpoint 1145269868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,142.07310
Policy Entropy: 1.77392
Value Function Loss: 0.05171

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.31130

Collected Steps per Second: 21,849.75291
Overall Steps per Second: 10,587.90504

Timestep Collection Time: 2.28863
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.72294

Cumulative Model Updates: 137,236
Cumulative Timesteps: 1,145,319,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,729.50578
Policy Entropy: 1.76108
Value Function Loss: 0.05308

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.30780
Value Function Update Magnitude: 0.30764

Collected Steps per Second: 21,815.98659
Overall Steps per Second: 10,448.53395

Timestep Collection Time: 2.29291
Timestep Consumption Time: 2.49456
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.78747

Cumulative Model Updates: 137,242
Cumulative Timesteps: 1,145,369,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1145369896...
Checkpoint 1145369896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,473.53829
Policy Entropy: 1.75147
Value Function Loss: 0.05168

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.31164
Value Function Update Magnitude: 0.30304

Collected Steps per Second: 21,393.77428
Overall Steps per Second: 10,373.70798

Timestep Collection Time: 2.33788
Timestep Consumption Time: 2.48354
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.82142

Cumulative Model Updates: 137,248
Cumulative Timesteps: 1,145,419,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,538.30164
Policy Entropy: 1.75357
Value Function Loss: 0.05288

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.31116
Value Function Update Magnitude: 0.29234

Collected Steps per Second: 21,653.12603
Overall Steps per Second: 10,404.35975

Timestep Collection Time: 2.30969
Timestep Consumption Time: 2.49714
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.80683

Cumulative Model Updates: 137,254
Cumulative Timesteps: 1,145,469,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1145469924...
Checkpoint 1145469924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,794.59102
Policy Entropy: 1.76004
Value Function Loss: 0.05308

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.31054
Value Function Update Magnitude: 0.30574

Collected Steps per Second: 21,206.04403
Overall Steps per Second: 10,456.65859

Timestep Collection Time: 2.35810
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.78222

Cumulative Model Updates: 137,260
Cumulative Timesteps: 1,145,519,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,057.97217
Policy Entropy: 1.78758
Value Function Loss: 0.05689

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.31472
Value Function Update Magnitude: 0.32253

Collected Steps per Second: 21,823.42844
Overall Steps per Second: 10,483.98844

Timestep Collection Time: 2.29148
Timestep Consumption Time: 2.47846
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.76994

Cumulative Model Updates: 137,266
Cumulative Timesteps: 1,145,569,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1145569938...
Checkpoint 1145569938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,459.07192
Policy Entropy: 1.79631
Value Function Loss: 0.05373

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.31078
Value Function Update Magnitude: 0.33352

Collected Steps per Second: 20,903.74478
Overall Steps per Second: 10,398.54403

Timestep Collection Time: 2.39201
Timestep Consumption Time: 2.41655
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.80856

Cumulative Model Updates: 137,272
Cumulative Timesteps: 1,145,619,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,467.14787
Policy Entropy: 1.77754
Value Function Loss: 0.05399

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.30597
Value Function Update Magnitude: 0.32417

Collected Steps per Second: 21,704.95295
Overall Steps per Second: 10,662.29683

Timestep Collection Time: 2.30491
Timestep Consumption Time: 2.38714
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.69205

Cumulative Model Updates: 137,278
Cumulative Timesteps: 1,145,669,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1145669968...
Checkpoint 1145669968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,107.88516
Policy Entropy: 1.76923
Value Function Loss: 0.05416

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.31237
Value Function Update Magnitude: 0.32989

Collected Steps per Second: 21,167.62620
Overall Steps per Second: 10,606.47096

Timestep Collection Time: 2.36295
Timestep Consumption Time: 2.35285
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.71580

Cumulative Model Updates: 137,284
Cumulative Timesteps: 1,145,719,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,849.99628
Policy Entropy: 1.78005
Value Function Loss: 0.06351

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.32200
Value Function Update Magnitude: 0.35240

Collected Steps per Second: 21,367.60355
Overall Steps per Second: 10,551.06303

Timestep Collection Time: 2.33999
Timestep Consumption Time: 2.39887
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.73886

Cumulative Model Updates: 137,290
Cumulative Timesteps: 1,145,769,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1145769986...
Checkpoint 1145769986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,334.77224
Policy Entropy: 1.78117
Value Function Loss: 0.06125

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.30404
Value Function Update Magnitude: 0.36039

Collected Steps per Second: 21,445.86951
Overall Steps per Second: 10,540.01538

Timestep Collection Time: 2.33164
Timestep Consumption Time: 2.41257
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.74421

Cumulative Model Updates: 137,296
Cumulative Timesteps: 1,145,819,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,834.15142
Policy Entropy: 1.77112
Value Function Loss: 0.05717

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.29497
Value Function Update Magnitude: 0.35429

Collected Steps per Second: 22,062.32041
Overall Steps per Second: 10,540.11046

Timestep Collection Time: 2.26631
Timestep Consumption Time: 2.47748
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.74378

Cumulative Model Updates: 137,302
Cumulative Timesteps: 1,145,869,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1145869990...
Checkpoint 1145869990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,240.89044
Policy Entropy: 1.75406
Value Function Loss: 0.05257

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.29266
Value Function Update Magnitude: 0.34012

Collected Steps per Second: 21,646.92114
Overall Steps per Second: 10,616.08631

Timestep Collection Time: 2.30980
Timestep Consumption Time: 2.40004
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.70983

Cumulative Model Updates: 137,308
Cumulative Timesteps: 1,145,919,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,051.90549
Policy Entropy: 1.76229
Value Function Loss: 0.05618

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.28304
Value Function Update Magnitude: 0.34055

Collected Steps per Second: 22,126.76741
Overall Steps per Second: 10,550.42257

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.74066

Cumulative Model Updates: 137,314
Cumulative Timesteps: 1,145,970,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1145970006...
Checkpoint 1145970006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,502.64396
Policy Entropy: 1.75961
Value Function Loss: 0.05489

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.30028
Value Function Update Magnitude: 0.35238

Collected Steps per Second: 20,525.22811
Overall Steps per Second: 10,114.66392

Timestep Collection Time: 2.43788
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.94707

Cumulative Model Updates: 137,320
Cumulative Timesteps: 1,146,020,044

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,055.52861
Policy Entropy: 1.77832
Value Function Loss: 0.05407

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.31017
Value Function Update Magnitude: 0.33438

Collected Steps per Second: 21,888.64594
Overall Steps per Second: 10,502.13063

Timestep Collection Time: 2.28529
Timestep Consumption Time: 2.47774
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.76303

Cumulative Model Updates: 137,326
Cumulative Timesteps: 1,146,070,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1146070066...
Checkpoint 1146070066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,378.64806
Policy Entropy: 1.76924
Value Function Loss: 0.05300

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.30415

Collected Steps per Second: 21,506.60657
Overall Steps per Second: 10,351.74249

Timestep Collection Time: 2.32496
Timestep Consumption Time: 2.50534
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.83030

Cumulative Model Updates: 137,332
Cumulative Timesteps: 1,146,120,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,077.84539
Policy Entropy: 1.74784
Value Function Loss: 0.05617

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.31830
Value Function Update Magnitude: 0.32069

Collected Steps per Second: 21,862.65539
Overall Steps per Second: 10,408.39525

Timestep Collection Time: 2.28700
Timestep Consumption Time: 2.51681
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.80381

Cumulative Model Updates: 137,338
Cumulative Timesteps: 1,146,170,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1146170068...
Checkpoint 1146170068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,288.55220
Policy Entropy: 1.73365
Value Function Loss: 0.05018

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.31705
Value Function Update Magnitude: 0.35672

Collected Steps per Second: 22,077.39628
Overall Steps per Second: 10,493.18362

Timestep Collection Time: 2.26494
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.76538

Cumulative Model Updates: 137,344
Cumulative Timesteps: 1,146,220,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,794.07708
Policy Entropy: 1.74470
Value Function Loss: 0.05000

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.31240
Value Function Update Magnitude: 0.34927

Collected Steps per Second: 22,026.09793
Overall Steps per Second: 10,389.80966

Timestep Collection Time: 2.27003
Timestep Consumption Time: 2.54237
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.81241

Cumulative Model Updates: 137,350
Cumulative Timesteps: 1,146,270,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1146270072...
Checkpoint 1146270072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,907.64699
Policy Entropy: 1.76549
Value Function Loss: 0.04780

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.30756
Value Function Update Magnitude: 0.33944

Collected Steps per Second: 21,663.17560
Overall Steps per Second: 10,430.64979

Timestep Collection Time: 2.30890
Timestep Consumption Time: 2.48640
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.79529

Cumulative Model Updates: 137,356
Cumulative Timesteps: 1,146,320,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,932.33514
Policy Entropy: 1.75036
Value Function Loss: 0.04831

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.30422
Value Function Update Magnitude: 0.32046

Collected Steps per Second: 22,103.75781
Overall Steps per Second: 10,654.35330

Timestep Collection Time: 2.26260
Timestep Consumption Time: 2.43144
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.69404

Cumulative Model Updates: 137,362
Cumulative Timesteps: 1,146,370,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1146370102...
Checkpoint 1146370102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,673.30831
Policy Entropy: 1.75228
Value Function Loss: 0.05192

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07760
Policy Update Magnitude: 0.31259
Value Function Update Magnitude: 0.31690

Collected Steps per Second: 21,817.31814
Overall Steps per Second: 10,603.55051

Timestep Collection Time: 2.29295
Timestep Consumption Time: 2.42490
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.71785

Cumulative Model Updates: 137,368
Cumulative Timesteps: 1,146,420,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,253.70814
Policy Entropy: 1.74859
Value Function Loss: 0.05262

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.32066
Value Function Update Magnitude: 0.30348

Collected Steps per Second: 22,096.54651
Overall Steps per Second: 10,570.97636

Timestep Collection Time: 2.26479
Timestep Consumption Time: 2.46931
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.73409

Cumulative Model Updates: 137,374
Cumulative Timesteps: 1,146,470,172

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1146470172...
Checkpoint 1146470172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,127.38314
Policy Entropy: 1.76750
Value Function Loss: 0.05189

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.29961

Collected Steps per Second: 21,771.10170
Overall Steps per Second: 10,587.59502

Timestep Collection Time: 2.29874
Timestep Consumption Time: 2.42812
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.72685

Cumulative Model Updates: 137,380
Cumulative Timesteps: 1,146,520,218

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,346.07874
Policy Entropy: 1.75823
Value Function Loss: 0.05143

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.30946
Value Function Update Magnitude: 0.31429

Collected Steps per Second: 21,588.91776
Overall Steps per Second: 10,508.12817

Timestep Collection Time: 2.31674
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.75974

Cumulative Model Updates: 137,386
Cumulative Timesteps: 1,146,570,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1146570234...
Checkpoint 1146570234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,167.31596
Policy Entropy: 1.75866
Value Function Loss: 0.04792

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.30430
Value Function Update Magnitude: 0.32669

Collected Steps per Second: 21,441.44282
Overall Steps per Second: 10,371.21168

Timestep Collection Time: 2.33203
Timestep Consumption Time: 2.48920
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.82123

Cumulative Model Updates: 137,392
Cumulative Timesteps: 1,146,620,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,437.38626
Policy Entropy: 1.77184
Value Function Loss: 0.05076

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.29484
Value Function Update Magnitude: 0.33138

Collected Steps per Second: 21,615.67419
Overall Steps per Second: 10,384.67435

Timestep Collection Time: 2.31397
Timestep Consumption Time: 2.50255
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.81652

Cumulative Model Updates: 137,398
Cumulative Timesteps: 1,146,670,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1146670254...
Checkpoint 1146670254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,029.97385
Policy Entropy: 1.77774
Value Function Loss: 0.04880

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.28800
Value Function Update Magnitude: 0.32872

Collected Steps per Second: 21,554.75852
Overall Steps per Second: 10,536.18078

Timestep Collection Time: 2.32181
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.74992

Cumulative Model Updates: 137,404
Cumulative Timesteps: 1,146,720,300

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,318.63849
Policy Entropy: 1.77500
Value Function Loss: 0.04937

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.29636
Value Function Update Magnitude: 0.32180

Collected Steps per Second: 21,107.35257
Overall Steps per Second: 10,423.66625

Timestep Collection Time: 2.36903
Timestep Consumption Time: 2.42813
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.79716

Cumulative Model Updates: 137,410
Cumulative Timesteps: 1,146,770,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1146770304...
Checkpoint 1146770304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,200.14157
Policy Entropy: 1.77036
Value Function Loss: 0.04799

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.29978
Value Function Update Magnitude: 0.31645

Collected Steps per Second: 21,085.10804
Overall Steps per Second: 10,382.84207

Timestep Collection Time: 2.37153
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.81602

Cumulative Model Updates: 137,416
Cumulative Timesteps: 1,146,820,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,786.48271
Policy Entropy: 1.76659
Value Function Loss: 0.05201

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07678
Policy Update Magnitude: 0.30557
Value Function Update Magnitude: 0.31639

Collected Steps per Second: 21,535.77200
Overall Steps per Second: 10,659.59517

Timestep Collection Time: 2.32228
Timestep Consumption Time: 2.36946
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.69174

Cumulative Model Updates: 137,422
Cumulative Timesteps: 1,146,870,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1146870320...
Checkpoint 1146870320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,962.53575
Policy Entropy: 1.75755
Value Function Loss: 0.05400

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.31552
Value Function Update Magnitude: 0.34284

Collected Steps per Second: 21,401.22328
Overall Steps per Second: 10,648.79757

Timestep Collection Time: 2.33818
Timestep Consumption Time: 2.36094
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.69912

Cumulative Model Updates: 137,428
Cumulative Timesteps: 1,146,920,360

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,964.31279
Policy Entropy: 1.74502
Value Function Loss: 0.05622

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.32133
Value Function Update Magnitude: 0.35996

Collected Steps per Second: 21,497.41881
Overall Steps per Second: 10,512.65959

Timestep Collection Time: 2.32633
Timestep Consumption Time: 2.43080
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.75712

Cumulative Model Updates: 137,434
Cumulative Timesteps: 1,146,970,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1146970370...
Checkpoint 1146970370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.27369
Policy Entropy: 1.75351
Value Function Loss: 0.05622

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.32317
Value Function Update Magnitude: 0.38189

Collected Steps per Second: 21,941.17225
Overall Steps per Second: 10,648.39682

Timestep Collection Time: 2.28001
Timestep Consumption Time: 2.41798
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.69798

Cumulative Model Updates: 137,440
Cumulative Timesteps: 1,147,020,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,423.56364
Policy Entropy: 1.77580
Value Function Loss: 0.05456

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.32403
Value Function Update Magnitude: 0.40480

Collected Steps per Second: 22,161.58851
Overall Steps per Second: 10,588.47270

Timestep Collection Time: 2.25760
Timestep Consumption Time: 2.46754
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.72514

Cumulative Model Updates: 137,446
Cumulative Timesteps: 1,147,070,428

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1147070428...
Checkpoint 1147070428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,632.17275
Policy Entropy: 1.77650
Value Function Loss: 0.05311

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.32219
Value Function Update Magnitude: 0.37467

Collected Steps per Second: 21,859.73219
Overall Steps per Second: 10,543.33734

Timestep Collection Time: 2.28768
Timestep Consumption Time: 2.45541
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.74309

Cumulative Model Updates: 137,452
Cumulative Timesteps: 1,147,120,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,798.90260
Policy Entropy: 1.77686
Value Function Loss: 0.05607

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.31910
Value Function Update Magnitude: 0.33574

Collected Steps per Second: 21,487.87098
Overall Steps per Second: 10,417.50184

Timestep Collection Time: 2.32801
Timestep Consumption Time: 2.47391
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.80192

Cumulative Model Updates: 137,458
Cumulative Timesteps: 1,147,170,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1147170460...
Checkpoint 1147170460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,194.98429
Policy Entropy: 1.77308
Value Function Loss: 0.05821

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.32223
Value Function Update Magnitude: 0.34089

Collected Steps per Second: 21,752.46479
Overall Steps per Second: 10,576.58073

Timestep Collection Time: 2.29988
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.73007

Cumulative Model Updates: 137,464
Cumulative Timesteps: 1,147,220,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,517.25763
Policy Entropy: 1.79459
Value Function Loss: 0.05716

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.31178
Value Function Update Magnitude: 0.35555

Collected Steps per Second: 21,373.71402
Overall Steps per Second: 10,477.96863

Timestep Collection Time: 2.33942
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.77211

Cumulative Model Updates: 137,470
Cumulative Timesteps: 1,147,270,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1147270490...
Checkpoint 1147270490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,579.90254
Policy Entropy: 1.78774
Value Function Loss: 0.05348

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.31313
Value Function Update Magnitude: 0.36465

Collected Steps per Second: 21,622.59588
Overall Steps per Second: 10,395.94272

Timestep Collection Time: 2.31471
Timestep Consumption Time: 2.49967
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.81438

Cumulative Model Updates: 137,476
Cumulative Timesteps: 1,147,320,540

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,607.12349
Policy Entropy: 1.77548
Value Function Loss: 0.05077

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.30654
Value Function Update Magnitude: 0.34886

Collected Steps per Second: 21,783.15875
Overall Steps per Second: 10,395.41659

Timestep Collection Time: 2.29719
Timestep Consumption Time: 2.51647
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.81366

Cumulative Model Updates: 137,482
Cumulative Timesteps: 1,147,370,580

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1147370580...
Checkpoint 1147370580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,513.15702
Policy Entropy: 1.77179
Value Function Loss: 0.05956

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.31382
Value Function Update Magnitude: 0.31124

Collected Steps per Second: 21,943.42857
Overall Steps per Second: 10,586.90428

Timestep Collection Time: 2.27922
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.72414

Cumulative Model Updates: 137,488
Cumulative Timesteps: 1,147,420,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,878.62963
Policy Entropy: 1.77579
Value Function Loss: 0.05920

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.31892
Value Function Update Magnitude: 0.25751

Collected Steps per Second: 21,999.53026
Overall Steps per Second: 10,422.58196

Timestep Collection Time: 2.27359
Timestep Consumption Time: 2.52541
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.79900

Cumulative Model Updates: 137,494
Cumulative Timesteps: 1,147,470,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1147470612...
Checkpoint 1147470612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,959.55829
Policy Entropy: 1.77337
Value Function Loss: 0.05987

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.32080
Value Function Update Magnitude: 0.23945

Collected Steps per Second: 21,796.26346
Overall Steps per Second: 10,623.33114

Timestep Collection Time: 2.29480
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.27586
Total Iteration Time: 4.70832

Cumulative Model Updates: 137,500
Cumulative Timesteps: 1,147,520,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,883.89609
Policy Entropy: 1.75790
Value Function Loss: 0.05134

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.31695
Value Function Update Magnitude: 0.28668

Collected Steps per Second: 21,949.22239
Overall Steps per Second: 10,449.11018

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.50852
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.78778

Cumulative Model Updates: 137,506
Cumulative Timesteps: 1,147,570,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1147570658...
Checkpoint 1147570658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,941.06350
Policy Entropy: 1.76495
Value Function Loss: 0.05012

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.31414
Value Function Update Magnitude: 0.30340

Collected Steps per Second: 21,539.16852
Overall Steps per Second: 10,368.97736

Timestep Collection Time: 2.32191
Timestep Consumption Time: 2.50132
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.82323

Cumulative Model Updates: 137,512
Cumulative Timesteps: 1,147,620,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,484.25347
Policy Entropy: 1.77880
Value Function Loss: 0.05324

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.31441
Value Function Update Magnitude: 0.30224

Collected Steps per Second: 22,222.47786
Overall Steps per Second: 10,690.50623

Timestep Collection Time: 2.25141
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.68004

Cumulative Model Updates: 137,518
Cumulative Timesteps: 1,147,670,702

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1147670702...
Checkpoint 1147670702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,247.60241
Policy Entropy: 1.77317
Value Function Loss: 0.04823

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.30814
Value Function Update Magnitude: 0.30418

Collected Steps per Second: 21,806.73088
Overall Steps per Second: 10,460.22525

Timestep Collection Time: 2.29507
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.78460

Cumulative Model Updates: 137,524
Cumulative Timesteps: 1,147,720,750

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,069.87986
Policy Entropy: 1.77624
Value Function Loss: 0.05275

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.30385
Value Function Update Magnitude: 0.30135

Collected Steps per Second: 21,524.35985
Overall Steps per Second: 10,324.70384

Timestep Collection Time: 2.32369
Timestep Consumption Time: 2.52061
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.84430

Cumulative Model Updates: 137,530
Cumulative Timesteps: 1,147,770,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1147770766...
Checkpoint 1147770766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,242.40273
Policy Entropy: 1.77005
Value Function Loss: 0.05182

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.29678
Value Function Update Magnitude: 0.31297

Collected Steps per Second: 21,545.45914
Overall Steps per Second: 10,510.61092

Timestep Collection Time: 2.32132
Timestep Consumption Time: 2.43711
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.75843

Cumulative Model Updates: 137,536
Cumulative Timesteps: 1,147,820,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,884.95732
Policy Entropy: 1.77433
Value Function Loss: 0.05462

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.28284
Value Function Update Magnitude: 0.31849

Collected Steps per Second: 21,417.03577
Overall Steps per Second: 10,486.98889

Timestep Collection Time: 2.33524
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.76915

Cumulative Model Updates: 137,542
Cumulative Timesteps: 1,147,870,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1147870794...
Checkpoint 1147870794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,584.93366
Policy Entropy: 1.76287
Value Function Loss: 0.05089

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08049
Policy Update Magnitude: 0.30195
Value Function Update Magnitude: 0.32595

Collected Steps per Second: 21,335.17822
Overall Steps per Second: 10,317.01722

Timestep Collection Time: 2.34392
Timestep Consumption Time: 2.50322
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.84714

Cumulative Model Updates: 137,548
Cumulative Timesteps: 1,147,920,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,632.92886
Policy Entropy: 1.75789
Value Function Loss: 0.05250

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.31120
Value Function Update Magnitude: 0.32312

Collected Steps per Second: 21,594.52345
Overall Steps per Second: 10,374.08753

Timestep Collection Time: 2.31614
Timestep Consumption Time: 2.50510
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.82124

Cumulative Model Updates: 137,554
Cumulative Timesteps: 1,147,970,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1147970818...
Checkpoint 1147970818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,556.53388
Policy Entropy: 1.76568
Value Function Loss: 0.05480

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.31630
Value Function Update Magnitude: 0.33046

Collected Steps per Second: 21,489.14364
Overall Steps per Second: 10,596.81995

Timestep Collection Time: 2.32890
Timestep Consumption Time: 2.39384
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.72274

Cumulative Model Updates: 137,560
Cumulative Timesteps: 1,148,020,864

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,943.91437
Policy Entropy: 1.78509
Value Function Loss: 0.05798

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.31869
Value Function Update Magnitude: 0.34409

Collected Steps per Second: 21,253.57786
Overall Steps per Second: 10,479.75354

Timestep Collection Time: 2.35367
Timestep Consumption Time: 2.41972
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.77339

Cumulative Model Updates: 137,566
Cumulative Timesteps: 1,148,070,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1148070888...
Checkpoint 1148070888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,084.45380
Policy Entropy: 1.76972
Value Function Loss: 0.05475

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.31633
Value Function Update Magnitude: 0.35096

Collected Steps per Second: 21,250.04993
Overall Steps per Second: 10,602.66007

Timestep Collection Time: 2.35322
Timestep Consumption Time: 2.36315
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.71636

Cumulative Model Updates: 137,572
Cumulative Timesteps: 1,148,120,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,311.33270
Policy Entropy: 1.77648
Value Function Loss: 0.05360

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.31074
Value Function Update Magnitude: 0.33048

Collected Steps per Second: 21,260.95296
Overall Steps per Second: 10,502.16928

Timestep Collection Time: 2.35361
Timestep Consumption Time: 2.41112
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.76473

Cumulative Model Updates: 137,578
Cumulative Timesteps: 1,148,170,934

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1148170934...
Checkpoint 1148170934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,439.94940
Policy Entropy: 1.75190
Value Function Loss: 0.05284

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.31301
Value Function Update Magnitude: 0.30480

Collected Steps per Second: 21,327.01048
Overall Steps per Second: 10,621.06877

Timestep Collection Time: 2.34510
Timestep Consumption Time: 2.36384
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.70894

Cumulative Model Updates: 137,584
Cumulative Timesteps: 1,148,220,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,897.17641
Policy Entropy: 1.75541
Value Function Loss: 0.05229

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.31457
Value Function Update Magnitude: 0.32660

Collected Steps per Second: 21,503.73532
Overall Steps per Second: 10,452.54002

Timestep Collection Time: 2.32611
Timestep Consumption Time: 2.45933
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.78544

Cumulative Model Updates: 137,590
Cumulative Timesteps: 1,148,270,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1148270968...
Checkpoint 1148270968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,810.30971
Policy Entropy: 1.74307
Value Function Loss: 0.05311

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.31969
Value Function Update Magnitude: 0.33578

Collected Steps per Second: 21,913.52603
Overall Steps per Second: 10,653.43480

Timestep Collection Time: 2.28279
Timestep Consumption Time: 2.41278
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.69557

Cumulative Model Updates: 137,596
Cumulative Timesteps: 1,148,320,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,583.88210
Policy Entropy: 1.74177
Value Function Loss: 0.05203

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.30708
Value Function Update Magnitude: 0.35414

Collected Steps per Second: 21,467.60628
Overall Steps per Second: 10,447.72165

Timestep Collection Time: 2.32909
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.78573

Cumulative Model Updates: 137,602
Cumulative Timesteps: 1,148,370,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1148370992...
Checkpoint 1148370992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,711.29150
Policy Entropy: 1.74374
Value Function Loss: 0.05014

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.28842
Value Function Update Magnitude: 0.34064

Collected Steps per Second: 21,368.56651
Overall Steps per Second: 10,547.52052

Timestep Collection Time: 2.34092
Timestep Consumption Time: 2.40162
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.74254

Cumulative Model Updates: 137,608
Cumulative Timesteps: 1,148,421,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,769.45073
Policy Entropy: 1.74763
Value Function Loss: 0.05041

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.28216
Value Function Update Magnitude: 0.32820

Collected Steps per Second: 21,566.75284
Overall Steps per Second: 10,514.61886

Timestep Collection Time: 2.31913
Timestep Consumption Time: 2.43768
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.75681

Cumulative Model Updates: 137,614
Cumulative Timesteps: 1,148,471,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1148471030...
Checkpoint 1148471030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,404.23942
Policy Entropy: 1.75762
Value Function Loss: 0.05215

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.28987
Value Function Update Magnitude: 0.33191

Collected Steps per Second: 21,641.17492
Overall Steps per Second: 10,400.97133

Timestep Collection Time: 2.31152
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.80955

Cumulative Model Updates: 137,620
Cumulative Timesteps: 1,148,521,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,936.42890
Policy Entropy: 1.74452
Value Function Loss: 0.05453

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.28938
Value Function Update Magnitude: 0.34452

Collected Steps per Second: 21,662.93326
Overall Steps per Second: 10,365.42108

Timestep Collection Time: 2.30920
Timestep Consumption Time: 2.51685
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.82605

Cumulative Model Updates: 137,626
Cumulative Timesteps: 1,148,571,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1148571078...
Checkpoint 1148571078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,015.16966
Policy Entropy: 1.73828
Value Function Loss: 0.05303

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.30795
Value Function Update Magnitude: 0.35863

Collected Steps per Second: 22,094.84521
Overall Steps per Second: 10,545.35667

Timestep Collection Time: 2.26406
Timestep Consumption Time: 2.47964
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.74370

Cumulative Model Updates: 137,632
Cumulative Timesteps: 1,148,621,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,530.56880
Policy Entropy: 1.74372
Value Function Loss: 0.05473

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.30168
Value Function Update Magnitude: 0.36447

Collected Steps per Second: 22,244.40307
Overall Steps per Second: 10,521.87127

Timestep Collection Time: 2.24839
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.75334

Cumulative Model Updates: 137,638
Cumulative Timesteps: 1,148,671,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1148671116...
Checkpoint 1148671116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,315.55469
Policy Entropy: 1.75611
Value Function Loss: 0.06106

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.31880
Value Function Update Magnitude: 0.37248

Collected Steps per Second: 21,912.40113
Overall Steps per Second: 10,573.97224

Timestep Collection Time: 2.28254
Timestep Consumption Time: 2.44756
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.73011

Cumulative Model Updates: 137,644
Cumulative Timesteps: 1,148,721,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,585.14491
Policy Entropy: 1.76506
Value Function Loss: 0.05934

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.31767
Value Function Update Magnitude: 0.37440

Collected Steps per Second: 21,168.84087
Overall Steps per Second: 10,367.42219

Timestep Collection Time: 2.36243
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.82376

Cumulative Model Updates: 137,650
Cumulative Timesteps: 1,148,771,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1148771142...
Checkpoint 1148771142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,904.03784
Policy Entropy: 1.75676
Value Function Loss: 0.05622

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.31760
Value Function Update Magnitude: 0.37571

Collected Steps per Second: 21,385.55421
Overall Steps per Second: 10,275.38015

Timestep Collection Time: 2.33868
Timestep Consumption Time: 2.52868
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.86736

Cumulative Model Updates: 137,656
Cumulative Timesteps: 1,148,821,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,332.32672
Policy Entropy: 1.76507
Value Function Loss: 0.05241

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.31691
Value Function Update Magnitude: 0.36016

Collected Steps per Second: 21,282.83254
Overall Steps per Second: 10,409.47349

Timestep Collection Time: 2.35016
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.80505

Cumulative Model Updates: 137,662
Cumulative Timesteps: 1,148,871,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1148871174...
Checkpoint 1148871174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,587.28652
Policy Entropy: 1.76448
Value Function Loss: 0.05221

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.31625
Value Function Update Magnitude: 0.35270

Collected Steps per Second: 21,114.25028
Overall Steps per Second: 10,258.14899

Timestep Collection Time: 2.36921
Timestep Consumption Time: 2.50731
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.87651

Cumulative Model Updates: 137,668
Cumulative Timesteps: 1,148,921,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,527.47791
Policy Entropy: 1.76985
Value Function Loss: 0.05451

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.30739
Value Function Update Magnitude: 0.33685

Collected Steps per Second: 21,309.12522
Overall Steps per Second: 10,398.58729

Timestep Collection Time: 2.34707
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.80969

Cumulative Model Updates: 137,674
Cumulative Timesteps: 1,148,971,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1148971212...
Checkpoint 1148971212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,356.15903
Policy Entropy: 1.76958
Value Function Loss: 0.05523

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.30690
Value Function Update Magnitude: 0.33427

Collected Steps per Second: 20,344.05509
Overall Steps per Second: 10,183.82917

Timestep Collection Time: 2.45841
Timestep Consumption Time: 2.45271
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.91112

Cumulative Model Updates: 137,680
Cumulative Timesteps: 1,149,021,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,461.03631
Policy Entropy: 1.76131
Value Function Loss: 0.05122

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.31183
Value Function Update Magnitude: 0.33295

Collected Steps per Second: 16,652.59139
Overall Steps per Second: 9,029.12041

Timestep Collection Time: 3.00326
Timestep Consumption Time: 2.53571
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 5.53897

Cumulative Model Updates: 137,686
Cumulative Timesteps: 1,149,071,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1149071238...
Checkpoint 1149071238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,664.78009
Policy Entropy: 1.76213
Value Function Loss: 0.04824

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.31346
Value Function Update Magnitude: 0.36315

Collected Steps per Second: 19,833.95961
Overall Steps per Second: 10,189.30070

Timestep Collection Time: 2.52093
Timestep Consumption Time: 2.38618
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.90711

Cumulative Model Updates: 137,692
Cumulative Timesteps: 1,149,121,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,874.56699
Policy Entropy: 1.74575
Value Function Loss: 0.04785

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.31359
Value Function Update Magnitude: 0.37692

Collected Steps per Second: 19,917.24307
Overall Steps per Second: 10,033.83999

Timestep Collection Time: 2.51169
Timestep Consumption Time: 2.47404
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.98573

Cumulative Model Updates: 137,698
Cumulative Timesteps: 1,149,171,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1149171264...
Checkpoint 1149171264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,307.30846
Policy Entropy: 1.76803
Value Function Loss: 0.05054

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.31224
Value Function Update Magnitude: 0.37346

Collected Steps per Second: 20,247.66519
Overall Steps per Second: 10,174.98584

Timestep Collection Time: 2.47080
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.91676

Cumulative Model Updates: 137,704
Cumulative Timesteps: 1,149,221,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,190.30097
Policy Entropy: 1.77181
Value Function Loss: 0.04991

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08013
Policy Update Magnitude: 0.31014
Value Function Update Magnitude: 0.36545

Collected Steps per Second: 12,692.92349
Overall Steps per Second: 7,401.02720

Timestep Collection Time: 3.94078
Timestep Consumption Time: 2.81774
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 6.75852

Cumulative Model Updates: 137,710
Cumulative Timesteps: 1,149,271,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1149271312...
Checkpoint 1149271312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,665.94757
Policy Entropy: 1.76415
Value Function Loss: 0.04942

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.30882
Value Function Update Magnitude: 0.34396

Collected Steps per Second: 9,006.73367
Overall Steps per Second: 6,147.33307

Timestep Collection Time: 5.55229
Timestep Consumption Time: 2.58262
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 8.13491

Cumulative Model Updates: 137,716
Cumulative Timesteps: 1,149,321,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,712.04841
Policy Entropy: 1.75946
Value Function Loss: 0.04936

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.31148
Value Function Update Magnitude: 0.31588

Collected Steps per Second: 20,991.47297
Overall Steps per Second: 10,255.32308

Timestep Collection Time: 2.38421
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.88020

Cumulative Model Updates: 137,722
Cumulative Timesteps: 1,149,371,368

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1149371368...
Checkpoint 1149371368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,181.70109
Policy Entropy: 1.76559
Value Function Loss: 0.05247

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07582
Policy Update Magnitude: 0.31495
Value Function Update Magnitude: 0.32414

Collected Steps per Second: 19,923.07259
Overall Steps per Second: 10,077.29094

Timestep Collection Time: 2.51005
Timestep Consumption Time: 2.45239
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.96244

Cumulative Model Updates: 137,728
Cumulative Timesteps: 1,149,421,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,870.77286
Policy Entropy: 1.76823
Value Function Loss: 0.05407

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.31679
Value Function Update Magnitude: 0.34259

Collected Steps per Second: 21,708.12559
Overall Steps per Second: 10,541.32968

Timestep Collection Time: 2.30476
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.74627

Cumulative Model Updates: 137,734
Cumulative Timesteps: 1,149,471,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1149471408...
Checkpoint 1149471408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,197.63856
Policy Entropy: 1.76483
Value Function Loss: 0.05628

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.31919
Value Function Update Magnitude: 0.35227

Collected Steps per Second: 21,548.00462
Overall Steps per Second: 10,375.24078

Timestep Collection Time: 2.32059
Timestep Consumption Time: 2.49896
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.81955

Cumulative Model Updates: 137,740
Cumulative Timesteps: 1,149,521,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,188.32584
Policy Entropy: 1.75738
Value Function Loss: 0.05427

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07313
Policy Update Magnitude: 0.31944
Value Function Update Magnitude: 0.36543

Collected Steps per Second: 22,125.64539
Overall Steps per Second: 10,439.16141

Timestep Collection Time: 2.26217
Timestep Consumption Time: 2.53247
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.79464

Cumulative Model Updates: 137,746
Cumulative Timesteps: 1,149,571,464

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1149571464...
Checkpoint 1149571464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,016.68100
Policy Entropy: 1.77025
Value Function Loss: 0.05528

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.32092
Value Function Update Magnitude: 0.36525

Collected Steps per Second: 22,011.26795
Overall Steps per Second: 10,444.99918

Timestep Collection Time: 2.27284
Timestep Consumption Time: 2.51682
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.78966

Cumulative Model Updates: 137,752
Cumulative Timesteps: 1,149,621,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,424.50836
Policy Entropy: 1.74807
Value Function Loss: 0.05650

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08060
Policy Update Magnitude: 0.32347
Value Function Update Magnitude: 0.36484

Collected Steps per Second: 21,867.04235
Overall Steps per Second: 10,465.46133

Timestep Collection Time: 2.28746
Timestep Consumption Time: 2.49207
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.77953

Cumulative Model Updates: 137,758
Cumulative Timesteps: 1,149,671,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1149671512...
Checkpoint 1149671512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,827.32273
Policy Entropy: 1.74413
Value Function Loss: 0.05404

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.32487
Value Function Update Magnitude: 0.34655

Collected Steps per Second: 21,477.66139
Overall Steps per Second: 10,388.18508

Timestep Collection Time: 2.32800
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.81316

Cumulative Model Updates: 137,764
Cumulative Timesteps: 1,149,721,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,820.08410
Policy Entropy: 1.74565
Value Function Loss: 0.05405

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.32153
Value Function Update Magnitude: 0.32582

Collected Steps per Second: 21,929.59280
Overall Steps per Second: 10,617.10500

Timestep Collection Time: 2.28039
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.71014

Cumulative Model Updates: 137,770
Cumulative Timesteps: 1,149,771,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1149771520...
Checkpoint 1149771520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,033.57702
Policy Entropy: 1.75681
Value Function Loss: 0.05492

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.32364
Value Function Update Magnitude: 0.32938

Collected Steps per Second: 21,649.05712
Overall Steps per Second: 10,390.76022

Timestep Collection Time: 2.31068
Timestep Consumption Time: 2.50360
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.81428

Cumulative Model Updates: 137,776
Cumulative Timesteps: 1,149,821,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,101.01026
Policy Entropy: 1.76922
Value Function Loss: 0.06191

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.33000
Value Function Update Magnitude: 0.34356

Collected Steps per Second: 21,766.11544
Overall Steps per Second: 10,428.14979

Timestep Collection Time: 2.29798
Timestep Consumption Time: 2.49847
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.79644

Cumulative Model Updates: 137,782
Cumulative Timesteps: 1,149,871,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1149871562...
Checkpoint 1149871562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,942.00121
Policy Entropy: 1.75053
Value Function Loss: 0.05698

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.32705
Value Function Update Magnitude: 0.38013

Collected Steps per Second: 20,675.10093
Overall Steps per Second: 10,484.44705

Timestep Collection Time: 2.41982
Timestep Consumption Time: 2.35201
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.77183

Cumulative Model Updates: 137,788
Cumulative Timesteps: 1,149,921,592

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,359.06796
Policy Entropy: 1.74933
Value Function Loss: 0.05383

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.31515
Value Function Update Magnitude: 0.37832

Collected Steps per Second: 20,562.18433
Overall Steps per Second: 10,439.78099

Timestep Collection Time: 2.43243
Timestep Consumption Time: 2.35848
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.79091

Cumulative Model Updates: 137,794
Cumulative Timesteps: 1,149,971,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1149971608...
Checkpoint 1149971608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,997.00154
Policy Entropy: 1.72318
Value Function Loss: 0.05138

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.30894
Value Function Update Magnitude: 0.36285

Collected Steps per Second: 20,969.97204
Overall Steps per Second: 10,380.91266

Timestep Collection Time: 2.38656
Timestep Consumption Time: 2.43441
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.82096

Cumulative Model Updates: 137,800
Cumulative Timesteps: 1,150,021,654

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,905.26704
Policy Entropy: 1.75449
Value Function Loss: 0.05916

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.31581
Value Function Update Magnitude: 0.34912

Collected Steps per Second: 21,055.52855
Overall Steps per Second: 10,379.25641

Timestep Collection Time: 2.37562
Timestep Consumption Time: 2.44360
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.81923

Cumulative Model Updates: 137,806
Cumulative Timesteps: 1,150,071,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1150071674...
Checkpoint 1150071674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,616.95123
Policy Entropy: 1.75137
Value Function Loss: 0.06000

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.31862
Value Function Update Magnitude: 0.35749

Collected Steps per Second: 21,482.64137
Overall Steps per Second: 10,674.52409

Timestep Collection Time: 2.32960
Timestep Consumption Time: 2.35876
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.68836

Cumulative Model Updates: 137,812
Cumulative Timesteps: 1,150,121,720

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,350.92928
Policy Entropy: 1.75618
Value Function Loss: 0.06059

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.32518
Value Function Update Magnitude: 0.36989

Collected Steps per Second: 21,328.36391
Overall Steps per Second: 10,389.15624

Timestep Collection Time: 2.34458
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.81329

Cumulative Model Updates: 137,818
Cumulative Timesteps: 1,150,171,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1150171726...
Checkpoint 1150171726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,854.37462
Policy Entropy: 1.71912
Value Function Loss: 0.05408

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.32677
Value Function Update Magnitude: 0.35428

Collected Steps per Second: 21,619.28861
Overall Steps per Second: 10,585.20081

Timestep Collection Time: 2.31414
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.72641

Cumulative Model Updates: 137,824
Cumulative Timesteps: 1,150,221,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,954.87501
Policy Entropy: 1.70282
Value Function Loss: 0.05473

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.32457
Value Function Update Magnitude: 0.34997

Collected Steps per Second: 21,909.56460
Overall Steps per Second: 10,532.88082

Timestep Collection Time: 2.28348
Timestep Consumption Time: 2.46641
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.74989

Cumulative Model Updates: 137,830
Cumulative Timesteps: 1,150,271,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1150271786...
Checkpoint 1150271786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,342.80963
Policy Entropy: 1.70771
Value Function Loss: 0.05670

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.32553
Value Function Update Magnitude: 0.35585

Collected Steps per Second: 22,066.52076
Overall Steps per Second: 10,643.57572

Timestep Collection Time: 2.26714
Timestep Consumption Time: 2.43316
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.70030

Cumulative Model Updates: 137,836
Cumulative Timesteps: 1,150,321,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,901.52424
Policy Entropy: 1.71492
Value Function Loss: 0.05794

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.32717
Value Function Update Magnitude: 0.36517

Collected Steps per Second: 21,714.28467
Overall Steps per Second: 10,409.13691

Timestep Collection Time: 2.30282
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.80386

Cumulative Model Updates: 137,842
Cumulative Timesteps: 1,150,371,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1150371818...
Checkpoint 1150371818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,656.37316
Policy Entropy: 1.72817
Value Function Loss: 0.05769

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.32244
Value Function Update Magnitude: 0.36992

Collected Steps per Second: 21,600.09172
Overall Steps per Second: 10,387.51719

Timestep Collection Time: 2.31582
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.81559

Cumulative Model Updates: 137,848
Cumulative Timesteps: 1,150,421,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,091.49382
Policy Entropy: 1.73166
Value Function Loss: 0.05786

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.32452
Value Function Update Magnitude: 0.36405

Collected Steps per Second: 21,604.17986
Overall Steps per Second: 10,374.89541

Timestep Collection Time: 2.31640
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.82357

Cumulative Model Updates: 137,854
Cumulative Timesteps: 1,150,471,884

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1150471884...
Checkpoint 1150471884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,455.86156
Policy Entropy: 1.73511
Value Function Loss: 0.05941

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.33023
Value Function Update Magnitude: 0.35927

Collected Steps per Second: 21,388.56536
Overall Steps per Second: 10,563.89147

Timestep Collection Time: 2.33891
Timestep Consumption Time: 2.39665
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.73557

Cumulative Model Updates: 137,860
Cumulative Timesteps: 1,150,521,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,928.95972
Policy Entropy: 1.74210
Value Function Loss: 0.06215

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 0.33225
Value Function Update Magnitude: 0.36962

Collected Steps per Second: 21,818.99456
Overall Steps per Second: 10,441.69048

Timestep Collection Time: 2.29259
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.79060

Cumulative Model Updates: 137,866
Cumulative Timesteps: 1,150,571,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1150571932...
Checkpoint 1150571932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,226.14598
Policy Entropy: 1.73405
Value Function Loss: 0.05788

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.32915
Value Function Update Magnitude: 0.36493

Collected Steps per Second: 21,519.23547
Overall Steps per Second: 10,344.35121

Timestep Collection Time: 2.32369
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.83394

Cumulative Model Updates: 137,872
Cumulative Timesteps: 1,150,621,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,700.35500
Policy Entropy: 1.73081
Value Function Loss: 0.05662

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.32862
Value Function Update Magnitude: 0.36195

Collected Steps per Second: 22,034.43569
Overall Steps per Second: 10,443.14188

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.52057
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.79147

Cumulative Model Updates: 137,878
Cumulative Timesteps: 1,150,671,974

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1150671974...
Checkpoint 1150671974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,750.69044
Policy Entropy: 1.71385
Value Function Loss: 0.05069

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.32357
Value Function Update Magnitude: 0.35921

Collected Steps per Second: 22,184.21217
Overall Steps per Second: 10,469.45757

Timestep Collection Time: 2.25467
Timestep Consumption Time: 2.52285
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.77752

Cumulative Model Updates: 137,884
Cumulative Timesteps: 1,150,721,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,941.00804
Policy Entropy: 1.70876
Value Function Loss: 0.04792

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.31385
Value Function Update Magnitude: 0.34199

Collected Steps per Second: 21,943.87915
Overall Steps per Second: 10,457.59976

Timestep Collection Time: 2.27918
Timestep Consumption Time: 2.50337
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.78255

Cumulative Model Updates: 137,890
Cumulative Timesteps: 1,150,772,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1150772006...
Checkpoint 1150772006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,610.53564
Policy Entropy: 1.69171
Value Function Loss: 0.04832

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.30835
Value Function Update Magnitude: 0.31485

Collected Steps per Second: 21,844.35658
Overall Steps per Second: 10,589.64352

Timestep Collection Time: 2.28956
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.72292

Cumulative Model Updates: 137,896
Cumulative Timesteps: 1,150,822,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,886.35639
Policy Entropy: 1.70105
Value Function Loss: 0.04956

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.30971
Value Function Update Magnitude: 0.28328

Collected Steps per Second: 22,133.89279
Overall Steps per Second: 10,526.79503

Timestep Collection Time: 2.25952
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.75092

Cumulative Model Updates: 137,902
Cumulative Timesteps: 1,150,872,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1150872032...
Checkpoint 1150872032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,646.91544
Policy Entropy: 1.70132
Value Function Loss: 0.05262

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.30399
Value Function Update Magnitude: 0.29090

Collected Steps per Second: 21,805.31283
Overall Steps per Second: 10,592.56253

Timestep Collection Time: 2.29366
Timestep Consumption Time: 2.42795
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.72161

Cumulative Model Updates: 137,908
Cumulative Timesteps: 1,150,922,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,477.58531
Policy Entropy: 1.69621
Value Function Loss: 0.05109

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.29655
Value Function Update Magnitude: 0.29508

Collected Steps per Second: 22,081.76982
Overall Steps per Second: 10,489.62054

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.50361
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.76910

Cumulative Model Updates: 137,914
Cumulative Timesteps: 1,150,972,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1150972072...
Checkpoint 1150972072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,129.01102
Policy Entropy: 1.69603
Value Function Loss: 0.04948

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.29528
Value Function Update Magnitude: 0.28512

Collected Steps per Second: 21,443.22068
Overall Steps per Second: 10,379.27867

Timestep Collection Time: 2.33230
Timestep Consumption Time: 2.48615
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.81845

Cumulative Model Updates: 137,920
Cumulative Timesteps: 1,151,022,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,581.84564
Policy Entropy: 1.69449
Value Function Loss: 0.05189

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.30761
Value Function Update Magnitude: 0.28928

Collected Steps per Second: 22,030.69274
Overall Steps per Second: 10,528.63115

Timestep Collection Time: 2.26983
Timestep Consumption Time: 2.47969
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.74953

Cumulative Model Updates: 137,926
Cumulative Timesteps: 1,151,072,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1151072090...
Checkpoint 1151072090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,971.10350
Policy Entropy: 1.71019
Value Function Loss: 0.05257

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.31424
Value Function Update Magnitude: 0.29064

Collected Steps per Second: 20,900.90825
Overall Steps per Second: 10,378.75509

Timestep Collection Time: 2.39444
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.82197

Cumulative Model Updates: 137,932
Cumulative Timesteps: 1,151,122,136

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,660.58886
Policy Entropy: 1.70343
Value Function Loss: 0.05383

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.31578
Value Function Update Magnitude: 0.30659

Collected Steps per Second: 21,889.94799
Overall Steps per Second: 10,485.68557

Timestep Collection Time: 2.28534
Timestep Consumption Time: 2.48554
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.77089

Cumulative Model Updates: 137,938
Cumulative Timesteps: 1,151,172,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1151172162...
Checkpoint 1151172162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,219.34670
Policy Entropy: 1.70674
Value Function Loss: 0.05143

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07870
Policy Update Magnitude: 0.31422
Value Function Update Magnitude: 0.32127

Collected Steps per Second: 21,503.53235
Overall Steps per Second: 10,361.95499

Timestep Collection Time: 2.32548
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.82592

Cumulative Model Updates: 137,944
Cumulative Timesteps: 1,151,222,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,554.12919
Policy Entropy: 1.69772
Value Function Loss: 0.05456

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07681
Policy Update Magnitude: 0.31343
Value Function Update Magnitude: 0.34204

Collected Steps per Second: 22,466.30593
Overall Steps per Second: 10,651.73765

Timestep Collection Time: 2.22627
Timestep Consumption Time: 2.46930
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.69557

Cumulative Model Updates: 137,950
Cumulative Timesteps: 1,151,272,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1151272184...
Checkpoint 1151272184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,526.20596
Policy Entropy: 1.69600
Value Function Loss: 0.05591

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.31737
Value Function Update Magnitude: 0.35021

Collected Steps per Second: 21,795.55487
Overall Steps per Second: 10,441.52822

Timestep Collection Time: 2.29561
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.79183

Cumulative Model Updates: 137,956
Cumulative Timesteps: 1,151,322,218

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,952.40859
Policy Entropy: 1.70047
Value Function Loss: 0.05588

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.31879
Value Function Update Magnitude: 0.36353

Collected Steps per Second: 22,337.77875
Overall Steps per Second: 10,687.45465

Timestep Collection Time: 2.23881
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.67932

Cumulative Model Updates: 137,962
Cumulative Timesteps: 1,151,372,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1151372228...
Checkpoint 1151372228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,922.83021
Policy Entropy: 1.70410
Value Function Loss: 0.05664

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.32342
Value Function Update Magnitude: 0.37185

Collected Steps per Second: 21,800.14304
Overall Steps per Second: 10,586.46009

Timestep Collection Time: 2.29457
Timestep Consumption Time: 2.43052
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.72509

Cumulative Model Updates: 137,968
Cumulative Timesteps: 1,151,422,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,244.23832
Policy Entropy: 1.70566
Value Function Loss: 0.05698

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.30885
Value Function Update Magnitude: 0.36296

Collected Steps per Second: 22,177.65493
Overall Steps per Second: 10,531.56269

Timestep Collection Time: 2.25596
Timestep Consumption Time: 2.49471
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.75067

Cumulative Model Updates: 137,974
Cumulative Timesteps: 1,151,472,282

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1151472282...
Checkpoint 1151472282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,158.65690
Policy Entropy: 1.71453
Value Function Loss: 0.05930

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.29331
Value Function Update Magnitude: 0.33238

Collected Steps per Second: 21,877.54584
Overall Steps per Second: 10,605.32261

Timestep Collection Time: 2.28645
Timestep Consumption Time: 2.43023
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.71669

Cumulative Model Updates: 137,980
Cumulative Timesteps: 1,151,522,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,701.93570
Policy Entropy: 1.72807
Value Function Loss: 0.06190

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.31881
Value Function Update Magnitude: 0.32583

Collected Steps per Second: 20,947.59392
Overall Steps per Second: 10,189.73141

Timestep Collection Time: 2.38844
Timestep Consumption Time: 2.52160
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.91004

Cumulative Model Updates: 137,986
Cumulative Timesteps: 1,151,572,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1151572336...
Checkpoint 1151572336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,357.74307
Policy Entropy: 1.72850
Value Function Loss: 0.06081

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.33056
Value Function Update Magnitude: 0.36424

Collected Steps per Second: 21,348.17321
Overall Steps per Second: 10,492.54957

Timestep Collection Time: 2.34259
Timestep Consumption Time: 2.42365
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.76624

Cumulative Model Updates: 137,992
Cumulative Timesteps: 1,151,622,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,952.85268
Policy Entropy: 1.71893
Value Function Loss: 0.05844

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.33014
Value Function Update Magnitude: 0.37938

Collected Steps per Second: 21,708.72128
Overall Steps per Second: 10,568.88768

Timestep Collection Time: 2.30451
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.73352

Cumulative Model Updates: 137,998
Cumulative Timesteps: 1,151,672,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1151672374...
Checkpoint 1151672374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,337.82896
Policy Entropy: 1.69294
Value Function Loss: 0.05898

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.32858
Value Function Update Magnitude: 0.34907

Collected Steps per Second: 21,495.72500
Overall Steps per Second: 10,504.40659

Timestep Collection Time: 2.32716
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.76219

Cumulative Model Updates: 138,004
Cumulative Timesteps: 1,151,722,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,874.90053
Policy Entropy: 1.69341
Value Function Loss: 0.06166

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.32742
Value Function Update Magnitude: 0.34297

Collected Steps per Second: 22,370.44400
Overall Steps per Second: 10,499.31783

Timestep Collection Time: 2.23554
Timestep Consumption Time: 2.52763
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.76317

Cumulative Model Updates: 138,010
Cumulative Timesteps: 1,151,772,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1151772408...
Checkpoint 1151772408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,338.22421
Policy Entropy: 1.69922
Value Function Loss: 0.06661

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.32719
Value Function Update Magnitude: 0.33195

Collected Steps per Second: 21,755.16322
Overall Steps per Second: 10,531.79768

Timestep Collection Time: 2.29950
Timestep Consumption Time: 2.45050
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.75000

Cumulative Model Updates: 138,016
Cumulative Timesteps: 1,151,822,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,006.67220
Policy Entropy: 1.70944
Value Function Loss: 0.06232

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.32101
Value Function Update Magnitude: 0.33364

Collected Steps per Second: 22,091.79077
Overall Steps per Second: 10,660.24401

Timestep Collection Time: 2.26428
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.69239

Cumulative Model Updates: 138,022
Cumulative Timesteps: 1,151,872,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1151872456...
Checkpoint 1151872456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,284.04897
Policy Entropy: 1.69333
Value Function Loss: 0.05739

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.31424
Value Function Update Magnitude: 0.33221

Collected Steps per Second: 21,786.37283
Overall Steps per Second: 10,544.49942

Timestep Collection Time: 2.29630
Timestep Consumption Time: 2.44817
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.74446

Cumulative Model Updates: 138,028
Cumulative Timesteps: 1,151,922,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,498.90265
Policy Entropy: 1.68697
Value Function Loss: 0.05363

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.31845
Value Function Update Magnitude: 0.31907

Collected Steps per Second: 22,078.44658
Overall Steps per Second: 10,476.65536

Timestep Collection Time: 2.26583
Timestep Consumption Time: 2.50917
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.77500

Cumulative Model Updates: 138,034
Cumulative Timesteps: 1,151,972,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1151972510...
Checkpoint 1151972510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,350.81403
Policy Entropy: 1.69305
Value Function Loss: 0.05881

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.32653
Value Function Update Magnitude: 0.33702

Collected Steps per Second: 21,624.31221
Overall Steps per Second: 10,550.67378

Timestep Collection Time: 2.31277
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.74017

Cumulative Model Updates: 138,040
Cumulative Timesteps: 1,152,022,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,083.06509
Policy Entropy: 1.69762
Value Function Loss: 0.05897

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.32803
Value Function Update Magnitude: 0.33959

Collected Steps per Second: 21,730.29328
Overall Steps per Second: 10,598.99397

Timestep Collection Time: 2.30278
Timestep Consumption Time: 2.41843
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.72120

Cumulative Model Updates: 138,046
Cumulative Timesteps: 1,152,072,562

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1152072562...
Checkpoint 1152072562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,769.92871
Policy Entropy: 1.68412
Value Function Loss: 0.06140

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.32521
Value Function Update Magnitude: 0.31095

Collected Steps per Second: 21,238.75353
Overall Steps per Second: 10,305.59110

Timestep Collection Time: 2.35569
Timestep Consumption Time: 2.49915
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.85484

Cumulative Model Updates: 138,052
Cumulative Timesteps: 1,152,122,594

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,883.55113
Policy Entropy: 1.67756
Value Function Loss: 0.06245

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.32990
Value Function Update Magnitude: 0.34334

Collected Steps per Second: 21,698.13072
Overall Steps per Second: 10,402.23082

Timestep Collection Time: 2.30564
Timestep Consumption Time: 2.50372
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.80935

Cumulative Model Updates: 138,058
Cumulative Timesteps: 1,152,172,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1152172622...
Checkpoint 1152172622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,715.11424
Policy Entropy: 1.68819
Value Function Loss: 0.06379

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.33271
Value Function Update Magnitude: 0.35660

Collected Steps per Second: 21,142.82935
Overall Steps per Second: 10,427.33785

Timestep Collection Time: 2.36619
Timestep Consumption Time: 2.43158
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.79777

Cumulative Model Updates: 138,064
Cumulative Timesteps: 1,152,222,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,627.57920
Policy Entropy: 1.70176
Value Function Loss: 0.06292

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.33740
Value Function Update Magnitude: 0.37589

Collected Steps per Second: 21,961.90886
Overall Steps per Second: 10,535.73614

Timestep Collection Time: 2.27676
Timestep Consumption Time: 2.46918
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.74594

Cumulative Model Updates: 138,070
Cumulative Timesteps: 1,152,272,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1152272652...
Checkpoint 1152272652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,015.34730
Policy Entropy: 1.70209
Value Function Loss: 0.05990

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.33382
Value Function Update Magnitude: 0.38581

Collected Steps per Second: 21,741.24492
Overall Steps per Second: 10,561.72907

Timestep Collection Time: 2.29987
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.73426

Cumulative Model Updates: 138,076
Cumulative Timesteps: 1,152,322,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,924.45332
Policy Entropy: 1.70089
Value Function Loss: 0.05880

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.32974
Value Function Update Magnitude: 0.37119

Collected Steps per Second: 22,245.81811
Overall Steps per Second: 10,542.19822

Timestep Collection Time: 2.24860
Timestep Consumption Time: 2.49633
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.74493

Cumulative Model Updates: 138,082
Cumulative Timesteps: 1,152,372,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1152372676...
Checkpoint 1152372676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,497.27427
Policy Entropy: 1.68922
Value Function Loss: 0.05979

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08284
Policy Update Magnitude: 0.32731
Value Function Update Magnitude: 0.36820

Collected Steps per Second: 21,855.41318
Overall Steps per Second: 10,584.16756

Timestep Collection Time: 2.28914
Timestep Consumption Time: 2.43774
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.72687

Cumulative Model Updates: 138,088
Cumulative Timesteps: 1,152,422,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,866.68474
Policy Entropy: 1.67872
Value Function Loss: 0.05865

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.32767
Value Function Update Magnitude: 0.38488

Collected Steps per Second: 22,286.61072
Overall Steps per Second: 10,499.10600

Timestep Collection Time: 2.24395
Timestep Consumption Time: 2.51931
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.76326

Cumulative Model Updates: 138,094
Cumulative Timesteps: 1,152,472,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1152472716...
Checkpoint 1152472716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,942.96259
Policy Entropy: 1.66621
Value Function Loss: 0.05606

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.33016
Value Function Update Magnitude: 0.37845

Collected Steps per Second: 21,351.79929
Overall Steps per Second: 10,623.57685

Timestep Collection Time: 2.34210
Timestep Consumption Time: 2.36517
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.70727

Cumulative Model Updates: 138,100
Cumulative Timesteps: 1,152,522,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,465.78993
Policy Entropy: 1.65938
Value Function Loss: 0.05495

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.32050
Value Function Update Magnitude: 0.35855

Collected Steps per Second: 21,179.95505
Overall Steps per Second: 10,461.97388

Timestep Collection Time: 2.36148
Timestep Consumption Time: 2.41926
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.78074

Cumulative Model Updates: 138,106
Cumulative Timesteps: 1,152,572,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1152572740...
Checkpoint 1152572740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,997.06687
Policy Entropy: 1.66969
Value Function Loss: 0.05465

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.31944
Value Function Update Magnitude: 0.36481

Collected Steps per Second: 20,879.71671
Overall Steps per Second: 10,392.26189

Timestep Collection Time: 2.39687
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.81570

Cumulative Model Updates: 138,112
Cumulative Timesteps: 1,152,622,786

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,606.35835
Policy Entropy: 1.67798
Value Function Loss: 0.05765

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.32656
Value Function Update Magnitude: 0.39418

Collected Steps per Second: 21,175.33077
Overall Steps per Second: 10,299.73811

Timestep Collection Time: 2.36199
Timestep Consumption Time: 2.49405
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.85605

Cumulative Model Updates: 138,118
Cumulative Timesteps: 1,152,672,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1152672802...
Checkpoint 1152672802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,544.14628
Policy Entropy: 1.67654
Value Function Loss: 0.05869

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.32717
Value Function Update Magnitude: 0.37774

Collected Steps per Second: 21,643.01012
Overall Steps per Second: 10,594.90695

Timestep Collection Time: 2.31243
Timestep Consumption Time: 2.41135
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.72378

Cumulative Model Updates: 138,124
Cumulative Timesteps: 1,152,722,850

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,215.25188
Policy Entropy: 1.68706
Value Function Loss: 0.06142

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.32730
Value Function Update Magnitude: 0.34493

Collected Steps per Second: 22,043.60048
Overall Steps per Second: 10,468.69674

Timestep Collection Time: 2.26823
Timestep Consumption Time: 2.50791
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.77614

Cumulative Model Updates: 138,130
Cumulative Timesteps: 1,152,772,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1152772850...
Checkpoint 1152772850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,787.66879
Policy Entropy: 1.68266
Value Function Loss: 0.06130

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.33362
Value Function Update Magnitude: 0.36520

Collected Steps per Second: 22,013.85060
Overall Steps per Second: 10,621.55480

Timestep Collection Time: 2.27248
Timestep Consumption Time: 2.43738
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.70986

Cumulative Model Updates: 138,136
Cumulative Timesteps: 1,152,822,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,342.11431
Policy Entropy: 1.69544
Value Function Loss: 0.06261

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08782
Policy Update Magnitude: 0.33630
Value Function Update Magnitude: 0.38685

Collected Steps per Second: 21,865.30943
Overall Steps per Second: 10,492.81719

Timestep Collection Time: 2.28673
Timestep Consumption Time: 2.47844
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.76516

Cumulative Model Updates: 138,142
Cumulative Timesteps: 1,152,872,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1152872876...
Checkpoint 1152872876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,219.46265
Policy Entropy: 1.68991
Value Function Loss: 0.06145

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.33366
Value Function Update Magnitude: 0.38371

Collected Steps per Second: 21,672.09227
Overall Steps per Second: 10,565.67317

Timestep Collection Time: 2.30758
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.73325

Cumulative Model Updates: 138,148
Cumulative Timesteps: 1,152,922,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,784.07300
Policy Entropy: 1.68386
Value Function Loss: 0.05617

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.32625
Value Function Update Magnitude: 0.35367

Collected Steps per Second: 21,747.54520
Overall Steps per Second: 10,527.70893

Timestep Collection Time: 2.30031
Timestep Consumption Time: 2.45154
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.75184

Cumulative Model Updates: 138,154
Cumulative Timesteps: 1,152,972,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1152972912...
Checkpoint 1152972912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,596.88413
Policy Entropy: 1.68801
Value Function Loss: 0.05587

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08018
Policy Update Magnitude: 0.32328
Value Function Update Magnitude: 0.32548

Collected Steps per Second: 22,062.78191
Overall Steps per Second: 10,592.50737

Timestep Collection Time: 2.26771
Timestep Consumption Time: 2.45563
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.72334

Cumulative Model Updates: 138,160
Cumulative Timesteps: 1,153,022,944

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,262.77570
Policy Entropy: 1.67711
Value Function Loss: 0.05732

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.32773
Value Function Update Magnitude: 0.32157

Collected Steps per Second: 21,595.35735
Overall Steps per Second: 10,540.07130

Timestep Collection Time: 2.31633
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.74589

Cumulative Model Updates: 138,166
Cumulative Timesteps: 1,153,072,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1153072966...
Checkpoint 1153072966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,807.05371
Policy Entropy: 1.67669
Value Function Loss: 0.06005

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.33688
Value Function Update Magnitude: 0.36399

Collected Steps per Second: 21,647.54063
Overall Steps per Second: 10,541.11840

Timestep Collection Time: 2.30973
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.74333

Cumulative Model Updates: 138,172
Cumulative Timesteps: 1,153,122,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,859.22505
Policy Entropy: 1.67389
Value Function Loss: 0.05620

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.32962
Value Function Update Magnitude: 0.38896

Collected Steps per Second: 21,206.25828
Overall Steps per Second: 10,466.58162

Timestep Collection Time: 2.35827
Timestep Consumption Time: 2.41980
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.77806

Cumulative Model Updates: 138,178
Cumulative Timesteps: 1,153,172,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1153172976...
Checkpoint 1153172976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,663.83004
Policy Entropy: 1.68853
Value Function Loss: 0.05833

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.32525
Value Function Update Magnitude: 0.38066

Collected Steps per Second: 21,585.12074
Overall Steps per Second: 10,393.61032

Timestep Collection Time: 2.31808
Timestep Consumption Time: 2.49603
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.81411

Cumulative Model Updates: 138,184
Cumulative Timesteps: 1,153,223,012

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,590.46108
Policy Entropy: 1.70333
Value Function Loss: 0.06212

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.31289
Value Function Update Magnitude: 0.37665

Collected Steps per Second: 21,402.06492
Overall Steps per Second: 10,304.86563

Timestep Collection Time: 2.33819
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.85615

Cumulative Model Updates: 138,190
Cumulative Timesteps: 1,153,273,054

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1153273054...
Checkpoint 1153273054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,475.51233
Policy Entropy: 1.70773
Value Function Loss: 0.05775

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.29299
Value Function Update Magnitude: 0.37549

Collected Steps per Second: 21,643.50660
Overall Steps per Second: 10,548.58307

Timestep Collection Time: 2.31016
Timestep Consumption Time: 2.42981
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.73997

Cumulative Model Updates: 138,196
Cumulative Timesteps: 1,153,323,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,786.51807
Policy Entropy: 1.70735
Value Function Loss: 0.05425

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.29180
Value Function Update Magnitude: 0.35854

Collected Steps per Second: 21,891.50673
Overall Steps per Second: 10,510.18555

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.75824

Cumulative Model Updates: 138,202
Cumulative Timesteps: 1,153,373,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1153373064...
Checkpoint 1153373064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,946.56420
Policy Entropy: 1.69306
Value Function Loss: 0.05578

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.30356
Value Function Update Magnitude: 0.34448

Collected Steps per Second: 21,931.84804
Overall Steps per Second: 10,605.51196

Timestep Collection Time: 2.28025
Timestep Consumption Time: 2.43523
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.71547

Cumulative Model Updates: 138,208
Cumulative Timesteps: 1,153,423,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,661.06070
Policy Entropy: 1.69355
Value Function Loss: 0.05592

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.31670
Value Function Update Magnitude: 0.34205

Collected Steps per Second: 20,926.18854
Overall Steps per Second: 10,240.70193

Timestep Collection Time: 2.39136
Timestep Consumption Time: 2.49522
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.88658

Cumulative Model Updates: 138,214
Cumulative Timesteps: 1,153,473,116

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1153473116...
Checkpoint 1153473116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,368.59775
Policy Entropy: 1.70608
Value Function Loss: 0.05880

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.32015
Value Function Update Magnitude: 0.35089

Collected Steps per Second: 21,670.95628
Overall Steps per Second: 10,498.60217

Timestep Collection Time: 2.30825
Timestep Consumption Time: 2.45638
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.76463

Cumulative Model Updates: 138,220
Cumulative Timesteps: 1,153,523,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,774.37842
Policy Entropy: 1.71308
Value Function Loss: 0.05743

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.32530
Value Function Update Magnitude: 0.35096

Collected Steps per Second: 21,774.76623
Overall Steps per Second: 10,422.75036

Timestep Collection Time: 2.29679
Timestep Consumption Time: 2.50156
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.79835

Cumulative Model Updates: 138,226
Cumulative Timesteps: 1,153,573,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1153573150...
Checkpoint 1153573150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,855.78059
Policy Entropy: 1.70763
Value Function Loss: 0.06311

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.32834
Value Function Update Magnitude: 0.36159

Collected Steps per Second: 21,679.63990
Overall Steps per Second: 10,556.79051

Timestep Collection Time: 2.30742
Timestep Consumption Time: 2.43114
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.73856

Cumulative Model Updates: 138,232
Cumulative Timesteps: 1,153,623,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,159.32972
Policy Entropy: 1.69956
Value Function Loss: 0.06024

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.32707
Value Function Update Magnitude: 0.34973

Collected Steps per Second: 22,140.12766
Overall Steps per Second: 10,629.75249

Timestep Collection Time: 2.25943
Timestep Consumption Time: 2.44661
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.70604

Cumulative Model Updates: 138,238
Cumulative Timesteps: 1,153,673,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1153673198...
Checkpoint 1153673198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,759.98741
Policy Entropy: 1.67610
Value Function Loss: 0.05911

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.31618
Value Function Update Magnitude: 0.33742

Collected Steps per Second: 21,772.75978
Overall Steps per Second: 10,541.89781

Timestep Collection Time: 2.29691
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.74393

Cumulative Model Updates: 138,244
Cumulative Timesteps: 1,153,723,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,989.96882
Policy Entropy: 1.67975
Value Function Loss: 0.05615

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.31130
Value Function Update Magnitude: 0.30915

Collected Steps per Second: 22,044.32795
Overall Steps per Second: 10,460.75238

Timestep Collection Time: 2.26834
Timestep Consumption Time: 2.51181
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.78015

Cumulative Model Updates: 138,250
Cumulative Timesteps: 1,153,773,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1153773212...
Checkpoint 1153773212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,977.23376
Policy Entropy: 1.67865
Value Function Loss: 0.05902

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.31825
Value Function Update Magnitude: 0.31450

Collected Steps per Second: 22,042.10836
Overall Steps per Second: 10,610.60916

Timestep Collection Time: 2.26929
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.71415

Cumulative Model Updates: 138,256
Cumulative Timesteps: 1,153,823,232

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,962.39162
Policy Entropy: 1.67946
Value Function Loss: 0.06232

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.33024
Value Function Update Magnitude: 0.35290

Collected Steps per Second: 22,080.94542
Overall Steps per Second: 10,499.24577

Timestep Collection Time: 2.26476
Timestep Consumption Time: 2.49825
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.76301

Cumulative Model Updates: 138,262
Cumulative Timesteps: 1,153,873,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1153873240...
Checkpoint 1153873240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,047.96695
Policy Entropy: 1.67762
Value Function Loss: 0.06209

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.33099
Value Function Update Magnitude: 0.35777

Collected Steps per Second: 21,768.86709
Overall Steps per Second: 10,576.69074

Timestep Collection Time: 2.29814
Timestep Consumption Time: 2.43188
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.73002

Cumulative Model Updates: 138,268
Cumulative Timesteps: 1,153,923,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,281.19377
Policy Entropy: 1.69107
Value Function Loss: 0.07006

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.33000
Value Function Update Magnitude: 0.33765

Collected Steps per Second: 21,590.25690
Overall Steps per Second: 10,501.48022

Timestep Collection Time: 2.31632
Timestep Consumption Time: 2.44586
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.76219

Cumulative Model Updates: 138,274
Cumulative Timesteps: 1,153,973,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1153973278...
Checkpoint 1153973278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,065.02335
Policy Entropy: 1.71457
Value Function Loss: 0.06753

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.33175
Value Function Update Magnitude: 0.29493

Collected Steps per Second: 21,429.77813
Overall Steps per Second: 10,349.77795

Timestep Collection Time: 2.33339
Timestep Consumption Time: 2.49802
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.83141

Cumulative Model Updates: 138,280
Cumulative Timesteps: 1,154,023,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,299.80644
Policy Entropy: 1.71590
Value Function Loss: 0.06430

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.32846
Value Function Update Magnitude: 0.30906

Collected Steps per Second: 21,452.95463
Overall Steps per Second: 10,392.64700

Timestep Collection Time: 2.33208
Timestep Consumption Time: 2.48190
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.81398

Cumulative Model Updates: 138,286
Cumulative Timesteps: 1,154,073,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1154073312...
Checkpoint 1154073312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,136.19176
Policy Entropy: 1.71736
Value Function Loss: 0.06435

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.32276
Value Function Update Magnitude: 0.33981

Collected Steps per Second: 21,625.40111
Overall Steps per Second: 10,510.22091

Timestep Collection Time: 2.31348
Timestep Consumption Time: 2.44665
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.76013

Cumulative Model Updates: 138,292
Cumulative Timesteps: 1,154,123,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,153.83867
Policy Entropy: 1.70531
Value Function Loss: 0.06560

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.32352
Value Function Update Magnitude: 0.36808

Collected Steps per Second: 21,748.59088
Overall Steps per Second: 10,521.82141

Timestep Collection Time: 2.29928
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.75260

Cumulative Model Updates: 138,298
Cumulative Timesteps: 1,154,173,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1154173348...
Checkpoint 1154173348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,712.26066
Policy Entropy: 1.70279
Value Function Loss: 0.06542

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.32630
Value Function Update Magnitude: 0.38027

Collected Steps per Second: 22,065.71556
Overall Steps per Second: 10,601.71359

Timestep Collection Time: 2.26668
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.71773

Cumulative Model Updates: 138,304
Cumulative Timesteps: 1,154,223,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,991.15715
Policy Entropy: 1.68842
Value Function Loss: 0.05942

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.32508
Value Function Update Magnitude: 0.36266

Collected Steps per Second: 22,013.17682
Overall Steps per Second: 10,470.19142

Timestep Collection Time: 2.27146
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.77565

Cumulative Model Updates: 138,310
Cumulative Timesteps: 1,154,273,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1154273366...
Checkpoint 1154273366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,238.93054
Policy Entropy: 1.68108
Value Function Loss: 0.05993

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.33074
Value Function Update Magnitude: 0.36291

Collected Steps per Second: 21,884.08053
Overall Steps per Second: 10,605.32750

Timestep Collection Time: 2.28531
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.71574

Cumulative Model Updates: 138,316
Cumulative Timesteps: 1,154,323,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,465.92909
Policy Entropy: 1.69546
Value Function Loss: 0.06884

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.33629
Value Function Update Magnitude: 0.36845

Collected Steps per Second: 22,125.32792
Overall Steps per Second: 10,547.63585

Timestep Collection Time: 2.26003
Timestep Consumption Time: 2.48074
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.74078

Cumulative Model Updates: 138,322
Cumulative Timesteps: 1,154,373,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1154373382...
Checkpoint 1154373382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,690.17234
Policy Entropy: 1.70090
Value Function Loss: 0.07236

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.34275
Value Function Update Magnitude: 0.39290

Collected Steps per Second: 21,967.79082
Overall Steps per Second: 10,624.80264

Timestep Collection Time: 2.27661
Timestep Consumption Time: 2.43049
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.70710

Cumulative Model Updates: 138,328
Cumulative Timesteps: 1,154,423,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,000.03803
Policy Entropy: 1.69100
Value Function Loss: 0.06926

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.34038
Value Function Update Magnitude: 0.40141

Collected Steps per Second: 21,849.30971
Overall Steps per Second: 10,406.57627

Timestep Collection Time: 2.29014
Timestep Consumption Time: 2.51816
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.80831

Cumulative Model Updates: 138,334
Cumulative Timesteps: 1,154,473,432

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1154473432...
Checkpoint 1154473432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,881.86525
Policy Entropy: 1.68060
Value Function Loss: 0.06179

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.33020
Value Function Update Magnitude: 0.38049

Collected Steps per Second: 21,244.86914
Overall Steps per Second: 10,303.73439

Timestep Collection Time: 2.35436
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.85436

Cumulative Model Updates: 138,340
Cumulative Timesteps: 1,154,523,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,549.74035
Policy Entropy: 1.68108
Value Function Loss: 0.06450

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.32772
Value Function Update Magnitude: 0.38100

Collected Steps per Second: 21,656.62250
Overall Steps per Second: 10,357.58221

Timestep Collection Time: 2.30932
Timestep Consumption Time: 2.51922
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.82854

Cumulative Model Updates: 138,346
Cumulative Timesteps: 1,154,573,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1154573462...
Checkpoint 1154573462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,412.55062
Policy Entropy: 1.70281
Value Function Loss: 0.06753

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.31270
Value Function Update Magnitude: 0.37951

Collected Steps per Second: 21,620.13944
Overall Steps per Second: 10,539.39456

Timestep Collection Time: 2.31506
Timestep Consumption Time: 2.43398
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.74904

Cumulative Model Updates: 138,352
Cumulative Timesteps: 1,154,623,514

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,158.56222
Policy Entropy: 1.71048
Value Function Loss: 0.06424

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.31648
Value Function Update Magnitude: 0.37103

Collected Steps per Second: 22,185.09728
Overall Steps per Second: 10,616.94888

Timestep Collection Time: 2.25521
Timestep Consumption Time: 2.45726
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.71246

Cumulative Model Updates: 138,358
Cumulative Timesteps: 1,154,673,546

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1154673546...
Checkpoint 1154673546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,862.99422
Policy Entropy: 1.72296
Value Function Loss: 0.06163

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.32658
Value Function Update Magnitude: 0.38375

Collected Steps per Second: 21,951.75492
Overall Steps per Second: 10,582.75425

Timestep Collection Time: 2.27954
Timestep Consumption Time: 2.44890
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.72845

Cumulative Model Updates: 138,364
Cumulative Timesteps: 1,154,723,586

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,504.68795
Policy Entropy: 1.72573
Value Function Loss: 0.06440

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.33037
Value Function Update Magnitude: 0.38603

Collected Steps per Second: 22,104.25235
Overall Steps per Second: 10,560.67248

Timestep Collection Time: 2.26291
Timestep Consumption Time: 2.47353
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.73644

Cumulative Model Updates: 138,370
Cumulative Timesteps: 1,154,773,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1154773606...
Checkpoint 1154773606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,482.07504
Policy Entropy: 1.73861
Value Function Loss: 0.06450

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.32980
Value Function Update Magnitude: 0.36551

Collected Steps per Second: 21,581.75286
Overall Steps per Second: 10,505.34065

Timestep Collection Time: 2.31825
Timestep Consumption Time: 2.44428
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.76253

Cumulative Model Updates: 138,376
Cumulative Timesteps: 1,154,823,638

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,456.43701
Policy Entropy: 1.71746
Value Function Loss: 0.05866

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.32357
Value Function Update Magnitude: 0.33518

Collected Steps per Second: 22,225.93385
Overall Steps per Second: 10,529.71668

Timestep Collection Time: 2.24998
Timestep Consumption Time: 2.49924
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.74923

Cumulative Model Updates: 138,382
Cumulative Timesteps: 1,154,873,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1154873646...
Checkpoint 1154873646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,076.65032
Policy Entropy: 1.69857
Value Function Loss: 0.05652

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.31717
Value Function Update Magnitude: 0.33113

Collected Steps per Second: 21,854.93940
Overall Steps per Second: 10,570.19267

Timestep Collection Time: 2.28827
Timestep Consumption Time: 2.44296
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.73123

Cumulative Model Updates: 138,388
Cumulative Timesteps: 1,154,923,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,123.49575
Policy Entropy: 1.67763
Value Function Loss: 0.05292

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.31494
Value Function Update Magnitude: 0.33486

Collected Steps per Second: 21,951.24713
Overall Steps per Second: 10,462.89066

Timestep Collection Time: 2.27850
Timestep Consumption Time: 2.50182
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.78032

Cumulative Model Updates: 138,394
Cumulative Timesteps: 1,154,973,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1154973672...
Checkpoint 1154973672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,783.22314
Policy Entropy: 1.68325
Value Function Loss: 0.05306

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.31246
Value Function Update Magnitude: 0.34333

Collected Steps per Second: 21,519.62707
Overall Steps per Second: 10,368.79811

Timestep Collection Time: 2.32458
Timestep Consumption Time: 2.49990
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.82447

Cumulative Model Updates: 138,400
Cumulative Timesteps: 1,155,023,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,532.36897
Policy Entropy: 1.68020
Value Function Loss: 0.05142

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07412
Policy Update Magnitude: 0.31504
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 21,575.54061
Overall Steps per Second: 10,361.55463

Timestep Collection Time: 2.31874
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.82823

Cumulative Model Updates: 138,406
Cumulative Timesteps: 1,155,073,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1155073724...
Checkpoint 1155073724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,141.95867
Policy Entropy: 1.68020
Value Function Loss: 0.05502

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.32012
Value Function Update Magnitude: 0.35451

Collected Steps per Second: 21,352.78927
Overall Steps per Second: 10,480.64045

Timestep Collection Time: 2.34255
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.77261

Cumulative Model Updates: 138,412
Cumulative Timesteps: 1,155,123,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,987.32020
Policy Entropy: 1.66457
Value Function Loss: 0.05645

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07857
Policy Update Magnitude: 0.32320
Value Function Update Magnitude: 0.34903

Collected Steps per Second: 22,068.74332
Overall Steps per Second: 10,566.22818

Timestep Collection Time: 2.26701
Timestep Consumption Time: 2.46789
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.73490

Cumulative Model Updates: 138,418
Cumulative Timesteps: 1,155,173,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1155173774...
Checkpoint 1155173774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,132.36854
Policy Entropy: 1.68909
Value Function Loss: 0.05420

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.34251

Collected Steps per Second: 21,928.74871
Overall Steps per Second: 10,572.60066

Timestep Collection Time: 2.28093
Timestep Consumption Time: 2.44998
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.73091

Cumulative Model Updates: 138,424
Cumulative Timesteps: 1,155,223,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,112.19819
Policy Entropy: 1.68758
Value Function Loss: 0.05458

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.31376
Value Function Update Magnitude: 0.34342

Collected Steps per Second: 22,046.81786
Overall Steps per Second: 10,505.81065

Timestep Collection Time: 2.26854
Timestep Consumption Time: 2.49207
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.76060

Cumulative Model Updates: 138,430
Cumulative Timesteps: 1,155,273,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1155273806...
Checkpoint 1155273806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,247.53514
Policy Entropy: 1.70696
Value Function Loss: 0.05719

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.31538
Value Function Update Magnitude: 0.33446

Collected Steps per Second: 21,873.49462
Overall Steps per Second: 10,554.16738

Timestep Collection Time: 2.28825
Timestep Consumption Time: 2.45414
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.74239

Cumulative Model Updates: 138,436
Cumulative Timesteps: 1,155,323,858

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,020.18088
Policy Entropy: 1.69016
Value Function Loss: 0.05522

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.31828
Value Function Update Magnitude: 0.35230

Collected Steps per Second: 22,021.66782
Overall Steps per Second: 10,496.11363

Timestep Collection Time: 2.27158
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.76595

Cumulative Model Updates: 138,442
Cumulative Timesteps: 1,155,373,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1155373882...
Checkpoint 1155373882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,557.81334
Policy Entropy: 1.69364
Value Function Loss: 0.05500

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.31340
Value Function Update Magnitude: 0.36202

Collected Steps per Second: 21,731.73822
Overall Steps per Second: 10,566.05415

Timestep Collection Time: 2.30207
Timestep Consumption Time: 2.43271
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.73479

Cumulative Model Updates: 138,448
Cumulative Timesteps: 1,155,423,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,021.56030
Policy Entropy: 1.69140
Value Function Loss: 0.05036

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07382
Policy Update Magnitude: 0.30827
Value Function Update Magnitude: 0.33067

Collected Steps per Second: 22,076.69812
Overall Steps per Second: 10,554.17212

Timestep Collection Time: 2.26537
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.73860

Cumulative Model Updates: 138,454
Cumulative Timesteps: 1,155,473,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1155473922...
Checkpoint 1155473922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,243.22957
Policy Entropy: 1.69382
Value Function Loss: 0.05189

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07208
Policy Update Magnitude: 0.30357
Value Function Update Magnitude: 0.30633

Collected Steps per Second: 21,584.51767
Overall Steps per Second: 10,575.63581

Timestep Collection Time: 2.31694
Timestep Consumption Time: 2.41186
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.72879

Cumulative Model Updates: 138,460
Cumulative Timesteps: 1,155,523,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,469.38104
Policy Entropy: 1.69869
Value Function Loss: 0.05047

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.30584
Value Function Update Magnitude: 0.30330

Collected Steps per Second: 21,061.82970
Overall Steps per Second: 10,565.59992

Timestep Collection Time: 2.37463
Timestep Consumption Time: 2.35904
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.73366

Cumulative Model Updates: 138,466
Cumulative Timesteps: 1,155,573,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1155573946...
Checkpoint 1155573946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,648.48586
Policy Entropy: 1.69529
Value Function Loss: 0.05264

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07964
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.31961

Collected Steps per Second: 20,652.24301
Overall Steps per Second: 10,335.59191

Timestep Collection Time: 2.42259
Timestep Consumption Time: 2.41815
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.84075

Cumulative Model Updates: 138,472
Cumulative Timesteps: 1,155,623,978

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,021.65647
Policy Entropy: 1.70048
Value Function Loss: 0.05331

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.31109
Value Function Update Magnitude: 0.31435

Collected Steps per Second: 21,159.19554
Overall Steps per Second: 10,628.55762

Timestep Collection Time: 2.36436
Timestep Consumption Time: 2.34258
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.70694

Cumulative Model Updates: 138,478
Cumulative Timesteps: 1,155,674,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1155674006...
Checkpoint 1155674006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,822.80796
Policy Entropy: 1.68916
Value Function Loss: 0.05205

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.30802
Value Function Update Magnitude: 0.31383

Collected Steps per Second: 20,674.64123
Overall Steps per Second: 10,295.53484

Timestep Collection Time: 2.41881
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.85725

Cumulative Model Updates: 138,484
Cumulative Timesteps: 1,155,724,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,298.60782
Policy Entropy: 1.70580
Value Function Loss: 0.05731

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.31257
Value Function Update Magnitude: 0.31617

Collected Steps per Second: 21,586.57065
Overall Steps per Second: 10,493.04383

Timestep Collection Time: 2.31700
Timestep Consumption Time: 2.44959
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.76659

Cumulative Model Updates: 138,490
Cumulative Timesteps: 1,155,774,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1155774030...
Checkpoint 1155774030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,741.05892
Policy Entropy: 1.71490
Value Function Loss: 0.05842

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.32067
Value Function Update Magnitude: 0.33089

Collected Steps per Second: 21,936.61105
Overall Steps per Second: 10,563.13552

Timestep Collection Time: 2.27975
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.73439

Cumulative Model Updates: 138,496
Cumulative Timesteps: 1,155,824,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,407.66221
Policy Entropy: 1.73754
Value Function Loss: 0.05882

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.31755
Value Function Update Magnitude: 0.35629

Collected Steps per Second: 21,961.85551
Overall Steps per Second: 10,484.63398

Timestep Collection Time: 2.27768
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.77098

Cumulative Model Updates: 138,502
Cumulative Timesteps: 1,155,874,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1155874062...
Checkpoint 1155874062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,593.11831
Policy Entropy: 1.72102
Value Function Loss: 0.05208

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.31174
Value Function Update Magnitude: 0.35568

Collected Steps per Second: 21,671.16473
Overall Steps per Second: 10,624.06254

Timestep Collection Time: 2.30740
Timestep Consumption Time: 2.39928
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.70667

Cumulative Model Updates: 138,508
Cumulative Timesteps: 1,155,924,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,577.22991
Policy Entropy: 1.72147
Value Function Loss: 0.05202

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.30866
Value Function Update Magnitude: 0.33852

Collected Steps per Second: 22,333.69071
Overall Steps per Second: 10,541.68338

Timestep Collection Time: 2.23922
Timestep Consumption Time: 2.50481
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.74402

Cumulative Model Updates: 138,514
Cumulative Timesteps: 1,155,974,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1155974076...
Checkpoint 1155974076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,875.85310
Policy Entropy: 1.70855
Value Function Loss: 0.05277

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.30965
Value Function Update Magnitude: 0.33959

Collected Steps per Second: 21,732.34522
Overall Steps per Second: 10,567.92739

Timestep Collection Time: 2.30072
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.73130

Cumulative Model Updates: 138,520
Cumulative Timesteps: 1,156,024,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,443.43345
Policy Entropy: 1.70455
Value Function Loss: 0.05480

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.31147
Value Function Update Magnitude: 0.33046

Collected Steps per Second: 21,813.05225
Overall Steps per Second: 10,454.93403

Timestep Collection Time: 2.29358
Timestep Consumption Time: 2.49172
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.78530

Cumulative Model Updates: 138,526
Cumulative Timesteps: 1,156,074,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1156074106...
Checkpoint 1156074106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,673.14556
Policy Entropy: 1.68503
Value Function Loss: 0.05059

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.31072
Value Function Update Magnitude: 0.31301

Collected Steps per Second: 21,312.31954
Overall Steps per Second: 10,320.43515

Timestep Collection Time: 2.34756
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.84786

Cumulative Model Updates: 138,532
Cumulative Timesteps: 1,156,124,138

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,661.76781
Policy Entropy: 1.68200
Value Function Loss: 0.04971

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08046
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.31206

Collected Steps per Second: 21,558.98781
Overall Steps per Second: 10,343.08943

Timestep Collection Time: 2.32024
Timestep Consumption Time: 2.51603
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.83627

Cumulative Model Updates: 138,538
Cumulative Timesteps: 1,156,174,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1156174160...
Checkpoint 1156174160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,925.60676
Policy Entropy: 1.68112
Value Function Loss: 0.05092

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.30708
Value Function Update Magnitude: 0.31158

Collected Steps per Second: 21,579.81402
Overall Steps per Second: 10,539.18260

Timestep Collection Time: 2.31883
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.74800

Cumulative Model Updates: 138,544
Cumulative Timesteps: 1,156,224,200

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,123.31665
Policy Entropy: 1.69599
Value Function Loss: 0.05366

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.31187
Value Function Update Magnitude: 0.31976

Collected Steps per Second: 22,009.70302
Overall Steps per Second: 10,526.56483

Timestep Collection Time: 2.27418
Timestep Consumption Time: 2.48084
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.75502

Cumulative Model Updates: 138,550
Cumulative Timesteps: 1,156,274,254

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1156274254...
Checkpoint 1156274254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,940.64988
Policy Entropy: 1.70003
Value Function Loss: 0.05367

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.30910
Value Function Update Magnitude: 0.33079

Collected Steps per Second: 21,685.06961
Overall Steps per Second: 10,386.44387

Timestep Collection Time: 2.30638
Timestep Consumption Time: 2.50894
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.81532

Cumulative Model Updates: 138,556
Cumulative Timesteps: 1,156,324,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,705.61117
Policy Entropy: 1.69393
Value Function Loss: 0.05133

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.34501

Collected Steps per Second: 21,932.99153
Overall Steps per Second: 10,512.13081

Timestep Collection Time: 2.28095
Timestep Consumption Time: 2.47813
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.75907

Cumulative Model Updates: 138,562
Cumulative Timesteps: 1,156,374,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1156374296...
Checkpoint 1156374296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,620.44099
Policy Entropy: 1.70186
Value Function Loss: 0.05384

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.31494
Value Function Update Magnitude: 0.33670

Collected Steps per Second: 22,055.84019
Overall Steps per Second: 10,490.11796

Timestep Collection Time: 2.26725
Timestep Consumption Time: 2.49972
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.76696

Cumulative Model Updates: 138,568
Cumulative Timesteps: 1,156,424,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,985.08409
Policy Entropy: 1.69371
Value Function Loss: 0.05451

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.32096
Value Function Update Magnitude: 0.34401

Collected Steps per Second: 22,392.57281
Overall Steps per Second: 10,741.15055

Timestep Collection Time: 2.23395
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.65723

Cumulative Model Updates: 138,574
Cumulative Timesteps: 1,156,474,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1156474326...
Checkpoint 1156474326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,172.16092
Policy Entropy: 1.69086
Value Function Loss: 0.04940

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.31401
Value Function Update Magnitude: 0.32842

Collected Steps per Second: 21,522.23109
Overall Steps per Second: 10,344.17841

Timestep Collection Time: 2.32346
Timestep Consumption Time: 2.51076
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.83422

Cumulative Model Updates: 138,580
Cumulative Timesteps: 1,156,524,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,188.02907
Policy Entropy: 1.67681
Value Function Loss: 0.04891

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.28701

Collected Steps per Second: 22,109.80448
Overall Steps per Second: 10,524.95884

Timestep Collection Time: 2.26180
Timestep Consumption Time: 2.48957
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.75137

Cumulative Model Updates: 138,586
Cumulative Timesteps: 1,156,574,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1156574340...
Checkpoint 1156574340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,255.12144
Policy Entropy: 1.69273
Value Function Loss: 0.05178

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07998
Policy Update Magnitude: 0.31540
Value Function Update Magnitude: 0.29892

Collected Steps per Second: 21,320.51055
Overall Steps per Second: 10,461.65352

Timestep Collection Time: 2.34516
Timestep Consumption Time: 2.43420
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.77936

Cumulative Model Updates: 138,592
Cumulative Timesteps: 1,156,624,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,319.99994
Policy Entropy: 1.70188
Value Function Loss: 0.05672

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.31774
Value Function Update Magnitude: 0.31780

Collected Steps per Second: 21,114.56080
Overall Steps per Second: 10,482.16031

Timestep Collection Time: 2.36936
Timestep Consumption Time: 2.40332
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.77268

Cumulative Model Updates: 138,598
Cumulative Timesteps: 1,156,674,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1156674368...
Checkpoint 1156674368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,356.41228
Policy Entropy: 1.70818
Value Function Loss: 0.06404

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.32229
Value Function Update Magnitude: 0.31495

Collected Steps per Second: 20,687.87109
Overall Steps per Second: 10,326.76547

Timestep Collection Time: 2.41794
Timestep Consumption Time: 2.42598
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.84392

Cumulative Model Updates: 138,604
Cumulative Timesteps: 1,156,724,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,156.81712
Policy Entropy: 1.72720
Value Function Loss: 0.06508

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.32400
Value Function Update Magnitude: 0.31262

Collected Steps per Second: 20,723.06998
Overall Steps per Second: 10,307.11531

Timestep Collection Time: 2.41345
Timestep Consumption Time: 2.43893
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.85238

Cumulative Model Updates: 138,610
Cumulative Timesteps: 1,156,774,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1156774404...
Checkpoint 1156774404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,380.08740
Policy Entropy: 1.73670
Value Function Loss: 0.06493

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.32368
Value Function Update Magnitude: 0.31992

Collected Steps per Second: 20,992.60612
Overall Steps per Second: 10,557.16969

Timestep Collection Time: 2.38208
Timestep Consumption Time: 2.35461
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.73669

Cumulative Model Updates: 138,616
Cumulative Timesteps: 1,156,824,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,444.77212
Policy Entropy: 1.74980
Value Function Loss: 0.06354

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.32105
Value Function Update Magnitude: 0.37393

Collected Steps per Second: 21,646.01156
Overall Steps per Second: 10,552.63665

Timestep Collection Time: 2.31119
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.74081

Cumulative Model Updates: 138,622
Cumulative Timesteps: 1,156,874,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1156874438...
Checkpoint 1156874438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,929.18142
Policy Entropy: 1.73824
Value Function Loss: 0.06282

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.32123
Value Function Update Magnitude: 0.34533

Collected Steps per Second: 21,057.16074
Overall Steps per Second: 10,535.06286

Timestep Collection Time: 2.37525
Timestep Consumption Time: 2.37233
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.74757

Cumulative Model Updates: 138,628
Cumulative Timesteps: 1,156,924,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,930.49784
Policy Entropy: 1.75101
Value Function Loss: 0.06521

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.32431
Value Function Update Magnitude: 0.34261

Collected Steps per Second: 21,176.78358
Overall Steps per Second: 10,578.57198

Timestep Collection Time: 2.36127
Timestep Consumption Time: 2.36565
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.72691

Cumulative Model Updates: 138,634
Cumulative Timesteps: 1,156,974,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1156974458...
Checkpoint 1156974458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,741.85011
Policy Entropy: 1.72907
Value Function Loss: 0.06312

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.32370
Value Function Update Magnitude: 0.28712

Collected Steps per Second: 21,262.27565
Overall Steps per Second: 10,592.69846

Timestep Collection Time: 2.35215
Timestep Consumption Time: 2.36922
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.72137

Cumulative Model Updates: 138,640
Cumulative Timesteps: 1,157,024,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,120.69510
Policy Entropy: 1.73261
Value Function Loss: 0.05976

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.29736

Collected Steps per Second: 21,340.63696
Overall Steps per Second: 10,462.65591

Timestep Collection Time: 2.34360
Timestep Consumption Time: 2.43664
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.78024

Cumulative Model Updates: 138,646
Cumulative Timesteps: 1,157,074,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1157074484...
Checkpoint 1157074484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,316.28778
Policy Entropy: 1.70438
Value Function Loss: 0.05482

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.30376
Value Function Update Magnitude: 0.33559

Collected Steps per Second: 21,519.46728
Overall Steps per Second: 10,587.68465

Timestep Collection Time: 2.32469
Timestep Consumption Time: 2.40024
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.72492

Cumulative Model Updates: 138,652
Cumulative Timesteps: 1,157,124,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,799.35238
Policy Entropy: 1.71569
Value Function Loss: 0.05467

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.30981
Value Function Update Magnitude: 0.35916

Collected Steps per Second: 21,931.51745
Overall Steps per Second: 10,504.74919

Timestep Collection Time: 2.27992
Timestep Consumption Time: 2.48003
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.75994

Cumulative Model Updates: 138,658
Cumulative Timesteps: 1,157,174,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1157174512...
Checkpoint 1157174512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,165.50732
Policy Entropy: 1.70909
Value Function Loss: 0.05629

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.31304
Value Function Update Magnitude: 0.36311

Collected Steps per Second: 20,015.49468
Overall Steps per Second: 10,147.49106

Timestep Collection Time: 2.49866
Timestep Consumption Time: 2.42984
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.92851

Cumulative Model Updates: 138,664
Cumulative Timesteps: 1,157,224,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,850.93078
Policy Entropy: 1.71218
Value Function Loss: 0.05976

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.31399
Value Function Update Magnitude: 0.35103

Collected Steps per Second: 21,509.68575
Overall Steps per Second: 10,578.86420

Timestep Collection Time: 2.32500
Timestep Consumption Time: 2.40235
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.72735

Cumulative Model Updates: 138,670
Cumulative Timesteps: 1,157,274,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1157274534...
Checkpoint 1157274534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,973.70594
Policy Entropy: 1.71023
Value Function Loss: 0.05577

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.31113
Value Function Update Magnitude: 0.34655

Collected Steps per Second: 21,498.20482
Overall Steps per Second: 10,512.25646

Timestep Collection Time: 2.32671
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.75826

Cumulative Model Updates: 138,676
Cumulative Timesteps: 1,157,324,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,110.80426
Policy Entropy: 1.69639
Value Function Loss: 0.05166

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.30994
Value Function Update Magnitude: 0.34215

Collected Steps per Second: 21,466.99823
Overall Steps per Second: 10,487.33397

Timestep Collection Time: 2.33018
Timestep Consumption Time: 2.43957
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.76975

Cumulative Model Updates: 138,682
Cumulative Timesteps: 1,157,374,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1157374576...
Checkpoint 1157374576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,650.39394
Policy Entropy: 1.68793
Value Function Loss: 0.04683

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.30659
Value Function Update Magnitude: 0.32262

Collected Steps per Second: 21,444.80757
Overall Steps per Second: 10,221.64820

Timestep Collection Time: 2.33241
Timestep Consumption Time: 2.56093
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.89334

Cumulative Model Updates: 138,688
Cumulative Timesteps: 1,157,424,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,908.36380
Policy Entropy: 1.69017
Value Function Loss: 0.05160

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.32194

Collected Steps per Second: 22,109.16638
Overall Steps per Second: 10,474.22317

Timestep Collection Time: 2.26250
Timestep Consumption Time: 2.51322
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.77572

Cumulative Model Updates: 138,694
Cumulative Timesteps: 1,157,474,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1157474616...
Checkpoint 1157474616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,032.01307
Policy Entropy: 1.69359
Value Function Loss: 0.05482

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.31814
Value Function Update Magnitude: 0.35271

Collected Steps per Second: 22,133.19670
Overall Steps per Second: 10,652.05145

Timestep Collection Time: 2.25950
Timestep Consumption Time: 2.43537
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.69487

Cumulative Model Updates: 138,700
Cumulative Timesteps: 1,157,524,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,146.41628
Policy Entropy: 1.69681
Value Function Loss: 0.05385

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.31520
Value Function Update Magnitude: 0.36349

Collected Steps per Second: 22,067.07986
Overall Steps per Second: 10,433.54858

Timestep Collection Time: 2.26582
Timestep Consumption Time: 2.52641
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.79223

Cumulative Model Updates: 138,706
Cumulative Timesteps: 1,157,574,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1157574626...
Checkpoint 1157574626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,158.00737
Policy Entropy: 1.70414
Value Function Loss: 0.05418

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.30754
Value Function Update Magnitude: 0.34382

Collected Steps per Second: 21,969.43299
Overall Steps per Second: 10,613.33224

Timestep Collection Time: 2.27662
Timestep Consumption Time: 2.43595
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.71256

Cumulative Model Updates: 138,712
Cumulative Timesteps: 1,157,624,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,502.62840
Policy Entropy: 1.71147
Value Function Loss: 0.05518

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.30777
Value Function Update Magnitude: 0.32749

Collected Steps per Second: 21,928.41291
Overall Steps per Second: 10,471.64382

Timestep Collection Time: 2.28051
Timestep Consumption Time: 2.49505
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.77556

Cumulative Model Updates: 138,718
Cumulative Timesteps: 1,157,674,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1157674650...
Checkpoint 1157674650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,458.93083
Policy Entropy: 1.70095
Value Function Loss: 0.06046

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.31502
Value Function Update Magnitude: 0.31060

Collected Steps per Second: 21,825.63845
Overall Steps per Second: 10,574.21203

Timestep Collection Time: 2.29107
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.72886

Cumulative Model Updates: 138,724
Cumulative Timesteps: 1,157,724,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,043.44815
Policy Entropy: 1.68374
Value Function Loss: 0.05985

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.31859
Value Function Update Magnitude: 0.29500

Collected Steps per Second: 21,731.68536
Overall Steps per Second: 10,575.86033

Timestep Collection Time: 2.30208
Timestep Consumption Time: 2.42832
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.73040

Cumulative Model Updates: 138,730
Cumulative Timesteps: 1,157,774,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1157774682...
Checkpoint 1157774682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,375.17014
Policy Entropy: 1.68871
Value Function Loss: 0.06065

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.32032
Value Function Update Magnitude: 0.25872

Collected Steps per Second: 21,980.02047
Overall Steps per Second: 10,653.84354

Timestep Collection Time: 2.27534
Timestep Consumption Time: 2.41893
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.69427

Cumulative Model Updates: 138,736
Cumulative Timesteps: 1,157,824,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,244.72345
Policy Entropy: 1.70591
Value Function Loss: 0.05498

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.31523
Value Function Update Magnitude: 0.24265

Collected Steps per Second: 21,504.67586
Overall Steps per Second: 10,380.49759

Timestep Collection Time: 2.32712
Timestep Consumption Time: 2.49384
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.82096

Cumulative Model Updates: 138,742
Cumulative Timesteps: 1,157,874,738

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1157874738...
Checkpoint 1157874738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,555.01946
Policy Entropy: 1.70285
Value Function Loss: 0.05563

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.31461
Value Function Update Magnitude: 0.30521

Collected Steps per Second: 21,379.94907
Overall Steps per Second: 10,336.09891

Timestep Collection Time: 2.33883
Timestep Consumption Time: 2.49898
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.83780

Cumulative Model Updates: 138,748
Cumulative Timesteps: 1,157,924,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,936.41316
Policy Entropy: 1.70446
Value Function Loss: 0.05710

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.31684
Value Function Update Magnitude: 0.31571

Collected Steps per Second: 21,379.92407
Overall Steps per Second: 10,293.95519

Timestep Collection Time: 2.33958
Timestep Consumption Time: 2.51958
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.85916

Cumulative Model Updates: 138,754
Cumulative Timesteps: 1,157,974,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1157974762...
Checkpoint 1157974762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,287.31175
Policy Entropy: 1.70740
Value Function Loss: 0.06394

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.32167
Value Function Update Magnitude: 0.29613

Collected Steps per Second: 21,492.69651
Overall Steps per Second: 10,366.34091

Timestep Collection Time: 2.32814
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.82697

Cumulative Model Updates: 138,760
Cumulative Timesteps: 1,158,024,800

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,423.75299
Policy Entropy: 1.70861
Value Function Loss: 0.06288

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.32326
Value Function Update Magnitude: 0.31328

Collected Steps per Second: 21,950.20981
Overall Steps per Second: 10,395.01839

Timestep Collection Time: 2.27934
Timestep Consumption Time: 2.53373
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.81307

Cumulative Model Updates: 138,766
Cumulative Timesteps: 1,158,074,832

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1158074832...
Checkpoint 1158074832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,955.24797
Policy Entropy: 1.67941
Value Function Loss: 0.05841

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.32043
Value Function Update Magnitude: 0.33130

Collected Steps per Second: 21,426.02173
Overall Steps per Second: 10,572.27283

Timestep Collection Time: 2.33445
Timestep Consumption Time: 2.39660
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.73105

Cumulative Model Updates: 138,772
Cumulative Timesteps: 1,158,124,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,095.03317
Policy Entropy: 1.68052
Value Function Loss: 0.05351

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.31816
Value Function Update Magnitude: 0.32480

Collected Steps per Second: 21,155.02979
Overall Steps per Second: 10,431.76986

Timestep Collection Time: 2.36511
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.79631

Cumulative Model Updates: 138,778
Cumulative Timesteps: 1,158,174,884

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1158174884...
Checkpoint 1158174884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,541.98436
Policy Entropy: 1.67789
Value Function Loss: 0.05333

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.31838
Value Function Update Magnitude: 0.33048

Collected Steps per Second: 21,288.38653
Overall Steps per Second: 10,610.60705

Timestep Collection Time: 2.35001
Timestep Consumption Time: 2.36489
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.71490

Cumulative Model Updates: 138,784
Cumulative Timesteps: 1,158,224,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,276.54505
Policy Entropy: 1.70045
Value Function Loss: 0.05439

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.30799
Value Function Update Magnitude: 0.30832

Collected Steps per Second: 21,310.56526
Overall Steps per Second: 10,494.77473

Timestep Collection Time: 2.34747
Timestep Consumption Time: 2.41928
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.76675

Cumulative Model Updates: 138,790
Cumulative Timesteps: 1,158,274,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1158274938...
Checkpoint 1158274938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,028.09966
Policy Entropy: 1.67901
Value Function Loss: 0.05453

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.29856
Value Function Update Magnitude: 0.30885

Collected Steps per Second: 21,603.86189
Overall Steps per Second: 10,611.84783

Timestep Collection Time: 2.31486
Timestep Consumption Time: 2.39779
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.71266

Cumulative Model Updates: 138,796
Cumulative Timesteps: 1,158,324,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,195.64813
Policy Entropy: 1.69334
Value Function Loss: 0.05570

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.30568
Value Function Update Magnitude: 0.32406

Collected Steps per Second: 21,857.20212
Overall Steps per Second: 10,487.09738

Timestep Collection Time: 2.28767
Timestep Consumption Time: 2.48029
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.76795

Cumulative Model Updates: 138,802
Cumulative Timesteps: 1,158,374,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1158374950...
Checkpoint 1158374950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,101.72780
Policy Entropy: 1.69082
Value Function Loss: 0.05566

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.31339
Value Function Update Magnitude: 0.32694

Collected Steps per Second: 21,610.67753
Overall Steps per Second: 10,581.70395

Timestep Collection Time: 2.31506
Timestep Consumption Time: 2.41291
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.72797

Cumulative Model Updates: 138,808
Cumulative Timesteps: 1,158,424,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,540.02284
Policy Entropy: 1.70947
Value Function Loss: 0.05317

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.31178
Value Function Update Magnitude: 0.33601

Collected Steps per Second: 21,536.93109
Overall Steps per Second: 10,559.18265

Timestep Collection Time: 2.32169
Timestep Consumption Time: 2.41372
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.73540

Cumulative Model Updates: 138,814
Cumulative Timesteps: 1,158,474,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1158474982...
Checkpoint 1158474982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,021.24506
Policy Entropy: 1.71193
Value Function Loss: 0.05273

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.30811
Value Function Update Magnitude: 0.30638

Collected Steps per Second: 21,522.63179
Overall Steps per Second: 10,355.15393

Timestep Collection Time: 2.32509
Timestep Consumption Time: 2.50748
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.83257

Cumulative Model Updates: 138,820
Cumulative Timesteps: 1,158,525,024

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,442.48350
Policy Entropy: 1.70271
Value Function Loss: 0.05813

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.27979

Collected Steps per Second: 21,884.77229
Overall Steps per Second: 10,404.50353

Timestep Collection Time: 2.28497
Timestep Consumption Time: 2.52122
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.80619

Cumulative Model Updates: 138,826
Cumulative Timesteps: 1,158,575,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1158575030...
Checkpoint 1158575030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,670.59698
Policy Entropy: 1.69191
Value Function Loss: 0.05797

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07691
Policy Update Magnitude: 0.31918
Value Function Update Magnitude: 0.32248

Collected Steps per Second: 22,095.09246
Overall Steps per Second: 10,453.08573

Timestep Collection Time: 2.26421
Timestep Consumption Time: 2.52174
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.78596

Cumulative Model Updates: 138,832
Cumulative Timesteps: 1,158,625,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,760.88388
Policy Entropy: 1.68572
Value Function Loss: 0.05736

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.31989
Value Function Update Magnitude: 0.34763

Collected Steps per Second: 22,076.08661
Overall Steps per Second: 10,473.31203

Timestep Collection Time: 2.26652
Timestep Consumption Time: 2.51095
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.77748

Cumulative Model Updates: 138,838
Cumulative Timesteps: 1,158,675,094

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1158675094...
Checkpoint 1158675094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,408.52783
Policy Entropy: 1.68682
Value Function Loss: 0.05462

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.32057
Value Function Update Magnitude: 0.34751

Collected Steps per Second: 22,095.93631
Overall Steps per Second: 10,652.03331

Timestep Collection Time: 2.26395
Timestep Consumption Time: 2.43225
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.69619

Cumulative Model Updates: 138,844
Cumulative Timesteps: 1,158,725,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,721.70894
Policy Entropy: 1.66924
Value Function Loss: 0.05289

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.31359
Value Function Update Magnitude: 0.32873

Collected Steps per Second: 22,223.41480
Overall Steps per Second: 10,493.20387

Timestep Collection Time: 2.25096
Timestep Consumption Time: 2.51632
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.76728

Cumulative Model Updates: 138,850
Cumulative Timesteps: 1,158,775,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1158775142...
Checkpoint 1158775142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,019.53762
Policy Entropy: 1.66282
Value Function Loss: 0.04859

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.30371
Value Function Update Magnitude: 0.32168

Collected Steps per Second: 21,795.75961
Overall Steps per Second: 10,583.43380

Timestep Collection Time: 2.29402
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.72436

Cumulative Model Updates: 138,856
Cumulative Timesteps: 1,158,825,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,283.74970
Policy Entropy: 1.66648
Value Function Loss: 0.04796

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.30104
Value Function Update Magnitude: 0.30584

Collected Steps per Second: 22,117.97441
Overall Steps per Second: 10,471.91705

Timestep Collection Time: 2.26232
Timestep Consumption Time: 2.51598
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.77830

Cumulative Model Updates: 138,862
Cumulative Timesteps: 1,158,875,180

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1158875180...
Checkpoint 1158875180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,597.28018
Policy Entropy: 1.67000
Value Function Loss: 0.05183

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.30818
Value Function Update Magnitude: 0.30624

Collected Steps per Second: 21,722.65276
Overall Steps per Second: 10,575.44269

Timestep Collection Time: 2.30193
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.72831

Cumulative Model Updates: 138,868
Cumulative Timesteps: 1,158,925,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,499.28502
Policy Entropy: 1.67357
Value Function Loss: 0.05631

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.30563
Value Function Update Magnitude: 0.32627

Collected Steps per Second: 21,499.15247
Overall Steps per Second: 10,489.17016

Timestep Collection Time: 2.32577
Timestep Consumption Time: 2.44125
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.76701

Cumulative Model Updates: 138,874
Cumulative Timesteps: 1,158,975,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1158975186...
Checkpoint 1158975186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,378.20345
Policy Entropy: 1.66199
Value Function Loss: 0.05822

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.29051
Value Function Update Magnitude: 0.35637

Collected Steps per Second: 21,262.99467
Overall Steps per Second: 10,290.57595

Timestep Collection Time: 2.35197
Timestep Consumption Time: 2.50781
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.85979

Cumulative Model Updates: 138,880
Cumulative Timesteps: 1,159,025,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,392.07250
Policy Entropy: 1.67333
Value Function Loss: 0.05290

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.29452
Value Function Update Magnitude: 0.35035

Collected Steps per Second: 21,613.02314
Overall Steps per Second: 10,405.90820

Timestep Collection Time: 2.31518
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.80861

Cumulative Model Updates: 138,886
Cumulative Timesteps: 1,159,075,234

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1159075234...
Checkpoint 1159075234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,904.53232
Policy Entropy: 1.68644
Value Function Loss: 0.05444

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08256
Policy Update Magnitude: 0.30514
Value Function Update Magnitude: 0.33329

Collected Steps per Second: 21,087.27074
Overall Steps per Second: 10,264.10999

Timestep Collection Time: 2.37328
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.87582

Cumulative Model Updates: 138,892
Cumulative Timesteps: 1,159,125,280

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,563.41602
Policy Entropy: 1.71650
Value Function Loss: 0.05541

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.30524
Value Function Update Magnitude: 0.33181

Collected Steps per Second: 21,628.71760
Overall Steps per Second: 10,408.64970

Timestep Collection Time: 2.31239
Timestep Consumption Time: 2.49265
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.80504

Cumulative Model Updates: 138,898
Cumulative Timesteps: 1,159,175,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1159175294...
Checkpoint 1159175294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,725.37014
Policy Entropy: 1.73063
Value Function Loss: 0.06044

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.29987
Value Function Update Magnitude: 0.31444

Collected Steps per Second: 21,552.41120
Overall Steps per Second: 10,351.04994

Timestep Collection Time: 2.32123
Timestep Consumption Time: 2.51191
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.83313

Cumulative Model Updates: 138,904
Cumulative Timesteps: 1,159,225,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,228.02964
Policy Entropy: 1.71557
Value Function Loss: 0.06180

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.30444
Value Function Update Magnitude: 0.29975

Collected Steps per Second: 22,493.87856
Overall Steps per Second: 10,716.75489

Timestep Collection Time: 2.22300
Timestep Consumption Time: 2.44296
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.66596

Cumulative Model Updates: 138,910
Cumulative Timesteps: 1,159,275,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1159275326...
Checkpoint 1159275326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,163.83625
Policy Entropy: 1.69799
Value Function Loss: 0.06123

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.30558
Value Function Update Magnitude: 0.32379

Collected Steps per Second: 21,128.90049
Overall Steps per Second: 10,589.72719

Timestep Collection Time: 2.36681
Timestep Consumption Time: 2.35551
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.72231

Cumulative Model Updates: 138,916
Cumulative Timesteps: 1,159,325,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,312.32721
Policy Entropy: 1.68512
Value Function Loss: 0.06141

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.31621
Value Function Update Magnitude: 0.33849

Collected Steps per Second: 21,633.54177
Overall Steps per Second: 10,541.90741

Timestep Collection Time: 2.31178
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.74411

Cumulative Model Updates: 138,922
Cumulative Timesteps: 1,159,375,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1159375346...
Checkpoint 1159375346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,980.59665
Policy Entropy: 1.71089
Value Function Loss: 0.06448

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.32142
Value Function Update Magnitude: 0.34870

Collected Steps per Second: 21,407.50150
Overall Steps per Second: 10,672.60381

Timestep Collection Time: 2.33684
Timestep Consumption Time: 2.35048
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.68733

Cumulative Model Updates: 138,928
Cumulative Timesteps: 1,159,425,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,263.78946
Policy Entropy: 1.70848
Value Function Loss: 0.06382

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.32260
Value Function Update Magnitude: 0.35354

Collected Steps per Second: 21,500.10263
Overall Steps per Second: 10,509.27301

Timestep Collection Time: 2.32641
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.75942

Cumulative Model Updates: 138,934
Cumulative Timesteps: 1,159,475,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1159475390...
Checkpoint 1159475390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,255.81358
Policy Entropy: 1.71437
Value Function Loss: 0.06197

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.31883
Value Function Update Magnitude: 0.35405

Collected Steps per Second: 21,364.60907
Overall Steps per Second: 10,540.46018

Timestep Collection Time: 2.34051
Timestep Consumption Time: 2.40350
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.74401

Cumulative Model Updates: 138,940
Cumulative Timesteps: 1,159,525,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,725.22532
Policy Entropy: 1.70305
Value Function Loss: 0.05720

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.31844
Value Function Update Magnitude: 0.35089

Collected Steps per Second: 21,075.91208
Overall Steps per Second: 10,437.33101

Timestep Collection Time: 2.37371
Timestep Consumption Time: 2.41947
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.79318

Cumulative Model Updates: 138,946
Cumulative Timesteps: 1,159,575,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1159575422...
Checkpoint 1159575422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,370.10434
Policy Entropy: 1.70714
Value Function Loss: 0.05825

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.31632
Value Function Update Magnitude: 0.34303

Collected Steps per Second: 20,901.22311
Overall Steps per Second: 10,229.23053

Timestep Collection Time: 2.39383
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.89128

Cumulative Model Updates: 138,952
Cumulative Timesteps: 1,159,625,456

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,695.19382
Policy Entropy: 1.70636
Value Function Loss: 0.05616

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.30787
Value Function Update Magnitude: 0.32652

Collected Steps per Second: 21,782.21997
Overall Steps per Second: 10,481.16021

Timestep Collection Time: 2.29573
Timestep Consumption Time: 2.47531
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.77104

Cumulative Model Updates: 138,958
Cumulative Timesteps: 1,159,675,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1159675462...
Checkpoint 1159675462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,943.18805
Policy Entropy: 1.69799
Value Function Loss: 0.05757

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07760
Policy Update Magnitude: 0.30673
Value Function Update Magnitude: 0.31039

Collected Steps per Second: 21,414.61204
Overall Steps per Second: 10,542.95391

Timestep Collection Time: 2.33560
Timestep Consumption Time: 2.40842
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.74402

Cumulative Model Updates: 138,964
Cumulative Timesteps: 1,159,725,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,610.30652
Policy Entropy: 1.67334
Value Function Loss: 0.05458

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.30777
Value Function Update Magnitude: 0.28977

Collected Steps per Second: 21,974.83768
Overall Steps per Second: 10,488.15534

Timestep Collection Time: 2.27697
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.77071

Cumulative Model Updates: 138,970
Cumulative Timesteps: 1,159,775,514

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1159775514...
Checkpoint 1159775514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,193.98845
Policy Entropy: 1.67392
Value Function Loss: 0.05783

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.30824
Value Function Update Magnitude: 0.28237

Collected Steps per Second: 21,550.08227
Overall Steps per Second: 10,557.17289

Timestep Collection Time: 2.32073
Timestep Consumption Time: 2.41652
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.73725

Cumulative Model Updates: 138,976
Cumulative Timesteps: 1,159,825,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,733.87175
Policy Entropy: 1.68425
Value Function Loss: 0.05737

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07815
Policy Update Magnitude: 0.31231
Value Function Update Magnitude: 0.33047

Collected Steps per Second: 22,033.42041
Overall Steps per Second: 10,543.44748

Timestep Collection Time: 2.27019
Timestep Consumption Time: 2.47399
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.74418

Cumulative Model Updates: 138,982
Cumulative Timesteps: 1,159,875,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1159875546...
Checkpoint 1159875546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,833.04478
Policy Entropy: 1.69227
Value Function Loss: 0.05721

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.31597
Value Function Update Magnitude: 0.35603

Collected Steps per Second: 22,078.41530
Overall Steps per Second: 10,665.53519

Timestep Collection Time: 2.26656
Timestep Consumption Time: 2.42538
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.69194

Cumulative Model Updates: 138,988
Cumulative Timesteps: 1,159,925,588

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,085.41392
Policy Entropy: 1.68509
Value Function Loss: 0.05933

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07773
Policy Update Magnitude: 0.31994
Value Function Update Magnitude: 0.35661

Collected Steps per Second: 22,204.89604
Overall Steps per Second: 10,575.38996

Timestep Collection Time: 2.25401
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.73269

Cumulative Model Updates: 138,994
Cumulative Timesteps: 1,159,975,638

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1159975638...
Checkpoint 1159975638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,060.29091
Policy Entropy: 1.66089
Value Function Loss: 0.05752

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.32002
Value Function Update Magnitude: 0.35780

Collected Steps per Second: 21,861.86039
Overall Steps per Second: 10,450.85290

Timestep Collection Time: 2.28745
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.78506

Cumulative Model Updates: 139,000
Cumulative Timesteps: 1,160,025,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,892.95250
Policy Entropy: 1.67520
Value Function Loss: 0.05962

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.31241
Value Function Update Magnitude: 0.36285

Collected Steps per Second: 21,954.20326
Overall Steps per Second: 10,521.73974

Timestep Collection Time: 2.27820
Timestep Consumption Time: 2.47539
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.75359

Cumulative Model Updates: 139,006
Cumulative Timesteps: 1,160,075,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1160075662...
Checkpoint 1160075662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,684.94515
Policy Entropy: 1.67419
Value Function Loss: 0.05439

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.31482
Value Function Update Magnitude: 0.35716

Collected Steps per Second: 21,982.04799
Overall Steps per Second: 10,619.58740

Timestep Collection Time: 2.27531
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.70979

Cumulative Model Updates: 139,012
Cumulative Timesteps: 1,160,125,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,703.16603
Policy Entropy: 1.70331
Value Function Loss: 0.06327

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.32013
Value Function Update Magnitude: 0.34215

Collected Steps per Second: 21,236.60719
Overall Steps per Second: 10,428.91938

Timestep Collection Time: 2.35546
Timestep Consumption Time: 2.44101
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.79647

Cumulative Model Updates: 139,018
Cumulative Timesteps: 1,160,175,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1160175700...
Checkpoint 1160175700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,234.57934
Policy Entropy: 1.69530
Value Function Loss: 0.06713

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.32810
Value Function Update Magnitude: 0.37026

Collected Steps per Second: 21,206.78870
Overall Steps per Second: 10,255.61823

Timestep Collection Time: 2.35906
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.87811

Cumulative Model Updates: 139,024
Cumulative Timesteps: 1,160,225,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,469.74558
Policy Entropy: 1.69324
Value Function Loss: 0.06770

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.32670
Value Function Update Magnitude: 0.37432

Collected Steps per Second: 21,624.63009
Overall Steps per Second: 10,534.66566

Timestep Collection Time: 2.31347
Timestep Consumption Time: 2.43542
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.74889

Cumulative Model Updates: 139,030
Cumulative Timesteps: 1,160,275,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1160275756...
Checkpoint 1160275756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,089.45256
Policy Entropy: 1.69058
Value Function Loss: 0.06458

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.32430
Value Function Update Magnitude: 0.36873

Collected Steps per Second: 21,814.08716
Overall Steps per Second: 10,649.04657

Timestep Collection Time: 2.29283
Timestep Consumption Time: 2.40393
PPO Batch Consumption Time: 0.27429
Total Iteration Time: 4.69676

Cumulative Model Updates: 139,036
Cumulative Timesteps: 1,160,325,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,658.10940
Policy Entropy: 1.69969
Value Function Loss: 0.05857

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.31933
Value Function Update Magnitude: 0.36434

Collected Steps per Second: 22,091.38654
Overall Steps per Second: 10,483.65924

Timestep Collection Time: 2.26396
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.77066

Cumulative Model Updates: 139,042
Cumulative Timesteps: 1,160,375,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1160375786...
Checkpoint 1160375786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,474.92362
Policy Entropy: 1.71263
Value Function Loss: 0.05945

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.31857
Value Function Update Magnitude: 0.34527

Collected Steps per Second: 21,924.18021
Overall Steps per Second: 10,545.38603

Timestep Collection Time: 2.28104
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.74236

Cumulative Model Updates: 139,048
Cumulative Timesteps: 1,160,425,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,473.12790
Policy Entropy: 1.72517
Value Function Loss: 0.06351

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.32431
Value Function Update Magnitude: 0.34470

Collected Steps per Second: 22,194.33530
Overall Steps per Second: 10,558.32163

Timestep Collection Time: 2.25490
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.73996

Cumulative Model Updates: 139,054
Cumulative Timesteps: 1,160,475,842

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1160475842...
Checkpoint 1160475842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,948.07719
Policy Entropy: 1.70776
Value Function Loss: 0.06799

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.32794
Value Function Update Magnitude: 0.35130

Collected Steps per Second: 22,063.58637
Overall Steps per Second: 10,506.40895

Timestep Collection Time: 2.26817
Timestep Consumption Time: 2.49502
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.76319

Cumulative Model Updates: 139,060
Cumulative Timesteps: 1,160,525,886

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,052.30607
Policy Entropy: 1.72044
Value Function Loss: 0.06664

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.32325
Value Function Update Magnitude: 0.37153

Collected Steps per Second: 22,480.76960
Overall Steps per Second: 10,571.43249

Timestep Collection Time: 2.22475
Timestep Consumption Time: 2.50631
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.73105

Cumulative Model Updates: 139,066
Cumulative Timesteps: 1,160,575,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1160575900...
Checkpoint 1160575900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,998.29878
Policy Entropy: 1.69647
Value Function Loss: 0.06534

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.30035
Value Function Update Magnitude: 0.36110

Collected Steps per Second: 21,928.58330
Overall Steps per Second: 10,504.71042

Timestep Collection Time: 2.28086
Timestep Consumption Time: 2.48043
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.76129

Cumulative Model Updates: 139,072
Cumulative Timesteps: 1,160,625,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,904.76442
Policy Entropy: 1.71549
Value Function Loss: 0.06055

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.28917
Value Function Update Magnitude: 0.36748

Collected Steps per Second: 22,010.64176
Overall Steps per Second: 10,471.56304

Timestep Collection Time: 2.27254
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.77675

Cumulative Model Updates: 139,078
Cumulative Timesteps: 1,160,675,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1160675936...
Checkpoint 1160675936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,287.92536
Policy Entropy: 1.69868
Value Function Loss: 0.05693

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.28674
Value Function Update Magnitude: 0.36206

Collected Steps per Second: 21,940.98993
Overall Steps per Second: 10,620.18005

Timestep Collection Time: 2.28012
Timestep Consumption Time: 2.43054
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.71065

Cumulative Model Updates: 139,084
Cumulative Timesteps: 1,160,725,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,775.03829
Policy Entropy: 1.71161
Value Function Loss: 0.05682

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.28891
Value Function Update Magnitude: 0.35663

Collected Steps per Second: 21,806.12705
Overall Steps per Second: 10,449.16282

Timestep Collection Time: 2.29486
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.78909

Cumulative Model Updates: 139,090
Cumulative Timesteps: 1,160,776,006

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1160776006...
Checkpoint 1160776006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,710.96671
Policy Entropy: 1.72483
Value Function Loss: 0.05733

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.29084
Value Function Update Magnitude: 0.35040

Collected Steps per Second: 21,484.97673
Overall Steps per Second: 10,338.86580

Timestep Collection Time: 2.32758
Timestep Consumption Time: 2.50931
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.83689

Cumulative Model Updates: 139,096
Cumulative Timesteps: 1,160,826,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,048.96376
Policy Entropy: 1.72583
Value Function Loss: 0.05779

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.30761
Value Function Update Magnitude: 0.34171

Collected Steps per Second: 21,556.41376
Overall Steps per Second: 10,341.59604

Timestep Collection Time: 2.32033
Timestep Consumption Time: 2.51625
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.83658

Cumulative Model Updates: 139,102
Cumulative Timesteps: 1,160,876,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1160876032...
Checkpoint 1160876032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,455.05748
Policy Entropy: 1.71024
Value Function Loss: 0.06383

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.31669
Value Function Update Magnitude: 0.32943

Collected Steps per Second: 21,245.69778
Overall Steps per Second: 10,297.05545

Timestep Collection Time: 2.35408
Timestep Consumption Time: 2.50304
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.85712

Cumulative Model Updates: 139,108
Cumulative Timesteps: 1,160,926,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,508.83118
Policy Entropy: 1.71058
Value Function Loss: 0.07163

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.32725
Value Function Update Magnitude: 0.33025

Collected Steps per Second: 21,816.82315
Overall Steps per Second: 10,324.39166

Timestep Collection Time: 2.29208
Timestep Consumption Time: 2.55140
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.84348

Cumulative Model Updates: 139,114
Cumulative Timesteps: 1,160,976,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1160976052...
Checkpoint 1160976052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,368.96442
Policy Entropy: 1.70967
Value Function Loss: 0.07147

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.32454
Value Function Update Magnitude: 0.33407

Collected Steps per Second: 22,072.27826
Overall Steps per Second: 10,601.90953

Timestep Collection Time: 2.26719
Timestep Consumption Time: 2.45291
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.72009

Cumulative Model Updates: 139,120
Cumulative Timesteps: 1,161,026,094

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,224.87660
Policy Entropy: 1.71625
Value Function Loss: 0.06906

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.31704
Value Function Update Magnitude: 0.39374

Collected Steps per Second: 22,186.79336
Overall Steps per Second: 10,524.65400

Timestep Collection Time: 2.25359
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.75075

Cumulative Model Updates: 139,126
Cumulative Timesteps: 1,161,076,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1161076094...
Checkpoint 1161076094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,101.64656
Policy Entropy: 1.69989
Value Function Loss: 0.06564

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.28932
Value Function Update Magnitude: 0.41809

Collected Steps per Second: 21,659.61497
Overall Steps per Second: 10,567.85225

Timestep Collection Time: 2.31011
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.73474

Cumulative Model Updates: 139,132
Cumulative Timesteps: 1,161,126,130

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,139.13024
Policy Entropy: 1.70225
Value Function Loss: 0.06300

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.30435
Value Function Update Magnitude: 0.40740

Collected Steps per Second: 22,094.68221
Overall Steps per Second: 10,468.43320

Timestep Collection Time: 2.26453
Timestep Consumption Time: 2.51499
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.77951

Cumulative Model Updates: 139,138
Cumulative Timesteps: 1,161,176,164

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1161176164...
Checkpoint 1161176164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,217.40309
Policy Entropy: 1.68700
Value Function Loss: 0.06278

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.31679
Value Function Update Magnitude: 0.37812

Collected Steps per Second: 21,517.59165
Overall Steps per Second: 10,368.66130

Timestep Collection Time: 2.32442
Timestep Consumption Time: 2.49934
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.82377

Cumulative Model Updates: 139,144
Cumulative Timesteps: 1,161,226,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,395.11878
Policy Entropy: 1.66905
Value Function Loss: 0.05654

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.30783
Value Function Update Magnitude: 0.36434

Collected Steps per Second: 21,768.90660
Overall Steps per Second: 10,468.56592

Timestep Collection Time: 2.29860
Timestep Consumption Time: 2.48123
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.77983

Cumulative Model Updates: 139,150
Cumulative Timesteps: 1,161,276,218

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1161276218...
Checkpoint 1161276218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,517.61981
Policy Entropy: 1.65785
Value Function Loss: 0.05802

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.29217
Value Function Update Magnitude: 0.37378

Collected Steps per Second: 21,677.49733
Overall Steps per Second: 10,520.06984

Timestep Collection Time: 2.30755
Timestep Consumption Time: 2.44736
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.75491

Cumulative Model Updates: 139,156
Cumulative Timesteps: 1,161,326,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,085.75877
Policy Entropy: 1.66784
Value Function Loss: 0.05488

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.30978
Value Function Update Magnitude: 0.35313

Collected Steps per Second: 21,657.63276
Overall Steps per Second: 10,409.30295

Timestep Collection Time: 2.30865
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.80340

Cumulative Model Updates: 139,162
Cumulative Timesteps: 1,161,376,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1161376240...
Checkpoint 1161376240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,985.24650
Policy Entropy: 1.68343
Value Function Loss: 0.05847

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.31808
Value Function Update Magnitude: 0.34143

Collected Steps per Second: 21,479.37891
Overall Steps per Second: 10,297.21513

Timestep Collection Time: 2.32819
Timestep Consumption Time: 2.52827
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.85646

Cumulative Model Updates: 139,168
Cumulative Timesteps: 1,161,426,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,701.29805
Policy Entropy: 1.69263
Value Function Loss: 0.06146

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.31686
Value Function Update Magnitude: 0.35638

Collected Steps per Second: 22,028.96626
Overall Steps per Second: 10,424.11851

Timestep Collection Time: 2.27083
Timestep Consumption Time: 2.52804
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.79887

Cumulative Model Updates: 139,174
Cumulative Timesteps: 1,161,476,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1161476272...
Checkpoint 1161476272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,143.44044
Policy Entropy: 1.68976
Value Function Loss: 0.06460

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.31927
Value Function Update Magnitude: 0.32358

Collected Steps per Second: 22,016.78446
Overall Steps per Second: 10,657.49173

Timestep Collection Time: 2.27199
Timestep Consumption Time: 2.42161
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.69360

Cumulative Model Updates: 139,180
Cumulative Timesteps: 1,161,526,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,806.41795
Policy Entropy: 1.70310
Value Function Loss: 0.06662

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.32327
Value Function Update Magnitude: 0.26519

Collected Steps per Second: 22,085.11936
Overall Steps per Second: 10,502.55465

Timestep Collection Time: 2.26406
Timestep Consumption Time: 2.49688
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.76094

Cumulative Model Updates: 139,186
Cumulative Timesteps: 1,161,576,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1161576296...
Checkpoint 1161576296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,087.51698
Policy Entropy: 1.72064
Value Function Loss: 0.06518

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.32388
Value Function Update Magnitude: 0.25179

Collected Steps per Second: 21,516.38877
Overall Steps per Second: 10,502.31636

Timestep Collection Time: 2.32465
Timestep Consumption Time: 2.43792
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.76257

Cumulative Model Updates: 139,192
Cumulative Timesteps: 1,161,626,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,716.23095
Policy Entropy: 1.72632
Value Function Loss: 0.06414

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.32794
Value Function Update Magnitude: 0.34056

Collected Steps per Second: 21,164.72307
Overall Steps per Second: 10,478.68217

Timestep Collection Time: 2.36393
Timestep Consumption Time: 2.41071
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.77465

Cumulative Model Updates: 139,198
Cumulative Timesteps: 1,161,676,346

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1161676346...
Checkpoint 1161676346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,674.55500
Policy Entropy: 1.72473
Value Function Loss: 0.06062

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.32656
Value Function Update Magnitude: 0.38479

Collected Steps per Second: 21,059.70824
Overall Steps per Second: 10,571.57970

Timestep Collection Time: 2.37430
Timestep Consumption Time: 2.35555
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.72985

Cumulative Model Updates: 139,204
Cumulative Timesteps: 1,161,726,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,510.03329
Policy Entropy: 1.70818
Value Function Loss: 0.05631

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.31912
Value Function Update Magnitude: 0.36732

Collected Steps per Second: 21,320.49187
Overall Steps per Second: 10,472.20551

Timestep Collection Time: 2.34582
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.77588

Cumulative Model Updates: 139,210
Cumulative Timesteps: 1,161,776,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1161776362...
Checkpoint 1161776362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,432.95406
Policy Entropy: 1.72287
Value Function Loss: 0.05878

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.31687
Value Function Update Magnitude: 0.31545

Collected Steps per Second: 20,959.19773
Overall Steps per Second: 10,440.28663

Timestep Collection Time: 2.38683
Timestep Consumption Time: 2.40480
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.79163

Cumulative Model Updates: 139,216
Cumulative Timesteps: 1,161,826,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,762.06751
Policy Entropy: 1.73084
Value Function Loss: 0.06000

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.31573
Value Function Update Magnitude: 0.30553

Collected Steps per Second: 21,077.93591
Overall Steps per Second: 10,282.30208

Timestep Collection Time: 2.37338
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.86525

Cumulative Model Updates: 139,222
Cumulative Timesteps: 1,161,876,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1161876414...
Checkpoint 1161876414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,437.13637
Policy Entropy: 1.73110
Value Function Loss: 0.05710

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.31187
Value Function Update Magnitude: 0.29178

Collected Steps per Second: 21,522.01842
Overall Steps per Second: 10,573.89914

Timestep Collection Time: 2.32395
Timestep Consumption Time: 2.40619
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.73014

Cumulative Model Updates: 139,228
Cumulative Timesteps: 1,161,926,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,919.68254
Policy Entropy: 1.71672
Value Function Loss: 0.05490

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07301
Policy Update Magnitude: 0.30713
Value Function Update Magnitude: 0.31385

Collected Steps per Second: 21,397.30904
Overall Steps per Second: 10,548.81128

Timestep Collection Time: 2.33777
Timestep Consumption Time: 2.40419
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.74196

Cumulative Model Updates: 139,234
Cumulative Timesteps: 1,161,976,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1161976452...
Checkpoint 1161976452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,079.22493
Policy Entropy: 1.70352
Value Function Loss: 0.05536

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07881
Policy Update Magnitude: 0.31053
Value Function Update Magnitude: 0.32214

Collected Steps per Second: 21,455.84802
Overall Steps per Second: 10,538.60346

Timestep Collection Time: 2.33232
Timestep Consumption Time: 2.41612
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.74845

Cumulative Model Updates: 139,240
Cumulative Timesteps: 1,162,026,494

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,060.72181
Policy Entropy: 1.70924
Value Function Loss: 0.05562

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.29607
Value Function Update Magnitude: 0.30811

Collected Steps per Second: 21,755.18498
Overall Steps per Second: 10,569.33107

Timestep Collection Time: 2.29950
Timestep Consumption Time: 2.43363
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.73313

Cumulative Model Updates: 139,246
Cumulative Timesteps: 1,162,076,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1162076520...
Checkpoint 1162076520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,666.27741
Policy Entropy: 1.71672
Value Function Loss: 0.05113

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.27783
Value Function Update Magnitude: 0.33060

Collected Steps per Second: 22,140.01698
Overall Steps per Second: 10,552.25967

Timestep Collection Time: 2.25998
Timestep Consumption Time: 2.48175
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.74173

Cumulative Model Updates: 139,252
Cumulative Timesteps: 1,162,126,556

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,187.24000
Policy Entropy: 1.71541
Value Function Loss: 0.05594

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.29818
Value Function Update Magnitude: 0.34140

Collected Steps per Second: 22,056.34747
Overall Steps per Second: 10,482.01448

Timestep Collection Time: 2.26819
Timestep Consumption Time: 2.50456
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.77275

Cumulative Model Updates: 139,258
Cumulative Timesteps: 1,162,176,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1162176584...
Checkpoint 1162176584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,182.66477
Policy Entropy: 1.72634
Value Function Loss: 0.06040

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.30933
Value Function Update Magnitude: 0.34619

Collected Steps per Second: 21,839.43959
Overall Steps per Second: 10,570.01353

Timestep Collection Time: 2.28999
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.73150

Cumulative Model Updates: 139,264
Cumulative Timesteps: 1,162,226,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,032.02364
Policy Entropy: 1.73974
Value Function Loss: 0.06781

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.31799
Value Function Update Magnitude: 0.36549

Collected Steps per Second: 21,885.81855
Overall Steps per Second: 10,509.96503

Timestep Collection Time: 2.28577
Timestep Consumption Time: 2.47409
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.75986

Cumulative Model Updates: 139,270
Cumulative Timesteps: 1,162,276,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1162276622...
Checkpoint 1162276622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,337.77711
Policy Entropy: 1.73090
Value Function Loss: 0.06826

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.32026
Value Function Update Magnitude: 0.37149

Collected Steps per Second: 21,544.18198
Overall Steps per Second: 10,593.62358

Timestep Collection Time: 2.32258
Timestep Consumption Time: 2.40083
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.72341

Cumulative Model Updates: 139,276
Cumulative Timesteps: 1,162,326,660

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,302.84632
Policy Entropy: 1.73272
Value Function Loss: 0.06576

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.32315
Value Function Update Magnitude: 0.38470

Collected Steps per Second: 21,791.36395
Overall Steps per Second: 10,593.83078

Timestep Collection Time: 2.29467
Timestep Consumption Time: 2.42544
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.72011

Cumulative Model Updates: 139,282
Cumulative Timesteps: 1,162,376,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1162376664...
Checkpoint 1162376664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,067.89036
Policy Entropy: 1.72020
Value Function Loss: 0.06112

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.31845
Value Function Update Magnitude: 0.36850

Collected Steps per Second: 21,571.68725
Overall Steps per Second: 10,504.41729

Timestep Collection Time: 2.31785
Timestep Consumption Time: 2.44205
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.75990

Cumulative Model Updates: 139,288
Cumulative Timesteps: 1,162,426,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,304.16812
Policy Entropy: 1.73108
Value Function Loss: 0.06050

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.31081
Value Function Update Magnitude: 0.37146

Collected Steps per Second: 21,603.15695
Overall Steps per Second: 10,502.83488

Timestep Collection Time: 2.31466
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.76100

Cumulative Model Updates: 139,294
Cumulative Timesteps: 1,162,476,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1162476668...
Checkpoint 1162476668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,607.86227
Policy Entropy: 1.73177
Value Function Loss: 0.06553

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.31397
Value Function Update Magnitude: 0.36220

Collected Steps per Second: 21,897.78690
Overall Steps per Second: 10,589.31984

Timestep Collection Time: 2.28507
Timestep Consumption Time: 2.44026
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.72533

Cumulative Model Updates: 139,300
Cumulative Timesteps: 1,162,526,706

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,656.85045
Policy Entropy: 1.72509
Value Function Loss: 0.06617

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.31549
Value Function Update Magnitude: 0.35329

Collected Steps per Second: 21,968.22891
Overall Steps per Second: 10,554.96308

Timestep Collection Time: 2.27656
Timestep Consumption Time: 2.46168
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.73824

Cumulative Model Updates: 139,306
Cumulative Timesteps: 1,162,576,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1162576718...
Checkpoint 1162576718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,853.53135
Policy Entropy: 1.71002
Value Function Loss: 0.06420

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.31332
Value Function Update Magnitude: 0.37506

Collected Steps per Second: 22,035.08102
Overall Steps per Second: 10,640.62238

Timestep Collection Time: 2.27056
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.70198

Cumulative Model Updates: 139,312
Cumulative Timesteps: 1,162,626,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,819.07590
Policy Entropy: 1.69705
Value Function Loss: 0.05972

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.31133
Value Function Update Magnitude: 0.39647

Collected Steps per Second: 21,905.10460
Overall Steps per Second: 10,418.20956

Timestep Collection Time: 2.28303
Timestep Consumption Time: 2.51722
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.80025

Cumulative Model Updates: 139,318
Cumulative Timesteps: 1,162,676,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1162676760...
Checkpoint 1162676760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,142.05503
Policy Entropy: 1.70423
Value Function Loss: 0.05970

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08252
Policy Update Magnitude: 0.32067
Value Function Update Magnitude: 0.39608

Collected Steps per Second: 21,790.52463
Overall Steps per Second: 10,554.18459

Timestep Collection Time: 2.29522
Timestep Consumption Time: 2.44357
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.73878

Cumulative Model Updates: 139,324
Cumulative Timesteps: 1,162,726,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,020.88746
Policy Entropy: 1.69490
Value Function Loss: 0.05417

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.31627
Value Function Update Magnitude: 0.37586

Collected Steps per Second: 21,784.39091
Overall Steps per Second: 10,475.44641

Timestep Collection Time: 2.29531
Timestep Consumption Time: 2.47794
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.77326

Cumulative Model Updates: 139,330
Cumulative Timesteps: 1,162,776,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1162776776...
Checkpoint 1162776776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,666.57863
Policy Entropy: 1.69338
Value Function Loss: 0.05091

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.30569
Value Function Update Magnitude: 0.34865

Collected Steps per Second: 21,822.94737
Overall Steps per Second: 10,599.30754

Timestep Collection Time: 2.29327
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.72163

Cumulative Model Updates: 139,336
Cumulative Timesteps: 1,162,826,822

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,778.85157
Policy Entropy: 1.68231
Value Function Loss: 0.04727

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.30577
Value Function Update Magnitude: 0.31782

Collected Steps per Second: 20,469.74990
Overall Steps per Second: 10,099.17759

Timestep Collection Time: 2.44321
Timestep Consumption Time: 2.50887
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.95209

Cumulative Model Updates: 139,342
Cumulative Timesteps: 1,162,876,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1162876834...
Checkpoint 1162876834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,084.19400
Policy Entropy: 1.71098
Value Function Loss: 0.04991

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.30792

Collected Steps per Second: 21,144.37380
Overall Steps per Second: 10,307.95888

Timestep Collection Time: 2.36498
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.85120

Cumulative Model Updates: 139,348
Cumulative Timesteps: 1,162,926,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,707.98900
Policy Entropy: 1.70657
Value Function Loss: 0.05068

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.30273
Value Function Update Magnitude: 0.29667

Collected Steps per Second: 21,660.15801
Overall Steps per Second: 10,337.05516

Timestep Collection Time: 2.30931
Timestep Consumption Time: 2.52959
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.83890

Cumulative Model Updates: 139,354
Cumulative Timesteps: 1,162,976,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1162976860...
Checkpoint 1162976860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,982.22394
Policy Entropy: 1.71664
Value Function Loss: 0.05123

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07540
Policy Update Magnitude: 0.30075
Value Function Update Magnitude: 0.30366

Collected Steps per Second: 21,364.91177
Overall Steps per Second: 10,245.00326

Timestep Collection Time: 2.34178
Timestep Consumption Time: 2.54177
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.88355

Cumulative Model Updates: 139,360
Cumulative Timesteps: 1,163,026,892

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,539.79920
Policy Entropy: 1.70704
Value Function Loss: 0.04931

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.29924
Value Function Update Magnitude: 0.31951

Collected Steps per Second: 22,173.90225
Overall Steps per Second: 10,446.26538

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.53302
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.78927

Cumulative Model Updates: 139,366
Cumulative Timesteps: 1,163,076,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1163076922...
Checkpoint 1163076922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,600.68121
Policy Entropy: 1.72163
Value Function Loss: 0.05204

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.30097
Value Function Update Magnitude: 0.32846

Collected Steps per Second: 21,777.11953
Overall Steps per Second: 10,536.63338

Timestep Collection Time: 2.29700
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.74744

Cumulative Model Updates: 139,372
Cumulative Timesteps: 1,163,126,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,308.42505
Policy Entropy: 1.72457
Value Function Loss: 0.05497

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.30109
Value Function Update Magnitude: 0.33741

Collected Steps per Second: 22,006.33627
Overall Steps per Second: 10,513.29543

Timestep Collection Time: 2.27307
Timestep Consumption Time: 2.48490
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.75798

Cumulative Model Updates: 139,378
Cumulative Timesteps: 1,163,176,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1163176966...
Checkpoint 1163176966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,297.37253
Policy Entropy: 1.72324
Value Function Loss: 0.05458

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.30181
Value Function Update Magnitude: 0.33108

Collected Steps per Second: 21,716.15908
Overall Steps per Second: 10,592.97272

Timestep Collection Time: 2.30381
Timestep Consumption Time: 2.41913
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.72294

Cumulative Model Updates: 139,384
Cumulative Timesteps: 1,163,226,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,903.79632
Policy Entropy: 1.70781
Value Function Loss: 0.05196

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.30001
Value Function Update Magnitude: 0.31478

Collected Steps per Second: 22,000.95090
Overall Steps per Second: 10,518.01906

Timestep Collection Time: 2.27363
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.75584

Cumulative Model Updates: 139,390
Cumulative Timesteps: 1,163,277,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1163277018...
Checkpoint 1163277018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,541.23228
Policy Entropy: 1.69215
Value Function Loss: 0.04763

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.30028
Value Function Update Magnitude: 0.30180

Collected Steps per Second: 21,799.79072
Overall Steps per Second: 10,620.94884

Timestep Collection Time: 2.29589
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.71238

Cumulative Model Updates: 139,396
Cumulative Timesteps: 1,163,327,068

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,526.10220
Policy Entropy: 1.68583
Value Function Loss: 0.04703

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.29966
Value Function Update Magnitude: 0.30132

Collected Steps per Second: 21,821.47568
Overall Steps per Second: 10,434.62695

Timestep Collection Time: 2.29297
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.79519

Cumulative Model Updates: 139,402
Cumulative Timesteps: 1,163,377,104

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1163377104...
Checkpoint 1163377104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,034.26893
Policy Entropy: 1.69869
Value Function Loss: 0.04582

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07769
Policy Update Magnitude: 0.29614
Value Function Update Magnitude: 0.30978

Collected Steps per Second: 19,400.88403
Overall Steps per Second: 9,945.02237

Timestep Collection Time: 2.57761
Timestep Consumption Time: 2.45083
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 5.02845

Cumulative Model Updates: 139,408
Cumulative Timesteps: 1,163,427,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,207.96985
Policy Entropy: 1.70257
Value Function Loss: 0.04661

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.29874
Value Function Update Magnitude: 0.32933

Collected Steps per Second: 21,507.14495
Overall Steps per Second: 10,363.55471

Timestep Collection Time: 2.32490
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.82479

Cumulative Model Updates: 139,414
Cumulative Timesteps: 1,163,477,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1163477114...
Checkpoint 1163477114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,301.15042
Policy Entropy: 1.71200
Value Function Loss: 0.04861

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07863
Policy Update Magnitude: 0.30059
Value Function Update Magnitude: 0.33654

Collected Steps per Second: 21,286.25868
Overall Steps per Second: 10,292.43629

Timestep Collection Time: 2.34940
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.85891

Cumulative Model Updates: 139,420
Cumulative Timesteps: 1,163,527,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,308.71996
Policy Entropy: 1.70544
Value Function Loss: 0.05109

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.30164
Value Function Update Magnitude: 0.34503

Collected Steps per Second: 22,024.95116
Overall Steps per Second: 10,429.39023

Timestep Collection Time: 2.27024
Timestep Consumption Time: 2.52409
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.79434

Cumulative Model Updates: 139,426
Cumulative Timesteps: 1,163,577,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1163577126...
Checkpoint 1163577126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,880.49602
Policy Entropy: 1.70286
Value Function Loss: 0.05400

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08396
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.35168

Collected Steps per Second: 21,303.77012
Overall Steps per Second: 10,559.44524

Timestep Collection Time: 2.34850
Timestep Consumption Time: 2.38962
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.73813

Cumulative Model Updates: 139,432
Cumulative Timesteps: 1,163,627,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,912.30263
Policy Entropy: 1.68843
Value Function Loss: 0.05334

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.30245
Value Function Update Magnitude: 0.35888

Collected Steps per Second: 21,459.63515
Overall Steps per Second: 10,477.68156

Timestep Collection Time: 2.33182
Timestep Consumption Time: 2.44405
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.77587

Cumulative Model Updates: 139,438
Cumulative Timesteps: 1,163,677,198

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1163677198...
Checkpoint 1163677198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,515.80704
Policy Entropy: 1.68908
Value Function Loss: 0.05191

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.30148
Value Function Update Magnitude: 0.35884

Collected Steps per Second: 21,272.56207
Overall Steps per Second: 10,621.68947

Timestep Collection Time: 2.35148
Timestep Consumption Time: 2.35794
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.70942

Cumulative Model Updates: 139,444
Cumulative Timesteps: 1,163,727,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,512.07976
Policy Entropy: 1.69744
Value Function Loss: 0.05239

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.30349
Value Function Update Magnitude: 0.35499

Collected Steps per Second: 21,732.15921
Overall Steps per Second: 10,591.64029

Timestep Collection Time: 2.30295
Timestep Consumption Time: 2.42229
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.72524

Cumulative Model Updates: 139,450
Cumulative Timesteps: 1,163,777,268

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1163777268...
Checkpoint 1163777268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,443.46026
Policy Entropy: 1.71686
Value Function Loss: 0.05771

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.30635
Value Function Update Magnitude: 0.35020

Collected Steps per Second: 21,325.12919
Overall Steps per Second: 10,471.63204

Timestep Collection Time: 2.34587
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.77729

Cumulative Model Updates: 139,456
Cumulative Timesteps: 1,163,827,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,036.37809
Policy Entropy: 1.71652
Value Function Loss: 0.05889

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.30679
Value Function Update Magnitude: 0.36228

Collected Steps per Second: 21,821.65999
Overall Steps per Second: 10,505.23844

Timestep Collection Time: 2.29148
Timestep Consumption Time: 2.46843
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.75991

Cumulative Model Updates: 139,462
Cumulative Timesteps: 1,163,877,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1163877298...
Checkpoint 1163877298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,334.23806
Policy Entropy: 1.71302
Value Function Loss: 0.06091

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.31044
Value Function Update Magnitude: 0.36735

Collected Steps per Second: 21,585.09394
Overall Steps per Second: 10,600.57160

Timestep Collection Time: 2.31697
Timestep Consumption Time: 2.40089
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.71786

Cumulative Model Updates: 139,468
Cumulative Timesteps: 1,163,927,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,724.84962
Policy Entropy: 1.70871
Value Function Loss: 0.06116

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.31948
Value Function Update Magnitude: 0.32840

Collected Steps per Second: 21,712.17847
Overall Steps per Second: 10,466.16688

Timestep Collection Time: 2.30378
Timestep Consumption Time: 2.47543
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.77921

Cumulative Model Updates: 139,474
Cumulative Timesteps: 1,163,977,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1163977330...
Checkpoint 1163977330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,375.46171
Policy Entropy: 1.71476
Value Function Loss: 0.06341

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.32128
Value Function Update Magnitude: 0.29604

Collected Steps per Second: 21,276.67812
Overall Steps per Second: 10,370.27609

Timestep Collection Time: 2.35046
Timestep Consumption Time: 2.47198
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.82244

Cumulative Model Updates: 139,480
Cumulative Timesteps: 1,164,027,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,495.02968
Policy Entropy: 1.72438
Value Function Loss: 0.06158

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.31796
Value Function Update Magnitude: 0.26816

Collected Steps per Second: 21,898.46726
Overall Steps per Second: 10,687.27366

Timestep Collection Time: 2.28409
Timestep Consumption Time: 2.39606
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.68015

Cumulative Model Updates: 139,486
Cumulative Timesteps: 1,164,077,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1164077358...
Checkpoint 1164077358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,562.45682
Policy Entropy: 1.72951
Value Function Loss: 0.05708

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08341
Policy Update Magnitude: 0.31114
Value Function Update Magnitude: 0.24500

Collected Steps per Second: 21,598.70688
Overall Steps per Second: 10,379.33346

Timestep Collection Time: 2.31514
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.81765

Cumulative Model Updates: 139,492
Cumulative Timesteps: 1,164,127,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,835.82836
Policy Entropy: 1.73361
Value Function Loss: 0.05269

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.29952
Value Function Update Magnitude: 0.27940

Collected Steps per Second: 22,093.11551
Overall Steps per Second: 10,377.02040

Timestep Collection Time: 2.26369
Timestep Consumption Time: 2.55580
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.81950

Cumulative Model Updates: 139,498
Cumulative Timesteps: 1,164,177,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1164177374...
Checkpoint 1164177374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,328.29940
Policy Entropy: 1.71829
Value Function Loss: 0.05343

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.28646
Value Function Update Magnitude: 0.30311

Collected Steps per Second: 21,723.10489
Overall Steps per Second: 10,513.43796

Timestep Collection Time: 2.30271
Timestep Consumption Time: 2.45520
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.75791

Cumulative Model Updates: 139,504
Cumulative Timesteps: 1,164,227,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,779.56012
Policy Entropy: 1.69316
Value Function Loss: 0.05151

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.29436
Value Function Update Magnitude: 0.32324

Collected Steps per Second: 21,862.56386
Overall Steps per Second: 10,533.87129

Timestep Collection Time: 2.28784
Timestep Consumption Time: 2.46046
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.74830

Cumulative Model Updates: 139,510
Cumulative Timesteps: 1,164,277,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1164277414...
Checkpoint 1164277414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,695.06171
Policy Entropy: 1.69383
Value Function Loss: 0.05350

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.28317
Value Function Update Magnitude: 0.33514

Collected Steps per Second: 21,590.50608
Overall Steps per Second: 10,585.58541

Timestep Collection Time: 2.31806
Timestep Consumption Time: 2.40988
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.72794

Cumulative Model Updates: 139,516
Cumulative Timesteps: 1,164,327,462

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,371.06259
Policy Entropy: 1.70116
Value Function Loss: 0.05357

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.28108
Value Function Update Magnitude: 0.33132

Collected Steps per Second: 22,024.17244
Overall Steps per Second: 10,482.11990

Timestep Collection Time: 2.27159
Timestep Consumption Time: 2.50129
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.77289

Cumulative Model Updates: 139,522
Cumulative Timesteps: 1,164,377,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1164377492...
Checkpoint 1164377492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,081.07089
Policy Entropy: 1.72279
Value Function Loss: 0.05608

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.30366
Value Function Update Magnitude: 0.32898

Collected Steps per Second: 21,918.00753
Overall Steps per Second: 10,606.01318

Timestep Collection Time: 2.28187
Timestep Consumption Time: 2.43376
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.71563

Cumulative Model Updates: 139,528
Cumulative Timesteps: 1,164,427,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,880.94810
Policy Entropy: 1.71664
Value Function Loss: 0.05820

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.31608
Value Function Update Magnitude: 0.35566

Collected Steps per Second: 22,129.17967
Overall Steps per Second: 10,525.79672

Timestep Collection Time: 2.26100
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.75346

Cumulative Model Updates: 139,534
Cumulative Timesteps: 1,164,477,540

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1164477540...
Checkpoint 1164477540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,659.38082
Policy Entropy: 1.70793
Value Function Loss: 0.05604

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08214
Policy Update Magnitude: 0.31864
Value Function Update Magnitude: 0.36457

Collected Steps per Second: 21,614.14127
Overall Steps per Second: 10,405.64332

Timestep Collection Time: 2.31497
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.80854

Cumulative Model Updates: 139,540
Cumulative Timesteps: 1,164,527,576

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,977.86170
Policy Entropy: 1.69833
Value Function Loss: 0.05632

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.31686
Value Function Update Magnitude: 0.36474

Collected Steps per Second: 21,857.50138
Overall Steps per Second: 10,604.91988

Timestep Collection Time: 2.28873
Timestep Consumption Time: 2.42851
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.71724

Cumulative Model Updates: 139,546
Cumulative Timesteps: 1,164,577,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1164577602...
Checkpoint 1164577602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,622.12664
Policy Entropy: 1.69857
Value Function Loss: 0.05472

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.31209
Value Function Update Magnitude: 0.35684

Collected Steps per Second: 21,373.84773
Overall Steps per Second: 10,303.85842

Timestep Collection Time: 2.34165
Timestep Consumption Time: 2.51576
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.85740

Cumulative Model Updates: 139,552
Cumulative Timesteps: 1,164,627,652

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,646.52370
Policy Entropy: 1.69709
Value Function Loss: 0.05094

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.31090
Value Function Update Magnitude: 0.34462

Collected Steps per Second: 21,875.73633
Overall Steps per Second: 10,455.74581

Timestep Collection Time: 2.28582
Timestep Consumption Time: 2.49662
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.78244

Cumulative Model Updates: 139,558
Cumulative Timesteps: 1,164,677,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1164677656...
Checkpoint 1164677656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,292.57664
Policy Entropy: 1.70192
Value Function Loss: 0.05216

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.31092
Value Function Update Magnitude: 0.33839

Collected Steps per Second: 21,800.41892
Overall Steps per Second: 10,520.64275

Timestep Collection Time: 2.29574
Timestep Consumption Time: 2.46139
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.75712

Cumulative Model Updates: 139,564
Cumulative Timesteps: 1,164,727,704

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,512.28280
Policy Entropy: 1.71435
Value Function Loss: 0.05369

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07615
Policy Update Magnitude: 0.31003
Value Function Update Magnitude: 0.32261

Collected Steps per Second: 21,907.29926
Overall Steps per Second: 10,601.76676

Timestep Collection Time: 2.28262
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.71676

Cumulative Model Updates: 139,570
Cumulative Timesteps: 1,164,777,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1164777710...
Checkpoint 1164777710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,455.37186
Policy Entropy: 1.71215
Value Function Loss: 0.05777

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.31030
Value Function Update Magnitude: 0.31796

Collected Steps per Second: 21,638.16933
Overall Steps per Second: 10,528.17406

Timestep Collection Time: 2.31129
Timestep Consumption Time: 2.43902
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.75030

Cumulative Model Updates: 139,576
Cumulative Timesteps: 1,164,827,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,119.34049
Policy Entropy: 1.70824
Value Function Loss: 0.05464

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.31036
Value Function Update Magnitude: 0.32823

Collected Steps per Second: 22,053.88165
Overall Steps per Second: 10,524.59304

Timestep Collection Time: 2.26917
Timestep Consumption Time: 2.48579
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.75496

Cumulative Model Updates: 139,582
Cumulative Timesteps: 1,164,877,766

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1164877766...
Checkpoint 1164877766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,411.06965
Policy Entropy: 1.71208
Value Function Loss: 0.04922

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08256
Policy Update Magnitude: 0.30072
Value Function Update Magnitude: 0.33482

Collected Steps per Second: 21,942.36485
Overall Steps per Second: 10,640.71846

Timestep Collection Time: 2.27897
Timestep Consumption Time: 2.42052
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.69949

Cumulative Model Updates: 139,588
Cumulative Timesteps: 1,164,927,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,055.24646
Policy Entropy: 1.72149
Value Function Loss: 0.04600

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07645
Policy Update Magnitude: 0.29470
Value Function Update Magnitude: 0.31296

Collected Steps per Second: 22,030.41823
Overall Steps per Second: 10,447.33105

Timestep Collection Time: 2.26977
Timestep Consumption Time: 2.51652
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.78629

Cumulative Model Updates: 139,594
Cumulative Timesteps: 1,164,977,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1164977776...
Checkpoint 1164977776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,101.83804
Policy Entropy: 1.72768
Value Function Loss: 0.05089

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07355
Policy Update Magnitude: 0.30134
Value Function Update Magnitude: 0.30291

Collected Steps per Second: 21,545.04983
Overall Steps per Second: 10,552.87048

Timestep Collection Time: 2.32137
Timestep Consumption Time: 2.41801
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.73937

Cumulative Model Updates: 139,600
Cumulative Timesteps: 1,165,027,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,098.92756
Policy Entropy: 1.72083
Value Function Loss: 0.05427

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.31122
Value Function Update Magnitude: 0.32578

Collected Steps per Second: 21,233.61549
Overall Steps per Second: 10,620.68740

Timestep Collection Time: 2.35551
Timestep Consumption Time: 2.35379
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.70930

Cumulative Model Updates: 139,606
Cumulative Timesteps: 1,165,077,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1165077806...
Checkpoint 1165077806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,465.30030
Policy Entropy: 1.72588
Value Function Loss: 0.05844

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.31655
Value Function Update Magnitude: 0.34206

Collected Steps per Second: 20,548.21953
Overall Steps per Second: 10,319.01735

Timestep Collection Time: 2.43437
Timestep Consumption Time: 2.41318
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.84755

Cumulative Model Updates: 139,612
Cumulative Timesteps: 1,165,127,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,289.15728
Policy Entropy: 1.71140
Value Function Loss: 0.05610

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.31514
Value Function Update Magnitude: 0.36241

Collected Steps per Second: 20,985.86421
Overall Steps per Second: 10,365.91463

Timestep Collection Time: 2.38437
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.82717

Cumulative Model Updates: 139,618
Cumulative Timesteps: 1,165,177,866

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1165177866...
Checkpoint 1165177866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,693.99125
Policy Entropy: 1.70879
Value Function Loss: 0.05264

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.30671
Value Function Update Magnitude: 0.34255

Collected Steps per Second: 21,450.16369
Overall Steps per Second: 10,605.72568

Timestep Collection Time: 2.33136
Timestep Consumption Time: 2.38383
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.71519

Cumulative Model Updates: 139,624
Cumulative Timesteps: 1,165,227,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,257.15344
Policy Entropy: 1.70375
Value Function Loss: 0.04901

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07652
Policy Update Magnitude: 0.29839
Value Function Update Magnitude: 0.29820

Collected Steps per Second: 21,803.55871
Overall Steps per Second: 10,446.68148

Timestep Collection Time: 2.29375
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.78736

Cumulative Model Updates: 139,630
Cumulative Timesteps: 1,165,277,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1165277886...
Checkpoint 1165277886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,194.72949
Policy Entropy: 1.70287
Value Function Loss: 0.04972

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07425
Policy Update Magnitude: 0.29558
Value Function Update Magnitude: 0.29460

Collected Steps per Second: 21,476.09282
Overall Steps per Second: 10,556.86313

Timestep Collection Time: 2.32910
Timestep Consumption Time: 2.40905
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.73815

Cumulative Model Updates: 139,636
Cumulative Timesteps: 1,165,327,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,788.51280
Policy Entropy: 1.71046
Value Function Loss: 0.05326

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.29737
Value Function Update Magnitude: 0.30463

Collected Steps per Second: 21,950.44932
Overall Steps per Second: 10,449.22689

Timestep Collection Time: 2.27786
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.78504

Cumulative Model Updates: 139,642
Cumulative Timesteps: 1,165,377,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1165377906...
Checkpoint 1165377906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,826.59115
Policy Entropy: 1.69673
Value Function Loss: 0.05205

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.30472
Value Function Update Magnitude: 0.29675

Collected Steps per Second: 21,948.96335
Overall Steps per Second: 10,694.23471

Timestep Collection Time: 2.27929
Timestep Consumption Time: 2.39875
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.67803

Cumulative Model Updates: 139,648
Cumulative Timesteps: 1,165,427,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,107.81073
Policy Entropy: 1.70485
Value Function Loss: 0.04903

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.30188
Value Function Update Magnitude: 0.29302

Collected Steps per Second: 21,386.90449
Overall Steps per Second: 10,494.55947

Timestep Collection Time: 2.33825
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.76514

Cumulative Model Updates: 139,654
Cumulative Timesteps: 1,165,477,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1165477942...
Checkpoint 1165477942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,518.94325
Policy Entropy: 1.69616
Value Function Loss: 0.04739

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.30145
Value Function Update Magnitude: 0.28504

Collected Steps per Second: 21,837.05121
Overall Steps per Second: 10,567.76376

Timestep Collection Time: 2.29143
Timestep Consumption Time: 2.44354
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.73497

Cumulative Model Updates: 139,660
Cumulative Timesteps: 1,165,527,980

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,698.26410
Policy Entropy: 1.70941
Value Function Loss: 0.04789

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.29774
Value Function Update Magnitude: 0.28934

Collected Steps per Second: 21,726.26762
Overall Steps per Second: 10,443.66190

Timestep Collection Time: 2.30256
Timestep Consumption Time: 2.48752
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.79008

Cumulative Model Updates: 139,666
Cumulative Timesteps: 1,165,578,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1165578006...
Checkpoint 1165578006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,005.56639
Policy Entropy: 1.71639
Value Function Loss: 0.05584

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.30098
Value Function Update Magnitude: 0.30525

Collected Steps per Second: 21,123.42532
Overall Steps per Second: 10,241.80895

Timestep Collection Time: 2.36780
Timestep Consumption Time: 2.51571
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.88351

Cumulative Model Updates: 139,672
Cumulative Timesteps: 1,165,628,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,823.19511
Policy Entropy: 1.71661
Value Function Loss: 0.05221

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.29807
Value Function Update Magnitude: 0.33300

Collected Steps per Second: 21,569.43733
Overall Steps per Second: 10,532.63800

Timestep Collection Time: 2.31819
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.74734

Cumulative Model Updates: 139,678
Cumulative Timesteps: 1,165,678,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1165678024...
Checkpoint 1165678024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,798.38984
Policy Entropy: 1.72103
Value Function Loss: 0.05806

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.30243
Value Function Update Magnitude: 0.32239

Collected Steps per Second: 21,751.99662
Overall Steps per Second: 10,550.85836

Timestep Collection Time: 2.29892
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.73952

Cumulative Model Updates: 139,684
Cumulative Timesteps: 1,165,728,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,788.25907
Policy Entropy: 1.70370
Value Function Loss: 0.05389

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.30775
Value Function Update Magnitude: 0.30612

Collected Steps per Second: 21,476.70875
Overall Steps per Second: 10,425.11301

Timestep Collection Time: 2.32941
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.79880

Cumulative Model Updates: 139,690
Cumulative Timesteps: 1,165,778,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1165778058...
Checkpoint 1165778058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,560.91800
Policy Entropy: 1.70592
Value Function Loss: 0.05680

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.31000
Value Function Update Magnitude: 0.32985

Collected Steps per Second: 21,981.70154
Overall Steps per Second: 10,576.74421

Timestep Collection Time: 2.27571
Timestep Consumption Time: 2.45391
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.72962

Cumulative Model Updates: 139,696
Cumulative Timesteps: 1,165,828,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,064.14268
Policy Entropy: 1.69414
Value Function Loss: 0.05263

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.31289
Value Function Update Magnitude: 0.34078

Collected Steps per Second: 22,037.62685
Overall Steps per Second: 10,535.22575

Timestep Collection Time: 2.26912
Timestep Consumption Time: 2.47743
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.74655

Cumulative Model Updates: 139,702
Cumulative Timesteps: 1,165,878,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1165878088...
Checkpoint 1165878088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,852.97031
Policy Entropy: 1.70776
Value Function Loss: 0.05727

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.31683
Value Function Update Magnitude: 0.35107

Collected Steps per Second: 21,836.86224
Overall Steps per Second: 10,594.80559

Timestep Collection Time: 2.29090
Timestep Consumption Time: 2.43085
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.72175

Cumulative Model Updates: 139,708
Cumulative Timesteps: 1,165,928,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,320.16601
Policy Entropy: 1.69714
Value Function Loss: 0.06104

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.32501
Value Function Update Magnitude: 0.37732

Collected Steps per Second: 22,084.93479
Overall Steps per Second: 10,507.91903

Timestep Collection Time: 2.26435
Timestep Consumption Time: 2.49473
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.75908

Cumulative Model Updates: 139,714
Cumulative Timesteps: 1,165,978,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1165978122...
Checkpoint 1165978122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,282.90026
Policy Entropy: 1.69696
Value Function Loss: 0.06030

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.32648
Value Function Update Magnitude: 0.39280

Collected Steps per Second: 21,904.96177
Overall Steps per Second: 10,557.85531

Timestep Collection Time: 2.28341
Timestep Consumption Time: 2.45411
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.73752

Cumulative Model Updates: 139,720
Cumulative Timesteps: 1,166,028,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,686.04560
Policy Entropy: 1.68293
Value Function Loss: 0.05691

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.32296
Value Function Update Magnitude: 0.36936

Collected Steps per Second: 21,911.37103
Overall Steps per Second: 10,536.98239

Timestep Collection Time: 2.28229
Timestep Consumption Time: 2.46367
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.74595

Cumulative Model Updates: 139,726
Cumulative Timesteps: 1,166,078,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1166078148...
Checkpoint 1166078148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,398.17626
Policy Entropy: 1.70119
Value Function Loss: 0.05730

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.32206
Value Function Update Magnitude: 0.35109

Collected Steps per Second: 21,894.04311
Overall Steps per Second: 10,613.37214

Timestep Collection Time: 2.28427
Timestep Consumption Time: 2.42789
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.71217

Cumulative Model Updates: 139,732
Cumulative Timesteps: 1,166,128,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,513.51457
Policy Entropy: 1.69602
Value Function Loss: 0.05128

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.31520
Value Function Update Magnitude: 0.32444

Collected Steps per Second: 21,494.08328
Overall Steps per Second: 10,480.41698

Timestep Collection Time: 2.32725
Timestep Consumption Time: 2.44566
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.77290

Cumulative Model Updates: 139,738
Cumulative Timesteps: 1,166,178,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1166178182...
Checkpoint 1166178182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,818.81115
Policy Entropy: 1.70825
Value Function Loss: 0.05252

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.31440
Value Function Update Magnitude: 0.33351

Collected Steps per Second: 21,405.64934
Overall Steps per Second: 10,353.87680

Timestep Collection Time: 2.33593
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.82930

Cumulative Model Updates: 139,744
Cumulative Timesteps: 1,166,228,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,951.20320
Policy Entropy: 1.69860
Value Function Loss: 0.04890

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.30727
Value Function Update Magnitude: 0.32239

Collected Steps per Second: 21,843.37787
Overall Steps per Second: 10,418.18812

Timestep Collection Time: 2.29104
Timestep Consumption Time: 2.51248
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.80352

Cumulative Model Updates: 139,750
Cumulative Timesteps: 1,166,278,228

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1166278228...
Checkpoint 1166278228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,640.17117
Policy Entropy: 1.70132
Value Function Loss: 0.04920

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.30304
Value Function Update Magnitude: 0.30244

Collected Steps per Second: 22,287.20925
Overall Steps per Second: 10,563.09728

Timestep Collection Time: 2.24380
Timestep Consumption Time: 2.49042
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.73422

Cumulative Model Updates: 139,756
Cumulative Timesteps: 1,166,328,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,643.59549
Policy Entropy: 1.71864
Value Function Loss: 0.05150

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.30434
Value Function Update Magnitude: 0.32558

Collected Steps per Second: 21,442.83060
Overall Steps per Second: 10,467.35483

Timestep Collection Time: 2.33178
Timestep Consumption Time: 2.44497
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.77676

Cumulative Model Updates: 139,762
Cumulative Timesteps: 1,166,378,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1166378236...
Checkpoint 1166378236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,047.19538
Policy Entropy: 1.71774
Value Function Loss: 0.05174

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.30676
Value Function Update Magnitude: 0.32864

Collected Steps per Second: 21,271.01094
Overall Steps per Second: 10,647.85302

Timestep Collection Time: 2.35175
Timestep Consumption Time: 2.34629
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.69804

Cumulative Model Updates: 139,768
Cumulative Timesteps: 1,166,428,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,623.60881
Policy Entropy: 1.72580
Value Function Loss: 0.05740

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.31183
Value Function Update Magnitude: 0.31214

Collected Steps per Second: 21,585.94984
Overall Steps per Second: 10,563.12749

Timestep Collection Time: 2.31753
Timestep Consumption Time: 2.41838
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.73591

Cumulative Model Updates: 139,774
Cumulative Timesteps: 1,166,478,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1166478286...
Checkpoint 1166478286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,036.07710
Policy Entropy: 1.72710
Value Function Loss: 0.05649

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.30790
Value Function Update Magnitude: 0.28182

Collected Steps per Second: 21,253.55333
Overall Steps per Second: 10,462.23097

Timestep Collection Time: 2.35283
Timestep Consumption Time: 2.42684
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.77967

Cumulative Model Updates: 139,780
Cumulative Timesteps: 1,166,528,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,241.17226
Policy Entropy: 1.73499
Value Function Loss: 0.06143

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.30707
Value Function Update Magnitude: 0.25287

Collected Steps per Second: 21,241.52221
Overall Steps per Second: 10,446.74193

Timestep Collection Time: 2.35445
Timestep Consumption Time: 2.43288
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.78733

Cumulative Model Updates: 139,786
Cumulative Timesteps: 1,166,578,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1166578304...
Checkpoint 1166578304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,455.90870
Policy Entropy: 1.71563
Value Function Loss: 0.05561

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.31083
Value Function Update Magnitude: 0.28848

Collected Steps per Second: 20,253.77986
Overall Steps per Second: 10,136.76421

Timestep Collection Time: 2.46868
Timestep Consumption Time: 2.46387
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.93254

Cumulative Model Updates: 139,792
Cumulative Timesteps: 1,166,628,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,562.03105
Policy Entropy: 1.72045
Value Function Loss: 0.05351

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.30253
Value Function Update Magnitude: 0.28849

Collected Steps per Second: 21,218.82660
Overall Steps per Second: 10,482.91591

Timestep Collection Time: 2.35762
Timestep Consumption Time: 2.41452
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.77215

Cumulative Model Updates: 139,798
Cumulative Timesteps: 1,166,678,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1166678330...
Checkpoint 1166678330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,572.28165
Policy Entropy: 1.71079
Value Function Loss: 0.05545

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.30287
Value Function Update Magnitude: 0.29376

Collected Steps per Second: 21,441.65629
Overall Steps per Second: 10,402.72689

Timestep Collection Time: 2.33312
Timestep Consumption Time: 2.47581
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.80893

Cumulative Model Updates: 139,804
Cumulative Timesteps: 1,166,728,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,990.55981
Policy Entropy: 1.72902
Value Function Loss: 0.05779

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.30255
Value Function Update Magnitude: 0.31035

Collected Steps per Second: 21,489.91747
Overall Steps per Second: 10,414.70633

Timestep Collection Time: 2.32695
Timestep Consumption Time: 2.47453
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.80148

Cumulative Model Updates: 139,810
Cumulative Timesteps: 1,166,778,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1166778362...
Checkpoint 1166778362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,683.85575
Policy Entropy: 1.72488
Value Function Loss: 0.06133

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.29657
Value Function Update Magnitude: 0.28939

Collected Steps per Second: 21,582.52024
Overall Steps per Second: 10,575.21132

Timestep Collection Time: 2.31752
Timestep Consumption Time: 2.41222
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.72974

Cumulative Model Updates: 139,816
Cumulative Timesteps: 1,166,828,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,250.39090
Policy Entropy: 1.71953
Value Function Loss: 0.05937

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.31095
Value Function Update Magnitude: 0.27635

Collected Steps per Second: 22,052.64018
Overall Steps per Second: 10,463.79085

Timestep Collection Time: 2.26866
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.78125

Cumulative Model Updates: 139,822
Cumulative Timesteps: 1,166,878,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1166878410...
Checkpoint 1166878410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,150.75015
Policy Entropy: 1.70529
Value Function Loss: 0.05698

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.31285
Value Function Update Magnitude: 0.30264

Collected Steps per Second: 22,158.22454
Overall Steps per Second: 10,489.52772

Timestep Collection Time: 2.25713
Timestep Consumption Time: 2.51086
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.76799

Cumulative Model Updates: 139,828
Cumulative Timesteps: 1,166,928,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,068.37465
Policy Entropy: 1.69453
Value Function Loss: 0.05469

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.31430
Value Function Update Magnitude: 0.32456

Collected Steps per Second: 21,890.16867
Overall Steps per Second: 10,612.50275

Timestep Collection Time: 2.28495
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.71312

Cumulative Model Updates: 139,834
Cumulative Timesteps: 1,166,978,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1166978442...
Checkpoint 1166978442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,103.15140
Policy Entropy: 1.70417
Value Function Loss: 0.05808

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.31511
Value Function Update Magnitude: 0.32516

Collected Steps per Second: 21,662.00602
Overall Steps per Second: 10,541.10367

Timestep Collection Time: 2.30948
Timestep Consumption Time: 2.43651
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.74599

Cumulative Model Updates: 139,840
Cumulative Timesteps: 1,167,028,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,256.31967
Policy Entropy: 1.70053
Value Function Loss: 0.05873

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.32301
Value Function Update Magnitude: 0.34508

Collected Steps per Second: 21,913.68538
Overall Steps per Second: 10,483.24086

Timestep Collection Time: 2.28277
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.77181

Cumulative Model Updates: 139,846
Cumulative Timesteps: 1,167,078,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1167078494...
Checkpoint 1167078494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,896.67005
Policy Entropy: 1.70496
Value Function Loss: 0.05706

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.31938
Value Function Update Magnitude: 0.35865

Collected Steps per Second: 21,795.76077
Overall Steps per Second: 10,559.65005

Timestep Collection Time: 2.29421
Timestep Consumption Time: 2.44118
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.73538

Cumulative Model Updates: 139,852
Cumulative Timesteps: 1,167,128,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,214.47681
Policy Entropy: 1.69439
Value Function Loss: 0.05344

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.31671
Value Function Update Magnitude: 0.33872

Collected Steps per Second: 21,781.88706
Overall Steps per Second: 10,563.38407

Timestep Collection Time: 2.29677
Timestep Consumption Time: 2.43921
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.73598

Cumulative Model Updates: 139,858
Cumulative Timesteps: 1,167,178,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1167178526...
Checkpoint 1167178526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,878.71038
Policy Entropy: 1.71017
Value Function Loss: 0.05498

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.31474
Value Function Update Magnitude: 0.35133

Collected Steps per Second: 21,623.61999
Overall Steps per Second: 10,538.54527

Timestep Collection Time: 2.31432
Timestep Consumption Time: 2.43434
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.74866

Cumulative Model Updates: 139,864
Cumulative Timesteps: 1,167,228,570

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,201.85594
Policy Entropy: 1.71612
Value Function Loss: 0.05717

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.31523
Value Function Update Magnitude: 0.36201

Collected Steps per Second: 21,611.19581
Overall Steps per Second: 10,528.96622

Timestep Collection Time: 2.31380
Timestep Consumption Time: 2.43538
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74918

Cumulative Model Updates: 139,870
Cumulative Timesteps: 1,167,278,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1167278574...
Checkpoint 1167278574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,308.16729
Policy Entropy: 1.72419
Value Function Loss: 0.05561

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.30137
Value Function Update Magnitude: 0.36664

Collected Steps per Second: 21,592.08862
Overall Steps per Second: 10,541.22387

Timestep Collection Time: 2.31613
Timestep Consumption Time: 2.42810
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.74423

Cumulative Model Updates: 139,876
Cumulative Timesteps: 1,167,328,584

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,045.14499
Policy Entropy: 1.71075
Value Function Loss: 0.06032

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.30026
Value Function Update Magnitude: 0.37314

Collected Steps per Second: 22,130.26471
Overall Steps per Second: 10,502.32136

Timestep Collection Time: 2.26034
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.76295

Cumulative Model Updates: 139,882
Cumulative Timesteps: 1,167,378,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1167378606...
Checkpoint 1167378606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,827.58646
Policy Entropy: 1.69506
Value Function Loss: 0.05466

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.31028
Value Function Update Magnitude: 0.37424

Collected Steps per Second: 22,054.17626
Overall Steps per Second: 10,654.66820

Timestep Collection Time: 2.26714
Timestep Consumption Time: 2.42563
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.69278

Cumulative Model Updates: 139,888
Cumulative Timesteps: 1,167,428,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,174.56433
Policy Entropy: 1.69223
Value Function Loss: 0.05373

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.30318
Value Function Update Magnitude: 0.36159

Collected Steps per Second: 21,722.65851
Overall Steps per Second: 10,556.70502

Timestep Collection Time: 2.30220
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.73727

Cumulative Model Updates: 139,894
Cumulative Timesteps: 1,167,478,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1167478616...
Checkpoint 1167478616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,390.14379
Policy Entropy: 1.69063
Value Function Loss: 0.05164

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.30243
Value Function Update Magnitude: 0.34852

Collected Steps per Second: 22,092.70289
Overall Steps per Second: 10,573.24697

Timestep Collection Time: 2.26446
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.73156

Cumulative Model Updates: 139,900
Cumulative Timesteps: 1,167,528,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,513.92303
Policy Entropy: 1.68852
Value Function Loss: 0.06322

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.28924
Value Function Update Magnitude: 0.33594

Collected Steps per Second: 21,897.56898
Overall Steps per Second: 10,416.95408

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.51772
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.80217

Cumulative Model Updates: 139,906
Cumulative Timesteps: 1,167,578,668

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1167578668...
Checkpoint 1167578668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,014.62968
Policy Entropy: 1.68504
Value Function Loss: 0.06563

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.30698
Value Function Update Magnitude: 0.35106

Collected Steps per Second: 21,764.17961
Overall Steps per Second: 10,591.31962

Timestep Collection Time: 2.29965
Timestep Consumption Time: 2.42592
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.72557

Cumulative Model Updates: 139,912
Cumulative Timesteps: 1,167,628,718

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,997.77802
Policy Entropy: 1.68015
Value Function Loss: 0.06345

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.31847
Value Function Update Magnitude: 0.35161

Collected Steps per Second: 21,519.56537
Overall Steps per Second: 10,494.64516

Timestep Collection Time: 2.32347
Timestep Consumption Time: 2.44087
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.76433

Cumulative Model Updates: 139,918
Cumulative Timesteps: 1,167,678,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1167678718...
Checkpoint 1167678718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,571.70788
Policy Entropy: 1.68096
Value Function Loss: 0.05476

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.31040
Value Function Update Magnitude: 0.32946

Collected Steps per Second: 21,863.77678
Overall Steps per Second: 10,611.10545

Timestep Collection Time: 2.28689
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.71204

Cumulative Model Updates: 139,924
Cumulative Timesteps: 1,167,728,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,613.52101
Policy Entropy: 1.68740
Value Function Loss: 0.05391

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.30910
Value Function Update Magnitude: 0.31493

Collected Steps per Second: 21,775.17616
Overall Steps per Second: 10,576.20238

Timestep Collection Time: 2.29720
Timestep Consumption Time: 2.43247
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.72967

Cumulative Model Updates: 139,930
Cumulative Timesteps: 1,167,778,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1167778740...
Checkpoint 1167778740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,462.47855
Policy Entropy: 1.69258
Value Function Loss: 0.05399

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.30101
Value Function Update Magnitude: 0.29127

Collected Steps per Second: 21,633.67408
Overall Steps per Second: 10,518.13472

Timestep Collection Time: 2.31241
Timestep Consumption Time: 2.44375
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.75617

Cumulative Model Updates: 139,936
Cumulative Timesteps: 1,167,828,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,109.37629
Policy Entropy: 1.70643
Value Function Loss: 0.05779

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.29258
Value Function Update Magnitude: 0.27616

Collected Steps per Second: 22,003.56433
Overall Steps per Second: 10,593.00716

Timestep Collection Time: 2.27263
Timestep Consumption Time: 2.44803
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.72066

Cumulative Model Updates: 139,942
Cumulative Timesteps: 1,167,878,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1167878772...
Checkpoint 1167878772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,851.61709
Policy Entropy: 1.70561
Value Function Loss: 0.05558

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.30373
Value Function Update Magnitude: 0.31343

Collected Steps per Second: 21,782.84058
Overall Steps per Second: 10,555.75747

Timestep Collection Time: 2.29630
Timestep Consumption Time: 2.44234
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.73865

Cumulative Model Updates: 139,948
Cumulative Timesteps: 1,167,928,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,596.80656
Policy Entropy: 1.70549
Value Function Loss: 0.05374

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.28806
Value Function Update Magnitude: 0.33313

Collected Steps per Second: 21,306.75405
Overall Steps per Second: 10,457.14840

Timestep Collection Time: 2.34761
Timestep Consumption Time: 2.43572
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.78333

Cumulative Model Updates: 139,954
Cumulative Timesteps: 1,167,978,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1167978812...
Checkpoint 1167978812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,765.78064
Policy Entropy: 1.69603
Value Function Loss: 0.05173

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.29602
Value Function Update Magnitude: 0.33108

Collected Steps per Second: 21,132.33012
Overall Steps per Second: 10,580.36577

Timestep Collection Time: 2.36623
Timestep Consumption Time: 2.35988
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.72611

Cumulative Model Updates: 139,960
Cumulative Timesteps: 1,168,028,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,624.63512
Policy Entropy: 1.70190
Value Function Loss: 0.05585

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.30488
Value Function Update Magnitude: 0.33060

Collected Steps per Second: 21,689.34699
Overall Steps per Second: 10,522.27977

Timestep Collection Time: 2.30546
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.75220

Cumulative Model Updates: 139,966
Cumulative Timesteps: 1,168,078,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1168078820...
Checkpoint 1168078820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,831.68133
Policy Entropy: 1.70936
Value Function Loss: 0.05689

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.31158
Value Function Update Magnitude: 0.34331

Collected Steps per Second: 21,284.17773
Overall Steps per Second: 10,640.73738

Timestep Collection Time: 2.35020
Timestep Consumption Time: 2.35079
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.70099

Cumulative Model Updates: 139,972
Cumulative Timesteps: 1,168,128,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,474.22464
Policy Entropy: 1.70923
Value Function Loss: 0.05306

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.31319
Value Function Update Magnitude: 0.35397

Collected Steps per Second: 20,902.78708
Overall Steps per Second: 10,457.85572

Timestep Collection Time: 2.39260
Timestep Consumption Time: 2.38964
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.78224

Cumulative Model Updates: 139,978
Cumulative Timesteps: 1,168,178,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1168178854...
Checkpoint 1168178854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,406.14222
Policy Entropy: 1.71325
Value Function Loss: 0.05109

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.30860
Value Function Update Magnitude: 0.34210

Collected Steps per Second: 20,695.82545
Overall Steps per Second: 10,188.08212

Timestep Collection Time: 2.41682
Timestep Consumption Time: 2.49265
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.90946

Cumulative Model Updates: 139,984
Cumulative Timesteps: 1,168,228,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,037.93631
Policy Entropy: 1.70698
Value Function Loss: 0.05168

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.33561

Collected Steps per Second: 21,372.01154
Overall Steps per Second: 10,550.55316

Timestep Collection Time: 2.34082
Timestep Consumption Time: 2.40092
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.74174

Cumulative Model Updates: 139,990
Cumulative Timesteps: 1,168,278,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1168278900...
Checkpoint 1168278900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,972.76996
Policy Entropy: 1.70830
Value Function Loss: 0.05227

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.30908
Value Function Update Magnitude: 0.34768

Collected Steps per Second: 21,580.25540
Overall Steps per Second: 10,601.57540

Timestep Collection Time: 2.31786
Timestep Consumption Time: 2.40031
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.71817

Cumulative Model Updates: 139,996
Cumulative Timesteps: 1,168,328,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,392.17667
Policy Entropy: 1.70526
Value Function Loss: 0.05579

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.31107
Value Function Update Magnitude: 0.34880

Collected Steps per Second: 22,019.58374
Overall Steps per Second: 10,474.65761

Timestep Collection Time: 2.27116
Timestep Consumption Time: 2.50322
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.77438

Cumulative Model Updates: 140,002
Cumulative Timesteps: 1,168,378,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1168378930...
Checkpoint 1168378930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,584.26454
Policy Entropy: 1.70948
Value Function Loss: 0.05625

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.31398
Value Function Update Magnitude: 0.33610

Collected Steps per Second: 22,027.24730
Overall Steps per Second: 10,606.88536

Timestep Collection Time: 2.27128
Timestep Consumption Time: 2.44547
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.71675

Cumulative Model Updates: 140,008
Cumulative Timesteps: 1,168,428,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,274.61211
Policy Entropy: 1.70076
Value Function Loss: 0.05816

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.31685
Value Function Update Magnitude: 0.34287

Collected Steps per Second: 22,435.46575
Overall Steps per Second: 10,608.16927

Timestep Collection Time: 2.23040
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.71712

Cumulative Model Updates: 140,014
Cumulative Timesteps: 1,168,479,000

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1168479000...
Checkpoint 1168479000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,341.29624
Policy Entropy: 1.71307
Value Function Loss: 0.05895

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.31882
Value Function Update Magnitude: 0.36139

Collected Steps per Second: 21,211.67404
Overall Steps per Second: 10,430.91563

Timestep Collection Time: 2.35757
Timestep Consumption Time: 2.43664
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.79421

Cumulative Model Updates: 140,020
Cumulative Timesteps: 1,168,529,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,355.36827
Policy Entropy: 1.73186
Value Function Loss: 0.05796

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.31976
Value Function Update Magnitude: 0.37770

Collected Steps per Second: 21,727.23815
Overall Steps per Second: 10,555.76268

Timestep Collection Time: 2.30328
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.74092

Cumulative Model Updates: 140,026
Cumulative Timesteps: 1,168,579,052

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1168579052...
Checkpoint 1168579052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,447.90343
Policy Entropy: 1.74676
Value Function Loss: 0.06209

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.32306
Value Function Update Magnitude: 0.34360

Collected Steps per Second: 21,625.75038
Overall Steps per Second: 10,526.80922

Timestep Collection Time: 2.31363
Timestep Consumption Time: 2.43938
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.75301

Cumulative Model Updates: 140,032
Cumulative Timesteps: 1,168,629,086

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,506.96236
Policy Entropy: 1.72956
Value Function Loss: 0.05701

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.31959
Value Function Update Magnitude: 0.34043

Collected Steps per Second: 21,921.13957
Overall Steps per Second: 10,510.02453

Timestep Collection Time: 2.28136
Timestep Consumption Time: 2.47695
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.75831

Cumulative Model Updates: 140,038
Cumulative Timesteps: 1,168,679,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1168679096...
Checkpoint 1168679096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,452.78071
Policy Entropy: 1.70922
Value Function Loss: 0.06122

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.32101
Value Function Update Magnitude: 0.34588

Collected Steps per Second: 21,411.42564
Overall Steps per Second: 10,358.97643

Timestep Collection Time: 2.33735
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.83117

Cumulative Model Updates: 140,044
Cumulative Timesteps: 1,168,729,142

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,318.04017
Policy Entropy: 1.68320
Value Function Loss: 0.05671

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.31800
Value Function Update Magnitude: 0.34680

Collected Steps per Second: 22,245.42962
Overall Steps per Second: 10,642.35205

Timestep Collection Time: 2.24909
Timestep Consumption Time: 2.45213
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.70122

Cumulative Model Updates: 140,050
Cumulative Timesteps: 1,168,779,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1168779174...
Checkpoint 1168779174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,803.70394
Policy Entropy: 1.69314
Value Function Loss: 0.05937

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.31952
Value Function Update Magnitude: 0.35534

Collected Steps per Second: 21,610.96783
Overall Steps per Second: 10,359.07468

Timestep Collection Time: 2.31401
Timestep Consumption Time: 2.51345
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.82746

Cumulative Model Updates: 140,056
Cumulative Timesteps: 1,168,829,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,715.99480
Policy Entropy: 1.69786
Value Function Loss: 0.05870

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.31877
Value Function Update Magnitude: 0.36099

Collected Steps per Second: 22,205.71994
Overall Steps per Second: 10,518.99189

Timestep Collection Time: 2.25248
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.75502

Cumulative Model Updates: 140,062
Cumulative Timesteps: 1,168,879,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1168879200...
Checkpoint 1168879200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,971.59895
Policy Entropy: 1.71075
Value Function Loss: 0.05989

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.32071
Value Function Update Magnitude: 0.36595

Collected Steps per Second: 21,835.50794
Overall Steps per Second: 10,496.92518

Timestep Collection Time: 2.29086
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.76540

Cumulative Model Updates: 140,068
Cumulative Timesteps: 1,168,929,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,169.34235
Policy Entropy: 1.70014
Value Function Loss: 0.06113

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.32233
Value Function Update Magnitude: 0.36281

Collected Steps per Second: 22,377.09422
Overall Steps per Second: 10,527.40750

Timestep Collection Time: 2.23496
Timestep Consumption Time: 2.51568
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.75065

Cumulative Model Updates: 140,074
Cumulative Timesteps: 1,168,979,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1168979234...
Checkpoint 1168979234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,769.84173
Policy Entropy: 1.69323
Value Function Loss: 0.05980

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.32109
Value Function Update Magnitude: 0.36558

Collected Steps per Second: 21,522.43619
Overall Steps per Second: 10,508.04636

Timestep Collection Time: 2.32464
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.76130

Cumulative Model Updates: 140,080
Cumulative Timesteps: 1,169,029,266

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,968.76920
Policy Entropy: 1.69256
Value Function Loss: 0.05701

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.31764
Value Function Update Magnitude: 0.37460

Collected Steps per Second: 21,751.06745
Overall Steps per Second: 10,590.65634

Timestep Collection Time: 2.30012
Timestep Consumption Time: 2.42386
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.72398

Cumulative Model Updates: 140,086
Cumulative Timesteps: 1,169,079,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1169079296...
Checkpoint 1169079296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,587.42444
Policy Entropy: 1.69172
Value Function Loss: 0.06106

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08004
Policy Update Magnitude: 0.31964
Value Function Update Magnitude: 0.37904

Collected Steps per Second: 21,729.99987
Overall Steps per Second: 10,570.28605

Timestep Collection Time: 2.30235
Timestep Consumption Time: 2.43073
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.73308

Cumulative Model Updates: 140,092
Cumulative Timesteps: 1,169,129,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,591.91079
Policy Entropy: 1.69327
Value Function Loss: 0.05793

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.32147
Value Function Update Magnitude: 0.39915

Collected Steps per Second: 21,855.07300
Overall Steps per Second: 10,430.19050

Timestep Collection Time: 2.28816
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.79454

Cumulative Model Updates: 140,098
Cumulative Timesteps: 1,169,179,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1169179334...
Checkpoint 1169179334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,395.12603
Policy Entropy: 1.69200
Value Function Loss: 0.05946

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.32030
Value Function Update Magnitude: 0.41107

Collected Steps per Second: 21,060.24539
Overall Steps per Second: 10,202.38004

Timestep Collection Time: 2.37519
Timestep Consumption Time: 2.52779
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.90297

Cumulative Model Updates: 140,104
Cumulative Timesteps: 1,169,229,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,718.64923
Policy Entropy: 1.68615
Value Function Loss: 0.05380

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.32227
Value Function Update Magnitude: 0.39548

Collected Steps per Second: 21,832.24501
Overall Steps per Second: 10,478.45118

Timestep Collection Time: 2.29266
Timestep Consumption Time: 2.48419
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.77685

Cumulative Model Updates: 140,110
Cumulative Timesteps: 1,169,279,410

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1169279410...
Checkpoint 1169279410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,661.40502
Policy Entropy: 1.68941
Value Function Loss: 0.05389

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.30275
Value Function Update Magnitude: 0.37269

Collected Steps per Second: 21,951.84093
Overall Steps per Second: 10,564.00519

Timestep Collection Time: 2.27881
Timestep Consumption Time: 2.45652
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.73533

Cumulative Model Updates: 140,116
Cumulative Timesteps: 1,169,329,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,117.04863
Policy Entropy: 1.68925
Value Function Loss: 0.05457

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.29150
Value Function Update Magnitude: 0.35782

Collected Steps per Second: 22,057.28529
Overall Steps per Second: 10,463.79124

Timestep Collection Time: 2.26864
Timestep Consumption Time: 2.51357
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.78221

Cumulative Model Updates: 140,122
Cumulative Timesteps: 1,169,379,474

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1169379474...
Checkpoint 1169379474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,020.02435
Policy Entropy: 1.69461
Value Function Loss: 0.05565

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.29819
Value Function Update Magnitude: 0.34861

Collected Steps per Second: 21,841.40592
Overall Steps per Second: 10,589.06292

Timestep Collection Time: 2.29079
Timestep Consumption Time: 2.43428
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.72506

Cumulative Model Updates: 140,128
Cumulative Timesteps: 1,169,429,508

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,316.82483
Policy Entropy: 1.68864
Value Function Loss: 0.05408

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.31061
Value Function Update Magnitude: 0.34845

Collected Steps per Second: 22,111.23002
Overall Steps per Second: 10,628.82732

Timestep Collection Time: 2.26274
Timestep Consumption Time: 2.44446
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.70720

Cumulative Model Updates: 140,134
Cumulative Timesteps: 1,169,479,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1169479540...
Checkpoint 1169479540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,283.57162
Policy Entropy: 1.69369
Value Function Loss: 0.05169

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.31044
Value Function Update Magnitude: 0.32697

Collected Steps per Second: 21,807.17271
Overall Steps per Second: 10,532.41075

Timestep Collection Time: 2.29502
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.75181

Cumulative Model Updates: 140,140
Cumulative Timesteps: 1,169,529,588

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,241.85350
Policy Entropy: 1.69587
Value Function Loss: 0.05317

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.31816

Collected Steps per Second: 22,073.87936
Overall Steps per Second: 10,521.39928

Timestep Collection Time: 2.26603
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.75412

Cumulative Model Updates: 140,146
Cumulative Timesteps: 1,169,579,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1169579608...
Checkpoint 1169579608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,140.10419
Policy Entropy: 1.69719
Value Function Loss: 0.05459

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.31844
Value Function Update Magnitude: 0.31578

Collected Steps per Second: 21,704.85970
Overall Steps per Second: 10,556.54440

Timestep Collection Time: 2.30594
Timestep Consumption Time: 2.43520
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.74113

Cumulative Model Updates: 140,152
Cumulative Timesteps: 1,169,629,658

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,120.29913
Policy Entropy: 1.68816
Value Function Loss: 0.05417

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08333
Policy Update Magnitude: 0.31638
Value Function Update Magnitude: 0.29141

Collected Steps per Second: 21,447.79977
Overall Steps per Second: 10,497.54772

Timestep Collection Time: 2.33320
Timestep Consumption Time: 2.43382
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.76702

Cumulative Model Updates: 140,158
Cumulative Timesteps: 1,169,679,700

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1169679700...
Checkpoint 1169679700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,576.85687
Policy Entropy: 1.70453
Value Function Loss: 0.05141

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.31219
Value Function Update Magnitude: 0.30476

Collected Steps per Second: 21,477.29263
Overall Steps per Second: 10,361.89367

Timestep Collection Time: 2.32860
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.82653

Cumulative Model Updates: 140,164
Cumulative Timesteps: 1,169,729,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,576.62337
Policy Entropy: 1.70308
Value Function Loss: 0.05011

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.30950
Value Function Update Magnitude: 0.31344

Collected Steps per Second: 21,745.21955
Overall Steps per Second: 10,407.78260

Timestep Collection Time: 2.29954
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.80448

Cumulative Model Updates: 140,170
Cumulative Timesteps: 1,169,779,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1169779716...
Checkpoint 1169779716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,901.72136
Policy Entropy: 1.71278
Value Function Loss: 0.05357

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07942
Policy Update Magnitude: 0.30856
Value Function Update Magnitude: 0.31976

Collected Steps per Second: 21,524.67881
Overall Steps per Second: 10,517.19098

Timestep Collection Time: 2.32329
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.75488

Cumulative Model Updates: 140,176
Cumulative Timesteps: 1,169,829,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,573.53445
Policy Entropy: 1.68335
Value Function Loss: 0.05358

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07870
Policy Update Magnitude: 0.31233
Value Function Update Magnitude: 0.32972

Collected Steps per Second: 21,835.63452
Overall Steps per Second: 10,588.75649

Timestep Collection Time: 2.29112
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.72463

Cumulative Model Updates: 140,182
Cumulative Timesteps: 1,169,879,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1169879752...
Checkpoint 1169879752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,084.63270
Policy Entropy: 1.67572
Value Function Loss: 0.05578

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.31304
Value Function Update Magnitude: 0.33098

Collected Steps per Second: 21,428.80400
Overall Steps per Second: 10,603.62252

Timestep Collection Time: 2.33415
Timestep Consumption Time: 2.38292
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.71707

Cumulative Model Updates: 140,188
Cumulative Timesteps: 1,169,929,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,129.86979
Policy Entropy: 1.67636
Value Function Loss: 0.05257

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.31701
Value Function Update Magnitude: 0.33785

Collected Steps per Second: 21,492.87984
Overall Steps per Second: 10,513.64223

Timestep Collection Time: 2.32719
Timestep Consumption Time: 2.43025
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.75744

Cumulative Model Updates: 140,194
Cumulative Timesteps: 1,169,979,788

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1169979788...
Checkpoint 1169979788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,993.34819
Policy Entropy: 1.69025
Value Function Loss: 0.05370

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.31429
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 21,529.65138
Overall Steps per Second: 10,496.05431

Timestep Collection Time: 2.32284
Timestep Consumption Time: 2.44180
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.76465

Cumulative Model Updates: 140,200
Cumulative Timesteps: 1,170,029,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,809.05650
Policy Entropy: 1.72276
Value Function Loss: 0.05453

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.31310
Value Function Update Magnitude: 0.36662

Collected Steps per Second: 21,430.79946
Overall Steps per Second: 10,481.86717

Timestep Collection Time: 2.33486
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.77377

Cumulative Model Updates: 140,206
Cumulative Timesteps: 1,170,079,836

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1170079836...
Checkpoint 1170079836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,974.94265
Policy Entropy: 1.72303
Value Function Loss: 0.05609

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.30672
Value Function Update Magnitude: 0.38818

Collected Steps per Second: 21,264.85735
Overall Steps per Second: 10,610.69997

Timestep Collection Time: 2.35271
Timestep Consumption Time: 2.36234
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.71505

Cumulative Model Updates: 140,212
Cumulative Timesteps: 1,170,129,866

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,788.64754
Policy Entropy: 1.72264
Value Function Loss: 0.05241

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.29269
Value Function Update Magnitude: 0.37587

Collected Steps per Second: 21,014.62160
Overall Steps per Second: 10,436.07164

Timestep Collection Time: 2.37949
Timestep Consumption Time: 2.41197
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.79146

Cumulative Model Updates: 140,218
Cumulative Timesteps: 1,170,179,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1170179870...
Checkpoint 1170179870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,967.26856
Policy Entropy: 1.69873
Value Function Loss: 0.05089

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.28754
Value Function Update Magnitude: 0.35723

Collected Steps per Second: 21,297.59203
Overall Steps per Second: 10,331.19381

Timestep Collection Time: 2.34966
Timestep Consumption Time: 2.49412
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.84378

Cumulative Model Updates: 140,224
Cumulative Timesteps: 1,170,229,912

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,408.42614
Policy Entropy: 1.69957
Value Function Loss: 0.04774

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.29707
Value Function Update Magnitude: 0.34044

Collected Steps per Second: 21,534.45769
Overall Steps per Second: 10,412.77782

Timestep Collection Time: 2.32400
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.80621

Cumulative Model Updates: 140,230
Cumulative Timesteps: 1,170,279,958

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1170279958...
Checkpoint 1170279958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,444.24452
Policy Entropy: 1.67797
Value Function Loss: 0.05014

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.30650
Value Function Update Magnitude: 0.32748

Collected Steps per Second: 21,455.40156
Overall Steps per Second: 10,560.79686

Timestep Collection Time: 2.33051
Timestep Consumption Time: 2.40417
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.73468

Cumulative Model Updates: 140,236
Cumulative Timesteps: 1,170,329,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,606.70521
Policy Entropy: 1.68281
Value Function Loss: 0.05208

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.31213
Value Function Update Magnitude: 0.34179

Collected Steps per Second: 21,275.35020
Overall Steps per Second: 10,425.39958

Timestep Collection Time: 2.35051
Timestep Consumption Time: 2.44623
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.79675

Cumulative Model Updates: 140,242
Cumulative Timesteps: 1,170,379,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1170379968...
Checkpoint 1170379968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,022.91114
Policy Entropy: 1.68140
Value Function Loss: 0.04998

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.31009
Value Function Update Magnitude: 0.33993

Collected Steps per Second: 21,664.29891
Overall Steps per Second: 10,380.63454

Timestep Collection Time: 2.30887
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.81859

Cumulative Model Updates: 140,248
Cumulative Timesteps: 1,170,429,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,121.28463
Policy Entropy: 1.67680
Value Function Loss: 0.05187

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.30497
Value Function Update Magnitude: 0.32173

Collected Steps per Second: 21,686.26601
Overall Steps per Second: 10,340.47313

Timestep Collection Time: 2.30754
Timestep Consumption Time: 2.53189
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.83943

Cumulative Model Updates: 140,254
Cumulative Timesteps: 1,170,480,030

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1170480030...
Checkpoint 1170480030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,382.66760
Policy Entropy: 1.67654
Value Function Loss: 0.05149

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07400
Policy Update Magnitude: 0.30973
Value Function Update Magnitude: 0.32015

Collected Steps per Second: 22,021.88782
Overall Steps per Second: 10,563.94656

Timestep Collection Time: 2.27201
Timestep Consumption Time: 2.46429
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.73630

Cumulative Model Updates: 140,260
Cumulative Timesteps: 1,170,530,064

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,377.75630
Policy Entropy: 1.68607
Value Function Loss: 0.05121

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.30539
Value Function Update Magnitude: 0.32361

Collected Steps per Second: 22,077.97860
Overall Steps per Second: 10,484.10426

Timestep Collection Time: 2.26533
Timestep Consumption Time: 2.50513
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.77046

Cumulative Model Updates: 140,266
Cumulative Timesteps: 1,170,580,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1170580078...
Checkpoint 1170580078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,923.80394
Policy Entropy: 1.68360
Value Function Loss: 0.05113

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07531
Policy Update Magnitude: 0.30748
Value Function Update Magnitude: 0.33332

Collected Steps per Second: 21,935.88312
Overall Steps per Second: 10,600.68597

Timestep Collection Time: 2.28074
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.71951

Cumulative Model Updates: 140,272
Cumulative Timesteps: 1,170,630,108

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,851.94873
Policy Entropy: 1.68777
Value Function Loss: 0.05296

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.31668
Value Function Update Magnitude: 0.34139

Collected Steps per Second: 21,992.73342
Overall Steps per Second: 10,623.46300

Timestep Collection Time: 2.27348
Timestep Consumption Time: 2.43309
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.70656

Cumulative Model Updates: 140,278
Cumulative Timesteps: 1,170,680,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1170680108...
Checkpoint 1170680108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,868.85761
Policy Entropy: 1.68696
Value Function Loss: 0.05429

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.31825
Value Function Update Magnitude: 0.34944

Collected Steps per Second: 22,171.16338
Overall Steps per Second: 10,540.32814

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.48970
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.74596

Cumulative Model Updates: 140,284
Cumulative Timesteps: 1,170,730,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,077.29865
Policy Entropy: 1.70454
Value Function Loss: 0.05433

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.31340
Value Function Update Magnitude: 0.33899

Collected Steps per Second: 22,287.49866
Overall Steps per Second: 10,508.73300

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.51504
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.75890

Cumulative Model Updates: 140,290
Cumulative Timesteps: 1,170,780,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1170780142...
Checkpoint 1170780142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,319.83522
Policy Entropy: 1.68788
Value Function Loss: 0.05073

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.30692
Value Function Update Magnitude: 0.32804

Collected Steps per Second: 21,997.54509
Overall Steps per Second: 10,637.48364

Timestep Collection Time: 2.27389
Timestep Consumption Time: 2.42835
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.70224

Cumulative Model Updates: 140,296
Cumulative Timesteps: 1,170,830,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,848.66667
Policy Entropy: 1.67363
Value Function Loss: 0.05196

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.30589
Value Function Update Magnitude: 0.32856

Collected Steps per Second: 21,458.83357
Overall Steps per Second: 10,412.87932

Timestep Collection Time: 2.33172
Timestep Consumption Time: 2.47348
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.80520

Cumulative Model Updates: 140,302
Cumulative Timesteps: 1,170,880,198

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1170880198...
Checkpoint 1170880198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,836.22368
Policy Entropy: 1.69067
Value Function Loss: 0.05781

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.31436
Value Function Update Magnitude: 0.34785

Collected Steps per Second: 21,598.26002
Overall Steps per Second: 10,572.45227

Timestep Collection Time: 2.31648
Timestep Consumption Time: 2.41582
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.73230

Cumulative Model Updates: 140,308
Cumulative Timesteps: 1,170,930,230

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,212.73886
Policy Entropy: 1.70296
Value Function Loss: 0.05893

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.31800
Value Function Update Magnitude: 0.37175

Collected Steps per Second: 21,794.91815
Overall Steps per Second: 10,597.44718

Timestep Collection Time: 2.29558
Timestep Consumption Time: 2.42556
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.72114

Cumulative Model Updates: 140,314
Cumulative Timesteps: 1,170,980,262

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1170980262...
Checkpoint 1170980262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,962.68441
Policy Entropy: 1.72686
Value Function Loss: 0.05642

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.31253
Value Function Update Magnitude: 0.36324

Collected Steps per Second: 21,868.74677
Overall Steps per Second: 10,616.38977

Timestep Collection Time: 2.28692
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.71083

Cumulative Model Updates: 140,320
Cumulative Timesteps: 1,171,030,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,651.04162
Policy Entropy: 1.70739
Value Function Loss: 0.05587

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.30971
Value Function Update Magnitude: 0.34004

Collected Steps per Second: 21,893.46810
Overall Steps per Second: 10,421.76044

Timestep Collection Time: 2.28470
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.79957

Cumulative Model Updates: 140,326
Cumulative Timesteps: 1,171,080,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1171080294...
Checkpoint 1171080294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,217.78017
Policy Entropy: 1.70387
Value Function Loss: 0.05426

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.30828
Value Function Update Magnitude: 0.31677

Collected Steps per Second: 21,882.32239
Overall Steps per Second: 10,568.49620

Timestep Collection Time: 2.28614
Timestep Consumption Time: 2.44736
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.73350

Cumulative Model Updates: 140,332
Cumulative Timesteps: 1,171,130,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,298.93239
Policy Entropy: 1.69271
Value Function Loss: 0.05833

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.31250
Value Function Update Magnitude: 0.32527

Collected Steps per Second: 22,196.66196
Overall Steps per Second: 10,507.79888

Timestep Collection Time: 2.25367
Timestep Consumption Time: 2.50698
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.76065

Cumulative Model Updates: 140,338
Cumulative Timesteps: 1,171,180,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1171180344...
Checkpoint 1171180344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,489.34285
Policy Entropy: 1.69904
Value Function Loss: 0.05337

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.31822
Value Function Update Magnitude: 0.31648

Collected Steps per Second: 21,805.59709
Overall Steps per Second: 10,589.09287

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.42953
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.72316

Cumulative Model Updates: 140,344
Cumulative Timesteps: 1,171,230,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,213.50992
Policy Entropy: 1.68332
Value Function Loss: 0.05446

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.31312
Value Function Update Magnitude: 0.33394

Collected Steps per Second: 21,286.26709
Overall Steps per Second: 10,513.41586

Timestep Collection Time: 2.34912
Timestep Consumption Time: 2.40709
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.75621

Cumulative Model Updates: 140,350
Cumulative Timesteps: 1,171,280,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1171280362...
Checkpoint 1171280362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,448.18390
Policy Entropy: 1.67980
Value Function Loss: 0.05085

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.31466
Value Function Update Magnitude: 0.31832

Collected Steps per Second: 21,314.91887
Overall Steps per Second: 10,648.53581

Timestep Collection Time: 2.34662
Timestep Consumption Time: 2.35055
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.69717

Cumulative Model Updates: 140,356
Cumulative Timesteps: 1,171,330,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,290.52235
Policy Entropy: 1.66846
Value Function Loss: 0.05419

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.31536
Value Function Update Magnitude: 0.33103

Collected Steps per Second: 21,189.55808
Overall Steps per Second: 10,429.02312

Timestep Collection Time: 2.36031
Timestep Consumption Time: 2.43534
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.79566

Cumulative Model Updates: 140,362
Cumulative Timesteps: 1,171,380,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1171380394...
Checkpoint 1171380394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,469.74425
Policy Entropy: 1.68759
Value Function Loss: 0.05400

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.31096
Value Function Update Magnitude: 0.33072

Collected Steps per Second: 20,930.33318
Overall Steps per Second: 10,537.07260

Timestep Collection Time: 2.38974
Timestep Consumption Time: 2.35712
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.74686

Cumulative Model Updates: 140,368
Cumulative Timesteps: 1,171,430,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,459.62160
Policy Entropy: 1.68522
Value Function Loss: 0.05396

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.29015
Value Function Update Magnitude: 0.32173

Collected Steps per Second: 20,784.04940
Overall Steps per Second: 10,500.09401

Timestep Collection Time: 2.40579
Timestep Consumption Time: 2.35627
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.76205

Cumulative Model Updates: 140,374
Cumulative Timesteps: 1,171,480,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1171480414...
Checkpoint 1171480414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,239.04452
Policy Entropy: 1.70348
Value Function Loss: 0.05912

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.28630
Value Function Update Magnitude: 0.33559

Collected Steps per Second: 20,952.70125
Overall Steps per Second: 10,241.83048

Timestep Collection Time: 2.38766
Timestep Consumption Time: 2.49701
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.88467

Cumulative Model Updates: 140,380
Cumulative Timesteps: 1,171,530,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,799.11365
Policy Entropy: 1.69546
Value Function Loss: 0.06088

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.30683
Value Function Update Magnitude: 0.35789

Collected Steps per Second: 21,568.04407
Overall Steps per Second: 10,432.44804

Timestep Collection Time: 2.31880
Timestep Consumption Time: 2.47509
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.79389

Cumulative Model Updates: 140,386
Cumulative Timesteps: 1,171,580,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1171580454...
Checkpoint 1171580454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,529.74398
Policy Entropy: 1.69787
Value Function Loss: 0.06136

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.30590
Value Function Update Magnitude: 0.36882

Collected Steps per Second: 21,968.89740
Overall Steps per Second: 10,594.73480

Timestep Collection Time: 2.27594
Timestep Consumption Time: 2.44338
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.71933

Cumulative Model Updates: 140,392
Cumulative Timesteps: 1,171,630,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,563.75271
Policy Entropy: 1.70008
Value Function Loss: 0.05898

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.29938
Value Function Update Magnitude: 0.39573

Collected Steps per Second: 21,891.80452
Overall Steps per Second: 10,525.83354

Timestep Collection Time: 2.28579
Timestep Consumption Time: 2.46823
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.75402

Cumulative Model Updates: 140,398
Cumulative Timesteps: 1,171,680,494

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1171680494...
Checkpoint 1171680494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,552.27928
Policy Entropy: 1.69662
Value Function Loss: 0.05444

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.31315
Value Function Update Magnitude: 0.36373

Collected Steps per Second: 21,911.48904
Overall Steps per Second: 10,634.56361

Timestep Collection Time: 2.28346
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.70485

Cumulative Model Updates: 140,404
Cumulative Timesteps: 1,171,730,528

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,237.63286
Policy Entropy: 1.71082
Value Function Loss: 0.05334

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.31139
Value Function Update Magnitude: 0.34032

Collected Steps per Second: 21,971.66969
Overall Steps per Second: 10,438.84571

Timestep Collection Time: 2.27693
Timestep Consumption Time: 2.51555
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.79248

Cumulative Model Updates: 140,410
Cumulative Timesteps: 1,171,780,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1171780556...
Checkpoint 1171780556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,011.66351
Policy Entropy: 1.70262
Value Function Loss: 0.05181

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.30888
Value Function Update Magnitude: 0.32712

Collected Steps per Second: 22,081.81319
Overall Steps per Second: 10,615.39780

Timestep Collection Time: 2.26467
Timestep Consumption Time: 2.44622
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.71089

Cumulative Model Updates: 140,416
Cumulative Timesteps: 1,171,830,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,045.25693
Policy Entropy: 1.70503
Value Function Loss: 0.05140

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.30666
Value Function Update Magnitude: 0.31919

Collected Steps per Second: 22,082.20976
Overall Steps per Second: 10,508.06130

Timestep Collection Time: 2.26472
Timestep Consumption Time: 2.49448
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.75920

Cumulative Model Updates: 140,422
Cumulative Timesteps: 1,171,880,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1171880574...
Checkpoint 1171880574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,671.77538
Policy Entropy: 1.70608
Value Function Loss: 0.05137

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08115
Policy Update Magnitude: 0.30261
Value Function Update Magnitude: 0.32451

Collected Steps per Second: 21,840.23112
Overall Steps per Second: 10,596.21277

Timestep Collection Time: 2.29064
Timestep Consumption Time: 2.43067
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.72131

Cumulative Model Updates: 140,428
Cumulative Timesteps: 1,171,930,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,215.93686
Policy Entropy: 1.70764
Value Function Loss: 0.05183

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.30945
Value Function Update Magnitude: 0.32096

Collected Steps per Second: 21,289.23479
Overall Steps per Second: 10,439.09332

Timestep Collection Time: 2.34936
Timestep Consumption Time: 2.44186
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.79122

Cumulative Model Updates: 140,434
Cumulative Timesteps: 1,171,980,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1171980618...
Checkpoint 1171980618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,700.57291
Policy Entropy: 1.70879
Value Function Loss: 0.05204

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07621
Policy Update Magnitude: 0.31033
Value Function Update Magnitude: 0.32976

Collected Steps per Second: 21,348.38649
Overall Steps per Second: 10,295.73216

Timestep Collection Time: 2.34313
Timestep Consumption Time: 2.51539
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.85852

Cumulative Model Updates: 140,440
Cumulative Timesteps: 1,172,030,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,626.54605
Policy Entropy: 1.69962
Value Function Loss: 0.05229

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.33642

Collected Steps per Second: 21,630.68736
Overall Steps per Second: 10,439.67960

Timestep Collection Time: 2.31320
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.79287

Cumulative Model Updates: 140,446
Cumulative Timesteps: 1,172,080,676

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1172080676...
Checkpoint 1172080676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,591.62892
Policy Entropy: 1.70802
Value Function Loss: 0.04724

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.30643
Value Function Update Magnitude: 0.33823

Collected Steps per Second: 21,116.47793
Overall Steps per Second: 10,265.98179

Timestep Collection Time: 2.36848
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.87182

Cumulative Model Updates: 140,452
Cumulative Timesteps: 1,172,130,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,091.87419
Policy Entropy: 1.71449
Value Function Loss: 0.05325

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.30821
Value Function Update Magnitude: 0.33767

Collected Steps per Second: 21,796.07713
Overall Steps per Second: 10,410.33292

Timestep Collection Time: 2.29417
Timestep Consumption Time: 2.50913
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.80330

Cumulative Model Updates: 140,458
Cumulative Timesteps: 1,172,180,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1172180694...
Checkpoint 1172180694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,780.44111
Policy Entropy: 1.71673
Value Function Loss: 0.04939

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.31025
Value Function Update Magnitude: 0.34204

Collected Steps per Second: 22,200.93991
Overall Steps per Second: 10,647.18079

Timestep Collection Time: 2.25216
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.69608

Cumulative Model Updates: 140,464
Cumulative Timesteps: 1,172,230,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,109.87379
Policy Entropy: 1.72296
Value Function Loss: 0.05587

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07918
Policy Update Magnitude: 0.31063
Value Function Update Magnitude: 0.34864

Collected Steps per Second: 20,728.00876
Overall Steps per Second: 10,092.59126

Timestep Collection Time: 2.41412
Timestep Consumption Time: 2.54397
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.95809

Cumulative Model Updates: 140,470
Cumulative Timesteps: 1,172,280,734

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1172280734...
Checkpoint 1172280734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,361.69774
Policy Entropy: 1.71157
Value Function Loss: 0.05539

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.31435
Value Function Update Magnitude: 0.34410

Collected Steps per Second: 21,633.50530
Overall Steps per Second: 10,501.74941

Timestep Collection Time: 2.31141
Timestep Consumption Time: 2.45008
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.76149

Cumulative Model Updates: 140,476
Cumulative Timesteps: 1,172,330,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,606.49419
Policy Entropy: 1.69848
Value Function Loss: 0.05978

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.32013
Value Function Update Magnitude: 0.36220

Collected Steps per Second: 21,950.37956
Overall Steps per Second: 10,455.40214

Timestep Collection Time: 2.27887
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.78432

Cumulative Model Updates: 140,482
Cumulative Timesteps: 1,172,380,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1172380760...
Checkpoint 1172380760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,493.56593
Policy Entropy: 1.67996
Value Function Loss: 0.05479

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.31696
Value Function Update Magnitude: 0.36803

Collected Steps per Second: 22,063.71576
Overall Steps per Second: 10,649.04927

Timestep Collection Time: 2.26680
Timestep Consumption Time: 2.42977
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.69657

Cumulative Model Updates: 140,488
Cumulative Timesteps: 1,172,430,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,984.65506
Policy Entropy: 1.69445
Value Function Loss: 0.05499

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.31358
Value Function Update Magnitude: 0.36138

Collected Steps per Second: 21,917.50001
Overall Steps per Second: 10,471.67977

Timestep Collection Time: 2.28274
Timestep Consumption Time: 2.49510
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.77784

Cumulative Model Updates: 140,494
Cumulative Timesteps: 1,172,480,806

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1172480806...
Checkpoint 1172480806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,353.97961
Policy Entropy: 1.69142
Value Function Loss: 0.05120

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.30949
Value Function Update Magnitude: 0.36113

Collected Steps per Second: 21,656.80629
Overall Steps per Second: 10,572.56917

Timestep Collection Time: 2.30985
Timestep Consumption Time: 2.42164
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.73149

Cumulative Model Updates: 140,500
Cumulative Timesteps: 1,172,530,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,524.18410
Policy Entropy: 1.68681
Value Function Loss: 0.04870

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.30748
Value Function Update Magnitude: 0.35934

Collected Steps per Second: 22,036.87405
Overall Steps per Second: 10,534.33040

Timestep Collection Time: 2.26965
Timestep Consumption Time: 2.47825
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.74791

Cumulative Model Updates: 140,506
Cumulative Timesteps: 1,172,580,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1172580846...
Checkpoint 1172580846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,342.07783
Policy Entropy: 1.68562
Value Function Loss: 0.04917

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.30984
Value Function Update Magnitude: 0.35055

Collected Steps per Second: 21,212.45058
Overall Steps per Second: 10,288.67826

Timestep Collection Time: 2.35805
Timestep Consumption Time: 2.50361
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.86165

Cumulative Model Updates: 140,512
Cumulative Timesteps: 1,172,630,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,610.94208
Policy Entropy: 1.69155
Value Function Loss: 0.05080

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.31092
Value Function Update Magnitude: 0.35307

Collected Steps per Second: 21,524.97442
Overall Steps per Second: 10,372.50598

Timestep Collection Time: 2.32511
Timestep Consumption Time: 2.49995
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.82506

Cumulative Model Updates: 140,518
Cumulative Timesteps: 1,172,680,914

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1172680914...
Checkpoint 1172680914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,663.38747
Policy Entropy: 1.68920
Value Function Loss: 0.04987

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.30512
Value Function Update Magnitude: 0.36380

Collected Steps per Second: 21,817.75153
Overall Steps per Second: 10,602.79668

Timestep Collection Time: 2.29190
Timestep Consumption Time: 2.42422
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.71611

Cumulative Model Updates: 140,524
Cumulative Timesteps: 1,172,730,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,471.82522
Policy Entropy: 1.68501
Value Function Loss: 0.05568

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.30491
Value Function Update Magnitude: 0.35480

Collected Steps per Second: 21,618.85084
Overall Steps per Second: 10,493.45570

Timestep Collection Time: 2.31372
Timestep Consumption Time: 2.45306
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.76678

Cumulative Model Updates: 140,530
Cumulative Timesteps: 1,172,780,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1172780938...
Checkpoint 1172780938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,136.18052
Policy Entropy: 1.69151
Value Function Loss: 0.05972

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.32488
Value Function Update Magnitude: 0.38505

Collected Steps per Second: 21,429.73441
Overall Steps per Second: 10,624.47391

Timestep Collection Time: 2.33451
Timestep Consumption Time: 2.37424
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.70875

Cumulative Model Updates: 140,536
Cumulative Timesteps: 1,172,830,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,560.57192
Policy Entropy: 1.69530
Value Function Loss: 0.06140

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.32820
Value Function Update Magnitude: 0.38897

Collected Steps per Second: 21,608.34249
Overall Steps per Second: 10,543.20878

Timestep Collection Time: 2.31503
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.74467

Cumulative Model Updates: 140,542
Cumulative Timesteps: 1,172,880,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1172880990...
Checkpoint 1172880990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,884.21871
Policy Entropy: 1.71161
Value Function Loss: 0.06619

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08685
Policy Update Magnitude: 0.32785
Value Function Update Magnitude: 0.34353

Collected Steps per Second: 21,115.49904
Overall Steps per Second: 10,609.70077

Timestep Collection Time: 2.36859
Timestep Consumption Time: 2.34540
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.71399

Cumulative Model Updates: 140,548
Cumulative Timesteps: 1,172,931,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,174.65547
Policy Entropy: 1.69378
Value Function Loss: 0.06116

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.32245
Value Function Update Magnitude: 0.29382

Collected Steps per Second: 21,810.66456
Overall Steps per Second: 10,751.04592

Timestep Collection Time: 2.29310
Timestep Consumption Time: 2.35891
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.65201

Cumulative Model Updates: 140,554
Cumulative Timesteps: 1,172,981,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1172981018...
Checkpoint 1172981018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,757.85954
Policy Entropy: 1.68255
Value Function Loss: 0.05992

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.31656
Value Function Update Magnitude: 0.26910

Collected Steps per Second: 21,298.72661
Overall Steps per Second: 10,367.07965

Timestep Collection Time: 2.34812
Timestep Consumption Time: 2.47599
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.82412

Cumulative Model Updates: 140,560
Cumulative Timesteps: 1,173,031,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,275.16950
Policy Entropy: 1.67336
Value Function Loss: 0.05139

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.30510

Collected Steps per Second: 21,811.67590
Overall Steps per Second: 10,498.37270

Timestep Collection Time: 2.29263
Timestep Consumption Time: 2.47059
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.76321

Cumulative Model Updates: 140,566
Cumulative Timesteps: 1,173,081,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1173081036...
Checkpoint 1173081036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,999.63747
Policy Entropy: 1.69010
Value Function Loss: 0.05676

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.32005
Value Function Update Magnitude: 0.35231

Collected Steps per Second: 21,433.23386
Overall Steps per Second: 10,574.80252

Timestep Collection Time: 2.33385
Timestep Consumption Time: 2.39645
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.73030

Cumulative Model Updates: 140,572
Cumulative Timesteps: 1,173,131,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,726.05322
Policy Entropy: 1.69058
Value Function Loss: 0.05423

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.31747
Value Function Update Magnitude: 0.37478

Collected Steps per Second: 21,642.01391
Overall Steps per Second: 10,384.59248

Timestep Collection Time: 2.31078
Timestep Consumption Time: 2.50501
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.81579

Cumulative Model Updates: 140,578
Cumulative Timesteps: 1,173,181,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1173181068...
Checkpoint 1173181068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,017.62251
Policy Entropy: 1.69287
Value Function Loss: 0.05788

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.31531
Value Function Update Magnitude: 0.37729

Collected Steps per Second: 21,397.27519
Overall Steps per Second: 10,368.47979

Timestep Collection Time: 2.33684
Timestep Consumption Time: 2.48566
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.82250

Cumulative Model Updates: 140,584
Cumulative Timesteps: 1,173,231,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,841.43139
Policy Entropy: 1.68291
Value Function Loss: 0.05473

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.31905
Value Function Update Magnitude: 0.37132

Collected Steps per Second: 22,199.81207
Overall Steps per Second: 10,450.16002

Timestep Collection Time: 2.25245
Timestep Consumption Time: 2.53255
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.78500

Cumulative Model Updates: 140,590
Cumulative Timesteps: 1,173,281,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1173281074...
Checkpoint 1173281074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,537.74332
Policy Entropy: 1.68856
Value Function Loss: 0.05028

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08402
Policy Update Magnitude: 0.31364
Value Function Update Magnitude: 0.36742

Collected Steps per Second: 22,044.12555
Overall Steps per Second: 10,407.17202

Timestep Collection Time: 2.26827
Timestep Consumption Time: 2.53630
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.80457

Cumulative Model Updates: 140,596
Cumulative Timesteps: 1,173,331,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,437.83873
Policy Entropy: 1.69394
Value Function Loss: 0.04607

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.30270
Value Function Update Magnitude: 0.35675

Collected Steps per Second: 22,137.88573
Overall Steps per Second: 10,526.18711

Timestep Collection Time: 2.25984
Timestep Consumption Time: 2.49288
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.75272

Cumulative Model Updates: 140,602
Cumulative Timesteps: 1,173,381,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1173381104...
Checkpoint 1173381104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,857.71554
Policy Entropy: 1.70402
Value Function Loss: 0.04546

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.30178
Value Function Update Magnitude: 0.33564

Collected Steps per Second: 21,815.78085
Overall Steps per Second: 10,671.48912

Timestep Collection Time: 2.29302
Timestep Consumption Time: 2.39461
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.68763

Cumulative Model Updates: 140,608
Cumulative Timesteps: 1,173,431,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,036.96328
Policy Entropy: 1.68534
Value Function Loss: 0.05416

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.30893
Value Function Update Magnitude: 0.32493

Collected Steps per Second: 22,465.08733
Overall Steps per Second: 10,614.92680

Timestep Collection Time: 2.22585
Timestep Consumption Time: 2.48487
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.71072

Cumulative Model Updates: 140,614
Cumulative Timesteps: 1,173,481,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1173481132...
Checkpoint 1173481132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,112.57000
Policy Entropy: 1.67653
Value Function Loss: 0.05966

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.31667
Value Function Update Magnitude: 0.30777

Collected Steps per Second: 21,726.59404
Overall Steps per Second: 10,451.17804

Timestep Collection Time: 2.30234
Timestep Consumption Time: 2.48392
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.78625

Cumulative Model Updates: 140,620
Cumulative Timesteps: 1,173,531,154

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,813.03381
Policy Entropy: 1.68903
Value Function Loss: 0.06355

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.31923
Value Function Update Magnitude: 0.32068

Collected Steps per Second: 21,948.89282
Overall Steps per Second: 10,433.09919

Timestep Collection Time: 2.27875
Timestep Consumption Time: 2.51523
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.79397

Cumulative Model Updates: 140,626
Cumulative Timesteps: 1,173,581,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1173581170...
Checkpoint 1173581170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,775.60870
Policy Entropy: 1.71028
Value Function Loss: 0.06362

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.32788
Value Function Update Magnitude: 0.35648

Collected Steps per Second: 21,126.51723
Overall Steps per Second: 10,335.68940

Timestep Collection Time: 2.36736
Timestep Consumption Time: 2.47160
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.83896

Cumulative Model Updates: 140,632
Cumulative Timesteps: 1,173,631,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,885.82890
Policy Entropy: 1.71320
Value Function Loss: 0.06016

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.32634
Value Function Update Magnitude: 0.37416

Collected Steps per Second: 21,817.81059
Overall Steps per Second: 10,392.77737

Timestep Collection Time: 2.29216
Timestep Consumption Time: 2.51983
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.81200

Cumulative Model Updates: 140,638
Cumulative Timesteps: 1,173,681,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1173681194...
Checkpoint 1173681194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,283.56213
Policy Entropy: 1.70559
Value Function Loss: 0.05546

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.31961
Value Function Update Magnitude: 0.35747

Collected Steps per Second: 21,323.06048
Overall Steps per Second: 10,478.70693

Timestep Collection Time: 2.34591
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.77368

Cumulative Model Updates: 140,644
Cumulative Timesteps: 1,173,731,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,316.55867
Policy Entropy: 1.70403
Value Function Loss: 0.05465

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.31701
Value Function Update Magnitude: 0.34864

Collected Steps per Second: 21,847.94691
Overall Steps per Second: 10,579.85506

Timestep Collection Time: 2.28864
Timestep Consumption Time: 2.43752
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.72615

Cumulative Model Updates: 140,650
Cumulative Timesteps: 1,173,781,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1173781218...
Checkpoint 1173781218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,555.20473
Policy Entropy: 1.71186
Value Function Loss: 0.05025

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.31391
Value Function Update Magnitude: 0.33884

Collected Steps per Second: 21,426.93148
Overall Steps per Second: 10,526.14871

Timestep Collection Time: 2.33370
Timestep Consumption Time: 2.41676
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.75046

Cumulative Model Updates: 140,656
Cumulative Timesteps: 1,173,831,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,933.40554
Policy Entropy: 1.71870
Value Function Loss: 0.04664

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.30872
Value Function Update Magnitude: 0.32335

Collected Steps per Second: 22,263.67676
Overall Steps per Second: 10,500.15671

Timestep Collection Time: 2.24680
Timestep Consumption Time: 2.51713
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.76393

Cumulative Model Updates: 140,662
Cumulative Timesteps: 1,173,881,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1173881244...
Checkpoint 1173881244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,328.01346
Policy Entropy: 1.72159
Value Function Loss: 0.04652

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.30491
Value Function Update Magnitude: 0.28962

Collected Steps per Second: 22,074.49772
Overall Steps per Second: 10,582.65271

Timestep Collection Time: 2.26506
Timestep Consumption Time: 2.45966
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.72471

Cumulative Model Updates: 140,668
Cumulative Timesteps: 1,173,931,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,146.95901
Policy Entropy: 1.71597
Value Function Loss: 0.04854

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.30264
Value Function Update Magnitude: 0.29449

Collected Steps per Second: 22,162.81632
Overall Steps per Second: 10,483.80553

Timestep Collection Time: 2.25675
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.77079

Cumulative Model Updates: 140,674
Cumulative Timesteps: 1,173,981,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1173981260...
Checkpoint 1173981260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,687.33660
Policy Entropy: 1.73391
Value Function Loss: 0.05196

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.30492
Value Function Update Magnitude: 0.32824

Collected Steps per Second: 21,898.10739
Overall Steps per Second: 10,601.59483

Timestep Collection Time: 2.28431
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.71835

Cumulative Model Updates: 140,680
Cumulative Timesteps: 1,174,031,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,442.81822
Policy Entropy: 1.72945
Value Function Loss: 0.05213

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.30851
Value Function Update Magnitude: 0.31606

Collected Steps per Second: 22,302.29378
Overall Steps per Second: 10,517.70807

Timestep Collection Time: 2.24255
Timestep Consumption Time: 2.51267
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.75522

Cumulative Model Updates: 140,686
Cumulative Timesteps: 1,174,081,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1174081296...
Checkpoint 1174081296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,497.33511
Policy Entropy: 1.72798
Value Function Loss: 0.05181

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.30706
Value Function Update Magnitude: 0.31240

Collected Steps per Second: 21,792.54204
Overall Steps per Second: 10,578.30798

Timestep Collection Time: 2.29473
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.72741

Cumulative Model Updates: 140,692
Cumulative Timesteps: 1,174,131,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,640.89922
Policy Entropy: 1.71538
Value Function Loss: 0.05065

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.29416
Value Function Update Magnitude: 0.32064

Collected Steps per Second: 21,781.81156
Overall Steps per Second: 10,569.44026

Timestep Collection Time: 2.29742
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.73459

Cumulative Model Updates: 140,698
Cumulative Timesteps: 1,174,181,346

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1174181346...
Checkpoint 1174181346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,141.28515
Policy Entropy: 1.70363
Value Function Loss: 0.05307

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.28176
Value Function Update Magnitude: 0.33280

Collected Steps per Second: 21,732.76753
Overall Steps per Second: 10,563.30077

Timestep Collection Time: 2.30104
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.73413

Cumulative Model Updates: 140,704
Cumulative Timesteps: 1,174,231,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,697.12170
Policy Entropy: 1.70619
Value Function Loss: 0.05099

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.28789
Value Function Update Magnitude: 0.33684

Collected Steps per Second: 21,714.35666
Overall Steps per Second: 10,459.14973

Timestep Collection Time: 2.30345
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.78222

Cumulative Model Updates: 140,710
Cumulative Timesteps: 1,174,281,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1174281372...
Checkpoint 1174281372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,578.75771
Policy Entropy: 1.69332
Value Function Loss: 0.05258

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.29571
Value Function Update Magnitude: 0.32445

Collected Steps per Second: 21,374.60038
Overall Steps per Second: 10,301.64319

Timestep Collection Time: 2.34110
Timestep Consumption Time: 2.51638
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.85748

Cumulative Model Updates: 140,716
Cumulative Timesteps: 1,174,331,412

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,495.93940
Policy Entropy: 1.70136
Value Function Loss: 0.05579

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.31045
Value Function Update Magnitude: 0.31567

Collected Steps per Second: 22,291.98580
Overall Steps per Second: 10,448.92250

Timestep Collection Time: 2.24421
Timestep Consumption Time: 2.54365
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.78786

Cumulative Model Updates: 140,722
Cumulative Timesteps: 1,174,381,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1174381440...
Checkpoint 1174381440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,059.13601
Policy Entropy: 1.69792
Value Function Loss: 0.05789

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.31770
Value Function Update Magnitude: 0.33312

Collected Steps per Second: 21,968.48077
Overall Steps per Second: 10,429.56429

Timestep Collection Time: 2.27653
Timestep Consumption Time: 2.51868
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.79521

Cumulative Model Updates: 140,728
Cumulative Timesteps: 1,174,431,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,555.39606
Policy Entropy: 1.70665
Value Function Loss: 0.05641

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.31628
Value Function Update Magnitude: 0.33950

Collected Steps per Second: 22,154.91743
Overall Steps per Second: 10,656.77580

Timestep Collection Time: 2.25756
Timestep Consumption Time: 2.43579
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.69335

Cumulative Model Updates: 140,734
Cumulative Timesteps: 1,174,481,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1174481468...
Checkpoint 1174481468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,814.72406
Policy Entropy: 1.71152
Value Function Loss: 0.05630

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.31557
Value Function Update Magnitude: 0.33199

Collected Steps per Second: 21,742.44313
Overall Steps per Second: 10,558.24465

Timestep Collection Time: 2.30011
Timestep Consumption Time: 2.43647
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.73658

Cumulative Model Updates: 140,740
Cumulative Timesteps: 1,174,531,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,343.86946
Policy Entropy: 1.70381
Value Function Loss: 0.05376

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.31483
Value Function Update Magnitude: 0.33145

Collected Steps per Second: 22,087.58216
Overall Steps per Second: 10,451.68706

Timestep Collection Time: 2.26408
Timestep Consumption Time: 2.52060
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.78468

Cumulative Model Updates: 140,746
Cumulative Timesteps: 1,174,581,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1174581486...
Checkpoint 1174581486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,797.94318
Policy Entropy: 1.71479
Value Function Loss: 0.05249

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.30927
Value Function Update Magnitude: 0.33838

Collected Steps per Second: 21,824.82216
Overall Steps per Second: 10,577.94289

Timestep Collection Time: 2.29189
Timestep Consumption Time: 2.43682
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.72871

Cumulative Model Updates: 140,752
Cumulative Timesteps: 1,174,631,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,701.08161
Policy Entropy: 1.71341
Value Function Loss: 0.04983

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.30871
Value Function Update Magnitude: 0.33655

Collected Steps per Second: 21,761.18487
Overall Steps per Second: 10,605.03744

Timestep Collection Time: 2.29896
Timestep Consumption Time: 2.41843
PPO Batch Consumption Time: 0.27662
Total Iteration Time: 4.71738

Cumulative Model Updates: 140,758
Cumulative Timesteps: 1,174,681,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1174681534...
Checkpoint 1174681534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,677.33625
Policy Entropy: 1.71899
Value Function Loss: 0.05020

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.30734
Value Function Update Magnitude: 0.33003

Collected Steps per Second: 21,562.01267
Overall Steps per Second: 10,510.73504

Timestep Collection Time: 2.31908
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.75742

Cumulative Model Updates: 140,764
Cumulative Timesteps: 1,174,731,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,488.70855
Policy Entropy: 1.70311
Value Function Loss: 0.05326

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.31119
Value Function Update Magnitude: 0.32309

Collected Steps per Second: 21,526.65924
Overall Steps per Second: 10,486.39070

Timestep Collection Time: 2.32354
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.76980

Cumulative Model Updates: 140,770
Cumulative Timesteps: 1,174,781,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1174781556...
Checkpoint 1174781556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,409.92059
Policy Entropy: 1.69498
Value Function Loss: 0.05422

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.31715
Value Function Update Magnitude: 0.33457

Collected Steps per Second: 20,002.81023
Overall Steps per Second: 9,856.24156

Timestep Collection Time: 2.50015
Timestep Consumption Time: 2.57379
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 5.07394

Cumulative Model Updates: 140,776
Cumulative Timesteps: 1,174,831,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,944.74947
Policy Entropy: 1.70462
Value Function Loss: 0.05070

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.30080
Value Function Update Magnitude: 0.34881

Collected Steps per Second: 21,570.64981
Overall Steps per Second: 10,432.06156

Timestep Collection Time: 2.31908
Timestep Consumption Time: 2.47614
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.79522

Cumulative Model Updates: 140,782
Cumulative Timesteps: 1,174,881,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1174881590...
Checkpoint 1174881590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,382.14436
Policy Entropy: 1.70489
Value Function Loss: 0.05152

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.28871
Value Function Update Magnitude: 0.34762

Collected Steps per Second: 21,521.21844
Overall Steps per Second: 10,364.81042

Timestep Collection Time: 2.32496
Timestep Consumption Time: 2.50253
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.82749

Cumulative Model Updates: 140,788
Cumulative Timesteps: 1,174,931,626

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,553.53576
Policy Entropy: 1.70763
Value Function Loss: 0.04709

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.29133
Value Function Update Magnitude: 0.33351

Collected Steps per Second: 22,068.03754
Overall Steps per Second: 10,465.67305

Timestep Collection Time: 2.26581
Timestep Consumption Time: 2.51190
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.77771

Cumulative Model Updates: 140,794
Cumulative Timesteps: 1,174,981,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1174981628...
Checkpoint 1174981628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,097.01050
Policy Entropy: 1.70505
Value Function Loss: 0.05249

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.29797
Value Function Update Magnitude: 0.33731

Collected Steps per Second: 22,035.38800
Overall Steps per Second: 10,438.99464

Timestep Collection Time: 2.26971
Timestep Consumption Time: 2.52136
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.79107

Cumulative Model Updates: 140,800
Cumulative Timesteps: 1,175,031,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,759.08604
Policy Entropy: 1.71005
Value Function Loss: 0.05274

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.31042
Value Function Update Magnitude: 0.34945

Collected Steps per Second: 21,939.59394
Overall Steps per Second: 10,452.72312

Timestep Collection Time: 2.28044
Timestep Consumption Time: 2.50606
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.78650

Cumulative Model Updates: 140,806
Cumulative Timesteps: 1,175,081,674

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1175081674...
Checkpoint 1175081674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,388.55296
Policy Entropy: 1.71667
Value Function Loss: 0.05563

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.31151
Value Function Update Magnitude: 0.36154

Collected Steps per Second: 21,851.28522
Overall Steps per Second: 10,595.43063

Timestep Collection Time: 2.28975
Timestep Consumption Time: 2.43247
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.72222

Cumulative Model Updates: 140,812
Cumulative Timesteps: 1,175,131,708

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,322.09400
Policy Entropy: 1.70889
Value Function Loss: 0.05778

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08916
Policy Update Magnitude: 0.32051
Value Function Update Magnitude: 0.37163

Collected Steps per Second: 21,785.01281
Overall Steps per Second: 10,569.91364

Timestep Collection Time: 2.29561
Timestep Consumption Time: 2.43574
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.73135

Cumulative Model Updates: 140,818
Cumulative Timesteps: 1,175,181,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1175181718...
Checkpoint 1175181718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,198.93275
Policy Entropy: 1.71134
Value Function Loss: 0.05604

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.32120
Value Function Update Magnitude: 0.37946

Collected Steps per Second: 21,534.97852
Overall Steps per Second: 10,578.43533

Timestep Collection Time: 2.32292
Timestep Consumption Time: 2.40595
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.72887

Cumulative Model Updates: 140,824
Cumulative Timesteps: 1,175,231,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,347.75369
Policy Entropy: 1.72497
Value Function Loss: 0.05974

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.31841
Value Function Update Magnitude: 0.36303

Collected Steps per Second: 21,527.29657
Overall Steps per Second: 10,502.53917

Timestep Collection Time: 2.32328
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.76209

Cumulative Model Updates: 140,830
Cumulative Timesteps: 1,175,281,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1175281756...
Checkpoint 1175281756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,764.71642
Policy Entropy: 1.74186
Value Function Loss: 0.05561

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.31928
Value Function Update Magnitude: 0.34788

Collected Steps per Second: 21,202.71029
Overall Steps per Second: 10,600.06832

Timestep Collection Time: 2.35960
Timestep Consumption Time: 2.36018
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.71978

Cumulative Model Updates: 140,836
Cumulative Timesteps: 1,175,331,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,774.25432
Policy Entropy: 1.74842
Value Function Loss: 0.05747

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.31553
Value Function Update Magnitude: 0.31086

Collected Steps per Second: 20,814.03084
Overall Steps per Second: 10,494.38696

Timestep Collection Time: 2.40319
Timestep Consumption Time: 2.36317
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.76636

Cumulative Model Updates: 140,842
Cumulative Timesteps: 1,175,381,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1175381806...
Checkpoint 1175381806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,332.45284
Policy Entropy: 1.73707
Value Function Loss: 0.05277

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.31181
Value Function Update Magnitude: 0.31295

Collected Steps per Second: 20,813.95372
Overall Steps per Second: 10,502.87850

Timestep Collection Time: 2.40233
Timestep Consumption Time: 2.35846
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.76079

Cumulative Model Updates: 140,848
Cumulative Timesteps: 1,175,431,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,779.35686
Policy Entropy: 1.72322
Value Function Loss: 0.05101

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.30750
Value Function Update Magnitude: 0.34092

Collected Steps per Second: 20,862.13584
Overall Steps per Second: 10,243.75159

Timestep Collection Time: 2.39678
Timestep Consumption Time: 2.48444
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.88122

Cumulative Model Updates: 140,854
Cumulative Timesteps: 1,175,481,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1175481810...
Checkpoint 1175481810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,647.73715
Policy Entropy: 1.71199
Value Function Loss: 0.05646

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.31247
Value Function Update Magnitude: 0.36522

Collected Steps per Second: 22,120.57540
Overall Steps per Second: 10,490.45268

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.76719

Cumulative Model Updates: 140,860
Cumulative Timesteps: 1,175,531,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,725.28985
Policy Entropy: 1.72009
Value Function Loss: 0.05748

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.32027
Value Function Update Magnitude: 0.37604

Collected Steps per Second: 22,031.36478
Overall Steps per Second: 10,493.64267

Timestep Collection Time: 2.27004
Timestep Consumption Time: 2.49590
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.76593

Cumulative Model Updates: 140,866
Cumulative Timesteps: 1,175,581,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1175581832...
Checkpoint 1175581832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,370.22231
Policy Entropy: 1.71742
Value Function Loss: 0.05473

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.31394
Value Function Update Magnitude: 0.36835

Collected Steps per Second: 22,134.39505
Overall Steps per Second: 10,588.46106

Timestep Collection Time: 2.25974
Timestep Consumption Time: 2.46408
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.72382

Cumulative Model Updates: 140,872
Cumulative Timesteps: 1,175,631,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,895.65809
Policy Entropy: 1.71038
Value Function Loss: 0.04782

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.30631
Value Function Update Magnitude: 0.35961

Collected Steps per Second: 22,314.27735
Overall Steps per Second: 10,554.48403

Timestep Collection Time: 2.24206
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.74017

Cumulative Model Updates: 140,878
Cumulative Timesteps: 1,175,681,880

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1175681880...
Checkpoint 1175681880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,042.28419
Policy Entropy: 1.69917
Value Function Loss: 0.04626

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.30680
Value Function Update Magnitude: 0.33326

Collected Steps per Second: 21,858.96699
Overall Steps per Second: 10,609.12097

Timestep Collection Time: 2.28950
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.71726

Cumulative Model Updates: 140,884
Cumulative Timesteps: 1,175,731,926

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,914.58932
Policy Entropy: 1.69517
Value Function Loss: 0.04723

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.30648
Value Function Update Magnitude: 0.32275

Collected Steps per Second: 22,098.04410
Overall Steps per Second: 10,487.29183

Timestep Collection Time: 2.26282
Timestep Consumption Time: 2.50523
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.76806

Cumulative Model Updates: 140,890
Cumulative Timesteps: 1,175,781,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1175781930...
Checkpoint 1175781930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,362.27357
Policy Entropy: 1.70408
Value Function Loss: 0.05217

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07825
Policy Update Magnitude: 0.30835
Value Function Update Magnitude: 0.32084

Collected Steps per Second: 21,821.73148
Overall Steps per Second: 10,596.09878

Timestep Collection Time: 2.29184
Timestep Consumption Time: 2.42801
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.71985

Cumulative Model Updates: 140,896
Cumulative Timesteps: 1,175,831,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,730.17153
Policy Entropy: 1.69837
Value Function Loss: 0.05369

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07770
Policy Update Magnitude: 0.31412
Value Function Update Magnitude: 0.33314

Collected Steps per Second: 21,839.08995
Overall Steps per Second: 10,425.24377

Timestep Collection Time: 2.29030
Timestep Consumption Time: 2.50748
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.79778

Cumulative Model Updates: 140,902
Cumulative Timesteps: 1,175,881,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1175881960...
Checkpoint 1175881960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,532.84581
Policy Entropy: 1.70243
Value Function Loss: 0.05461

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.31361
Value Function Update Magnitude: 0.33830

Collected Steps per Second: 21,446.34655
Overall Steps per Second: 10,566.92496

Timestep Collection Time: 2.33336
Timestep Consumption Time: 2.40236
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.73572

Cumulative Model Updates: 140,908
Cumulative Timesteps: 1,175,932,002

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,690.26516
Policy Entropy: 1.70252
Value Function Loss: 0.04982

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.30546
Value Function Update Magnitude: 0.33573

Collected Steps per Second: 21,573.31047
Overall Steps per Second: 10,476.47314

Timestep Collection Time: 2.31768
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.77260

Cumulative Model Updates: 140,914
Cumulative Timesteps: 1,175,982,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1175982002...
Checkpoint 1175982002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,806.90251
Policy Entropy: 1.69615
Value Function Loss: 0.05096

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.30240
Value Function Update Magnitude: 0.33505

Collected Steps per Second: 20,957.30973
Overall Steps per Second: 10,261.92974

Timestep Collection Time: 2.38638
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.87355

Cumulative Model Updates: 140,920
Cumulative Timesteps: 1,176,032,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,313.51790
Policy Entropy: 1.69936
Value Function Loss: 0.04872

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07403
Policy Update Magnitude: 0.30694
Value Function Update Magnitude: 0.33210

Collected Steps per Second: 22,153.58021
Overall Steps per Second: 10,429.29128

Timestep Collection Time: 2.25842
Timestep Consumption Time: 2.53884
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.79726

Cumulative Model Updates: 140,926
Cumulative Timesteps: 1,176,082,046

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1176082046...
Checkpoint 1176082046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,949.94556
Policy Entropy: 1.70426
Value Function Loss: 0.05393

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07280
Policy Update Magnitude: 0.30775
Value Function Update Magnitude: 0.32153

Collected Steps per Second: 21,935.50979
Overall Steps per Second: 10,575.87463

Timestep Collection Time: 2.27968
Timestep Consumption Time: 2.44863
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.72831

Cumulative Model Updates: 140,932
Cumulative Timesteps: 1,176,132,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,758.95455
Policy Entropy: 1.70270
Value Function Loss: 0.05215

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07458
Policy Update Magnitude: 0.31088
Value Function Update Magnitude: 0.34947

Collected Steps per Second: 22,012.49352
Overall Steps per Second: 10,487.95204

Timestep Collection Time: 2.27262
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.76985

Cumulative Model Updates: 140,938
Cumulative Timesteps: 1,176,182,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1176182078...
Checkpoint 1176182078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,674.79994
Policy Entropy: 1.69420
Value Function Loss: 0.05119

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.31108
Value Function Update Magnitude: 0.35143

Collected Steps per Second: 21,899.34203
Overall Steps per Second: 10,590.67013

Timestep Collection Time: 2.28345
Timestep Consumption Time: 2.43826
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.72170

Cumulative Model Updates: 140,944
Cumulative Timesteps: 1,176,232,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,459.83460
Policy Entropy: 1.69507
Value Function Loss: 0.05101

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.30647
Value Function Update Magnitude: 0.33135

Collected Steps per Second: 22,159.60007
Overall Steps per Second: 10,526.14411

Timestep Collection Time: 2.25717
Timestep Consumption Time: 2.49462
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.75179

Cumulative Model Updates: 140,950
Cumulative Timesteps: 1,176,282,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1176282102...
Checkpoint 1176282102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,820.92643
Policy Entropy: 1.71197
Value Function Loss: 0.04825

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.29847
Value Function Update Magnitude: 0.33477

Collected Steps per Second: 21,939.23053
Overall Steps per Second: 10,613.27606

Timestep Collection Time: 2.27902
Timestep Consumption Time: 2.43206
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.71108

Cumulative Model Updates: 140,956
Cumulative Timesteps: 1,176,332,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,558.93740
Policy Entropy: 1.71511
Value Function Loss: 0.05120

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.29954
Value Function Update Magnitude: 0.33096

Collected Steps per Second: 21,500.21774
Overall Steps per Second: 10,520.72765

Timestep Collection Time: 2.32705
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.75556

Cumulative Model Updates: 140,962
Cumulative Timesteps: 1,176,382,134

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1176382134...
Checkpoint 1176382134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,422.02171
Policy Entropy: 1.69760
Value Function Loss: 0.05052

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.30165
Value Function Update Magnitude: 0.31087

Collected Steps per Second: 21,323.31467
Overall Steps per Second: 10,357.24199

Timestep Collection Time: 2.34485
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.82754

Cumulative Model Updates: 140,968
Cumulative Timesteps: 1,176,432,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,956.13801
Policy Entropy: 1.69973
Value Function Loss: 0.05343

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.30659
Value Function Update Magnitude: 0.30413

Collected Steps per Second: 21,625.29534
Overall Steps per Second: 10,419.77086

Timestep Collection Time: 2.31359
Timestep Consumption Time: 2.48805
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.80164

Cumulative Model Updates: 140,974
Cumulative Timesteps: 1,176,482,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1176482166...
Checkpoint 1176482166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,286.20144
Policy Entropy: 1.70875
Value Function Loss: 0.05079

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.30219
Value Function Update Magnitude: 0.34247

Collected Steps per Second: 21,689.05911
Overall Steps per Second: 10,444.98889

Timestep Collection Time: 2.30623
Timestep Consumption Time: 2.48267
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.78890

Cumulative Model Updates: 140,980
Cumulative Timesteps: 1,176,532,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,913.03919
Policy Entropy: 1.71209
Value Function Loss: 0.04829

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.28351
Value Function Update Magnitude: 0.34309

Collected Steps per Second: 21,691.71803
Overall Steps per Second: 10,533.57732

Timestep Collection Time: 2.30530
Timestep Consumption Time: 2.44199
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.74730

Cumulative Model Updates: 140,986
Cumulative Timesteps: 1,176,582,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1176582192...
Checkpoint 1176582192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,521.29855
Policy Entropy: 1.70687
Value Function Loss: 0.04609

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.28710
Value Function Update Magnitude: 0.33167

Collected Steps per Second: 21,287.64959
Overall Steps per Second: 10,572.81214

Timestep Collection Time: 2.34981
Timestep Consumption Time: 2.38138
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.73119

Cumulative Model Updates: 140,992
Cumulative Timesteps: 1,176,632,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,689.02499
Policy Entropy: 1.70088
Value Function Loss: 0.04659

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.29903
Value Function Update Magnitude: 0.32486

Collected Steps per Second: 21,316.20488
Overall Steps per Second: 10,413.86122

Timestep Collection Time: 2.34563
Timestep Consumption Time: 2.45566
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.80129

Cumulative Model Updates: 140,998
Cumulative Timesteps: 1,176,682,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1176682214...
Checkpoint 1176682214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,668.06198
Policy Entropy: 1.69625
Value Function Loss: 0.04596

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.30135
Value Function Update Magnitude: 0.32780

Collected Steps per Second: 21,101.82752
Overall Steps per Second: 10,595.10359

Timestep Collection Time: 2.36956
Timestep Consumption Time: 2.34979
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.71935

Cumulative Model Updates: 141,004
Cumulative Timesteps: 1,176,732,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,712.60787
Policy Entropy: 1.69897
Value Function Loss: 0.04670

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.30877
Value Function Update Magnitude: 0.33040

Collected Steps per Second: 21,270.86054
Overall Steps per Second: 10,511.59314

Timestep Collection Time: 2.35092
Timestep Consumption Time: 2.40631
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.75722

Cumulative Model Updates: 141,010
Cumulative Timesteps: 1,176,782,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1176782222...
Checkpoint 1176782222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,830.29711
Policy Entropy: 1.68736
Value Function Loss: 0.04535

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.30606
Value Function Update Magnitude: 0.32659

Collected Steps per Second: 21,228.81684
Overall Steps per Second: 10,332.54175

Timestep Collection Time: 2.35727
Timestep Consumption Time: 2.48588
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.84315

Cumulative Model Updates: 141,016
Cumulative Timesteps: 1,176,832,264

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,702.56060
Policy Entropy: 1.69231
Value Function Loss: 0.04494

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.30122
Value Function Update Magnitude: 0.31479

Collected Steps per Second: 22,173.24485
Overall Steps per Second: 10,736.95732

Timestep Collection Time: 2.25587
Timestep Consumption Time: 2.40280
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.65868

Cumulative Model Updates: 141,022
Cumulative Timesteps: 1,176,882,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1176882284...
Checkpoint 1176882284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,299.32816
Policy Entropy: 1.71213
Value Function Loss: 0.04630

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08018
Policy Update Magnitude: 0.29963
Value Function Update Magnitude: 0.30752

Collected Steps per Second: 21,999.46587
Overall Steps per Second: 10,680.42433

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.40993
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.68390

Cumulative Model Updates: 141,028
Cumulative Timesteps: 1,176,932,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,301.49062
Policy Entropy: 1.72585
Value Function Loss: 0.04921

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.29955
Value Function Update Magnitude: 0.30449

Collected Steps per Second: 21,443.99510
Overall Steps per Second: 10,533.61783

Timestep Collection Time: 2.33324
Timestep Consumption Time: 2.41669
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.74993

Cumulative Model Updates: 141,034
Cumulative Timesteps: 1,176,982,344

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1176982344...
Checkpoint 1176982344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,185.02550
Policy Entropy: 1.72573
Value Function Loss: 0.05350

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.31147
Value Function Update Magnitude: 0.30877

Collected Steps per Second: 21,438.65425
Overall Steps per Second: 10,540.71432

Timestep Collection Time: 2.33261
Timestep Consumption Time: 2.41166
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.74427

Cumulative Model Updates: 141,040
Cumulative Timesteps: 1,177,032,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,342.98951
Policy Entropy: 1.69876
Value Function Loss: 0.05798

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.32977

Collected Steps per Second: 21,740.91975
Overall Steps per Second: 10,577.62036

Timestep Collection Time: 2.30110
Timestep Consumption Time: 2.42851
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.72961

Cumulative Model Updates: 141,046
Cumulative Timesteps: 1,177,082,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1177082380...
Checkpoint 1177082380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,231.39335
Policy Entropy: 1.70908
Value Function Loss: 0.05545

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.31421
Value Function Update Magnitude: 0.34284

Collected Steps per Second: 21,561.22198
Overall Steps per Second: 10,528.13070

Timestep Collection Time: 2.31972
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.75070

Cumulative Model Updates: 141,052
Cumulative Timesteps: 1,177,132,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,085.01741
Policy Entropy: 1.72496
Value Function Loss: 0.05676

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.31148
Value Function Update Magnitude: 0.34457

Collected Steps per Second: 21,856.70334
Overall Steps per Second: 10,475.79511

Timestep Collection Time: 2.28763
Timestep Consumption Time: 2.48528
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.77291

Cumulative Model Updates: 141,058
Cumulative Timesteps: 1,177,182,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1177182396...
Checkpoint 1177182396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,332.70807
Policy Entropy: 1.72856
Value Function Loss: 0.05385

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.30968
Value Function Update Magnitude: 0.35110

Collected Steps per Second: 21,543.32349
Overall Steps per Second: 10,295.02224

Timestep Collection Time: 2.32202
Timestep Consumption Time: 2.53703
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.85905

Cumulative Model Updates: 141,064
Cumulative Timesteps: 1,177,232,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,592.70158
Policy Entropy: 1.72047
Value Function Loss: 0.05543

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.30856
Value Function Update Magnitude: 0.37887

Collected Steps per Second: 22,070.14328
Overall Steps per Second: 10,466.91080

Timestep Collection Time: 2.26777
Timestep Consumption Time: 2.51397
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.78174

Cumulative Model Updates: 141,070
Cumulative Timesteps: 1,177,282,470

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1177282470...
Checkpoint 1177282470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,660.19074
Policy Entropy: 1.71122
Value Function Loss: 0.05430

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08721
Policy Update Magnitude: 0.31742
Value Function Update Magnitude: 0.38277

Collected Steps per Second: 22,116.80595
Overall Steps per Second: 10,569.15386

Timestep Collection Time: 2.26081
Timestep Consumption Time: 2.47012
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.73094

Cumulative Model Updates: 141,076
Cumulative Timesteps: 1,177,332,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,032.59901
Policy Entropy: 1.70768
Value Function Loss: 0.05403

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.31638
Value Function Update Magnitude: 0.37296

Collected Steps per Second: 22,021.36035
Overall Steps per Second: 10,429.26737

Timestep Collection Time: 2.27198
Timestep Consumption Time: 2.52529
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.79727

Cumulative Model Updates: 141,082
Cumulative Timesteps: 1,177,382,504

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1177382504...
Checkpoint 1177382504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,150.52666
Policy Entropy: 1.71527
Value Function Loss: 0.05356

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.29935
Value Function Update Magnitude: 0.36380

Collected Steps per Second: 21,725.27593
Overall Steps per Second: 10,595.88918

Timestep Collection Time: 2.30156
Timestep Consumption Time: 2.41744
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.71900

Cumulative Model Updates: 141,088
Cumulative Timesteps: 1,177,432,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,520.92137
Policy Entropy: 1.71752
Value Function Loss: 0.05250

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.28930
Value Function Update Magnitude: 0.35163

Collected Steps per Second: 22,085.40940
Overall Steps per Second: 10,518.80609

Timestep Collection Time: 2.26502
Timestep Consumption Time: 2.49065
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.75567

Cumulative Model Updates: 141,094
Cumulative Timesteps: 1,177,482,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1177482530...
Checkpoint 1177482530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,160.53474
Policy Entropy: 1.71596
Value Function Loss: 0.05062

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.30210
Value Function Update Magnitude: 0.31134

Collected Steps per Second: 21,906.25315
Overall Steps per Second: 10,613.13217

Timestep Collection Time: 2.28291
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.71209

Cumulative Model Updates: 141,100
Cumulative Timesteps: 1,177,532,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,752.13641
Policy Entropy: 1.71156
Value Function Loss: 0.05164

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.31193
Value Function Update Magnitude: 0.28836

Collected Steps per Second: 21,594.38328
Overall Steps per Second: 10,478.24096

Timestep Collection Time: 2.31542
Timestep Consumption Time: 2.45638
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.77179

Cumulative Model Updates: 141,106
Cumulative Timesteps: 1,177,582,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1177582540...
Checkpoint 1177582540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,414.53907
Policy Entropy: 1.70999
Value Function Loss: 0.05039

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.31256
Value Function Update Magnitude: 0.27771

Collected Steps per Second: 21,577.99535
Overall Steps per Second: 10,543.13820

Timestep Collection Time: 2.31718
Timestep Consumption Time: 2.42525
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.74242

Cumulative Model Updates: 141,112
Cumulative Timesteps: 1,177,632,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,549.88904
Policy Entropy: 1.70746
Value Function Loss: 0.05259

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.31241
Value Function Update Magnitude: 0.30848

Collected Steps per Second: 21,779.41003
Overall Steps per Second: 10,531.33802

Timestep Collection Time: 2.29575
Timestep Consumption Time: 2.45199
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74773

Cumulative Model Updates: 141,118
Cumulative Timesteps: 1,177,682,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1177682540...
Checkpoint 1177682540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,680.42308
Policy Entropy: 1.68151
Value Function Loss: 0.05256

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.31120
Value Function Update Magnitude: 0.31144

Collected Steps per Second: 21,481.92564
Overall Steps per Second: 10,378.89761

Timestep Collection Time: 2.32866
Timestep Consumption Time: 2.49112
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.81978

Cumulative Model Updates: 141,124
Cumulative Timesteps: 1,177,732,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,112.28630
Policy Entropy: 1.67458
Value Function Loss: 0.05001

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.30427
Value Function Update Magnitude: 0.27306

Collected Steps per Second: 21,706.47460
Overall Steps per Second: 10,337.28819

Timestep Collection Time: 2.30374
Timestep Consumption Time: 2.53370
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.83744

Cumulative Model Updates: 141,130
Cumulative Timesteps: 1,177,782,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1177782570...
Checkpoint 1177782570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,648.34628
Policy Entropy: 1.68598
Value Function Loss: 0.05726

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.30246
Value Function Update Magnitude: 0.29551

Collected Steps per Second: 21,864.00783
Overall Steps per Second: 10,481.62451

Timestep Collection Time: 2.28842
Timestep Consumption Time: 2.48508
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.77350

Cumulative Model Updates: 141,136
Cumulative Timesteps: 1,177,832,604

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,751.71976
Policy Entropy: 1.71518
Value Function Loss: 0.05524

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.31713
Value Function Update Magnitude: 0.36326

Collected Steps per Second: 22,086.98961
Overall Steps per Second: 10,444.57180

Timestep Collection Time: 2.26495
Timestep Consumption Time: 2.52471
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.78966

Cumulative Model Updates: 141,142
Cumulative Timesteps: 1,177,882,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1177882630...
Checkpoint 1177882630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,937.27845
Policy Entropy: 1.72665
Value Function Loss: 0.05760

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.32017
Value Function Update Magnitude: 0.38128

Collected Steps per Second: 20,674.61546
Overall Steps per Second: 10,276.23953

Timestep Collection Time: 2.41930
Timestep Consumption Time: 2.44805
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.86734

Cumulative Model Updates: 141,148
Cumulative Timesteps: 1,177,932,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,400.14123
Policy Entropy: 1.72318
Value Function Loss: 0.05449

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.31697
Value Function Update Magnitude: 0.37212

Collected Steps per Second: 21,837.34713
Overall Steps per Second: 10,453.27823

Timestep Collection Time: 2.29039
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.78472

Cumulative Model Updates: 141,154
Cumulative Timesteps: 1,177,982,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1177982664...
Checkpoint 1177982664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,445.51416
Policy Entropy: 1.70724
Value Function Loss: 0.05117

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.31573
Value Function Update Magnitude: 0.36819

Collected Steps per Second: 21,267.21621
Overall Steps per Second: 10,298.42029

Timestep Collection Time: 2.35188
Timestep Consumption Time: 2.50498
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.85686

Cumulative Model Updates: 141,160
Cumulative Timesteps: 1,178,032,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,635.26301
Policy Entropy: 1.70596
Value Function Loss: 0.05020

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.31285
Value Function Update Magnitude: 0.36083

Collected Steps per Second: 21,379.93828
Overall Steps per Second: 10,454.56673

Timestep Collection Time: 2.33948
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.78432

Cumulative Model Updates: 141,166
Cumulative Timesteps: 1,178,082,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1178082700...
Checkpoint 1178082700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,827.28357
Policy Entropy: 1.69660
Value Function Loss: 0.05155

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.31333
Value Function Update Magnitude: 0.36409

Collected Steps per Second: 21,330.53577
Overall Steps per Second: 10,605.00936

Timestep Collection Time: 2.34528
Timestep Consumption Time: 2.37193
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.71720

Cumulative Model Updates: 141,172
Cumulative Timesteps: 1,178,132,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,865.53238
Policy Entropy: 1.70581
Value Function Loss: 0.05371

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.31401
Value Function Update Magnitude: 0.35610

Collected Steps per Second: 21,691.92881
Overall Steps per Second: 10,562.07863

Timestep Collection Time: 2.30556
Timestep Consumption Time: 2.42949
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.73505

Cumulative Model Updates: 141,178
Cumulative Timesteps: 1,178,182,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1178182738...
Checkpoint 1178182738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,960.06458
Policy Entropy: 1.70497
Value Function Loss: 0.05582

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.31787
Value Function Update Magnitude: 0.36019

Collected Steps per Second: 21,421.31996
Overall Steps per Second: 10,479.10218

Timestep Collection Time: 2.33440
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.77197

Cumulative Model Updates: 141,184
Cumulative Timesteps: 1,178,232,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,907.21050
Policy Entropy: 1.71249
Value Function Loss: 0.05461

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.31615
Value Function Update Magnitude: 0.37301

Collected Steps per Second: 21,760.55240
Overall Steps per Second: 10,455.40189

Timestep Collection Time: 2.29884
Timestep Consumption Time: 2.48567
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.78451

Cumulative Model Updates: 141,190
Cumulative Timesteps: 1,178,282,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1178282768...
Checkpoint 1178282768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,317.23309
Policy Entropy: 1.71112
Value Function Loss: 0.05808

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.30832
Value Function Update Magnitude: 0.38116

Collected Steps per Second: 21,811.94535
Overall Steps per Second: 10,621.46037

Timestep Collection Time: 2.29232
Timestep Consumption Time: 2.41513
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.70745

Cumulative Model Updates: 141,196
Cumulative Timesteps: 1,178,332,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,039.15984
Policy Entropy: 1.72622
Value Function Loss: 0.05294

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.31034
Value Function Update Magnitude: 0.38317

Collected Steps per Second: 22,273.66318
Overall Steps per Second: 10,576.06812

Timestep Collection Time: 2.24516
Timestep Consumption Time: 2.48325
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.72841

Cumulative Model Updates: 141,202
Cumulative Timesteps: 1,178,382,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1178382776...
Checkpoint 1178382776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,645.86863
Policy Entropy: 1.72751
Value Function Loss: 0.05491

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.31860
Value Function Update Magnitude: 0.37810

Collected Steps per Second: 21,647.04082
Overall Steps per Second: 10,519.02528

Timestep Collection Time: 2.31117
Timestep Consumption Time: 2.44497
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.75614

Cumulative Model Updates: 141,208
Cumulative Timesteps: 1,178,432,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,891.14180
Policy Entropy: 1.72969
Value Function Loss: 0.05263

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.31929
Value Function Update Magnitude: 0.35646

Collected Steps per Second: 21,489.91378
Overall Steps per Second: 10,444.40629

Timestep Collection Time: 2.32695
Timestep Consumption Time: 2.46087
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.78783

Cumulative Model Updates: 141,214
Cumulative Timesteps: 1,178,482,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1178482812...
Checkpoint 1178482812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,397.89914
Policy Entropy: 1.71292
Value Function Loss: 0.05687

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.32182
Value Function Update Magnitude: 0.32498

Collected Steps per Second: 21,194.31297
Overall Steps per Second: 10,270.48871

Timestep Collection Time: 2.35997
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.87007

Cumulative Model Updates: 141,220
Cumulative Timesteps: 1,178,532,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,343.87709
Policy Entropy: 1.71603
Value Function Loss: 0.05474

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.31587
Value Function Update Magnitude: 0.33757

Collected Steps per Second: 21,834.25650
Overall Steps per Second: 10,406.41801

Timestep Collection Time: 2.29108
Timestep Consumption Time: 2.51595
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.80703

Cumulative Model Updates: 141,226
Cumulative Timesteps: 1,178,582,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1178582854...
Checkpoint 1178582854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,786.82867
Policy Entropy: 1.71048
Value Function Loss: 0.05601

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.31303
Value Function Update Magnitude: 0.34893

Collected Steps per Second: 21,494.18261
Overall Steps per Second: 10,359.94942

Timestep Collection Time: 2.32696
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.82782

Cumulative Model Updates: 141,232
Cumulative Timesteps: 1,178,632,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,314.44944
Policy Entropy: 1.72422
Value Function Loss: 0.05491

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.31714
Value Function Update Magnitude: 0.35022

Collected Steps per Second: 21,779.64330
Overall Steps per Second: 10,413.09423

Timestep Collection Time: 2.29664
Timestep Consumption Time: 2.50693
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.80357

Cumulative Model Updates: 141,238
Cumulative Timesteps: 1,178,682,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1178682890...
Checkpoint 1178682890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,000.52516
Policy Entropy: 1.71085
Value Function Loss: 0.05131

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.31634
Value Function Update Magnitude: 0.35133

Collected Steps per Second: 21,904.85890
Overall Steps per Second: 10,552.00829

Timestep Collection Time: 2.28287
Timestep Consumption Time: 2.45613
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.73900

Cumulative Model Updates: 141,244
Cumulative Timesteps: 1,178,732,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,189.59546
Policy Entropy: 1.72358
Value Function Loss: 0.04894

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.31262
Value Function Update Magnitude: 0.33776

Collected Steps per Second: 22,145.27640
Overall Steps per Second: 10,479.59623

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.51467
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.77366

Cumulative Model Updates: 141,250
Cumulative Timesteps: 1,178,782,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1178782922...
Checkpoint 1178782922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,624.63006
Policy Entropy: 1.70535
Value Function Loss: 0.05114

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.31350
Value Function Update Magnitude: 0.33519

Collected Steps per Second: 21,440.20790
Overall Steps per Second: 10,491.44675

Timestep Collection Time: 2.33281
Timestep Consumption Time: 2.43450
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.76731

Cumulative Model Updates: 141,256
Cumulative Timesteps: 1,178,832,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,293.11273
Policy Entropy: 1.70349
Value Function Loss: 0.05193

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.31435
Value Function Update Magnitude: 0.33423

Collected Steps per Second: 21,828.55231
Overall Steps per Second: 10,588.46275

Timestep Collection Time: 2.29168
Timestep Consumption Time: 2.43271
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.72439

Cumulative Model Updates: 141,262
Cumulative Timesteps: 1,178,882,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1178882962...
Checkpoint 1178882962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,275.55960
Policy Entropy: 1.70262
Value Function Loss: 0.05434

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.31270
Value Function Update Magnitude: 0.31940

Collected Steps per Second: 21,885.57066
Overall Steps per Second: 10,626.33526

Timestep Collection Time: 2.28516
Timestep Consumption Time: 2.42126
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.70642

Cumulative Model Updates: 141,268
Cumulative Timesteps: 1,178,932,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,830.26809
Policy Entropy: 1.71065
Value Function Loss: 0.05710

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.31655
Value Function Update Magnitude: 0.32758

Collected Steps per Second: 21,828.33708
Overall Steps per Second: 10,405.49712

Timestep Collection Time: 2.29133
Timestep Consumption Time: 2.51536
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.80669

Cumulative Model Updates: 141,274
Cumulative Timesteps: 1,178,982,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1178982990...
Checkpoint 1178982990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,694.95604
Policy Entropy: 1.72081
Value Function Loss: 0.05343

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.31529
Value Function Update Magnitude: 0.33944

Collected Steps per Second: 21,931.56732
Overall Steps per Second: 10,586.54302

Timestep Collection Time: 2.28137
Timestep Consumption Time: 2.44482
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.72619

Cumulative Model Updates: 141,280
Cumulative Timesteps: 1,179,033,024

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,092.76693
Policy Entropy: 1.72534
Value Function Loss: 0.05227

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08812
Policy Update Magnitude: 0.30860
Value Function Update Magnitude: 0.31967

Collected Steps per Second: 21,253.71242
Overall Steps per Second: 10,449.23982

Timestep Collection Time: 2.35375
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.78753

Cumulative Model Updates: 141,286
Cumulative Timesteps: 1,179,083,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1179083050...
Checkpoint 1179083050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,944.72768
Policy Entropy: 1.71406
Value Function Loss: 0.04947

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.30529
Value Function Update Magnitude: 0.28886

Collected Steps per Second: 21,386.28885
Overall Steps per Second: 10,304.12071

Timestep Collection Time: 2.33879
Timestep Consumption Time: 2.51539
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.85417

Cumulative Model Updates: 141,292
Cumulative Timesteps: 1,179,133,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,396.71518
Policy Entropy: 1.71940
Value Function Loss: 0.04964

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.30848
Value Function Update Magnitude: 0.31045

Collected Steps per Second: 21,303.02192
Overall Steps per Second: 10,472.88842

Timestep Collection Time: 2.34737
Timestep Consumption Time: 2.42744
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.77481

Cumulative Model Updates: 141,298
Cumulative Timesteps: 1,179,183,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1179183074...
Checkpoint 1179183074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,089.59847
Policy Entropy: 1.70225
Value Function Loss: 0.04901

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.29943
Value Function Update Magnitude: 0.32686

Collected Steps per Second: 21,876.71322
Overall Steps per Second: 10,597.83102

Timestep Collection Time: 2.28645
Timestep Consumption Time: 2.43338
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.71983

Cumulative Model Updates: 141,304
Cumulative Timesteps: 1,179,233,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,324.23380
Policy Entropy: 1.71639
Value Function Loss: 0.04994

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.27919
Value Function Update Magnitude: 0.32498

Collected Steps per Second: 21,250.95914
Overall Steps per Second: 10,512.27976

Timestep Collection Time: 2.35368
Timestep Consumption Time: 2.40437
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.75805

Cumulative Model Updates: 141,310
Cumulative Timesteps: 1,179,283,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1179283112...
Checkpoint 1179283112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,812.62020
Policy Entropy: 1.72069
Value Function Loss: 0.05262

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.28457
Value Function Update Magnitude: 0.30123

Collected Steps per Second: 21,279.19985
Overall Steps per Second: 10,609.57822

Timestep Collection Time: 2.34981
Timestep Consumption Time: 2.36310
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.71291

Cumulative Model Updates: 141,316
Cumulative Timesteps: 1,179,333,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,181.32647
Policy Entropy: 1.74023
Value Function Loss: 0.05566

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.30808
Value Function Update Magnitude: 0.28433

Collected Steps per Second: 21,580.77540
Overall Steps per Second: 10,584.44585

Timestep Collection Time: 2.31725
Timestep Consumption Time: 2.40742
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.72467

Cumulative Model Updates: 141,322
Cumulative Timesteps: 1,179,383,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1179383122...
Checkpoint 1179383122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,668.83244
Policy Entropy: 1.73398
Value Function Loss: 0.05497

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.31464
Value Function Update Magnitude: 0.32253

Collected Steps per Second: 21,395.07417
Overall Steps per Second: 10,491.30290

Timestep Collection Time: 2.33755
Timestep Consumption Time: 2.42945
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.76700

Cumulative Model Updates: 141,328
Cumulative Timesteps: 1,179,433,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,387.02485
Policy Entropy: 1.71433
Value Function Loss: 0.04866

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.31165
Value Function Update Magnitude: 0.34726

Collected Steps per Second: 21,580.64132
Overall Steps per Second: 10,572.24607

Timestep Collection Time: 2.31763
Timestep Consumption Time: 2.41324
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.73088

Cumulative Model Updates: 141,334
Cumulative Timesteps: 1,179,483,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1179483150...
Checkpoint 1179483150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,735.05144
Policy Entropy: 1.71096
Value Function Loss: 0.04698

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.33312

Collected Steps per Second: 21,477.28947
Overall Steps per Second: 10,467.91330

Timestep Collection Time: 2.32841
Timestep Consumption Time: 2.44885
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.77727

Cumulative Model Updates: 141,340
Cumulative Timesteps: 1,179,533,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,954.34617
Policy Entropy: 1.71643
Value Function Loss: 0.04987

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.31273
Value Function Update Magnitude: 0.33737

Collected Steps per Second: 21,726.53943
Overall Steps per Second: 10,421.50108

Timestep Collection Time: 2.30271
Timestep Consumption Time: 2.49794
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.80065

Cumulative Model Updates: 141,346
Cumulative Timesteps: 1,179,583,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1179583188...
Checkpoint 1179583188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,682.90966
Policy Entropy: 1.71577
Value Function Loss: 0.05003

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.31153
Value Function Update Magnitude: 0.35865

Collected Steps per Second: 21,207.19324
Overall Steps per Second: 10,362.37732

Timestep Collection Time: 2.35778
Timestep Consumption Time: 2.46756
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.82534

Cumulative Model Updates: 141,352
Cumulative Timesteps: 1,179,633,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,374.37004
Policy Entropy: 1.69861
Value Function Loss: 0.04825

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.30721
Value Function Update Magnitude: 0.35276

Collected Steps per Second: 21,688.99691
Overall Steps per Second: 10,485.90583

Timestep Collection Time: 2.30541
Timestep Consumption Time: 2.46309
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.76850

Cumulative Model Updates: 141,358
Cumulative Timesteps: 1,179,683,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1179683192...
Checkpoint 1179683192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,106.06786
Policy Entropy: 1.70742
Value Function Loss: 0.05128

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08009
Policy Update Magnitude: 0.31164
Value Function Update Magnitude: 0.32913

Collected Steps per Second: 21,755.45426
Overall Steps per Second: 10,462.80086

Timestep Collection Time: 2.29965
Timestep Consumption Time: 2.48205
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.78170

Cumulative Model Updates: 141,364
Cumulative Timesteps: 1,179,733,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,566.20491
Policy Entropy: 1.72713
Value Function Loss: 0.05632

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.32052
Value Function Update Magnitude: 0.30896

Collected Steps per Second: 21,668.75395
Overall Steps per Second: 10,443.40505

Timestep Collection Time: 2.30858
Timestep Consumption Time: 2.48143
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.79001

Cumulative Model Updates: 141,370
Cumulative Timesteps: 1,179,783,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1179783246...
Checkpoint 1179783246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,613.06001
Policy Entropy: 1.73780
Value Function Loss: 0.05807

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.32255
Value Function Update Magnitude: 0.30358

Collected Steps per Second: 21,367.74411
Overall Steps per Second: 10,282.97402

Timestep Collection Time: 2.34072
Timestep Consumption Time: 2.52324
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.86396

Cumulative Model Updates: 141,376
Cumulative Timesteps: 1,179,833,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,968.39826
Policy Entropy: 1.74275
Value Function Loss: 0.05372

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.31569
Value Function Update Magnitude: 0.30172

Collected Steps per Second: 21,777.83033
Overall Steps per Second: 10,399.30274

Timestep Collection Time: 2.29610
Timestep Consumption Time: 2.51230
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.80840

Cumulative Model Updates: 141,382
Cumulative Timesteps: 1,179,883,266

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1179883266...
Checkpoint 1179883266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,268.75031
Policy Entropy: 1.73086
Value Function Loss: 0.05288

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.29303
Value Function Update Magnitude: 0.30249

Collected Steps per Second: 22,072.43048
Overall Steps per Second: 10,621.65604

Timestep Collection Time: 2.26663
Timestep Consumption Time: 2.44356
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.71019

Cumulative Model Updates: 141,388
Cumulative Timesteps: 1,179,933,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,980.12425
Policy Entropy: 1.72814
Value Function Loss: 0.05264

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.29025
Value Function Update Magnitude: 0.32412

Collected Steps per Second: 22,003.40177
Overall Steps per Second: 10,459.32856

Timestep Collection Time: 2.27247
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.78061

Cumulative Model Updates: 141,394
Cumulative Timesteps: 1,179,983,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1179983298...
Checkpoint 1179983298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,247.10702
Policy Entropy: 1.71485
Value Function Loss: 0.05559

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.29203
Value Function Update Magnitude: 0.34828

Collected Steps per Second: 22,062.00650
Overall Steps per Second: 10,629.60479

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.43760
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.70403

Cumulative Model Updates: 141,400
Cumulative Timesteps: 1,180,033,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,052.05087
Policy Entropy: 1.71164
Value Function Loss: 0.05607

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.31310
Value Function Update Magnitude: 0.35446

Collected Steps per Second: 21,963.95137
Overall Steps per Second: 10,457.02969

Timestep Collection Time: 2.27737
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.78339

Cumulative Model Updates: 141,406
Cumulative Timesteps: 1,180,083,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1180083320...
Checkpoint 1180083320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,243.39349
Policy Entropy: 1.70872
Value Function Loss: 0.05837

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.32262
Value Function Update Magnitude: 0.36083

Collected Steps per Second: 22,058.90688
Overall Steps per Second: 10,634.29197

Timestep Collection Time: 2.26720
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.70290

Cumulative Model Updates: 141,412
Cumulative Timesteps: 1,180,133,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,684.04116
Policy Entropy: 1.70996
Value Function Loss: 0.06048

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.32747
Value Function Update Magnitude: 0.38707

Collected Steps per Second: 22,036.21380
Overall Steps per Second: 10,508.98689

Timestep Collection Time: 2.27063
Timestep Consumption Time: 2.49063
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.76126

Cumulative Model Updates: 141,418
Cumulative Timesteps: 1,180,183,368

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1180183368...
Checkpoint 1180183368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,675.21810
Policy Entropy: 1.69975
Value Function Loss: 0.06211

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.33210
Value Function Update Magnitude: 0.40987

Collected Steps per Second: 21,488.51745
Overall Steps per Second: 10,499.55699

Timestep Collection Time: 2.32850
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.76553

Cumulative Model Updates: 141,424
Cumulative Timesteps: 1,180,233,404

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,192.46490
Policy Entropy: 1.69633
Value Function Loss: 0.05845

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.33428
Value Function Update Magnitude: 0.40471

Collected Steps per Second: 21,334.21327
Overall Steps per Second: 10,527.48496

Timestep Collection Time: 2.34440
Timestep Consumption Time: 2.40659
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.75099

Cumulative Model Updates: 141,430
Cumulative Timesteps: 1,180,283,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1180283420...
Checkpoint 1180283420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,396.46831
Policy Entropy: 1.70159
Value Function Loss: 0.05349

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.32634
Value Function Update Magnitude: 0.38687

Collected Steps per Second: 21,213.82663
Overall Steps per Second: 10,282.44282

Timestep Collection Time: 2.35808
Timestep Consumption Time: 2.50691
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.86499

Cumulative Model Updates: 141,436
Cumulative Timesteps: 1,180,333,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,721.24993
Policy Entropy: 1.70488
Value Function Loss: 0.04784

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.31446
Value Function Update Magnitude: 0.36080

Collected Steps per Second: 21,743.28224
Overall Steps per Second: 10,385.60574

Timestep Collection Time: 2.30020
Timestep Consumption Time: 2.51550
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.81570

Cumulative Model Updates: 141,442
Cumulative Timesteps: 1,180,383,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1180383458...
Checkpoint 1180383458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,919.56270
Policy Entropy: 1.71165
Value Function Loss: 0.04898

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.31208
Value Function Update Magnitude: 0.33745

Collected Steps per Second: 21,688.51554
Overall Steps per Second: 10,548.31633

Timestep Collection Time: 2.30629
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.74199

Cumulative Model Updates: 141,448
Cumulative Timesteps: 1,180,433,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,078.12734
Policy Entropy: 1.70979
Value Function Loss: 0.05408

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.31595
Value Function Update Magnitude: 0.32314

Collected Steps per Second: 21,937.27079
Overall Steps per Second: 10,574.43840

Timestep Collection Time: 2.27950
Timestep Consumption Time: 2.44945
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.72895

Cumulative Model Updates: 141,454
Cumulative Timesteps: 1,180,483,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1180483484...
Checkpoint 1180483484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,995.15973
Policy Entropy: 1.71006
Value Function Loss: 0.05486

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08502
Policy Update Magnitude: 0.31817
Value Function Update Magnitude: 0.33214

Collected Steps per Second: 21,898.29378
Overall Steps per Second: 10,566.77929

Timestep Collection Time: 2.28383
Timestep Consumption Time: 2.44912
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.73295

Cumulative Model Updates: 141,460
Cumulative Timesteps: 1,180,533,496

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,931.53304
Policy Entropy: 1.70337
Value Function Loss: 0.05270

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.31577
Value Function Update Magnitude: 0.33759

Collected Steps per Second: 22,048.30226
Overall Steps per Second: 10,495.91852

Timestep Collection Time: 2.26956
Timestep Consumption Time: 2.49800
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.76757

Cumulative Model Updates: 141,466
Cumulative Timesteps: 1,180,583,536

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1180583536...
Checkpoint 1180583536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,819.95030
Policy Entropy: 1.70201
Value Function Loss: 0.05120

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.31560
Value Function Update Magnitude: 0.32763

Collected Steps per Second: 21,835.50655
Overall Steps per Second: 10,568.36830

Timestep Collection Time: 2.29003
Timestep Consumption Time: 2.44145
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.73148

Cumulative Model Updates: 141,472
Cumulative Timesteps: 1,180,633,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,006.02566
Policy Entropy: 1.71803
Value Function Loss: 0.04953

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.31361
Value Function Update Magnitude: 0.33248

Collected Steps per Second: 22,057.85328
Overall Steps per Second: 10,612.82105

Timestep Collection Time: 2.26822
Timestep Consumption Time: 2.44608
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.71430

Cumulative Model Updates: 141,478
Cumulative Timesteps: 1,180,683,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1180683572...
Checkpoint 1180683572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,937.83595
Policy Entropy: 1.71792
Value Function Loss: 0.05257

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.31345
Value Function Update Magnitude: 0.33325

Collected Steps per Second: 22,065.36395
Overall Steps per Second: 10,531.62599

Timestep Collection Time: 2.26645
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.74855

Cumulative Model Updates: 141,484
Cumulative Timesteps: 1,180,733,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,966.78882
Policy Entropy: 1.70799
Value Function Loss: 0.05332

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.31693
Value Function Update Magnitude: 0.32267

Collected Steps per Second: 21,848.91580
Overall Steps per Second: 10,464.23442

Timestep Collection Time: 2.28972
Timestep Consumption Time: 2.49113
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.78086

Cumulative Model Updates: 141,490
Cumulative Timesteps: 1,180,783,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1180783610...
Checkpoint 1180783610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,191.44139
Policy Entropy: 1.69495
Value Function Loss: 0.05587

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.32061
Value Function Update Magnitude: 0.30941

Collected Steps per Second: 21,407.35144
Overall Steps per Second: 10,343.67080

Timestep Collection Time: 2.33621
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.83503

Cumulative Model Updates: 141,496
Cumulative Timesteps: 1,180,833,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,689.51811
Policy Entropy: 1.68604
Value Function Loss: 0.05309

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.31817
Value Function Update Magnitude: 0.34348

Collected Steps per Second: 21,548.77908
Overall Steps per Second: 10,331.20560

Timestep Collection Time: 2.32125
Timestep Consumption Time: 2.52040
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.84164

Cumulative Model Updates: 141,502
Cumulative Timesteps: 1,180,883,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1180883642...
Checkpoint 1180883642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,141.86975
Policy Entropy: 1.68904
Value Function Loss: 0.05055

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.30435
Value Function Update Magnitude: 0.33167

Collected Steps per Second: 21,648.77245
Overall Steps per Second: 10,392.70902

Timestep Collection Time: 2.31062
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.81318

Cumulative Model Updates: 141,508
Cumulative Timesteps: 1,180,933,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,024.51856
Policy Entropy: 1.70079
Value Function Loss: 0.05283

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.30441
Value Function Update Magnitude: 0.28212

Collected Steps per Second: 22,271.03252
Overall Steps per Second: 10,609.47676

Timestep Collection Time: 2.24543
Timestep Consumption Time: 2.46809
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.71352

Cumulative Model Updates: 141,514
Cumulative Timesteps: 1,180,983,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1180983672...
Checkpoint 1180983672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,788.72309
Policy Entropy: 1.70960
Value Function Loss: 0.05188

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.30334

Collected Steps per Second: 22,108.56846
Overall Steps per Second: 10,638.85992

Timestep Collection Time: 2.26157
Timestep Consumption Time: 2.43819
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.69975

Cumulative Model Updates: 141,520
Cumulative Timesteps: 1,181,033,672

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,997.36532
Policy Entropy: 1.72707
Value Function Loss: 0.05130

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.31075
Value Function Update Magnitude: 0.32573

Collected Steps per Second: 21,985.71913
Overall Steps per Second: 10,518.01409

Timestep Collection Time: 2.27457
Timestep Consumption Time: 2.47994
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.75451

Cumulative Model Updates: 141,526
Cumulative Timesteps: 1,181,083,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1181083680...
Checkpoint 1181083680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,389.32257
Policy Entropy: 1.70787
Value Function Loss: 0.05263

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.31136
Value Function Update Magnitude: 0.33797

Collected Steps per Second: 21,738.23774
Overall Steps per Second: 10,582.00924

Timestep Collection Time: 2.30129
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.72746

Cumulative Model Updates: 141,532
Cumulative Timesteps: 1,181,133,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,090.13645
Policy Entropy: 1.69509
Value Function Loss: 0.05202

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.31177
Value Function Update Magnitude: 0.33482

Collected Steps per Second: 21,928.53351
Overall Steps per Second: 10,519.69577

Timestep Collection Time: 2.28123
Timestep Consumption Time: 2.47404
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.75527

Cumulative Model Updates: 141,538
Cumulative Timesteps: 1,181,183,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1181183730...
Checkpoint 1181183730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,184.91796
Policy Entropy: 1.69596
Value Function Loss: 0.05240

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.30738
Value Function Update Magnitude: 0.33606

Collected Steps per Second: 21,900.01120
Overall Steps per Second: 10,589.12095

Timestep Collection Time: 2.28365
Timestep Consumption Time: 2.43931
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.72296

Cumulative Model Updates: 141,544
Cumulative Timesteps: 1,181,233,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,359.42165
Policy Entropy: 1.70642
Value Function Loss: 0.05148

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.31164
Value Function Update Magnitude: 0.35561

Collected Steps per Second: 21,911.94518
Overall Steps per Second: 10,494.99937

Timestep Collection Time: 2.28186
Timestep Consumption Time: 2.48231
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.76417

Cumulative Model Updates: 141,550
Cumulative Timesteps: 1,181,283,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1181283742...
Checkpoint 1181283742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,138.84895
Policy Entropy: 1.70585
Value Function Loss: 0.05135

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.31323
Value Function Update Magnitude: 0.36545

Collected Steps per Second: 21,373.29464
Overall Steps per Second: 10,335.87332

Timestep Collection Time: 2.34058
Timestep Consumption Time: 2.49945
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.84004

Cumulative Model Updates: 141,556
Cumulative Timesteps: 1,181,333,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,494.07857
Policy Entropy: 1.69393
Value Function Loss: 0.05134

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.31069
Value Function Update Magnitude: 0.35703

Collected Steps per Second: 21,608.01402
Overall Steps per Second: 10,334.70505

Timestep Collection Time: 2.31460
Timestep Consumption Time: 2.52482
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.83942

Cumulative Model Updates: 141,562
Cumulative Timesteps: 1,181,383,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1181383782...
Checkpoint 1181383782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,305.21226
Policy Entropy: 1.69564
Value Function Loss: 0.04962

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.33779

Collected Steps per Second: 21,268.19593
Overall Steps per Second: 10,270.57873

Timestep Collection Time: 2.35112
Timestep Consumption Time: 2.51755
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.86866

Cumulative Model Updates: 141,568
Cumulative Timesteps: 1,181,433,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,967.73983
Policy Entropy: 1.68954
Value Function Loss: 0.04883

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.31023
Value Function Update Magnitude: 0.33669

Collected Steps per Second: 21,540.46702
Overall Steps per Second: 10,422.24285

Timestep Collection Time: 2.32363
Timestep Consumption Time: 2.47879
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.80242

Cumulative Model Updates: 141,574
Cumulative Timesteps: 1,181,483,838

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1181483838...
Checkpoint 1181483838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,323.69070
Policy Entropy: 1.69184
Value Function Loss: 0.04698

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.30767
Value Function Update Magnitude: 0.31454

Collected Steps per Second: 21,602.29907
Overall Steps per Second: 10,554.20084

Timestep Collection Time: 2.31540
Timestep Consumption Time: 2.42375
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73916

Cumulative Model Updates: 141,580
Cumulative Timesteps: 1,181,533,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,657.33852
Policy Entropy: 1.68014
Value Function Loss: 0.04354

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.29902
Value Function Update Magnitude: 0.30692

Collected Steps per Second: 21,778.82239
Overall Steps per Second: 10,493.56487

Timestep Collection Time: 2.29682
Timestep Consumption Time: 2.47010
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.76692

Cumulative Model Updates: 141,586
Cumulative Timesteps: 1,181,583,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1181583878...
Checkpoint 1181583878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,884.21966
Policy Entropy: 1.69142
Value Function Loss: 0.04809

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.30519
Value Function Update Magnitude: 0.29845

Collected Steps per Second: 21,835.71645
Overall Steps per Second: 10,542.61534

Timestep Collection Time: 2.28983
Timestep Consumption Time: 2.45283
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.74266

Cumulative Model Updates: 141,592
Cumulative Timesteps: 1,181,633,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,317.61237
Policy Entropy: 1.70943
Value Function Loss: 0.05072

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.30685
Value Function Update Magnitude: 0.31060

Collected Steps per Second: 20,920.39445
Overall Steps per Second: 10,147.47378

Timestep Collection Time: 2.39049
Timestep Consumption Time: 2.53783
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.92832

Cumulative Model Updates: 141,598
Cumulative Timesteps: 1,181,683,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1181683888...
Checkpoint 1181683888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,741.91798
Policy Entropy: 1.70831
Value Function Loss: 0.05221

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.30470
Value Function Update Magnitude: 0.32670

Collected Steps per Second: 21,182.27433
Overall Steps per Second: 10,285.23174

Timestep Collection Time: 2.36103
Timestep Consumption Time: 2.50148
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.86251

Cumulative Model Updates: 141,604
Cumulative Timesteps: 1,181,733,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,821.19308
Policy Entropy: 1.71161
Value Function Loss: 0.04585

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.30090
Value Function Update Magnitude: 0.32022

Collected Steps per Second: 21,764.18919
Overall Steps per Second: 10,385.31929

Timestep Collection Time: 2.29947
Timestep Consumption Time: 2.51945
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.81892

Cumulative Model Updates: 141,610
Cumulative Timesteps: 1,181,783,946

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1181783946...
Checkpoint 1181783946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,961.44487
Policy Entropy: 1.70142
Value Function Loss: 0.04614

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.30101
Value Function Update Magnitude: 0.30123

Collected Steps per Second: 21,028.74175
Overall Steps per Second: 10,565.11455

Timestep Collection Time: 2.37970
Timestep Consumption Time: 2.35684
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.73653

Cumulative Model Updates: 141,616
Cumulative Timesteps: 1,181,833,988

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,880.60585
Policy Entropy: 1.69981
Value Function Loss: 0.04786

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.30397
Value Function Update Magnitude: 0.30273

Collected Steps per Second: 21,524.70229
Overall Steps per Second: 10,563.17683

Timestep Collection Time: 2.32291
Timestep Consumption Time: 2.41051
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.73342

Cumulative Model Updates: 141,622
Cumulative Timesteps: 1,181,883,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1181883988...
Checkpoint 1181883988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,333.75819
Policy Entropy: 1.70929
Value Function Loss: 0.05171

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.30644
Value Function Update Magnitude: 0.28858

Collected Steps per Second: 21,279.23805
Overall Steps per Second: 10,575.49302

Timestep Collection Time: 2.35046
Timestep Consumption Time: 2.37896
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.72942

Cumulative Model Updates: 141,628
Cumulative Timesteps: 1,181,934,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,484.02974
Policy Entropy: 1.71155
Value Function Loss: 0.05123

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07804
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.27790

Collected Steps per Second: 21,470.46826
Overall Steps per Second: 10,476.52875

Timestep Collection Time: 2.32980
Timestep Consumption Time: 2.44487
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.77467

Cumulative Model Updates: 141,634
Cumulative Timesteps: 1,181,984,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1181984026...
Checkpoint 1181984026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,850.05256
Policy Entropy: 1.71375
Value Function Loss: 0.04956

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.31332
Value Function Update Magnitude: 0.29891

Collected Steps per Second: 21,351.31883
Overall Steps per Second: 10,649.59144

Timestep Collection Time: 2.34281
Timestep Consumption Time: 2.35428
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.69708

Cumulative Model Updates: 141,640
Cumulative Timesteps: 1,182,034,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,316.87330
Policy Entropy: 1.70578
Value Function Loss: 0.04976

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.31164
Value Function Update Magnitude: 0.31924

Collected Steps per Second: 21,649.06603
Overall Steps per Second: 10,624.53230

Timestep Collection Time: 2.31040
Timestep Consumption Time: 2.39738
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.70778

Cumulative Model Updates: 141,646
Cumulative Timesteps: 1,182,084,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1182084066...
Checkpoint 1182084066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,218.14043
Policy Entropy: 1.69668
Value Function Loss: 0.04988

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.30928
Value Function Update Magnitude: 0.31323

Collected Steps per Second: 21,416.80847
Overall Steps per Second: 10,454.96468

Timestep Collection Time: 2.33518
Timestep Consumption Time: 2.44839
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.78356

Cumulative Model Updates: 141,652
Cumulative Timesteps: 1,182,134,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,972.79331
Policy Entropy: 1.69575
Value Function Loss: 0.05035

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.29836
Value Function Update Magnitude: 0.30926

Collected Steps per Second: 21,751.07083
Overall Steps per Second: 10,440.09642

Timestep Collection Time: 2.29874
Timestep Consumption Time: 2.49049
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.78923

Cumulative Model Updates: 141,658
Cumulative Timesteps: 1,182,184,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1182184078...
Checkpoint 1182184078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,984.63047
Policy Entropy: 1.68412
Value Function Loss: 0.04726

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09187
Policy Update Magnitude: 0.29081
Value Function Update Magnitude: 0.31056

Collected Steps per Second: 21,107.03311
Overall Steps per Second: 10,305.25670

Timestep Collection Time: 2.36897
Timestep Consumption Time: 2.48311
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.85209

Cumulative Model Updates: 141,664
Cumulative Timesteps: 1,182,234,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,020.46881
Policy Entropy: 1.67116
Value Function Loss: 0.04450

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.27555
Value Function Update Magnitude: 0.29865

Collected Steps per Second: 21,656.82973
Overall Steps per Second: 10,394.50107

Timestep Collection Time: 2.30985
Timestep Consumption Time: 2.50270
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.81254

Cumulative Model Updates: 141,670
Cumulative Timesteps: 1,182,284,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1182284104...
Checkpoint 1182284104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,484.78697
Policy Entropy: 1.66880
Value Function Loss: 0.04278

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07741
Policy Update Magnitude: 0.28935
Value Function Update Magnitude: 0.28713

Collected Steps per Second: 21,695.16407
Overall Steps per Second: 10,526.42967

Timestep Collection Time: 2.30512
Timestep Consumption Time: 2.44578
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.75090

Cumulative Model Updates: 141,676
Cumulative Timesteps: 1,182,334,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,374.15183
Policy Entropy: 1.68473
Value Function Loss: 0.04225

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07720
Policy Update Magnitude: 0.29381
Value Function Update Magnitude: 0.28350

Collected Steps per Second: 22,150.51832
Overall Steps per Second: 10,469.13827

Timestep Collection Time: 2.25855
Timestep Consumption Time: 2.52007
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.77862

Cumulative Model Updates: 141,682
Cumulative Timesteps: 1,182,384,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1182384142...
Checkpoint 1182384142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,706.47011
Policy Entropy: 1.67566
Value Function Loss: 0.04543

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.29787
Value Function Update Magnitude: 0.27820

Collected Steps per Second: 21,761.41718
Overall Steps per Second: 10,537.89320

Timestep Collection Time: 2.29801
Timestep Consumption Time: 2.44753
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.74554

Cumulative Model Updates: 141,688
Cumulative Timesteps: 1,182,434,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,965.01085
Policy Entropy: 1.68497
Value Function Loss: 0.04866

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.30113
Value Function Update Magnitude: 0.27677

Collected Steps per Second: 22,030.97452
Overall Steps per Second: 10,675.76409

Timestep Collection Time: 2.27062
Timestep Consumption Time: 2.41513
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.68575

Cumulative Model Updates: 141,694
Cumulative Timesteps: 1,182,484,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1182484174...
Checkpoint 1182484174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,913.87511
Policy Entropy: 1.67350
Value Function Loss: 0.05161

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.30948
Value Function Update Magnitude: 0.28877

Collected Steps per Second: 22,047.80290
Overall Steps per Second: 10,546.42952

Timestep Collection Time: 2.26807
Timestep Consumption Time: 2.47344
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.74151

Cumulative Model Updates: 141,700
Cumulative Timesteps: 1,182,534,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,443.13309
Policy Entropy: 1.68451
Value Function Loss: 0.05011

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.31235
Value Function Update Magnitude: 0.30919

Collected Steps per Second: 22,261.48095
Overall Steps per Second: 10,536.88533

Timestep Collection Time: 2.24720
Timestep Consumption Time: 2.50050
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.74770

Cumulative Model Updates: 141,706
Cumulative Timesteps: 1,182,584,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1182584206...
Checkpoint 1182584206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,668.37972
Policy Entropy: 1.67526
Value Function Loss: 0.04693

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.30809
Value Function Update Magnitude: 0.31838

Collected Steps per Second: 21,780.34407
Overall Steps per Second: 10,597.80914

Timestep Collection Time: 2.29583
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.71833

Cumulative Model Updates: 141,712
Cumulative Timesteps: 1,182,634,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,075.53092
Policy Entropy: 1.67566
Value Function Loss: 0.04394

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.30181
Value Function Update Magnitude: 0.31917

Collected Steps per Second: 22,105.02174
Overall Steps per Second: 10,508.13044

Timestep Collection Time: 2.26338
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.76127

Cumulative Model Updates: 141,718
Cumulative Timesteps: 1,182,684,242

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1182684242...
Checkpoint 1182684242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,149.67540
Policy Entropy: 1.68255
Value Function Loss: 0.04485

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.30149
Value Function Update Magnitude: 0.31750

Collected Steps per Second: 20,604.79970
Overall Steps per Second: 10,494.14211

Timestep Collection Time: 2.42875
Timestep Consumption Time: 2.34000
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.76876

Cumulative Model Updates: 141,724
Cumulative Timesteps: 1,182,734,286

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,480.14101
Policy Entropy: 1.69650
Value Function Loss: 0.05023

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.30335
Value Function Update Magnitude: 0.31310

Collected Steps per Second: 21,154.95333
Overall Steps per Second: 10,472.91159

Timestep Collection Time: 2.36361
Timestep Consumption Time: 2.41081
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.77441

Cumulative Model Updates: 141,730
Cumulative Timesteps: 1,182,784,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1182784288...
Checkpoint 1182784288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,318.31749
Policy Entropy: 1.69789
Value Function Loss: 0.05151

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.31349
Value Function Update Magnitude: 0.32591

Collected Steps per Second: 20,923.34839
Overall Steps per Second: 10,400.62128

Timestep Collection Time: 2.39025
Timestep Consumption Time: 2.41831
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.80856

Cumulative Model Updates: 141,736
Cumulative Timesteps: 1,182,834,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,024.64220
Policy Entropy: 1.69328
Value Function Loss: 0.05143

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.31798
Value Function Update Magnitude: 0.33917

Collected Steps per Second: 21,748.72065
Overall Steps per Second: 10,700.00910

Timestep Collection Time: 2.29945
Timestep Consumption Time: 2.37438
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.67383

Cumulative Model Updates: 141,742
Cumulative Timesteps: 1,182,884,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1182884310...
Checkpoint 1182884310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,965.47000
Policy Entropy: 1.67910
Value Function Loss: 0.04620

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.31280
Value Function Update Magnitude: 0.33905

Collected Steps per Second: 21,058.89341
Overall Steps per Second: 10,298.33651

Timestep Collection Time: 2.37496
Timestep Consumption Time: 2.48155
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.85651

Cumulative Model Updates: 141,748
Cumulative Timesteps: 1,182,934,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,402.37536
Policy Entropy: 1.67616
Value Function Loss: 0.04662

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.30745
Value Function Update Magnitude: 0.33466

Collected Steps per Second: 21,832.18297
Overall Steps per Second: 10,473.11748

Timestep Collection Time: 2.29249
Timestep Consumption Time: 2.48641
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.77890

Cumulative Model Updates: 141,754
Cumulative Timesteps: 1,182,984,374

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1182984374...
Checkpoint 1182984374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,862.83845
Policy Entropy: 1.68830
Value Function Loss: 0.04767

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.30636
Value Function Update Magnitude: 0.32337

Collected Steps per Second: 21,834.40525
Overall Steps per Second: 10,540.02452

Timestep Collection Time: 2.29051
Timestep Consumption Time: 2.45445
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.74496

Cumulative Model Updates: 141,760
Cumulative Timesteps: 1,183,034,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,827.14600
Policy Entropy: 1.70100
Value Function Loss: 0.04909

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.30978
Value Function Update Magnitude: 0.33746

Collected Steps per Second: 22,107.91049
Overall Steps per Second: 10,528.77250

Timestep Collection Time: 2.26218
Timestep Consumption Time: 2.48785
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.75003

Cumulative Model Updates: 141,766
Cumulative Timesteps: 1,183,084,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1183084398...
Checkpoint 1183084398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,434.87274
Policy Entropy: 1.71231
Value Function Loss: 0.05077

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.30869
Value Function Update Magnitude: 0.34519

Collected Steps per Second: 22,007.54575
Overall Steps per Second: 10,654.08068

Timestep Collection Time: 2.27286
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.69491

Cumulative Model Updates: 141,772
Cumulative Timesteps: 1,183,134,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,478.53594
Policy Entropy: 1.70509
Value Function Loss: 0.05099

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.31398
Value Function Update Magnitude: 0.35221

Collected Steps per Second: 21,950.73813
Overall Steps per Second: 10,452.21664

Timestep Collection Time: 2.27901
Timestep Consumption Time: 2.50715
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.78616

Cumulative Model Updates: 141,778
Cumulative Timesteps: 1,183,184,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1183184444...
Checkpoint 1183184444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,753.78248
Policy Entropy: 1.70649
Value Function Loss: 0.05226

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.31652
Value Function Update Magnitude: 0.36736

Collected Steps per Second: 21,565.33383
Overall Steps per Second: 10,516.22809

Timestep Collection Time: 2.31928
Timestep Consumption Time: 2.43680
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.75608

Cumulative Model Updates: 141,784
Cumulative Timesteps: 1,183,234,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,886.86758
Policy Entropy: 1.69774
Value Function Loss: 0.05260

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.31889
Value Function Update Magnitude: 0.36258

Collected Steps per Second: 21,527.47772
Overall Steps per Second: 10,586.85800

Timestep Collection Time: 2.32429
Timestep Consumption Time: 2.40195
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.72624

Cumulative Model Updates: 141,790
Cumulative Timesteps: 1,183,284,496

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1183284496...
Checkpoint 1183284496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,033.68310
Policy Entropy: 1.69110
Value Function Loss: 0.05470

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.32056
Value Function Update Magnitude: 0.35713

Collected Steps per Second: 21,301.83854
Overall Steps per Second: 10,497.08670

Timestep Collection Time: 2.34834
Timestep Consumption Time: 2.41717
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.76551

Cumulative Model Updates: 141,796
Cumulative Timesteps: 1,183,334,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,402.47149
Policy Entropy: 1.68268
Value Function Loss: 0.05546

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.32274
Value Function Update Magnitude: 0.35901

Collected Steps per Second: 21,583.39032
Overall Steps per Second: 10,494.94166

Timestep Collection Time: 2.31660
Timestep Consumption Time: 2.44760
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.76420

Cumulative Model Updates: 141,802
Cumulative Timesteps: 1,183,384,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1183384520...
Checkpoint 1183384520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,398.35615
Policy Entropy: 1.68839
Value Function Loss: 0.05204

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08756
Policy Update Magnitude: 0.31693
Value Function Update Magnitude: 0.34358

Collected Steps per Second: 21,690.96345
Overall Steps per Second: 10,371.42726

Timestep Collection Time: 2.30548
Timestep Consumption Time: 2.51623
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.82171

Cumulative Model Updates: 141,808
Cumulative Timesteps: 1,183,434,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,630.93464
Policy Entropy: 1.68719
Value Function Loss: 0.04857

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08584
Policy Update Magnitude: 0.31190
Value Function Update Magnitude: 0.33329

Collected Steps per Second: 22,238.31159
Overall Steps per Second: 10,517.13341

Timestep Collection Time: 2.24855
Timestep Consumption Time: 2.50598
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.75453

Cumulative Model Updates: 141,814
Cumulative Timesteps: 1,183,484,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1183484532...
Checkpoint 1183484532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,690.71563
Policy Entropy: 1.68793
Value Function Loss: 0.04967

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.31515
Value Function Update Magnitude: 0.30962

Collected Steps per Second: 22,096.86935
Overall Steps per Second: 10,477.23003

Timestep Collection Time: 2.26295
Timestep Consumption Time: 2.50969
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.77264

Cumulative Model Updates: 141,820
Cumulative Timesteps: 1,183,534,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,668.64515
Policy Entropy: 1.67759
Value Function Loss: 0.05305

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.31769
Value Function Update Magnitude: 0.32378

Collected Steps per Second: 21,752.28679
Overall Steps per Second: 10,396.00137

Timestep Collection Time: 2.29861
Timestep Consumption Time: 2.51093
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.80954

Cumulative Model Updates: 141,826
Cumulative Timesteps: 1,183,584,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1183584536...
Checkpoint 1183584536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,763.49838
Policy Entropy: 1.67183
Value Function Loss: 0.05672

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.30798
Value Function Update Magnitude: 0.34296

Collected Steps per Second: 21,698.65019
Overall Steps per Second: 10,548.58819

Timestep Collection Time: 2.30429
Timestep Consumption Time: 2.43568
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73997

Cumulative Model Updates: 141,832
Cumulative Timesteps: 1,183,634,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,409.47574
Policy Entropy: 1.67062
Value Function Loss: 0.05370

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.29662
Value Function Update Magnitude: 0.35929

Collected Steps per Second: 21,756.35854
Overall Steps per Second: 10,541.63638

Timestep Collection Time: 2.29882
Timestep Consumption Time: 2.44560
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.74442

Cumulative Model Updates: 141,838
Cumulative Timesteps: 1,183,684,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1183684550...
Checkpoint 1183684550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,356.25661
Policy Entropy: 1.66618
Value Function Loss: 0.05264

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.30417
Value Function Update Magnitude: 0.33953

Collected Steps per Second: 21,882.52551
Overall Steps per Second: 10,601.97632

Timestep Collection Time: 2.28548
Timestep Consumption Time: 2.43176
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.71723

Cumulative Model Updates: 141,844
Cumulative Timesteps: 1,183,734,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,746.92142
Policy Entropy: 1.67340
Value Function Loss: 0.04926

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.31342
Value Function Update Magnitude: 0.32906

Collected Steps per Second: 21,499.94280
Overall Steps per Second: 10,474.46825

Timestep Collection Time: 2.32763
Timestep Consumption Time: 2.45008
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.77771

Cumulative Model Updates: 141,850
Cumulative Timesteps: 1,183,784,606

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1183784606...
Checkpoint 1183784606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,293.75365
Policy Entropy: 1.67342
Value Function Loss: 0.05150

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.31519
Value Function Update Magnitude: 0.32825

Collected Steps per Second: 21,233.56154
Overall Steps per Second: 10,279.55736

Timestep Collection Time: 2.35636
Timestep Consumption Time: 2.51097
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.86733

Cumulative Model Updates: 141,856
Cumulative Timesteps: 1,183,834,640

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,087.23151
Policy Entropy: 1.68024
Value Function Loss: 0.05228

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.31438
Value Function Update Magnitude: 0.33117

Collected Steps per Second: 21,467.16473
Overall Steps per Second: 10,417.55629

Timestep Collection Time: 2.32970
Timestep Consumption Time: 2.47104
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.80074

Cumulative Model Updates: 141,862
Cumulative Timesteps: 1,183,884,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1183884652...
Checkpoint 1183884652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,769.37314
Policy Entropy: 1.68807
Value Function Loss: 0.05341

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.31494
Value Function Update Magnitude: 0.33664

Collected Steps per Second: 21,554.06553
Overall Steps per Second: 10,352.97380

Timestep Collection Time: 2.32142
Timestep Consumption Time: 2.51159
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.83301

Cumulative Model Updates: 141,868
Cumulative Timesteps: 1,183,934,688

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,933.36669
Policy Entropy: 1.70303
Value Function Loss: 0.05252

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.31515
Value Function Update Magnitude: 0.34341

Collected Steps per Second: 22,116.44480
Overall Steps per Second: 10,521.55429

Timestep Collection Time: 2.26139
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.75348

Cumulative Model Updates: 141,874
Cumulative Timesteps: 1,183,984,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1183984702...
Checkpoint 1183984702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,721.18655
Policy Entropy: 1.69957
Value Function Loss: 0.05134

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.31490
Value Function Update Magnitude: 0.33549

Collected Steps per Second: 21,788.52760
Overall Steps per Second: 10,406.81819

Timestep Collection Time: 2.29616
Timestep Consumption Time: 2.51126
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.80743

Cumulative Model Updates: 141,880
Cumulative Timesteps: 1,184,034,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,820.40824
Policy Entropy: 1.69304
Value Function Loss: 0.05483

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.31468
Value Function Update Magnitude: 0.30918

Collected Steps per Second: 22,111.69323
Overall Steps per Second: 10,472.14613

Timestep Collection Time: 2.26179
Timestep Consumption Time: 2.51393
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.77572

Cumulative Model Updates: 141,886
Cumulative Timesteps: 1,184,084,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1184084744...
Checkpoint 1184084744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,074.53726
Policy Entropy: 1.68464
Value Function Loss: 0.05693

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.29344
Value Function Update Magnitude: 0.29878

Collected Steps per Second: 22,006.62223
Overall Steps per Second: 10,654.66503

Timestep Collection Time: 2.27286
Timestep Consumption Time: 2.42161
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.69447

Cumulative Model Updates: 141,892
Cumulative Timesteps: 1,184,134,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,956.84587
Policy Entropy: 1.69357
Value Function Loss: 0.05689

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.29349
Value Function Update Magnitude: 0.35459

Collected Steps per Second: 22,114.24390
Overall Steps per Second: 10,514.93834

Timestep Collection Time: 2.26216
Timestep Consumption Time: 2.49545
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.75761

Cumulative Model Updates: 141,898
Cumulative Timesteps: 1,184,184,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1184184788...
Checkpoint 1184184788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,154.32290
Policy Entropy: 1.69571
Value Function Loss: 0.05046

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.31364
Value Function Update Magnitude: 0.36675

Collected Steps per Second: 21,404.03007
Overall Steps per Second: 10,556.25774

Timestep Collection Time: 2.33629
Timestep Consumption Time: 2.40081
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.73710

Cumulative Model Updates: 141,904
Cumulative Timesteps: 1,184,234,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,736.10128
Policy Entropy: 1.70650
Value Function Loss: 0.05289

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.31638
Value Function Update Magnitude: 0.35129

Collected Steps per Second: 21,234.62542
Overall Steps per Second: 10,448.55431

Timestep Collection Time: 2.35587
Timestep Consumption Time: 2.43197
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.78784

Cumulative Model Updates: 141,910
Cumulative Timesteps: 1,184,284,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1184284820...
Checkpoint 1184284820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,061.31593
Policy Entropy: 1.69229
Value Function Loss: 0.05252

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.31474
Value Function Update Magnitude: 0.34111

Collected Steps per Second: 20,674.15808
Overall Steps per Second: 10,328.22646

Timestep Collection Time: 2.41954
Timestep Consumption Time: 2.42369
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.84323

Cumulative Model Updates: 141,916
Cumulative Timesteps: 1,184,334,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,597.12487
Policy Entropy: 1.69129
Value Function Loss: 0.05488

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.30586
Value Function Update Magnitude: 0.35305

Collected Steps per Second: 21,143.76475
Overall Steps per Second: 10,296.86488

Timestep Collection Time: 2.36628
Timestep Consumption Time: 2.49268
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.85895

Cumulative Model Updates: 141,922
Cumulative Timesteps: 1,184,384,874

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1184384874...
Checkpoint 1184384874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,812.81571
Policy Entropy: 1.68102
Value Function Loss: 0.05188

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.31309
Value Function Update Magnitude: 0.36093

Collected Steps per Second: 21,484.66408
Overall Steps per Second: 10,583.23456

Timestep Collection Time: 2.32827
Timestep Consumption Time: 2.39827
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.72653

Cumulative Model Updates: 141,928
Cumulative Timesteps: 1,184,434,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,093.42992
Policy Entropy: 1.67579
Value Function Loss: 0.05285

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.31795
Value Function Update Magnitude: 0.35892

Collected Steps per Second: 21,746.50298
Overall Steps per Second: 10,621.00518

Timestep Collection Time: 2.29996
Timestep Consumption Time: 2.40920
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.70916

Cumulative Model Updates: 141,934
Cumulative Timesteps: 1,184,484,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1184484912...
Checkpoint 1184484912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,958.86066
Policy Entropy: 1.66533
Value Function Loss: 0.05383

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.32353
Value Function Update Magnitude: 0.35389

Collected Steps per Second: 21,754.23352
Overall Steps per Second: 10,541.89318

Timestep Collection Time: 2.29941
Timestep Consumption Time: 2.44565
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.74507

Cumulative Model Updates: 141,940
Cumulative Timesteps: 1,184,534,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,131.87994
Policy Entropy: 1.66425
Value Function Loss: 0.05457

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.32253
Value Function Update Magnitude: 0.37131

Collected Steps per Second: 22,098.32957
Overall Steps per Second: 10,479.08579

Timestep Collection Time: 2.26343
Timestep Consumption Time: 2.50970
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.77313

Cumulative Model Updates: 141,946
Cumulative Timesteps: 1,184,584,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1184584952...
Checkpoint 1184584952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,684.70740
Policy Entropy: 1.66838
Value Function Loss: 0.05595

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09508
Policy Update Magnitude: 0.33065
Value Function Update Magnitude: 0.39023

Collected Steps per Second: 21,728.48570
Overall Steps per Second: 10,537.97161

Timestep Collection Time: 2.30140
Timestep Consumption Time: 2.44391
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.74532

Cumulative Model Updates: 141,952
Cumulative Timesteps: 1,184,634,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,652.93181
Policy Entropy: 1.66455
Value Function Loss: 0.05655

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.33508
Value Function Update Magnitude: 0.37855

Collected Steps per Second: 21,792.74533
Overall Steps per Second: 10,583.72122

Timestep Collection Time: 2.29434
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.72424

Cumulative Model Updates: 141,958
Cumulative Timesteps: 1,184,684,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1184684958...
Checkpoint 1184684958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,774.59612
Policy Entropy: 1.66651
Value Function Loss: 0.05645

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.32929
Value Function Update Magnitude: 0.36436

Collected Steps per Second: 22,034.07034
Overall Steps per Second: 10,647.83075

Timestep Collection Time: 2.26994
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.69729

Cumulative Model Updates: 141,964
Cumulative Timesteps: 1,184,734,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,301.70298
Policy Entropy: 1.67941
Value Function Loss: 0.05248

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.32117
Value Function Update Magnitude: 0.37224

Collected Steps per Second: 21,783.80704
Overall Steps per Second: 10,376.17794

Timestep Collection Time: 2.29602
Timestep Consumption Time: 2.52425
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.82027

Cumulative Model Updates: 141,970
Cumulative Timesteps: 1,184,784,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1184784990...
Checkpoint 1184784990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,032.99320
Policy Entropy: 1.68926
Value Function Loss: 0.05025

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.31939
Value Function Update Magnitude: 0.35979

Collected Steps per Second: 21,950.63351
Overall Steps per Second: 10,626.66914

Timestep Collection Time: 2.27793
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.70533

Cumulative Model Updates: 141,976
Cumulative Timesteps: 1,184,834,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,069.88089
Policy Entropy: 1.69275
Value Function Loss: 0.04809

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.31340
Value Function Update Magnitude: 0.35230

Collected Steps per Second: 21,753.08956
Overall Steps per Second: 10,467.60164

Timestep Collection Time: 2.29926
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.77817

Cumulative Model Updates: 141,982
Cumulative Timesteps: 1,184,885,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1184885008...
Checkpoint 1184885008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,466.60808
Policy Entropy: 1.68647
Value Function Loss: 0.04748

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08284
Policy Update Magnitude: 0.30916
Value Function Update Magnitude: 0.35467

Collected Steps per Second: 21,241.06881
Overall Steps per Second: 10,300.24776

Timestep Collection Time: 2.35572
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.85794

Cumulative Model Updates: 141,988
Cumulative Timesteps: 1,184,935,046

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,928.68879
Policy Entropy: 1.68441
Value Function Loss: 0.04899

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.30679
Value Function Update Magnitude: 0.35369

Collected Steps per Second: 21,569.28404
Overall Steps per Second: 10,353.82784

Timestep Collection Time: 2.31830
Timestep Consumption Time: 2.51122
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.82952

Cumulative Model Updates: 141,994
Cumulative Timesteps: 1,184,985,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1184985050...
Checkpoint 1184985050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,817.07410
Policy Entropy: 1.68076
Value Function Loss: 0.04845

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.36065

Collected Steps per Second: 21,630.19759
Overall Steps per Second: 10,562.46243

Timestep Collection Time: 2.31168
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.73393

Cumulative Model Updates: 142,000
Cumulative Timesteps: 1,185,035,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,962.85334
Policy Entropy: 1.68660
Value Function Loss: 0.04729

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.30861
Value Function Update Magnitude: 0.36678

Collected Steps per Second: 21,615.61740
Overall Steps per Second: 10,500.08029

Timestep Collection Time: 2.31333
Timestep Consumption Time: 2.44892
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.76225

Cumulative Model Updates: 142,006
Cumulative Timesteps: 1,185,085,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1185085056...
Checkpoint 1185085056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,055.86268
Policy Entropy: 1.69006
Value Function Loss: 0.04879

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.30932
Value Function Update Magnitude: 0.32679

Collected Steps per Second: 21,485.45563
Overall Steps per Second: 10,337.09998

Timestep Collection Time: 2.32902
Timestep Consumption Time: 2.51180
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.84082

Cumulative Model Updates: 142,012
Cumulative Timesteps: 1,185,135,096

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,583.29768
Policy Entropy: 1.69841
Value Function Loss: 0.04698

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.30527
Value Function Update Magnitude: 0.28492

Collected Steps per Second: 22,212.33329
Overall Steps per Second: 10,428.48477

Timestep Collection Time: 2.25145
Timestep Consumption Time: 2.54407
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.79552

Cumulative Model Updates: 142,018
Cumulative Timesteps: 1,185,185,106

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1185185106...
Checkpoint 1185185106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,550.35229
Policy Entropy: 1.68962
Value Function Loss: 0.05115

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08209
Policy Update Magnitude: 0.30621
Value Function Update Magnitude: 0.29458

Collected Steps per Second: 22,096.74653
Overall Steps per Second: 10,486.03907

Timestep Collection Time: 2.26314
Timestep Consumption Time: 2.50587
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.76901

Cumulative Model Updates: 142,024
Cumulative Timesteps: 1,185,235,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,572.30231
Policy Entropy: 1.68206
Value Function Loss: 0.05134

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.31541
Value Function Update Magnitude: 0.33341

Collected Steps per Second: 22,252.89430
Overall Steps per Second: 10,516.57184

Timestep Collection Time: 2.24852
Timestep Consumption Time: 2.50931
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.75782

Cumulative Model Updates: 142,030
Cumulative Timesteps: 1,185,285,150

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1185285150...
Checkpoint 1185285150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,619.89339
Policy Entropy: 1.66373
Value Function Loss: 0.05582

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.31838
Value Function Update Magnitude: 0.36609

Collected Steps per Second: 21,929.51691
Overall Steps per Second: 10,602.70491

Timestep Collection Time: 2.28104
Timestep Consumption Time: 2.43682
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.71785

Cumulative Model Updates: 142,036
Cumulative Timesteps: 1,185,335,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,270.73379
Policy Entropy: 1.66098
Value Function Loss: 0.05325

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.32319
Value Function Update Magnitude: 0.36541

Collected Steps per Second: 21,973.01570
Overall Steps per Second: 10,484.43470

Timestep Collection Time: 2.27670
Timestep Consumption Time: 2.49475
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.77145

Cumulative Model Updates: 142,042
Cumulative Timesteps: 1,185,385,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1185385198...
Checkpoint 1185385198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,469.70664
Policy Entropy: 1.65399
Value Function Loss: 0.04979

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.31885
Value Function Update Magnitude: 0.34703

Collected Steps per Second: 20,860.58566
Overall Steps per Second: 10,130.18509

Timestep Collection Time: 2.39888
Timestep Consumption Time: 2.54101
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.93989

Cumulative Model Updates: 142,048
Cumulative Timesteps: 1,185,435,240

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,905.55036
Policy Entropy: 1.65749
Value Function Loss: 0.05125

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.31687
Value Function Update Magnitude: 0.34088

Collected Steps per Second: 21,948.27433
Overall Steps per Second: 10,615.84009

Timestep Collection Time: 2.27954
Timestep Consumption Time: 2.43342
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.71296

Cumulative Model Updates: 142,054
Cumulative Timesteps: 1,185,485,272

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1185485272...
Checkpoint 1185485272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,760.98010
Policy Entropy: 1.66089
Value Function Loss: 0.05280

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.32029
Value Function Update Magnitude: 0.35817

Collected Steps per Second: 21,722.68201
Overall Steps per Second: 10,570.45783

Timestep Collection Time: 2.30193
Timestep Consumption Time: 2.42862
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.73054

Cumulative Model Updates: 142,060
Cumulative Timesteps: 1,185,535,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,053.51472
Policy Entropy: 1.66429
Value Function Loss: 0.05125

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.32209
Value Function Update Magnitude: 0.34706

Collected Steps per Second: 21,463.83031
Overall Steps per Second: 10,520.77898

Timestep Collection Time: 2.33062
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.75478

Cumulative Model Updates: 142,066
Cumulative Timesteps: 1,185,585,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1185585300...
Checkpoint 1185585300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,036.05113
Policy Entropy: 1.66295
Value Function Loss: 0.05238

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.31647
Value Function Update Magnitude: 0.29706

Collected Steps per Second: 21,569.16541
Overall Steps per Second: 10,531.19805

Timestep Collection Time: 2.31812
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.74780

Cumulative Model Updates: 142,072
Cumulative Timesteps: 1,185,635,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,276.23750
Policy Entropy: 1.67808
Value Function Loss: 0.04726

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.31243
Value Function Update Magnitude: 0.29628

Collected Steps per Second: 21,702.31652
Overall Steps per Second: 10,555.69608

Timestep Collection Time: 2.30436
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.73773

Cumulative Model Updates: 142,078
Cumulative Timesteps: 1,185,685,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1185685310...
Checkpoint 1185685310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,204.75763
Policy Entropy: 1.69031
Value Function Loss: 0.04953

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.31284
Value Function Update Magnitude: 0.31681

Collected Steps per Second: 21,895.75479
Overall Steps per Second: 10,517.65001

Timestep Collection Time: 2.28556
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.75810

Cumulative Model Updates: 142,084
Cumulative Timesteps: 1,185,735,354

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,567.19171
Policy Entropy: 1.70129
Value Function Loss: 0.04710

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.29706

Collected Steps per Second: 22,143.54803
Overall Steps per Second: 10,483.87502

Timestep Collection Time: 2.25953
Timestep Consumption Time: 2.51294
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.77247

Cumulative Model Updates: 142,090
Cumulative Timesteps: 1,185,785,388

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1185785388...
Checkpoint 1185785388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,451.85631
Policy Entropy: 1.69828
Value Function Loss: 0.05207

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.31371
Value Function Update Magnitude: 0.28326

Collected Steps per Second: 21,664.65940
Overall Steps per Second: 10,427.94745

Timestep Collection Time: 2.30837
Timestep Consumption Time: 2.48740
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.79577

Cumulative Model Updates: 142,096
Cumulative Timesteps: 1,185,835,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,206.43678
Policy Entropy: 1.69890
Value Function Loss: 0.05121

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.31622
Value Function Update Magnitude: 0.30544

Collected Steps per Second: 21,991.91587
Overall Steps per Second: 10,630.60928

Timestep Collection Time: 2.27438
Timestep Consumption Time: 2.43071
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.70509

Cumulative Model Updates: 142,102
Cumulative Timesteps: 1,185,885,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1185885416...
Checkpoint 1185885416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,866.93860
Policy Entropy: 1.69301
Value Function Loss: 0.05620

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.32240
Value Function Update Magnitude: 0.35059

Collected Steps per Second: 21,741.60734
Overall Steps per Second: 10,397.54444

Timestep Collection Time: 2.30038
Timestep Consumption Time: 2.50979
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.81017

Cumulative Model Updates: 142,108
Cumulative Timesteps: 1,185,935,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,806.12918
Policy Entropy: 1.69305
Value Function Loss: 0.05686

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.33149
Value Function Update Magnitude: 0.36495

Collected Steps per Second: 22,299.68562
Overall Steps per Second: 10,699.69872

Timestep Collection Time: 2.24272
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.67415

Cumulative Model Updates: 142,114
Cumulative Timesteps: 1,185,985,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1185985442...
Checkpoint 1185985442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,906.43596
Policy Entropy: 1.70047
Value Function Loss: 0.05761

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.33176
Value Function Update Magnitude: 0.35681

Collected Steps per Second: 21,302.09197
Overall Steps per Second: 10,284.86634

Timestep Collection Time: 2.34953
Timestep Consumption Time: 2.51684
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.86637

Cumulative Model Updates: 142,120
Cumulative Timesteps: 1,186,035,492

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,706.35706
Policy Entropy: 1.70390
Value Function Loss: 0.05681

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.33003
Value Function Update Magnitude: 0.35409

Collected Steps per Second: 21,747.73523
Overall Steps per Second: 10,447.11397

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.48821
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.78850

Cumulative Model Updates: 142,126
Cumulative Timesteps: 1,186,085,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1186085518...
Checkpoint 1186085518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,939.15667
Policy Entropy: 1.70765
Value Function Loss: 0.05751

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.33140
Value Function Update Magnitude: 0.37660

Collected Steps per Second: 21,458.07909
Overall Steps per Second: 10,326.71969

Timestep Collection Time: 2.33208
Timestep Consumption Time: 2.51379
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.84588

Cumulative Model Updates: 142,132
Cumulative Timesteps: 1,186,135,560

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,886.59932
Policy Entropy: 1.69427
Value Function Loss: 0.05383

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.33248
Value Function Update Magnitude: 0.40666

Collected Steps per Second: 21,866.81254
Overall Steps per Second: 10,384.50927

Timestep Collection Time: 2.28684
Timestep Consumption Time: 2.52860
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.81544

Cumulative Model Updates: 142,138
Cumulative Timesteps: 1,186,185,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1186185566...
Checkpoint 1186185566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,330.77802
Policy Entropy: 1.69127
Value Function Loss: 0.05367

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.32715
Value Function Update Magnitude: 0.38699

Collected Steps per Second: 21,282.66242
Overall Steps per Second: 10,279.39787

Timestep Collection Time: 2.34942
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.86429

Cumulative Model Updates: 142,144
Cumulative Timesteps: 1,186,235,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,729.90249
Policy Entropy: 1.68814
Value Function Loss: 0.05205

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.32275
Value Function Update Magnitude: 0.33269

Collected Steps per Second: 21,681.49872
Overall Steps per Second: 10,386.87443

Timestep Collection Time: 2.30768
Timestep Consumption Time: 2.50936
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.81704

Cumulative Model Updates: 142,150
Cumulative Timesteps: 1,186,285,602

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1186285602...
Checkpoint 1186285602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,300.88443
Policy Entropy: 1.69101
Value Function Loss: 0.05287

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.32405
Value Function Update Magnitude: 0.27254

Collected Steps per Second: 21,748.43140
Overall Steps per Second: 10,513.63117

Timestep Collection Time: 2.29920
Timestep Consumption Time: 2.45691
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.75611

Cumulative Model Updates: 142,156
Cumulative Timesteps: 1,186,335,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,800.74422
Policy Entropy: 1.69866
Value Function Loss: 0.05985

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.32456
Value Function Update Magnitude: 0.25294

Collected Steps per Second: 22,266.13921
Overall Steps per Second: 10,448.51144

Timestep Collection Time: 2.24646
Timestep Consumption Time: 2.54082
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.78728

Cumulative Model Updates: 142,162
Cumulative Timesteps: 1,186,385,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1186385626...
Checkpoint 1186385626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,657.68292
Policy Entropy: 1.69591
Value Function Loss: 0.05636

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.32026
Value Function Update Magnitude: 0.27060

Collected Steps per Second: 21,945.89030
Overall Steps per Second: 10,482.77447

Timestep Collection Time: 2.27860
Timestep Consumption Time: 2.49170
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.77030

Cumulative Model Updates: 142,168
Cumulative Timesteps: 1,186,435,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,095.01028
Policy Entropy: 1.69854
Value Function Loss: 0.05118

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.31126
Value Function Update Magnitude: 0.26408

Collected Steps per Second: 22,421.55481
Overall Steps per Second: 10,751.73673

Timestep Collection Time: 2.23116
Timestep Consumption Time: 2.42167
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.65283

Cumulative Model Updates: 142,174
Cumulative Timesteps: 1,186,485,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1186485658...
Checkpoint 1186485658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,583.48891
Policy Entropy: 1.67863
Value Function Loss: 0.05182

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.31227
Value Function Update Magnitude: 0.24396

Collected Steps per Second: 21,912.98943
Overall Steps per Second: 10,618.59470

Timestep Collection Time: 2.28285
Timestep Consumption Time: 2.42813
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.71098

Cumulative Model Updates: 142,180
Cumulative Timesteps: 1,186,535,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,865.03902
Policy Entropy: 1.68301
Value Function Loss: 0.05320

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.32214
Value Function Update Magnitude: 0.26113

Collected Steps per Second: 22,204.73834
Overall Steps per Second: 10,490.75337

Timestep Collection Time: 2.25312
Timestep Consumption Time: 2.51584
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.76896

Cumulative Model Updates: 142,186
Cumulative Timesteps: 1,186,585,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1186585712...
Checkpoint 1186585712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,335.77571
Policy Entropy: 1.67831
Value Function Loss: 0.05756

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.32619
Value Function Update Magnitude: 0.32990

Collected Steps per Second: 21,888.61967
Overall Steps per Second: 10,614.14831

Timestep Collection Time: 2.28511
Timestep Consumption Time: 2.42727
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.71239

Cumulative Model Updates: 142,192
Cumulative Timesteps: 1,186,635,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,376.30562
Policy Entropy: 1.68586
Value Function Loss: 0.05540

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.32698
Value Function Update Magnitude: 0.36719

Collected Steps per Second: 21,681.59605
Overall Steps per Second: 10,415.66422

Timestep Collection Time: 2.30675
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.80181

Cumulative Model Updates: 142,198
Cumulative Timesteps: 1,186,685,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1186685744...
Checkpoint 1186685744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,241.57918
Policy Entropy: 1.67193
Value Function Loss: 0.05333

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08276
Policy Update Magnitude: 0.32765
Value Function Update Magnitude: 0.38460

Collected Steps per Second: 21,533.00605
Overall Steps per Second: 10,562.38937

Timestep Collection Time: 2.32257
Timestep Consumption Time: 2.41234
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.73491

Cumulative Model Updates: 142,204
Cumulative Timesteps: 1,186,735,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,274.44668
Policy Entropy: 1.66855
Value Function Loss: 0.05271

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.32365
Value Function Update Magnitude: 0.38370

Collected Steps per Second: 21,424.05340
Overall Steps per Second: 10,470.38476

Timestep Collection Time: 2.33383
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.77537

Cumulative Model Updates: 142,210
Cumulative Timesteps: 1,186,785,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1186785756...
Checkpoint 1186785756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,588.35688
Policy Entropy: 1.67878
Value Function Loss: 0.05160

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08552
Policy Update Magnitude: 0.32116
Value Function Update Magnitude: 0.38111

Collected Steps per Second: 20,964.36674
Overall Steps per Second: 10,206.31173

Timestep Collection Time: 2.38509
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.89913

Cumulative Model Updates: 142,216
Cumulative Timesteps: 1,186,835,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,008.31380
Policy Entropy: 1.69671
Value Function Loss: 0.05438

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.32205
Value Function Update Magnitude: 0.37282

Collected Steps per Second: 21,740.65033
Overall Steps per Second: 10,569.20994

Timestep Collection Time: 2.29993
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.73091

Cumulative Model Updates: 142,222
Cumulative Timesteps: 1,186,885,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1186885760...
Checkpoint 1186885760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,545.97426
Policy Entropy: 1.68463
Value Function Loss: 0.05360

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.31098
Value Function Update Magnitude: 0.36682

Collected Steps per Second: 21,761.69775
Overall Steps per Second: 10,510.15432

Timestep Collection Time: 2.29853
Timestep Consumption Time: 2.46067
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.75921

Cumulative Model Updates: 142,228
Cumulative Timesteps: 1,186,935,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,729.32777
Policy Entropy: 1.66817
Value Function Loss: 0.05426

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.30195
Value Function Update Magnitude: 0.36480

Collected Steps per Second: 22,141.75786
Overall Steps per Second: 10,445.38931

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.53115
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.79159

Cumulative Model Updates: 142,234
Cumulative Timesteps: 1,186,985,830

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1186985830...
Checkpoint 1186985830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,078.91470
Policy Entropy: 1.65691
Value Function Loss: 0.05486

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.30708
Value Function Update Magnitude: 0.36050

Collected Steps per Second: 21,810.27079
Overall Steps per Second: 10,450.77499

Timestep Collection Time: 2.29277
Timestep Consumption Time: 2.49214
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.78491

Cumulative Model Updates: 142,240
Cumulative Timesteps: 1,187,035,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,195.53156
Policy Entropy: 1.65494
Value Function Loss: 0.05399

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.31614
Value Function Update Magnitude: 0.35545

Collected Steps per Second: 22,229.64959
Overall Steps per Second: 10,670.80273

Timestep Collection Time: 2.25024
Timestep Consumption Time: 2.43751
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.68774

Cumulative Model Updates: 142,246
Cumulative Timesteps: 1,187,085,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1187085858...
Checkpoint 1187085858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,817.08620
Policy Entropy: 1.66229
Value Function Loss: 0.05406

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.35403

Collected Steps per Second: 21,771.06277
Overall Steps per Second: 10,613.15420

Timestep Collection Time: 2.29745
Timestep Consumption Time: 2.41538
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.71283

Cumulative Model Updates: 142,252
Cumulative Timesteps: 1,187,135,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,173.24984
Policy Entropy: 1.66310
Value Function Loss: 0.05145

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.31722
Value Function Update Magnitude: 0.33003

Collected Steps per Second: 22,067.14523
Overall Steps per Second: 10,504.31345

Timestep Collection Time: 2.26808
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.76471

Cumulative Model Updates: 142,258
Cumulative Timesteps: 1,187,185,926

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1187185926...
Checkpoint 1187185926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,281.47929
Policy Entropy: 1.65482
Value Function Loss: 0.05076

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.31861
Value Function Update Magnitude: 0.31606

Collected Steps per Second: 21,503.68355
Overall Steps per Second: 10,327.61371

Timestep Collection Time: 2.32611
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.84333

Cumulative Model Updates: 142,264
Cumulative Timesteps: 1,187,235,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,968.16532
Policy Entropy: 1.63923
Value Function Loss: 0.04976

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.31778
Value Function Update Magnitude: 0.29392

Collected Steps per Second: 20,128.14263
Overall Steps per Second: 10,294.80702

Timestep Collection Time: 2.48448
Timestep Consumption Time: 2.37311
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.85759

Cumulative Model Updates: 142,270
Cumulative Timesteps: 1,187,285,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1187285954...
Checkpoint 1187285954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,939.09724
Policy Entropy: 1.63908
Value Function Loss: 0.04814

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.31308
Value Function Update Magnitude: 0.29082

Collected Steps per Second: 20,341.41302
Overall Steps per Second: 10,269.52125

Timestep Collection Time: 2.45912
Timestep Consumption Time: 2.41180
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.87092

Cumulative Model Updates: 142,276
Cumulative Timesteps: 1,187,335,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,427.18049
Policy Entropy: 1.64964
Value Function Loss: 0.04673

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.30561
Value Function Update Magnitude: 0.30384

Collected Steps per Second: 20,387.22029
Overall Steps per Second: 10,365.79008

Timestep Collection Time: 2.45438
Timestep Consumption Time: 2.37284
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.82722

Cumulative Model Updates: 142,282
Cumulative Timesteps: 1,187,386,014

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1187386014...
Checkpoint 1187386014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,723.06969
Policy Entropy: 1.65156
Value Function Loss: 0.04753

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.30955
Value Function Update Magnitude: 0.30779

Collected Steps per Second: 20,755.41292
Overall Steps per Second: 10,350.42139

Timestep Collection Time: 2.41103
Timestep Consumption Time: 2.42375
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.83478

Cumulative Model Updates: 142,288
Cumulative Timesteps: 1,187,436,056

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,501.50239
Policy Entropy: 1.66759
Value Function Loss: 0.05388

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.32096
Value Function Update Magnitude: 0.30825

Collected Steps per Second: 21,822.48169
Overall Steps per Second: 10,390.69495

Timestep Collection Time: 2.29250
Timestep Consumption Time: 2.52219
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.81469

Cumulative Model Updates: 142,294
Cumulative Timesteps: 1,187,486,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1187486084...
Checkpoint 1187486084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,645.32031
Policy Entropy: 1.67726
Value Function Loss: 0.05313

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.31597
Value Function Update Magnitude: 0.29035

Collected Steps per Second: 21,610.21540
Overall Steps per Second: 10,577.46978

Timestep Collection Time: 2.31566
Timestep Consumption Time: 2.41534
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.73100

Cumulative Model Updates: 142,300
Cumulative Timesteps: 1,187,536,126

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,189.14948
Policy Entropy: 1.68278
Value Function Loss: 0.05444

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.31470
Value Function Update Magnitude: 0.31083

Collected Steps per Second: 22,101.62258
Overall Steps per Second: 10,525.90809

Timestep Collection Time: 2.26373
Timestep Consumption Time: 2.48950
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.75322

Cumulative Model Updates: 142,306
Cumulative Timesteps: 1,187,586,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1187586158...
Checkpoint 1187586158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,038.80927
Policy Entropy: 1.67868
Value Function Loss: 0.04981

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.31386
Value Function Update Magnitude: 0.32578

Collected Steps per Second: 21,766.07131
Overall Steps per Second: 10,608.85791

Timestep Collection Time: 2.29770
Timestep Consumption Time: 2.41647
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.71417

Cumulative Model Updates: 142,312
Cumulative Timesteps: 1,187,636,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,294.57063
Policy Entropy: 1.68590
Value Function Loss: 0.04610

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.30727
Value Function Update Magnitude: 0.31135

Collected Steps per Second: 22,184.84329
Overall Steps per Second: 10,471.44669

Timestep Collection Time: 2.25415
Timestep Consumption Time: 2.52150
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.77565

Cumulative Model Updates: 142,318
Cumulative Timesteps: 1,187,686,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1187686178...
Checkpoint 1187686178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,571.55994
Policy Entropy: 1.70093
Value Function Loss: 0.04631

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.30374
Value Function Update Magnitude: 0.29758

Collected Steps per Second: 21,983.11915
Overall Steps per Second: 10,604.37746

Timestep Collection Time: 2.27620
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.71862

Cumulative Model Updates: 142,324
Cumulative Timesteps: 1,187,736,216

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,658.41944
Policy Entropy: 1.70903
Value Function Loss: 0.05010

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.31028
Value Function Update Magnitude: 0.27257

Collected Steps per Second: 21,804.69095
Overall Steps per Second: 10,462.71878

Timestep Collection Time: 2.29327
Timestep Consumption Time: 2.48599
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.77925

Cumulative Model Updates: 142,330
Cumulative Timesteps: 1,187,786,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1187786220...
Checkpoint 1187786220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,327.96079
Policy Entropy: 1.69560
Value Function Loss: 0.05677

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.31978
Value Function Update Magnitude: 0.31988

Collected Steps per Second: 21,528.50027
Overall Steps per Second: 10,365.23459

Timestep Collection Time: 2.32250
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.82382

Cumulative Model Updates: 142,336
Cumulative Timesteps: 1,187,836,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,185.99848
Policy Entropy: 1.68885
Value Function Loss: 0.05471

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.32657
Value Function Update Magnitude: 0.36454

Collected Steps per Second: 21,629.59402
Overall Steps per Second: 10,375.05814

Timestep Collection Time: 2.31257
Timestep Consumption Time: 2.50861
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.82118

Cumulative Model Updates: 142,342
Cumulative Timesteps: 1,187,886,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1187886240...
Checkpoint 1187886240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,286.02308
Policy Entropy: 1.67863
Value Function Loss: 0.05226

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.32370
Value Function Update Magnitude: 0.37747

Collected Steps per Second: 21,498.22905
Overall Steps per Second: 10,504.71873

Timestep Collection Time: 2.32587
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.75996

Cumulative Model Updates: 142,348
Cumulative Timesteps: 1,187,936,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,437.82262
Policy Entropy: 1.68141
Value Function Loss: 0.04925

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.31801
Value Function Update Magnitude: 0.36856

Collected Steps per Second: 21,654.05526
Overall Steps per Second: 10,532.07570

Timestep Collection Time: 2.31051
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.75044

Cumulative Model Updates: 142,354
Cumulative Timesteps: 1,187,986,274

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1187986274...
Checkpoint 1187986274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,302.55798
Policy Entropy: 1.68478
Value Function Loss: 0.05203

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.32040
Value Function Update Magnitude: 0.35296

Collected Steps per Second: 21,482.14698
Overall Steps per Second: 10,351.15764

Timestep Collection Time: 2.32751
Timestep Consumption Time: 2.50286
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.83038

Cumulative Model Updates: 142,360
Cumulative Timesteps: 1,188,036,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,017.82915
Policy Entropy: 1.68538
Value Function Loss: 0.05037

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.31618
Value Function Update Magnitude: 0.35347

Collected Steps per Second: 21,943.48433
Overall Steps per Second: 10,381.83973

Timestep Collection Time: 2.28068
Timestep Consumption Time: 2.53986
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.82053

Cumulative Model Updates: 142,366
Cumulative Timesteps: 1,188,086,320

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1188086320...
Checkpoint 1188086320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,006.45007
Policy Entropy: 1.69751
Value Function Loss: 0.04948

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.31450
Value Function Update Magnitude: 0.35964

Collected Steps per Second: 21,965.69629
Overall Steps per Second: 10,542.07390

Timestep Collection Time: 2.27810
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.74669

Cumulative Model Updates: 142,372
Cumulative Timesteps: 1,188,136,360

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,892.15299
Policy Entropy: 1.67764
Value Function Loss: 0.04640

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.30945
Value Function Update Magnitude: 0.34543

Collected Steps per Second: 22,085.92837
Overall Steps per Second: 10,448.47838

Timestep Collection Time: 2.26452
Timestep Consumption Time: 2.52221
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.78673

Cumulative Model Updates: 142,378
Cumulative Timesteps: 1,188,186,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1188186374...
Checkpoint 1188186374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,763.68405
Policy Entropy: 1.66865
Value Function Loss: 0.04849

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.32066

Collected Steps per Second: 21,935.36776
Overall Steps per Second: 10,591.71611

Timestep Collection Time: 2.28034
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.72256

Cumulative Model Updates: 142,384
Cumulative Timesteps: 1,188,236,394

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,260.79651
Policy Entropy: 1.66936
Value Function Loss: 0.05160

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.32490

Collected Steps per Second: 21,952.18780
Overall Steps per Second: 10,528.09334

Timestep Collection Time: 2.27886
Timestep Consumption Time: 2.47281
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.75167

Cumulative Model Updates: 142,390
Cumulative Timesteps: 1,188,286,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1188286420...
Checkpoint 1188286420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,244.03308
Policy Entropy: 1.68460
Value Function Loss: 0.04908

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.31415
Value Function Update Magnitude: 0.33242

Collected Steps per Second: 21,682.54616
Overall Steps per Second: 10,544.12251

Timestep Collection Time: 2.30683
Timestep Consumption Time: 2.43685
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.74369

Cumulative Model Updates: 142,396
Cumulative Timesteps: 1,188,336,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,213.34861
Policy Entropy: 1.70608
Value Function Loss: 0.04851

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.33397

Collected Steps per Second: 22,034.98295
Overall Steps per Second: 10,518.44069

Timestep Collection Time: 2.27084
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.75717

Cumulative Model Updates: 142,402
Cumulative Timesteps: 1,188,386,476

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1188386476...
Checkpoint 1188386476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,748.33956
Policy Entropy: 1.70695
Value Function Loss: 0.05112

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.31153
Value Function Update Magnitude: 0.33958

Collected Steps per Second: 21,187.19327
Overall Steps per Second: 10,270.48216

Timestep Collection Time: 2.36190
Timestep Consumption Time: 2.51051
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.87241

Cumulative Model Updates: 142,408
Cumulative Timesteps: 1,188,436,518

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,392.17392
Policy Entropy: 1.70171
Value Function Loss: 0.05374

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.32229
Value Function Update Magnitude: 0.35756

Collected Steps per Second: 21,534.07144
Overall Steps per Second: 10,393.91306

Timestep Collection Time: 2.32320
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.81320

Cumulative Model Updates: 142,414
Cumulative Timesteps: 1,188,486,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1188486546...
Checkpoint 1188486546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,311.71838
Policy Entropy: 1.68752
Value Function Loss: 0.05431

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.32263
Value Function Update Magnitude: 0.36116

Collected Steps per Second: 21,345.59894
Overall Steps per Second: 10,342.52068

Timestep Collection Time: 2.34325
Timestep Consumption Time: 2.49291
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.83615

Cumulative Model Updates: 142,420
Cumulative Timesteps: 1,188,536,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,167.12183
Policy Entropy: 1.69944
Value Function Loss: 0.05323

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.31962
Value Function Update Magnitude: 0.36879

Collected Steps per Second: 21,723.77550
Overall Steps per Second: 10,407.91924

Timestep Collection Time: 2.30163
Timestep Consumption Time: 2.50241
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.80403

Cumulative Model Updates: 142,426
Cumulative Timesteps: 1,188,586,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1188586564...
Checkpoint 1188586564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,170.42681
Policy Entropy: 1.70112
Value Function Loss: 0.05423

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.31717
Value Function Update Magnitude: 0.35601

Collected Steps per Second: 21,416.19924
Overall Steps per Second: 10,495.41403

Timestep Collection Time: 2.33692
Timestep Consumption Time: 2.43164
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.76856

Cumulative Model Updates: 142,432
Cumulative Timesteps: 1,188,636,612

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,901.17046
Policy Entropy: 1.71261
Value Function Loss: 0.05112

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.30659
Value Function Update Magnitude: 0.35278

Collected Steps per Second: 21,030.16536
Overall Steps per Second: 10,493.80362

Timestep Collection Time: 2.37896
Timestep Consumption Time: 2.38861
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.76758

Cumulative Model Updates: 142,438
Cumulative Timesteps: 1,188,686,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1188686642...
Checkpoint 1188686642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,615.41288
Policy Entropy: 1.70290
Value Function Loss: 0.05315

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08270
Policy Update Magnitude: 0.30204
Value Function Update Magnitude: 0.35532

Collected Steps per Second: 21,276.98828
Overall Steps per Second: 10,584.34634

Timestep Collection Time: 2.35240
Timestep Consumption Time: 2.37647
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.72887

Cumulative Model Updates: 142,444
Cumulative Timesteps: 1,188,736,694

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,026.99389
Policy Entropy: 1.70343
Value Function Loss: 0.05347

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.31824
Value Function Update Magnitude: 0.36150

Collected Steps per Second: 21,651.62093
Overall Steps per Second: 10,553.29359

Timestep Collection Time: 2.31003
Timestep Consumption Time: 2.42934
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.73937

Cumulative Model Updates: 142,450
Cumulative Timesteps: 1,188,786,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1188786710...
Checkpoint 1188786710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,215.32904
Policy Entropy: 1.69906
Value Function Loss: 0.05231

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.32134
Value Function Update Magnitude: 0.36685

Collected Steps per Second: 21,370.69569
Overall Steps per Second: 10,644.65769

Timestep Collection Time: 2.34049
Timestep Consumption Time: 2.35839
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.69888

Cumulative Model Updates: 142,456
Cumulative Timesteps: 1,188,836,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,740.84060
Policy Entropy: 1.69581
Value Function Loss: 0.05130

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.31724
Value Function Update Magnitude: 0.35933

Collected Steps per Second: 21,264.82383
Overall Steps per Second: 10,441.45814

Timestep Collection Time: 2.35234
Timestep Consumption Time: 2.43837
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.79071

Cumulative Model Updates: 142,462
Cumulative Timesteps: 1,188,886,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1188886750...
Checkpoint 1188886750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,351.16673
Policy Entropy: 1.69623
Value Function Loss: 0.04733

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.31114
Value Function Update Magnitude: 0.32604

Collected Steps per Second: 21,330.26475
Overall Steps per Second: 10,656.07850

Timestep Collection Time: 2.34427
Timestep Consumption Time: 2.34826
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.69253

Cumulative Model Updates: 142,468
Cumulative Timesteps: 1,188,936,754

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,191.75361
Policy Entropy: 1.70456
Value Function Loss: 0.05278

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.31672
Value Function Update Magnitude: 0.29897

Collected Steps per Second: 21,552.76643
Overall Steps per Second: 10,557.79365

Timestep Collection Time: 2.31998
Timestep Consumption Time: 2.41605
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.73603

Cumulative Model Updates: 142,474
Cumulative Timesteps: 1,188,986,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1188986756...
Checkpoint 1188986756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,264.06706
Policy Entropy: 1.69668
Value Function Loss: 0.05187

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.31827
Value Function Update Magnitude: 0.26738

Collected Steps per Second: 21,135.55415
Overall Steps per Second: 10,462.78486

Timestep Collection Time: 2.36672
Timestep Consumption Time: 2.41422
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.78095

Cumulative Model Updates: 142,480
Cumulative Timesteps: 1,189,036,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,888.28732
Policy Entropy: 1.69250
Value Function Loss: 0.05120

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.31344
Value Function Update Magnitude: 0.30107

Collected Steps per Second: 21,583.48594
Overall Steps per Second: 10,448.50285

Timestep Collection Time: 2.31668
Timestep Consumption Time: 2.46889
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.78557

Cumulative Model Updates: 142,486
Cumulative Timesteps: 1,189,086,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1189086780...
Checkpoint 1189086780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,872.81585
Policy Entropy: 1.67411
Value Function Loss: 0.04980

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.31669
Value Function Update Magnitude: 0.34318

Collected Steps per Second: 21,452.08926
Overall Steps per Second: 10,581.05263

Timestep Collection Time: 2.33255
Timestep Consumption Time: 2.39647
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.72902

Cumulative Model Updates: 142,492
Cumulative Timesteps: 1,189,136,818

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,651.58701
Policy Entropy: 1.66966
Value Function Loss: 0.04787

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.31720
Value Function Update Magnitude: 0.36726

Collected Steps per Second: 21,416.42236
Overall Steps per Second: 10,165.29396

Timestep Collection Time: 2.33522
Timestep Consumption Time: 2.58466
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.91988

Cumulative Model Updates: 142,498
Cumulative Timesteps: 1,189,186,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1189186830...
Checkpoint 1189186830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,390.79466
Policy Entropy: 1.66884
Value Function Loss: 0.04961

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.35718

Collected Steps per Second: 22,130.36524
Overall Steps per Second: 10,471.28593

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.51723
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.77802

Cumulative Model Updates: 142,504
Cumulative Timesteps: 1,189,236,862

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,788.81828
Policy Entropy: 1.67919
Value Function Loss: 0.04955

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.31653
Value Function Update Magnitude: 0.35662

Collected Steps per Second: 21,801.84274
Overall Steps per Second: 10,534.66090

Timestep Collection Time: 2.29384
Timestep Consumption Time: 2.45334
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.74719

Cumulative Model Updates: 142,510
Cumulative Timesteps: 1,189,286,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1189286872...
Checkpoint 1189286872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,370.83381
Policy Entropy: 1.67326
Value Function Loss: 0.05184

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.31863
Value Function Update Magnitude: 0.36875

Collected Steps per Second: 21,924.82416
Overall Steps per Second: 10,596.76981

Timestep Collection Time: 2.28052
Timestep Consumption Time: 2.43790
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.71842

Cumulative Model Updates: 142,516
Cumulative Timesteps: 1,189,336,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,623.82310
Policy Entropy: 1.65902
Value Function Loss: 0.04997

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.31582
Value Function Update Magnitude: 0.35677

Collected Steps per Second: 22,000.94067
Overall Steps per Second: 10,486.10368

Timestep Collection Time: 2.27263
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.76822

Cumulative Model Updates: 142,522
Cumulative Timesteps: 1,189,386,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1189386872...
Checkpoint 1189386872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,075.35412
Policy Entropy: 1.66816
Value Function Loss: 0.05117

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.31658
Value Function Update Magnitude: 0.34286

Collected Steps per Second: 22,133.67200
Overall Steps per Second: 10,647.33312

Timestep Collection Time: 2.26009
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.69827

Cumulative Model Updates: 142,528
Cumulative Timesteps: 1,189,436,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,527.24523
Policy Entropy: 1.68056
Value Function Loss: 0.05112

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.31775
Value Function Update Magnitude: 0.34131

Collected Steps per Second: 21,652.91477
Overall Steps per Second: 10,475.83298

Timestep Collection Time: 2.31008
Timestep Consumption Time: 2.46472
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.77480

Cumulative Model Updates: 142,534
Cumulative Timesteps: 1,189,486,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1189486916...
Checkpoint 1189486916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,607.00634
Policy Entropy: 1.70327
Value Function Loss: 0.05218

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.31652
Value Function Update Magnitude: 0.35308

Collected Steps per Second: 21,549.43358
Overall Steps per Second: 10,391.57469

Timestep Collection Time: 2.32025
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.81159

Cumulative Model Updates: 142,540
Cumulative Timesteps: 1,189,536,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,992.54367
Policy Entropy: 1.71089
Value Function Loss: 0.05145

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.31311
Value Function Update Magnitude: 0.35215

Collected Steps per Second: 21,762.11801
Overall Steps per Second: 10,421.26329

Timestep Collection Time: 2.29812
Timestep Consumption Time: 2.50091
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.79903

Cumulative Model Updates: 142,546
Cumulative Timesteps: 1,189,586,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1189586928...
Checkpoint 1189586928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,695.46583
Policy Entropy: 1.70826
Value Function Loss: 0.04713

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.30850
Value Function Update Magnitude: 0.35079

Collected Steps per Second: 22,036.82329
Overall Steps per Second: 10,466.35808

Timestep Collection Time: 2.27056
Timestep Consumption Time: 2.51009
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.78065

Cumulative Model Updates: 142,552
Cumulative Timesteps: 1,189,636,964

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,887.52421
Policy Entropy: 1.69760
Value Function Loss: 0.04881

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.30839
Value Function Update Magnitude: 0.33873

Collected Steps per Second: 21,961.22958
Overall Steps per Second: 10,550.31061

Timestep Collection Time: 2.27719
Timestep Consumption Time: 2.46295
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.74014

Cumulative Model Updates: 142,558
Cumulative Timesteps: 1,189,686,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1189686974...
Checkpoint 1189686974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,601.36428
Policy Entropy: 1.69109
Value Function Loss: 0.04604

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.30746
Value Function Update Magnitude: 0.33252

Collected Steps per Second: 22,144.92979
Overall Steps per Second: 10,520.83121

Timestep Collection Time: 2.25867
Timestep Consumption Time: 2.49552
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.75419

Cumulative Model Updates: 142,564
Cumulative Timesteps: 1,189,736,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,042.60141
Policy Entropy: 1.69962
Value Function Loss: 0.05057

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.30765
Value Function Update Magnitude: 0.33254

Collected Steps per Second: 22,056.92736
Overall Steps per Second: 10,467.98369

Timestep Collection Time: 2.26695
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.77666

Cumulative Model Updates: 142,570
Cumulative Timesteps: 1,189,786,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1189786994...
Checkpoint 1189786994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,197.85650
Policy Entropy: 1.69345
Value Function Loss: 0.04613

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.31072
Value Function Update Magnitude: 0.31211

Collected Steps per Second: 22,085.74520
Overall Steps per Second: 10,673.74869

Timestep Collection Time: 2.26408
Timestep Consumption Time: 2.42068
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.68476

Cumulative Model Updates: 142,576
Cumulative Timesteps: 1,189,836,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,395.79440
Policy Entropy: 1.70920
Value Function Loss: 0.04694

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.30177
Value Function Update Magnitude: 0.29777

Collected Steps per Second: 22,019.91222
Overall Steps per Second: 10,444.64152

Timestep Collection Time: 2.27140
Timestep Consumption Time: 2.51728
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.78868

Cumulative Model Updates: 142,582
Cumulative Timesteps: 1,189,887,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1189887014...
Checkpoint 1189887014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,215.59506
Policy Entropy: 1.70766
Value Function Loss: 0.04860

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.30387
Value Function Update Magnitude: 0.31135

Collected Steps per Second: 21,640.60811
Overall Steps per Second: 10,556.55139

Timestep Collection Time: 2.31186
Timestep Consumption Time: 2.42738
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.73924

Cumulative Model Updates: 142,588
Cumulative Timesteps: 1,189,937,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,173.98507
Policy Entropy: 1.72012
Value Function Loss: 0.05134

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.31930

Collected Steps per Second: 21,867.66370
Overall Steps per Second: 10,505.86639

Timestep Collection Time: 2.28785
Timestep Consumption Time: 2.47425
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.76210

Cumulative Model Updates: 142,594
Cumulative Timesteps: 1,189,987,074

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1189987074...
Checkpoint 1189987074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,455.88630
Policy Entropy: 1.69089
Value Function Loss: 0.05473

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.31324
Value Function Update Magnitude: 0.33523

Collected Steps per Second: 21,451.50063
Overall Steps per Second: 10,368.24222

Timestep Collection Time: 2.33093
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.82261

Cumulative Model Updates: 142,600
Cumulative Timesteps: 1,190,037,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,457.47101
Policy Entropy: 1.65940
Value Function Loss: 0.05043

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.31370
Value Function Update Magnitude: 0.33364

Collected Steps per Second: 21,378.97053
Overall Steps per Second: 10,306.23360

Timestep Collection Time: 2.33903
Timestep Consumption Time: 2.51299
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.85202

Cumulative Model Updates: 142,606
Cumulative Timesteps: 1,190,087,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1190087082...
Checkpoint 1190087082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,527.22503
Policy Entropy: 1.65207
Value Function Loss: 0.05089

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.31533
Value Function Update Magnitude: 0.33435

Collected Steps per Second: 21,761.64531
Overall Steps per Second: 10,598.95791

Timestep Collection Time: 2.29780
Timestep Consumption Time: 2.42002
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.71782

Cumulative Model Updates: 142,612
Cumulative Timesteps: 1,190,137,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,491.50590
Policy Entropy: 1.67206
Value Function Loss: 0.04956

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.31595
Value Function Update Magnitude: 0.33905

Collected Steps per Second: 21,710.51495
Overall Steps per Second: 10,469.60965

Timestep Collection Time: 2.30386
Timestep Consumption Time: 2.47359
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.77745

Cumulative Model Updates: 142,618
Cumulative Timesteps: 1,190,187,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1190187104...
Checkpoint 1190187104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,768.39973
Policy Entropy: 1.68443
Value Function Loss: 0.04798

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.31544
Value Function Update Magnitude: 0.33414

Collected Steps per Second: 21,633.13339
Overall Steps per Second: 10,547.05863

Timestep Collection Time: 2.31303
Timestep Consumption Time: 2.43124
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.74426

Cumulative Model Updates: 142,624
Cumulative Timesteps: 1,190,237,142

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,123.13361
Policy Entropy: 1.69806
Value Function Loss: 0.05076

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.31845
Value Function Update Magnitude: 0.32929

Collected Steps per Second: 21,798.43922
Overall Steps per Second: 10,296.69361

Timestep Collection Time: 2.29466
Timestep Consumption Time: 2.56321
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.85787

Cumulative Model Updates: 142,630
Cumulative Timesteps: 1,190,287,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1190287162...
Checkpoint 1190287162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,172.60178
Policy Entropy: 1.68222
Value Function Loss: 0.05058

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.31998
Value Function Update Magnitude: 0.33460

Collected Steps per Second: 22,000.11825
Overall Steps per Second: 10,445.22713

Timestep Collection Time: 2.27317
Timestep Consumption Time: 2.51466
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.78783

Cumulative Model Updates: 142,636
Cumulative Timesteps: 1,190,337,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,417.10068
Policy Entropy: 1.69199
Value Function Loss: 0.05096

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.32020
Value Function Update Magnitude: 0.33844

Collected Steps per Second: 21,541.36212
Overall Steps per Second: 10,497.48539

Timestep Collection Time: 2.32177
Timestep Consumption Time: 2.44261
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.76438

Cumulative Model Updates: 142,642
Cumulative Timesteps: 1,190,387,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1190387186...
Checkpoint 1190387186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,248.96085
Policy Entropy: 1.69440
Value Function Loss: 0.05254

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.31115
Value Function Update Magnitude: 0.32349

Collected Steps per Second: 21,201.57135
Overall Steps per Second: 10,587.52551

Timestep Collection Time: 2.35841
Timestep Consumption Time: 2.36432
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.72273

Cumulative Model Updates: 142,648
Cumulative Timesteps: 1,190,437,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,082.19147
Policy Entropy: 1.70025
Value Function Loss: 0.05155

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.30589
Value Function Update Magnitude: 0.32043

Collected Steps per Second: 21,178.21112
Overall Steps per Second: 10,450.59229

Timestep Collection Time: 2.36101
Timestep Consumption Time: 2.42360
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.78461

Cumulative Model Updates: 142,654
Cumulative Timesteps: 1,190,487,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1190487190...
Checkpoint 1190487190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,597.51482
Policy Entropy: 1.71417
Value Function Loss: 0.05224

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.31412
Value Function Update Magnitude: 0.34357

Collected Steps per Second: 21,564.82522
Overall Steps per Second: 10,733.44338

Timestep Collection Time: 2.31933
Timestep Consumption Time: 2.34050
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.65983

Cumulative Model Updates: 142,660
Cumulative Timesteps: 1,190,537,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,634.14605
Policy Entropy: 1.69834
Value Function Loss: 0.04711

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.31181
Value Function Update Magnitude: 0.32999

Collected Steps per Second: 21,314.89275
Overall Steps per Second: 10,507.99186

Timestep Collection Time: 2.34700
Timestep Consumption Time: 2.41376
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.76076

Cumulative Model Updates: 142,666
Cumulative Timesteps: 1,190,587,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1190587232...
Checkpoint 1190587232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,705.77293
Policy Entropy: 1.69733
Value Function Loss: 0.04954

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.30936
Value Function Update Magnitude: 0.28559

Collected Steps per Second: 21,246.26495
Overall Steps per Second: 10,486.21024

Timestep Collection Time: 2.35496
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.77141

Cumulative Model Updates: 142,672
Cumulative Timesteps: 1,190,637,266

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,985.19132
Policy Entropy: 1.68540
Value Function Loss: 0.04965

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.31195
Value Function Update Magnitude: 0.28340

Collected Steps per Second: 21,777.42562
Overall Steps per Second: 10,478.87622

Timestep Collection Time: 2.29669
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.77303

Cumulative Model Updates: 142,678
Cumulative Timesteps: 1,190,687,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1190687282...
Checkpoint 1190687282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,859.20585
Policy Entropy: 1.69617
Value Function Loss: 0.05329

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.32105
Value Function Update Magnitude: 0.31650

Collected Steps per Second: 21,247.46586
Overall Steps per Second: 10,400.46573

Timestep Collection Time: 2.35548
Timestep Consumption Time: 2.45661
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.81209

Cumulative Model Updates: 142,684
Cumulative Timesteps: 1,190,737,330

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,807.70390
Policy Entropy: 1.69285
Value Function Loss: 0.05164

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.32403
Value Function Update Magnitude: 0.29876

Collected Steps per Second: 21,715.60958
Overall Steps per Second: 10,615.65627

Timestep Collection Time: 2.30295
Timestep Consumption Time: 2.40801
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.71097

Cumulative Model Updates: 142,690
Cumulative Timesteps: 1,190,787,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1190787340...
Checkpoint 1190787340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,336.57319
Policy Entropy: 1.70347
Value Function Loss: 0.05792

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08439
Policy Update Magnitude: 0.32790
Value Function Update Magnitude: 0.27289

Collected Steps per Second: 21,420.65443
Overall Steps per Second: 10,391.23950

Timestep Collection Time: 2.33485
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.81309

Cumulative Model Updates: 142,696
Cumulative Timesteps: 1,190,837,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,735.33236
Policy Entropy: 1.70360
Value Function Loss: 0.05754

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.32785
Value Function Update Magnitude: 0.29435

Collected Steps per Second: 22,380.13541
Overall Steps per Second: 10,499.19777

Timestep Collection Time: 2.23618
Timestep Consumption Time: 2.53047
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.76665

Cumulative Model Updates: 142,702
Cumulative Timesteps: 1,190,887,400

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1190887400...
Checkpoint 1190887400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,731.89357
Policy Entropy: 1.71754
Value Function Loss: 0.05884

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.32279
Value Function Update Magnitude: 0.27936

Collected Steps per Second: 21,931.93489
Overall Steps per Second: 10,481.00822

Timestep Collection Time: 2.28097
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.77301

Cumulative Model Updates: 142,708
Cumulative Timesteps: 1,190,937,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,936.79608
Policy Entropy: 1.71934
Value Function Loss: 0.05385

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.31878
Value Function Update Magnitude: 0.32809

Collected Steps per Second: 21,909.89004
Overall Steps per Second: 10,481.41889

Timestep Collection Time: 2.28335
Timestep Consumption Time: 2.48967
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.77302

Cumulative Model Updates: 142,714
Cumulative Timesteps: 1,190,987,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1190987454...
Checkpoint 1190987454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,999.82049
Policy Entropy: 1.71508
Value Function Loss: 0.05206

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.31872
Value Function Update Magnitude: 0.34495

Collected Steps per Second: 21,839.63431
Overall Steps per Second: 10,579.75276

Timestep Collection Time: 2.28951
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.72620

Cumulative Model Updates: 142,720
Cumulative Timesteps: 1,191,037,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,058.87819
Policy Entropy: 1.70417
Value Function Loss: 0.04941

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.31864
Value Function Update Magnitude: 0.35441

Collected Steps per Second: 21,254.85387
Overall Steps per Second: 10,461.03787

Timestep Collection Time: 2.35353
Timestep Consumption Time: 2.42840
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.78193

Cumulative Model Updates: 142,726
Cumulative Timesteps: 1,191,087,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1191087480...
Checkpoint 1191087480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,428.29147
Policy Entropy: 1.71630
Value Function Loss: 0.05618

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.31561
Value Function Update Magnitude: 0.35388

Collected Steps per Second: 21,075.94908
Overall Steps per Second: 10,254.60363

Timestep Collection Time: 2.37247
Timestep Consumption Time: 2.50359
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.87605

Cumulative Model Updates: 142,732
Cumulative Timesteps: 1,191,137,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,505.35433
Policy Entropy: 1.71757
Value Function Loss: 0.05421

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.30052
Value Function Update Magnitude: 0.34887

Collected Steps per Second: 21,669.65018
Overall Steps per Second: 10,429.22519

Timestep Collection Time: 2.30885
Timestep Consumption Time: 2.48844
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.79729

Cumulative Model Updates: 142,738
Cumulative Timesteps: 1,191,187,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1191187514...
Checkpoint 1191187514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,615.17466
Policy Entropy: 1.72945
Value Function Loss: 0.05548

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.30494
Value Function Update Magnitude: 0.35720

Collected Steps per Second: 21,402.07954
Overall Steps per Second: 10,345.87441

Timestep Collection Time: 2.33837
Timestep Consumption Time: 2.49892
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.83729

Cumulative Model Updates: 142,744
Cumulative Timesteps: 1,191,237,560

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,480.13070
Policy Entropy: 1.72296
Value Function Loss: 0.05021

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.31299
Value Function Update Magnitude: 0.36710

Collected Steps per Second: 21,874.84132
Overall Steps per Second: 10,390.24019

Timestep Collection Time: 2.28646
Timestep Consumption Time: 2.52729
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.81375

Cumulative Model Updates: 142,750
Cumulative Timesteps: 1,191,287,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1191287576...
Checkpoint 1191287576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,171.13645
Policy Entropy: 1.72534
Value Function Loss: 0.05175

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.31261
Value Function Update Magnitude: 0.36461

Collected Steps per Second: 21,677.46545
Overall Steps per Second: 10,555.12872

Timestep Collection Time: 2.30682
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.73760

Cumulative Model Updates: 142,756
Cumulative Timesteps: 1,191,337,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,931.81974
Policy Entropy: 1.70864
Value Function Loss: 0.05284

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.29654
Value Function Update Magnitude: 0.33939

Collected Steps per Second: 21,941.36495
Overall Steps per Second: 10,453.40866

Timestep Collection Time: 2.27880
Timestep Consumption Time: 2.50433
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.78313

Cumulative Model Updates: 142,762
Cumulative Timesteps: 1,191,387,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1191387582...
Checkpoint 1191387582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,923.80119
Policy Entropy: 1.70996
Value Function Loss: 0.05191

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.28448
Value Function Update Magnitude: 0.31017

Collected Steps per Second: 21,931.42851
Overall Steps per Second: 10,593.80147

Timestep Collection Time: 2.28056
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.72125

Cumulative Model Updates: 142,768
Cumulative Timesteps: 1,191,437,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,267.62543
Policy Entropy: 1.70574
Value Function Loss: 0.05111

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08126
Policy Update Magnitude: 0.29784
Value Function Update Magnitude: 0.34305

Collected Steps per Second: 21,994.57039
Overall Steps per Second: 10,497.79691

Timestep Collection Time: 2.27438
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.76519

Cumulative Model Updates: 142,774
Cumulative Timesteps: 1,191,487,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1191487622...
Checkpoint 1191487622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,473.94573
Policy Entropy: 1.70790
Value Function Loss: 0.05237

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.31412
Value Function Update Magnitude: 0.35738

Collected Steps per Second: 21,697.45598
Overall Steps per Second: 10,590.96048

Timestep Collection Time: 2.30571
Timestep Consumption Time: 2.41794
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.72365

Cumulative Model Updates: 142,780
Cumulative Timesteps: 1,191,537,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,993.58335
Policy Entropy: 1.69537
Value Function Loss: 0.05076

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.31407
Value Function Update Magnitude: 0.36448

Collected Steps per Second: 21,477.49386
Overall Steps per Second: 10,507.90123

Timestep Collection Time: 2.32820
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.75870

Cumulative Model Updates: 142,786
Cumulative Timesteps: 1,191,587,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1191587654...
Checkpoint 1191587654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,351.56288
Policy Entropy: 1.69690
Value Function Loss: 0.04794

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.31292
Value Function Update Magnitude: 0.36238

Collected Steps per Second: 20,858.85810
Overall Steps per Second: 10,389.23885

Timestep Collection Time: 2.39841
Timestep Consumption Time: 2.41696
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.81537

Cumulative Model Updates: 142,792
Cumulative Timesteps: 1,191,637,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,707.97845
Policy Entropy: 1.69687
Value Function Loss: 0.04871

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.31336
Value Function Update Magnitude: 0.34855

Collected Steps per Second: 21,488.86221
Overall Steps per Second: 10,668.29904

Timestep Collection Time: 2.32762
Timestep Consumption Time: 2.36085
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.68847

Cumulative Model Updates: 142,798
Cumulative Timesteps: 1,191,687,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1191687700...
Checkpoint 1191687700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,911.80157
Policy Entropy: 1.71519
Value Function Loss: 0.05288

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.31690
Value Function Update Magnitude: 0.36191

Collected Steps per Second: 20,723.49884
Overall Steps per Second: 10,319.31518

Timestep Collection Time: 2.41388
Timestep Consumption Time: 2.43373
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.84761

Cumulative Model Updates: 142,804
Cumulative Timesteps: 1,191,737,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,613.51761
Policy Entropy: 1.71770
Value Function Loss: 0.05150

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.31837
Value Function Update Magnitude: 0.38052

Collected Steps per Second: 21,182.36340
Overall Steps per Second: 10,417.26496

Timestep Collection Time: 2.36064
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.80011

Cumulative Model Updates: 142,810
Cumulative Timesteps: 1,191,787,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1191787728...
Checkpoint 1191787728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,151.73584
Policy Entropy: 1.73487
Value Function Loss: 0.05177

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.31301
Value Function Update Magnitude: 0.36121

Collected Steps per Second: 20,814.64011
Overall Steps per Second: 10,225.12171

Timestep Collection Time: 2.40350
Timestep Consumption Time: 2.48916
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.89266

Cumulative Model Updates: 142,816
Cumulative Timesteps: 1,191,837,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,693.87695
Policy Entropy: 1.72674
Value Function Loss: 0.04940

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.31075
Value Function Update Magnitude: 0.37072

Collected Steps per Second: 22,139.77093
Overall Steps per Second: 10,519.41554

Timestep Collection Time: 2.25919
Timestep Consumption Time: 2.49563
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.75483

Cumulative Model Updates: 142,822
Cumulative Timesteps: 1,191,887,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1191887774...
Checkpoint 1191887774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,229.63847
Policy Entropy: 1.72490
Value Function Loss: 0.05059

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.31129
Value Function Update Magnitude: 0.37455

Collected Steps per Second: 21,982.98707
Overall Steps per Second: 10,494.94272

Timestep Collection Time: 2.27567
Timestep Consumption Time: 2.49101
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.76668

Cumulative Model Updates: 142,828
Cumulative Timesteps: 1,191,937,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,181.74724
Policy Entropy: 1.71313
Value Function Loss: 0.05268

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.31447
Value Function Update Magnitude: 0.36973

Collected Steps per Second: 22,111.98404
Overall Steps per Second: 10,540.54884

Timestep Collection Time: 2.26203
Timestep Consumption Time: 2.48326
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.74529

Cumulative Model Updates: 142,834
Cumulative Timesteps: 1,191,987,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1191987818...
Checkpoint 1191987818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,679.62459
Policy Entropy: 1.71431
Value Function Loss: 0.05193

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.31652
Value Function Update Magnitude: 0.37275

Collected Steps per Second: 22,235.70748
Overall Steps per Second: 10,571.38885

Timestep Collection Time: 2.24953
Timestep Consumption Time: 2.48210
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.73164

Cumulative Model Updates: 142,840
Cumulative Timesteps: 1,192,037,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,735.62338
Policy Entropy: 1.71606
Value Function Loss: 0.05362

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08200
Policy Update Magnitude: 0.31481
Value Function Update Magnitude: 0.36921

Collected Steps per Second: 22,130.60436
Overall Steps per Second: 10,528.80973

Timestep Collection Time: 2.26067
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.75172

Cumulative Model Updates: 142,846
Cumulative Timesteps: 1,192,087,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1192087868...
Checkpoint 1192087868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,319.37769
Policy Entropy: 1.71084
Value Function Loss: 0.05375

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.32011
Value Function Update Magnitude: 0.37238

Collected Steps per Second: 21,810.82727
Overall Steps per Second: 10,601.90083

Timestep Collection Time: 2.29281
Timestep Consumption Time: 2.42408
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.71689

Cumulative Model Updates: 142,852
Cumulative Timesteps: 1,192,137,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,948.86613
Policy Entropy: 1.70364
Value Function Loss: 0.05752

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.32344
Value Function Update Magnitude: 0.39055

Collected Steps per Second: 22,136.39839
Overall Steps per Second: 10,514.82347

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.75576

Cumulative Model Updates: 142,858
Cumulative Timesteps: 1,192,187,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1192187882...
Checkpoint 1192187882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,611.22396
Policy Entropy: 1.70928
Value Function Loss: 0.05314

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.32271
Value Function Update Magnitude: 0.38044

Collected Steps per Second: 21,565.10512
Overall Steps per Second: 10,520.52464

Timestep Collection Time: 2.31865
Timestep Consumption Time: 2.43415
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.75280

Cumulative Model Updates: 142,864
Cumulative Timesteps: 1,192,237,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,329.10667
Policy Entropy: 1.72159
Value Function Loss: 0.05372

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.32160
Value Function Update Magnitude: 0.36892

Collected Steps per Second: 21,552.21784
Overall Steps per Second: 10,461.27619

Timestep Collection Time: 2.32236
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.78450

Cumulative Model Updates: 142,870
Cumulative Timesteps: 1,192,287,936

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1192287936...
Checkpoint 1192287936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,597.91054
Policy Entropy: 1.71855
Value Function Loss: 0.05163

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.31748
Value Function Update Magnitude: 0.37251

Collected Steps per Second: 21,354.79014
Overall Steps per Second: 10,351.10306

Timestep Collection Time: 2.34214
Timestep Consumption Time: 2.48980
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.83195

Cumulative Model Updates: 142,876
Cumulative Timesteps: 1,192,337,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,291.78678
Policy Entropy: 1.70716
Value Function Loss: 0.05211

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.29940
Value Function Update Magnitude: 0.38130

Collected Steps per Second: 21,625.03193
Overall Steps per Second: 10,358.22059

Timestep Collection Time: 2.31223
Timestep Consumption Time: 2.51505
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.82728

Cumulative Model Updates: 142,882
Cumulative Timesteps: 1,192,387,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1192387954...
Checkpoint 1192387954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,001.02000
Policy Entropy: 1.71150
Value Function Loss: 0.05413

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.31504
Value Function Update Magnitude: 0.39279

Collected Steps per Second: 21,564.17376
Overall Steps per Second: 10,562.06190

Timestep Collection Time: 2.31987
Timestep Consumption Time: 2.41652
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.73639

Cumulative Model Updates: 142,888
Cumulative Timesteps: 1,192,437,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,106.08338
Policy Entropy: 1.70995
Value Function Loss: 0.05375

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.32006
Value Function Update Magnitude: 0.38730

Collected Steps per Second: 21,994.97346
Overall Steps per Second: 10,575.97442

Timestep Collection Time: 2.27488
Timestep Consumption Time: 2.45622
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.73110

Cumulative Model Updates: 142,894
Cumulative Timesteps: 1,192,488,016

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1192488016...
Checkpoint 1192488016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,595.17683
Policy Entropy: 1.72560
Value Function Loss: 0.05280

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.32138
Value Function Update Magnitude: 0.37642

Collected Steps per Second: 22,130.15066
Overall Steps per Second: 10,543.46439

Timestep Collection Time: 2.26017
Timestep Consumption Time: 2.48381
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.74398

Cumulative Model Updates: 142,900
Cumulative Timesteps: 1,192,538,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,108.38455
Policy Entropy: 1.71475
Value Function Loss: 0.05080

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.31928
Value Function Update Magnitude: 0.36734

Collected Steps per Second: 21,994.74468
Overall Steps per Second: 10,460.75385

Timestep Collection Time: 2.27473
Timestep Consumption Time: 2.50810
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.78283

Cumulative Model Updates: 142,906
Cumulative Timesteps: 1,192,588,066

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1192588066...
Checkpoint 1192588066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,580.88161
Policy Entropy: 1.72540
Value Function Loss: 0.04896

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.31861
Value Function Update Magnitude: 0.36479

Collected Steps per Second: 21,684.43746
Overall Steps per Second: 10,559.86162

Timestep Collection Time: 2.30663
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.73662

Cumulative Model Updates: 142,912
Cumulative Timesteps: 1,192,638,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,350.86065
Policy Entropy: 1.71448
Value Function Loss: 0.04481

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.30866
Value Function Update Magnitude: 0.36562

Collected Steps per Second: 22,135.61256
Overall Steps per Second: 10,549.89108

Timestep Collection Time: 2.25926
Timestep Consumption Time: 2.48108
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.74033

Cumulative Model Updates: 142,918
Cumulative Timesteps: 1,192,688,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1192688094...
Checkpoint 1192688094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,384.36259
Policy Entropy: 1.71241
Value Function Loss: 0.04497

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08685
Policy Update Magnitude: 0.30240
Value Function Update Magnitude: 0.34732

Collected Steps per Second: 21,948.34513
Overall Steps per Second: 10,616.40249

Timestep Collection Time: 2.28054
Timestep Consumption Time: 2.43424
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.71478

Cumulative Model Updates: 142,924
Cumulative Timesteps: 1,192,738,148

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,248.96700
Policy Entropy: 1.71514
Value Function Loss: 0.04852

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.30975
Value Function Update Magnitude: 0.31775

Collected Steps per Second: 21,880.53953
Overall Steps per Second: 10,480.58929

Timestep Collection Time: 2.28669
Timestep Consumption Time: 2.48728
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.77397

Cumulative Model Updates: 142,930
Cumulative Timesteps: 1,192,788,182

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1192788182...
Checkpoint 1192788182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,073.76537
Policy Entropy: 1.71872
Value Function Loss: 0.05230

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.31413
Value Function Update Magnitude: 0.31323

Collected Steps per Second: 21,689.53577
Overall Steps per Second: 10,572.12488

Timestep Collection Time: 2.30692
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.73282

Cumulative Model Updates: 142,936
Cumulative Timesteps: 1,192,838,218

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,123.32280
Policy Entropy: 1.72428
Value Function Loss: 0.05177

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.31525
Value Function Update Magnitude: 0.35204

Collected Steps per Second: 21,576.04921
Overall Steps per Second: 10,578.00157

Timestep Collection Time: 2.31952
Timestep Consumption Time: 2.41162
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.73114

Cumulative Model Updates: 142,942
Cumulative Timesteps: 1,192,888,264

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1192888264...
Checkpoint 1192888264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,241.41925
Policy Entropy: 1.72368
Value Function Loss: 0.04832

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.31635
Value Function Update Magnitude: 0.37584

Collected Steps per Second: 21,295.34780
Overall Steps per Second: 10,267.86784

Timestep Collection Time: 2.34925
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.87229

Cumulative Model Updates: 142,948
Cumulative Timesteps: 1,192,938,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,144.18617
Policy Entropy: 1.71503
Value Function Loss: 0.04601

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.30925
Value Function Update Magnitude: 0.33919

Collected Steps per Second: 21,648.48895
Overall Steps per Second: 10,364.09074

Timestep Collection Time: 2.31102
Timestep Consumption Time: 2.51623
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.82724

Cumulative Model Updates: 142,954
Cumulative Timesteps: 1,192,988,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1192988322...
Checkpoint 1192988322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,409.87803
Policy Entropy: 1.70117
Value Function Loss: 0.04357

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07809
Policy Update Magnitude: 0.30094
Value Function Update Magnitude: 0.31381

Collected Steps per Second: 21,593.72457
Overall Steps per Second: 10,365.24568

Timestep Collection Time: 2.31771
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.82844

Cumulative Model Updates: 142,960
Cumulative Timesteps: 1,193,038,370

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,086.64448
Policy Entropy: 1.70288
Value Function Loss: 0.04576

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.30224
Value Function Update Magnitude: 0.30969

Collected Steps per Second: 22,144.19155
Overall Steps per Second: 10,457.80484

Timestep Collection Time: 2.25874
Timestep Consumption Time: 2.52410
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.78284

Cumulative Model Updates: 142,966
Cumulative Timesteps: 1,193,088,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1193088388...
Checkpoint 1193088388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,012.05903
Policy Entropy: 1.71083
Value Function Loss: 0.04833

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.30840
Value Function Update Magnitude: 0.32006

Collected Steps per Second: 22,256.03860
Overall Steps per Second: 10,504.27845

Timestep Collection Time: 2.24730
Timestep Consumption Time: 2.51419
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.76149

Cumulative Model Updates: 142,972
Cumulative Timesteps: 1,193,138,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,508.11992
Policy Entropy: 1.70085
Value Function Loss: 0.04896

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.31009
Value Function Update Magnitude: 0.33772

Collected Steps per Second: 22,149.80552
Overall Steps per Second: 10,486.62625

Timestep Collection Time: 2.25835
Timestep Consumption Time: 2.51173
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.77008

Cumulative Model Updates: 142,978
Cumulative Timesteps: 1,193,188,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1193188426...
Checkpoint 1193188426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,579.03327
Policy Entropy: 1.69382
Value Function Loss: 0.04610

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.30821
Value Function Update Magnitude: 0.33412

Collected Steps per Second: 22,055.11600
Overall Steps per Second: 10,651.76193

Timestep Collection Time: 2.26705
Timestep Consumption Time: 2.42701
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.69406

Cumulative Model Updates: 142,984
Cumulative Timesteps: 1,193,238,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,401.34254
Policy Entropy: 1.68424
Value Function Loss: 0.04642

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.30951
Value Function Update Magnitude: 0.34195

Collected Steps per Second: 22,111.70496
Overall Steps per Second: 10,484.84549

Timestep Collection Time: 2.26179
Timestep Consumption Time: 2.50814
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.76993

Cumulative Model Updates: 142,990
Cumulative Timesteps: 1,193,288,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1193288438...
Checkpoint 1193288438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,915.97037
Policy Entropy: 1.69350
Value Function Loss: 0.04691

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.30613
Value Function Update Magnitude: 0.32267

Collected Steps per Second: 21,617.17386
Overall Steps per Second: 10,518.12914

Timestep Collection Time: 2.31298
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.75370

Cumulative Model Updates: 142,996
Cumulative Timesteps: 1,193,338,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,504.12751
Policy Entropy: 1.70588
Value Function Loss: 0.04913

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.30576
Value Function Update Magnitude: 0.29999

Collected Steps per Second: 21,782.30313
Overall Steps per Second: 10,432.44794

Timestep Collection Time: 2.29553
Timestep Consumption Time: 2.49740
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.79293

Cumulative Model Updates: 143,002
Cumulative Timesteps: 1,193,388,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1193388440...
Checkpoint 1193388440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,922.21735
Policy Entropy: 1.70136
Value Function Loss: 0.04876

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.30679
Value Function Update Magnitude: 0.26485

Collected Steps per Second: 21,118.84541
Overall Steps per Second: 10,230.09409

Timestep Collection Time: 2.36878
Timestep Consumption Time: 2.52130
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.89008

Cumulative Model Updates: 143,008
Cumulative Timesteps: 1,193,438,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,820.17331
Policy Entropy: 1.70651
Value Function Loss: 0.05347

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.31194
Value Function Update Magnitude: 0.27813

Collected Steps per Second: 21,451.39327
Overall Steps per Second: 10,476.78968

Timestep Collection Time: 2.33104
Timestep Consumption Time: 2.44180
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.77284

Cumulative Model Updates: 143,014
Cumulative Timesteps: 1,193,488,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1193488470...
Checkpoint 1193488470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,809.49859
Policy Entropy: 1.71323
Value Function Loss: 0.04882

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.31629
Value Function Update Magnitude: 0.29517

Collected Steps per Second: 21,571.05226
Overall Steps per Second: 10,548.12980

Timestep Collection Time: 2.31940
Timestep Consumption Time: 2.42381
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.74321

Cumulative Model Updates: 143,020
Cumulative Timesteps: 1,193,538,502

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,488.83351
Policy Entropy: 1.72312
Value Function Loss: 0.04820

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.31085
Value Function Update Magnitude: 0.26280

Collected Steps per Second: 21,530.31518
Overall Steps per Second: 10,487.96410

Timestep Collection Time: 2.32379
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.77042

Cumulative Model Updates: 143,026
Cumulative Timesteps: 1,193,588,534

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1193588534...
Checkpoint 1193588534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,083.13296
Policy Entropy: 1.70713
Value Function Loss: 0.04707

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.31008
Value Function Update Magnitude: 0.28077

Collected Steps per Second: 21,533.28438
Overall Steps per Second: 10,376.81211

Timestep Collection Time: 2.32245
Timestep Consumption Time: 2.49695
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.81940

Cumulative Model Updates: 143,032
Cumulative Timesteps: 1,193,638,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,789.10925
Policy Entropy: 1.68031
Value Function Loss: 0.04750

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.31087
Value Function Update Magnitude: 0.33200

Collected Steps per Second: 22,388.13087
Overall Steps per Second: 10,693.08028

Timestep Collection Time: 2.23350
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.67630

Cumulative Model Updates: 143,038
Cumulative Timesteps: 1,193,688,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1193688548...
Checkpoint 1193688548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,770.06709
Policy Entropy: 1.69368
Value Function Loss: 0.04947

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.31509
Value Function Update Magnitude: 0.34292

Collected Steps per Second: 21,756.13962
Overall Steps per Second: 10,431.33702

Timestep Collection Time: 2.29940
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.79574

Cumulative Model Updates: 143,044
Cumulative Timesteps: 1,193,738,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,218.84539
Policy Entropy: 1.71161
Value Function Loss: 0.04969

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.31662
Value Function Update Magnitude: 0.34516

Collected Steps per Second: 21,657.39443
Overall Steps per Second: 10,721.68929

Timestep Collection Time: 2.30887
Timestep Consumption Time: 2.35495
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.66382

Cumulative Model Updates: 143,050
Cumulative Timesteps: 1,193,788,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1193788578...
Checkpoint 1193788578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,440.04290
Policy Entropy: 1.72090
Value Function Loss: 0.05184

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.31553
Value Function Update Magnitude: 0.31598

Collected Steps per Second: 21,230.20702
Overall Steps per Second: 10,590.76375

Timestep Collection Time: 2.35636
Timestep Consumption Time: 2.36719
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.72355

Cumulative Model Updates: 143,056
Cumulative Timesteps: 1,193,838,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,631.89083
Policy Entropy: 1.71632
Value Function Loss: 0.05066

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07701
Policy Update Magnitude: 0.31423
Value Function Update Magnitude: 0.30605

Collected Steps per Second: 21,601.94853
Overall Steps per Second: 10,526.69666

Timestep Collection Time: 2.31646
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.75363

Cumulative Model Updates: 143,062
Cumulative Timesteps: 1,193,888,644

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1193888644...
Checkpoint 1193888644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,704.47530
Policy Entropy: 1.69868
Value Function Loss: 0.04659

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.30750
Value Function Update Magnitude: 0.32480

Collected Steps per Second: 21,206.66905
Overall Steps per Second: 10,588.25045

Timestep Collection Time: 2.35992
Timestep Consumption Time: 2.36664
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72656

Cumulative Model Updates: 143,068
Cumulative Timesteps: 1,193,938,690

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,611.88184
Policy Entropy: 1.69536
Value Function Loss: 0.04612

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.30804
Value Function Update Magnitude: 0.31662

Collected Steps per Second: 21,047.14357
Overall Steps per Second: 10,435.34165

Timestep Collection Time: 2.37685
Timestep Consumption Time: 2.41705
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.79390

Cumulative Model Updates: 143,074
Cumulative Timesteps: 1,193,988,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1193988716...
Checkpoint 1193988716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,101.67165
Policy Entropy: 1.67949
Value Function Loss: 0.05035

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.30709
Value Function Update Magnitude: 0.29379

Collected Steps per Second: 21,344.02299
Overall Steps per Second: 10,355.87640

Timestep Collection Time: 2.34295
Timestep Consumption Time: 2.48600
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.82895

Cumulative Model Updates: 143,080
Cumulative Timesteps: 1,194,038,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,716.35244
Policy Entropy: 1.66730
Value Function Loss: 0.05341

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.31221
Value Function Update Magnitude: 0.27586

Collected Steps per Second: 21,398.31323
Overall Steps per Second: 10,363.52021

Timestep Collection Time: 2.33710
Timestep Consumption Time: 2.48848
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.82558

Cumulative Model Updates: 143,086
Cumulative Timesteps: 1,194,088,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1194088734...
Checkpoint 1194088734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,014.77909
Policy Entropy: 1.66235
Value Function Loss: 0.05408

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.31989
Value Function Update Magnitude: 0.29658

Collected Steps per Second: 21,412.69603
Overall Steps per Second: 10,347.73961

Timestep Collection Time: 2.33618
Timestep Consumption Time: 2.49811
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.83429

Cumulative Model Updates: 143,092
Cumulative Timesteps: 1,194,138,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,360.31575
Policy Entropy: 1.67391
Value Function Loss: 0.04969

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.31442
Value Function Update Magnitude: 0.30972

Collected Steps per Second: 21,710.80878
Overall Steps per Second: 10,389.75234

Timestep Collection Time: 2.30466
Timestep Consumption Time: 2.51124
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.81590

Cumulative Model Updates: 143,098
Cumulative Timesteps: 1,194,188,794

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1194188794...
Checkpoint 1194188794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,741.04621
Policy Entropy: 1.67965
Value Function Loss: 0.05136

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.31243
Value Function Update Magnitude: 0.31335

Collected Steps per Second: 21,541.07129
Overall Steps per Second: 10,493.09423

Timestep Collection Time: 2.32170
Timestep Consumption Time: 2.44448
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.76618

Cumulative Model Updates: 143,104
Cumulative Timesteps: 1,194,238,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,222.64273
Policy Entropy: 1.67891
Value Function Loss: 0.04728

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.31101
Value Function Update Magnitude: 0.31273

Collected Steps per Second: 21,837.19114
Overall Steps per Second: 10,557.52158

Timestep Collection Time: 2.29013
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.73691

Cumulative Model Updates: 143,110
Cumulative Timesteps: 1,194,288,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1194288816...
Checkpoint 1194288816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,352.05860
Policy Entropy: 1.66833
Value Function Loss: 0.05003

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.31230
Value Function Update Magnitude: 0.31409

Collected Steps per Second: 21,955.87068
Overall Steps per Second: 10,547.41844

Timestep Collection Time: 2.27784
Timestep Consumption Time: 2.46379
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.74163

Cumulative Model Updates: 143,116
Cumulative Timesteps: 1,194,338,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,714.63238
Policy Entropy: 1.67821
Value Function Loss: 0.04854

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.31399
Value Function Update Magnitude: 0.32735

Collected Steps per Second: 21,843.07112
Overall Steps per Second: 10,465.52641

Timestep Collection Time: 2.29052
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.78065

Cumulative Model Updates: 143,122
Cumulative Timesteps: 1,194,388,860

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1194388860...
Checkpoint 1194388860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,501.41009
Policy Entropy: 1.68525
Value Function Loss: 0.05369

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.31549
Value Function Update Magnitude: 0.34542

Collected Steps per Second: 22,009.87522
Overall Steps per Second: 10,660.25988

Timestep Collection Time: 2.27189
Timestep Consumption Time: 2.41880
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.69069

Cumulative Model Updates: 143,128
Cumulative Timesteps: 1,194,438,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,748.27815
Policy Entropy: 1.69912
Value Function Loss: 0.05586

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.32648
Value Function Update Magnitude: 0.35629

Collected Steps per Second: 22,426.15788
Overall Steps per Second: 10,565.38921

Timestep Collection Time: 2.23043
Timestep Consumption Time: 2.50390
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.73433

Cumulative Model Updates: 143,134
Cumulative Timesteps: 1,194,488,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1194488884...
Checkpoint 1194488884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,485.29819
Policy Entropy: 1.67957
Value Function Loss: 0.05381

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.32101
Value Function Update Magnitude: 0.36578

Collected Steps per Second: 22,207.32107
Overall Steps per Second: 10,562.22214

Timestep Collection Time: 2.25277
Timestep Consumption Time: 2.48373
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.73650

Cumulative Model Updates: 143,140
Cumulative Timesteps: 1,194,538,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,137.29051
Policy Entropy: 1.67968
Value Function Loss: 0.04818

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.31054
Value Function Update Magnitude: 0.35558

Collected Steps per Second: 21,826.27316
Overall Steps per Second: 10,422.11503

Timestep Collection Time: 2.29219
Timestep Consumption Time: 2.50818
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.80037

Cumulative Model Updates: 143,146
Cumulative Timesteps: 1,194,588,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1194588942...
Checkpoint 1194588942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,919.57791
Policy Entropy: 1.67629
Value Function Loss: 0.05133

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.30766
Value Function Update Magnitude: 0.35666

Collected Steps per Second: 21,540.96383
Overall Steps per Second: 10,373.87762

Timestep Collection Time: 2.32255
Timestep Consumption Time: 2.50014
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.82269

Cumulative Model Updates: 143,152
Cumulative Timesteps: 1,194,638,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,144.82054
Policy Entropy: 1.68351
Value Function Loss: 0.05518

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.29078
Value Function Update Magnitude: 0.36192

Collected Steps per Second: 21,527.51243
Overall Steps per Second: 10,356.16043

Timestep Collection Time: 2.32317
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.82920

Cumulative Model Updates: 143,158
Cumulative Timesteps: 1,194,688,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1194688984...
Checkpoint 1194688984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,063.72180
Policy Entropy: 1.69040
Value Function Loss: 0.05799

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.29391
Value Function Update Magnitude: 0.36649

Collected Steps per Second: 21,563.77978
Overall Steps per Second: 10,521.53642

Timestep Collection Time: 2.31917
Timestep Consumption Time: 2.43394
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.75311

Cumulative Model Updates: 143,164
Cumulative Timesteps: 1,194,738,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,004.14580
Policy Entropy: 1.69243
Value Function Loss: 0.05369

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.28681
Value Function Update Magnitude: 0.36384

Collected Steps per Second: 21,768.44807
Overall Steps per Second: 10,484.47891

Timestep Collection Time: 2.29718
Timestep Consumption Time: 2.47235
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.76953

Cumulative Model Updates: 143,170
Cumulative Timesteps: 1,194,789,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1194789000...
Checkpoint 1194789000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,155.49404
Policy Entropy: 1.68310
Value Function Loss: 0.05300

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.28331
Value Function Update Magnitude: 0.34064

Collected Steps per Second: 20,729.61977
Overall Steps per Second: 10,285.37409

Timestep Collection Time: 2.41239
Timestep Consumption Time: 2.44966
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.86205

Cumulative Model Updates: 143,176
Cumulative Timesteps: 1,194,839,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,451.07494
Policy Entropy: 1.68611
Value Function Loss: 0.05005

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.29757
Value Function Update Magnitude: 0.35188

Collected Steps per Second: 21,558.08511
Overall Steps per Second: 10,425.27738

Timestep Collection Time: 2.32052
Timestep Consumption Time: 2.47801
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.79853

Cumulative Model Updates: 143,182
Cumulative Timesteps: 1,194,889,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1194889034...
Checkpoint 1194889034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,344.17907
Policy Entropy: 1.67960
Value Function Loss: 0.05186

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.31460
Value Function Update Magnitude: 0.34562

Collected Steps per Second: 21,733.20791
Overall Steps per Second: 10,579.13209

Timestep Collection Time: 2.30182
Timestep Consumption Time: 2.42692
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.72874

Cumulative Model Updates: 143,188
Cumulative Timesteps: 1,194,939,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,699.80221
Policy Entropy: 1.68403
Value Function Loss: 0.04942

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.31427
Value Function Update Magnitude: 0.34563

Collected Steps per Second: 21,445.85821
Overall Steps per Second: 10,473.51513

Timestep Collection Time: 2.33304
Timestep Consumption Time: 2.44415
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.77719

Cumulative Model Updates: 143,194
Cumulative Timesteps: 1,194,989,094

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1194989094...
Checkpoint 1194989094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,363.28672
Policy Entropy: 1.67624
Value Function Loss: 0.05055

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.31652
Value Function Update Magnitude: 0.33770

Collected Steps per Second: 21,647.02129
Overall Steps per Second: 10,381.58151

Timestep Collection Time: 2.31210
Timestep Consumption Time: 2.50894
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.82104

Cumulative Model Updates: 143,200
Cumulative Timesteps: 1,195,039,144

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,541.43627
Policy Entropy: 1.68301
Value Function Loss: 0.05389

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.32677
Value Function Update Magnitude: 0.36154

Collected Steps per Second: 22,391.85796
Overall Steps per Second: 10,681.48471

Timestep Collection Time: 2.23295
Timestep Consumption Time: 2.44804
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.68100

Cumulative Model Updates: 143,206
Cumulative Timesteps: 1,195,089,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1195089144...
Checkpoint 1195089144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,214.18019
Policy Entropy: 1.68846
Value Function Loss: 0.05267

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.30481
Value Function Update Magnitude: 0.39762

Collected Steps per Second: 21,811.85038
Overall Steps per Second: 10,624.01024

Timestep Collection Time: 2.29343
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.70858

Cumulative Model Updates: 143,212
Cumulative Timesteps: 1,195,139,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,119.12238
Policy Entropy: 1.69717
Value Function Loss: 0.05361

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.30005
Value Function Update Magnitude: 0.41293

Collected Steps per Second: 22,157.09758
Overall Steps per Second: 10,515.92187

Timestep Collection Time: 2.25878
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.75926

Cumulative Model Updates: 143,218
Cumulative Timesteps: 1,195,189,216

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1195189216...
Checkpoint 1195189216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,629.63058
Policy Entropy: 1.68498
Value Function Loss: 0.05624

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.29528
Value Function Update Magnitude: 0.39935

Collected Steps per Second: 21,338.44159
Overall Steps per Second: 10,604.62159

Timestep Collection Time: 2.34413
Timestep Consumption Time: 2.37269
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.71681

Cumulative Model Updates: 143,224
Cumulative Timesteps: 1,195,239,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,790.03492
Policy Entropy: 1.67843
Value Function Loss: 0.05589

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.31552
Value Function Update Magnitude: 0.34888

Collected Steps per Second: 21,575.97431
Overall Steps per Second: 10,528.82444

Timestep Collection Time: 2.31850
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.75115

Cumulative Model Updates: 143,230
Cumulative Timesteps: 1,195,289,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1195289260...
Checkpoint 1195289260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,589.07761
Policy Entropy: 1.67910
Value Function Loss: 0.05339

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.31946
Value Function Update Magnitude: 0.28651

Collected Steps per Second: 21,270.65663
Overall Steps per Second: 10,631.75257

Timestep Collection Time: 2.35188
Timestep Consumption Time: 2.35346
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.70534

Cumulative Model Updates: 143,236
Cumulative Timesteps: 1,195,339,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,392.95133
Policy Entropy: 1.67446
Value Function Loss: 0.04812

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.31455
Value Function Update Magnitude: 0.27371

Collected Steps per Second: 21,041.33570
Overall Steps per Second: 10,459.46068

Timestep Collection Time: 2.37627
Timestep Consumption Time: 2.40409
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.78036

Cumulative Model Updates: 143,242
Cumulative Timesteps: 1,195,389,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1195389286...
Checkpoint 1195389286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,915.04137
Policy Entropy: 1.66716
Value Function Loss: 0.04620

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.31066
Value Function Update Magnitude: 0.29404

Collected Steps per Second: 20,956.43068
Overall Steps per Second: 10,263.76177

Timestep Collection Time: 2.38648
Timestep Consumption Time: 2.48620
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.87268

Cumulative Model Updates: 143,248
Cumulative Timesteps: 1,195,439,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,838.79698
Policy Entropy: 1.65336
Value Function Loss: 0.04490

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.30852
Value Function Update Magnitude: 0.32074

Collected Steps per Second: 21,816.33292
Overall Steps per Second: 10,481.62086

Timestep Collection Time: 2.29287
Timestep Consumption Time: 2.47948
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.77235

Cumulative Model Updates: 143,254
Cumulative Timesteps: 1,195,489,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1195489320...
Checkpoint 1195489320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,674.18494
Policy Entropy: 1.66409
Value Function Loss: 0.04833

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 0.31016
Value Function Update Magnitude: 0.33012

Collected Steps per Second: 21,189.27664
Overall Steps per Second: 10,486.59943

Timestep Collection Time: 2.36072
Timestep Consumption Time: 2.40937
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.77009

Cumulative Model Updates: 143,260
Cumulative Timesteps: 1,195,539,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,608.91621
Policy Entropy: 1.65744
Value Function Loss: 0.05147

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.31558
Value Function Update Magnitude: 0.30126

Collected Steps per Second: 21,755.95996
Overall Steps per Second: 10,499.37938

Timestep Collection Time: 2.29850
Timestep Consumption Time: 2.46426
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.76276

Cumulative Model Updates: 143,266
Cumulative Timesteps: 1,195,589,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1195589348...
Checkpoint 1195589348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,984.17199
Policy Entropy: 1.66310
Value Function Loss: 0.05412

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.32484
Value Function Update Magnitude: 0.31046

Collected Steps per Second: 21,920.35683
Overall Steps per Second: 10,544.09975

Timestep Collection Time: 2.28199
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.74407

Cumulative Model Updates: 143,272
Cumulative Timesteps: 1,195,639,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,185.00746
Policy Entropy: 1.65242
Value Function Loss: 0.05161

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08333
Policy Update Magnitude: 0.31920
Value Function Update Magnitude: 0.33594

Collected Steps per Second: 22,174.69994
Overall Steps per Second: 10,534.40484

Timestep Collection Time: 2.25663
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.75015

Cumulative Model Updates: 143,278
Cumulative Timesteps: 1,195,689,410

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1195689410...
Checkpoint 1195689410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,966.81953
Policy Entropy: 1.65493
Value Function Loss: 0.05360

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.32346
Value Function Update Magnitude: 0.36622

Collected Steps per Second: 21,917.22623
Overall Steps per Second: 10,600.35229

Timestep Collection Time: 2.28222
Timestep Consumption Time: 2.43649
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.71871

Cumulative Model Updates: 143,284
Cumulative Timesteps: 1,195,739,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,883.54960
Policy Entropy: 1.65594
Value Function Loss: 0.05106

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.32574
Value Function Update Magnitude: 0.39675

Collected Steps per Second: 22,276.95390
Overall Steps per Second: 10,497.85614

Timestep Collection Time: 2.24546
Timestep Consumption Time: 2.51951
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.76497

Cumulative Model Updates: 143,290
Cumulative Timesteps: 1,195,789,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1195789452...
Checkpoint 1195789452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,699.95873
Policy Entropy: 1.67736
Value Function Loss: 0.05311

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.32171
Value Function Update Magnitude: 0.39485

Collected Steps per Second: 21,673.80033
Overall Steps per Second: 10,571.51427

Timestep Collection Time: 2.30758
Timestep Consumption Time: 2.42344
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.73102

Cumulative Model Updates: 143,296
Cumulative Timesteps: 1,195,839,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,938.35417
Policy Entropy: 1.69027
Value Function Loss: 0.05172

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.32300
Value Function Update Magnitude: 0.36677

Collected Steps per Second: 22,164.17179
Overall Steps per Second: 10,548.36053

Timestep Collection Time: 2.25589
Timestep Consumption Time: 2.48418
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.74007

Cumulative Model Updates: 143,302
Cumulative Timesteps: 1,195,889,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1195889466...
Checkpoint 1195889466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,092.24755
Policy Entropy: 1.68251
Value Function Loss: 0.05278

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.32319
Value Function Update Magnitude: 0.35152

Collected Steps per Second: 21,636.89295
Overall Steps per Second: 10,554.45654

Timestep Collection Time: 2.31290
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74150

Cumulative Model Updates: 143,308
Cumulative Timesteps: 1,195,939,510

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,590.96869
Policy Entropy: 1.67630
Value Function Loss: 0.05354

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.32159
Value Function Update Magnitude: 0.33231

Collected Steps per Second: 21,214.24745
Overall Steps per Second: 10,243.69389

Timestep Collection Time: 2.35813
Timestep Consumption Time: 2.52546
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.88359

Cumulative Model Updates: 143,314
Cumulative Timesteps: 1,195,989,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1195989536...
Checkpoint 1195989536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,008.46710
Policy Entropy: 1.67680
Value Function Loss: 0.05427

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.29749
Value Function Update Magnitude: 0.33470

Collected Steps per Second: 21,428.47746
Overall Steps per Second: 10,465.79177

Timestep Collection Time: 2.33372
Timestep Consumption Time: 2.44452
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.77823

Cumulative Model Updates: 143,320
Cumulative Timesteps: 1,196,039,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,899.80386
Policy Entropy: 1.68911
Value Function Loss: 0.05403

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.27399
Value Function Update Magnitude: 0.35341

Collected Steps per Second: 21,821.11035
Overall Steps per Second: 10,575.76295

Timestep Collection Time: 2.29218
Timestep Consumption Time: 2.43731
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.72949

Cumulative Model Updates: 143,326
Cumulative Timesteps: 1,196,089,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1196089562...
Checkpoint 1196089562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,486.13483
Policy Entropy: 1.67844
Value Function Loss: 0.05469

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08663
Policy Update Magnitude: 0.30465
Value Function Update Magnitude: 0.37735

Collected Steps per Second: 21,621.63845
Overall Steps per Second: 10,513.41682

Timestep Collection Time: 2.31250
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.75583

Cumulative Model Updates: 143,332
Cumulative Timesteps: 1,196,139,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,898.03402
Policy Entropy: 1.67459
Value Function Loss: 0.05367

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.32209
Value Function Update Magnitude: 0.37088

Collected Steps per Second: 22,287.43413
Overall Steps per Second: 10,477.82435

Timestep Collection Time: 2.24485
Timestep Consumption Time: 2.53018
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.77504

Cumulative Model Updates: 143,338
Cumulative Timesteps: 1,196,189,594

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1196189594...
Checkpoint 1196189594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,496.14190
Policy Entropy: 1.68153
Value Function Loss: 0.05660

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.32150
Value Function Update Magnitude: 0.36364

Collected Steps per Second: 21,496.42369
Overall Steps per Second: 10,365.92206

Timestep Collection Time: 2.32718
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.82601

Cumulative Model Updates: 143,344
Cumulative Timesteps: 1,196,239,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,793.52608
Policy Entropy: 1.67829
Value Function Loss: 0.05572

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.31871
Value Function Update Magnitude: 0.36473

Collected Steps per Second: 22,309.25447
Overall Steps per Second: 10,705.46195

Timestep Collection Time: 2.24221
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.67257

Cumulative Model Updates: 143,350
Cumulative Timesteps: 1,196,289,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1196289642...
Checkpoint 1196289642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,333.98474
Policy Entropy: 1.66993
Value Function Loss: 0.05127

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.29935
Value Function Update Magnitude: 0.37146

Collected Steps per Second: 21,970.83666
Overall Steps per Second: 10,591.45616

Timestep Collection Time: 2.27693
Timestep Consumption Time: 2.44631
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.72324

Cumulative Model Updates: 143,356
Cumulative Timesteps: 1,196,339,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,340.43811
Policy Entropy: 1.64044
Value Function Loss: 0.05102

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.27416
Value Function Update Magnitude: 0.34751

Collected Steps per Second: 22,178.41192
Overall Steps per Second: 10,506.74488

Timestep Collection Time: 2.25508
Timestep Consumption Time: 2.50510
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.76018

Cumulative Model Updates: 143,362
Cumulative Timesteps: 1,196,389,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1196389682...
Checkpoint 1196389682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,515.86421
Policy Entropy: 1.64166
Value Function Loss: 0.05041

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.29508
Value Function Update Magnitude: 0.32755

Collected Steps per Second: 21,337.29957
Overall Steps per Second: 10,297.14713

Timestep Collection Time: 2.34378
Timestep Consumption Time: 2.51290
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.85668

Cumulative Model Updates: 143,368
Cumulative Timesteps: 1,196,439,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,155.15966
Policy Entropy: 1.64282
Value Function Loss: 0.05178

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.31280
Value Function Update Magnitude: 0.30303

Collected Steps per Second: 21,539.54789
Overall Steps per Second: 10,355.84165

Timestep Collection Time: 2.32168
Timestep Consumption Time: 2.50728
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.82897

Cumulative Model Updates: 143,374
Cumulative Timesteps: 1,196,489,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1196489700...
Checkpoint 1196489700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,943.26725
Policy Entropy: 1.65599
Value Function Loss: 0.05267

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.29043
Value Function Update Magnitude: 0.31137

Collected Steps per Second: 21,443.76930
Overall Steps per Second: 10,377.88866

Timestep Collection Time: 2.33289
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.82044

Cumulative Model Updates: 143,380
Cumulative Timesteps: 1,196,539,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,687.80390
Policy Entropy: 1.66154
Value Function Loss: 0.04593

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.28442
Value Function Update Magnitude: 0.32830

Collected Steps per Second: 21,643.85517
Overall Steps per Second: 10,358.08326

Timestep Collection Time: 2.31022
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.82734

Cumulative Model Updates: 143,386
Cumulative Timesteps: 1,196,589,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1196589728...
Checkpoint 1196589728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,129.48655
Policy Entropy: 1.65257
Value Function Loss: 0.04509

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.29127
Value Function Update Magnitude: 0.32063

Collected Steps per Second: 21,259.08710
Overall Steps per Second: 10,277.75234

Timestep Collection Time: 2.35203
Timestep Consumption Time: 2.51304
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.86507

Cumulative Model Updates: 143,392
Cumulative Timesteps: 1,196,639,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,115.85069
Policy Entropy: 1.66713
Value Function Loss: 0.04198

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.28133
Value Function Update Magnitude: 0.31895

Collected Steps per Second: 22,300.10608
Overall Steps per Second: 10,479.71111

Timestep Collection Time: 2.24277
Timestep Consumption Time: 2.52969
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.77246

Cumulative Model Updates: 143,398
Cumulative Timesteps: 1,196,689,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1196689744...
Checkpoint 1196689744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,214.62059
Policy Entropy: 1.68287
Value Function Loss: 0.05367

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.30455
Value Function Update Magnitude: 0.33240

Collected Steps per Second: 21,602.85066
Overall Steps per Second: 10,435.13159

Timestep Collection Time: 2.31525
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.79304

Cumulative Model Updates: 143,404
Cumulative Timesteps: 1,196,739,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,830.57621
Policy Entropy: 1.68922
Value Function Loss: 0.05733

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.32037
Value Function Update Magnitude: 0.35277

Collected Steps per Second: 22,199.88895
Overall Steps per Second: 10,482.10778

Timestep Collection Time: 2.25244
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.77041

Cumulative Model Updates: 143,410
Cumulative Timesteps: 1,196,789,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1196789764...
Checkpoint 1196789764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,373.04401
Policy Entropy: 1.67990
Value Function Loss: 0.05882

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.32367
Value Function Update Magnitude: 0.34516

Collected Steps per Second: 21,780.69912
Overall Steps per Second: 10,576.84657

Timestep Collection Time: 2.29589
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.72787

Cumulative Model Updates: 143,416
Cumulative Timesteps: 1,196,839,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,553.21670
Policy Entropy: 1.67342
Value Function Loss: 0.05188

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.31584
Value Function Update Magnitude: 0.33926

Collected Steps per Second: 21,517.11489
Overall Steps per Second: 10,507.77084

Timestep Collection Time: 2.32485
Timestep Consumption Time: 2.43582
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.76067

Cumulative Model Updates: 143,422
Cumulative Timesteps: 1,196,889,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1196889794...
Checkpoint 1196889794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,445.32600
Policy Entropy: 1.69762
Value Function Loss: 0.05480

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.31759
Value Function Update Magnitude: 0.34689

Collected Steps per Second: 21,514.70473
Overall Steps per Second: 10,707.51759

Timestep Collection Time: 2.32474
Timestep Consumption Time: 2.34638
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.67111

Cumulative Model Updates: 143,428
Cumulative Timesteps: 1,196,939,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,398.80249
Policy Entropy: 1.71524
Value Function Loss: 0.05744

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.31501
Value Function Update Magnitude: 0.34336

Collected Steps per Second: 21,753.07825
Overall Steps per Second: 10,754.63317

Timestep Collection Time: 2.29972
Timestep Consumption Time: 2.35186
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.65158

Cumulative Model Updates: 143,434
Cumulative Timesteps: 1,196,989,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1196989836...
Checkpoint 1196989836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,367.96326
Policy Entropy: 1.71235
Value Function Loss: 0.05852

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.31785
Value Function Update Magnitude: 0.35763

Collected Steps per Second: 20,874.80510
Overall Steps per Second: 10,348.72312

Timestep Collection Time: 2.39581
Timestep Consumption Time: 2.43687
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.83267

Cumulative Model Updates: 143,440
Cumulative Timesteps: 1,197,039,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,449.37300
Policy Entropy: 1.67932
Value Function Loss: 0.05702

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.29180
Value Function Update Magnitude: 0.36235

Collected Steps per Second: 21,166.70205
Overall Steps per Second: 10,435.10223

Timestep Collection Time: 2.36437
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.79593

Cumulative Model Updates: 143,446
Cumulative Timesteps: 1,197,089,894

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1197089894...
Checkpoint 1197089894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,575.93977
Policy Entropy: 1.66383
Value Function Loss: 0.05419

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.27733
Value Function Update Magnitude: 0.37210

Collected Steps per Second: 20,874.11863
Overall Steps per Second: 10,526.81812

Timestep Collection Time: 2.39675
Timestep Consumption Time: 2.35588
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.75262

Cumulative Model Updates: 143,452
Cumulative Timesteps: 1,197,139,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,195.52605
Policy Entropy: 1.67334
Value Function Loss: 0.05316

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.27779
Value Function Update Magnitude: 0.36319

Collected Steps per Second: 20,834.40865
Overall Steps per Second: 10,235.26455

Timestep Collection Time: 2.40045
Timestep Consumption Time: 2.48579
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.88624

Cumulative Model Updates: 143,458
Cumulative Timesteps: 1,197,189,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1197189936...
Checkpoint 1197189936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,837.60087
Policy Entropy: 1.69761
Value Function Loss: 0.05714

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.29911
Value Function Update Magnitude: 0.33101

Collected Steps per Second: 21,354.15048
Overall Steps per Second: 10,523.45089

Timestep Collection Time: 2.34212
Timestep Consumption Time: 2.41050
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.75262

Cumulative Model Updates: 143,464
Cumulative Timesteps: 1,197,239,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,573.66760
Policy Entropy: 1.70586
Value Function Loss: 0.05773

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.32047
Value Function Update Magnitude: 0.35022

Collected Steps per Second: 21,928.81825
Overall Steps per Second: 10,427.05820

Timestep Collection Time: 2.28166
Timestep Consumption Time: 2.51682
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.79848

Cumulative Model Updates: 143,470
Cumulative Timesteps: 1,197,289,984

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1197289984...
Checkpoint 1197289984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,888.78670
Policy Entropy: 1.68274
Value Function Loss: 0.05761

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.32762
Value Function Update Magnitude: 0.35053

Collected Steps per Second: 21,782.30391
Overall Steps per Second: 10,626.25702

Timestep Collection Time: 2.29700
Timestep Consumption Time: 2.41152
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.70853

Cumulative Model Updates: 143,476
Cumulative Timesteps: 1,197,340,018

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,723.41557
Policy Entropy: 1.67942
Value Function Loss: 0.05583

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.32598
Value Function Update Magnitude: 0.36555

Collected Steps per Second: 22,107.87780
Overall Steps per Second: 10,459.03350

Timestep Collection Time: 2.26308
Timestep Consumption Time: 2.52053
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.78362

Cumulative Model Updates: 143,482
Cumulative Timesteps: 1,197,390,050

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1197390050...
Checkpoint 1197390050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,119.00917
Policy Entropy: 1.68060
Value Function Loss: 0.05500

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.32164
Value Function Update Magnitude: 0.39124

Collected Steps per Second: 21,557.32677
Overall Steps per Second: 10,574.60409

Timestep Collection Time: 2.31995
Timestep Consumption Time: 2.40949
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.72944

Cumulative Model Updates: 143,488
Cumulative Timesteps: 1,197,440,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,521.24270
Policy Entropy: 1.69945
Value Function Loss: 0.05700

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.32669
Value Function Update Magnitude: 0.37988

Collected Steps per Second: 22,058.62482
Overall Steps per Second: 10,530.62714

Timestep Collection Time: 2.26832
Timestep Consumption Time: 2.48315
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.75147

Cumulative Model Updates: 143,494
Cumulative Timesteps: 1,197,490,098

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1197490098...
Checkpoint 1197490098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,972.34812
Policy Entropy: 1.70082
Value Function Loss: 0.05485

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.32707
Value Function Update Magnitude: 0.36884

Collected Steps per Second: 21,936.67263
Overall Steps per Second: 10,637.58145

Timestep Collection Time: 2.27974
Timestep Consumption Time: 2.42151
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.70126

Cumulative Model Updates: 143,500
Cumulative Timesteps: 1,197,540,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,865.37708
Policy Entropy: 1.68772
Value Function Loss: 0.05087

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.31549
Value Function Update Magnitude: 0.35879

Collected Steps per Second: 22,117.82338
Overall Steps per Second: 10,489.72534

Timestep Collection Time: 2.26143
Timestep Consumption Time: 2.50685
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.76829

Cumulative Model Updates: 143,506
Cumulative Timesteps: 1,197,590,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1197590126...
Checkpoint 1197590126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,817.90597
Policy Entropy: 1.68708
Value Function Loss: 0.05089

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.31190
Value Function Update Magnitude: 0.33354

Collected Steps per Second: 21,617.23928
Overall Steps per Second: 10,522.22161

Timestep Collection Time: 2.31445
Timestep Consumption Time: 2.44044
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.75489

Cumulative Model Updates: 143,512
Cumulative Timesteps: 1,197,640,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,071.45083
Policy Entropy: 1.67337
Value Function Loss: 0.05277

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.31947
Value Function Update Magnitude: 0.33306

Collected Steps per Second: 21,527.44015
Overall Steps per Second: 10,482.66585

Timestep Collection Time: 2.32317
Timestep Consumption Time: 2.44775
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.77092

Cumulative Model Updates: 143,518
Cumulative Timesteps: 1,197,690,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1197690170...
Checkpoint 1197690170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,875.95300
Policy Entropy: 1.69072
Value Function Loss: 0.05894

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.32570
Value Function Update Magnitude: 0.34584

Collected Steps per Second: 21,412.28497
Overall Steps per Second: 10,322.43481

Timestep Collection Time: 2.33735
Timestep Consumption Time: 2.51112
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.84847

Cumulative Model Updates: 143,524
Cumulative Timesteps: 1,197,740,218

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,462.49016
Policy Entropy: 1.68030
Value Function Loss: 0.05558

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.33056
Value Function Update Magnitude: 0.36978

Collected Steps per Second: 21,686.83043
Overall Steps per Second: 10,373.08378

Timestep Collection Time: 2.30730
Timestep Consumption Time: 2.51653
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.82383

Cumulative Model Updates: 143,530
Cumulative Timesteps: 1,197,790,256

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1197790256...
Checkpoint 1197790256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,412.36984
Policy Entropy: 1.67440
Value Function Loss: 0.05626

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.33069
Value Function Update Magnitude: 0.37407

Collected Steps per Second: 21,488.66417
Overall Steps per Second: 10,355.07232

Timestep Collection Time: 2.32681
Timestep Consumption Time: 2.50174
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.82855

Cumulative Model Updates: 143,536
Cumulative Timesteps: 1,197,840,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,673.63705
Policy Entropy: 1.67445
Value Function Loss: 0.05492

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.32049
Value Function Update Magnitude: 0.36028

Collected Steps per Second: 22,186.48211
Overall Steps per Second: 10,448.50390

Timestep Collection Time: 2.25480
Timestep Consumption Time: 2.53307
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.78786

Cumulative Model Updates: 143,542
Cumulative Timesteps: 1,197,890,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1197890282...
Checkpoint 1197890282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,027.67287
Policy Entropy: 1.67844
Value Function Loss: 0.05509

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.31236
Value Function Update Magnitude: 0.35240

Collected Steps per Second: 22,191.08006
Overall Steps per Second: 10,550.15393

Timestep Collection Time: 2.25361
Timestep Consumption Time: 2.48661
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.74022

Cumulative Model Updates: 143,548
Cumulative Timesteps: 1,197,940,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,941.33297
Policy Entropy: 1.69235
Value Function Loss: 0.05660

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.32522
Value Function Update Magnitude: 0.35484

Collected Steps per Second: 22,256.90574
Overall Steps per Second: 10,522.46649

Timestep Collection Time: 2.24865
Timestep Consumption Time: 2.50765
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.75630

Cumulative Model Updates: 143,554
Cumulative Timesteps: 1,197,990,340

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1197990340...
Checkpoint 1197990340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,606.07419
Policy Entropy: 1.69626
Value Function Loss: 0.05232

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.33023
Value Function Update Magnitude: 0.36123

Collected Steps per Second: 21,935.10816
Overall Steps per Second: 10,496.44615

Timestep Collection Time: 2.28073
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.76618

Cumulative Model Updates: 143,560
Cumulative Timesteps: 1,198,040,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,654.17713
Policy Entropy: 1.70637
Value Function Loss: 0.05160

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.32255
Value Function Update Magnitude: 0.35701

Collected Steps per Second: 21,969.27711
Overall Steps per Second: 10,462.68976

Timestep Collection Time: 2.27600
Timestep Consumption Time: 2.50308
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.77908

Cumulative Model Updates: 143,566
Cumulative Timesteps: 1,198,090,370

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1198090370...
Checkpoint 1198090370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,677.72927
Policy Entropy: 1.71631
Value Function Loss: 0.05229

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.31063
Value Function Update Magnitude: 0.35307

Collected Steps per Second: 21,924.86573
Overall Steps per Second: 10,598.90511

Timestep Collection Time: 2.28106
Timestep Consumption Time: 2.43754
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.71860

Cumulative Model Updates: 143,572
Cumulative Timesteps: 1,198,140,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,638.17351
Policy Entropy: 1.70550
Value Function Loss: 0.05165

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.30342
Value Function Update Magnitude: 0.35687

Collected Steps per Second: 22,059.63976
Overall Steps per Second: 10,514.77977

Timestep Collection Time: 2.26831
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.75883

Cumulative Model Updates: 143,578
Cumulative Timesteps: 1,198,190,420

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1198190420...
Checkpoint 1198190420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,946.31439
Policy Entropy: 1.70491
Value Function Loss: 0.05458

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.31820
Value Function Update Magnitude: 0.35954

Collected Steps per Second: 21,485.31392
Overall Steps per Second: 10,367.10694

Timestep Collection Time: 2.32875
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.82623

Cumulative Model Updates: 143,584
Cumulative Timesteps: 1,198,240,454

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,229.40988
Policy Entropy: 1.70819
Value Function Loss: 0.05249

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.32110
Value Function Update Magnitude: 0.35761

Collected Steps per Second: 21,530.26044
Overall Steps per Second: 10,370.28707

Timestep Collection Time: 2.32389
Timestep Consumption Time: 2.50085
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.82475

Cumulative Model Updates: 143,590
Cumulative Timesteps: 1,198,290,488

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1198290488...
Checkpoint 1198290488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,943.54899
Policy Entropy: 1.70815
Value Function Loss: 0.05555

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.32594
Value Function Update Magnitude: 0.36139

Collected Steps per Second: 21,372.61791
Overall Steps per Second: 10,487.88743

Timestep Collection Time: 2.34028
Timestep Consumption Time: 2.42884
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.76912

Cumulative Model Updates: 143,596
Cumulative Timesteps: 1,198,340,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,435.26720
Policy Entropy: 1.69141
Value Function Loss: 0.05346

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.32974
Value Function Update Magnitude: 0.34351

Collected Steps per Second: 21,569.78430
Overall Steps per Second: 10,499.17596

Timestep Collection Time: 2.32019
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.76666

Cumulative Model Updates: 143,602
Cumulative Timesteps: 1,198,390,552

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1198390552...
Checkpoint 1198390552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,654.72821
Policy Entropy: 1.68123
Value Function Loss: 0.05557

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.32656
Value Function Update Magnitude: 0.35436

Collected Steps per Second: 21,291.97871
Overall Steps per Second: 10,302.01780

Timestep Collection Time: 2.34924
Timestep Consumption Time: 2.50612
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.85536

Cumulative Model Updates: 143,608
Cumulative Timesteps: 1,198,440,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,260.79877
Policy Entropy: 1.67812
Value Function Loss: 0.05095

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08345
Policy Update Magnitude: 0.32301
Value Function Update Magnitude: 0.36869

Collected Steps per Second: 21,906.84956
Overall Steps per Second: 10,386.57330

Timestep Collection Time: 2.28385
Timestep Consumption Time: 2.53314
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.81699

Cumulative Model Updates: 143,614
Cumulative Timesteps: 1,198,490,604

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1198490604...
Checkpoint 1198490604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,469.48831
Policy Entropy: 1.69205
Value Function Loss: 0.05027

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.31825
Value Function Update Magnitude: 0.35913

Collected Steps per Second: 21,874.59269
Overall Steps per Second: 10,579.73837

Timestep Collection Time: 2.28713
Timestep Consumption Time: 2.44172
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.72885

Cumulative Model Updates: 143,620
Cumulative Timesteps: 1,198,540,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,228.46061
Policy Entropy: 1.68900
Value Function Loss: 0.05081

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.31348
Value Function Update Magnitude: 0.36197

Collected Steps per Second: 20,680.55512
Overall Steps per Second: 10,133.05191

Timestep Collection Time: 2.41908
Timestep Consumption Time: 2.51803
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.93711

Cumulative Model Updates: 143,626
Cumulative Timesteps: 1,198,590,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1198590662...
Checkpoint 1198590662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,323.57513
Policy Entropy: 1.68609
Value Function Loss: 0.05119

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.31277
Value Function Update Magnitude: 0.36191

Collected Steps per Second: 22,004.68523
Overall Steps per Second: 10,586.18996

Timestep Collection Time: 2.27370
Timestep Consumption Time: 2.45246
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.72616

Cumulative Model Updates: 143,632
Cumulative Timesteps: 1,198,640,694

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,809.24097
Policy Entropy: 1.68624
Value Function Loss: 0.04929

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.30509
Value Function Update Magnitude: 0.36102

Collected Steps per Second: 21,936.26086
Overall Steps per Second: 10,464.20868

Timestep Collection Time: 2.27942
Timestep Consumption Time: 2.49896
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.77838

Cumulative Model Updates: 143,638
Cumulative Timesteps: 1,198,690,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1198690696...
Checkpoint 1198690696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,968.71556
Policy Entropy: 1.68661
Value Function Loss: 0.04739

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.29891
Value Function Update Magnitude: 0.35060

Collected Steps per Second: 21,929.60335
Overall Steps per Second: 10,582.96984

Timestep Collection Time: 2.28011
Timestep Consumption Time: 2.44465
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.72476

Cumulative Model Updates: 143,644
Cumulative Timesteps: 1,198,740,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,439.62628
Policy Entropy: 1.68855
Value Function Loss: 0.04977

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.29562
Value Function Update Magnitude: 0.34834

Collected Steps per Second: 21,929.08451
Overall Steps per Second: 10,489.42949

Timestep Collection Time: 2.28172
Timestep Consumption Time: 2.48842
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.77014

Cumulative Model Updates: 143,650
Cumulative Timesteps: 1,198,790,734

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1198790734...
Checkpoint 1198790734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,342.44786
Policy Entropy: 1.69260
Value Function Loss: 0.05411

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.31075
Value Function Update Magnitude: 0.34141

Collected Steps per Second: 21,893.93145
Overall Steps per Second: 10,609.47386

Timestep Collection Time: 2.28419
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.71371

Cumulative Model Updates: 143,656
Cumulative Timesteps: 1,198,840,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,462.84376
Policy Entropy: 1.68641
Value Function Loss: 0.05426

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.32091
Value Function Update Magnitude: 0.36765

Collected Steps per Second: 21,031.76619
Overall Steps per Second: 10,525.78001

Timestep Collection Time: 2.37755
Timestep Consumption Time: 2.37308
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.75062

Cumulative Model Updates: 143,662
Cumulative Timesteps: 1,198,890,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1198890748...
Checkpoint 1198890748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,571.67682
Policy Entropy: 1.67620
Value Function Loss: 0.05000

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.31873
Value Function Update Magnitude: 0.37956

Collected Steps per Second: 20,868.40625
Overall Steps per Second: 10,539.50748

Timestep Collection Time: 2.39673
Timestep Consumption Time: 2.34884
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.74557

Cumulative Model Updates: 143,668
Cumulative Timesteps: 1,198,940,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,891.93196
Policy Entropy: 1.67204
Value Function Loss: 0.05457

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.32452
Value Function Update Magnitude: 0.37359

Collected Steps per Second: 20,999.02110
Overall Steps per Second: 10,528.13749

Timestep Collection Time: 2.38135
Timestep Consumption Time: 2.36840
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.74975

Cumulative Model Updates: 143,674
Cumulative Timesteps: 1,198,990,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1198990770...
Checkpoint 1198990770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,994.02648
Policy Entropy: 1.67746
Value Function Loss: 0.05420

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.32840
Value Function Update Magnitude: 0.37395

Collected Steps per Second: 21,244.12759
Overall Steps per Second: 10,612.82667

Timestep Collection Time: 2.35491
Timestep Consumption Time: 2.35901
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.71392

Cumulative Model Updates: 143,680
Cumulative Timesteps: 1,199,040,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,471.39872
Policy Entropy: 1.69563
Value Function Loss: 0.05451

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.32256
Value Function Update Magnitude: 0.33918

Collected Steps per Second: 21,351.86975
Overall Steps per Second: 10,478.16320

Timestep Collection Time: 2.34350
Timestep Consumption Time: 2.43196
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.77546

Cumulative Model Updates: 143,686
Cumulative Timesteps: 1,199,090,836

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1199090836...
Checkpoint 1199090836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,190.13549
Policy Entropy: 1.68526
Value Function Loss: 0.05250

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.31855
Value Function Update Magnitude: 0.31235

Collected Steps per Second: 21,161.15092
Overall Steps per Second: 10,239.29524

Timestep Collection Time: 2.36471
Timestep Consumption Time: 2.52234
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.88706

Cumulative Model Updates: 143,692
Cumulative Timesteps: 1,199,140,876

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,651.42026
Policy Entropy: 1.68114
Value Function Loss: 0.05338

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.31956
Value Function Update Magnitude: 0.34169

Collected Steps per Second: 22,134.46430
Overall Steps per Second: 10,570.45842

Timestep Collection Time: 2.26001
Timestep Consumption Time: 2.47243
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.73243

Cumulative Model Updates: 143,698
Cumulative Timesteps: 1,199,190,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1199190900...
Checkpoint 1199190900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,056.69993
Policy Entropy: 1.67001
Value Function Loss: 0.05522

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.31840
Value Function Update Magnitude: 0.34123

Collected Steps per Second: 22,260.10697
Overall Steps per Second: 10,590.59110

Timestep Collection Time: 2.24752
Timestep Consumption Time: 2.47649
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.72400

Cumulative Model Updates: 143,704
Cumulative Timesteps: 1,199,240,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,968.63258
Policy Entropy: 1.67949
Value Function Loss: 0.05507

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.32232
Value Function Update Magnitude: 0.34237

Collected Steps per Second: 21,908.00373
Overall Steps per Second: 10,531.71603

Timestep Collection Time: 2.28254
Timestep Consumption Time: 2.46559
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.74813

Cumulative Model Updates: 143,710
Cumulative Timesteps: 1,199,290,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1199290936...
Checkpoint 1199290936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,121.75406
Policy Entropy: 1.68379
Value Function Loss: 0.05681

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.32464
Value Function Update Magnitude: 0.35980

Collected Steps per Second: 22,111.25921
Overall Steps per Second: 10,541.40403

Timestep Collection Time: 2.26202
Timestep Consumption Time: 2.48270
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.74472

Cumulative Model Updates: 143,716
Cumulative Timesteps: 1,199,340,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,908.07424
Policy Entropy: 1.69931
Value Function Loss: 0.05568

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.32378
Value Function Update Magnitude: 0.38892

Collected Steps per Second: 21,764.09191
Overall Steps per Second: 10,430.21543

Timestep Collection Time: 2.29911
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.79741

Cumulative Model Updates: 143,722
Cumulative Timesteps: 1,199,390,990

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1199390990...
Checkpoint 1199390990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,665.70533
Policy Entropy: 1.68284
Value Function Loss: 0.05429

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.32331
Value Function Update Magnitude: 0.39130

Collected Steps per Second: 21,340.34137
Overall Steps per Second: 10,491.99811

Timestep Collection Time: 2.34382
Timestep Consumption Time: 2.42343
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.76725

Cumulative Model Updates: 143,728
Cumulative Timesteps: 1,199,441,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,784.06447
Policy Entropy: 1.66878
Value Function Loss: 0.05355

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.32571
Value Function Update Magnitude: 0.38278

Collected Steps per Second: 21,406.46402
Overall Steps per Second: 10,494.63034

Timestep Collection Time: 2.33584
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.76453

Cumulative Model Updates: 143,734
Cumulative Timesteps: 1,199,491,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1199491010...
Checkpoint 1199491010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,100.73321
Policy Entropy: 1.65865
Value Function Loss: 0.05194

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.32241
Value Function Update Magnitude: 0.36026

Collected Steps per Second: 21,448.74279
Overall Steps per Second: 10,336.13385

Timestep Collection Time: 2.33244
Timestep Consumption Time: 2.50766
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.84011

Cumulative Model Updates: 143,740
Cumulative Timesteps: 1,199,541,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,958.29766
Policy Entropy: 1.65644
Value Function Loss: 0.04891

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.31582
Value Function Update Magnitude: 0.33867

Collected Steps per Second: 21,715.16265
Overall Steps per Second: 10,356.61551

Timestep Collection Time: 2.30309
Timestep Consumption Time: 2.52590
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.82899

Cumulative Model Updates: 143,746
Cumulative Timesteps: 1,199,591,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1199591050...
Checkpoint 1199591050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,365.07315
Policy Entropy: 1.65123
Value Function Loss: 0.05027

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.31085
Value Function Update Magnitude: 0.32293

Collected Steps per Second: 21,719.10230
Overall Steps per Second: 10,331.48373

Timestep Collection Time: 2.30231
Timestep Consumption Time: 2.53766
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.83996

Cumulative Model Updates: 143,752
Cumulative Timesteps: 1,199,641,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,462.96952
Policy Entropy: 1.64408
Value Function Loss: 0.05092

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.30982
Value Function Update Magnitude: 0.31169

Collected Steps per Second: 21,808.59792
Overall Steps per Second: 10,395.42696

Timestep Collection Time: 2.29332
Timestep Consumption Time: 2.51784
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.81115

Cumulative Model Updates: 143,758
Cumulative Timesteps: 1,199,691,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1199691068...
Checkpoint 1199691068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,113.74701
Policy Entropy: 1.66124
Value Function Loss: 0.05269

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.31212
Value Function Update Magnitude: 0.31612

Collected Steps per Second: 21,972.95323
Overall Steps per Second: 10,576.04211

Timestep Collection Time: 2.27552
Timestep Consumption Time: 2.45214
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.72767

Cumulative Model Updates: 143,764
Cumulative Timesteps: 1,199,741,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,110.11100
Policy Entropy: 1.67141
Value Function Loss: 0.05295

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.31475
Value Function Update Magnitude: 0.31168

Collected Steps per Second: 22,096.13289
Overall Steps per Second: 10,454.96527

Timestep Collection Time: 2.26420
Timestep Consumption Time: 2.52109
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.78529

Cumulative Model Updates: 143,770
Cumulative Timesteps: 1,199,791,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1199791098...
Checkpoint 1199791098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,020.04906
Policy Entropy: 1.68619
Value Function Loss: 0.04956

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.31193
Value Function Update Magnitude: 0.31973

Collected Steps per Second: 21,928.64854
Overall Steps per Second: 10,569.33863

Timestep Collection Time: 2.28058
Timestep Consumption Time: 2.45103
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.73161

Cumulative Model Updates: 143,776
Cumulative Timesteps: 1,199,841,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,226.09326
Policy Entropy: 1.67912
Value Function Loss: 0.04954

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.32930

Collected Steps per Second: 22,102.42902
Overall Steps per Second: 10,527.35611

Timestep Collection Time: 2.26219
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.74953

Cumulative Model Updates: 143,782
Cumulative Timesteps: 1,199,891,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1199891108...
Checkpoint 1199891108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,673.83249
Policy Entropy: 1.68957
Value Function Loss: 0.04688

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.31188
Value Function Update Magnitude: 0.33477

Collected Steps per Second: 21,844.54057
Overall Steps per Second: 10,590.14281

Timestep Collection Time: 2.29082
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.72534

Cumulative Model Updates: 143,788
Cumulative Timesteps: 1,199,941,150

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,959.23191
Policy Entropy: 1.68228
Value Function Loss: 0.05155

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.31702
Value Function Update Magnitude: 0.32079

Collected Steps per Second: 21,655.23013
Overall Steps per Second: 10,504.22375

Timestep Collection Time: 2.30900
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.76018

Cumulative Model Updates: 143,794
Cumulative Timesteps: 1,199,991,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1199991152...
Checkpoint 1199991152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,586.04717
Policy Entropy: 1.68926
Value Function Loss: 0.05264

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.31953
Value Function Update Magnitude: 0.32802

Collected Steps per Second: 21,452.72888
Overall Steps per Second: 10,328.82737

Timestep Collection Time: 2.33164
Timestep Consumption Time: 2.51112
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.84276

Cumulative Model Updates: 143,800
Cumulative Timesteps: 1,200,041,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,623.97092
Policy Entropy: 1.67024
Value Function Loss: 0.05120

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.31071
Value Function Update Magnitude: 0.33109

Collected Steps per Second: 21,670.65814
Overall Steps per Second: 10,393.23676

Timestep Collection Time: 2.30884
Timestep Consumption Time: 2.50526
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.81409

Cumulative Model Updates: 143,806
Cumulative Timesteps: 1,200,091,206

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1200091206...
Checkpoint 1200091206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,392.04827
Policy Entropy: 1.67494
Value Function Loss: 0.04871

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.30929
Value Function Update Magnitude: 0.32962

Collected Steps per Second: 21,290.43332
Overall Steps per Second: 10,481.69182

Timestep Collection Time: 2.34960
Timestep Consumption Time: 2.42291
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.77251

Cumulative Model Updates: 143,812
Cumulative Timesteps: 1,200,141,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,753.05341
Policy Entropy: 1.67155
Value Function Loss: 0.04715

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.33004

Collected Steps per Second: 21,952.97250
Overall Steps per Second: 10,521.02757

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.47499
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.75277

Cumulative Model Updates: 143,818
Cumulative Timesteps: 1,200,191,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1200191234...
Checkpoint 1200191234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,675.06642
Policy Entropy: 1.67210
Value Function Loss: 0.05079

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.30705
Value Function Update Magnitude: 0.33402

Collected Steps per Second: 21,811.60365
Overall Steps per Second: 10,543.34893

Timestep Collection Time: 2.29254
Timestep Consumption Time: 2.45016
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.74271

Cumulative Model Updates: 143,824
Cumulative Timesteps: 1,200,241,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,124.72500
Policy Entropy: 1.68705
Value Function Loss: 0.05273

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.30134
Value Function Update Magnitude: 0.35236

Collected Steps per Second: 22,224.72717
Overall Steps per Second: 10,553.16956

Timestep Collection Time: 2.25155
Timestep Consumption Time: 2.49016
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.74170

Cumulative Model Updates: 143,830
Cumulative Timesteps: 1,200,291,278

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1200291278...
Checkpoint 1200291278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,196.85774
Policy Entropy: 1.67009
Value Function Loss: 0.05689

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.28487
Value Function Update Magnitude: 0.37129

Collected Steps per Second: 21,612.39430
Overall Steps per Second: 10,555.84240

Timestep Collection Time: 2.31580
Timestep Consumption Time: 2.42565
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.74145

Cumulative Model Updates: 143,836
Cumulative Timesteps: 1,200,341,328

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,817.31154
Policy Entropy: 1.67336
Value Function Loss: 0.06059

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.29620
Value Function Update Magnitude: 0.38205

Collected Steps per Second: 21,879.92999
Overall Steps per Second: 10,585.18115

Timestep Collection Time: 2.28556
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.72434

Cumulative Model Updates: 143,842
Cumulative Timesteps: 1,200,391,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1200391336...
Checkpoint 1200391336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,059.01074
Policy Entropy: 1.67425
Value Function Loss: 0.06042

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.31501
Value Function Update Magnitude: 0.36993

Collected Steps per Second: 21,531.48511
Overall Steps per Second: 10,511.92724

Timestep Collection Time: 2.32246
Timestep Consumption Time: 2.43461
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.75707

Cumulative Model Updates: 143,848
Cumulative Timesteps: 1,200,441,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,249.73748
Policy Entropy: 1.68493
Value Function Loss: 0.05602

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.29790
Value Function Update Magnitude: 0.35305

Collected Steps per Second: 21,598.88227
Overall Steps per Second: 10,525.93932

Timestep Collection Time: 2.31512
Timestep Consumption Time: 2.43543
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.75055

Cumulative Model Updates: 143,854
Cumulative Timesteps: 1,200,491,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1200491346...
Checkpoint 1200491346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,907.93222
Policy Entropy: 1.68341
Value Function Loss: 0.05318

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.29917
Value Function Update Magnitude: 0.35573

Collected Steps per Second: 21,207.10923
Overall Steps per Second: 10,282.26526

Timestep Collection Time: 2.35968
Timestep Consumption Time: 2.50715
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.86683

Cumulative Model Updates: 143,860
Cumulative Timesteps: 1,200,541,388

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,415.89888
Policy Entropy: 1.68191
Value Function Loss: 0.05184

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.30725
Value Function Update Magnitude: 0.36180

Collected Steps per Second: 21,706.20018
Overall Steps per Second: 10,396.78046

Timestep Collection Time: 2.30487
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.81207

Cumulative Model Updates: 143,866
Cumulative Timesteps: 1,200,591,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1200591418...
Checkpoint 1200591418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,376.06580
Policy Entropy: 1.70051
Value Function Loss: 0.05078

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.31321
Value Function Update Magnitude: 0.35661

Collected Steps per Second: 21,551.24889
Overall Steps per Second: 10,555.10691

Timestep Collection Time: 2.32181
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.74064

Cumulative Model Updates: 143,872
Cumulative Timesteps: 1,200,641,456

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,639.34847
Policy Entropy: 1.70177
Value Function Loss: 0.05571

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08621
Policy Update Magnitude: 0.31996
Value Function Update Magnitude: 0.34980

Collected Steps per Second: 22,328.76639
Overall Steps per Second: 10,544.30980

Timestep Collection Time: 2.24132
Timestep Consumption Time: 2.50493
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.74626

Cumulative Model Updates: 143,878
Cumulative Timesteps: 1,200,691,502

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1200691502...
Checkpoint 1200691502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,627.03523
Policy Entropy: 1.70110
Value Function Loss: 0.05648

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.32664
Value Function Update Magnitude: 0.36198

Collected Steps per Second: 21,078.63113
Overall Steps per Second: 10,563.85594

Timestep Collection Time: 2.37397
Timestep Consumption Time: 2.36294
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.73691

Cumulative Model Updates: 143,884
Cumulative Timesteps: 1,200,741,542

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,139.48194
Policy Entropy: 1.68788
Value Function Loss: 0.05476

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.32321
Value Function Update Magnitude: 0.36410

Collected Steps per Second: 21,521.90887
Overall Steps per Second: 10,535.78182

Timestep Collection Time: 2.32452
Timestep Consumption Time: 2.42387
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.74839

Cumulative Model Updates: 143,890
Cumulative Timesteps: 1,200,791,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1200791570...
Checkpoint 1200791570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,761.71297
Policy Entropy: 1.69112
Value Function Loss: 0.05227

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.31694
Value Function Update Magnitude: 0.33913

Collected Steps per Second: 21,266.35482
Overall Steps per Second: 10,601.65483

Timestep Collection Time: 2.35123
Timestep Consumption Time: 2.36521
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71643

Cumulative Model Updates: 143,896
Cumulative Timesteps: 1,200,841,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,552.60056
Policy Entropy: 1.68458
Value Function Loss: 0.04997

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.31339
Value Function Update Magnitude: 0.31768

Collected Steps per Second: 21,477.76724
Overall Steps per Second: 10,524.01974

Timestep Collection Time: 2.32929
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.75370

Cumulative Model Updates: 143,902
Cumulative Timesteps: 1,200,891,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1200891600...
Checkpoint 1200891600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,104.58418
Policy Entropy: 1.68650
Value Function Loss: 0.05347

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.31911
Value Function Update Magnitude: 0.34985

Collected Steps per Second: 21,059.06022
Overall Steps per Second: 10,308.73614

Timestep Collection Time: 2.37522
Timestep Consumption Time: 2.47697
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.85220

Cumulative Model Updates: 143,908
Cumulative Timesteps: 1,200,941,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,141.28107
Policy Entropy: 1.70892
Value Function Loss: 0.05435

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.32584
Value Function Update Magnitude: 0.36513

Collected Steps per Second: 22,066.81763
Overall Steps per Second: 10,690.67377

Timestep Collection Time: 2.26711
Timestep Consumption Time: 2.41248
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.67959

Cumulative Model Updates: 143,914
Cumulative Timesteps: 1,200,991,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1200991648...
Checkpoint 1200991648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,331.41532
Policy Entropy: 1.70858
Value Function Loss: 0.05544

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.32802
Value Function Update Magnitude: 0.37659

Collected Steps per Second: 21,107.71895
Overall Steps per Second: 10,290.37266

Timestep Collection Time: 2.36994
Timestep Consumption Time: 2.49130
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.86124

Cumulative Model Updates: 143,920
Cumulative Timesteps: 1,201,041,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,608.60264
Policy Entropy: 1.71496
Value Function Loss: 0.05383

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.32218
Value Function Update Magnitude: 0.37336

Collected Steps per Second: 21,605.56687
Overall Steps per Second: 10,432.94772

Timestep Collection Time: 2.31505
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.79423

Cumulative Model Updates: 143,926
Cumulative Timesteps: 1,201,091,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1201091690...
Checkpoint 1201091690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,243.68572
Policy Entropy: 1.69325
Value Function Loss: 0.05141

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.30158
Value Function Update Magnitude: 0.36822

Collected Steps per Second: 21,317.16927
Overall Steps per Second: 10,316.17861

Timestep Collection Time: 2.34693
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.84966

Cumulative Model Updates: 143,932
Cumulative Timesteps: 1,201,141,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,585.34363
Policy Entropy: 1.69009
Value Function Loss: 0.05326

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.30273
Value Function Update Magnitude: 0.36487

Collected Steps per Second: 21,758.80688
Overall Steps per Second: 10,465.78059

Timestep Collection Time: 2.29893
Timestep Consumption Time: 2.48065
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.77958

Cumulative Model Updates: 143,938
Cumulative Timesteps: 1,201,191,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1201191742...
Checkpoint 1201191742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,567.82969
Policy Entropy: 1.69359
Value Function Loss: 0.05405

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.29934
Value Function Update Magnitude: 0.36371

Collected Steps per Second: 21,546.91624
Overall Steps per Second: 10,484.28412

Timestep Collection Time: 2.32107
Timestep Consumption Time: 2.44911
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.77019

Cumulative Model Updates: 143,944
Cumulative Timesteps: 1,201,241,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,405.15560
Policy Entropy: 1.72854
Value Function Loss: 0.05753

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.31228
Value Function Update Magnitude: 0.36435

Collected Steps per Second: 22,355.22188
Overall Steps per Second: 10,452.66346

Timestep Collection Time: 2.23661
Timestep Consumption Time: 2.54686
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.78347

Cumulative Model Updates: 143,950
Cumulative Timesteps: 1,201,291,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1201291754...
Checkpoint 1201291754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,355.66257
Policy Entropy: 1.73337
Value Function Loss: 0.05017

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.30976
Value Function Update Magnitude: 0.35069

Collected Steps per Second: 21,560.03059
Overall Steps per Second: 10,412.58916

Timestep Collection Time: 2.31929
Timestep Consumption Time: 2.48297
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.80226

Cumulative Model Updates: 143,956
Cumulative Timesteps: 1,201,341,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,435.95845
Policy Entropy: 1.72449
Value Function Loss: 0.05466

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.31315
Value Function Update Magnitude: 0.33914

Collected Steps per Second: 22,323.12478
Overall Steps per Second: 10,681.47321

Timestep Collection Time: 2.24108
Timestep Consumption Time: 2.44254
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.68362

Cumulative Model Updates: 143,962
Cumulative Timesteps: 1,201,391,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1201391786...
Checkpoint 1201391786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,884.61507
Policy Entropy: 1.70961
Value Function Loss: 0.05547

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.32534
Value Function Update Magnitude: 0.35441

Collected Steps per Second: 22,208.06914
Overall Steps per Second: 10,672.70957

Timestep Collection Time: 2.25188
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.68578

Cumulative Model Updates: 143,968
Cumulative Timesteps: 1,201,441,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,468.91088
Policy Entropy: 1.71512
Value Function Loss: 0.05663

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.32532
Value Function Update Magnitude: 0.37167

Collected Steps per Second: 22,140.65532
Overall Steps per Second: 10,494.55336

Timestep Collection Time: 2.26037
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.76876

Cumulative Model Updates: 143,974
Cumulative Timesteps: 1,201,491,842

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1201491842...
Checkpoint 1201491842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,216.35935
Policy Entropy: 1.70692
Value Function Loss: 0.05459

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.31802
Value Function Update Magnitude: 0.36277

Collected Steps per Second: 21,756.31131
Overall Steps per Second: 10,559.46526

Timestep Collection Time: 2.29919
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.73717

Cumulative Model Updates: 143,980
Cumulative Timesteps: 1,201,541,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,615.40256
Policy Entropy: 1.70806
Value Function Loss: 0.05695

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.32408
Value Function Update Magnitude: 0.37425

Collected Steps per Second: 21,897.17376
Overall Steps per Second: 10,459.21825

Timestep Collection Time: 2.28340
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.78047

Cumulative Model Updates: 143,986
Cumulative Timesteps: 1,201,591,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1201591864...
Checkpoint 1201591864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,443.58386
Policy Entropy: 1.71648
Value Function Loss: 0.06106

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.33070
Value Function Update Magnitude: 0.38690

Collected Steps per Second: 21,224.03690
Overall Steps per Second: 10,355.19414

Timestep Collection Time: 2.35582
Timestep Consumption Time: 2.47268
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.82849

Cumulative Model Updates: 143,992
Cumulative Timesteps: 1,201,641,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,157.34359
Policy Entropy: 1.73253
Value Function Loss: 0.06034

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.33483
Value Function Update Magnitude: 0.39816

Collected Steps per Second: 21,650.45394
Overall Steps per Second: 10,401.67677

Timestep Collection Time: 2.30942
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.80692

Cumulative Model Updates: 143,998
Cumulative Timesteps: 1,201,691,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1201691864...
Checkpoint 1201691864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,650.00167
Policy Entropy: 1.73036
Value Function Loss: 0.05718

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.33201
Value Function Update Magnitude: 0.38971

Collected Steps per Second: 21,561.37480
Overall Steps per Second: 10,522.45458

Timestep Collection Time: 2.31961
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.75307

Cumulative Model Updates: 144,004
Cumulative Timesteps: 1,201,741,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,496.21261
Policy Entropy: 1.71621
Value Function Loss: 0.05423

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.32786
Value Function Update Magnitude: 0.37231

Collected Steps per Second: 21,699.94470
Overall Steps per Second: 10,411.28424

Timestep Collection Time: 2.30480
Timestep Consumption Time: 2.49903
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.80383

Cumulative Model Updates: 144,010
Cumulative Timesteps: 1,201,791,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1201791892...
Checkpoint 1201791892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,264.53387
Policy Entropy: 1.70997
Value Function Loss: 0.05419

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.32476
Value Function Update Magnitude: 0.36085

Collected Steps per Second: 21,479.33741
Overall Steps per Second: 10,254.01817

Timestep Collection Time: 2.32894
Timestep Consumption Time: 2.54954
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.87848

Cumulative Model Updates: 144,016
Cumulative Timesteps: 1,201,841,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,433.83075
Policy Entropy: 1.70769
Value Function Loss: 0.05614

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08652
Policy Update Magnitude: 0.32405
Value Function Update Magnitude: 0.35130

Collected Steps per Second: 21,911.25813
Overall Steps per Second: 10,513.64037

Timestep Collection Time: 2.28294
Timestep Consumption Time: 2.47488
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.75782

Cumulative Model Updates: 144,022
Cumulative Timesteps: 1,201,891,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1201891938...
Checkpoint 1201891938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,953.26672
Policy Entropy: 1.71731
Value Function Loss: 0.05913

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.32570
Value Function Update Magnitude: 0.34615

Collected Steps per Second: 22,158.49018
Overall Steps per Second: 10,569.19520

Timestep Collection Time: 2.25719
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.73224

Cumulative Model Updates: 144,028
Cumulative Timesteps: 1,201,941,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,440.60974
Policy Entropy: 1.71515
Value Function Loss: 0.05660

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.32452
Value Function Update Magnitude: 0.35045

Collected Steps per Second: 22,128.74432
Overall Steps per Second: 10,454.88622

Timestep Collection Time: 2.26005
Timestep Consumption Time: 2.52355
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.78360

Cumulative Model Updates: 144,034
Cumulative Timesteps: 1,201,991,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1201991966...
Checkpoint 1201991966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,297.99499
Policy Entropy: 1.71044
Value Function Loss: 0.05320

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.32322
Value Function Update Magnitude: 0.34606

Collected Steps per Second: 22,046.07891
Overall Steps per Second: 10,623.45016

Timestep Collection Time: 2.26843
Timestep Consumption Time: 2.43908
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.70751

Cumulative Model Updates: 144,040
Cumulative Timesteps: 1,202,041,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,365.87818
Policy Entropy: 1.70993
Value Function Loss: 0.05525

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08502
Policy Update Magnitude: 0.31700
Value Function Update Magnitude: 0.33418

Collected Steps per Second: 22,262.08503
Overall Steps per Second: 10,626.86999

Timestep Collection Time: 2.24732
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.70788

Cumulative Model Updates: 144,046
Cumulative Timesteps: 1,202,092,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1202092006...
Checkpoint 1202092006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,557.76736
Policy Entropy: 1.71121
Value Function Loss: 0.05360

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.30574
Value Function Update Magnitude: 0.34751

Collected Steps per Second: 22,041.74790
Overall Steps per Second: 10,477.93737

Timestep Collection Time: 2.26906
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.77327

Cumulative Model Updates: 144,052
Cumulative Timesteps: 1,202,142,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,165.86474
Policy Entropy: 1.69843
Value Function Loss: 0.05507

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.29654
Value Function Update Magnitude: 0.36034

Collected Steps per Second: 21,788.11136
Overall Steps per Second: 10,424.05849

Timestep Collection Time: 2.29575
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.79851

Cumulative Model Updates: 144,058
Cumulative Timesteps: 1,202,192,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1202192040...
Checkpoint 1202192040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,606.70776
Policy Entropy: 1.69314
Value Function Loss: 0.05517

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.29649
Value Function Update Magnitude: 0.37831

Collected Steps per Second: 21,579.64410
Overall Steps per Second: 10,394.61808

Timestep Collection Time: 2.31774
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.81172

Cumulative Model Updates: 144,064
Cumulative Timesteps: 1,202,242,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,562.21664
Policy Entropy: 1.68634
Value Function Loss: 0.05426

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.30278
Value Function Update Magnitude: 0.38373

Collected Steps per Second: 21,679.50807
Overall Steps per Second: 10,401.54922

Timestep Collection Time: 2.30651
Timestep Consumption Time: 2.50085
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.80736

Cumulative Model Updates: 144,070
Cumulative Timesteps: 1,202,292,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1202292060...
Checkpoint 1202292060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,952.97501
Policy Entropy: 1.70374
Value Function Loss: 0.05510

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.29791
Value Function Update Magnitude: 0.37104

Collected Steps per Second: 21,003.83517
Overall Steps per Second: 10,147.90218

Timestep Collection Time: 2.38128
Timestep Consumption Time: 2.54742
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.92870

Cumulative Model Updates: 144,076
Cumulative Timesteps: 1,202,342,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,183.10027
Policy Entropy: 1.69992
Value Function Loss: 0.05553

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.29942
Value Function Update Magnitude: 0.37601

Collected Steps per Second: 21,330.90114
Overall Steps per Second: 10,320.96995

Timestep Collection Time: 2.34411
Timestep Consumption Time: 2.50059
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.84470

Cumulative Model Updates: 144,082
Cumulative Timesteps: 1,202,392,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1202392078...
Checkpoint 1202392078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,693.75091
Policy Entropy: 1.69956
Value Function Loss: 0.05878

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.30324
Value Function Update Magnitude: 0.38404

Collected Steps per Second: 21,624.79905
Overall Steps per Second: 10,364.27734

Timestep Collection Time: 2.31225
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.82446

Cumulative Model Updates: 144,088
Cumulative Timesteps: 1,202,442,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,441.94407
Policy Entropy: 1.69984
Value Function Loss: 0.05769

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.31124
Value Function Update Magnitude: 0.37596

Collected Steps per Second: 21,519.17546
Overall Steps per Second: 10,332.61963

Timestep Collection Time: 2.32351
Timestep Consumption Time: 2.51553
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.83904

Cumulative Model Updates: 144,094
Cumulative Timesteps: 1,202,492,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1202492080...
Checkpoint 1202492080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,788.10729
Policy Entropy: 1.69315
Value Function Loss: 0.05743

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.32861
Value Function Update Magnitude: 0.37101

Collected Steps per Second: 21,898.32860
Overall Steps per Second: 10,583.22737

Timestep Collection Time: 2.28392
Timestep Consumption Time: 2.44186
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.72578

Cumulative Model Updates: 144,100
Cumulative Timesteps: 1,202,542,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,815.94999
Policy Entropy: 1.69255
Value Function Loss: 0.05718

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.33275
Value Function Update Magnitude: 0.37215

Collected Steps per Second: 21,873.11834
Overall Steps per Second: 10,428.23569

Timestep Collection Time: 2.28737
Timestep Consumption Time: 2.51037
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.79774

Cumulative Model Updates: 144,106
Cumulative Timesteps: 1,202,592,126

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1202592126...
Checkpoint 1202592126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,645.30460
Policy Entropy: 1.68408
Value Function Loss: 0.05352

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.32755
Value Function Update Magnitude: 0.37573

Collected Steps per Second: 21,822.55134
Overall Steps per Second: 10,335.71651

Timestep Collection Time: 2.29157
Timestep Consumption Time: 2.54679
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.83837

Cumulative Model Updates: 144,112
Cumulative Timesteps: 1,202,642,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,455.90673
Policy Entropy: 1.68657
Value Function Loss: 0.05144

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.32230
Value Function Update Magnitude: 0.36788

Collected Steps per Second: 21,962.66093
Overall Steps per Second: 10,406.73878

Timestep Collection Time: 2.27677
Timestep Consumption Time: 2.52819
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.80496

Cumulative Model Updates: 144,118
Cumulative Timesteps: 1,202,692,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1202692138...
Checkpoint 1202692138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,751.48493
Policy Entropy: 1.69008
Value Function Loss: 0.05137

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.32368
Value Function Update Magnitude: 0.36461

Collected Steps per Second: 21,687.38977
Overall Steps per Second: 10,397.31170

Timestep Collection Time: 2.30586
Timestep Consumption Time: 2.50385
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.80970

Cumulative Model Updates: 144,124
Cumulative Timesteps: 1,202,742,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,972.44237
Policy Entropy: 1.69829
Value Function Loss: 0.05639

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.32938
Value Function Update Magnitude: 0.37698

Collected Steps per Second: 22,132.50325
Overall Steps per Second: 10,656.92991

Timestep Collection Time: 2.25930
Timestep Consumption Time: 2.43286
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.69216

Cumulative Model Updates: 144,130
Cumulative Timesteps: 1,202,792,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1202792150...
Checkpoint 1202792150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,258.73004
Policy Entropy: 1.71106
Value Function Loss: 0.05797

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.32913
Value Function Update Magnitude: 0.36991

Collected Steps per Second: 22,010.48448
Overall Steps per Second: 10,615.61440

Timestep Collection Time: 2.27319
Timestep Consumption Time: 2.44006
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71325

Cumulative Model Updates: 144,136
Cumulative Timesteps: 1,202,842,184

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,564.08896
Policy Entropy: 1.71310
Value Function Loss: 0.05802

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.32846
Value Function Update Magnitude: 0.36703

Collected Steps per Second: 21,467.68294
Overall Steps per Second: 10,524.37127

Timestep Collection Time: 2.32955
Timestep Consumption Time: 2.42228
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.75183

Cumulative Model Updates: 144,142
Cumulative Timesteps: 1,202,892,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1202892194...
Checkpoint 1202892194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,382.38973
Policy Entropy: 1.69770
Value Function Loss: 0.05482

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.32767
Value Function Update Magnitude: 0.35878

Collected Steps per Second: 20,751.83047
Overall Steps per Second: 10,374.39234

Timestep Collection Time: 2.41155
Timestep Consumption Time: 2.41225
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.82380

Cumulative Model Updates: 144,148
Cumulative Timesteps: 1,202,942,238

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,161.67301
Policy Entropy: 1.68322
Value Function Loss: 0.05286

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.32537
Value Function Update Magnitude: 0.35661

Collected Steps per Second: 20,980.81316
Overall Steps per Second: 10,387.64687

Timestep Collection Time: 2.38370
Timestep Consumption Time: 2.43086
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.81456

Cumulative Model Updates: 144,154
Cumulative Timesteps: 1,202,992,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1202992250...
Checkpoint 1202992250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,816.32253
Policy Entropy: 1.68188
Value Function Loss: 0.05033

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.32098
Value Function Update Magnitude: 0.32432

Collected Steps per Second: 21,141.55342
Overall Steps per Second: 10,510.64692

Timestep Collection Time: 2.36567
Timestep Consumption Time: 2.39274
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.75841

Cumulative Model Updates: 144,160
Cumulative Timesteps: 1,203,042,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,850.68656
Policy Entropy: 1.70011
Value Function Loss: 0.05600

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.31741
Value Function Update Magnitude: 0.28378

Collected Steps per Second: 21,250.27958
Overall Steps per Second: 10,487.09124

Timestep Collection Time: 2.35395
Timestep Consumption Time: 2.41592
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.76986

Cumulative Model Updates: 144,166
Cumulative Timesteps: 1,203,092,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1203092286...
Checkpoint 1203092286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,174.56152
Policy Entropy: 1.71789
Value Function Loss: 0.05838

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.31898
Value Function Update Magnitude: 0.32498

Collected Steps per Second: 21,368.22420
Overall Steps per Second: 10,604.30303

Timestep Collection Time: 2.34095
Timestep Consumption Time: 2.37619
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.71714

Cumulative Model Updates: 144,172
Cumulative Timesteps: 1,203,142,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,340.79069
Policy Entropy: 1.70821
Value Function Loss: 0.06018

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.32386
Value Function Update Magnitude: 0.35803

Collected Steps per Second: 21,396.12565
Overall Steps per Second: 10,452.28902

Timestep Collection Time: 2.33715
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.78422

Cumulative Model Updates: 144,178
Cumulative Timesteps: 1,203,192,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1203192314...
Checkpoint 1203192314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,765.78893
Policy Entropy: 1.71892
Value Function Loss: 0.05802

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.32691
Value Function Update Magnitude: 0.37708

Collected Steps per Second: 21,681.39227
Overall Steps per Second: 10,587.73950

Timestep Collection Time: 2.30825
Timestep Consumption Time: 2.41854
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.72679

Cumulative Model Updates: 144,184
Cumulative Timesteps: 1,203,242,360

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,498.27087
Policy Entropy: 1.70605
Value Function Loss: 0.05776

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.32503
Value Function Update Magnitude: 0.37970

Collected Steps per Second: 22,052.28886
Overall Steps per Second: 10,520.20513

Timestep Collection Time: 2.26788
Timestep Consumption Time: 2.48602
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.75390

Cumulative Model Updates: 144,190
Cumulative Timesteps: 1,203,292,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1203292372...
Checkpoint 1203292372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,140.81756
Policy Entropy: 1.71324
Value Function Loss: 0.05609

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.32602
Value Function Update Magnitude: 0.38329

Collected Steps per Second: 21,985.19818
Overall Steps per Second: 10,710.66325

Timestep Collection Time: 2.27553
Timestep Consumption Time: 2.39533
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.67086

Cumulative Model Updates: 144,196
Cumulative Timesteps: 1,203,342,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,566.84556
Policy Entropy: 1.69852
Value Function Loss: 0.05218

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.32563
Value Function Update Magnitude: 0.38191

Collected Steps per Second: 21,985.01632
Overall Steps per Second: 10,542.10390

Timestep Collection Time: 2.27437
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.74308

Cumulative Model Updates: 144,202
Cumulative Timesteps: 1,203,392,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1203392402...
Checkpoint 1203392402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,321.62767
Policy Entropy: 1.71197
Value Function Loss: 0.05052

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.31831
Value Function Update Magnitude: 0.37105

Collected Steps per Second: 21,828.82973
Overall Steps per Second: 10,500.87348

Timestep Collection Time: 2.29092
Timestep Consumption Time: 2.47136
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.76227

Cumulative Model Updates: 144,208
Cumulative Timesteps: 1,203,442,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,967.84048
Policy Entropy: 1.72758
Value Function Loss: 0.04958

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08652
Policy Update Magnitude: 0.31314
Value Function Update Magnitude: 0.34681

Collected Steps per Second: 21,737.92546
Overall Steps per Second: 10,470.15783

Timestep Collection Time: 2.30206
Timestep Consumption Time: 2.47743
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.77949

Cumulative Model Updates: 144,214
Cumulative Timesteps: 1,203,492,452

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1203492452...
Checkpoint 1203492452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,817.01388
Policy Entropy: 1.73423
Value Function Loss: 0.05268

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08189
Policy Update Magnitude: 0.31688
Value Function Update Magnitude: 0.31369

Collected Steps per Second: 21,345.04689
Overall Steps per Second: 10,300.96011

Timestep Collection Time: 2.34349
Timestep Consumption Time: 2.51256
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.85605

Cumulative Model Updates: 144,220
Cumulative Timesteps: 1,203,542,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,205.24434
Policy Entropy: 1.73724
Value Function Loss: 0.05251

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.31732
Value Function Update Magnitude: 0.26899

Collected Steps per Second: 21,774.37281
Overall Steps per Second: 10,431.67174

Timestep Collection Time: 2.29701
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.79463

Cumulative Model Updates: 144,226
Cumulative Timesteps: 1,203,592,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1203592490...
Checkpoint 1203592490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,285.64934
Policy Entropy: 1.72783
Value Function Loss: 0.05691

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08103
Policy Update Magnitude: 0.31850
Value Function Update Magnitude: 0.31102

Collected Steps per Second: 21,450.13570
Overall Steps per Second: 10,477.77796

Timestep Collection Time: 2.33173
Timestep Consumption Time: 2.44180
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.77353

Cumulative Model Updates: 144,232
Cumulative Timesteps: 1,203,642,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,232.95948
Policy Entropy: 1.72532
Value Function Loss: 0.05640

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08256
Policy Update Magnitude: 0.31961
Value Function Update Magnitude: 0.34462

Collected Steps per Second: 21,778.81202
Overall Steps per Second: 10,597.38908

Timestep Collection Time: 2.29627
Timestep Consumption Time: 2.42282
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.71909

Cumulative Model Updates: 144,238
Cumulative Timesteps: 1,203,692,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1203692516...
Checkpoint 1203692516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,377.54464
Policy Entropy: 1.71773
Value Function Loss: 0.05603

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.32025
Value Function Update Magnitude: 0.36173

Collected Steps per Second: 21,744.84805
Overall Steps per Second: 10,511.82522

Timestep Collection Time: 2.30105
Timestep Consumption Time: 2.45892
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.75997

Cumulative Model Updates: 144,244
Cumulative Timesteps: 1,203,742,552

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,455.73009
Policy Entropy: 1.71907
Value Function Loss: 0.05281

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.31648
Value Function Update Magnitude: 0.36712

Collected Steps per Second: 21,944.00137
Overall Steps per Second: 10,470.53786

Timestep Collection Time: 2.27871
Timestep Consumption Time: 2.49698
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.77569

Cumulative Model Updates: 144,250
Cumulative Timesteps: 1,203,792,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1203792556...
Checkpoint 1203792556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,296.27404
Policy Entropy: 1.71473
Value Function Loss: 0.05240

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.31426
Value Function Update Magnitude: 0.31166

Collected Steps per Second: 21,984.99089
Overall Steps per Second: 10,609.36864

Timestep Collection Time: 2.27510
Timestep Consumption Time: 2.43941
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.71451

Cumulative Model Updates: 144,256
Cumulative Timesteps: 1,203,842,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,792.42292
Policy Entropy: 1.70849
Value Function Loss: 0.05391

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.30948
Value Function Update Magnitude: 0.26296

Collected Steps per Second: 22,023.96350
Overall Steps per Second: 10,507.39191

Timestep Collection Time: 2.27116
Timestep Consumption Time: 2.48930
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.76046

Cumulative Model Updates: 144,262
Cumulative Timesteps: 1,203,892,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1203892594...
Checkpoint 1203892594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,933.63555
Policy Entropy: 1.69641
Value Function Loss: 0.05123

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.31105
Value Function Update Magnitude: 0.25557

Collected Steps per Second: 22,022.44680
Overall Steps per Second: 10,620.34533

Timestep Collection Time: 2.27123
Timestep Consumption Time: 2.43841
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.70964

Cumulative Model Updates: 144,268
Cumulative Timesteps: 1,203,942,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,269.26197
Policy Entropy: 1.68930
Value Function Loss: 0.05530

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.31574
Value Function Update Magnitude: 0.26686

Collected Steps per Second: 22,061.46078
Overall Steps per Second: 10,481.89832

Timestep Collection Time: 2.26785
Timestep Consumption Time: 2.50534
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.77318

Cumulative Model Updates: 144,274
Cumulative Timesteps: 1,203,992,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1203992644...
Checkpoint 1203992644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,425.85870
Policy Entropy: 1.69200
Value Function Loss: 0.05343

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.30921
Value Function Update Magnitude: 0.31330

Collected Steps per Second: 21,821.00495
Overall Steps per Second: 10,574.07639

Timestep Collection Time: 2.29275
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.73138

Cumulative Model Updates: 144,280
Cumulative Timesteps: 1,204,042,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,974.61450
Policy Entropy: 1.69991
Value Function Loss: 0.05164

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.30629
Value Function Update Magnitude: 0.33386

Collected Steps per Second: 21,411.34861
Overall Steps per Second: 10,545.25415

Timestep Collection Time: 2.33614
Timestep Consumption Time: 2.40722
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.74337

Cumulative Model Updates: 144,286
Cumulative Timesteps: 1,204,092,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1204092694...
Checkpoint 1204092694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,148.21552
Policy Entropy: 1.71437
Value Function Loss: 0.04956

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.33649

Collected Steps per Second: 21,516.97561
Overall Steps per Second: 10,519.28852

Timestep Collection Time: 2.32384
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.75336

Cumulative Model Updates: 144,292
Cumulative Timesteps: 1,204,142,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,542.02319
Policy Entropy: 1.69978
Value Function Loss: 0.04994

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08126
Policy Update Magnitude: 0.30799
Value Function Update Magnitude: 0.34521

Collected Steps per Second: 21,466.42598
Overall Steps per Second: 10,475.30317

Timestep Collection Time: 2.33090
Timestep Consumption Time: 2.44567
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.77657

Cumulative Model Updates: 144,298
Cumulative Timesteps: 1,204,192,732

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1204192732...
Checkpoint 1204192732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,690.88114
Policy Entropy: 1.69853
Value Function Loss: 0.05137

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.30871
Value Function Update Magnitude: 0.31565

Collected Steps per Second: 20,775.72619
Overall Steps per Second: 10,329.61278

Timestep Collection Time: 2.40877
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.84471

Cumulative Model Updates: 144,304
Cumulative Timesteps: 1,204,242,776

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,610.36089
Policy Entropy: 1.68396
Value Function Loss: 0.05065

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.31088
Value Function Update Magnitude: 0.23356

Collected Steps per Second: 21,584.63087
Overall Steps per Second: 10,403.88591

Timestep Collection Time: 2.31748
Timestep Consumption Time: 2.49053
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.80801

Cumulative Model Updates: 144,310
Cumulative Timesteps: 1,204,292,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1204292798...
Checkpoint 1204292798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,852.63097
Policy Entropy: 1.68670
Value Function Loss: 0.05072

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.31358
Value Function Update Magnitude: 0.23383

Collected Steps per Second: 21,709.89275
Overall Steps per Second: 10,588.05441

Timestep Collection Time: 2.30420
Timestep Consumption Time: 2.42037
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.72457

Cumulative Model Updates: 144,316
Cumulative Timesteps: 1,204,342,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,847.95308
Policy Entropy: 1.70206
Value Function Loss: 0.05238

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.30090
Value Function Update Magnitude: 0.21859

Collected Steps per Second: 22,019.95585
Overall Steps per Second: 10,494.84222

Timestep Collection Time: 2.27139
Timestep Consumption Time: 2.49438
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.76577

Cumulative Model Updates: 144,322
Cumulative Timesteps: 1,204,392,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1204392838...
Checkpoint 1204392838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,327.95759
Policy Entropy: 1.71623
Value Function Loss: 0.05426

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.27856
Value Function Update Magnitude: 0.20409

Collected Steps per Second: 21,772.06519
Overall Steps per Second: 10,351.62149

Timestep Collection Time: 2.29716
Timestep Consumption Time: 2.53435
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.83151

Cumulative Model Updates: 144,328
Cumulative Timesteps: 1,204,442,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,935.69800
Policy Entropy: 1.71705
Value Function Loss: 0.05195

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.28280
Value Function Update Magnitude: 0.27173

Collected Steps per Second: 22,169.77201
Overall Steps per Second: 10,674.09670

Timestep Collection Time: 2.25568
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.68499

Cumulative Model Updates: 144,334
Cumulative Timesteps: 1,204,492,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1204492860...
Checkpoint 1204492860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,055.86827
Policy Entropy: 1.68892
Value Function Loss: 0.05268

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.29149
Value Function Update Magnitude: 0.30686

Collected Steps per Second: 21,769.81795
Overall Steps per Second: 10,450.42358

Timestep Collection Time: 2.29749
Timestep Consumption Time: 2.48853
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.78603

Cumulative Model Updates: 144,340
Cumulative Timesteps: 1,204,542,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,278.49973
Policy Entropy: 1.67985
Value Function Loss: 0.05167

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.31513
Value Function Update Magnitude: 0.34079

Collected Steps per Second: 22,044.54225
Overall Steps per Second: 10,649.37440

Timestep Collection Time: 2.26850
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.69586

Cumulative Model Updates: 144,346
Cumulative Timesteps: 1,204,592,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1204592884...
Checkpoint 1204592884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,914.71803
Policy Entropy: 1.67709
Value Function Loss: 0.05029

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.31824
Value Function Update Magnitude: 0.32384

Collected Steps per Second: 21,758.51021
Overall Steps per Second: 10,443.52571

Timestep Collection Time: 2.29823
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.78823

Cumulative Model Updates: 144,352
Cumulative Timesteps: 1,204,642,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,505.05533
Policy Entropy: 1.69326
Value Function Loss: 0.04837

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.31244
Value Function Update Magnitude: 0.32001

Collected Steps per Second: 22,269.82528
Overall Steps per Second: 10,680.91586

Timestep Collection Time: 2.24645
Timestep Consumption Time: 2.43742
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.68387

Cumulative Model Updates: 144,358
Cumulative Timesteps: 1,204,692,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1204692918...
Checkpoint 1204692918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,219.63246
Policy Entropy: 1.67904
Value Function Loss: 0.04445

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.30478
Value Function Update Magnitude: 0.32454

Collected Steps per Second: 22,050.87413
Overall Steps per Second: 10,655.37932

Timestep Collection Time: 2.26839
Timestep Consumption Time: 2.42595
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.69434

Cumulative Model Updates: 144,364
Cumulative Timesteps: 1,204,742,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,368.41909
Policy Entropy: 1.68267
Value Function Loss: 0.04691

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.30699
Value Function Update Magnitude: 0.31797

Collected Steps per Second: 21,633.94903
Overall Steps per Second: 10,540.52763

Timestep Collection Time: 2.31275
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.74682

Cumulative Model Updates: 144,370
Cumulative Timesteps: 1,204,792,972

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1204792972...
Checkpoint 1204792972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,544.35462
Policy Entropy: 1.69503
Value Function Loss: 0.04958

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.31363
Value Function Update Magnitude: 0.31968

Collected Steps per Second: 21,325.16738
Overall Steps per Second: 10,511.20060

Timestep Collection Time: 2.34652
Timestep Consumption Time: 2.41411
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.76064

Cumulative Model Updates: 144,376
Cumulative Timesteps: 1,204,843,012

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,784.73085
Policy Entropy: 1.69301
Value Function Loss: 0.04706

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08060
Policy Update Magnitude: 0.31380
Value Function Update Magnitude: 0.32020

Collected Steps per Second: 21,542.36106
Overall Steps per Second: 10,518.88358

Timestep Collection Time: 2.32249
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.75640

Cumulative Model Updates: 144,382
Cumulative Timesteps: 1,204,893,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1204893044...
Checkpoint 1204893044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,288.13131
Policy Entropy: 1.69827
Value Function Loss: 0.05115

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.30990
Value Function Update Magnitude: 0.31216

Collected Steps per Second: 21,052.16446
Overall Steps per Second: 10,602.13476

Timestep Collection Time: 2.37515
Timestep Consumption Time: 2.34107
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.71622

Cumulative Model Updates: 144,388
Cumulative Timesteps: 1,204,943,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,851.81239
Policy Entropy: 1.69823
Value Function Loss: 0.04908

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.30987
Value Function Update Magnitude: 0.30222

Collected Steps per Second: 21,291.35658
Overall Steps per Second: 10,567.93645

Timestep Collection Time: 2.34865
Timestep Consumption Time: 2.38321
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.73186

Cumulative Model Updates: 144,394
Cumulative Timesteps: 1,204,993,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1204993052...
Checkpoint 1204993052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,540.14722
Policy Entropy: 1.72595
Value Function Loss: 0.05792

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.28347

Collected Steps per Second: 21,116.44886
Overall Steps per Second: 10,552.44853

Timestep Collection Time: 2.36877
Timestep Consumption Time: 2.37136
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.74013

Cumulative Model Updates: 144,400
Cumulative Timesteps: 1,205,043,072

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,730.07816
Policy Entropy: 1.71844
Value Function Loss: 0.05545

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.31689
Value Function Update Magnitude: 0.25364

Collected Steps per Second: 21,478.05173
Overall Steps per Second: 10,474.10224

Timestep Collection Time: 2.32852
Timestep Consumption Time: 2.44631
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.77482

Cumulative Model Updates: 144,406
Cumulative Timesteps: 1,205,093,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1205093084...
Checkpoint 1205093084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,728.51775
Policy Entropy: 1.70210
Value Function Loss: 0.05319

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.25673

Collected Steps per Second: 21,327.94139
Overall Steps per Second: 10,390.51820

Timestep Collection Time: 2.34622
Timestep Consumption Time: 2.46971
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.81593

Cumulative Model Updates: 144,412
Cumulative Timesteps: 1,205,143,124

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,338.38401
Policy Entropy: 1.68991
Value Function Loss: 0.04909

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.31585
Value Function Update Magnitude: 0.29424

Collected Steps per Second: 22,280.11876
Overall Steps per Second: 10,714.80974

Timestep Collection Time: 2.24550
Timestep Consumption Time: 2.42374
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.66924

Cumulative Model Updates: 144,418
Cumulative Timesteps: 1,205,193,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1205193154...
Checkpoint 1205193154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,222.17494
Policy Entropy: 1.69818
Value Function Loss: 0.04818

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.31061
Value Function Update Magnitude: 0.31613

Collected Steps per Second: 21,919.74065
Overall Steps per Second: 10,651.74778

Timestep Collection Time: 2.28260
Timestep Consumption Time: 2.41466
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.69726

Cumulative Model Updates: 144,424
Cumulative Timesteps: 1,205,243,188

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,377.28357
Policy Entropy: 1.71135
Value Function Loss: 0.05100

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.30331
Value Function Update Magnitude: 0.33297

Collected Steps per Second: 21,892.30087
Overall Steps per Second: 10,510.30122

Timestep Collection Time: 2.28464
Timestep Consumption Time: 2.47412
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.75876

Cumulative Model Updates: 144,430
Cumulative Timesteps: 1,205,293,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1205293204...
Checkpoint 1205293204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,933.30129
Policy Entropy: 1.71024
Value Function Loss: 0.04995

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.30423
Value Function Update Magnitude: 0.34068

Collected Steps per Second: 21,589.92109
Overall Steps per Second: 10,517.11379

Timestep Collection Time: 2.31654
Timestep Consumption Time: 2.43894
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.75549

Cumulative Model Updates: 144,436
Cumulative Timesteps: 1,205,343,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,391.62001
Policy Entropy: 1.69961
Value Function Loss: 0.05345

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.30942
Value Function Update Magnitude: 0.34844

Collected Steps per Second: 21,708.86336
Overall Steps per Second: 10,542.83554

Timestep Collection Time: 2.30542
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.74711

Cumulative Model Updates: 144,442
Cumulative Timesteps: 1,205,393,266

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1205393266...
Checkpoint 1205393266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,599.28445
Policy Entropy: 1.69239
Value Function Loss: 0.04965

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.30868
Value Function Update Magnitude: 0.35739

Collected Steps per Second: 21,035.11397
Overall Steps per Second: 10,288.20317

Timestep Collection Time: 2.37812
Timestep Consumption Time: 2.48415
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.86227

Cumulative Model Updates: 144,448
Cumulative Timesteps: 1,205,443,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,904.19637
Policy Entropy: 1.68811
Value Function Loss: 0.04905

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.29851
Value Function Update Magnitude: 0.33756

Collected Steps per Second: 21,932.11905
Overall Steps per Second: 10,452.92746

Timestep Collection Time: 2.28140
Timestep Consumption Time: 2.50539
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.78679

Cumulative Model Updates: 144,454
Cumulative Timesteps: 1,205,493,326

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1205493326...
Checkpoint 1205493326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,991.75172
Policy Entropy: 1.68045
Value Function Loss: 0.04960

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.29696
Value Function Update Magnitude: 0.31919

Collected Steps per Second: 21,741.23057
Overall Steps per Second: 10,580.43748

Timestep Collection Time: 2.30005
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.72627

Cumulative Model Updates: 144,460
Cumulative Timesteps: 1,205,543,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,713.20066
Policy Entropy: 1.68366
Value Function Loss: 0.05136

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.31522
Value Function Update Magnitude: 0.32436

Collected Steps per Second: 22,147.02161
Overall Steps per Second: 10,414.48180

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.54489
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.80389

Cumulative Model Updates: 144,466
Cumulative Timesteps: 1,205,593,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1205593362...
Checkpoint 1205593362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,159.21263
Policy Entropy: 1.70082
Value Function Loss: 0.05009

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.31642
Value Function Update Magnitude: 0.32863

Collected Steps per Second: 21,808.46749
Overall Steps per Second: 10,553.90729

Timestep Collection Time: 2.29315
Timestep Consumption Time: 2.44538
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.73853

Cumulative Model Updates: 144,472
Cumulative Timesteps: 1,205,643,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,223.77259
Policy Entropy: 1.71379
Value Function Loss: 0.04840

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.31118
Value Function Update Magnitude: 0.30581

Collected Steps per Second: 22,248.75817
Overall Steps per Second: 10,520.53721

Timestep Collection Time: 2.24902
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.75622

Cumulative Model Updates: 144,478
Cumulative Timesteps: 1,205,693,410

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1205693410...
Checkpoint 1205693410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,803.62503
Policy Entropy: 1.71637
Value Function Loss: 0.04907

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.30898
Value Function Update Magnitude: 0.29072

Collected Steps per Second: 21,960.70894
Overall Steps per Second: 10,607.52554

Timestep Collection Time: 2.27688
Timestep Consumption Time: 2.43694
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.71382

Cumulative Model Updates: 144,484
Cumulative Timesteps: 1,205,743,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,930.45133
Policy Entropy: 1.71311
Value Function Loss: 0.05293

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.31216
Value Function Update Magnitude: 0.30051

Collected Steps per Second: 22,181.26345
Overall Steps per Second: 10,485.20879

Timestep Collection Time: 2.25424
Timestep Consumption Time: 2.51457
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.76881

Cumulative Model Updates: 144,490
Cumulative Timesteps: 1,205,793,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1205793414...
Checkpoint 1205793414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,779.59567
Policy Entropy: 1.70094
Value Function Loss: 0.05026

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.31726
Value Function Update Magnitude: 0.32499

Collected Steps per Second: 21,609.04902
Overall Steps per Second: 10,557.01799

Timestep Collection Time: 2.31477
Timestep Consumption Time: 2.42331
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.73808

Cumulative Model Updates: 144,496
Cumulative Timesteps: 1,205,843,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,101.46919
Policy Entropy: 1.72277
Value Function Loss: 0.05378

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08287
Policy Update Magnitude: 0.31472
Value Function Update Magnitude: 0.32349

Collected Steps per Second: 21,895.87361
Overall Steps per Second: 10,532.84509

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.46451
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.74895

Cumulative Model Updates: 144,502
Cumulative Timesteps: 1,205,893,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1205893454...
Checkpoint 1205893454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,316.26291
Policy Entropy: 1.70658
Value Function Loss: 0.04871

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.31296
Value Function Update Magnitude: 0.32845

Collected Steps per Second: 21,586.27342
Overall Steps per Second: 10,549.83695

Timestep Collection Time: 2.31684
Timestep Consumption Time: 2.42370
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.74055

Cumulative Model Updates: 144,508
Cumulative Timesteps: 1,205,943,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,921.07072
Policy Entropy: 1.71466
Value Function Loss: 0.04840

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.30845
Value Function Update Magnitude: 0.31967

Collected Steps per Second: 21,474.04337
Overall Steps per Second: 10,490.74089

Timestep Collection Time: 2.32858
Timestep Consumption Time: 2.43791
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.76649

Cumulative Model Updates: 144,514
Cumulative Timesteps: 1,205,993,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1205993470...
Checkpoint 1205993470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,527.20455
Policy Entropy: 1.68973
Value Function Loss: 0.04447

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.30808
Value Function Update Magnitude: 0.30829

Collected Steps per Second: 21,232.25417
Overall Steps per Second: 10,261.19826

Timestep Collection Time: 2.35632
Timestep Consumption Time: 2.51933
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.87565

Cumulative Model Updates: 144,520
Cumulative Timesteps: 1,206,043,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,606.96673
Policy Entropy: 1.69083
Value Function Loss: 0.04517

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.30166
Value Function Update Magnitude: 0.31900

Collected Steps per Second: 21,686.45658
Overall Steps per Second: 10,395.86185

Timestep Collection Time: 2.30586
Timestep Consumption Time: 2.50432
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.81018

Cumulative Model Updates: 144,526
Cumulative Timesteps: 1,206,093,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1206093506...
Checkpoint 1206093506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,706.47618
Policy Entropy: 1.69852
Value Function Loss: 0.04272

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.29647
Value Function Update Magnitude: 0.31898

Collected Steps per Second: 21,260.28060
Overall Steps per Second: 10,259.81966

Timestep Collection Time: 2.35312
Timestep Consumption Time: 2.52299
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.87611

Cumulative Model Updates: 144,532
Cumulative Timesteps: 1,206,143,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,824.12649
Policy Entropy: 1.71175
Value Function Loss: 0.04449

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.29886
Value Function Update Magnitude: 0.30130

Collected Steps per Second: 22,102.91365
Overall Steps per Second: 10,447.36822

Timestep Collection Time: 2.26341
Timestep Consumption Time: 2.52516
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.78857

Cumulative Model Updates: 144,538
Cumulative Timesteps: 1,206,193,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1206193562...
Checkpoint 1206193562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,507.64719
Policy Entropy: 1.71112
Value Function Loss: 0.04482

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.29968
Value Function Update Magnitude: 0.30033

Collected Steps per Second: 21,625.90078
Overall Steps per Second: 10,334.33108

Timestep Collection Time: 2.31417
Timestep Consumption Time: 2.52852
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.84269

Cumulative Model Updates: 144,544
Cumulative Timesteps: 1,206,243,608

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,068.63523
Policy Entropy: 1.70281
Value Function Loss: 0.04268

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07701
Policy Update Magnitude: 0.29542
Value Function Update Magnitude: 0.30089

Collected Steps per Second: 21,828.81361
Overall Steps per Second: 10,435.98999

Timestep Collection Time: 2.29220
Timestep Consumption Time: 2.50236
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.79456

Cumulative Model Updates: 144,550
Cumulative Timesteps: 1,206,293,644

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1206293644...
Checkpoint 1206293644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,828.22500
Policy Entropy: 1.69169
Value Function Loss: 0.04537

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.28671
Value Function Update Magnitude: 0.28501

Collected Steps per Second: 21,954.89242
Overall Steps per Second: 10,624.70143

Timestep Collection Time: 2.27785
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.70696

Cumulative Model Updates: 144,556
Cumulative Timesteps: 1,206,343,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,538.46948
Policy Entropy: 1.69802
Value Function Loss: 0.04580

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.27964
Value Function Update Magnitude: 0.28212

Collected Steps per Second: 22,335.55471
Overall Steps per Second: 10,642.98838

Timestep Collection Time: 2.23939
Timestep Consumption Time: 2.46023
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.69962

Cumulative Model Updates: 144,562
Cumulative Timesteps: 1,206,393,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1206393672...
Checkpoint 1206393672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,789.86001
Policy Entropy: 1.71188
Value Function Loss: 0.04893

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.29504
Value Function Update Magnitude: 0.29292

Collected Steps per Second: 21,798.32047
Overall Steps per Second: 10,416.83782

Timestep Collection Time: 2.29467
Timestep Consumption Time: 2.50717
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.80184

Cumulative Model Updates: 144,568
Cumulative Timesteps: 1,206,443,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,740.28147
Policy Entropy: 1.72663
Value Function Loss: 0.04843

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.30310
Value Function Update Magnitude: 0.30667

Collected Steps per Second: 22,057.34769
Overall Steps per Second: 10,496.40183

Timestep Collection Time: 2.26890
Timestep Consumption Time: 2.49902
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.76792

Cumulative Model Updates: 144,574
Cumulative Timesteps: 1,206,493,738

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1206493738...
Checkpoint 1206493738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,860.85415
Policy Entropy: 1.72518
Value Function Loss: 0.04759

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.30690
Value Function Update Magnitude: 0.33999

Collected Steps per Second: 21,498.81137
Overall Steps per Second: 10,519.46394

Timestep Collection Time: 2.32645
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.75461

Cumulative Model Updates: 144,580
Cumulative Timesteps: 1,206,543,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,193.40011
Policy Entropy: 1.72188
Value Function Loss: 0.05060

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.31283
Value Function Update Magnitude: 0.36396

Collected Steps per Second: 21,469.81128
Overall Steps per Second: 10,508.93001

Timestep Collection Time: 2.33006
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.76033

Cumulative Model Updates: 144,586
Cumulative Timesteps: 1,206,593,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1206593780...
Checkpoint 1206593780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,627.13087
Policy Entropy: 1.71542
Value Function Loss: 0.05075

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.31510
Value Function Update Magnitude: 0.33851

Collected Steps per Second: 21,609.12426
Overall Steps per Second: 10,401.48060

Timestep Collection Time: 2.31504
Timestep Consumption Time: 2.49447
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.80951

Cumulative Model Updates: 144,592
Cumulative Timesteps: 1,206,643,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,923.86831
Policy Entropy: 1.71265
Value Function Loss: 0.05188

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.31603
Value Function Update Magnitude: 0.33367

Collected Steps per Second: 21,149.15539
Overall Steps per Second: 10,465.17693

Timestep Collection Time: 2.36615
Timestep Consumption Time: 2.41562
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.78176

Cumulative Model Updates: 144,598
Cumulative Timesteps: 1,206,693,848

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1206693848...
Checkpoint 1206693848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,647.12295
Policy Entropy: 1.72112
Value Function Loss: 0.05213

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.32224
Value Function Update Magnitude: 0.35650

Collected Steps per Second: 21,549.87575
Overall Steps per Second: 10,461.71169

Timestep Collection Time: 2.32029
Timestep Consumption Time: 2.45923
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.77952

Cumulative Model Updates: 144,604
Cumulative Timesteps: 1,206,743,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,170.78400
Policy Entropy: 1.71144
Value Function Loss: 0.04787

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.31069
Value Function Update Magnitude: 0.35795

Collected Steps per Second: 21,502.27601
Overall Steps per Second: 10,518.20334

Timestep Collection Time: 2.32580
Timestep Consumption Time: 2.42881
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.75461

Cumulative Model Updates: 144,610
Cumulative Timesteps: 1,206,793,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1206793860...
Checkpoint 1206793860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,670.16053
Policy Entropy: 1.70300
Value Function Loss: 0.04723

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.28911
Value Function Update Magnitude: 0.32992

Collected Steps per Second: 21,294.38064
Overall Steps per Second: 10,545.31380

Timestep Collection Time: 2.34935
Timestep Consumption Time: 2.39475
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.74410

Cumulative Model Updates: 144,616
Cumulative Timesteps: 1,206,843,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,377.77877
Policy Entropy: 1.70742
Value Function Loss: 0.04573

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.29725
Value Function Update Magnitude: 0.30955

Collected Steps per Second: 21,723.13219
Overall Steps per Second: 10,450.25207

Timestep Collection Time: 2.30215
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.78553

Cumulative Model Updates: 144,622
Cumulative Timesteps: 1,206,893,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1206893898...
Checkpoint 1206893898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,388.69247
Policy Entropy: 1.70895
Value Function Loss: 0.04533

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.30430
Value Function Update Magnitude: 0.30773

Collected Steps per Second: 21,757.73721
Overall Steps per Second: 10,594.28967

Timestep Collection Time: 2.29895
Timestep Consumption Time: 2.42246
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.72141

Cumulative Model Updates: 144,628
Cumulative Timesteps: 1,206,943,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,148.86536
Policy Entropy: 1.71672
Value Function Loss: 0.04513

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.30633
Value Function Update Magnitude: 0.29800

Collected Steps per Second: 21,855.80455
Overall Steps per Second: 10,509.72238

Timestep Collection Time: 2.28900
Timestep Consumption Time: 2.47116
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.76016

Cumulative Model Updates: 144,634
Cumulative Timesteps: 1,206,993,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1206993946...
Checkpoint 1206993946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,518.39368
Policy Entropy: 1.68909
Value Function Loss: 0.04388

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.30032
Value Function Update Magnitude: 0.30907

Collected Steps per Second: 22,052.42570
Overall Steps per Second: 10,644.18605

Timestep Collection Time: 2.26823
Timestep Consumption Time: 2.43105
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.69928

Cumulative Model Updates: 144,640
Cumulative Timesteps: 1,207,043,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,402.81318
Policy Entropy: 1.68347
Value Function Loss: 0.04421

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.30057
Value Function Update Magnitude: 0.32681

Collected Steps per Second: 21,490.19382
Overall Steps per Second: 10,507.83787

Timestep Collection Time: 2.32795
Timestep Consumption Time: 2.43307
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.76102

Cumulative Model Updates: 144,646
Cumulative Timesteps: 1,207,093,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1207093994...
Checkpoint 1207093994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,285.59911
Policy Entropy: 1.68440
Value Function Loss: 0.04218

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.30082
Value Function Update Magnitude: 0.32015

Collected Steps per Second: 21,789.38947
Overall Steps per Second: 10,553.24522

Timestep Collection Time: 2.29589
Timestep Consumption Time: 2.44445
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.74034

Cumulative Model Updates: 144,652
Cumulative Timesteps: 1,207,144,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,588.04045
Policy Entropy: 1.69115
Value Function Loss: 0.04327

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.29965
Value Function Update Magnitude: 0.29196

Collected Steps per Second: 21,603.64717
Overall Steps per Second: 10,548.51631

Timestep Collection Time: 2.31452
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.74019

Cumulative Model Updates: 144,658
Cumulative Timesteps: 1,207,194,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1207194022...
Checkpoint 1207194022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,879.43264
Policy Entropy: 1.70632
Value Function Loss: 0.04569

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.30353
Value Function Update Magnitude: 0.30037

Collected Steps per Second: 21,575.39282
Overall Steps per Second: 10,521.88309

Timestep Collection Time: 2.31792
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.75295

Cumulative Model Updates: 144,664
Cumulative Timesteps: 1,207,244,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,323.50551
Policy Entropy: 1.70511
Value Function Loss: 0.04524

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.29985
Value Function Update Magnitude: 0.30627

Collected Steps per Second: 21,520.86731
Overall Steps per Second: 10,485.71863

Timestep Collection Time: 2.32491
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.77163

Cumulative Model Updates: 144,670
Cumulative Timesteps: 1,207,294,066

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1207294066...
Checkpoint 1207294066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,400.05101
Policy Entropy: 1.72930
Value Function Loss: 0.05080

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.30695
Value Function Update Magnitude: 0.32739

Collected Steps per Second: 22,225.72007
Overall Steps per Second: 10,639.86330

Timestep Collection Time: 2.25028
Timestep Consumption Time: 2.45035
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.70062

Cumulative Model Updates: 144,676
Cumulative Timesteps: 1,207,344,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,319.01214
Policy Entropy: 1.73205
Value Function Loss: 0.04840

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.30943
Value Function Update Magnitude: 0.35399

Collected Steps per Second: 22,054.52020
Overall Steps per Second: 10,467.40266

Timestep Collection Time: 2.26910
Timestep Consumption Time: 2.51183
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.78094

Cumulative Model Updates: 144,682
Cumulative Timesteps: 1,207,394,124

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1207394124...
Checkpoint 1207394124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,476.73460
Policy Entropy: 1.73222
Value Function Loss: 0.04591

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.30204
Value Function Update Magnitude: 0.34902

Collected Steps per Second: 22,179.15473
Overall Steps per Second: 10,700.40542

Timestep Collection Time: 2.25491
Timestep Consumption Time: 2.41893
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.67384

Cumulative Model Updates: 144,688
Cumulative Timesteps: 1,207,444,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,002.69893
Policy Entropy: 1.72416
Value Function Loss: 0.04283

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.29753
Value Function Update Magnitude: 0.31591

Collected Steps per Second: 21,820.64020
Overall Steps per Second: 10,386.66392

Timestep Collection Time: 2.29242
Timestep Consumption Time: 2.52357
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.81598

Cumulative Model Updates: 144,694
Cumulative Timesteps: 1,207,494,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1207494158...
Checkpoint 1207494158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,750.32440
Policy Entropy: 1.72244
Value Function Loss: 0.04692

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.30176
Value Function Update Magnitude: 0.31072

Collected Steps per Second: 21,662.80895
Overall Steps per Second: 10,557.10908

Timestep Collection Time: 2.30940
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.73880

Cumulative Model Updates: 144,700
Cumulative Timesteps: 1,207,544,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,197.31391
Policy Entropy: 1.70693
Value Function Loss: 0.04602

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.30919
Value Function Update Magnitude: 0.31956

Collected Steps per Second: 22,037.09670
Overall Steps per Second: 10,556.13301

Timestep Collection Time: 2.26936
Timestep Consumption Time: 2.46818
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.73753

Cumulative Model Updates: 144,706
Cumulative Timesteps: 1,207,594,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1207594196...
Checkpoint 1207594196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,262.48391
Policy Entropy: 1.70776
Value Function Loss: 0.04707

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.30528
Value Function Update Magnitude: 0.32500

Collected Steps per Second: 21,853.85001
Overall Steps per Second: 10,603.63148

Timestep Collection Time: 2.28802
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.71555

Cumulative Model Updates: 144,712
Cumulative Timesteps: 1,207,644,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,399.22030
Policy Entropy: 1.70161
Value Function Loss: 0.04501

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.30314
Value Function Update Magnitude: 0.33165

Collected Steps per Second: 21,430.36041
Overall Steps per Second: 10,437.12288

Timestep Collection Time: 2.33333
Timestep Consumption Time: 2.45765
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.79098

Cumulative Model Updates: 144,718
Cumulative Timesteps: 1,207,694,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1207694202...
Checkpoint 1207694202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,445.49821
Policy Entropy: 1.71088
Value Function Loss: 0.04376

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.30301
Value Function Update Magnitude: 0.32947

Collected Steps per Second: 21,341.36109
Overall Steps per Second: 10,299.78860

Timestep Collection Time: 2.34493
Timestep Consumption Time: 2.51381
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.85874

Cumulative Model Updates: 144,724
Cumulative Timesteps: 1,207,744,246

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,293.40358
Policy Entropy: 1.70036
Value Function Loss: 0.04223

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.30189
Value Function Update Magnitude: 0.32095

Collected Steps per Second: 21,790.48300
Overall Steps per Second: 10,394.29304

Timestep Collection Time: 2.29623
Timestep Consumption Time: 2.51756
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.81380

Cumulative Model Updates: 144,730
Cumulative Timesteps: 1,207,794,282

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1207794282...
Checkpoint 1207794282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,330.45594
Policy Entropy: 1.70156
Value Function Loss: 0.03813

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.29500
Value Function Update Magnitude: 0.30647

Collected Steps per Second: 21,941.90223
Overall Steps per Second: 10,571.40646

Timestep Collection Time: 2.27893
Timestep Consumption Time: 2.45119
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.73012

Cumulative Model Updates: 144,736
Cumulative Timesteps: 1,207,844,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,942.44747
Policy Entropy: 1.70225
Value Function Loss: 0.03762

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.28999
Value Function Update Magnitude: 0.28248

Collected Steps per Second: 21,750.01115
Overall Steps per Second: 10,568.71744

Timestep Collection Time: 2.30124
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.73586

Cumulative Model Updates: 144,742
Cumulative Timesteps: 1,207,894,338

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1207894338...
Checkpoint 1207894338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,211.74857
Policy Entropy: 1.69269
Value Function Loss: 0.04105

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.29379
Value Function Update Magnitude: 0.28725

Collected Steps per Second: 21,984.99722
Overall Steps per Second: 10,613.26098

Timestep Collection Time: 2.27555
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.71373

Cumulative Model Updates: 144,748
Cumulative Timesteps: 1,207,944,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,452.48354
Policy Entropy: 1.70212
Value Function Loss: 0.04356

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07346
Policy Update Magnitude: 0.30527
Value Function Update Magnitude: 0.29644

Collected Steps per Second: 20,904.20616
Overall Steps per Second: 10,354.04732

Timestep Collection Time: 2.39311
Timestep Consumption Time: 2.43843
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.83154

Cumulative Model Updates: 144,754
Cumulative Timesteps: 1,207,994,392

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1207994392...
Checkpoint 1207994392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,491.68744
Policy Entropy: 1.69952
Value Function Loss: 0.04417

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.30611
Value Function Update Magnitude: 0.30137

Collected Steps per Second: 21,964.84300
Overall Steps per Second: 10,642.73053

Timestep Collection Time: 2.27819
Timestep Consumption Time: 2.42361
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.70180

Cumulative Model Updates: 144,760
Cumulative Timesteps: 1,208,044,432

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,958.10959
Policy Entropy: 1.71056
Value Function Loss: 0.04247

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08345
Policy Update Magnitude: 0.30627
Value Function Update Magnitude: 0.30682

Collected Steps per Second: 22,051.76853
Overall Steps per Second: 10,524.33704

Timestep Collection Time: 2.26821
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.75260

Cumulative Model Updates: 144,766
Cumulative Timesteps: 1,208,094,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1208094450...
Checkpoint 1208094450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,139.87883
Policy Entropy: 1.69925
Value Function Loss: 0.04195

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.30203
Value Function Update Magnitude: 0.30323

Collected Steps per Second: 21,943.62372
Overall Steps per Second: 10,632.77081

Timestep Collection Time: 2.27957
Timestep Consumption Time: 2.42494
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.70451

Cumulative Model Updates: 144,772
Cumulative Timesteps: 1,208,144,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,498.21073
Policy Entropy: 1.69529
Value Function Loss: 0.04163

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08072
Policy Update Magnitude: 0.29667
Value Function Update Magnitude: 0.28055

Collected Steps per Second: 20,782.35199
Overall Steps per Second: 10,517.61789

Timestep Collection Time: 2.40627
Timestep Consumption Time: 2.34842
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.75469

Cumulative Model Updates: 144,778
Cumulative Timesteps: 1,208,194,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1208194480...
Checkpoint 1208194480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,981.85379
Policy Entropy: 1.70701
Value Function Loss: 0.04627

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.30131
Value Function Update Magnitude: 0.28654

Collected Steps per Second: 21,051.04860
Overall Steps per Second: 10,579.36654

Timestep Collection Time: 2.37660
Timestep Consumption Time: 2.35241
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.72902

Cumulative Model Updates: 144,784
Cumulative Timesteps: 1,208,244,510

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,473.84022
Policy Entropy: 1.71531
Value Function Loss: 0.05173

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.31061
Value Function Update Magnitude: 0.30483

Collected Steps per Second: 21,181.01860
Overall Steps per Second: 10,455.74999

Timestep Collection Time: 2.36127
Timestep Consumption Time: 2.42213
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.78340

Cumulative Model Updates: 144,790
Cumulative Timesteps: 1,208,294,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1208294524...
Checkpoint 1208294524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,718.00373
Policy Entropy: 1.74530
Value Function Loss: 0.05149

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.31516
Value Function Update Magnitude: 0.33788

Collected Steps per Second: 20,679.93493
Overall Steps per Second: 10,319.84186

Timestep Collection Time: 2.41877
Timestep Consumption Time: 2.42820
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.84697

Cumulative Model Updates: 144,796
Cumulative Timesteps: 1,208,344,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,112.40406
Policy Entropy: 1.73490
Value Function Loss: 0.04819

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.31052
Value Function Update Magnitude: 0.34156

Collected Steps per Second: 21,433.47878
Overall Steps per Second: 10,523.71322

Timestep Collection Time: 2.33280
Timestep Consumption Time: 2.41838
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.75117

Cumulative Model Updates: 144,802
Cumulative Timesteps: 1,208,394,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1208394544...
Checkpoint 1208394544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,110.57962
Policy Entropy: 1.73499
Value Function Loss: 0.04819

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.31357
Value Function Update Magnitude: 0.32702

Collected Steps per Second: 21,318.26822
Overall Steps per Second: 10,483.13467

Timestep Collection Time: 2.34672
Timestep Consumption Time: 2.42552
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.77224

Cumulative Model Updates: 144,808
Cumulative Timesteps: 1,208,444,572

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,810.85077
Policy Entropy: 1.71729
Value Function Loss: 0.04750

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.31049
Value Function Update Magnitude: 0.31985

Collected Steps per Second: 21,975.73572
Overall Steps per Second: 10,533.63442

Timestep Collection Time: 2.27542
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.74708

Cumulative Model Updates: 144,814
Cumulative Timesteps: 1,208,494,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1208494576...
Checkpoint 1208494576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,884.35056
Policy Entropy: 1.72297
Value Function Loss: 0.04766

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.31669

Collected Steps per Second: 21,895.09260
Overall Steps per Second: 10,500.22996

Timestep Collection Time: 2.28517
Timestep Consumption Time: 2.47987
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.76504

Cumulative Model Updates: 144,820
Cumulative Timesteps: 1,208,544,610

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,075.27485
Policy Entropy: 1.71300
Value Function Loss: 0.04358

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.31042
Value Function Update Magnitude: 0.31365

Collected Steps per Second: 22,021.48711
Overall Steps per Second: 10,528.41332

Timestep Collection Time: 2.27142
Timestep Consumption Time: 2.47954
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.75095

Cumulative Model Updates: 144,826
Cumulative Timesteps: 1,208,594,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1208594630...
Checkpoint 1208594630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,468.86336
Policy Entropy: 1.71676
Value Function Loss: 0.04535

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.30504
Value Function Update Magnitude: 0.31018

Collected Steps per Second: 21,875.53154
Overall Steps per Second: 10,561.52034

Timestep Collection Time: 2.28758
Timestep Consumption Time: 2.45056
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.73814

Cumulative Model Updates: 144,832
Cumulative Timesteps: 1,208,644,672

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,489.79124
Policy Entropy: 1.72000
Value Function Loss: 0.04958

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.31076
Value Function Update Magnitude: 0.30658

Collected Steps per Second: 22,105.80677
Overall Steps per Second: 10,460.98906

Timestep Collection Time: 2.26303
Timestep Consumption Time: 2.51912
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.78215

Cumulative Model Updates: 144,838
Cumulative Timesteps: 1,208,694,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1208694698...
Checkpoint 1208694698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,487.26123
Policy Entropy: 1.72217
Value Function Loss: 0.04911

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.31566
Value Function Update Magnitude: 0.31736

Collected Steps per Second: 21,872.09325
Overall Steps per Second: 10,582.21385

Timestep Collection Time: 2.28702
Timestep Consumption Time: 2.43996
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.72699

Cumulative Model Updates: 144,844
Cumulative Timesteps: 1,208,744,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,037.43727
Policy Entropy: 1.71374
Value Function Loss: 0.04889

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.31114
Value Function Update Magnitude: 0.30138

Collected Steps per Second: 21,653.48426
Overall Steps per Second: 10,528.76241

Timestep Collection Time: 2.31039
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.75156

Cumulative Model Updates: 144,850
Cumulative Timesteps: 1,208,794,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1208794748...
Checkpoint 1208794748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,165.10357
Policy Entropy: 1.71196
Value Function Loss: 0.05002

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.30696
Value Function Update Magnitude: 0.27865

Collected Steps per Second: 21,549.27809
Overall Steps per Second: 10,549.39824

Timestep Collection Time: 2.32166
Timestep Consumption Time: 2.42080
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.74245

Cumulative Model Updates: 144,856
Cumulative Timesteps: 1,208,844,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,089.49486
Policy Entropy: 1.71332
Value Function Loss: 0.04674

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08782
Policy Update Magnitude: 0.30292
Value Function Update Magnitude: 0.27559

Collected Steps per Second: 21,543.84154
Overall Steps per Second: 10,500.89337

Timestep Collection Time: 2.32233
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.76455

Cumulative Model Updates: 144,862
Cumulative Timesteps: 1,208,894,810

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1208894810...
Checkpoint 1208894810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,018.79316
Policy Entropy: 1.70394
Value Function Loss: 0.04705

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.29968
Value Function Update Magnitude: 0.27657

Collected Steps per Second: 21,447.96898
Overall Steps per Second: 10,388.14516

Timestep Collection Time: 2.33262
Timestep Consumption Time: 2.48344
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.81607

Cumulative Model Updates: 144,868
Cumulative Timesteps: 1,208,944,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,868.51635
Policy Entropy: 1.69517
Value Function Loss: 0.04232

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.29254
Value Function Update Magnitude: 0.28056

Collected Steps per Second: 22,458.37910
Overall Steps per Second: 10,672.01282

Timestep Collection Time: 2.22643
Timestep Consumption Time: 2.45891
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.68534

Cumulative Model Updates: 144,874
Cumulative Timesteps: 1,208,994,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1208994842...
Checkpoint 1208994842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,597.93720
Policy Entropy: 1.70051
Value Function Loss: 0.04654

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.29222
Value Function Update Magnitude: 0.29247

Collected Steps per Second: 21,821.15017
Overall Steps per Second: 10,380.39380

Timestep Collection Time: 2.29181
Timestep Consumption Time: 2.52592
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.81774

Cumulative Model Updates: 144,880
Cumulative Timesteps: 1,209,044,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,848.28869
Policy Entropy: 1.70941
Value Function Loss: 0.04716

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.30321

Collected Steps per Second: 22,296.46456
Overall Steps per Second: 10,696.20898

Timestep Collection Time: 2.24448
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.67867

Cumulative Model Updates: 144,886
Cumulative Timesteps: 1,209,094,896

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1209094896...
Checkpoint 1209094896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,497.24881
Policy Entropy: 1.73230
Value Function Loss: 0.05263

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08812
Policy Update Magnitude: 0.31720
Value Function Update Magnitude: 0.30946

Collected Steps per Second: 21,565.86983
Overall Steps per Second: 10,433.22002

Timestep Collection Time: 2.31885
Timestep Consumption Time: 2.47430
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.79315

Cumulative Model Updates: 144,892
Cumulative Timesteps: 1,209,144,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,201.23592
Policy Entropy: 1.73886
Value Function Loss: 0.05058

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.31788
Value Function Update Magnitude: 0.32757

Collected Steps per Second: 22,171.89181
Overall Steps per Second: 10,680.33836

Timestep Collection Time: 2.25673
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.68487

Cumulative Model Updates: 144,898
Cumulative Timesteps: 1,209,194,940

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1209194940...
Checkpoint 1209194940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,131.02233
Policy Entropy: 1.75283
Value Function Loss: 0.05291

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.31324
Value Function Update Magnitude: 0.33081

Collected Steps per Second: 22,202.72859
Overall Steps per Second: 10,691.74541

Timestep Collection Time: 2.25225
Timestep Consumption Time: 2.42482
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.67707

Cumulative Model Updates: 144,904
Cumulative Timesteps: 1,209,244,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,774.73162
Policy Entropy: 1.75483
Value Function Loss: 0.04985

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.30931
Value Function Update Magnitude: 0.32339

Collected Steps per Second: 22,216.91542
Overall Steps per Second: 10,478.76524

Timestep Collection Time: 2.25162
Timestep Consumption Time: 2.52223
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.77384

Cumulative Model Updates: 144,910
Cumulative Timesteps: 1,209,294,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1209294970...
Checkpoint 1209294970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,562.17737
Policy Entropy: 1.74916
Value Function Loss: 0.04757

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.30527
Value Function Update Magnitude: 0.28598

Collected Steps per Second: 21,521.57751
Overall Steps per Second: 10,370.81070

Timestep Collection Time: 2.32427
Timestep Consumption Time: 2.49907
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.82335

Cumulative Model Updates: 144,916
Cumulative Timesteps: 1,209,344,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,622.05718
Policy Entropy: 1.73710
Value Function Loss: 0.04731

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.30385
Value Function Update Magnitude: 0.24895

Collected Steps per Second: 21,754.85290
Overall Steps per Second: 10,402.15777

Timestep Collection Time: 2.29898
Timestep Consumption Time: 2.50906
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.80804

Cumulative Model Updates: 144,922
Cumulative Timesteps: 1,209,395,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1209395006...
Checkpoint 1209395006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,071.88345
Policy Entropy: 1.72326
Value Function Loss: 0.04566

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.30238
Value Function Update Magnitude: 0.22049

Collected Steps per Second: 21,165.06717
Overall Steps per Second: 10,472.46482

Timestep Collection Time: 2.36323
Timestep Consumption Time: 2.41291
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.77614

Cumulative Model Updates: 144,928
Cumulative Timesteps: 1,209,445,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,562.95315
Policy Entropy: 1.71670
Value Function Loss: 0.04457

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.29869
Value Function Update Magnitude: 0.20740

Collected Steps per Second: 21,565.94558
Overall Steps per Second: 10,483.39764

Timestep Collection Time: 2.31847
Timestep Consumption Time: 2.45098
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.76945

Cumulative Model Updates: 144,934
Cumulative Timesteps: 1,209,495,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1209495024...
Checkpoint 1209495024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,332.36347
Policy Entropy: 1.71751
Value Function Loss: 0.04625

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.28828
Value Function Update Magnitude: 0.22533

Collected Steps per Second: 21,390.17860
Overall Steps per Second: 10,319.79609

Timestep Collection Time: 2.33864
Timestep Consumption Time: 2.50874
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.84738

Cumulative Model Updates: 144,940
Cumulative Timesteps: 1,209,545,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,417.31752
Policy Entropy: 1.69801
Value Function Loss: 0.04449

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.26270
Value Function Update Magnitude: 0.25916

Collected Steps per Second: 22,218.99555
Overall Steps per Second: 10,437.59417

Timestep Collection Time: 2.25069
Timestep Consumption Time: 2.54046
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.79114

Cumulative Model Updates: 144,946
Cumulative Timesteps: 1,209,595,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1209595056...
Checkpoint 1209595056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,744.46603
Policy Entropy: 1.70700
Value Function Loss: 0.04971

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.26522
Value Function Update Magnitude: 0.29650

Collected Steps per Second: 21,863.51299
Overall Steps per Second: 10,542.12657

Timestep Collection Time: 2.28884
Timestep Consumption Time: 2.45802
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.74686

Cumulative Model Updates: 144,952
Cumulative Timesteps: 1,209,645,098

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,388.63408
Policy Entropy: 1.70571
Value Function Loss: 0.04728

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.30136
Value Function Update Magnitude: 0.31905

Collected Steps per Second: 22,144.75571
Overall Steps per Second: 10,465.37027

Timestep Collection Time: 2.25895
Timestep Consumption Time: 2.52100
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.77996

Cumulative Model Updates: 144,958
Cumulative Timesteps: 1,209,695,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1209695122...
Checkpoint 1209695122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,527.13978
Policy Entropy: 1.71654
Value Function Loss: 0.04707

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.30735
Value Function Update Magnitude: 0.32292

Collected Steps per Second: 21,628.84559
Overall Steps per Second: 10,543.55006

Timestep Collection Time: 2.31302
Timestep Consumption Time: 2.43187
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.74489

Cumulative Model Updates: 144,964
Cumulative Timesteps: 1,209,745,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,372.31547
Policy Entropy: 1.72021
Value Function Loss: 0.04499

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.30117
Value Function Update Magnitude: 0.30491

Collected Steps per Second: 21,761.09975
Overall Steps per Second: 10,552.21299

Timestep Collection Time: 2.29777
Timestep Consumption Time: 2.44076
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.73853

Cumulative Model Updates: 144,970
Cumulative Timesteps: 1,209,795,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1209795152...
Checkpoint 1209795152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,075.67433
Policy Entropy: 1.72729
Value Function Loss: 0.04815

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.30223
Value Function Update Magnitude: 0.30803

Collected Steps per Second: 21,814.13397
Overall Steps per Second: 10,593.87837

Timestep Collection Time: 2.29383
Timestep Consumption Time: 2.42946
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.72329

Cumulative Model Updates: 144,976
Cumulative Timesteps: 1,209,845,190

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,884.95829
Policy Entropy: 1.73762
Value Function Loss: 0.04836

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.30883
Value Function Update Magnitude: 0.31133

Collected Steps per Second: 20,576.91305
Overall Steps per Second: 10,082.84041

Timestep Collection Time: 2.43059
Timestep Consumption Time: 2.52972
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.96031

Cumulative Model Updates: 144,982
Cumulative Timesteps: 1,209,895,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1209895204...
Checkpoint 1209895204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,425.13876
Policy Entropy: 1.72012
Value Function Loss: 0.05060

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.31585
Value Function Update Magnitude: 0.31946

Collected Steps per Second: 21,279.34238
Overall Steps per Second: 10,298.79563

Timestep Collection Time: 2.35026
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.85610

Cumulative Model Updates: 144,988
Cumulative Timesteps: 1,209,945,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,906.97662
Policy Entropy: 1.71086
Value Function Loss: 0.05037

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.31800
Value Function Update Magnitude: 0.30617

Collected Steps per Second: 21,684.17142
Overall Steps per Second: 10,357.30700

Timestep Collection Time: 2.30638
Timestep Consumption Time: 2.52229
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.82867

Cumulative Model Updates: 144,994
Cumulative Timesteps: 1,209,995,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1209995228...
Checkpoint 1209995228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,843.82235
Policy Entropy: 1.71004
Value Function Loss: 0.05577

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.31976
Value Function Update Magnitude: 0.31375

Collected Steps per Second: 21,705.38384
Overall Steps per Second: 10,554.30948

Timestep Collection Time: 2.30477
Timestep Consumption Time: 2.43509
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.73986

Cumulative Model Updates: 145,000
Cumulative Timesteps: 1,210,045,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,297.66394
Policy Entropy: 1.70748
Value Function Loss: 0.05137

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.31718
Value Function Update Magnitude: 0.34727

Collected Steps per Second: 22,144.35038
Overall Steps per Second: 10,597.91339

Timestep Collection Time: 2.25818
Timestep Consumption Time: 2.46029
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.71848

Cumulative Model Updates: 145,006
Cumulative Timesteps: 1,210,095,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1210095260...
Checkpoint 1210095260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,735.98017
Policy Entropy: 1.72832
Value Function Loss: 0.05633

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.31918
Value Function Update Magnitude: 0.36043

Collected Steps per Second: 21,936.82491
Overall Steps per Second: 10,453.90954

Timestep Collection Time: 2.28028
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.78500

Cumulative Model Updates: 145,012
Cumulative Timesteps: 1,210,145,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,198.44062
Policy Entropy: 1.73567
Value Function Loss: 0.05018

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.30890
Value Function Update Magnitude: 0.36482

Collected Steps per Second: 22,072.11704
Overall Steps per Second: 10,553.49998

Timestep Collection Time: 2.26675
Timestep Consumption Time: 2.47405
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.74080

Cumulative Model Updates: 145,018
Cumulative Timesteps: 1,210,195,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1210195314...
Checkpoint 1210195314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,748.67965
Policy Entropy: 1.74725
Value Function Loss: 0.05327

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.30476
Value Function Update Magnitude: 0.34905

Collected Steps per Second: 21,302.73473
Overall Steps per Second: 10,622.73252

Timestep Collection Time: 2.34768
Timestep Consumption Time: 2.36034
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.70802

Cumulative Model Updates: 145,024
Cumulative Timesteps: 1,210,245,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,260.26110
Policy Entropy: 1.72859
Value Function Loss: 0.04933

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.31028
Value Function Update Magnitude: 0.31104

Collected Steps per Second: 21,504.78270
Overall Steps per Second: 10,480.20609

Timestep Collection Time: 2.32572
Timestep Consumption Time: 2.44652
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.77223

Cumulative Model Updates: 145,030
Cumulative Timesteps: 1,210,295,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1210295340...
Checkpoint 1210295340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,644.74613
Policy Entropy: 1.70866
Value Function Loss: 0.05055

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.28022

Collected Steps per Second: 21,195.83989
Overall Steps per Second: 10,577.13223

Timestep Collection Time: 2.35933
Timestep Consumption Time: 2.36860
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.72794

Cumulative Model Updates: 145,036
Cumulative Timesteps: 1,210,345,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,569.00956
Policy Entropy: 1.70319
Value Function Loss: 0.04491

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.31192
Value Function Update Magnitude: 0.26481

Collected Steps per Second: 21,285.60384
Overall Steps per Second: 10,501.32909

Timestep Collection Time: 2.35013
Timestep Consumption Time: 2.41345
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.76359

Cumulative Model Updates: 145,042
Cumulative Timesteps: 1,210,395,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1210395372...
Checkpoint 1210395372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,181.03465
Policy Entropy: 1.70505
Value Function Loss: 0.04578

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.30890
Value Function Update Magnitude: 0.29288

Collected Steps per Second: 21,269.24672
Overall Steps per Second: 10,379.65122

Timestep Collection Time: 2.35232
Timestep Consumption Time: 2.46788
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.82020

Cumulative Model Updates: 145,048
Cumulative Timesteps: 1,210,445,404

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,931.99664
Policy Entropy: 1.71289
Value Function Loss: 0.04638

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.29959
Value Function Update Magnitude: 0.31984

Collected Steps per Second: 21,618.73113
Overall Steps per Second: 10,447.14089

Timestep Collection Time: 2.31364
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.78772

Cumulative Model Updates: 145,054
Cumulative Timesteps: 1,210,495,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1210495422...
Checkpoint 1210495422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,728.26838
Policy Entropy: 1.71381
Value Function Loss: 0.04662

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.29157
Value Function Update Magnitude: 0.34377

Collected Steps per Second: 21,561.46085
Overall Steps per Second: 10,501.80005

Timestep Collection Time: 2.31969
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.76261

Cumulative Model Updates: 145,060
Cumulative Timesteps: 1,210,545,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,686.50804
Policy Entropy: 1.70730
Value Function Loss: 0.04299

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.29388
Value Function Update Magnitude: 0.33958

Collected Steps per Second: 21,725.55402
Overall Steps per Second: 10,444.30606

Timestep Collection Time: 2.30227
Timestep Consumption Time: 2.48676
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.78902

Cumulative Model Updates: 145,066
Cumulative Timesteps: 1,210,595,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1210595456...
Checkpoint 1210595456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,391.89783
Policy Entropy: 1.70912
Value Function Loss: 0.04569

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.30141
Value Function Update Magnitude: 0.31872

Collected Steps per Second: 21,680.28072
Overall Steps per Second: 10,560.79949

Timestep Collection Time: 2.30643
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.73487

Cumulative Model Updates: 145,072
Cumulative Timesteps: 1,210,645,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,918.23684
Policy Entropy: 1.72031
Value Function Loss: 0.04742

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.30663

Collected Steps per Second: 21,904.94937
Overall Steps per Second: 10,544.35979

Timestep Collection Time: 2.28359
Timestep Consumption Time: 2.46036
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.74396

Cumulative Model Updates: 145,078
Cumulative Timesteps: 1,210,695,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1210695482...
Checkpoint 1210695482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,397.43321
Policy Entropy: 1.71307
Value Function Loss: 0.04952

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.31660

Collected Steps per Second: 21,675.96923
Overall Steps per Second: 10,509.47147

Timestep Collection Time: 2.30707
Timestep Consumption Time: 2.45130
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.75837

Cumulative Model Updates: 145,084
Cumulative Timesteps: 1,210,745,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,188.28867
Policy Entropy: 1.71323
Value Function Loss: 0.04654

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.30881
Value Function Update Magnitude: 0.32277

Collected Steps per Second: 21,666.05706
Overall Steps per Second: 10,538.71921

Timestep Collection Time: 2.30831
Timestep Consumption Time: 2.43724
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.74555

Cumulative Model Updates: 145,090
Cumulative Timesteps: 1,210,795,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1210795502...
Checkpoint 1210795502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,480.25599
Policy Entropy: 1.70245
Value Function Loss: 0.04632

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.30910
Value Function Update Magnitude: 0.32355

Collected Steps per Second: 21,897.13791
Overall Steps per Second: 10,593.95354

Timestep Collection Time: 2.28432
Timestep Consumption Time: 2.43724
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.72156

Cumulative Model Updates: 145,096
Cumulative Timesteps: 1,210,845,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,436.07296
Policy Entropy: 1.69888
Value Function Loss: 0.04415

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.31942

Collected Steps per Second: 21,930.73099
Overall Steps per Second: 10,471.24100

Timestep Collection Time: 2.28146
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.77823

Cumulative Model Updates: 145,102
Cumulative Timesteps: 1,210,895,556

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1210895556...
Checkpoint 1210895556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,955.37610
Policy Entropy: 1.68168
Value Function Loss: 0.04831

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.31192
Value Function Update Magnitude: 0.32537

Collected Steps per Second: 21,881.42840
Overall Steps per Second: 10,587.72656

Timestep Collection Time: 2.28605
Timestep Consumption Time: 2.43848
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.72453

Cumulative Model Updates: 145,108
Cumulative Timesteps: 1,210,945,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,572.86088
Policy Entropy: 1.67516
Value Function Loss: 0.04747

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.31683
Value Function Update Magnitude: 0.33139

Collected Steps per Second: 21,764.53817
Overall Steps per Second: 10,595.61378

Timestep Collection Time: 2.29731
Timestep Consumption Time: 2.42162
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.71893

Cumulative Model Updates: 145,114
Cumulative Timesteps: 1,210,995,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1210995578...
Checkpoint 1210995578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,878.19852
Policy Entropy: 1.68637
Value Function Loss: 0.04366

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.30887
Value Function Update Magnitude: 0.31704

Collected Steps per Second: 20,772.09040
Overall Steps per Second: 10,518.66953

Timestep Collection Time: 2.40814
Timestep Consumption Time: 2.34741
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.75554

Cumulative Model Updates: 145,120
Cumulative Timesteps: 1,211,045,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,516.61493
Policy Entropy: 1.70392
Value Function Loss: 0.04142

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07237
Policy Update Magnitude: 0.30122
Value Function Update Magnitude: 0.30120

Collected Steps per Second: 21,054.85754
Overall Steps per Second: 10,581.63503

Timestep Collection Time: 2.37484
Timestep Consumption Time: 2.35051
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.72536

Cumulative Model Updates: 145,126
Cumulative Timesteps: 1,211,095,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1211095602...
Checkpoint 1211095602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,700.12316
Policy Entropy: 1.71316
Value Function Loss: 0.04480

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07046
Policy Update Magnitude: 0.30480
Value Function Update Magnitude: 0.28065

Collected Steps per Second: 21,321.32095
Overall Steps per Second: 10,605.17325

Timestep Collection Time: 2.34629
Timestep Consumption Time: 2.37084
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.71713

Cumulative Model Updates: 145,132
Cumulative Timesteps: 1,211,145,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,317.91325
Policy Entropy: 1.70457
Value Function Loss: 0.04421

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07500
Policy Update Magnitude: 0.30658
Value Function Update Magnitude: 0.29032

Collected Steps per Second: 21,436.79979
Overall Steps per Second: 10,471.45090

Timestep Collection Time: 2.33244
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.77489

Cumulative Model Updates: 145,138
Cumulative Timesteps: 1,211,195,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1211195628...
Checkpoint 1211195628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,224.00897
Policy Entropy: 1.68665
Value Function Loss: 0.04730

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07862
Policy Update Magnitude: 0.30785
Value Function Update Magnitude: 0.29355

Collected Steps per Second: 21,415.11923
Overall Steps per Second: 10,537.92069

Timestep Collection Time: 2.33536
Timestep Consumption Time: 2.41055
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.74591

Cumulative Model Updates: 145,144
Cumulative Timesteps: 1,211,245,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,034.22172
Policy Entropy: 1.68016
Value Function Loss: 0.04348

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.30458
Value Function Update Magnitude: 0.28563

Collected Steps per Second: 21,740.48266
Overall Steps per Second: 10,455.11983

Timestep Collection Time: 2.30216
Timestep Consumption Time: 2.48497
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.78713

Cumulative Model Updates: 145,150
Cumulative Timesteps: 1,211,295,690

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1211295690...
Checkpoint 1211295690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,452.01776
Policy Entropy: 1.67766
Value Function Loss: 0.04676

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.30719
Value Function Update Magnitude: 0.29842

Collected Steps per Second: 21,956.53773
Overall Steps per Second: 10,667.87326

Timestep Collection Time: 2.27859
Timestep Consumption Time: 2.41119
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.68978

Cumulative Model Updates: 145,156
Cumulative Timesteps: 1,211,345,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,722.19147
Policy Entropy: 1.69204
Value Function Loss: 0.04460

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.30766
Value Function Update Magnitude: 0.31489

Collected Steps per Second: 22,115.31312
Overall Steps per Second: 10,463.67026

Timestep Collection Time: 2.26223
Timestep Consumption Time: 2.51907
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.78131

Cumulative Model Updates: 145,162
Cumulative Timesteps: 1,211,395,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1211395750...
Checkpoint 1211395750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,809.74478
Policy Entropy: 1.69559
Value Function Loss: 0.05095

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.31121
Value Function Update Magnitude: 0.29620

Collected Steps per Second: 21,981.08771
Overall Steps per Second: 10,617.85937

Timestep Collection Time: 2.27614
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.71206

Cumulative Model Updates: 145,168
Cumulative Timesteps: 1,211,445,782

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,848.20380
Policy Entropy: 1.72111
Value Function Loss: 0.05064

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.31099
Value Function Update Magnitude: 0.23738

Collected Steps per Second: 21,583.26516
Overall Steps per Second: 10,553.84547

Timestep Collection Time: 2.31800
Timestep Consumption Time: 2.42245
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.74045

Cumulative Model Updates: 145,174
Cumulative Timesteps: 1,211,495,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1211495812...
Checkpoint 1211495812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,344.74776
Policy Entropy: 1.72394
Value Function Loss: 0.05539

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.31204
Value Function Update Magnitude: 0.20202

Collected Steps per Second: 21,461.18874
Overall Steps per Second: 10,506.39253

Timestep Collection Time: 2.33053
Timestep Consumption Time: 2.43000
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.76053

Cumulative Model Updates: 145,180
Cumulative Timesteps: 1,211,545,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,913.66969
Policy Entropy: 1.72339
Value Function Loss: 0.05163

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.30859
Value Function Update Magnitude: 0.18368

Collected Steps per Second: 21,563.88848
Overall Steps per Second: 10,496.26993

Timestep Collection Time: 2.31953
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.76531

Cumulative Model Updates: 145,186
Cumulative Timesteps: 1,211,595,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1211595846...
Checkpoint 1211595846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,920.34181
Policy Entropy: 1.71563
Value Function Loss: 0.04975

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.30360
Value Function Update Magnitude: 0.17291

Collected Steps per Second: 21,396.09613
Overall Steps per Second: 10,373.81147

Timestep Collection Time: 2.33762
Timestep Consumption Time: 2.48375
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.82137

Cumulative Model Updates: 145,192
Cumulative Timesteps: 1,211,645,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,453.18960
Policy Entropy: 1.71786
Value Function Loss: 0.04470

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.30079
Value Function Update Magnitude: 0.20203

Collected Steps per Second: 22,070.13331
Overall Steps per Second: 10,461.88135

Timestep Collection Time: 2.26587
Timestep Consumption Time: 2.51415
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.78002

Cumulative Model Updates: 145,198
Cumulative Timesteps: 1,211,695,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1211695870...
Checkpoint 1211695870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,496.68340
Policy Entropy: 1.71994
Value Function Loss: 0.04305

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.30276
Value Function Update Magnitude: 0.24854

Collected Steps per Second: 22,256.11596
Overall Steps per Second: 10,440.30946

Timestep Collection Time: 2.24702
Timestep Consumption Time: 2.54307
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.79009

Cumulative Model Updates: 145,204
Cumulative Timesteps: 1,211,745,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,091.21044
Policy Entropy: 1.72149
Value Function Loss: 0.04751

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07645
Policy Update Magnitude: 0.30919
Value Function Update Magnitude: 0.28516

Collected Steps per Second: 21,796.88768
Overall Steps per Second: 10,454.95049

Timestep Collection Time: 2.29427
Timestep Consumption Time: 2.48892
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.78319

Cumulative Model Updates: 145,210
Cumulative Timesteps: 1,211,795,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1211795888...
Checkpoint 1211795888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,209.66458
Policy Entropy: 1.70558
Value Function Loss: 0.04809

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.31061
Value Function Update Magnitude: 0.30917

Collected Steps per Second: 22,106.24571
Overall Steps per Second: 10,629.31465

Timestep Collection Time: 2.26189
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.70416

Cumulative Model Updates: 145,216
Cumulative Timesteps: 1,211,845,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,362.05236
Policy Entropy: 1.69996
Value Function Loss: 0.04696

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.30589
Value Function Update Magnitude: 0.30678

Collected Steps per Second: 21,829.58577
Overall Steps per Second: 10,453.49591

Timestep Collection Time: 2.29056
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.78328

Cumulative Model Updates: 145,222
Cumulative Timesteps: 1,211,895,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1211895892...
Checkpoint 1211895892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,578.58941
Policy Entropy: 1.70622
Value Function Loss: 0.04170

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.30092
Value Function Update Magnitude: 0.28917

Collected Steps per Second: 21,713.55086
Overall Steps per Second: 10,580.01308

Timestep Collection Time: 2.30483
Timestep Consumption Time: 2.42541
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.73024

Cumulative Model Updates: 145,228
Cumulative Timesteps: 1,211,945,938

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,436.85908
Policy Entropy: 1.70857
Value Function Loss: 0.04310

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.29728
Value Function Update Magnitude: 0.28843

Collected Steps per Second: 21,097.87361
Overall Steps per Second: 10,291.28711

Timestep Collection Time: 2.37190
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.86256

Cumulative Model Updates: 145,234
Cumulative Timesteps: 1,211,995,980

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1211995980...
Checkpoint 1211995980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,303.94970
Policy Entropy: 1.71339
Value Function Loss: 0.04213

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.29759
Value Function Update Magnitude: 0.29080

Collected Steps per Second: 21,808.37409
Overall Steps per Second: 10,437.13269

Timestep Collection Time: 2.29407
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.79346

Cumulative Model Updates: 145,240
Cumulative Timesteps: 1,212,046,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,524.71505
Policy Entropy: 1.71178
Value Function Loss: 0.04335

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07504
Policy Update Magnitude: 0.29593
Value Function Update Magnitude: 0.27248

Collected Steps per Second: 21,641.34961
Overall Steps per Second: 10,539.67406

Timestep Collection Time: 2.31067
Timestep Consumption Time: 2.43388
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.74455

Cumulative Model Updates: 145,246
Cumulative Timesteps: 1,212,096,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1212096016...
Checkpoint 1212096016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,029.12724
Policy Entropy: 1.72304
Value Function Loss: 0.04502

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.29582
Value Function Update Magnitude: 0.28942

Collected Steps per Second: 20,867.08644
Overall Steps per Second: 10,060.89222

Timestep Collection Time: 2.39669
Timestep Consumption Time: 2.57424
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.97093

Cumulative Model Updates: 145,252
Cumulative Timesteps: 1,212,146,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,180.70228
Policy Entropy: 1.71232
Value Function Loss: 0.04427

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.30073
Value Function Update Magnitude: 0.31765

Collected Steps per Second: 21,816.78220
Overall Steps per Second: 10,496.76020

Timestep Collection Time: 2.29310
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.76604

Cumulative Model Updates: 145,258
Cumulative Timesteps: 1,212,196,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1212196056...
Checkpoint 1212196056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,325.83433
Policy Entropy: 1.71681
Value Function Loss: 0.04361

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.30000
Value Function Update Magnitude: 0.32556

Collected Steps per Second: 21,837.67924
Overall Steps per Second: 10,578.78298

Timestep Collection Time: 2.29136
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.73003

Cumulative Model Updates: 145,264
Cumulative Timesteps: 1,212,246,094

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,488.48473
Policy Entropy: 1.69984
Value Function Loss: 0.04346

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.28357
Value Function Update Magnitude: 0.32496

Collected Steps per Second: 21,845.76301
Overall Steps per Second: 10,539.70705

Timestep Collection Time: 2.28960
Timestep Consumption Time: 2.45608
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.74567

Cumulative Model Updates: 145,270
Cumulative Timesteps: 1,212,296,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1212296112...
Checkpoint 1212296112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,757.08126
Policy Entropy: 1.70436
Value Function Loss: 0.04081

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.27918
Value Function Update Magnitude: 0.32027

Collected Steps per Second: 21,945.82257
Overall Steps per Second: 10,582.53489

Timestep Collection Time: 2.27934
Timestep Consumption Time: 2.44750
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.72684

Cumulative Model Updates: 145,276
Cumulative Timesteps: 1,212,346,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,410.64041
Policy Entropy: 1.68982
Value Function Loss: 0.04222

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.29233
Value Function Update Magnitude: 0.31974

Collected Steps per Second: 22,058.91724
Overall Steps per Second: 10,499.30360

Timestep Collection Time: 2.26756
Timestep Consumption Time: 2.49656
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.76413

Cumulative Model Updates: 145,282
Cumulative Timesteps: 1,212,396,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1212396154...
Checkpoint 1212396154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,724.35789
Policy Entropy: 1.71633
Value Function Loss: 0.04788

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.30609
Value Function Update Magnitude: 0.31494

Collected Steps per Second: 21,792.02470
Overall Steps per Second: 10,587.41747

Timestep Collection Time: 2.29469
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.72315

Cumulative Model Updates: 145,288
Cumulative Timesteps: 1,212,446,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,541.73540
Policy Entropy: 1.70760
Value Function Loss: 0.05202

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.31289
Value Function Update Magnitude: 0.28360

Collected Steps per Second: 21,668.80358
Overall Steps per Second: 10,533.93418

Timestep Collection Time: 2.30940
Timestep Consumption Time: 2.44115
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.75055

Cumulative Model Updates: 145,294
Cumulative Timesteps: 1,212,496,202

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1212496202...
Checkpoint 1212496202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,863.79592
Policy Entropy: 1.73191
Value Function Loss: 0.05075

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.30860
Value Function Update Magnitude: 0.27979

Collected Steps per Second: 21,292.47575
Overall Steps per Second: 10,287.59435

Timestep Collection Time: 2.34994
Timestep Consumption Time: 2.51378
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.86372

Cumulative Model Updates: 145,300
Cumulative Timesteps: 1,212,546,238

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,439.90966
Policy Entropy: 1.71072
Value Function Loss: 0.04854

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.30371
Value Function Update Magnitude: 0.30212

Collected Steps per Second: 21,529.86609
Overall Steps per Second: 10,387.35498

Timestep Collection Time: 2.32338
Timestep Consumption Time: 2.49229
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.81566

Cumulative Model Updates: 145,306
Cumulative Timesteps: 1,212,596,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1212596260...
Checkpoint 1212596260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,591.42777
Policy Entropy: 1.70398
Value Function Loss: 0.04536

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.30929
Value Function Update Magnitude: 0.31416

Collected Steps per Second: 21,583.95307
Overall Steps per Second: 10,549.89247

Timestep Collection Time: 2.31654
Timestep Consumption Time: 2.42285
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.73938

Cumulative Model Updates: 145,312
Cumulative Timesteps: 1,212,646,260

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,546.96394
Policy Entropy: 1.69015
Value Function Loss: 0.04774

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.31051
Value Function Update Magnitude: 0.34090

Collected Steps per Second: 22,161.93019
Overall Steps per Second: 10,508.02685

Timestep Collection Time: 2.25657
Timestep Consumption Time: 2.50265
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.75922

Cumulative Model Updates: 145,318
Cumulative Timesteps: 1,212,696,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1212696270...
Checkpoint 1212696270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,726.79939
Policy Entropy: 1.68737
Value Function Loss: 0.05258

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.31495
Value Function Update Magnitude: 0.35924

Collected Steps per Second: 21,829.31435
Overall Steps per Second: 10,551.59055

Timestep Collection Time: 2.29114
Timestep Consumption Time: 2.44881
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73995

Cumulative Model Updates: 145,324
Cumulative Timesteps: 1,212,746,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,152.84352
Policy Entropy: 1.69240
Value Function Loss: 0.05337

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.32321
Value Function Update Magnitude: 0.37121

Collected Steps per Second: 21,876.85877
Overall Steps per Second: 10,627.76911

Timestep Collection Time: 2.28561
Timestep Consumption Time: 2.41923
PPO Batch Consumption Time: 0.27561
Total Iteration Time: 4.70484

Cumulative Model Updates: 145,330
Cumulative Timesteps: 1,212,796,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1212796286...
Checkpoint 1212796286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,251.58400
Policy Entropy: 1.71872
Value Function Loss: 0.05189

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.32575
Value Function Update Magnitude: 0.37735

Collected Steps per Second: 21,766.30999
Overall Steps per Second: 10,589.83806

Timestep Collection Time: 2.29832
Timestep Consumption Time: 2.42564
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.72396

Cumulative Model Updates: 145,336
Cumulative Timesteps: 1,212,846,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,414.51068
Policy Entropy: 1.72590
Value Function Loss: 0.04976

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.31401
Value Function Update Magnitude: 0.35819

Collected Steps per Second: 22,045.87442
Overall Steps per Second: 10,429.52545

Timestep Collection Time: 2.26918
Timestep Consumption Time: 2.52740
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.79657

Cumulative Model Updates: 145,342
Cumulative Timesteps: 1,212,896,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1212896338...
Checkpoint 1212896338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,672.56731
Policy Entropy: 1.72312
Value Function Loss: 0.04946

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.31026
Value Function Update Magnitude: 0.30718

Collected Steps per Second: 21,886.63053
Overall Steps per Second: 10,589.71544

Timestep Collection Time: 2.28569
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.72402

Cumulative Model Updates: 145,348
Cumulative Timesteps: 1,212,946,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,469.36008
Policy Entropy: 1.71478
Value Function Loss: 0.05168

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.31529
Value Function Update Magnitude: 0.28558

Collected Steps per Second: 22,003.47230
Overall Steps per Second: 10,526.52496

Timestep Collection Time: 2.27273
Timestep Consumption Time: 2.47793
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.75067

Cumulative Model Updates: 145,354
Cumulative Timesteps: 1,212,996,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1212996372...
Checkpoint 1212996372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,625.49315
Policy Entropy: 1.73181
Value Function Loss: 0.05134

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.31995
Value Function Update Magnitude: 0.26906

Collected Steps per Second: 21,277.98957
Overall Steps per Second: 10,331.05731

Timestep Collection Time: 2.35079
Timestep Consumption Time: 2.49093
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.84171

Cumulative Model Updates: 145,360
Cumulative Timesteps: 1,213,046,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,395.22244
Policy Entropy: 1.73116
Value Function Loss: 0.05551

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.32012
Value Function Update Magnitude: 0.28950

Collected Steps per Second: 21,889.69931
Overall Steps per Second: 10,465.26666

Timestep Collection Time: 2.28610
Timestep Consumption Time: 2.49562
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.78172

Cumulative Model Updates: 145,366
Cumulative Timesteps: 1,213,096,434

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1213096434...
Checkpoint 1213096434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,912.03404
Policy Entropy: 1.72028
Value Function Loss: 0.05175

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.31859
Value Function Update Magnitude: 0.31200

Collected Steps per Second: 20,999.16896
Overall Steps per Second: 10,553.60110

Timestep Collection Time: 2.38171
Timestep Consumption Time: 2.35733
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.73905

Cumulative Model Updates: 145,372
Cumulative Timesteps: 1,213,146,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,099.10738
Policy Entropy: 1.71637
Value Function Loss: 0.04892

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.31026
Value Function Update Magnitude: 0.33607

Collected Steps per Second: 21,702.28331
Overall Steps per Second: 10,553.21931

Timestep Collection Time: 2.30547
Timestep Consumption Time: 2.43564
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.74111

Cumulative Model Updates: 145,378
Cumulative Timesteps: 1,213,196,482

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1213196482...
Checkpoint 1213196482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,555.84916
Policy Entropy: 1.73363
Value Function Loss: 0.04563

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.31650

Collected Steps per Second: 21,392.81213
Overall Steps per Second: 10,485.27737

Timestep Collection Time: 2.33751
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.76916

Cumulative Model Updates: 145,384
Cumulative Timesteps: 1,213,246,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,159.81002
Policy Entropy: 1.73087
Value Function Loss: 0.04952

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.30941
Value Function Update Magnitude: 0.31955

Collected Steps per Second: 21,715.82360
Overall Steps per Second: 10,535.84912

Timestep Collection Time: 2.30321
Timestep Consumption Time: 2.44402
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.74722

Cumulative Model Updates: 145,390
Cumulative Timesteps: 1,213,296,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1213296504...
Checkpoint 1213296504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,907.70657
Policy Entropy: 1.70901
Value Function Loss: 0.05111

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.31275
Value Function Update Magnitude: 0.33013

Collected Steps per Second: 21,295.00341
Overall Steps per Second: 10,526.13060

Timestep Collection Time: 2.34881
Timestep Consumption Time: 2.40298
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.75179

Cumulative Model Updates: 145,396
Cumulative Timesteps: 1,213,346,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,666.77851
Policy Entropy: 1.69557
Value Function Loss: 0.05443

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.32169
Value Function Update Magnitude: 0.34250

Collected Steps per Second: 21,609.56663
Overall Steps per Second: 10,460.09375

Timestep Collection Time: 2.31444
Timestep Consumption Time: 2.46697
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.78141

Cumulative Model Updates: 145,402
Cumulative Timesteps: 1,213,396,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1213396536...
Checkpoint 1213396536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,058.05991
Policy Entropy: 1.73324
Value Function Loss: 0.05355

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.32391
Value Function Update Magnitude: 0.34035

Collected Steps per Second: 21,921.15022
Overall Steps per Second: 10,689.37675

Timestep Collection Time: 2.28163
Timestep Consumption Time: 2.39741
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.67904

Cumulative Model Updates: 145,408
Cumulative Timesteps: 1,213,446,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,184.37005
Policy Entropy: 1.73268
Value Function Loss: 0.05180

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.31834
Value Function Update Magnitude: 0.36114

Collected Steps per Second: 21,912.16619
Overall Steps per Second: 10,483.60672

Timestep Collection Time: 2.28248
Timestep Consumption Time: 2.48821
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.77069

Cumulative Model Updates: 145,414
Cumulative Timesteps: 1,213,496,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1213496566...
Checkpoint 1213496566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,742.39677
Policy Entropy: 1.72893
Value Function Loss: 0.05456

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.31902
Value Function Update Magnitude: 0.38337

Collected Steps per Second: 21,674.59468
Overall Steps per Second: 10,633.49045

Timestep Collection Time: 2.30796
Timestep Consumption Time: 2.39643
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.70438

Cumulative Model Updates: 145,420
Cumulative Timesteps: 1,213,546,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,861.33612
Policy Entropy: 1.71647
Value Function Loss: 0.05078

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.31968
Value Function Update Magnitude: 0.39637

Collected Steps per Second: 21,977.46497
Overall Steps per Second: 10,445.20898

Timestep Collection Time: 2.27670
Timestep Consumption Time: 2.51363
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.79033

Cumulative Model Updates: 145,426
Cumulative Timesteps: 1,213,596,626

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1213596626...
Checkpoint 1213596626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,976.31924
Policy Entropy: 1.72021
Value Function Loss: 0.05138

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.31796
Value Function Update Magnitude: 0.37266

Collected Steps per Second: 20,337.55712
Overall Steps per Second: 10,161.23144

Timestep Collection Time: 2.46096
Timestep Consumption Time: 2.46462
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.92558

Cumulative Model Updates: 145,432
Cumulative Timesteps: 1,213,646,676

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,329.11594
Policy Entropy: 1.71847
Value Function Loss: 0.04813

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.31790
Value Function Update Magnitude: 0.35761

Collected Steps per Second: 22,137.74872
Overall Steps per Second: 10,442.15417

Timestep Collection Time: 2.25967
Timestep Consumption Time: 2.53091
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.79058

Cumulative Model Updates: 145,438
Cumulative Timesteps: 1,213,696,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1213696700...
Checkpoint 1213696700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,987.25409
Policy Entropy: 1.69216
Value Function Loss: 0.04725

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.31231
Value Function Update Magnitude: 0.36660

Collected Steps per Second: 21,874.07874
Overall Steps per Second: 10,575.52385

Timestep Collection Time: 2.28764
Timestep Consumption Time: 2.44404
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.73168

Cumulative Model Updates: 145,444
Cumulative Timesteps: 1,213,746,740

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,960.50582
Policy Entropy: 1.69335
Value Function Loss: 0.04967

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.31753
Value Function Update Magnitude: 0.37393

Collected Steps per Second: 22,103.30906
Overall Steps per Second: 10,510.63208

Timestep Collection Time: 2.26229
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.75747

Cumulative Model Updates: 145,450
Cumulative Timesteps: 1,213,796,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1213796744...
Checkpoint 1213796744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,571.40890
Policy Entropy: 1.68817
Value Function Loss: 0.04913

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.31739
Value Function Update Magnitude: 0.36240

Collected Steps per Second: 21,672.11920
Overall Steps per Second: 10,561.39358

Timestep Collection Time: 2.30896
Timestep Consumption Time: 2.42905
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.73801

Cumulative Model Updates: 145,456
Cumulative Timesteps: 1,213,846,784

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,347.55112
Policy Entropy: 1.70129
Value Function Loss: 0.05206

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.31702
Value Function Update Magnitude: 0.34502

Collected Steps per Second: 22,019.95598
Overall Steps per Second: 10,611.79654

Timestep Collection Time: 2.27076
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.71193

Cumulative Model Updates: 145,462
Cumulative Timesteps: 1,213,896,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1213896786...
Checkpoint 1213896786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,051.29542
Policy Entropy: 1.69680
Value Function Loss: 0.04671

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.31231
Value Function Update Magnitude: 0.33950

Collected Steps per Second: 21,982.24849
Overall Steps per Second: 10,619.35853

Timestep Collection Time: 2.27502
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.70932

Cumulative Model Updates: 145,468
Cumulative Timesteps: 1,213,946,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,748.11852
Policy Entropy: 1.70233
Value Function Loss: 0.04776

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.30943
Value Function Update Magnitude: 0.34346

Collected Steps per Second: 22,154.77117
Overall Steps per Second: 10,486.53902

Timestep Collection Time: 2.25793
Timestep Consumption Time: 2.51237
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.77031

Cumulative Model Updates: 145,474
Cumulative Timesteps: 1,213,996,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1213996820...
Checkpoint 1213996820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,224.46115
Policy Entropy: 1.70733
Value Function Loss: 0.04607

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.31176
Value Function Update Magnitude: 0.34429

Collected Steps per Second: 21,694.68734
Overall Steps per Second: 10,550.88838

Timestep Collection Time: 2.30480
Timestep Consumption Time: 2.43432
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.73913

Cumulative Model Updates: 145,480
Cumulative Timesteps: 1,214,046,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,282.89438
Policy Entropy: 1.70592
Value Function Loss: 0.04658

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.30904
Value Function Update Magnitude: 0.35510

Collected Steps per Second: 21,555.80068
Overall Steps per Second: 10,443.62359

Timestep Collection Time: 2.32142
Timestep Consumption Time: 2.47002
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.79144

Cumulative Model Updates: 145,486
Cumulative Timesteps: 1,214,096,862

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1214096862...
Checkpoint 1214096862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,071.65972
Policy Entropy: 1.70863
Value Function Loss: 0.04654

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.31434
Value Function Update Magnitude: 0.37143

Collected Steps per Second: 21,101.98446
Overall Steps per Second: 10,216.46224

Timestep Collection Time: 2.37030
Timestep Consumption Time: 2.52553
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.89582

Cumulative Model Updates: 145,492
Cumulative Timesteps: 1,214,146,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,671.18678
Policy Entropy: 1.69988
Value Function Loss: 0.04700

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.31578
Value Function Update Magnitude: 0.34908

Collected Steps per Second: 21,677.31764
Overall Steps per Second: 10,457.54704

Timestep Collection Time: 2.30887
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.78602

Cumulative Model Updates: 145,498
Cumulative Timesteps: 1,214,196,930

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1214196930...
Checkpoint 1214196930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,869.31522
Policy Entropy: 1.69572
Value Function Loss: 0.04472

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.31272
Value Function Update Magnitude: 0.31358

Collected Steps per Second: 21,660.25898
Overall Steps per Second: 10,384.85718

Timestep Collection Time: 2.30921
Timestep Consumption Time: 2.50723
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.81644

Cumulative Model Updates: 145,504
Cumulative Timesteps: 1,214,246,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,845.49911
Policy Entropy: 1.70631
Value Function Loss: 0.04479

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07763
Policy Update Magnitude: 0.30643
Value Function Update Magnitude: 0.28088

Collected Steps per Second: 22,097.71193
Overall Steps per Second: 10,622.58819

Timestep Collection Time: 2.26268
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.70695

Cumulative Model Updates: 145,510
Cumulative Timesteps: 1,214,296,948

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1214296948...
Checkpoint 1214296948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,735.61120
Policy Entropy: 1.70997
Value Function Loss: 0.04453

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.30582
Value Function Update Magnitude: 0.28709

Collected Steps per Second: 21,934.26561
Overall Steps per Second: 10,610.25851

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.43376
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.71412

Cumulative Model Updates: 145,516
Cumulative Timesteps: 1,214,346,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,524.98094
Policy Entropy: 1.71647
Value Function Loss: 0.04555

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.30486
Value Function Update Magnitude: 0.31004

Collected Steps per Second: 21,903.19208
Overall Steps per Second: 10,590.70427

Timestep Collection Time: 2.28451
Timestep Consumption Time: 2.44020
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.72471

Cumulative Model Updates: 145,522
Cumulative Timesteps: 1,214,397,004

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1214397004...
Checkpoint 1214397004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,450.61998
Policy Entropy: 1.72448
Value Function Loss: 0.05162

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08115
Policy Update Magnitude: 0.30984
Value Function Update Magnitude: 0.33164

Collected Steps per Second: 21,665.37965
Overall Steps per Second: 10,552.42123

Timestep Collection Time: 2.30857
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.73977

Cumulative Model Updates: 145,528
Cumulative Timesteps: 1,214,447,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,018.07425
Policy Entropy: 1.73685
Value Function Loss: 0.05355

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.31484
Value Function Update Magnitude: 0.35987

Collected Steps per Second: 22,017.07578
Overall Steps per Second: 10,484.27455

Timestep Collection Time: 2.27187
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.77095

Cumulative Model Updates: 145,534
Cumulative Timesteps: 1,214,497,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1214497040...
Checkpoint 1214497040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,017.30674
Policy Entropy: 1.73166
Value Function Loss: 0.05323

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.31286
Value Function Update Magnitude: 0.37070

Collected Steps per Second: 21,859.79518
Overall Steps per Second: 10,585.40843

Timestep Collection Time: 2.28776
Timestep Consumption Time: 2.43667
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.72443

Cumulative Model Updates: 145,540
Cumulative Timesteps: 1,214,547,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,318.15651
Policy Entropy: 1.72226
Value Function Loss: 0.04881

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.30249
Value Function Update Magnitude: 0.37530

Collected Steps per Second: 21,930.08038
Overall Steps per Second: 10,629.93583

Timestep Collection Time: 2.28025
Timestep Consumption Time: 2.42401
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.70426

Cumulative Model Updates: 145,546
Cumulative Timesteps: 1,214,597,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1214597056...
Checkpoint 1214597056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,503.51223
Policy Entropy: 1.71580
Value Function Loss: 0.04657

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.30578
Value Function Update Magnitude: 0.36395

Collected Steps per Second: 21,656.38961
Overall Steps per Second: 10,542.09979

Timestep Collection Time: 2.31036
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.74611

Cumulative Model Updates: 145,552
Cumulative Timesteps: 1,214,647,090

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,427.97684
Policy Entropy: 1.70912
Value Function Loss: 0.04645

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.31219
Value Function Update Magnitude: 0.35619

Collected Steps per Second: 21,794.86710
Overall Steps per Second: 10,455.18847

Timestep Collection Time: 2.29605
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.78633

Cumulative Model Updates: 145,558
Cumulative Timesteps: 1,214,697,132

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1214697132...
Checkpoint 1214697132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,607.99369
Policy Entropy: 1.70877
Value Function Loss: 0.04713

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.31314
Value Function Update Magnitude: 0.35745

Collected Steps per Second: 21,649.94219
Overall Steps per Second: 10,541.19904

Timestep Collection Time: 2.31031
Timestep Consumption Time: 2.43469
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.74500

Cumulative Model Updates: 145,564
Cumulative Timesteps: 1,214,747,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,309.32087
Policy Entropy: 1.71444
Value Function Loss: 0.04832

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.31573
Value Function Update Magnitude: 0.36673

Collected Steps per Second: 21,682.82997
Overall Steps per Second: 10,501.90733

Timestep Collection Time: 2.30726
Timestep Consumption Time: 2.45644
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.76371

Cumulative Model Updates: 145,570
Cumulative Timesteps: 1,214,797,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1214797178...
Checkpoint 1214797178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,617.41347
Policy Entropy: 1.71935
Value Function Loss: 0.05049

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.31713
Value Function Update Magnitude: 0.36071

Collected Steps per Second: 21,952.79359
Overall Steps per Second: 10,629.51982

Timestep Collection Time: 2.27853
Timestep Consumption Time: 2.42724
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.70576

Cumulative Model Updates: 145,576
Cumulative Timesteps: 1,214,847,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,740.07520
Policy Entropy: 1.72098
Value Function Loss: 0.04799

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.31311
Value Function Update Magnitude: 0.35777

Collected Steps per Second: 22,110.66657
Overall Steps per Second: 10,428.82644

Timestep Collection Time: 2.26253
Timestep Consumption Time: 2.53437
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.79690

Cumulative Model Updates: 145,582
Cumulative Timesteps: 1,214,897,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1214897224...
Checkpoint 1214897224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,510.80450
Policy Entropy: 1.70899
Value Function Loss: 0.04680

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.30453
Value Function Update Magnitude: 0.35748

Collected Steps per Second: 21,410.63138
Overall Steps per Second: 10,651.45024

Timestep Collection Time: 2.33576
Timestep Consumption Time: 2.35938
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.69514

Cumulative Model Updates: 145,588
Cumulative Timesteps: 1,214,947,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,739.38862
Policy Entropy: 1.69622
Value Function Loss: 0.04486

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.31073
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 21,426.04243
Overall Steps per Second: 10,509.00934

Timestep Collection Time: 2.33436
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.75934

Cumulative Model Updates: 145,594
Cumulative Timesteps: 1,214,997,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1214997250...
Checkpoint 1214997250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,968.68106
Policy Entropy: 1.69440
Value Function Loss: 0.05070

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.31880
Value Function Update Magnitude: 0.31809

Collected Steps per Second: 21,349.14253
Overall Steps per Second: 10,678.01921

Timestep Collection Time: 2.34267
Timestep Consumption Time: 2.34116
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.68383

Cumulative Model Updates: 145,600
Cumulative Timesteps: 1,215,047,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,799.59344
Policy Entropy: 1.70591
Value Function Loss: 0.04927

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.31780
Value Function Update Magnitude: 0.28723

Collected Steps per Second: 20,988.61584
Overall Steps per Second: 10,387.08612

Timestep Collection Time: 2.38320
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.81560

Cumulative Model Updates: 145,606
Cumulative Timesteps: 1,215,097,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1215097284...
Checkpoint 1215097284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,639.48801
Policy Entropy: 1.70973
Value Function Loss: 0.04769

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.30671
Value Function Update Magnitude: 0.29627

Collected Steps per Second: 20,992.25825
Overall Steps per Second: 10,581.86973

Timestep Collection Time: 2.38202
Timestep Consumption Time: 2.34342
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.72544

Cumulative Model Updates: 145,612
Cumulative Timesteps: 1,215,147,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,037.08182
Policy Entropy: 1.70297
Value Function Loss: 0.04513

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.30506
Value Function Update Magnitude: 0.27691

Collected Steps per Second: 21,098.41732
Overall Steps per Second: 10,476.28727

Timestep Collection Time: 2.37146
Timestep Consumption Time: 2.40447
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.77593

Cumulative Model Updates: 145,618
Cumulative Timesteps: 1,215,197,322

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1215197322...
Checkpoint 1215197322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,417.75788
Policy Entropy: 1.69480
Value Function Loss: 0.04513

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.30548
Value Function Update Magnitude: 0.26521

Collected Steps per Second: 21,330.06764
Overall Steps per Second: 10,332.81154

Timestep Collection Time: 2.34552
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.84186

Cumulative Model Updates: 145,624
Cumulative Timesteps: 1,215,247,352

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,307.22044
Policy Entropy: 1.71828
Value Function Loss: 0.04374

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07705
Policy Update Magnitude: 0.30537
Value Function Update Magnitude: 0.28064

Collected Steps per Second: 22,044.25997
Overall Steps per Second: 10,476.12482

Timestep Collection Time: 2.27007
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.77677

Cumulative Model Updates: 145,630
Cumulative Timesteps: 1,215,297,394

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1215297394...
Checkpoint 1215297394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,192.31892
Policy Entropy: 1.70923
Value Function Loss: 0.04538

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.30745
Value Function Update Magnitude: 0.30412

Collected Steps per Second: 22,175.08246
Overall Steps per Second: 10,509.78507

Timestep Collection Time: 2.25632
Timestep Consumption Time: 2.50439
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.76071

Cumulative Model Updates: 145,636
Cumulative Timesteps: 1,215,347,428

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,641.75214
Policy Entropy: 1.72512
Value Function Loss: 0.04467

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.30507
Value Function Update Magnitude: 0.31552

Collected Steps per Second: 21,951.30748
Overall Steps per Second: 10,531.60413

Timestep Collection Time: 2.27904
Timestep Consumption Time: 2.47123
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.75027

Cumulative Model Updates: 145,642
Cumulative Timesteps: 1,215,397,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1215397456...
Checkpoint 1215397456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,400.04262
Policy Entropy: 1.71763
Value Function Loss: 0.04843

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.29081
Value Function Update Magnitude: 0.31723

Collected Steps per Second: 21,801.37821
Overall Steps per Second: 10,548.10658

Timestep Collection Time: 2.29444
Timestep Consumption Time: 2.44783
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.74227

Cumulative Model Updates: 145,648
Cumulative Timesteps: 1,215,447,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,373.56964
Policy Entropy: 1.73833
Value Function Loss: 0.04471

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.27297
Value Function Update Magnitude: 0.31517

Collected Steps per Second: 21,983.45151
Overall Steps per Second: 10,501.70826

Timestep Collection Time: 2.27571
Timestep Consumption Time: 2.48808
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.76380

Cumulative Model Updates: 145,654
Cumulative Timesteps: 1,215,497,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1215497506...
Checkpoint 1215497506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,337.39884
Policy Entropy: 1.72087
Value Function Loss: 0.04502

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.27851
Value Function Update Magnitude: 0.29534

Collected Steps per Second: 20,762.66036
Overall Steps per Second: 10,218.31462

Timestep Collection Time: 2.40875
Timestep Consumption Time: 2.48560
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.89435

Cumulative Model Updates: 145,660
Cumulative Timesteps: 1,215,547,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,400.81177
Policy Entropy: 1.70747
Value Function Loss: 0.04582

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.29068
Value Function Update Magnitude: 0.27963

Collected Steps per Second: 21,454.13535
Overall Steps per Second: 10,487.10590

Timestep Collection Time: 2.33130
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.76929

Cumulative Model Updates: 145,666
Cumulative Timesteps: 1,215,597,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1215597534...
Checkpoint 1215597534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,037.66482
Policy Entropy: 1.70642
Value Function Loss: 0.04908

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.30791
Value Function Update Magnitude: 0.30230

Collected Steps per Second: 21,527.05647
Overall Steps per Second: 10,370.14556

Timestep Collection Time: 2.32312
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.82250

Cumulative Model Updates: 145,672
Cumulative Timesteps: 1,215,647,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,875.55426
Policy Entropy: 1.72793
Value Function Loss: 0.05510

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.32113
Value Function Update Magnitude: 0.33407

Collected Steps per Second: 21,872.07234
Overall Steps per Second: 10,419.97122

Timestep Collection Time: 2.28639
Timestep Consumption Time: 2.51286
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.79925

Cumulative Model Updates: 145,678
Cumulative Timesteps: 1,215,697,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1215697552...
Checkpoint 1215697552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,625.58953
Policy Entropy: 1.72495
Value Function Loss: 0.05267

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.32541
Value Function Update Magnitude: 0.37290

Collected Steps per Second: 22,008.95472
Overall Steps per Second: 10,557.82046

Timestep Collection Time: 2.27335
Timestep Consumption Time: 2.46570
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.73905

Cumulative Model Updates: 145,684
Cumulative Timesteps: 1,215,747,586

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,129.57178
Policy Entropy: 1.71547
Value Function Loss: 0.05211

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.32227
Value Function Update Magnitude: 0.40190

Collected Steps per Second: 22,120.47294
Overall Steps per Second: 10,449.70177

Timestep Collection Time: 2.26098
Timestep Consumption Time: 2.52518
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.78617

Cumulative Model Updates: 145,690
Cumulative Timesteps: 1,215,797,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1215797600...
Checkpoint 1215797600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,890.91719
Policy Entropy: 1.70293
Value Function Loss: 0.04720

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.31584
Value Function Update Magnitude: 0.38599

Collected Steps per Second: 22,135.16317
Overall Steps per Second: 10,579.94247

Timestep Collection Time: 2.26002
Timestep Consumption Time: 2.46836
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.72838

Cumulative Model Updates: 145,696
Cumulative Timesteps: 1,215,847,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,763.67344
Policy Entropy: 1.71381
Value Function Loss: 0.04543

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.31163
Value Function Update Magnitude: 0.35542

Collected Steps per Second: 21,607.43110
Overall Steps per Second: 10,423.15169

Timestep Collection Time: 2.31430
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.79759

Cumulative Model Updates: 145,702
Cumulative Timesteps: 1,215,897,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1215897632...
Checkpoint 1215897632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,964.49293
Policy Entropy: 1.71742
Value Function Loss: 0.04520

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.31219
Value Function Update Magnitude: 0.35026

Collected Steps per Second: 21,814.97905
Overall Steps per Second: 10,577.04110

Timestep Collection Time: 2.29347
Timestep Consumption Time: 2.43678
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.73025

Cumulative Model Updates: 145,708
Cumulative Timesteps: 1,215,947,664

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,752.49502
Policy Entropy: 1.72716
Value Function Loss: 0.05023

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.31600
Value Function Update Magnitude: 0.33095

Collected Steps per Second: 22,096.51220
Overall Steps per Second: 10,533.30635

Timestep Collection Time: 2.26316
Timestep Consumption Time: 2.48444
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.74761

Cumulative Model Updates: 145,714
Cumulative Timesteps: 1,215,997,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1215997672...
Checkpoint 1215997672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,355.47824
Policy Entropy: 1.72343
Value Function Loss: 0.05278

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.31262
Value Function Update Magnitude: 0.36180

Collected Steps per Second: 21,412.94724
Overall Steps per Second: 10,329.12766

Timestep Collection Time: 2.33662
Timestep Consumption Time: 2.50735
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.84397

Cumulative Model Updates: 145,720
Cumulative Timesteps: 1,216,047,706

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,160.41624
Policy Entropy: 1.73910
Value Function Loss: 0.05185

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.31162
Value Function Update Magnitude: 0.33319

Collected Steps per Second: 21,551.41391
Overall Steps per Second: 10,338.97985

Timestep Collection Time: 2.32031
Timestep Consumption Time: 2.51634
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.83665

Cumulative Model Updates: 145,726
Cumulative Timesteps: 1,216,097,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1216097712...
Checkpoint 1216097712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,926.18440
Policy Entropy: 1.72823
Value Function Loss: 0.05341

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.30746
Value Function Update Magnitude: 0.30015

Collected Steps per Second: 21,811.07257
Overall Steps per Second: 10,579.18119

Timestep Collection Time: 2.29315
Timestep Consumption Time: 2.43463
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.72778

Cumulative Model Updates: 145,732
Cumulative Timesteps: 1,216,147,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,928.99061
Policy Entropy: 1.72922
Value Function Loss: 0.05134

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.30116
Value Function Update Magnitude: 0.34263

Collected Steps per Second: 21,457.22577
Overall Steps per Second: 10,498.55372

Timestep Collection Time: 2.33171
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.76561

Cumulative Model Updates: 145,738
Cumulative Timesteps: 1,216,197,760

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1216197760...
Checkpoint 1216197760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,568.47313
Policy Entropy: 1.71943
Value Function Loss: 0.04898

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.29432
Value Function Update Magnitude: 0.36875

Collected Steps per Second: 21,565.57990
Overall Steps per Second: 10,361.98437

Timestep Collection Time: 2.32009
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.82861

Cumulative Model Updates: 145,744
Cumulative Timesteps: 1,216,247,794

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,478.80148
Policy Entropy: 1.70624
Value Function Loss: 0.04816

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.29962
Value Function Update Magnitude: 0.35131

Collected Steps per Second: 22,205.42442
Overall Steps per Second: 10,661.58681

Timestep Collection Time: 2.25188
Timestep Consumption Time: 2.43823
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.69011

Cumulative Model Updates: 145,750
Cumulative Timesteps: 1,216,297,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1216297798...
Checkpoint 1216297798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,336.60144
Policy Entropy: 1.71689
Value Function Loss: 0.05122

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.31465
Value Function Update Magnitude: 0.35042

Collected Steps per Second: 21,599.85171
Overall Steps per Second: 10,376.11497

Timestep Collection Time: 2.31492
Timestep Consumption Time: 2.50403
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.81895

Cumulative Model Updates: 145,756
Cumulative Timesteps: 1,216,347,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,264.99043
Policy Entropy: 1.72129
Value Function Loss: 0.05177

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.32705
Value Function Update Magnitude: 0.35608

Collected Steps per Second: 22,276.56104
Overall Steps per Second: 10,721.67422

Timestep Collection Time: 2.24550
Timestep Consumption Time: 2.42000
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.66550

Cumulative Model Updates: 145,762
Cumulative Timesteps: 1,216,397,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1216397822...
Checkpoint 1216397822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,605.98826
Policy Entropy: 1.74303
Value Function Loss: 0.05226

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.32270
Value Function Update Magnitude: 0.35172

Collected Steps per Second: 21,418.94286
Overall Steps per Second: 10,679.15834

Timestep Collection Time: 2.33494
Timestep Consumption Time: 2.34820
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.68314

Cumulative Model Updates: 145,768
Cumulative Timesteps: 1,216,447,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,471.69710
Policy Entropy: 1.74422
Value Function Loss: 0.04855

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.36039

Collected Steps per Second: 21,346.42100
Overall Steps per Second: 10,484.98911

Timestep Collection Time: 2.34391
Timestep Consumption Time: 2.42806
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.77196

Cumulative Model Updates: 145,774
Cumulative Timesteps: 1,216,497,868

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1216497868...
Checkpoint 1216497868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,930.71856
Policy Entropy: 1.73880
Value Function Loss: 0.04555

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.30296
Value Function Update Magnitude: 0.34555

Collected Steps per Second: 21,197.63772
Overall Steps per Second: 10,605.93201

Timestep Collection Time: 2.36045
Timestep Consumption Time: 2.35729
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.71774

Cumulative Model Updates: 145,780
Cumulative Timesteps: 1,216,547,904

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,355.21417
Policy Entropy: 1.72179
Value Function Loss: 0.04376

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.30409
Value Function Update Magnitude: 0.31374

Collected Steps per Second: 20,950.80323
Overall Steps per Second: 10,550.94082

Timestep Collection Time: 2.38740
Timestep Consumption Time: 2.35322
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.74062

Cumulative Model Updates: 145,786
Cumulative Timesteps: 1,216,597,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1216597922...
Checkpoint 1216597922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,770.02338
Policy Entropy: 1.71946
Value Function Loss: 0.04750

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.31602
Value Function Update Magnitude: 0.33613

Collected Steps per Second: 20,677.06926
Overall Steps per Second: 10,187.22596

Timestep Collection Time: 2.41978
Timestep Consumption Time: 2.49166
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.91145

Cumulative Model Updates: 145,792
Cumulative Timesteps: 1,216,647,956

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,815.20919
Policy Entropy: 1.71260
Value Function Loss: 0.04551

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.31775
Value Function Update Magnitude: 0.36309

Collected Steps per Second: 21,658.55586
Overall Steps per Second: 10,420.46755

Timestep Collection Time: 2.30920
Timestep Consumption Time: 2.49039
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.79959

Cumulative Model Updates: 145,798
Cumulative Timesteps: 1,216,697,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1216697970...
Checkpoint 1216697970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,854.57260
Policy Entropy: 1.73379
Value Function Loss: 0.04613

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.31802
Value Function Update Magnitude: 0.35472

Collected Steps per Second: 21,474.02454
Overall Steps per Second: 10,566.70303

Timestep Collection Time: 2.32951
Timestep Consumption Time: 2.40460
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.73412

Cumulative Model Updates: 145,804
Cumulative Timesteps: 1,216,747,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,032.12025
Policy Entropy: 1.72589
Value Function Loss: 0.04473

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.31484
Value Function Update Magnitude: 0.33405

Collected Steps per Second: 22,126.55665
Overall Steps per Second: 10,531.04765

Timestep Collection Time: 2.26154
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.75166

Cumulative Model Updates: 145,810
Cumulative Timesteps: 1,216,798,034

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1216798034...
Checkpoint 1216798034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,707.44969
Policy Entropy: 1.72112
Value Function Loss: 0.04519

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.31347
Value Function Update Magnitude: 0.33177

Collected Steps per Second: 21,933.03249
Overall Steps per Second: 10,586.25049

Timestep Collection Time: 2.28122
Timestep Consumption Time: 2.44510
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.72632

Cumulative Model Updates: 145,816
Cumulative Timesteps: 1,216,848,068

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,521.99353
Policy Entropy: 1.70970
Value Function Loss: 0.04864

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.33681

Collected Steps per Second: 22,079.54534
Overall Steps per Second: 10,526.89930

Timestep Collection Time: 2.26545
Timestep Consumption Time: 2.48619
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.75164

Cumulative Model Updates: 145,822
Cumulative Timesteps: 1,216,898,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1216898088...
Checkpoint 1216898088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,567.85481
Policy Entropy: 1.71391
Value Function Loss: 0.05167

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.31882
Value Function Update Magnitude: 0.33395

Collected Steps per Second: 21,772.86512
Overall Steps per Second: 10,569.72822

Timestep Collection Time: 2.29644
Timestep Consumption Time: 2.43405
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.73049

Cumulative Model Updates: 145,828
Cumulative Timesteps: 1,216,948,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,300.85706
Policy Entropy: 1.72316
Value Function Loss: 0.05198

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.31556
Value Function Update Magnitude: 0.33734

Collected Steps per Second: 22,216.66633
Overall Steps per Second: 10,483.02519

Timestep Collection Time: 2.25146
Timestep Consumption Time: 2.52006
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.77152

Cumulative Model Updates: 145,834
Cumulative Timesteps: 1,216,998,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1216998108...
Checkpoint 1216998108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,776.81109
Policy Entropy: 1.71569
Value Function Loss: 0.04890

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.31168
Value Function Update Magnitude: 0.32304

Collected Steps per Second: 22,019.22027
Overall Steps per Second: 10,625.74558

Timestep Collection Time: 2.27093
Timestep Consumption Time: 2.43500
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.70593

Cumulative Model Updates: 145,840
Cumulative Timesteps: 1,217,048,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,939.92575
Policy Entropy: 1.70245
Value Function Loss: 0.04826

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.31029
Value Function Update Magnitude: 0.30710

Collected Steps per Second: 21,921.22831
Overall Steps per Second: 10,438.35062

Timestep Collection Time: 2.28144
Timestep Consumption Time: 2.50974
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.79118

Cumulative Model Updates: 145,846
Cumulative Timesteps: 1,217,098,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1217098124...
Checkpoint 1217098124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,207.90107
Policy Entropy: 1.70811
Value Function Loss: 0.04968

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.30760
Value Function Update Magnitude: 0.31774

Collected Steps per Second: 21,194.70302
Overall Steps per Second: 10,269.91577

Timestep Collection Time: 2.35908
Timestep Consumption Time: 2.50951
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.86859

Cumulative Model Updates: 145,852
Cumulative Timesteps: 1,217,148,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,208.64247
Policy Entropy: 1.72342
Value Function Loss: 0.04634

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.30611
Value Function Update Magnitude: 0.32663

Collected Steps per Second: 21,632.88898
Overall Steps per Second: 10,402.60356

Timestep Collection Time: 2.31139
Timestep Consumption Time: 2.49529
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.80668

Cumulative Model Updates: 145,858
Cumulative Timesteps: 1,217,198,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1217198126...
Checkpoint 1217198126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,817.05336
Policy Entropy: 1.70958
Value Function Loss: 0.04505

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.29149
Value Function Update Magnitude: 0.32338

Collected Steps per Second: 21,546.43408
Overall Steps per Second: 10,408.37312

Timestep Collection Time: 2.32178
Timestep Consumption Time: 2.48455
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.80632

Cumulative Model Updates: 145,864
Cumulative Timesteps: 1,217,248,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,644.19896
Policy Entropy: 1.70593
Value Function Loss: 0.04539

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.28836
Value Function Update Magnitude: 0.31639

Collected Steps per Second: 21,852.57668
Overall Steps per Second: 10,604.30526

Timestep Collection Time: 2.28888
Timestep Consumption Time: 2.42788
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.71676

Cumulative Model Updates: 145,870
Cumulative Timesteps: 1,217,298,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1217298170...
Checkpoint 1217298170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,467.72226
Policy Entropy: 1.71114
Value Function Loss: 0.04760

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.29936
Value Function Update Magnitude: 0.35074

Collected Steps per Second: 21,459.25140
Overall Steps per Second: 10,310.13194

Timestep Collection Time: 2.33093
Timestep Consumption Time: 2.52061
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.85154

Cumulative Model Updates: 145,876
Cumulative Timesteps: 1,217,348,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,164.48805
Policy Entropy: 1.74218
Value Function Loss: 0.04460

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.30834
Value Function Update Magnitude: 0.36170

Collected Steps per Second: 21,945.05093
Overall Steps per Second: 10,338.54209

Timestep Collection Time: 2.27906
Timestep Consumption Time: 2.55857
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.83763

Cumulative Model Updates: 145,882
Cumulative Timesteps: 1,217,398,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1217398204...
Checkpoint 1217398204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,939.51000
Policy Entropy: 1.73472
Value Function Loss: 0.04425

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.30725
Value Function Update Magnitude: 0.33878

Collected Steps per Second: 21,228.59113
Overall Steps per Second: 10,634.54350

Timestep Collection Time: 2.35607
Timestep Consumption Time: 2.34710
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.70316

Cumulative Model Updates: 145,888
Cumulative Timesteps: 1,217,448,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,836.48297
Policy Entropy: 1.73561
Value Function Loss: 0.04389

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.30373
Value Function Update Magnitude: 0.32801

Collected Steps per Second: 21,452.16014
Overall Steps per Second: 10,536.75736

Timestep Collection Time: 2.33226
Timestep Consumption Time: 2.41607
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.74833

Cumulative Model Updates: 145,894
Cumulative Timesteps: 1,217,498,252

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1217498252...
Checkpoint 1217498252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,073.98087
Policy Entropy: 1.72932
Value Function Loss: 0.04388

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.30431
Value Function Update Magnitude: 0.33773

Collected Steps per Second: 21,164.58360
Overall Steps per Second: 10,594.33311

Timestep Collection Time: 2.36310
Timestep Consumption Time: 2.35773
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.72083

Cumulative Model Updates: 145,900
Cumulative Timesteps: 1,217,548,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,449.29554
Policy Entropy: 1.74076
Value Function Loss: 0.04443

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.30250
Value Function Update Magnitude: 0.34472

Collected Steps per Second: 21,390.71724
Overall Steps per Second: 10,506.39775

Timestep Collection Time: 2.33924
Timestep Consumption Time: 2.42338
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.76262

Cumulative Model Updates: 145,906
Cumulative Timesteps: 1,217,598,304

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1217598304...
Checkpoint 1217598304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,823.83366
Policy Entropy: 1.72399
Value Function Loss: 0.04392

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.30819
Value Function Update Magnitude: 0.31786

Collected Steps per Second: 21,277.70989
Overall Steps per Second: 10,384.42273

Timestep Collection Time: 2.35082
Timestep Consumption Time: 2.46601
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.81683

Cumulative Model Updates: 145,912
Cumulative Timesteps: 1,217,648,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,740.50610
Policy Entropy: 1.71759
Value Function Loss: 0.04806

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.32883

Collected Steps per Second: 21,669.04955
Overall Steps per Second: 10,647.03317

Timestep Collection Time: 2.30882
Timestep Consumption Time: 2.39014
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.69896

Cumulative Model Updates: 145,918
Cumulative Timesteps: 1,217,698,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1217698354...
Checkpoint 1217698354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,704.82017
Policy Entropy: 1.71728
Value Function Loss: 0.05206

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.31638
Value Function Update Magnitude: 0.33691

Collected Steps per Second: 21,387.71526
Overall Steps per Second: 10,443.56055

Timestep Collection Time: 2.33929
Timestep Consumption Time: 2.45142
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.79070

Cumulative Model Updates: 145,924
Cumulative Timesteps: 1,217,748,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,093.39234
Policy Entropy: 1.71658
Value Function Loss: 0.05048

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08345
Policy Update Magnitude: 0.32091
Value Function Update Magnitude: 0.34823

Collected Steps per Second: 21,778.57775
Overall Steps per Second: 10,661.57204

Timestep Collection Time: 2.29602
Timestep Consumption Time: 2.39410
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.69012

Cumulative Model Updates: 145,930
Cumulative Timesteps: 1,217,798,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1217798390...
Checkpoint 1217798390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,947.67558
Policy Entropy: 1.71343
Value Function Loss: 0.04576

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.31756
Value Function Update Magnitude: 0.34724

Collected Steps per Second: 21,438.70450
Overall Steps per Second: 10,325.81760

Timestep Collection Time: 2.33288
Timestep Consumption Time: 2.51070
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.84359

Cumulative Model Updates: 145,936
Cumulative Timesteps: 1,217,848,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,071.88738
Policy Entropy: 1.70079
Value Function Loss: 0.04258

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08017
Policy Update Magnitude: 0.30765
Value Function Update Magnitude: 0.31261

Collected Steps per Second: 22,263.68361
Overall Steps per Second: 10,484.36026

Timestep Collection Time: 2.24761
Timestep Consumption Time: 2.52522
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.77282

Cumulative Model Updates: 145,942
Cumulative Timesteps: 1,217,898,444

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1217898444...
Checkpoint 1217898444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,565.12502
Policy Entropy: 1.69935
Value Function Loss: 0.04380

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.30365
Value Function Update Magnitude: 0.30191

Collected Steps per Second: 21,784.21091
Overall Steps per Second: 10,513.75375

Timestep Collection Time: 2.29662
Timestep Consumption Time: 2.46191
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.75853

Cumulative Model Updates: 145,948
Cumulative Timesteps: 1,217,948,474

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,737.95255
Policy Entropy: 1.69445
Value Function Loss: 0.04832

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07594
Policy Update Magnitude: 0.31237
Value Function Update Magnitude: 0.30681

Collected Steps per Second: 22,119.19099
Overall Steps per Second: 10,473.20719

Timestep Collection Time: 2.26093
Timestep Consumption Time: 2.51411
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.77504

Cumulative Model Updates: 145,954
Cumulative Timesteps: 1,217,998,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1217998484...
Checkpoint 1217998484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,757.78707
Policy Entropy: 1.69587
Value Function Loss: 0.04626

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.31507
Value Function Update Magnitude: 0.31270

Collected Steps per Second: 21,869.21478
Overall Steps per Second: 10,588.98839

Timestep Collection Time: 2.28659
Timestep Consumption Time: 2.43586
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.72245

Cumulative Model Updates: 145,960
Cumulative Timesteps: 1,218,048,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,932.07360
Policy Entropy: 1.69587
Value Function Loss: 0.04621

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.31459
Value Function Update Magnitude: 0.31349

Collected Steps per Second: 22,234.27525
Overall Steps per Second: 10,505.58275

Timestep Collection Time: 2.24932
Timestep Consumption Time: 2.51120
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.76052

Cumulative Model Updates: 145,966
Cumulative Timesteps: 1,218,098,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1218098502...
Checkpoint 1218098502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,818.30386
Policy Entropy: 1.70726
Value Function Loss: 0.04218

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.31041
Value Function Update Magnitude: 0.27734

Collected Steps per Second: 21,778.30425
Overall Steps per Second: 10,573.02913

Timestep Collection Time: 2.29595
Timestep Consumption Time: 2.43325
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.72920

Cumulative Model Updates: 145,972
Cumulative Timesteps: 1,218,148,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,244.60009
Policy Entropy: 1.72087
Value Function Loss: 0.04455

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.30652
Value Function Update Magnitude: 0.28290

Collected Steps per Second: 22,168.21995
Overall Steps per Second: 10,520.31414

Timestep Collection Time: 2.25665
Timestep Consumption Time: 2.49853
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.75518

Cumulative Model Updates: 145,978
Cumulative Timesteps: 1,218,198,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1218198530...
Checkpoint 1218198530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,526.33251
Policy Entropy: 1.72588
Value Function Loss: 0.04195

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.30585
Value Function Update Magnitude: 0.32145

Collected Steps per Second: 21,604.69186
Overall Steps per Second: 10,389.25230

Timestep Collection Time: 2.31468
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.81344

Cumulative Model Updates: 145,984
Cumulative Timesteps: 1,218,248,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,142.95989
Policy Entropy: 1.73666
Value Function Loss: 0.04502

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.31175
Value Function Update Magnitude: 0.34700

Collected Steps per Second: 22,076.64486
Overall Steps per Second: 10,622.27279

Timestep Collection Time: 2.26629
Timestep Consumption Time: 2.44382
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.71010

Cumulative Model Updates: 145,990
Cumulative Timesteps: 1,218,298,570

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1218298570...
Checkpoint 1218298570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,424.62770
Policy Entropy: 1.75549
Value Function Loss: 0.04309

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.30155
Value Function Update Magnitude: 0.31905

Collected Steps per Second: 20,917.39173
Overall Steps per Second: 10,357.13564

Timestep Collection Time: 2.39112
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.82913

Cumulative Model Updates: 145,996
Cumulative Timesteps: 1,218,348,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,322.95679
Policy Entropy: 1.74919
Value Function Loss: 0.04680

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.30072
Value Function Update Magnitude: 0.26526

Collected Steps per Second: 21,748.54096
Overall Steps per Second: 10,399.48684

Timestep Collection Time: 2.30038
Timestep Consumption Time: 2.51043
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.81081

Cumulative Model Updates: 146,002
Cumulative Timesteps: 1,218,398,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1218398616...
Checkpoint 1218398616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,539.93213
Policy Entropy: 1.73570
Value Function Loss: 0.04293

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.29604
Value Function Update Magnitude: 0.28457

Collected Steps per Second: 21,499.51161
Overall Steps per Second: 10,351.03989

Timestep Collection Time: 2.32591
Timestep Consumption Time: 2.50510
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.83101

Cumulative Model Updates: 146,008
Cumulative Timesteps: 1,218,448,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,934.74782
Policy Entropy: 1.72269
Value Function Loss: 0.04428

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.29676
Value Function Update Magnitude: 0.29259

Collected Steps per Second: 21,880.30390
Overall Steps per Second: 10,454.17591

Timestep Collection Time: 2.28635
Timestep Consumption Time: 2.49892
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.78526

Cumulative Model Updates: 146,014
Cumulative Timesteps: 1,218,498,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1218498648...
Checkpoint 1218498648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,256.96589
Policy Entropy: 1.72538
Value Function Loss: 0.04276

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.29986
Value Function Update Magnitude: 0.30141

Collected Steps per Second: 22,038.36556
Overall Steps per Second: 10,472.67239

Timestep Collection Time: 2.27004
Timestep Consumption Time: 2.50696
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.77700

Cumulative Model Updates: 146,020
Cumulative Timesteps: 1,218,548,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,845.97002
Policy Entropy: 1.73597
Value Function Loss: 0.04762

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.30783
Value Function Update Magnitude: 0.31015

Collected Steps per Second: 22,426.34815
Overall Steps per Second: 10,582.73921

Timestep Collection Time: 2.23077
Timestep Consumption Time: 2.49655
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.72732

Cumulative Model Updates: 146,026
Cumulative Timesteps: 1,218,598,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1218598704...
Checkpoint 1218598704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,886.58998
Policy Entropy: 1.71442
Value Function Loss: 0.04949

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.30896
Value Function Update Magnitude: 0.32905

Collected Steps per Second: 21,419.94214
Overall Steps per Second: 10,531.49248

Timestep Collection Time: 2.33474
Timestep Consumption Time: 2.41387
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.74861

Cumulative Model Updates: 146,032
Cumulative Timesteps: 1,218,648,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,505.12885
Policy Entropy: 1.72676
Value Function Loss: 0.05002

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.31099
Value Function Update Magnitude: 0.33535

Collected Steps per Second: 21,639.43416
Overall Steps per Second: 10,533.04094

Timestep Collection Time: 2.31152
Timestep Consumption Time: 2.43735
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.74887

Cumulative Model Updates: 146,038
Cumulative Timesteps: 1,218,698,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1218698734...
Checkpoint 1218698734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,615.12261
Policy Entropy: 1.71638
Value Function Loss: 0.05040

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.31583
Value Function Update Magnitude: 0.34857

Collected Steps per Second: 21,130.17141
Overall Steps per Second: 10,618.71227

Timestep Collection Time: 2.36714
Timestep Consumption Time: 2.34323
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.71036

Cumulative Model Updates: 146,044
Cumulative Timesteps: 1,218,748,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,199.90059
Policy Entropy: 1.71846
Value Function Loss: 0.04900

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.32268
Value Function Update Magnitude: 0.34974

Collected Steps per Second: 21,547.25152
Overall Steps per Second: 10,624.61000

Timestep Collection Time: 2.32160
Timestep Consumption Time: 2.38672
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.70831

Cumulative Model Updates: 146,050
Cumulative Timesteps: 1,218,798,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1218798776...
Checkpoint 1218798776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,667.86907
Policy Entropy: 1.72248
Value Function Loss: 0.04591

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.31481
Value Function Update Magnitude: 0.33510

Collected Steps per Second: 21,018.85116
Overall Steps per Second: 10,469.91642

Timestep Collection Time: 2.37958
Timestep Consumption Time: 2.39754
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.77712

Cumulative Model Updates: 146,056
Cumulative Timesteps: 1,218,848,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,135.13669
Policy Entropy: 1.73461
Value Function Loss: 0.04753

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.30582
Value Function Update Magnitude: 0.31057

Collected Steps per Second: 21,634.03912
Overall Steps per Second: 10,407.33520

Timestep Collection Time: 2.31182
Timestep Consumption Time: 2.49383
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.80565

Cumulative Model Updates: 146,062
Cumulative Timesteps: 1,218,898,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1218898806...
Checkpoint 1218898806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,501.22937
Policy Entropy: 1.75798
Value Function Loss: 0.04657

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.29281
Value Function Update Magnitude: 0.31915

Collected Steps per Second: 21,728.61400
Overall Steps per Second: 10,602.17739

Timestep Collection Time: 2.30157
Timestep Consumption Time: 2.41538
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.71696

Cumulative Model Updates: 146,068
Cumulative Timesteps: 1,218,948,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,062.48757
Policy Entropy: 1.75335
Value Function Loss: 0.04915

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.30493
Value Function Update Magnitude: 0.33830

Collected Steps per Second: 21,406.47432
Overall Steps per Second: 10,556.48167

Timestep Collection Time: 2.33780
Timestep Consumption Time: 2.40280
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.74059

Cumulative Model Updates: 146,074
Cumulative Timesteps: 1,218,998,860

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1218998860...
Checkpoint 1218998860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,046.85194
Policy Entropy: 1.76631
Value Function Loss: 0.04801

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.31039
Value Function Update Magnitude: 0.34851

Collected Steps per Second: 21,840.59716
Overall Steps per Second: 10,590.98998

Timestep Collection Time: 2.29096
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.72439

Cumulative Model Updates: 146,080
Cumulative Timesteps: 1,219,048,896

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,809.26783
Policy Entropy: 1.75692
Value Function Loss: 0.04805

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.31416
Value Function Update Magnitude: 0.35363

Collected Steps per Second: 22,130.51509
Overall Steps per Second: 10,476.02414

Timestep Collection Time: 2.26041
Timestep Consumption Time: 2.51469
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.77509

Cumulative Model Updates: 146,086
Cumulative Timesteps: 1,219,098,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1219098920...
Checkpoint 1219098920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,317.16144
Policy Entropy: 1.75634
Value Function Loss: 0.04590

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.31171
Value Function Update Magnitude: 0.33864

Collected Steps per Second: 22,043.11027
Overall Steps per Second: 10,572.94225

Timestep Collection Time: 2.27019
Timestep Consumption Time: 2.46284
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.73302

Cumulative Model Updates: 146,092
Cumulative Timesteps: 1,219,148,962

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,404.27955
Policy Entropy: 1.73230
Value Function Loss: 0.04434

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.30651
Value Function Update Magnitude: 0.32647

Collected Steps per Second: 21,935.37301
Overall Steps per Second: 10,462.70878

Timestep Collection Time: 2.28015
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.78041

Cumulative Model Updates: 146,098
Cumulative Timesteps: 1,219,198,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1219198978...
Checkpoint 1219198978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,474.56845
Policy Entropy: 1.71741
Value Function Loss: 0.04130

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.30065
Value Function Update Magnitude: 0.32473

Collected Steps per Second: 22,066.72618
Overall Steps per Second: 10,637.51585

Timestep Collection Time: 2.26767
Timestep Consumption Time: 2.43644
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.70411

Cumulative Model Updates: 146,104
Cumulative Timesteps: 1,219,249,018

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,841.83194
Policy Entropy: 1.71819
Value Function Loss: 0.04251

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.29762
Value Function Update Magnitude: 0.31635

Collected Steps per Second: 20,663.11955
Overall Steps per Second: 10,048.23462

Timestep Collection Time: 2.42035
Timestep Consumption Time: 2.55684
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.97719

Cumulative Model Updates: 146,110
Cumulative Timesteps: 1,219,299,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1219299030...
Checkpoint 1219299030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,546.65438
Policy Entropy: 1.72332
Value Function Loss: 0.04056

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.29762
Value Function Update Magnitude: 0.30668

Collected Steps per Second: 21,759.40331
Overall Steps per Second: 10,565.66301

Timestep Collection Time: 2.29896
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.73458

Cumulative Model Updates: 146,116
Cumulative Timesteps: 1,219,349,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,419.77241
Policy Entropy: 1.72911
Value Function Loss: 0.04562

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.30258
Value Function Update Magnitude: 0.29277

Collected Steps per Second: 21,663.56620
Overall Steps per Second: 10,565.99952

Timestep Collection Time: 2.30987
Timestep Consumption Time: 2.42608
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.73595

Cumulative Model Updates: 146,122
Cumulative Timesteps: 1,219,399,094

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1219399094...
Checkpoint 1219399094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,240.95445
Policy Entropy: 1.72749
Value Function Loss: 0.04246

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.30468
Value Function Update Magnitude: 0.30598

Collected Steps per Second: 21,737.94430
Overall Steps per Second: 10,530.81588

Timestep Collection Time: 2.30013
Timestep Consumption Time: 2.44784
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.74797

Cumulative Model Updates: 146,128
Cumulative Timesteps: 1,219,449,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,659.39331
Policy Entropy: 1.72534
Value Function Loss: 0.04186

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.29911
Value Function Update Magnitude: 0.31870

Collected Steps per Second: 21,926.43679
Overall Steps per Second: 10,545.98779

Timestep Collection Time: 2.28181
Timestep Consumption Time: 2.46236
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.74417

Cumulative Model Updates: 146,134
Cumulative Timesteps: 1,219,499,126

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1219499126...
Checkpoint 1219499126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,713.93324
Policy Entropy: 1.72560
Value Function Loss: 0.04019

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.29850
Value Function Update Magnitude: 0.31418

Collected Steps per Second: 21,783.69620
Overall Steps per Second: 10,535.08440

Timestep Collection Time: 2.29539
Timestep Consumption Time: 2.45085
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.74624

Cumulative Model Updates: 146,140
Cumulative Timesteps: 1,219,549,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,477.93443
Policy Entropy: 1.73514
Value Function Loss: 0.04776

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07944
Policy Update Magnitude: 0.30462
Value Function Update Magnitude: 0.33010

Collected Steps per Second: 21,783.18564
Overall Steps per Second: 10,581.65048

Timestep Collection Time: 2.29544
Timestep Consumption Time: 2.42991
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.72535

Cumulative Model Updates: 146,146
Cumulative Timesteps: 1,219,599,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1219599130...
Checkpoint 1219599130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,790.55394
Policy Entropy: 1.73957
Value Function Loss: 0.05260

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.31834
Value Function Update Magnitude: 0.33313

Collected Steps per Second: 22,075.06395
Overall Steps per Second: 10,654.84504

Timestep Collection Time: 2.26708
Timestep Consumption Time: 2.42994
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.69702

Cumulative Model Updates: 146,152
Cumulative Timesteps: 1,219,649,176

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,215.78518
Policy Entropy: 1.74377
Value Function Loss: 0.05200

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.31570
Value Function Update Magnitude: 0.34404

Collected Steps per Second: 22,159.10136
Overall Steps per Second: 10,511.88650

Timestep Collection Time: 2.25722
Timestep Consumption Time: 2.50101
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.75823

Cumulative Model Updates: 146,158
Cumulative Timesteps: 1,219,699,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1219699194...
Checkpoint 1219699194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,829.60496
Policy Entropy: 1.72728
Value Function Loss: 0.04617

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.31137
Value Function Update Magnitude: 0.34717

Collected Steps per Second: 22,041.87922
Overall Steps per Second: 10,507.57206

Timestep Collection Time: 2.26959
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.76095

Cumulative Model Updates: 146,164
Cumulative Timesteps: 1,219,749,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,845.59464
Policy Entropy: 1.71073
Value Function Loss: 0.04480

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.33408

Collected Steps per Second: 21,589.95637
Overall Steps per Second: 10,446.26036

Timestep Collection Time: 2.31728
Timestep Consumption Time: 2.47199
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.78927

Cumulative Model Updates: 146,170
Cumulative Timesteps: 1,219,799,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1219799250...
Checkpoint 1219799250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,988.70556
Policy Entropy: 1.70212
Value Function Loss: 0.04315

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.30296
Value Function Update Magnitude: 0.31484

Collected Steps per Second: 20,670.17349
Overall Steps per Second: 10,335.96943

Timestep Collection Time: 2.41982
Timestep Consumption Time: 2.41940
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.83922

Cumulative Model Updates: 146,176
Cumulative Timesteps: 1,219,849,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,973.24972
Policy Entropy: 1.70050
Value Function Loss: 0.04694

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.30619
Value Function Update Magnitude: 0.31354

Collected Steps per Second: 21,284.76681
Overall Steps per Second: 10,474.46999

Timestep Collection Time: 2.34976
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.77485

Cumulative Model Updates: 146,182
Cumulative Timesteps: 1,219,899,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1219899282...
Checkpoint 1219899282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,747.78489
Policy Entropy: 1.73210
Value Function Loss: 0.04736

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.31281
Value Function Update Magnitude: 0.32640

Collected Steps per Second: 21,318.26429
Overall Steps per Second: 10,481.26576

Timestep Collection Time: 2.34653
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.77271

Cumulative Model Updates: 146,188
Cumulative Timesteps: 1,219,949,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,173.84531
Policy Entropy: 1.73114
Value Function Loss: 0.04846

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.31411
Value Function Update Magnitude: 0.32494

Collected Steps per Second: 21,360.56549
Overall Steps per Second: 10,470.21988

Timestep Collection Time: 2.34076
Timestep Consumption Time: 2.43469
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.77545

Cumulative Model Updates: 146,194
Cumulative Timesteps: 1,219,999,306

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1219999306...
Checkpoint 1219999306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,609.01005
Policy Entropy: 1.74419
Value Function Loss: 0.04766

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.31362
Value Function Update Magnitude: 0.32330

Collected Steps per Second: 21,288.26372
Overall Steps per Second: 10,595.13970

Timestep Collection Time: 2.35050
Timestep Consumption Time: 2.37223
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.72273

Cumulative Model Updates: 146,200
Cumulative Timesteps: 1,220,049,344

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,896.80265
Policy Entropy: 1.72304
Value Function Loss: 0.04294

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.30660
Value Function Update Magnitude: 0.31338

Collected Steps per Second: 21,595.89700
Overall Steps per Second: 10,482.55009

Timestep Collection Time: 2.31701
Timestep Consumption Time: 2.45644
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.77346

Cumulative Model Updates: 146,206
Cumulative Timesteps: 1,220,099,382

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1220099382...
Checkpoint 1220099382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,433.14790
Policy Entropy: 1.72561
Value Function Loss: 0.04602

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.30587
Value Function Update Magnitude: 0.32026

Collected Steps per Second: 21,747.50149
Overall Steps per Second: 10,609.65893

Timestep Collection Time: 2.29985
Timestep Consumption Time: 2.41434
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.71419

Cumulative Model Updates: 146,212
Cumulative Timesteps: 1,220,149,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,453.03150
Policy Entropy: 1.70968
Value Function Loss: 0.04624

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.30985
Value Function Update Magnitude: 0.32791

Collected Steps per Second: 22,023.78290
Overall Steps per Second: 10,512.59589

Timestep Collection Time: 2.27182
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.75943

Cumulative Model Updates: 146,218
Cumulative Timesteps: 1,220,199,432

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1220199432...
Checkpoint 1220199432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,969.82529
Policy Entropy: 1.73563
Value Function Loss: 0.05422

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.31928
Value Function Update Magnitude: 0.35002

Collected Steps per Second: 22,201.59087
Overall Steps per Second: 10,641.78873

Timestep Collection Time: 2.25245
Timestep Consumption Time: 2.44676
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.69921

Cumulative Model Updates: 146,224
Cumulative Timesteps: 1,220,249,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,690.42444
Policy Entropy: 1.74641
Value Function Loss: 0.05324

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.32392
Value Function Update Magnitude: 0.34659

Collected Steps per Second: 22,050.29947
Overall Steps per Second: 10,516.43101

Timestep Collection Time: 2.26754
Timestep Consumption Time: 2.48692
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.75446

Cumulative Model Updates: 146,230
Cumulative Timesteps: 1,220,299,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1220299440...
Checkpoint 1220299440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,323.95273
Policy Entropy: 1.76106
Value Function Loss: 0.05228

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.31333
Value Function Update Magnitude: 0.33284

Collected Steps per Second: 21,749.95864
Overall Steps per Second: 10,581.74924

Timestep Collection Time: 2.29895
Timestep Consumption Time: 2.42636
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.72531

Cumulative Model Updates: 146,236
Cumulative Timesteps: 1,220,349,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,117.29120
Policy Entropy: 1.74804
Value Function Loss: 0.04954

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.30933
Value Function Update Magnitude: 0.31671

Collected Steps per Second: 21,629.17867
Overall Steps per Second: 10,451.64999

Timestep Collection Time: 2.31178
Timestep Consumption Time: 2.47234
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.78412

Cumulative Model Updates: 146,242
Cumulative Timesteps: 1,220,399,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1220399444...
Checkpoint 1220399444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,818.52594
Policy Entropy: 1.73298
Value Function Loss: 0.04709

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.30809
Value Function Update Magnitude: 0.32599

Collected Steps per Second: 21,439.84560
Overall Steps per Second: 10,321.63516

Timestep Collection Time: 2.33239
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.84477

Cumulative Model Updates: 146,248
Cumulative Timesteps: 1,220,449,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,487.15045
Policy Entropy: 1.70594
Value Function Loss: 0.04373

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.30559
Value Function Update Magnitude: 0.32661

Collected Steps per Second: 22,476.23658
Overall Steps per Second: 10,691.54117

Timestep Collection Time: 2.22617
Timestep Consumption Time: 2.45379
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.67996

Cumulative Model Updates: 146,254
Cumulative Timesteps: 1,220,499,486

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1220499486...
Checkpoint 1220499486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,661.57841
Policy Entropy: 1.70438
Value Function Loss: 0.04390

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.30392
Value Function Update Magnitude: 0.29598

Collected Steps per Second: 21,982.27225
Overall Steps per Second: 10,635.54967

Timestep Collection Time: 2.27574
Timestep Consumption Time: 2.42792
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.70366

Cumulative Model Updates: 146,260
Cumulative Timesteps: 1,220,549,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,809.00847
Policy Entropy: 1.70142
Value Function Loss: 0.04530

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.31052
Value Function Update Magnitude: 0.31178

Collected Steps per Second: 21,939.28415
Overall Steps per Second: 10,538.87275

Timestep Collection Time: 2.28048
Timestep Consumption Time: 2.46690
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.74738

Cumulative Model Updates: 146,266
Cumulative Timesteps: 1,220,599,544

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1220599544...
Checkpoint 1220599544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,497.50345
Policy Entropy: 1.71446
Value Function Loss: 0.04805

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.31833
Value Function Update Magnitude: 0.33778

Collected Steps per Second: 22,101.42869
Overall Steps per Second: 10,630.60831

Timestep Collection Time: 2.26329
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.70547

Cumulative Model Updates: 146,272
Cumulative Timesteps: 1,220,649,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,807.75154
Policy Entropy: 1.70249
Value Function Loss: 0.04262

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.30838
Value Function Update Magnitude: 0.34739

Collected Steps per Second: 22,228.48072
Overall Steps per Second: 10,495.08913

Timestep Collection Time: 2.25081
Timestep Consumption Time: 2.51638
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.76718

Cumulative Model Updates: 146,278
Cumulative Timesteps: 1,220,699,598

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1220699598...
Checkpoint 1220699598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,362.78561
Policy Entropy: 1.70860
Value Function Loss: 0.03940

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.29683
Value Function Update Magnitude: 0.33642

Collected Steps per Second: 21,956.72280
Overall Steps per Second: 10,620.36212

Timestep Collection Time: 2.27930
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.71227

Cumulative Model Updates: 146,284
Cumulative Timesteps: 1,220,749,644

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,502.10524
Policy Entropy: 1.70918
Value Function Loss: 0.03839

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07853
Policy Update Magnitude: 0.29267
Value Function Update Magnitude: 0.32189

Collected Steps per Second: 21,573.44078
Overall Steps per Second: 10,435.02448

Timestep Collection Time: 2.31766
Timestep Consumption Time: 2.47389
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.79156

Cumulative Model Updates: 146,290
Cumulative Timesteps: 1,220,799,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1220799644...
Checkpoint 1220799644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,884.65278
Policy Entropy: 1.70446
Value Function Loss: 0.04049

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.29402
Value Function Update Magnitude: 0.32107

Collected Steps per Second: 21,649.97376
Overall Steps per Second: 10,556.72639

Timestep Collection Time: 2.30956
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.73651

Cumulative Model Updates: 146,296
Cumulative Timesteps: 1,220,849,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,451.86671
Policy Entropy: 1.68890
Value Function Loss: 0.04379

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.30297
Value Function Update Magnitude: 0.34155

Collected Steps per Second: 21,702.34699
Overall Steps per Second: 10,510.19493

Timestep Collection Time: 2.30491
Timestep Consumption Time: 2.45447
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.75938

Cumulative Model Updates: 146,302
Cumulative Timesteps: 1,220,899,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1220899668...
Checkpoint 1220899668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,660.87157
Policy Entropy: 1.67883
Value Function Loss: 0.04553

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.30831
Value Function Update Magnitude: 0.36734

Collected Steps per Second: 21,895.90811
Overall Steps per Second: 10,570.24194

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.44771
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.73215

Cumulative Model Updates: 146,308
Cumulative Timesteps: 1,220,949,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,889.95042
Policy Entropy: 1.69335
Value Function Loss: 0.04859

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.31139
Value Function Update Magnitude: 0.36325

Collected Steps per Second: 21,759.02846
Overall Steps per Second: 10,514.06963

Timestep Collection Time: 2.29955
Timestep Consumption Time: 2.45941
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.75896

Cumulative Model Updates: 146,314
Cumulative Timesteps: 1,220,999,724

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1220999724...
Checkpoint 1220999724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,777.60738
Policy Entropy: 1.69010
Value Function Loss: 0.04677

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.31046
Value Function Update Magnitude: 0.35094

Collected Steps per Second: 22,015.71770
Overall Steps per Second: 10,599.26266

Timestep Collection Time: 2.27192
Timestep Consumption Time: 2.44709
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.71901

Cumulative Model Updates: 146,320
Cumulative Timesteps: 1,221,049,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,197.95477
Policy Entropy: 1.70572
Value Function Loss: 0.04911

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.28838
Value Function Update Magnitude: 0.32408

Collected Steps per Second: 22,257.78757
Overall Steps per Second: 10,502.28944

Timestep Collection Time: 2.24694
Timestep Consumption Time: 2.51507
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.76201

Cumulative Model Updates: 146,326
Cumulative Timesteps: 1,221,099,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1221099754...
Checkpoint 1221099754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,799.29396
Policy Entropy: 1.69052
Value Function Loss: 0.04838

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.30494
Value Function Update Magnitude: 0.32688

Collected Steps per Second: 22,060.55035
Overall Steps per Second: 10,615.36824

Timestep Collection Time: 2.26658
Timestep Consumption Time: 2.44376
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.71034

Cumulative Model Updates: 146,332
Cumulative Timesteps: 1,221,149,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,440.60575
Policy Entropy: 1.69465
Value Function Loss: 0.04962

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.31248
Value Function Update Magnitude: 0.31919

Collected Steps per Second: 21,192.47177
Overall Steps per Second: 10,432.51391

Timestep Collection Time: 2.36065
Timestep Consumption Time: 2.43474
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.79539

Cumulative Model Updates: 146,338
Cumulative Timesteps: 1,221,199,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1221199784...
Checkpoint 1221199784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,795.36989
Policy Entropy: 1.69423
Value Function Loss: 0.04628

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.31430
Value Function Update Magnitude: 0.30932

Collected Steps per Second: 21,305.82731
Overall Steps per Second: 10,317.57221

Timestep Collection Time: 2.34743
Timestep Consumption Time: 2.50003
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.84746

Cumulative Model Updates: 146,344
Cumulative Timesteps: 1,221,249,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,109.01326
Policy Entropy: 1.69554
Value Function Loss: 0.04676

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.31592
Value Function Update Magnitude: 0.29960

Collected Steps per Second: 21,806.19955
Overall Steps per Second: 10,389.15617

Timestep Collection Time: 2.29393
Timestep Consumption Time: 2.52089
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.81483

Cumulative Model Updates: 146,350
Cumulative Timesteps: 1,221,299,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1221299820...
Checkpoint 1221299820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,514.25434
Policy Entropy: 1.69491
Value Function Loss: 0.04422

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.30298
Value Function Update Magnitude: 0.31641

Collected Steps per Second: 21,535.40309
Overall Steps per Second: 10,360.41133

Timestep Collection Time: 2.32194
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.82645

Cumulative Model Updates: 146,356
Cumulative Timesteps: 1,221,349,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,478.47304
Policy Entropy: 1.70325
Value Function Loss: 0.04646

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.28207
Value Function Update Magnitude: 0.31401

Collected Steps per Second: 22,182.38902
Overall Steps per Second: 10,471.25856

Timestep Collection Time: 2.25440
Timestep Consumption Time: 2.52134
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.77574

Cumulative Model Updates: 146,362
Cumulative Timesteps: 1,221,399,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1221399832...
Checkpoint 1221399832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,774.91727
Policy Entropy: 1.71432
Value Function Loss: 0.04452

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.29245
Value Function Update Magnitude: 0.33088

Collected Steps per Second: 21,999.53788
Overall Steps per Second: 10,427.04951

Timestep Collection Time: 2.27432
Timestep Consumption Time: 2.52416
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.79848

Cumulative Model Updates: 146,368
Cumulative Timesteps: 1,221,449,866

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,561.59823
Policy Entropy: 1.70541
Value Function Loss: 0.04515

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.30282
Value Function Update Magnitude: 0.33257

Collected Steps per Second: 21,319.74997
Overall Steps per Second: 10,481.36905

Timestep Collection Time: 2.34656
Timestep Consumption Time: 2.42648
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.77304

Cumulative Model Updates: 146,374
Cumulative Timesteps: 1,221,499,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1221499894...
Checkpoint 1221499894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,906.50946
Policy Entropy: 1.69316
Value Function Loss: 0.04230

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.30493
Value Function Update Magnitude: 0.32406

Collected Steps per Second: 21,138.14101
Overall Steps per Second: 10,555.45469

Timestep Collection Time: 2.36605
Timestep Consumption Time: 2.37216
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.73821

Cumulative Model Updates: 146,380
Cumulative Timesteps: 1,221,549,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,348.99490
Policy Entropy: 1.67868
Value Function Loss: 0.04572

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.30916
Value Function Update Magnitude: 0.25718

Collected Steps per Second: 21,413.97374
Overall Steps per Second: 10,536.42931

Timestep Collection Time: 2.33623
Timestep Consumption Time: 2.41187
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.74810

Cumulative Model Updates: 146,386
Cumulative Timesteps: 1,221,599,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1221599936...
Checkpoint 1221599936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,885.81132
Policy Entropy: 1.69898
Value Function Loss: 0.04593

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.31219
Value Function Update Magnitude: 0.24223

Collected Steps per Second: 21,164.12774
Overall Steps per Second: 10,598.73934

Timestep Collection Time: 2.36306
Timestep Consumption Time: 2.35562
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.71867

Cumulative Model Updates: 146,392
Cumulative Timesteps: 1,221,649,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,442.28192
Policy Entropy: 1.69501
Value Function Loss: 0.04752

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.31197
Value Function Update Magnitude: 0.32004

Collected Steps per Second: 21,236.96239
Overall Steps per Second: 10,473.54779

Timestep Collection Time: 2.35467
Timestep Consumption Time: 2.41984
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.77450

Cumulative Model Updates: 146,398
Cumulative Timesteps: 1,221,699,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1221699954...
Checkpoint 1221699954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,432.94152
Policy Entropy: 1.70981
Value Function Loss: 0.04462

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.31355
Value Function Update Magnitude: 0.31671

Collected Steps per Second: 20,911.26909
Overall Steps per Second: 10,230.47366

Timestep Collection Time: 2.39182
Timestep Consumption Time: 2.49710
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.88892

Cumulative Model Updates: 146,404
Cumulative Timesteps: 1,221,749,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,921.16114
Policy Entropy: 1.68856
Value Function Loss: 0.04287

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.30991
Value Function Update Magnitude: 0.31118

Collected Steps per Second: 21,433.61244
Overall Steps per Second: 10,466.16223

Timestep Collection Time: 2.33400
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.77978

Cumulative Model Updates: 146,410
Cumulative Timesteps: 1,221,799,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1221799996...
Checkpoint 1221799996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,008.82750
Policy Entropy: 1.69721
Value Function Loss: 0.04346

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.30843
Value Function Update Magnitude: 0.31446

Collected Steps per Second: 21,653.15419
Overall Steps per Second: 10,616.41713

Timestep Collection Time: 2.30941
Timestep Consumption Time: 2.40084
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.71025

Cumulative Model Updates: 146,416
Cumulative Timesteps: 1,221,850,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,447.09959
Policy Entropy: 1.69927
Value Function Loss: 0.04390

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.30853
Value Function Update Magnitude: 0.31359

Collected Steps per Second: 21,743.27796
Overall Steps per Second: 10,422.41341

Timestep Collection Time: 2.30048
Timestep Consumption Time: 2.49879
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.79927

Cumulative Model Updates: 146,422
Cumulative Timesteps: 1,221,900,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1221900022...
Checkpoint 1221900022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,277.94266
Policy Entropy: 1.71450
Value Function Loss: 0.04657

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.31043
Value Function Update Magnitude: 0.32096

Collected Steps per Second: 21,366.56459
Overall Steps per Second: 10,312.33393

Timestep Collection Time: 2.34048
Timestep Consumption Time: 2.50886
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.84934

Cumulative Model Updates: 146,428
Cumulative Timesteps: 1,221,950,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,233.09688
Policy Entropy: 1.71797
Value Function Loss: 0.04736

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.31428
Value Function Update Magnitude: 0.33352

Collected Steps per Second: 22,324.19274
Overall Steps per Second: 10,463.84125

Timestep Collection Time: 2.24089
Timestep Consumption Time: 2.53996
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.78084

Cumulative Model Updates: 146,434
Cumulative Timesteps: 1,222,000,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1222000056...
Checkpoint 1222000056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,737.82686
Policy Entropy: 1.71471
Value Function Loss: 0.04493

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.31129
Value Function Update Magnitude: 0.33518

Collected Steps per Second: 22,035.52453
Overall Steps per Second: 10,545.79065

Timestep Collection Time: 2.26906
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.74123

Cumulative Model Updates: 146,440
Cumulative Timesteps: 1,222,050,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,554.60403
Policy Entropy: 1.71721
Value Function Loss: 0.04251

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.30722
Value Function Update Magnitude: 0.32533

Collected Steps per Second: 22,204.05499
Overall Steps per Second: 10,496.18204

Timestep Collection Time: 2.25265
Timestep Consumption Time: 2.51270
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.76535

Cumulative Model Updates: 146,446
Cumulative Timesteps: 1,222,100,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1222100074...
Checkpoint 1222100074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,024.66241
Policy Entropy: 1.69873
Value Function Loss: 0.04077

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.30163
Value Function Update Magnitude: 0.29633

Collected Steps per Second: 21,893.10053
Overall Steps per Second: 10,637.97973

Timestep Collection Time: 2.28446
Timestep Consumption Time: 2.41699
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.70146

Cumulative Model Updates: 146,452
Cumulative Timesteps: 1,222,150,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,548.62306
Policy Entropy: 1.69196
Value Function Loss: 0.04361

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.30693
Value Function Update Magnitude: 0.24885

Collected Steps per Second: 22,319.14232
Overall Steps per Second: 10,569.85263

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.49180
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.73346

Cumulative Model Updates: 146,458
Cumulative Timesteps: 1,222,200,120

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1222200120...
Checkpoint 1222200120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,644.46051
Policy Entropy: 1.69368
Value Function Loss: 0.04990

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.30951
Value Function Update Magnitude: 0.27270

Collected Steps per Second: 21,625.62692
Overall Steps per Second: 10,464.60875

Timestep Collection Time: 2.31207
Timestep Consumption Time: 2.46594
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.77801

Cumulative Model Updates: 146,464
Cumulative Timesteps: 1,222,250,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,365.73197
Policy Entropy: 1.70587
Value Function Loss: 0.04849

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.31219
Value Function Update Magnitude: 0.32252

Collected Steps per Second: 22,177.67784
Overall Steps per Second: 10,463.80883

Timestep Collection Time: 2.25488
Timestep Consumption Time: 2.52426
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.77914

Cumulative Model Updates: 146,470
Cumulative Timesteps: 1,222,300,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1222300128...
Checkpoint 1222300128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,610.81473
Policy Entropy: 1.71336
Value Function Loss: 0.04479

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08333
Policy Update Magnitude: 0.30883
Value Function Update Magnitude: 0.32836

Collected Steps per Second: 21,650.79686
Overall Steps per Second: 10,564.79293

Timestep Collection Time: 2.31022
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.73440

Cumulative Model Updates: 146,476
Cumulative Timesteps: 1,222,350,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,545.55530
Policy Entropy: 1.69865
Value Function Loss: 0.03897

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.30028
Value Function Update Magnitude: 0.31481

Collected Steps per Second: 21,860.58934
Overall Steps per Second: 10,628.22643

Timestep Collection Time: 2.28923
Timestep Consumption Time: 2.41936
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.70859

Cumulative Model Updates: 146,482
Cumulative Timesteps: 1,222,400,190

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1222400190...
Checkpoint 1222400190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,167.56502
Policy Entropy: 1.70659
Value Function Loss: 0.04031

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.29792
Value Function Update Magnitude: 0.31094

Collected Steps per Second: 21,496.52055
Overall Steps per Second: 10,521.66973

Timestep Collection Time: 2.32689
Timestep Consumption Time: 2.42711
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.75400

Cumulative Model Updates: 146,488
Cumulative Timesteps: 1,222,450,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,850.71356
Policy Entropy: 1.70432
Value Function Loss: 0.04478

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.30244
Value Function Update Magnitude: 0.32453

Collected Steps per Second: 21,973.74137
Overall Steps per Second: 10,462.18385

Timestep Collection Time: 2.27553
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.77931

Cumulative Model Updates: 146,494
Cumulative Timesteps: 1,222,500,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1222500212...
Checkpoint 1222500212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,549.67284
Policy Entropy: 1.70691
Value Function Loss: 0.04956

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.30418
Value Function Update Magnitude: 0.34649

Collected Steps per Second: 20,770.83092
Overall Steps per Second: 10,274.20402

Timestep Collection Time: 2.40761
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.86734

Cumulative Model Updates: 146,500
Cumulative Timesteps: 1,222,550,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,448.36236
Policy Entropy: 1.69673
Value Function Loss: 0.04886

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.31667
Value Function Update Magnitude: 0.36242

Collected Steps per Second: 21,651.27015
Overall Steps per Second: 10,600.90513

Timestep Collection Time: 2.31155
Timestep Consumption Time: 2.40956
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.72111

Cumulative Model Updates: 146,506
Cumulative Timesteps: 1,222,600,268

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1222600268...
Checkpoint 1222600268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,755.97920
Policy Entropy: 1.72027
Value Function Loss: 0.05171

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.31623
Value Function Update Magnitude: 0.36797

Collected Steps per Second: 21,031.05391
Overall Steps per Second: 10,436.29653

Timestep Collection Time: 2.37848
Timestep Consumption Time: 2.41460
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.79308

Cumulative Model Updates: 146,512
Cumulative Timesteps: 1,222,650,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,202.64501
Policy Entropy: 1.73381
Value Function Loss: 0.05179

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08459
Policy Update Magnitude: 0.31985
Value Function Update Magnitude: 0.35635

Collected Steps per Second: 21,576.79741
Overall Steps per Second: 10,518.97204

Timestep Collection Time: 2.31907
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.75693

Cumulative Model Updates: 146,518
Cumulative Timesteps: 1,222,700,328

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1222700328...
Checkpoint 1222700328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,916.44633
Policy Entropy: 1.73564
Value Function Loss: 0.05112

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.31945
Value Function Update Magnitude: 0.35812

Collected Steps per Second: 21,479.89928
Overall Steps per Second: 10,541.11477

Timestep Collection Time: 2.32906
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.74599

Cumulative Model Updates: 146,524
Cumulative Timesteps: 1,222,750,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,471.47801
Policy Entropy: 1.71512
Value Function Loss: 0.04642

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.31623
Value Function Update Magnitude: 0.35836

Collected Steps per Second: 21,937.07754
Overall Steps per Second: 10,496.72325

Timestep Collection Time: 2.28007
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.76511

Cumulative Model Updates: 146,530
Cumulative Timesteps: 1,222,800,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1222800374...
Checkpoint 1222800374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,424.70977
Policy Entropy: 1.71166
Value Function Loss: 0.04318

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.31225
Value Function Update Magnitude: 0.35952

Collected Steps per Second: 21,693.56688
Overall Steps per Second: 10,609.35844

Timestep Collection Time: 2.30686
Timestep Consumption Time: 2.41011
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.71697

Cumulative Model Updates: 146,536
Cumulative Timesteps: 1,222,850,418

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,221.51685
Policy Entropy: 1.71417
Value Function Loss: 0.04340

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.34533

Collected Steps per Second: 21,723.87076
Overall Steps per Second: 10,450.36892

Timestep Collection Time: 2.30346
Timestep Consumption Time: 2.48489
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.78835

Cumulative Model Updates: 146,542
Cumulative Timesteps: 1,222,900,458

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1222900458...
Checkpoint 1222900458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,170.27951
Policy Entropy: 1.71828
Value Function Loss: 0.04287

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.30675
Value Function Update Magnitude: 0.34468

Collected Steps per Second: 21,468.49720
Overall Steps per Second: 10,338.71747

Timestep Collection Time: 2.33095
Timestep Consumption Time: 2.50930
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.84025

Cumulative Model Updates: 146,548
Cumulative Timesteps: 1,222,950,500

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,391.88463
Policy Entropy: 1.72446
Value Function Loss: 0.04772

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.31052
Value Function Update Magnitude: 0.34769

Collected Steps per Second: 21,860.84047
Overall Steps per Second: 10,449.85642

Timestep Collection Time: 2.28848
Timestep Consumption Time: 2.49896
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.78743

Cumulative Model Updates: 146,554
Cumulative Timesteps: 1,223,000,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1223000528...
Checkpoint 1223000528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,295.75759
Policy Entropy: 1.71688
Value Function Loss: 0.04791

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.32138
Value Function Update Magnitude: 0.35316

Collected Steps per Second: 21,483.76027
Overall Steps per Second: 10,168.84087

Timestep Collection Time: 2.32762
Timestep Consumption Time: 2.58995
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.91757

Cumulative Model Updates: 146,560
Cumulative Timesteps: 1,223,050,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,982.82785
Policy Entropy: 1.73877
Value Function Loss: 0.05202

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.32599
Value Function Update Magnitude: 0.37083

Collected Steps per Second: 22,276.07488
Overall Steps per Second: 10,482.76201

Timestep Collection Time: 2.24456
Timestep Consumption Time: 2.52517
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.76974

Cumulative Model Updates: 146,566
Cumulative Timesteps: 1,223,100,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1223100534...
Checkpoint 1223100534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,594.64220
Policy Entropy: 1.72456
Value Function Loss: 0.04798

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.31991
Value Function Update Magnitude: 0.38642

Collected Steps per Second: 22,039.23883
Overall Steps per Second: 10,525.74597

Timestep Collection Time: 2.27004
Timestep Consumption Time: 2.48307
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.75311

Cumulative Model Updates: 146,572
Cumulative Timesteps: 1,223,150,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,918.83462
Policy Entropy: 1.73981
Value Function Loss: 0.05058

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.32146
Value Function Update Magnitude: 0.38915

Collected Steps per Second: 22,202.46144
Overall Steps per Second: 10,520.61010

Timestep Collection Time: 2.25227
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.75315

Cumulative Model Updates: 146,578
Cumulative Timesteps: 1,223,200,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1223200570...
Checkpoint 1223200570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,090.45373
Policy Entropy: 1.73657
Value Function Loss: 0.05251

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.32118
Value Function Update Magnitude: 0.37484

Collected Steps per Second: 21,920.47380
Overall Steps per Second: 10,620.91189

Timestep Collection Time: 2.28216
Timestep Consumption Time: 2.42798
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.71014

Cumulative Model Updates: 146,584
Cumulative Timesteps: 1,223,250,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,906.13134
Policy Entropy: 1.74320
Value Function Loss: 0.04998

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.31475
Value Function Update Magnitude: 0.36270

Collected Steps per Second: 22,303.53990
Overall Steps per Second: 10,575.24337

Timestep Collection Time: 2.24404
Timestep Consumption Time: 2.48871
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.73275

Cumulative Model Updates: 146,590
Cumulative Timesteps: 1,223,300,646

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1223300646...
Checkpoint 1223300646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,214.14502
Policy Entropy: 1.73283
Value Function Loss: 0.04650

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.31114
Value Function Update Magnitude: 0.35091

Collected Steps per Second: 21,708.84119
Overall Steps per Second: 10,520.66324

Timestep Collection Time: 2.30395
Timestep Consumption Time: 2.45013
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.75407

Cumulative Model Updates: 146,596
Cumulative Timesteps: 1,223,350,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,865.95937
Policy Entropy: 1.70884
Value Function Loss: 0.04401

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.33762

Collected Steps per Second: 21,719.19894
Overall Steps per Second: 10,436.99971

Timestep Collection Time: 2.30322
Timestep Consumption Time: 2.48973
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.79295

Cumulative Model Updates: 146,602
Cumulative Timesteps: 1,223,400,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1223400686...
Checkpoint 1223400686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,368.72353
Policy Entropy: 1.72470
Value Function Loss: 0.04526

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.31014
Value Function Update Magnitude: 0.33693

Collected Steps per Second: 21,050.34494
Overall Steps per Second: 10,579.57480

Timestep Collection Time: 2.37535
Timestep Consumption Time: 2.35092
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.72628

Cumulative Model Updates: 146,608
Cumulative Timesteps: 1,223,450,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,747.91537
Policy Entropy: 1.72659
Value Function Loss: 0.04704

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.30731
Value Function Update Magnitude: 0.34976

Collected Steps per Second: 21,100.78784
Overall Steps per Second: 10,498.72885

Timestep Collection Time: 2.37166
Timestep Consumption Time: 2.39501
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.76667

Cumulative Model Updates: 146,614
Cumulative Timesteps: 1,223,500,732

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1223500732...
Checkpoint 1223500732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,100.87235
Policy Entropy: 1.72543
Value Function Loss: 0.04644

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.30550
Value Function Update Magnitude: 0.36682

Collected Steps per Second: 21,404.00297
Overall Steps per Second: 10,578.30962

Timestep Collection Time: 2.33685
Timestep Consumption Time: 2.39150
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.72835

Cumulative Model Updates: 146,620
Cumulative Timesteps: 1,223,550,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,271.88416
Policy Entropy: 1.71521
Value Function Loss: 0.04656

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.31108
Value Function Update Magnitude: 0.36292

Collected Steps per Second: 21,439.32580
Overall Steps per Second: 10,500.97201

Timestep Collection Time: 2.33347
Timestep Consumption Time: 2.43066
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.76413

Cumulative Model Updates: 146,626
Cumulative Timesteps: 1,223,600,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1223600778...
Checkpoint 1223600778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,859.33596
Policy Entropy: 1.71740
Value Function Loss: 0.04612

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.30878
Value Function Update Magnitude: 0.35215

Collected Steps per Second: 21,990.88619
Overall Steps per Second: 10,650.91908

Timestep Collection Time: 2.27431
Timestep Consumption Time: 2.42144
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.69575

Cumulative Model Updates: 146,632
Cumulative Timesteps: 1,223,650,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,154.98583
Policy Entropy: 1.73028
Value Function Loss: 0.04652

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.29612
Value Function Update Magnitude: 0.35647

Collected Steps per Second: 21,866.19717
Overall Steps per Second: 10,455.42021

Timestep Collection Time: 2.28865
Timestep Consumption Time: 2.49777
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.78642

Cumulative Model Updates: 146,638
Cumulative Timesteps: 1,223,700,836

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1223700836...
Checkpoint 1223700836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,632.78930
Policy Entropy: 1.72151
Value Function Loss: 0.04696

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.28526
Value Function Update Magnitude: 0.35255

Collected Steps per Second: 22,154.93038
Overall Steps per Second: 10,621.24427

Timestep Collection Time: 2.25783
Timestep Consumption Time: 2.45179
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.70962

Cumulative Model Updates: 146,644
Cumulative Timesteps: 1,223,750,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,051.66980
Policy Entropy: 1.70731
Value Function Loss: 0.04783

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.30704
Value Function Update Magnitude: 0.33560

Collected Steps per Second: 21,958.00748
Overall Steps per Second: 10,510.27790

Timestep Collection Time: 2.27835
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.75991

Cumulative Model Updates: 146,650
Cumulative Timesteps: 1,223,800,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1223800886...
Checkpoint 1223800886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,409.38068
Policy Entropy: 1.69955
Value Function Loss: 0.04765

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.31600
Value Function Update Magnitude: 0.31479

Collected Steps per Second: 22,007.09644
Overall Steps per Second: 10,642.47596

Timestep Collection Time: 2.27427
Timestep Consumption Time: 2.42859
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.70285

Cumulative Model Updates: 146,656
Cumulative Timesteps: 1,223,850,936

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,090.13834
Policy Entropy: 1.69710
Value Function Loss: 0.04780

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.31963
Value Function Update Magnitude: 0.31787

Collected Steps per Second: 21,157.50110
Overall Steps per Second: 10,397.25718

Timestep Collection Time: 2.36502
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.81262

Cumulative Model Updates: 146,662
Cumulative Timesteps: 1,223,900,974

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1223900974...
Checkpoint 1223900974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,929.48587
Policy Entropy: 1.69691
Value Function Loss: 0.04928

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.32693
Value Function Update Magnitude: 0.34137

Collected Steps per Second: 21,515.89503
Overall Steps per Second: 10,326.42699

Timestep Collection Time: 2.32479
Timestep Consumption Time: 2.51909
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.84388

Cumulative Model Updates: 146,668
Cumulative Timesteps: 1,223,950,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,800.50425
Policy Entropy: 1.70566
Value Function Loss: 0.04747

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.32524
Value Function Update Magnitude: 0.35046

Collected Steps per Second: 21,494.23167
Overall Steps per Second: 10,365.42647

Timestep Collection Time: 2.32639
Timestep Consumption Time: 2.49772
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.82411

Cumulative Model Updates: 146,674
Cumulative Timesteps: 1,224,000,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1224000998...
Checkpoint 1224000998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,422.04605
Policy Entropy: 1.70053
Value Function Loss: 0.04647

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.32000
Value Function Update Magnitude: 0.33762

Collected Steps per Second: 21,512.86633
Overall Steps per Second: 10,408.85996

Timestep Collection Time: 2.32540
Timestep Consumption Time: 2.48070
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.80610

Cumulative Model Updates: 146,680
Cumulative Timesteps: 1,224,051,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,056.02235
Policy Entropy: 1.71985
Value Function Loss: 0.04776

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.31534
Value Function Update Magnitude: 0.31273

Collected Steps per Second: 21,660.98711
Overall Steps per Second: 10,379.97359

Timestep Collection Time: 2.30977
Timestep Consumption Time: 2.51028
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.82005

Cumulative Model Updates: 146,686
Cumulative Timesteps: 1,224,101,056

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1224101056...
Checkpoint 1224101056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,182.90174
Policy Entropy: 1.71849
Value Function Loss: 0.04614

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.30573
Value Function Update Magnitude: 0.31108

Collected Steps per Second: 22,045.72555
Overall Steps per Second: 10,586.23829

Timestep Collection Time: 2.26865
Timestep Consumption Time: 2.45579
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.72444

Cumulative Model Updates: 146,692
Cumulative Timesteps: 1,224,151,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,661.68462
Policy Entropy: 1.71791
Value Function Loss: 0.04836

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.31038
Value Function Update Magnitude: 0.32356

Collected Steps per Second: 22,106.14353
Overall Steps per Second: 10,445.72733

Timestep Collection Time: 2.26209
Timestep Consumption Time: 2.52513
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.78722

Cumulative Model Updates: 146,698
Cumulative Timesteps: 1,224,201,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1224201076...
Checkpoint 1224201076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,553.11359
Policy Entropy: 1.70135
Value Function Loss: 0.04726

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.31437
Value Function Update Magnitude: 0.34968

Collected Steps per Second: 22,137.04169
Overall Steps per Second: 10,519.35862

Timestep Collection Time: 2.25902
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.75390

Cumulative Model Updates: 146,704
Cumulative Timesteps: 1,224,251,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,809.10376
Policy Entropy: 1.68544
Value Function Loss: 0.04674

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.31851
Value Function Update Magnitude: 0.35300

Collected Steps per Second: 21,891.14397
Overall Steps per Second: 10,470.98301

Timestep Collection Time: 2.28485
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.77682

Cumulative Model Updates: 146,710
Cumulative Timesteps: 1,224,301,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1224301102...
Checkpoint 1224301102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,222.73520
Policy Entropy: 1.70669
Value Function Loss: 0.05007

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.32348
Value Function Update Magnitude: 0.33397

Collected Steps per Second: 21,832.64266
Overall Steps per Second: 10,584.90523

Timestep Collection Time: 2.29042
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.72427

Cumulative Model Updates: 146,716
Cumulative Timesteps: 1,224,351,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,540.37726
Policy Entropy: 1.71424
Value Function Loss: 0.05171

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.32430
Value Function Update Magnitude: 0.35977

Collected Steps per Second: 22,135.07119
Overall Steps per Second: 10,510.94760

Timestep Collection Time: 2.26021
Timestep Consumption Time: 2.49959
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.75980

Cumulative Model Updates: 146,722
Cumulative Timesteps: 1,224,401,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1224401138...
Checkpoint 1224401138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,363.42499
Policy Entropy: 1.72203
Value Function Loss: 0.05134

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.32689
Value Function Update Magnitude: 0.36290

Collected Steps per Second: 21,102.19011
Overall Steps per Second: 10,589.69496

Timestep Collection Time: 2.37151
Timestep Consumption Time: 2.35422
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.72573

Cumulative Model Updates: 146,728
Cumulative Timesteps: 1,224,451,182

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,839.07316
Policy Entropy: 1.70285
Value Function Loss: 0.04817

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.31590
Value Function Update Magnitude: 0.33584

Collected Steps per Second: 20,929.43522
Overall Steps per Second: 10,519.54583

Timestep Collection Time: 2.39108
Timestep Consumption Time: 2.36616
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.75724

Cumulative Model Updates: 146,734
Cumulative Timesteps: 1,224,501,226

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1224501226...
Checkpoint 1224501226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,472.33604
Policy Entropy: 1.70460
Value Function Loss: 0.05506

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.31749
Value Function Update Magnitude: 0.31817

Collected Steps per Second: 20,787.28659
Overall Steps per Second: 10,348.19549

Timestep Collection Time: 2.40657
Timestep Consumption Time: 2.42771
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.83427

Cumulative Model Updates: 146,740
Cumulative Timesteps: 1,224,551,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,651.00748
Policy Entropy: 1.71620
Value Function Loss: 0.05294

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.31654
Value Function Update Magnitude: 0.31919

Collected Steps per Second: 21,094.82273
Overall Steps per Second: 10,371.30684

Timestep Collection Time: 2.37091
Timestep Consumption Time: 2.45143
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.82234

Cumulative Model Updates: 146,746
Cumulative Timesteps: 1,224,601,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1224601266...
Checkpoint 1224601266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,634.76842
Policy Entropy: 1.71175
Value Function Loss: 0.05046

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.30397
Value Function Update Magnitude: 0.33200

Collected Steps per Second: 21,082.50602
Overall Steps per Second: 10,318.16330

Timestep Collection Time: 2.37401
Timestep Consumption Time: 2.47666
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.85067

Cumulative Model Updates: 146,752
Cumulative Timesteps: 1,224,651,316

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,572.05520
Policy Entropy: 1.70916
Value Function Loss: 0.04528

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.29817
Value Function Update Magnitude: 0.32693

Collected Steps per Second: 21,407.71698
Overall Steps per Second: 10,348.03338

Timestep Collection Time: 2.33729
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.83531

Cumulative Model Updates: 146,758
Cumulative Timesteps: 1,224,701,352

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1224701352...
Checkpoint 1224701352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,642.57846
Policy Entropy: 1.69074
Value Function Loss: 0.04757

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.31013
Value Function Update Magnitude: 0.33565

Collected Steps per Second: 21,922.62268
Overall Steps per Second: 10,591.79243

Timestep Collection Time: 2.28285
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.72498

Cumulative Model Updates: 146,764
Cumulative Timesteps: 1,224,751,398

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,043.77543
Policy Entropy: 1.70384
Value Function Loss: 0.04862

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.31928
Value Function Update Magnitude: 0.35447

Collected Steps per Second: 21,839.71795
Overall Steps per Second: 10,441.33126

Timestep Collection Time: 2.29078
Timestep Consumption Time: 2.50075
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.79153

Cumulative Model Updates: 146,770
Cumulative Timesteps: 1,224,801,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1224801428...
Checkpoint 1224801428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,571.29683
Policy Entropy: 1.69813
Value Function Loss: 0.04751

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.32313
Value Function Update Magnitude: 0.35804

Collected Steps per Second: 21,677.66136
Overall Steps per Second: 10,569.83550

Timestep Collection Time: 2.30763
Timestep Consumption Time: 2.42508
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.73271

Cumulative Model Updates: 146,776
Cumulative Timesteps: 1,224,851,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,740.38854
Policy Entropy: 1.70857
Value Function Loss: 0.04792

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.32219
Value Function Update Magnitude: 0.34782

Collected Steps per Second: 22,048.82634
Overall Steps per Second: 10,500.17136

Timestep Collection Time: 2.26887
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.76430

Cumulative Model Updates: 146,782
Cumulative Timesteps: 1,224,901,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1224901478...
Checkpoint 1224901478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,211.45839
Policy Entropy: 1.69234
Value Function Loss: 0.04270

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.31510
Value Function Update Magnitude: 0.34421

Collected Steps per Second: 21,052.65196
Overall Steps per Second: 10,232.55629

Timestep Collection Time: 2.37566
Timestep Consumption Time: 2.51207
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.88773

Cumulative Model Updates: 146,788
Cumulative Timesteps: 1,224,951,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,953.32950
Policy Entropy: 1.69471
Value Function Loss: 0.04331

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.30752
Value Function Update Magnitude: 0.32566

Collected Steps per Second: 21,554.83695
Overall Steps per Second: 10,490.41231

Timestep Collection Time: 2.32078
Timestep Consumption Time: 2.44777
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.76854

Cumulative Model Updates: 146,794
Cumulative Timesteps: 1,225,001,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1225001516...
Checkpoint 1225001516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,427.43855
Policy Entropy: 1.69231
Value Function Loss: 0.04195

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.30675
Value Function Update Magnitude: 0.30628

Collected Steps per Second: 21,557.84347
Overall Steps per Second: 10,536.82937

Timestep Collection Time: 2.31953
Timestep Consumption Time: 2.42611
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.74564

Cumulative Model Updates: 146,800
Cumulative Timesteps: 1,225,051,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,463.35878
Policy Entropy: 1.70369
Value Function Loss: 0.04513

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.30957
Value Function Update Magnitude: 0.31324

Collected Steps per Second: 21,510.91353
Overall Steps per Second: 10,462.23378

Timestep Collection Time: 2.32524
Timestep Consumption Time: 2.45558
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.78081

Cumulative Model Updates: 146,806
Cumulative Timesteps: 1,225,101,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1225101538...
Checkpoint 1225101538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,756.04674
Policy Entropy: 1.70101
Value Function Loss: 0.04310

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.30840
Value Function Update Magnitude: 0.30155

Collected Steps per Second: 21,724.56103
Overall Steps per Second: 10,316.53338

Timestep Collection Time: 2.30173
Timestep Consumption Time: 2.54525
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.84698

Cumulative Model Updates: 146,812
Cumulative Timesteps: 1,225,151,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,199.22401
Policy Entropy: 1.68627
Value Function Loss: 0.04391

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.29618
Value Function Update Magnitude: 0.30990

Collected Steps per Second: 22,171.07381
Overall Steps per Second: 10,466.58320

Timestep Collection Time: 2.25609
Timestep Consumption Time: 2.52293
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.77902

Cumulative Model Updates: 146,818
Cumulative Timesteps: 1,225,201,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1225201562...
Checkpoint 1225201562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,289.47162
Policy Entropy: 1.67042
Value Function Loss: 0.04413

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.28841
Value Function Update Magnitude: 0.32287

Collected Steps per Second: 22,051.57822
Overall Steps per Second: 10,592.65036

Timestep Collection Time: 2.26759
Timestep Consumption Time: 2.45304
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.72063

Cumulative Model Updates: 146,824
Cumulative Timesteps: 1,225,251,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,765.75842
Policy Entropy: 1.68222
Value Function Loss: 0.05003

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.31033
Value Function Update Magnitude: 0.32542

Collected Steps per Second: 22,025.67613
Overall Steps per Second: 10,415.30275

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.53146
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.80236

Cumulative Model Updates: 146,830
Cumulative Timesteps: 1,225,301,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1225301584...
Checkpoint 1225301584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,504.24112
Policy Entropy: 1.69304
Value Function Loss: 0.05312

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.31826
Value Function Update Magnitude: 0.33960

Collected Steps per Second: 21,810.34685
Overall Steps per Second: 10,559.88989

Timestep Collection Time: 2.29377
Timestep Consumption Time: 2.44378
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.73755

Cumulative Model Updates: 146,836
Cumulative Timesteps: 1,225,351,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,434.20991
Policy Entropy: 1.70009
Value Function Loss: 0.05063

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.31853
Value Function Update Magnitude: 0.34963

Collected Steps per Second: 22,186.61244
Overall Steps per Second: 10,569.09305

Timestep Collection Time: 2.25568
Timestep Consumption Time: 2.47944
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.73513

Cumulative Model Updates: 146,842
Cumulative Timesteps: 1,225,401,658

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1225401658...
Checkpoint 1225401658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,849.97862
Policy Entropy: 1.68696
Value Function Loss: 0.04749

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 0.31429
Value Function Update Magnitude: 0.32242

Collected Steps per Second: 21,792.90916
Overall Steps per Second: 10,580.54932

Timestep Collection Time: 2.29552
Timestep Consumption Time: 2.43259
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.72811

Cumulative Model Updates: 146,848
Cumulative Timesteps: 1,225,451,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,247.59786
Policy Entropy: 1.68980
Value Function Loss: 0.04797

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.31750
Value Function Update Magnitude: 0.28211

Collected Steps per Second: 21,603.45821
Overall Steps per Second: 10,540.09540

Timestep Collection Time: 2.31556
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.74607

Cumulative Model Updates: 146,854
Cumulative Timesteps: 1,225,501,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1225501708...
Checkpoint 1225501708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,728.94635
Policy Entropy: 1.69733
Value Function Loss: 0.05112

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.32113
Value Function Update Magnitude: 0.31276

Collected Steps per Second: 21,340.77691
Overall Steps per Second: 10,501.45707

Timestep Collection Time: 2.34396
Timestep Consumption Time: 2.41938
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.76334

Cumulative Model Updates: 146,860
Cumulative Timesteps: 1,225,551,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,213.04805
Policy Entropy: 1.70634
Value Function Loss: 0.05672

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.32727
Value Function Update Magnitude: 0.29487

Collected Steps per Second: 20,827.93932
Overall Steps per Second: 10,496.41768

Timestep Collection Time: 2.40120
Timestep Consumption Time: 2.36348
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.76467

Cumulative Model Updates: 146,866
Cumulative Timesteps: 1,225,601,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1225601742...
Checkpoint 1225601742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,199.22280
Policy Entropy: 1.71212
Value Function Loss: 0.05442

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.30030
Value Function Update Magnitude: 0.32558

Collected Steps per Second: 20,988.99588
Overall Steps per Second: 10,402.49146

Timestep Collection Time: 2.38353
Timestep Consumption Time: 2.42570
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.80923

Cumulative Model Updates: 146,872
Cumulative Timesteps: 1,225,651,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,645.68809
Policy Entropy: 1.70294
Value Function Loss: 0.05296

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.28994
Value Function Update Magnitude: 0.35517

Collected Steps per Second: 21,325.03339
Overall Steps per Second: 10,520.53615

Timestep Collection Time: 2.34476
Timestep Consumption Time: 2.40804
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.75280

Cumulative Model Updates: 146,878
Cumulative Timesteps: 1,225,701,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1225701772...
Checkpoint 1225701772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,609.69817
Policy Entropy: 1.70408
Value Function Loss: 0.04818

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.29064
Value Function Update Magnitude: 0.34727

Collected Steps per Second: 21,302.77951
Overall Steps per Second: 10,410.60525

Timestep Collection Time: 2.34927
Timestep Consumption Time: 2.45794
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.80721

Cumulative Model Updates: 146,884
Cumulative Timesteps: 1,225,751,818

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,291.28797
Policy Entropy: 1.70451
Value Function Loss: 0.05461

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.30060
Value Function Update Magnitude: 0.34698

Collected Steps per Second: 21,000.31098
Overall Steps per Second: 10,420.14605

Timestep Collection Time: 2.38216
Timestep Consumption Time: 2.41874
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.80089

Cumulative Model Updates: 146,890
Cumulative Timesteps: 1,225,801,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1225801844...
Checkpoint 1225801844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,676.00318
Policy Entropy: 1.70928
Value Function Loss: 0.05350

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.31561
Value Function Update Magnitude: 0.35928

Collected Steps per Second: 21,374.90769
Overall Steps per Second: 10,405.77380

Timestep Collection Time: 2.34031
Timestep Consumption Time: 2.46702
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.80733

Cumulative Model Updates: 146,896
Cumulative Timesteps: 1,225,851,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,159.72459
Policy Entropy: 1.71545
Value Function Loss: 0.05674

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.32079
Value Function Update Magnitude: 0.35147

Collected Steps per Second: 21,946.60438
Overall Steps per Second: 10,658.64305

Timestep Collection Time: 2.27835
Timestep Consumption Time: 2.41287
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.69122

Cumulative Model Updates: 146,902
Cumulative Timesteps: 1,225,901,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1225901870...
Checkpoint 1225901870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,488.35069
Policy Entropy: 1.72292
Value Function Loss: 0.05304

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.32212
Value Function Update Magnitude: 0.36897

Collected Steps per Second: 21,799.38293
Overall Steps per Second: 10,623.79850

Timestep Collection Time: 2.29484
Timestep Consumption Time: 2.41403
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.70886

Cumulative Model Updates: 146,908
Cumulative Timesteps: 1,225,951,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,344.24624
Policy Entropy: 1.71381
Value Function Loss: 0.05240

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.30740
Value Function Update Magnitude: 0.36189

Collected Steps per Second: 22,189.50566
Overall Steps per Second: 10,545.05827

Timestep Collection Time: 2.25377
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.74251

Cumulative Model Updates: 146,914
Cumulative Timesteps: 1,226,001,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1226001906...
Checkpoint 1226001906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,522.74062
Policy Entropy: 1.70407
Value Function Loss: 0.05147

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.30742
Value Function Update Magnitude: 0.35755

Collected Steps per Second: 21,764.61359
Overall Steps per Second: 10,626.40757

Timestep Collection Time: 2.29896
Timestep Consumption Time: 2.40969
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.70865

Cumulative Model Updates: 146,920
Cumulative Timesteps: 1,226,051,942

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,307.80017
Policy Entropy: 1.68129
Value Function Loss: 0.04952

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.31173
Value Function Update Magnitude: 0.36878

Collected Steps per Second: 21,654.76324
Overall Steps per Second: 10,540.16301

Timestep Collection Time: 2.30924
Timestep Consumption Time: 2.43509
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.74433

Cumulative Model Updates: 146,926
Cumulative Timesteps: 1,226,101,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1226101948...
Checkpoint 1226101948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,690.86110
Policy Entropy: 1.67899
Value Function Loss: 0.04775

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.31968
Value Function Update Magnitude: 0.36425

Collected Steps per Second: 21,337.78493
Overall Steps per Second: 10,485.81957

Timestep Collection Time: 2.34439
Timestep Consumption Time: 2.42625
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.77063

Cumulative Model Updates: 146,932
Cumulative Timesteps: 1,226,151,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,560.45962
Policy Entropy: 1.68539
Value Function Loss: 0.05131

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.32537
Value Function Update Magnitude: 0.36291

Collected Steps per Second: 21,644.66384
Overall Steps per Second: 10,535.30638

Timestep Collection Time: 2.31087
Timestep Consumption Time: 2.43679
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.74765

Cumulative Model Updates: 146,938
Cumulative Timesteps: 1,226,201,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1226201990...
Checkpoint 1226201990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,856.88860
Policy Entropy: 1.70196
Value Function Loss: 0.05008

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.32325
Value Function Update Magnitude: 0.35584

Collected Steps per Second: 21,427.50376
Overall Steps per Second: 10,312.14145

Timestep Collection Time: 2.33420
Timestep Consumption Time: 2.51601
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.85021

Cumulative Model Updates: 146,944
Cumulative Timesteps: 1,226,252,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,046.65695
Policy Entropy: 1.69823
Value Function Loss: 0.04981

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.30280
Value Function Update Magnitude: 0.35884

Collected Steps per Second: 21,943.18274
Overall Steps per Second: 10,410.23244

Timestep Collection Time: 2.27898
Timestep Consumption Time: 2.52476
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.80374

Cumulative Model Updates: 146,950
Cumulative Timesteps: 1,226,302,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1226302014...
Checkpoint 1226302014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,247.77173
Policy Entropy: 1.71045
Value Function Loss: 0.04788

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.30508
Value Function Update Magnitude: 0.37034

Collected Steps per Second: 22,028.33700
Overall Steps per Second: 10,542.00615

Timestep Collection Time: 2.27053
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74445

Cumulative Model Updates: 146,956
Cumulative Timesteps: 1,226,352,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,230.70232
Policy Entropy: 1.70134
Value Function Loss: 0.04565

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.31357
Value Function Update Magnitude: 0.38438

Collected Steps per Second: 22,024.44789
Overall Steps per Second: 10,408.37750

Timestep Collection Time: 2.27057
Timestep Consumption Time: 2.53402
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.80459

Cumulative Model Updates: 146,962
Cumulative Timesteps: 1,226,402,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1226402038...
Checkpoint 1226402038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,606.34125
Policy Entropy: 1.70073
Value Function Loss: 0.04753

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.31960
Value Function Update Magnitude: 0.36900

Collected Steps per Second: 21,836.59149
Overall Steps per Second: 10,453.43575

Timestep Collection Time: 2.29010
Timestep Consumption Time: 2.49378
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.78388

Cumulative Model Updates: 146,968
Cumulative Timesteps: 1,226,452,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,510.22387
Policy Entropy: 1.68939
Value Function Loss: 0.04919

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.31914
Value Function Update Magnitude: 0.37090

Collected Steps per Second: 22,145.75788
Overall Steps per Second: 10,650.88583

Timestep Collection Time: 2.25822
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.69538

Cumulative Model Updates: 146,974
Cumulative Timesteps: 1,226,502,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1226502056...
Checkpoint 1226502056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,058.65772
Policy Entropy: 1.68498
Value Function Loss: 0.04715

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.32144
Value Function Update Magnitude: 0.36093

Collected Steps per Second: 21,733.16801
Overall Steps per Second: 10,441.59038

Timestep Collection Time: 2.30137
Timestep Consumption Time: 2.48871
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.79007

Cumulative Model Updates: 146,980
Cumulative Timesteps: 1,226,552,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,278.77243
Policy Entropy: 1.69248
Value Function Loss: 0.04497

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.31892
Value Function Update Magnitude: 0.35555

Collected Steps per Second: 22,050.31332
Overall Steps per Second: 10,648.48825

Timestep Collection Time: 2.26890
Timestep Consumption Time: 2.42942
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.69832

Cumulative Model Updates: 146,986
Cumulative Timesteps: 1,226,602,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1226602102...
Checkpoint 1226602102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,870.86492
Policy Entropy: 1.70060
Value Function Loss: 0.05058

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.32637
Value Function Update Magnitude: 0.33861

Collected Steps per Second: 21,648.30911
Overall Steps per Second: 10,396.47758

Timestep Collection Time: 2.31168
Timestep Consumption Time: 2.50187
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.81355

Cumulative Model Updates: 146,992
Cumulative Timesteps: 1,226,652,146

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,528.60585
Policy Entropy: 1.71917
Value Function Loss: 0.05156

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.33414
Value Function Update Magnitude: 0.34053

Collected Steps per Second: 21,278.93552
Overall Steps per Second: 10,334.85488

Timestep Collection Time: 2.34974
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.83800

Cumulative Model Updates: 146,998
Cumulative Timesteps: 1,226,702,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1226702146...
Checkpoint 1226702146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,172.13931
Policy Entropy: 1.71371
Value Function Loss: 0.04972

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.33298
Value Function Update Magnitude: 0.36523

Collected Steps per Second: 21,350.44282
Overall Steps per Second: 10,353.55383

Timestep Collection Time: 2.34337
Timestep Consumption Time: 2.48898
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.83235

Cumulative Model Updates: 147,004
Cumulative Timesteps: 1,226,752,178

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,697.99418
Policy Entropy: 1.71183
Value Function Loss: 0.04872

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.33209
Value Function Update Magnitude: 0.36977

Collected Steps per Second: 21,843.01558
Overall Steps per Second: 10,380.82530

Timestep Collection Time: 2.28961
Timestep Consumption Time: 2.52812
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.81773

Cumulative Model Updates: 147,010
Cumulative Timesteps: 1,226,802,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1226802190...
Checkpoint 1226802190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,045.94581
Policy Entropy: 1.70376
Value Function Loss: 0.04780

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.32889
Value Function Update Magnitude: 0.37654

Collected Steps per Second: 21,623.51319
Overall Steps per Second: 10,535.58829

Timestep Collection Time: 2.31239
Timestep Consumption Time: 2.43362
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.74601

Cumulative Model Updates: 147,016
Cumulative Timesteps: 1,226,852,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,369.94008
Policy Entropy: 1.71344
Value Function Loss: 0.04845

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.32100
Value Function Update Magnitude: 0.36866

Collected Steps per Second: 21,567.19488
Overall Steps per Second: 10,432.03283

Timestep Collection Time: 2.31834
Timestep Consumption Time: 2.47459
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.79293

Cumulative Model Updates: 147,022
Cumulative Timesteps: 1,226,902,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1226902192...
Checkpoint 1226902192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,234.48647
Policy Entropy: 1.70226
Value Function Loss: 0.04996

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.32441
Value Function Update Magnitude: 0.35700

Collected Steps per Second: 21,252.54250
Overall Steps per Second: 10,604.11744

Timestep Collection Time: 2.35285
Timestep Consumption Time: 2.36268
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.71553

Cumulative Model Updates: 147,028
Cumulative Timesteps: 1,226,952,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,935.18877
Policy Entropy: 1.71566
Value Function Loss: 0.04934

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.32950
Value Function Update Magnitude: 0.35828

Collected Steps per Second: 21,615.68382
Overall Steps per Second: 10,517.48400

Timestep Collection Time: 2.31517
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.75817

Cumulative Model Updates: 147,034
Cumulative Timesteps: 1,227,002,240

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1227002240...
Checkpoint 1227002240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,365.00123
Policy Entropy: 1.70809
Value Function Loss: 0.05051

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.32873
Value Function Update Magnitude: 0.36346

Collected Steps per Second: 20,574.72278
Overall Steps per Second: 10,257.98483

Timestep Collection Time: 2.43017
Timestep Consumption Time: 2.44409
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.87425

Cumulative Model Updates: 147,040
Cumulative Timesteps: 1,227,052,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,036.64410
Policy Entropy: 1.71040
Value Function Loss: 0.04897

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.32340
Value Function Update Magnitude: 0.37185

Collected Steps per Second: 20,500.89050
Overall Steps per Second: 10,071.67652

Timestep Collection Time: 2.43970
Timestep Consumption Time: 2.52631
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.96601

Cumulative Model Updates: 147,046
Cumulative Timesteps: 1,227,102,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1227102256...
Checkpoint 1227102256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,176.42538
Policy Entropy: 1.69978
Value Function Loss: 0.04938

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.32604
Value Function Update Magnitude: 0.36684

Collected Steps per Second: 20,819.87866
Overall Steps per Second: 10,167.35916

Timestep Collection Time: 2.40251
Timestep Consumption Time: 2.51715
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.91966

Cumulative Model Updates: 147,052
Cumulative Timesteps: 1,227,152,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,078.53085
Policy Entropy: 1.70433
Value Function Loss: 0.04643

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08341
Policy Update Magnitude: 0.32683
Value Function Update Magnitude: 0.35307

Collected Steps per Second: 20,786.54280
Overall Steps per Second: 10,318.81448

Timestep Collection Time: 2.40598
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.84668

Cumulative Model Updates: 147,058
Cumulative Timesteps: 1,227,202,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1227202288...
Checkpoint 1227202288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,057.14840
Policy Entropy: 1.69141
Value Function Loss: 0.04939

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08251
Policy Update Magnitude: 0.32756
Value Function Update Magnitude: 0.35419

Collected Steps per Second: 21,823.00101
Overall Steps per Second: 10,672.46424

Timestep Collection Time: 2.29235
Timestep Consumption Time: 2.39504
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.68739

Cumulative Model Updates: 147,064
Cumulative Timesteps: 1,227,252,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,613.75061
Policy Entropy: 1.69207
Value Function Loss: 0.04624

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.32461
Value Function Update Magnitude: 0.37528

Collected Steps per Second: 21,683.27727
Overall Steps per Second: 10,521.15588

Timestep Collection Time: 2.30795
Timestep Consumption Time: 2.44856
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.75651

Cumulative Model Updates: 147,070
Cumulative Timesteps: 1,227,302,358

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1227302358...
Checkpoint 1227302358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,394.11861
Policy Entropy: 1.70556
Value Function Loss: 0.05135

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.32728
Value Function Update Magnitude: 0.39260

Collected Steps per Second: 21,171.83808
Overall Steps per Second: 10,259.47156

Timestep Collection Time: 2.36172
Timestep Consumption Time: 2.51202
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.87374

Cumulative Model Updates: 147,076
Cumulative Timesteps: 1,227,352,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,153.59593
Policy Entropy: 1.73512
Value Function Loss: 0.05835

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.33253
Value Function Update Magnitude: 0.37601

Collected Steps per Second: 21,677.50940
Overall Steps per Second: 10,429.21621

Timestep Collection Time: 2.30663
Timestep Consumption Time: 2.48779
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.79442

Cumulative Model Updates: 147,082
Cumulative Timesteps: 1,227,402,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1227402362...
Checkpoint 1227402362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,488.23558
Policy Entropy: 1.74424
Value Function Loss: 0.06343

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.33528
Value Function Update Magnitude: 0.40741

Collected Steps per Second: 21,498.12021
Overall Steps per Second: 10,529.32502

Timestep Collection Time: 2.32625
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.74959

Cumulative Model Updates: 147,088
Cumulative Timesteps: 1,227,452,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,766.54760
Policy Entropy: 1.75055
Value Function Loss: 0.06172

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.33492
Value Function Update Magnitude: 0.42973

Collected Steps per Second: 21,646.98962
Overall Steps per Second: 10,570.65743

Timestep Collection Time: 2.31081
Timestep Consumption Time: 2.42135
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.73216

Cumulative Model Updates: 147,094
Cumulative Timesteps: 1,227,502,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1227502394...
Checkpoint 1227502394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,949.85142
Policy Entropy: 1.74211
Value Function Loss: 0.05569

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.32551
Value Function Update Magnitude: 0.41530

Collected Steps per Second: 21,814.20973
Overall Steps per Second: 10,484.07247

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.47735
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.76971

Cumulative Model Updates: 147,100
Cumulative Timesteps: 1,227,552,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,208.64990
Policy Entropy: 1.73725
Value Function Loss: 0.05168

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.32189
Value Function Update Magnitude: 0.40212

Collected Steps per Second: 22,178.00057
Overall Steps per Second: 10,480.77354

Timestep Collection Time: 2.25611
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.77408

Cumulative Model Updates: 147,106
Cumulative Timesteps: 1,227,602,436

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1227602436...
Checkpoint 1227602436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,306.90228
Policy Entropy: 1.72228
Value Function Loss: 0.04914

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.32401
Value Function Update Magnitude: 0.37710

Collected Steps per Second: 21,933.57420
Overall Steps per Second: 10,645.22094

Timestep Collection Time: 2.28034
Timestep Consumption Time: 2.41811
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.69845

Cumulative Model Updates: 147,112
Cumulative Timesteps: 1,227,652,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,688.52998
Policy Entropy: 1.71589
Value Function Loss: 0.05091

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.32658
Value Function Update Magnitude: 0.37659

Collected Steps per Second: 22,143.58317
Overall Steps per Second: 10,508.51132

Timestep Collection Time: 2.25808
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.75824

Cumulative Model Updates: 147,118
Cumulative Timesteps: 1,227,702,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1227702454...
Checkpoint 1227702454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,197.02510
Policy Entropy: 1.71733
Value Function Loss: 0.04849

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.32177
Value Function Update Magnitude: 0.38031

Collected Steps per Second: 21,913.68247
Overall Steps per Second: 10,580.25323

Timestep Collection Time: 2.28223
Timestep Consumption Time: 2.44469
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.72692

Cumulative Model Updates: 147,124
Cumulative Timesteps: 1,227,752,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,007.63307
Policy Entropy: 1.70313
Value Function Loss: 0.04969

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.31776
Value Function Update Magnitude: 0.35724

Collected Steps per Second: 22,081.20622
Overall Steps per Second: 10,550.19610

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.47587
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.74114

Cumulative Model Updates: 147,130
Cumulative Timesteps: 1,227,802,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1227802486...
Checkpoint 1227802486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,979.16403
Policy Entropy: 1.71560
Value Function Loss: 0.05166

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.31541
Value Function Update Magnitude: 0.35259

Collected Steps per Second: 21,488.71106
Overall Steps per Second: 10,520.68294

Timestep Collection Time: 2.32755
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.75406

Cumulative Model Updates: 147,136
Cumulative Timesteps: 1,227,852,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,728.61123
Policy Entropy: 1.73046
Value Function Loss: 0.05720

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.32065
Value Function Update Magnitude: 0.36143

Collected Steps per Second: 21,564.87708
Overall Steps per Second: 10,490.52569

Timestep Collection Time: 2.32035
Timestep Consumption Time: 2.44948
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.76983

Cumulative Model Updates: 147,142
Cumulative Timesteps: 1,227,902,540

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1227902540...
Checkpoint 1227902540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,898.06737
Policy Entropy: 1.74901
Value Function Loss: 0.05256

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.32232
Value Function Update Magnitude: 0.35419

Collected Steps per Second: 21,132.01373
Overall Steps per Second: 10,240.41091

Timestep Collection Time: 2.36665
Timestep Consumption Time: 2.51714
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.88379

Cumulative Model Updates: 147,148
Cumulative Timesteps: 1,227,952,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,861.59064
Policy Entropy: 1.71782
Value Function Loss: 0.05285

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.32202
Value Function Update Magnitude: 0.35535

Collected Steps per Second: 21,417.30271
Overall Steps per Second: 10,500.66270

Timestep Collection Time: 2.33465
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.76179

Cumulative Model Updates: 147,154
Cumulative Timesteps: 1,228,002,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1228002554...
Checkpoint 1228002554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,579.26732
Policy Entropy: 1.70979
Value Function Loss: 0.04563

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.32270
Value Function Update Magnitude: 0.35479

Collected Steps per Second: 21,448.14565
Overall Steps per Second: 10,551.20188

Timestep Collection Time: 2.33186
Timestep Consumption Time: 2.40827
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.74012

Cumulative Model Updates: 147,160
Cumulative Timesteps: 1,228,052,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,301.66860
Policy Entropy: 1.71464
Value Function Loss: 0.04780

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.32117
Value Function Update Magnitude: 0.34769

Collected Steps per Second: 21,910.18428
Overall Steps per Second: 10,486.40523

Timestep Collection Time: 2.28250
Timestep Consumption Time: 2.48653
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.76903

Cumulative Model Updates: 147,166
Cumulative Timesteps: 1,228,102,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1228102578...
Checkpoint 1228102578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,179.32213
Policy Entropy: 1.72866
Value Function Loss: 0.04921

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.32231
Value Function Update Magnitude: 0.32129

Collected Steps per Second: 21,782.32116
Overall Steps per Second: 10,379.42117

Timestep Collection Time: 2.29553
Timestep Consumption Time: 2.52189
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.81742

Cumulative Model Updates: 147,172
Cumulative Timesteps: 1,228,152,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,713.52156
Policy Entropy: 1.73215
Value Function Loss: 0.04882

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.31737
Value Function Update Magnitude: 0.32557

Collected Steps per Second: 22,177.87770
Overall Steps per Second: 10,664.76222

Timestep Collection Time: 2.25567
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.69077

Cumulative Model Updates: 147,178
Cumulative Timesteps: 1,228,202,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1228202606...
Checkpoint 1228202606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,199.52876
Policy Entropy: 1.72743
Value Function Loss: 0.04697

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.31085
Value Function Update Magnitude: 0.34508

Collected Steps per Second: 21,853.53604
Overall Steps per Second: 10,616.92403

Timestep Collection Time: 2.28869
Timestep Consumption Time: 2.42228
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.71097

Cumulative Model Updates: 147,184
Cumulative Timesteps: 1,228,252,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,170.40208
Policy Entropy: 1.72113
Value Function Loss: 0.04555

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.30932
Value Function Update Magnitude: 0.33965

Collected Steps per Second: 21,960.90278
Overall Steps per Second: 10,589.80263

Timestep Collection Time: 2.27750
Timestep Consumption Time: 2.44553
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.72303

Cumulative Model Updates: 147,190
Cumulative Timesteps: 1,228,302,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1228302638...
Checkpoint 1228302638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,772.31597
Policy Entropy: 1.72010
Value Function Loss: 0.04690

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.31083
Value Function Update Magnitude: 0.34581

Collected Steps per Second: 21,321.23700
Overall Steps per Second: 10,637.84295

Timestep Collection Time: 2.34517
Timestep Consumption Time: 2.35522
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.70039

Cumulative Model Updates: 147,196
Cumulative Timesteps: 1,228,352,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,261.41043
Policy Entropy: 1.72423
Value Function Loss: 0.04849

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.31745
Value Function Update Magnitude: 0.35543

Collected Steps per Second: 21,438.84797
Overall Steps per Second: 10,508.21658

Timestep Collection Time: 2.33277
Timestep Consumption Time: 2.42655
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.75932

Cumulative Model Updates: 147,202
Cumulative Timesteps: 1,228,402,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1228402652...
Checkpoint 1228402652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,786.04241
Policy Entropy: 1.71224
Value Function Loss: 0.04717

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.31984
Value Function Update Magnitude: 0.36131

Collected Steps per Second: 20,977.43099
Overall Steps per Second: 10,583.01411

Timestep Collection Time: 2.38380
Timestep Consumption Time: 2.34132
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.72512

Cumulative Model Updates: 147,208
Cumulative Timesteps: 1,228,452,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,048.31475
Policy Entropy: 1.70043
Value Function Loss: 0.04707

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.31656
Value Function Update Magnitude: 0.35844

Collected Steps per Second: 21,242.65092
Overall Steps per Second: 10,452.33818

Timestep Collection Time: 2.35489
Timestep Consumption Time: 2.43103
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.78591

Cumulative Model Updates: 147,214
Cumulative Timesteps: 1,228,502,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1228502682...
Checkpoint 1228502682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,652.18190
Policy Entropy: 1.70881
Value Function Loss: 0.04608

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.31606
Value Function Update Magnitude: 0.36629

Collected Steps per Second: 21,108.07610
Overall Steps per Second: 10,560.01496

Timestep Collection Time: 2.36990
Timestep Consumption Time: 2.36722
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.73711

Cumulative Model Updates: 147,220
Cumulative Timesteps: 1,228,552,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,941.44466
Policy Entropy: 1.72658
Value Function Loss: 0.04905

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.32026
Value Function Update Magnitude: 0.36401

Collected Steps per Second: 21,244.71282
Overall Steps per Second: 10,474.91131

Timestep Collection Time: 2.35409
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.77446

Cumulative Model Updates: 147,226
Cumulative Timesteps: 1,228,602,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1228602718...
Checkpoint 1228602718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,041.70808
Policy Entropy: 1.74495
Value Function Loss: 0.05249

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.32691
Value Function Update Magnitude: 0.36962

Collected Steps per Second: 21,858.62935
Overall Steps per Second: 10,590.08351

Timestep Collection Time: 2.28843
Timestep Consumption Time: 2.43504
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.72348

Cumulative Model Updates: 147,232
Cumulative Timesteps: 1,228,652,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,837.36381
Policy Entropy: 1.72764
Value Function Loss: 0.04944

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.32228
Value Function Update Magnitude: 0.36415

Collected Steps per Second: 20,519.79600
Overall Steps per Second: 10,117.15014

Timestep Collection Time: 2.43784
Timestep Consumption Time: 2.50663
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.94448

Cumulative Model Updates: 147,238
Cumulative Timesteps: 1,228,702,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1228702764...
Checkpoint 1228702764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,639.60588
Policy Entropy: 1.70833
Value Function Loss: 0.04429

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.30878
Value Function Update Magnitude: 0.34240

Collected Steps per Second: 21,679.73336
Overall Steps per Second: 10,606.34981

Timestep Collection Time: 2.30732
Timestep Consumption Time: 2.40892
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.71623

Cumulative Model Updates: 147,244
Cumulative Timesteps: 1,228,752,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,228.03258
Policy Entropy: 1.70625
Value Function Loss: 0.04473

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07870
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.32830

Collected Steps per Second: 21,468.80136
Overall Steps per Second: 10,495.10641

Timestep Collection Time: 2.32952
Timestep Consumption Time: 2.43575
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.76527

Cumulative Model Updates: 147,250
Cumulative Timesteps: 1,228,802,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1228802798...
Checkpoint 1228802798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,170.76727
Policy Entropy: 1.71318
Value Function Loss: 0.04561

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.31269
Value Function Update Magnitude: 0.33433

Collected Steps per Second: 21,987.76944
Overall Steps per Second: 10,582.36589

Timestep Collection Time: 2.27481
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.72654

Cumulative Model Updates: 147,256
Cumulative Timesteps: 1,228,852,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,306.00581
Policy Entropy: 1.72018
Value Function Loss: 0.04700

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.31584
Value Function Update Magnitude: 0.34866

Collected Steps per Second: 21,918.15218
Overall Steps per Second: 10,470.54833

Timestep Collection Time: 2.28121
Timestep Consumption Time: 2.49408
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.77530

Cumulative Model Updates: 147,262
Cumulative Timesteps: 1,228,902,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1228902816...
Checkpoint 1228902816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,936.67586
Policy Entropy: 1.72559
Value Function Loss: 0.04549

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.31341
Value Function Update Magnitude: 0.35109

Collected Steps per Second: 21,663.83128
Overall Steps per Second: 10,533.40581

Timestep Collection Time: 2.30827
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.74737

Cumulative Model Updates: 147,268
Cumulative Timesteps: 1,228,952,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,713.81913
Policy Entropy: 1.72276
Value Function Loss: 0.04747

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.31935
Value Function Update Magnitude: 0.35863

Collected Steps per Second: 21,646.31689
Overall Steps per Second: 10,524.29404

Timestep Collection Time: 2.31116
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.75357

Cumulative Model Updates: 147,274
Cumulative Timesteps: 1,229,002,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1229002850...
Checkpoint 1229002850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,601.30571
Policy Entropy: 1.73752
Value Function Loss: 0.04667

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.32194
Value Function Update Magnitude: 0.34926

Collected Steps per Second: 21,958.81226
Overall Steps per Second: 10,617.71307

Timestep Collection Time: 2.27827
Timestep Consumption Time: 2.43348
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.71175

Cumulative Model Updates: 147,280
Cumulative Timesteps: 1,229,052,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,285.11549
Policy Entropy: 1.73903
Value Function Loss: 0.04776

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.31450
Value Function Update Magnitude: 0.33881

Collected Steps per Second: 22,000.26710
Overall Steps per Second: 10,504.93570

Timestep Collection Time: 2.27406
Timestep Consumption Time: 2.48846
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.76252

Cumulative Model Updates: 147,286
Cumulative Timesteps: 1,229,102,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1229102908...
Checkpoint 1229102908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,017.15512
Policy Entropy: 1.73121
Value Function Loss: 0.04928

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.31633
Value Function Update Magnitude: 0.35060

Collected Steps per Second: 21,957.38159
Overall Steps per Second: 10,623.39287

Timestep Collection Time: 2.27932
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.71111

Cumulative Model Updates: 147,292
Cumulative Timesteps: 1,229,152,956

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,955.35735
Policy Entropy: 1.73381
Value Function Loss: 0.04958

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.31520
Value Function Update Magnitude: 0.35034

Collected Steps per Second: 21,517.24271
Overall Steps per Second: 10,506.32975

Timestep Collection Time: 2.32409
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.75980

Cumulative Model Updates: 147,298
Cumulative Timesteps: 1,229,202,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1229202964...
Checkpoint 1229202964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,731.42647
Policy Entropy: 1.73153
Value Function Loss: 0.04844

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.31452
Value Function Update Magnitude: 0.35248

Collected Steps per Second: 20,798.10244
Overall Steps per Second: 10,532.27933

Timestep Collection Time: 2.40503
Timestep Consumption Time: 2.34418
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.74921

Cumulative Model Updates: 147,304
Cumulative Timesteps: 1,229,252,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,760.92233
Policy Entropy: 1.73392
Value Function Loss: 0.04981

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.31961
Value Function Update Magnitude: 0.35778

Collected Steps per Second: 21,057.08823
Overall Steps per Second: 10,531.31167

Timestep Collection Time: 2.37469
Timestep Consumption Time: 2.37344
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.74813

Cumulative Model Updates: 147,310
Cumulative Timesteps: 1,229,302,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1229302988...
Checkpoint 1229302988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,910.03260
Policy Entropy: 1.70904
Value Function Loss: 0.04898

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.32213
Value Function Update Magnitude: 0.36124

Collected Steps per Second: 20,956.46725
Overall Steps per Second: 10,549.04855

Timestep Collection Time: 2.38638
Timestep Consumption Time: 2.35434
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.74071

Cumulative Model Updates: 147,316
Cumulative Timesteps: 1,229,352,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,695.17059
Policy Entropy: 1.70436
Value Function Loss: 0.05049

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.32381
Value Function Update Magnitude: 0.36941

Collected Steps per Second: 21,342.61353
Overall Steps per Second: 10,605.76385

Timestep Collection Time: 2.34282
Timestep Consumption Time: 2.37178
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.71461

Cumulative Model Updates: 147,322
Cumulative Timesteps: 1,229,403,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1229403000...
Checkpoint 1229403000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,588.03181
Policy Entropy: 1.70142
Value Function Loss: 0.04994

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.31774
Value Function Update Magnitude: 0.36712

Collected Steps per Second: 21,562.68972
Overall Steps per Second: 10,579.34432

Timestep Collection Time: 2.31956
Timestep Consumption Time: 2.40814
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.72770

Cumulative Model Updates: 147,328
Cumulative Timesteps: 1,229,453,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,732.44099
Policy Entropy: 1.70523
Value Function Loss: 0.05358

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.31608
Value Function Update Magnitude: 0.35756

Collected Steps per Second: 22,088.33789
Overall Steps per Second: 10,537.33296

Timestep Collection Time: 2.26373
Timestep Consumption Time: 2.48149
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74522

Cumulative Model Updates: 147,334
Cumulative Timesteps: 1,229,503,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1229503018...
Checkpoint 1229503018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,440.89410
Policy Entropy: 1.70230
Value Function Loss: 0.05226

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.32244
Value Function Update Magnitude: 0.36353

Collected Steps per Second: 21,941.24614
Overall Steps per Second: 10,511.26417

Timestep Collection Time: 2.28100
Timestep Consumption Time: 2.48037
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.76137

Cumulative Model Updates: 147,340
Cumulative Timesteps: 1,229,553,066

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,372.29823
Policy Entropy: 1.70567
Value Function Loss: 0.04765

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.31763
Value Function Update Magnitude: 0.36441

Collected Steps per Second: 22,072.53794
Overall Steps per Second: 10,524.35049

Timestep Collection Time: 2.26780
Timestep Consumption Time: 2.48841
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.75621

Cumulative Model Updates: 147,346
Cumulative Timesteps: 1,229,603,122

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1229603122...
Checkpoint 1229603122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,377.85498
Policy Entropy: 1.70251
Value Function Loss: 0.04730

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.31654
Value Function Update Magnitude: 0.35442

Collected Steps per Second: 22,199.68600
Overall Steps per Second: 10,570.86676

Timestep Collection Time: 2.25237
Timestep Consumption Time: 2.47780
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.73017

Cumulative Model Updates: 147,352
Cumulative Timesteps: 1,229,653,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,595.01623
Policy Entropy: 1.70614
Value Function Loss: 0.04425

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.34052

Collected Steps per Second: 21,538.88351
Overall Steps per Second: 10,550.95798

Timestep Collection Time: 2.32240
Timestep Consumption Time: 2.41859
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.74099

Cumulative Model Updates: 147,358
Cumulative Timesteps: 1,229,703,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1229703146...
Checkpoint 1229703146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,112.33077
Policy Entropy: 1.69974
Value Function Loss: 0.04241

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.31128
Value Function Update Magnitude: 0.32885

Collected Steps per Second: 21,594.72469
Overall Steps per Second: 10,502.04231

Timestep Collection Time: 2.31603
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.76231

Cumulative Model Updates: 147,364
Cumulative Timesteps: 1,229,753,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,072.56969
Policy Entropy: 1.69662
Value Function Loss: 0.04168

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.30707
Value Function Update Magnitude: 0.31767

Collected Steps per Second: 21,651.61373
Overall Steps per Second: 10,525.74617

Timestep Collection Time: 2.31059
Timestep Consumption Time: 2.44233
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.75292

Cumulative Model Updates: 147,370
Cumulative Timesteps: 1,229,803,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1229803188...
Checkpoint 1229803188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,616.24682
Policy Entropy: 1.68858
Value Function Loss: 0.04129

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07222
Policy Update Magnitude: 0.30429
Value Function Update Magnitude: 0.31478

Collected Steps per Second: 21,377.42566
Overall Steps per Second: 10,322.17798

Timestep Collection Time: 2.34013
Timestep Consumption Time: 2.50633
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.84646

Cumulative Model Updates: 147,376
Cumulative Timesteps: 1,229,853,214

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,413.33550
Policy Entropy: 1.67997
Value Function Loss: 0.04447

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.30832
Value Function Update Magnitude: 0.32536

Collected Steps per Second: 22,067.47454
Overall Steps per Second: 10,458.03793

Timestep Collection Time: 2.26614
Timestep Consumption Time: 2.51564
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.78178

Cumulative Model Updates: 147,382
Cumulative Timesteps: 1,229,903,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1229903222...
Checkpoint 1229903222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,153.43519
Policy Entropy: 1.68926
Value Function Loss: 0.04453

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.31150
Value Function Update Magnitude: 0.32948

Collected Steps per Second: 21,891.73851
Overall Steps per Second: 10,444.69996

Timestep Collection Time: 2.28534
Timestep Consumption Time: 2.50465
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.78999

Cumulative Model Updates: 147,388
Cumulative Timesteps: 1,229,953,252

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,958.89275
Policy Entropy: 1.70267
Value Function Loss: 0.04950

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.31508
Value Function Update Magnitude: 0.34108

Collected Steps per Second: 22,104.52859
Overall Steps per Second: 10,499.91294

Timestep Collection Time: 2.26298
Timestep Consumption Time: 2.50106
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.76404

Cumulative Model Updates: 147,394
Cumulative Timesteps: 1,230,003,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1230003274...
Checkpoint 1230003274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,791.10070
Policy Entropy: 1.71647
Value Function Loss: 0.04848

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.31557
Value Function Update Magnitude: 0.34382

Collected Steps per Second: 21,210.61851
Overall Steps per Second: 10,611.86660

Timestep Collection Time: 2.35797
Timestep Consumption Time: 2.35506
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.71303

Cumulative Model Updates: 147,400
Cumulative Timesteps: 1,230,053,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,261.61021
Policy Entropy: 1.71348
Value Function Loss: 0.05088

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.31723
Value Function Update Magnitude: 0.35487

Collected Steps per Second: 21,468.93897
Overall Steps per Second: 10,479.67189

Timestep Collection Time: 2.32988
Timestep Consumption Time: 2.44317
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.77305

Cumulative Model Updates: 147,406
Cumulative Timesteps: 1,230,103,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1230103308...
Checkpoint 1230103308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,753.00554
Policy Entropy: 1.73018
Value Function Loss: 0.05103

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.32308
Value Function Update Magnitude: 0.36831

Collected Steps per Second: 21,346.80509
Overall Steps per Second: 10,626.20869

Timestep Collection Time: 2.34311
Timestep Consumption Time: 2.36393
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.70704

Cumulative Model Updates: 147,412
Cumulative Timesteps: 1,230,153,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,737.56765
Policy Entropy: 1.73941
Value Function Loss: 0.05282

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.32431
Value Function Update Magnitude: 0.36618

Collected Steps per Second: 21,283.82845
Overall Steps per Second: 10,513.99234

Timestep Collection Time: 2.35014
Timestep Consumption Time: 2.40733
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.75747

Cumulative Model Updates: 147,418
Cumulative Timesteps: 1,230,203,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1230203346...
Checkpoint 1230203346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,008.54784
Policy Entropy: 1.74612
Value Function Loss: 0.05425

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.32584
Value Function Update Magnitude: 0.36695

Collected Steps per Second: 20,849.15318
Overall Steps per Second: 10,220.84793

Timestep Collection Time: 2.39875
Timestep Consumption Time: 2.49438
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.89314

Cumulative Model Updates: 147,424
Cumulative Timesteps: 1,230,253,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,714.76217
Policy Entropy: 1.71718
Value Function Loss: 0.05229

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.32331
Value Function Update Magnitude: 0.36771

Collected Steps per Second: 21,502.73368
Overall Steps per Second: 10,396.19157

Timestep Collection Time: 2.32659
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.81215

Cumulative Model Updates: 147,430
Cumulative Timesteps: 1,230,303,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1230303386...
Checkpoint 1230303386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,302.07473
Policy Entropy: 1.70635
Value Function Loss: 0.04891

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.31979
Value Function Update Magnitude: 0.34769

Collected Steps per Second: 21,136.24624
Overall Steps per Second: 10,296.88113

Timestep Collection Time: 2.36702
Timestep Consumption Time: 2.49173
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.85875

Cumulative Model Updates: 147,436
Cumulative Timesteps: 1,230,353,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,184.10074
Policy Entropy: 1.69890
Value Function Loss: 0.04764

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.32252
Value Function Update Magnitude: 0.33196

Collected Steps per Second: 21,786.02360
Overall Steps per Second: 10,486.87395

Timestep Collection Time: 2.29588
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.76958

Cumulative Model Updates: 147,442
Cumulative Timesteps: 1,230,403,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1230403434...
Checkpoint 1230403434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,380.95048
Policy Entropy: 1.70786
Value Function Loss: 0.04615

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.32019
Value Function Update Magnitude: 0.32714

Collected Steps per Second: 21,603.59238
Overall Steps per Second: 10,478.09479

Timestep Collection Time: 2.31684
Timestep Consumption Time: 2.45999
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.77682

Cumulative Model Updates: 147,448
Cumulative Timesteps: 1,230,453,486

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,940.81367
Policy Entropy: 1.71084
Value Function Loss: 0.05446

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.32848
Value Function Update Magnitude: 0.31205

Collected Steps per Second: 22,169.70491
Overall Steps per Second: 10,472.29212

Timestep Collection Time: 2.25551
Timestep Consumption Time: 2.51938
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.77489

Cumulative Model Updates: 147,454
Cumulative Timesteps: 1,230,503,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1230503490...
Checkpoint 1230503490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,772.60128
Policy Entropy: 1.70612
Value Function Loss: 0.05799

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.33608
Value Function Update Magnitude: 0.34209

Collected Steps per Second: 21,958.66845
Overall Steps per Second: 10,594.46267

Timestep Collection Time: 2.27792
Timestep Consumption Time: 2.44342
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.72133

Cumulative Model Updates: 147,460
Cumulative Timesteps: 1,230,553,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,403.38616
Policy Entropy: 1.71312
Value Function Loss: 0.05713

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.33623
Value Function Update Magnitude: 0.37467

Collected Steps per Second: 21,815.61893
Overall Steps per Second: 10,604.24272

Timestep Collection Time: 2.29230
Timestep Consumption Time: 2.42355
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.71585

Cumulative Model Updates: 147,466
Cumulative Timesteps: 1,230,603,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1230603518...
Checkpoint 1230603518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,808.94665
Policy Entropy: 1.71057
Value Function Loss: 0.05237

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.32716
Value Function Update Magnitude: 0.34618

Collected Steps per Second: 22,015.61089
Overall Steps per Second: 10,556.69487

Timestep Collection Time: 2.27148
Timestep Consumption Time: 2.46561
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.73709

Cumulative Model Updates: 147,472
Cumulative Timesteps: 1,230,653,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,679.92793
Policy Entropy: 1.71652
Value Function Loss: 0.05436

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.32752
Value Function Update Magnitude: 0.33282

Collected Steps per Second: 22,103.04902
Overall Steps per Second: 10,455.18614

Timestep Collection Time: 2.26240
Timestep Consumption Time: 2.52049
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.78289

Cumulative Model Updates: 147,478
Cumulative Timesteps: 1,230,703,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1230703532...
Checkpoint 1230703532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,947.18735
Policy Entropy: 1.70633
Value Function Loss: 0.05418

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.32729
Value Function Update Magnitude: 0.33706

Collected Steps per Second: 21,927.41735
Overall Steps per Second: 10,608.79594

Timestep Collection Time: 2.28025
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.71307

Cumulative Model Updates: 147,484
Cumulative Timesteps: 1,230,753,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,447.79698
Policy Entropy: 1.71002
Value Function Loss: 0.05344

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.32622
Value Function Update Magnitude: 0.30822

Collected Steps per Second: 21,842.91753
Overall Steps per Second: 10,475.87566

Timestep Collection Time: 2.28907
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.77287

Cumulative Model Updates: 147,490
Cumulative Timesteps: 1,230,803,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1230803532...
Checkpoint 1230803532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,624.98915
Policy Entropy: 1.71212
Value Function Loss: 0.05411

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.33372
Value Function Update Magnitude: 0.33208

Collected Steps per Second: 21,401.01781
Overall Steps per Second: 10,343.67722

Timestep Collection Time: 2.33690
Timestep Consumption Time: 2.49813
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.83503

Cumulative Model Updates: 147,496
Cumulative Timesteps: 1,230,853,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,398.82557
Policy Entropy: 1.73609
Value Function Loss: 0.05385

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.33642
Value Function Update Magnitude: 0.38045

Collected Steps per Second: 21,906.75801
Overall Steps per Second: 10,469.42990

Timestep Collection Time: 2.28258
Timestep Consumption Time: 2.49361
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.77619

Cumulative Model Updates: 147,502
Cumulative Timesteps: 1,230,903,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1230903548...
Checkpoint 1230903548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,760.35520
Policy Entropy: 1.74916
Value Function Loss: 0.05345

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.33212
Value Function Update Magnitude: 0.40776

Collected Steps per Second: 21,306.94223
Overall Steps per Second: 10,443.68563

Timestep Collection Time: 2.34750
Timestep Consumption Time: 2.44181
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.78931

Cumulative Model Updates: 147,508
Cumulative Timesteps: 1,230,953,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,372.61770
Policy Entropy: 1.75036
Value Function Loss: 0.05137

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.32509
Value Function Update Magnitude: 0.39184

Collected Steps per Second: 21,626.20283
Overall Steps per Second: 10,576.12743

Timestep Collection Time: 2.31451
Timestep Consumption Time: 2.41823
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.73273

Cumulative Model Updates: 147,514
Cumulative Timesteps: 1,231,003,620

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1231003620...
Checkpoint 1231003620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,719.84263
Policy Entropy: 1.73604
Value Function Loss: 0.05135

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.32354
Value Function Update Magnitude: 0.37062

Collected Steps per Second: 20,834.46644
Overall Steps per Second: 10,500.04083

Timestep Collection Time: 2.40121
Timestep Consumption Time: 2.36334
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.76455

Cumulative Model Updates: 147,520
Cumulative Timesteps: 1,231,053,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,504.04154
Policy Entropy: 1.74990
Value Function Loss: 0.05181

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08090
Policy Update Magnitude: 0.32888
Value Function Update Magnitude: 0.37780

Collected Steps per Second: 21,530.34704
Overall Steps per Second: 10,501.55694

Timestep Collection Time: 2.32333
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.76329

Cumulative Model Updates: 147,526
Cumulative Timesteps: 1,231,103,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1231103670...
Checkpoint 1231103670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,523.59659
Policy Entropy: 1.74941
Value Function Loss: 0.05013

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.32771
Value Function Update Magnitude: 0.36955

Collected Steps per Second: 21,468.33821
Overall Steps per Second: 10,624.93497

Timestep Collection Time: 2.33041
Timestep Consumption Time: 2.37833
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.70873

Cumulative Model Updates: 147,532
Cumulative Timesteps: 1,231,153,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,757.36640
Policy Entropy: 1.73817
Value Function Loss: 0.05317

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.32993
Value Function Update Magnitude: 0.36735

Collected Steps per Second: 21,438.16683
Overall Steps per Second: 10,477.49465

Timestep Collection Time: 2.33415
Timestep Consumption Time: 2.44180
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.77595

Cumulative Model Updates: 147,538
Cumulative Timesteps: 1,231,203,740

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1231203740...
Checkpoint 1231203740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,166.25311
Policy Entropy: 1.71869
Value Function Loss: 0.05220

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.32915
Value Function Update Magnitude: 0.37177

Collected Steps per Second: 21,178.23886
Overall Steps per Second: 10,593.74804

Timestep Collection Time: 2.36176
Timestep Consumption Time: 2.35970
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.72146

Cumulative Model Updates: 147,544
Cumulative Timesteps: 1,231,253,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,248.03233
Policy Entropy: 1.70622
Value Function Loss: 0.05253

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.32866
Value Function Update Magnitude: 0.37333

Collected Steps per Second: 21,673.77213
Overall Steps per Second: 10,457.15089

Timestep Collection Time: 2.30841
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.78448

Cumulative Model Updates: 147,550
Cumulative Timesteps: 1,231,303,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1231303790...
Checkpoint 1231303790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,821.86600
Policy Entropy: 1.69446
Value Function Loss: 0.04989

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.32901
Value Function Update Magnitude: 0.36832

Collected Steps per Second: 21,990.66891
Overall Steps per Second: 10,673.74814

Timestep Collection Time: 2.27515
Timestep Consumption Time: 2.41224
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.68739

Cumulative Model Updates: 147,556
Cumulative Timesteps: 1,231,353,822

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,721.35231
Policy Entropy: 1.69906
Value Function Loss: 0.05020

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.32724
Value Function Update Magnitude: 0.34934

Collected Steps per Second: 21,721.01669
Overall Steps per Second: 10,480.69008

Timestep Collection Time: 2.30284
Timestep Consumption Time: 2.46975
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.77259

Cumulative Model Updates: 147,562
Cumulative Timesteps: 1,231,403,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1231403842...
Checkpoint 1231403842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,462.22715
Policy Entropy: 1.70000
Value Function Loss: 0.05187

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.32213
Value Function Update Magnitude: 0.32878

Collected Steps per Second: 21,267.60974
Overall Steps per Second: 10,275.56146

Timestep Collection Time: 2.35212
Timestep Consumption Time: 2.51613
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.86825

Cumulative Model Updates: 147,568
Cumulative Timesteps: 1,231,453,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,105.02662
Policy Entropy: 1.72276
Value Function Loss: 0.05341

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.32479
Value Function Update Magnitude: 0.33336

Collected Steps per Second: 21,616.81948
Overall Steps per Second: 10,360.83523

Timestep Collection Time: 2.31338
Timestep Consumption Time: 2.51325
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.82664

Cumulative Model Updates: 147,574
Cumulative Timesteps: 1,231,503,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1231503874...
Checkpoint 1231503874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,452.70600
Policy Entropy: 1.73231
Value Function Loss: 0.05181

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.32237
Value Function Update Magnitude: 0.35266

Collected Steps per Second: 21,693.47302
Overall Steps per Second: 10,355.66230

Timestep Collection Time: 2.30659
Timestep Consumption Time: 2.52535
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.83195

Cumulative Model Updates: 147,580
Cumulative Timesteps: 1,231,553,912

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,058.98083
Policy Entropy: 1.74443
Value Function Loss: 0.04858

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.31830
Value Function Update Magnitude: 0.34727

Collected Steps per Second: 22,370.65422
Overall Steps per Second: 10,512.51340

Timestep Collection Time: 2.23579
Timestep Consumption Time: 2.52197
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.75776

Cumulative Model Updates: 147,586
Cumulative Timesteps: 1,231,603,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1231603928...
Checkpoint 1231603928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,263.97157
Policy Entropy: 1.73847
Value Function Loss: 0.05087

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.32063
Value Function Update Magnitude: 0.34670

Collected Steps per Second: 22,006.19379
Overall Steps per Second: 10,446.37207

Timestep Collection Time: 2.27263
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.78750

Cumulative Model Updates: 147,592
Cumulative Timesteps: 1,231,653,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,699.68663
Policy Entropy: 1.73401
Value Function Loss: 0.05477

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.32693
Value Function Update Magnitude: 0.36462

Collected Steps per Second: 22,187.65545
Overall Steps per Second: 10,469.54391

Timestep Collection Time: 2.25432
Timestep Consumption Time: 2.52316
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.77748

Cumulative Model Updates: 147,598
Cumulative Timesteps: 1,231,703,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1231703958...
Checkpoint 1231703958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,962.00307
Policy Entropy: 1.72552
Value Function Loss: 0.05363

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.32801
Value Function Update Magnitude: 0.38041

Collected Steps per Second: 21,877.78904
Overall Steps per Second: 10,560.99055

Timestep Collection Time: 2.28652
Timestep Consumption Time: 2.45016
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.73668

Cumulative Model Updates: 147,604
Cumulative Timesteps: 1,231,753,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,881.72343
Policy Entropy: 1.74758
Value Function Loss: 0.05763

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.32506
Value Function Update Magnitude: 0.37028

Collected Steps per Second: 22,171.17287
Overall Steps per Second: 10,518.66264

Timestep Collection Time: 2.25707
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.75745

Cumulative Model Updates: 147,610
Cumulative Timesteps: 1,231,804,024

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1231804024...
Checkpoint 1231804024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,271.35940
Policy Entropy: 1.74223
Value Function Loss: 0.05424

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.32298
Value Function Update Magnitude: 0.36395

Collected Steps per Second: 21,811.77598
Overall Steps per Second: 10,602.67447

Timestep Collection Time: 2.29234
Timestep Consumption Time: 2.42345
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.71579

Cumulative Model Updates: 147,616
Cumulative Timesteps: 1,231,854,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,611.36207
Policy Entropy: 1.75250
Value Function Loss: 0.05502

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.32074
Value Function Update Magnitude: 0.35838

Collected Steps per Second: 22,117.40901
Overall Steps per Second: 10,480.62577

Timestep Collection Time: 2.26193
Timestep Consumption Time: 2.51145
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.77338

Cumulative Model Updates: 147,622
Cumulative Timesteps: 1,231,904,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1231904052...
Checkpoint 1231904052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,288.41810
Policy Entropy: 1.74429
Value Function Loss: 0.05145

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.31745
Value Function Update Magnitude: 0.36133

Collected Steps per Second: 21,487.08390
Overall Steps per Second: 10,367.89333

Timestep Collection Time: 2.32754
Timestep Consumption Time: 2.49620
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.82374

Cumulative Model Updates: 147,628
Cumulative Timesteps: 1,231,954,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,548.97762
Policy Entropy: 1.75113
Value Function Loss: 0.05120

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08462
Policy Update Magnitude: 0.31778
Value Function Update Magnitude: 0.36290

Collected Steps per Second: 21,865.94400
Overall Steps per Second: 10,475.97752

Timestep Collection Time: 2.28812
Timestep Consumption Time: 2.48775
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.77588

Cumulative Model Updates: 147,634
Cumulative Timesteps: 1,232,004,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1232004096...
Checkpoint 1232004096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,767.80263
Policy Entropy: 1.74126
Value Function Loss: 0.04847

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.31337
Value Function Update Magnitude: 0.35885

Collected Steps per Second: 21,265.17228
Overall Steps per Second: 10,450.59758

Timestep Collection Time: 2.35126
Timestep Consumption Time: 2.43315
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.78442

Cumulative Model Updates: 147,640
Cumulative Timesteps: 1,232,054,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,471.62306
Policy Entropy: 1.72879
Value Function Loss: 0.04462

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.31315
Value Function Update Magnitude: 0.34627

Collected Steps per Second: 21,949.69343
Overall Steps per Second: 10,461.08063

Timestep Collection Time: 2.27876
Timestep Consumption Time: 2.50259
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.78134

Cumulative Model Updates: 147,646
Cumulative Timesteps: 1,232,104,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1232104114...
Checkpoint 1232104114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,876.54403
Policy Entropy: 1.73180
Value Function Loss: 0.04707

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08018
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.33682

Collected Steps per Second: 21,015.28632
Overall Steps per Second: 10,349.72351

Timestep Collection Time: 2.38074
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.83414

Cumulative Model Updates: 147,652
Cumulative Timesteps: 1,232,154,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,545.90641
Policy Entropy: 1.74640
Value Function Loss: 0.04909

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.31940
Value Function Update Magnitude: 0.34993

Collected Steps per Second: 21,652.81667
Overall Steps per Second: 10,701.44483

Timestep Collection Time: 2.31111
Timestep Consumption Time: 2.36508
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.67619

Cumulative Model Updates: 147,658
Cumulative Timesteps: 1,232,204,188

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1232204188...
Checkpoint 1232204188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,929.51247
Policy Entropy: 1.73597
Value Function Loss: 0.05120

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.31822
Value Function Update Magnitude: 0.36901

Collected Steps per Second: 21,186.37336
Overall Steps per Second: 10,630.57551

Timestep Collection Time: 2.36048
Timestep Consumption Time: 2.34388
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.70435

Cumulative Model Updates: 147,664
Cumulative Timesteps: 1,232,254,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,793.64425
Policy Entropy: 1.73334
Value Function Loss: 0.04845

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.31139
Value Function Update Magnitude: 0.37116

Collected Steps per Second: 21,455.96184
Overall Steps per Second: 10,498.45801

Timestep Collection Time: 2.33082
Timestep Consumption Time: 2.43274
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.76356

Cumulative Model Updates: 147,670
Cumulative Timesteps: 1,232,304,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1232304208...
Checkpoint 1232304208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,198.81357
Policy Entropy: 1.71515
Value Function Loss: 0.04711

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.31790
Value Function Update Magnitude: 0.35288

Collected Steps per Second: 21,616.87728
Overall Steps per Second: 10,580.72059

Timestep Collection Time: 2.31514
Timestep Consumption Time: 2.41479
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.72992

Cumulative Model Updates: 147,676
Cumulative Timesteps: 1,232,354,254

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,955.13120
Policy Entropy: 1.71959
Value Function Loss: 0.04752

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.32119
Value Function Update Magnitude: 0.34960

Collected Steps per Second: 21,867.76969
Overall Steps per Second: 10,520.37158

Timestep Collection Time: 2.28720
Timestep Consumption Time: 2.46700
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.75420

Cumulative Model Updates: 147,682
Cumulative Timesteps: 1,232,404,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1232404270...
Checkpoint 1232404270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,677.21657
Policy Entropy: 1.72387
Value Function Loss: 0.04686

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.32080
Value Function Update Magnitude: 0.34370

Collected Steps per Second: 20,886.23764
Overall Steps per Second: 10,206.52784

Timestep Collection Time: 2.39517
Timestep Consumption Time: 2.50621
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.90137

Cumulative Model Updates: 147,688
Cumulative Timesteps: 1,232,454,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,124.98083
Policy Entropy: 1.72016
Value Function Loss: 0.05099

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.32326
Value Function Update Magnitude: 0.34711

Collected Steps per Second: 21,388.70691
Overall Steps per Second: 10,444.91670

Timestep Collection Time: 2.33862
Timestep Consumption Time: 2.45032
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.78893

Cumulative Model Updates: 147,694
Cumulative Timesteps: 1,232,504,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1232504316...
Checkpoint 1232504316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,955.72836
Policy Entropy: 1.73091
Value Function Loss: 0.05371

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.32631
Value Function Update Magnitude: 0.37342

Collected Steps per Second: 21,462.73593
Overall Steps per Second: 10,577.14426

Timestep Collection Time: 2.33158
Timestep Consumption Time: 2.39957
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.73114

Cumulative Model Updates: 147,700
Cumulative Timesteps: 1,232,554,358

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,686.17922
Policy Entropy: 1.74022
Value Function Loss: 0.05450

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.32775
Value Function Update Magnitude: 0.37628

Collected Steps per Second: 21,877.66332
Overall Steps per Second: 10,603.66283

Timestep Collection Time: 2.28580
Timestep Consumption Time: 2.43030
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.71611

Cumulative Model Updates: 147,706
Cumulative Timesteps: 1,232,604,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1232604366...
Checkpoint 1232604366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,385.99666
Policy Entropy: 1.74040
Value Function Loss: 0.05377

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.31890
Value Function Update Magnitude: 0.34706

Collected Steps per Second: 21,571.75836
Overall Steps per Second: 10,502.93199

Timestep Collection Time: 2.31812
Timestep Consumption Time: 2.44302
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.76115

Cumulative Model Updates: 147,712
Cumulative Timesteps: 1,232,654,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,384.09578
Policy Entropy: 1.74428
Value Function Loss: 0.05124

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.29464
Value Function Update Magnitude: 0.32609

Collected Steps per Second: 21,873.22043
Overall Steps per Second: 10,561.77140

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.44884
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.73538

Cumulative Model Updates: 147,718
Cumulative Timesteps: 1,232,704,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1232704386...
Checkpoint 1232704386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,352.08807
Policy Entropy: 1.75584
Value Function Loss: 0.04803

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.29030
Value Function Update Magnitude: 0.34344

Collected Steps per Second: 21,895.24820
Overall Steps per Second: 10,570.87927

Timestep Collection Time: 2.28378
Timestep Consumption Time: 2.44657
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.73035

Cumulative Model Updates: 147,724
Cumulative Timesteps: 1,232,754,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,051.78502
Policy Entropy: 1.76258
Value Function Loss: 0.04518

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.30581
Value Function Update Magnitude: 0.34381

Collected Steps per Second: 22,007.79601
Overall Steps per Second: 10,464.69853

Timestep Collection Time: 2.27383
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.78198

Cumulative Model Updates: 147,730
Cumulative Timesteps: 1,232,804,432

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1232804432...
Checkpoint 1232804432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,464.08466
Policy Entropy: 1.75672
Value Function Loss: 0.04946

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.31759
Value Function Update Magnitude: 0.32882

Collected Steps per Second: 22,162.51284
Overall Steps per Second: 10,645.10371

Timestep Collection Time: 2.25742
Timestep Consumption Time: 2.44240
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.69981

Cumulative Model Updates: 147,736
Cumulative Timesteps: 1,232,854,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,926.94371
Policy Entropy: 1.74963
Value Function Loss: 0.05131

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.31399
Value Function Update Magnitude: 0.32422

Collected Steps per Second: 22,118.81234
Overall Steps per Second: 10,473.23021

Timestep Collection Time: 2.26269
Timestep Consumption Time: 2.51597
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.77866

Cumulative Model Updates: 147,742
Cumulative Timesteps: 1,232,904,510

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1232904510...
Checkpoint 1232904510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,664.74588
Policy Entropy: 1.76474
Value Function Loss: 0.05200

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.29364
Value Function Update Magnitude: 0.34354

Collected Steps per Second: 21,934.56803
Overall Steps per Second: 10,671.39969

Timestep Collection Time: 2.28015
Timestep Consumption Time: 2.40659
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.68673

Cumulative Model Updates: 147,748
Cumulative Timesteps: 1,232,954,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,754.79178
Policy Entropy: 1.76545
Value Function Loss: 0.04953

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.30011
Value Function Update Magnitude: 0.33366

Collected Steps per Second: 21,810.54848
Overall Steps per Second: 10,445.08050

Timestep Collection Time: 2.29339
Timestep Consumption Time: 2.49547
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.78886

Cumulative Model Updates: 147,754
Cumulative Timesteps: 1,233,004,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1233004544...
Checkpoint 1233004544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,267.09532
Policy Entropy: 1.74823
Value Function Loss: 0.04812

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.29597
Value Function Update Magnitude: 0.32208

Collected Steps per Second: 21,619.60085
Overall Steps per Second: 10,561.00648

Timestep Collection Time: 2.31327
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.73553

Cumulative Model Updates: 147,760
Cumulative Timesteps: 1,233,054,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,310.21938
Policy Entropy: 1.73582
Value Function Loss: 0.05028

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.29394
Value Function Update Magnitude: 0.33289

Collected Steps per Second: 21,834.40338
Overall Steps per Second: 10,485.74598

Timestep Collection Time: 2.29033
Timestep Consumption Time: 2.47881
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.76914

Cumulative Model Updates: 147,766
Cumulative Timesteps: 1,233,104,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1233104564...
Checkpoint 1233104564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,978.77474
Policy Entropy: 1.73248
Value Function Loss: 0.05122

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.29659
Value Function Update Magnitude: 0.33807

Collected Steps per Second: 21,568.39514
Overall Steps per Second: 10,359.83759

Timestep Collection Time: 2.31858
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.82710

Cumulative Model Updates: 147,772
Cumulative Timesteps: 1,233,154,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,633.77798
Policy Entropy: 1.73557
Value Function Loss: 0.05167

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.31174
Value Function Update Magnitude: 0.34121

Collected Steps per Second: 22,017.98232
Overall Steps per Second: 10,459.75088

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.51076
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.78291

Cumulative Model Updates: 147,778
Cumulative Timesteps: 1,233,204,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1233204600...
Checkpoint 1233204600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,838.44009
Policy Entropy: 1.73448
Value Function Loss: 0.05328

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.31720
Value Function Update Magnitude: 0.35202

Collected Steps per Second: 22,230.50974
Overall Steps per Second: 10,472.98297

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.52594
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.77591

Cumulative Model Updates: 147,784
Cumulative Timesteps: 1,233,254,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,509.56412
Policy Entropy: 1.73394
Value Function Loss: 0.05143

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.31607
Value Function Update Magnitude: 0.35519

Collected Steps per Second: 22,267.55304
Overall Steps per Second: 10,475.50443

Timestep Collection Time: 2.24650
Timestep Consumption Time: 2.52883
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.77533

Cumulative Model Updates: 147,790
Cumulative Timesteps: 1,233,304,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1233304642...
Checkpoint 1233304642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,212.35696
Policy Entropy: 1.72969
Value Function Loss: 0.04865

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.30709
Value Function Update Magnitude: 0.35415

Collected Steps per Second: 22,322.46825
Overall Steps per Second: 10,692.76824

Timestep Collection Time: 2.24142
Timestep Consumption Time: 2.43782
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.67924

Cumulative Model Updates: 147,796
Cumulative Timesteps: 1,233,354,676

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,482.82175
Policy Entropy: 1.72107
Value Function Loss: 0.04495

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.30010
Value Function Update Magnitude: 0.33237

Collected Steps per Second: 22,235.64890
Overall Steps per Second: 10,520.60001

Timestep Collection Time: 2.25008
Timestep Consumption Time: 2.50554
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.75562

Cumulative Model Updates: 147,802
Cumulative Timesteps: 1,233,404,708

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1233404708...
Checkpoint 1233404708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,266.59014
Policy Entropy: 1.72237
Value Function Loss: 0.04498

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.30413
Value Function Update Magnitude: 0.33543

Collected Steps per Second: 21,934.78365
Overall Steps per Second: 10,497.99926

Timestep Collection Time: 2.28094
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.76586

Cumulative Model Updates: 147,808
Cumulative Timesteps: 1,233,454,740

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,223.15795
Policy Entropy: 1.73488
Value Function Loss: 0.05048

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.31363
Value Function Update Magnitude: 0.32956

Collected Steps per Second: 22,026.70717
Overall Steps per Second: 10,477.04156

Timestep Collection Time: 2.27097
Timestep Consumption Time: 2.50347
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.77444

Cumulative Model Updates: 147,814
Cumulative Timesteps: 1,233,504,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1233504762...
Checkpoint 1233504762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,780.44950
Policy Entropy: 1.74295
Value Function Loss: 0.05060

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.29998
Value Function Update Magnitude: 0.32739

Collected Steps per Second: 22,174.79841
Overall Steps per Second: 10,711.56809

Timestep Collection Time: 2.25517
Timestep Consumption Time: 2.41342
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.66860

Cumulative Model Updates: 147,820
Cumulative Timesteps: 1,233,554,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,681.12251
Policy Entropy: 1.73877
Value Function Loss: 0.05338

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.35270

Collected Steps per Second: 21,531.68933
Overall Steps per Second: 10,395.97584

Timestep Collection Time: 2.32430
Timestep Consumption Time: 2.48968
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.81398

Cumulative Model Updates: 147,826
Cumulative Timesteps: 1,233,604,816

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1233604816...
Checkpoint 1233604816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,892.50626
Policy Entropy: 1.73592
Value Function Loss: 0.05007

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.31942
Value Function Update Magnitude: 0.35243

Collected Steps per Second: 21,471.59221
Overall Steps per Second: 10,410.16045

Timestep Collection Time: 2.33080
Timestep Consumption Time: 2.47662
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.80742

Cumulative Model Updates: 147,832
Cumulative Timesteps: 1,233,654,862

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,045.40262
Policy Entropy: 1.73353
Value Function Loss: 0.05406

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.31711
Value Function Update Magnitude: 0.35431

Collected Steps per Second: 21,594.52561
Overall Steps per Second: 10,424.35068

Timestep Collection Time: 2.31633
Timestep Consumption Time: 2.48205
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.79838

Cumulative Model Updates: 147,838
Cumulative Timesteps: 1,233,704,882

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1233704882...
Checkpoint 1233704882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,782.07620
Policy Entropy: 1.74646
Value Function Loss: 0.05506

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.31937
Value Function Update Magnitude: 0.36002

Collected Steps per Second: 20,793.28940
Overall Steps per Second: 10,511.70008

Timestep Collection Time: 2.40491
Timestep Consumption Time: 2.35226
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.75718

Cumulative Model Updates: 147,844
Cumulative Timesteps: 1,233,754,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,538.97740
Policy Entropy: 1.73997
Value Function Loss: 0.05672

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.32268
Value Function Update Magnitude: 0.36739

Collected Steps per Second: 20,884.10142
Overall Steps per Second: 10,403.13663

Timestep Collection Time: 2.39426
Timestep Consumption Time: 2.41217
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.80643

Cumulative Model Updates: 147,850
Cumulative Timesteps: 1,233,804,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1233804890...
Checkpoint 1233804890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,769.93507
Policy Entropy: 1.74201
Value Function Loss: 0.05163

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.31271
Value Function Update Magnitude: 0.38002

Collected Steps per Second: 21,640.53946
Overall Steps per Second: 10,642.72541

Timestep Collection Time: 2.31122
Timestep Consumption Time: 2.38833
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.69955

Cumulative Model Updates: 147,856
Cumulative Timesteps: 1,233,854,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,602.22224
Policy Entropy: 1.73207
Value Function Loss: 0.05237

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.31656
Value Function Update Magnitude: 0.37772

Collected Steps per Second: 21,474.65356
Overall Steps per Second: 10,463.95727

Timestep Collection Time: 2.32898
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.77964

Cumulative Model Updates: 147,862
Cumulative Timesteps: 1,233,904,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1233904920...
Checkpoint 1233904920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,286.13064
Policy Entropy: 1.73223
Value Function Loss: 0.04814

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.29824
Value Function Update Magnitude: 0.37799

Collected Steps per Second: 21,004.42783
Overall Steps per Second: 10,547.47835

Timestep Collection Time: 2.38169
Timestep Consumption Time: 2.36125
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.74293

Cumulative Model Updates: 147,868
Cumulative Timesteps: 1,233,954,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,470.06355
Policy Entropy: 1.73590
Value Function Loss: 0.05153

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.30997
Value Function Update Magnitude: 0.36952

Collected Steps per Second: 21,397.77270
Overall Steps per Second: 10,522.79054

Timestep Collection Time: 2.33669
Timestep Consumption Time: 2.41490
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.75159

Cumulative Model Updates: 147,874
Cumulative Timesteps: 1,234,004,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1234004946...
Checkpoint 1234004946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,855.02500
Policy Entropy: 1.73496
Value Function Loss: 0.05032

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.31904
Value Function Update Magnitude: 0.37690

Collected Steps per Second: 21,899.35756
Overall Steps per Second: 10,654.84825

Timestep Collection Time: 2.28317
Timestep Consumption Time: 2.40953
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.69270

Cumulative Model Updates: 147,880
Cumulative Timesteps: 1,234,054,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,397.16532
Policy Entropy: 1.71696
Value Function Loss: 0.05172

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.31808
Value Function Update Magnitude: 0.37038

Collected Steps per Second: 21,977.58251
Overall Steps per Second: 10,496.13538

Timestep Collection Time: 2.27550
Timestep Consumption Time: 2.48911
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.76461

Cumulative Model Updates: 147,886
Cumulative Timesteps: 1,234,104,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1234104956...
Checkpoint 1234104956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,939.29337
Policy Entropy: 1.71570
Value Function Loss: 0.05121

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.31879
Value Function Update Magnitude: 0.36772

Collected Steps per Second: 21,943.20253
Overall Steps per Second: 10,541.43849

Timestep Collection Time: 2.27970
Timestep Consumption Time: 2.46576
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.74546

Cumulative Model Updates: 147,892
Cumulative Timesteps: 1,234,154,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,769.36608
Policy Entropy: 1.71228
Value Function Loss: 0.05124

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.32204
Value Function Update Magnitude: 0.35836

Collected Steps per Second: 21,683.42281
Overall Steps per Second: 10,492.30510

Timestep Collection Time: 2.30665
Timestep Consumption Time: 2.46028
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.76692

Cumulative Model Updates: 147,898
Cumulative Timesteps: 1,234,204,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1234204996...
Checkpoint 1234204996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,767.75719
Policy Entropy: 1.72982
Value Function Loss: 0.05316

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.32157
Value Function Update Magnitude: 0.35133

Collected Steps per Second: 21,456.12835
Overall Steps per Second: 10,365.05102

Timestep Collection Time: 2.33211
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.82757

Cumulative Model Updates: 147,904
Cumulative Timesteps: 1,234,255,034

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,884.84146
Policy Entropy: 1.74351
Value Function Loss: 0.05707

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.32279
Value Function Update Magnitude: 0.35212

Collected Steps per Second: 22,005.30330
Overall Steps per Second: 10,652.81501

Timestep Collection Time: 2.27391
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.69716

Cumulative Model Updates: 147,910
Cumulative Timesteps: 1,234,305,072

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1234305072...
Checkpoint 1234305072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,525.03948
Policy Entropy: 1.76691
Value Function Loss: 0.05697

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.32582
Value Function Update Magnitude: 0.36092

Collected Steps per Second: 21,073.53793
Overall Steps per Second: 10,245.79020

Timestep Collection Time: 2.37359
Timestep Consumption Time: 2.50841
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.88201

Cumulative Model Updates: 147,916
Cumulative Timesteps: 1,234,355,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,224.58025
Policy Entropy: 1.78428
Value Function Loss: 0.05796

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.32618
Value Function Update Magnitude: 0.36810

Collected Steps per Second: 21,853.47606
Overall Steps per Second: 10,596.00887

Timestep Collection Time: 2.28879
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.72046

Cumulative Model Updates: 147,922
Cumulative Timesteps: 1,234,405,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1234405110...
Checkpoint 1234405110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,416.75432
Policy Entropy: 1.76968
Value Function Loss: 0.05619

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.32034
Value Function Update Magnitude: 0.36844

Collected Steps per Second: 21,564.08000
Overall Steps per Second: 10,529.57701

Timestep Collection Time: 2.31951
Timestep Consumption Time: 2.43073
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.75024

Cumulative Model Updates: 147,928
Cumulative Timesteps: 1,234,455,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,049.19051
Policy Entropy: 1.74533
Value Function Loss: 0.05085

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.31517
Value Function Update Magnitude: 0.36400

Collected Steps per Second: 21,775.88908
Overall Steps per Second: 10,450.89312

Timestep Collection Time: 2.29612
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.78428

Cumulative Model Updates: 147,934
Cumulative Timesteps: 1,234,505,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1234505128...
Checkpoint 1234505128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,000.51400
Policy Entropy: 1.72056
Value Function Loss: 0.04898

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.31805
Value Function Update Magnitude: 0.33696

Collected Steps per Second: 21,818.67266
Overall Steps per Second: 10,551.70198

Timestep Collection Time: 2.29217
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.73971

Cumulative Model Updates: 147,940
Cumulative Timesteps: 1,234,555,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,564.52450
Policy Entropy: 1.71936
Value Function Loss: 0.04548

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.31491
Value Function Update Magnitude: 0.33687

Collected Steps per Second: 21,924.27057
Overall Steps per Second: 10,590.54680

Timestep Collection Time: 2.28222
Timestep Consumption Time: 2.44237
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.72459

Cumulative Model Updates: 147,946
Cumulative Timesteps: 1,234,605,176

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1234605176...
Checkpoint 1234605176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,137.66491
Policy Entropy: 1.71752
Value Function Loss: 0.04995

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.31880
Value Function Update Magnitude: 0.34311

Collected Steps per Second: 21,870.59570
Overall Steps per Second: 10,593.27037

Timestep Collection Time: 2.28718
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.72205

Cumulative Model Updates: 147,952
Cumulative Timesteps: 1,234,655,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,181.16929
Policy Entropy: 1.72512
Value Function Loss: 0.05575

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.32626
Value Function Update Magnitude: 0.35161

Collected Steps per Second: 22,101.86246
Overall Steps per Second: 10,473.34502

Timestep Collection Time: 2.26307
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.77574

Cumulative Model Updates: 147,958
Cumulative Timesteps: 1,234,705,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1234705216...
Checkpoint 1234705216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,520.93230
Policy Entropy: 1.71671
Value Function Loss: 0.05533

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.32596
Value Function Update Magnitude: 0.37762

Collected Steps per Second: 21,628.98131
Overall Steps per Second: 10,557.67083

Timestep Collection Time: 2.31208
Timestep Consumption Time: 2.42457
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.73665

Cumulative Model Updates: 147,964
Cumulative Timesteps: 1,234,755,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,814.15974
Policy Entropy: 1.70404
Value Function Loss: 0.05544

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.32503
Value Function Update Magnitude: 0.37918

Collected Steps per Second: 22,286.81683
Overall Steps per Second: 10,528.87697

Timestep Collection Time: 2.24474
Timestep Consumption Time: 2.50677
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.75150

Cumulative Model Updates: 147,970
Cumulative Timesteps: 1,234,805,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1234805252...
Checkpoint 1234805252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,788.48811
Policy Entropy: 1.69620
Value Function Loss: 0.05451

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.32645
Value Function Update Magnitude: 0.35605

Collected Steps per Second: 21,627.09936
Overall Steps per Second: 10,589.35982

Timestep Collection Time: 2.31265
Timestep Consumption Time: 2.41058
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.72323

Cumulative Model Updates: 147,976
Cumulative Timesteps: 1,234,855,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,611.26707
Policy Entropy: 1.71594
Value Function Loss: 0.05495

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.32939
Value Function Update Magnitude: 0.36294

Collected Steps per Second: 21,335.35877
Overall Steps per Second: 10,453.90129

Timestep Collection Time: 2.34353
Timestep Consumption Time: 2.43938
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.78290

Cumulative Model Updates: 147,982
Cumulative Timesteps: 1,234,905,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1234905268...
Checkpoint 1234905268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,111.86580
Policy Entropy: 1.72387
Value Function Loss: 0.05438

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07971
Policy Update Magnitude: 0.33085
Value Function Update Magnitude: 0.36929

Collected Steps per Second: 21,243.76578
Overall Steps per Second: 10,263.87392

Timestep Collection Time: 2.35410
Timestep Consumption Time: 2.51833
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.87243

Cumulative Model Updates: 147,988
Cumulative Timesteps: 1,234,955,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,544.72060
Policy Entropy: 1.72853
Value Function Loss: 0.05086

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.32721
Value Function Update Magnitude: 0.37855

Collected Steps per Second: 21,698.78505
Overall Steps per Second: 10,459.29997

Timestep Collection Time: 2.30612
Timestep Consumption Time: 2.47814
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.78426

Cumulative Model Updates: 147,994
Cumulative Timesteps: 1,235,005,318

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1235005318...
Checkpoint 1235005318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,718.27231
Policy Entropy: 1.71477
Value Function Loss: 0.04911

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.32407
Value Function Update Magnitude: 0.38322

Collected Steps per Second: 21,213.47813
Overall Steps per Second: 10,276.26613

Timestep Collection Time: 2.35784
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.86733

Cumulative Model Updates: 148,000
Cumulative Timesteps: 1,235,055,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,714.49025
Policy Entropy: 1.72313
Value Function Loss: 0.04868

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.32394
Value Function Update Magnitude: 0.36487

Collected Steps per Second: 21,950.24485
Overall Steps per Second: 10,407.60621

Timestep Collection Time: 2.27897
Timestep Consumption Time: 2.52751
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.80648

Cumulative Model Updates: 148,006
Cumulative Timesteps: 1,235,105,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1235105360...
Checkpoint 1235105360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,467.77428
Policy Entropy: 1.72134
Value Function Loss: 0.05255

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.32814
Value Function Update Magnitude: 0.34397

Collected Steps per Second: 21,906.76554
Overall Steps per Second: 10,562.49555

Timestep Collection Time: 2.28295
Timestep Consumption Time: 2.45192
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.73487

Cumulative Model Updates: 148,012
Cumulative Timesteps: 1,235,155,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,459.16428
Policy Entropy: 1.72595
Value Function Loss: 0.04892

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.32423
Value Function Update Magnitude: 0.35049

Collected Steps per Second: 22,148.12945
Overall Steps per Second: 10,481.96151

Timestep Collection Time: 2.25843
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.77201

Cumulative Model Updates: 148,018
Cumulative Timesteps: 1,235,205,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1235205392...
Checkpoint 1235205392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,692.31750
Policy Entropy: 1.71705
Value Function Loss: 0.04602

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.31013
Value Function Update Magnitude: 0.34465

Collected Steps per Second: 21,212.86280
Overall Steps per Second: 10,586.85464

Timestep Collection Time: 2.35734
Timestep Consumption Time: 2.36606
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.72340

Cumulative Model Updates: 148,024
Cumulative Timesteps: 1,235,255,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,196.96828
Policy Entropy: 1.70442
Value Function Loss: 0.04598

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.30970
Value Function Update Magnitude: 0.32257

Collected Steps per Second: 21,499.02980
Overall Steps per Second: 10,493.28376

Timestep Collection Time: 2.32690
Timestep Consumption Time: 2.44053
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.76743

Cumulative Model Updates: 148,030
Cumulative Timesteps: 1,235,305,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1235305424...
Checkpoint 1235305424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,114.41082
Policy Entropy: 1.70470
Value Function Loss: 0.05033

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.31519
Value Function Update Magnitude: 0.32001

Collected Steps per Second: 21,149.81377
Overall Steps per Second: 10,579.84360

Timestep Collection Time: 2.36437
Timestep Consumption Time: 2.36216
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.72653

Cumulative Model Updates: 148,036
Cumulative Timesteps: 1,235,355,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,338.95302
Policy Entropy: 1.71002
Value Function Loss: 0.05216

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.31880
Value Function Update Magnitude: 0.31596

Collected Steps per Second: 21,407.03198
Overall Steps per Second: 10,531.12429

Timestep Collection Time: 2.33671
Timestep Consumption Time: 2.41321
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.74992

Cumulative Model Updates: 148,042
Cumulative Timesteps: 1,235,405,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1235405452...
Checkpoint 1235405452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,983.04627
Policy Entropy: 1.73030
Value Function Loss: 0.05653

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.31737
Value Function Update Magnitude: 0.32542

Collected Steps per Second: 21,294.41295
Overall Steps per Second: 10,389.23567

Timestep Collection Time: 2.34832
Timestep Consumption Time: 2.46494
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.81325

Cumulative Model Updates: 148,048
Cumulative Timesteps: 1,235,455,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,037.42259
Policy Entropy: 1.71268
Value Function Loss: 0.05589

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.31878
Value Function Update Magnitude: 0.34458

Collected Steps per Second: 21,723.94136
Overall Steps per Second: 10,465.56294

Timestep Collection Time: 2.30271
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.77987

Cumulative Model Updates: 148,054
Cumulative Timesteps: 1,235,505,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1235505482...
Checkpoint 1235505482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,989.51567
Policy Entropy: 1.70691
Value Function Loss: 0.05553

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.31817
Value Function Update Magnitude: 0.35621

Collected Steps per Second: 21,740.97914
Overall Steps per Second: 10,444.76166

Timestep Collection Time: 2.30008
Timestep Consumption Time: 2.48758
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.78766

Cumulative Model Updates: 148,060
Cumulative Timesteps: 1,235,555,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,801.22308
Policy Entropy: 1.71635
Value Function Loss: 0.05139

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.31361
Value Function Update Magnitude: 0.33624

Collected Steps per Second: 21,817.77563
Overall Steps per Second: 10,472.41828

Timestep Collection Time: 2.29180
Timestep Consumption Time: 2.48284
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.77464

Cumulative Model Updates: 148,066
Cumulative Timesteps: 1,235,605,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1235605490...
Checkpoint 1235605490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,339.80416
Policy Entropy: 1.71385
Value Function Loss: 0.04855

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.30890
Value Function Update Magnitude: 0.31589

Collected Steps per Second: 21,455.35295
Overall Steps per Second: 10,382.38744

Timestep Collection Time: 2.33229
Timestep Consumption Time: 2.48742
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.81970

Cumulative Model Updates: 148,072
Cumulative Timesteps: 1,235,655,530

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,382.51713
Policy Entropy: 1.73519
Value Function Loss: 0.05200

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.31069
Value Function Update Magnitude: 0.29235

Collected Steps per Second: 22,195.07035
Overall Steps per Second: 10,635.34906

Timestep Collection Time: 2.25284
Timestep Consumption Time: 2.44865
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.70149

Cumulative Model Updates: 148,078
Cumulative Timesteps: 1,235,705,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1235705532...
Checkpoint 1235705532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,948.77687
Policy Entropy: 1.73738
Value Function Loss: 0.05460

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.31720
Value Function Update Magnitude: 0.28064

Collected Steps per Second: 21,796.30581
Overall Steps per Second: 10,366.65289

Timestep Collection Time: 2.29488
Timestep Consumption Time: 2.53020
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.82509

Cumulative Model Updates: 148,084
Cumulative Timesteps: 1,235,755,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,823.97486
Policy Entropy: 1.75847
Value Function Loss: 0.05588

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.31879
Value Function Update Magnitude: 0.29728

Collected Steps per Second: 22,157.90299
Overall Steps per Second: 10,523.75156

Timestep Collection Time: 2.25752
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.75325

Cumulative Model Updates: 148,090
Cumulative Timesteps: 1,235,805,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1235805574...
Checkpoint 1235805574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,268.43651
Policy Entropy: 1.73832
Value Function Loss: 0.05536

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.31731
Value Function Update Magnitude: 0.33451

Collected Steps per Second: 21,897.54541
Overall Steps per Second: 10,481.96620

Timestep Collection Time: 2.28510
Timestep Consumption Time: 2.48863
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.77372

Cumulative Model Updates: 148,096
Cumulative Timesteps: 1,235,855,612

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,784.39315
Policy Entropy: 1.73736
Value Function Loss: 0.05043

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.29969
Value Function Update Magnitude: 0.35384

Collected Steps per Second: 22,107.88832
Overall Steps per Second: 10,436.49314

Timestep Collection Time: 2.26236
Timestep Consumption Time: 2.53005
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.79241

Cumulative Model Updates: 148,102
Cumulative Timesteps: 1,235,905,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1235905628...
Checkpoint 1235905628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,286.91550
Policy Entropy: 1.72726
Value Function Loss: 0.04947

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.28135
Value Function Update Magnitude: 0.34929

Collected Steps per Second: 21,836.13895
Overall Steps per Second: 10,563.96878

Timestep Collection Time: 2.29079
Timestep Consumption Time: 2.44436
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.73515

Cumulative Model Updates: 148,108
Cumulative Timesteps: 1,235,955,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,428.24853
Policy Entropy: 1.74590
Value Function Loss: 0.04721

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.29708
Value Function Update Magnitude: 0.34965

Collected Steps per Second: 22,047.58311
Overall Steps per Second: 10,554.31485

Timestep Collection Time: 2.26873
Timestep Consumption Time: 2.47056
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.73929

Cumulative Model Updates: 148,114
Cumulative Timesteps: 1,236,005,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1236005670...
Checkpoint 1236005670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,104.21161
Policy Entropy: 1.73941
Value Function Loss: 0.04753

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.30782
Value Function Update Magnitude: 0.36372

Collected Steps per Second: 21,829.96656
Overall Steps per Second: 10,590.87603

Timestep Collection Time: 2.29135
Timestep Consumption Time: 2.43159
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.72293

Cumulative Model Updates: 148,120
Cumulative Timesteps: 1,236,055,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,889.93070
Policy Entropy: 1.74332
Value Function Loss: 0.05000

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.31070
Value Function Update Magnitude: 0.33751

Collected Steps per Second: 21,481.30827
Overall Steps per Second: 10,486.35867

Timestep Collection Time: 2.32816
Timestep Consumption Time: 2.44108
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.76924

Cumulative Model Updates: 148,126
Cumulative Timesteps: 1,236,105,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1236105702...
Checkpoint 1236105702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,987.98470
Policy Entropy: 1.73877
Value Function Loss: 0.05191

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.31529
Value Function Update Magnitude: 0.33383

Collected Steps per Second: 21,048.10666
Overall Steps per Second: 10,264.17105

Timestep Collection Time: 2.37608
Timestep Consumption Time: 2.49640
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.87248

Cumulative Model Updates: 148,132
Cumulative Timesteps: 1,236,155,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,097.25436
Policy Entropy: 1.73904
Value Function Loss: 0.05199

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.31451
Value Function Update Magnitude: 0.32584

Collected Steps per Second: 21,652.11191
Overall Steps per Second: 10,399.29127

Timestep Collection Time: 2.30943
Timestep Consumption Time: 2.49898
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.80840

Cumulative Model Updates: 148,138
Cumulative Timesteps: 1,236,205,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1236205718...
Checkpoint 1236205718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,061.11216
Policy Entropy: 1.72571
Value Function Loss: 0.05091

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.31765
Value Function Update Magnitude: 0.31956

Collected Steps per Second: 21,423.46968
Overall Steps per Second: 10,363.81739

Timestep Collection Time: 2.33492
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.82660

Cumulative Model Updates: 148,144
Cumulative Timesteps: 1,236,255,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,791.20418
Policy Entropy: 1.72528
Value Function Loss: 0.05848

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.31652
Value Function Update Magnitude: 0.29288

Collected Steps per Second: 21,888.51564
Overall Steps per Second: 10,458.99157

Timestep Collection Time: 2.28467
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.78134

Cumulative Model Updates: 148,150
Cumulative Timesteps: 1,236,305,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1236305748...
Checkpoint 1236305748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,258.02353
Policy Entropy: 1.72168
Value Function Loss: 0.05793

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.32203
Value Function Update Magnitude: 0.26308

Collected Steps per Second: 21,998.56758
Overall Steps per Second: 10,454.34200

Timestep Collection Time: 2.27433
Timestep Consumption Time: 2.51143
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.78576

Cumulative Model Updates: 148,156
Cumulative Timesteps: 1,236,355,780

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,383.60505
Policy Entropy: 1.71789
Value Function Loss: 0.06062

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.32946
Value Function Update Magnitude: 0.26032

Collected Steps per Second: 22,112.64278
Overall Steps per Second: 10,473.52767

Timestep Collection Time: 2.26115
Timestep Consumption Time: 2.51279
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.77394

Cumulative Model Updates: 148,162
Cumulative Timesteps: 1,236,405,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1236405780...
Checkpoint 1236405780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,123.04290
Policy Entropy: 1.72867
Value Function Loss: 0.05231

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.32507
Value Function Update Magnitude: 0.29269

Collected Steps per Second: 21,931.03159
Overall Steps per Second: 10,605.83707

Timestep Collection Time: 2.28015
Timestep Consumption Time: 2.43480
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.71495

Cumulative Model Updates: 148,168
Cumulative Timesteps: 1,236,455,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,123.41985
Policy Entropy: 1.70412
Value Function Loss: 0.05067

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.31870
Value Function Update Magnitude: 0.33547

Collected Steps per Second: 22,238.06208
Overall Steps per Second: 10,496.24213

Timestep Collection Time: 2.24876
Timestep Consumption Time: 2.51561
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.76437

Cumulative Model Updates: 148,174
Cumulative Timesteps: 1,236,505,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1236505794...
Checkpoint 1236505794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,057.87395
Policy Entropy: 1.71113
Value Function Loss: 0.05088

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07771
Policy Update Magnitude: 0.32171
Value Function Update Magnitude: 0.34358

Collected Steps per Second: 22,152.15229
Overall Steps per Second: 10,600.38148

Timestep Collection Time: 2.25901
Timestep Consumption Time: 2.46176
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.72077

Cumulative Model Updates: 148,180
Cumulative Timesteps: 1,236,555,836

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,987.14492
Policy Entropy: 1.70385
Value Function Loss: 0.05255

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.32189
Value Function Update Magnitude: 0.33829

Collected Steps per Second: 21,579.02500
Overall Steps per Second: 10,563.58023

Timestep Collection Time: 2.31725
Timestep Consumption Time: 2.41637
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.73362

Cumulative Model Updates: 148,186
Cumulative Timesteps: 1,236,605,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1236605840...
Checkpoint 1236605840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,820.96776
Policy Entropy: 1.72963
Value Function Loss: 0.05135

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.31662
Value Function Update Magnitude: 0.29899

Collected Steps per Second: 21,251.88060
Overall Steps per Second: 10,549.87823

Timestep Collection Time: 2.35311
Timestep Consumption Time: 2.38704
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.74015

Cumulative Model Updates: 148,192
Cumulative Timesteps: 1,236,655,848

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,001.82456
Policy Entropy: 1.72276
Value Function Loss: 0.04866

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.31088
Value Function Update Magnitude: 0.31870

Collected Steps per Second: 21,234.40765
Overall Steps per Second: 10,442.85427

Timestep Collection Time: 2.35561
Timestep Consumption Time: 2.43427
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.78988

Cumulative Model Updates: 148,198
Cumulative Timesteps: 1,236,705,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1236705868...
Checkpoint 1236705868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,460.30874
Policy Entropy: 1.72260
Value Function Loss: 0.04826

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.31326
Value Function Update Magnitude: 0.35809

Collected Steps per Second: 20,759.26536
Overall Steps per Second: 10,343.66913

Timestep Collection Time: 2.40953
Timestep Consumption Time: 2.42628
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.83581

Cumulative Model Updates: 148,204
Cumulative Timesteps: 1,236,755,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,602.56700
Policy Entropy: 1.72382
Value Function Loss: 0.04612

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.31573
Value Function Update Magnitude: 0.37229

Collected Steps per Second: 21,053.54286
Overall Steps per Second: 10,317.91945

Timestep Collection Time: 2.37490
Timestep Consumption Time: 2.47104
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.84594

Cumulative Model Updates: 148,210
Cumulative Timesteps: 1,236,805,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1236805888...
Checkpoint 1236805888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,195.93672
Policy Entropy: 1.72299
Value Function Loss: 0.04737

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.31303
Value Function Update Magnitude: 0.35170

Collected Steps per Second: 21,522.57575
Overall Steps per Second: 10,585.08480

Timestep Collection Time: 2.32454
Timestep Consumption Time: 2.40193
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.72646

Cumulative Model Updates: 148,216
Cumulative Timesteps: 1,236,855,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,517.12635
Policy Entropy: 1.72351
Value Function Loss: 0.04752

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.31424
Value Function Update Magnitude: 0.34091

Collected Steps per Second: 21,579.92740
Overall Steps per Second: 10,452.64047

Timestep Collection Time: 2.31715
Timestep Consumption Time: 2.46671
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.78386

Cumulative Model Updates: 148,222
Cumulative Timesteps: 1,236,905,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1236905922...
Checkpoint 1236905922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,873.19506
Policy Entropy: 1.72302
Value Function Loss: 0.04679

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07564
Policy Update Magnitude: 0.31294
Value Function Update Magnitude: 0.33211

Collected Steps per Second: 21,667.69174
Overall Steps per Second: 10,408.42112

Timestep Collection Time: 2.30943
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.80765

Cumulative Model Updates: 148,228
Cumulative Timesteps: 1,236,955,962

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,667.67645
Policy Entropy: 1.73219
Value Function Loss: 0.04414

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.30774
Value Function Update Magnitude: 0.30740

Collected Steps per Second: 22,312.84722
Overall Steps per Second: 10,678.07688

Timestep Collection Time: 2.24194
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.68474

Cumulative Model Updates: 148,234
Cumulative Timesteps: 1,237,005,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1237005986...
Checkpoint 1237005986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,840.08298
Policy Entropy: 1.72521
Value Function Loss: 0.04756

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.30766
Value Function Update Magnitude: 0.29406

Collected Steps per Second: 21,737.80102
Overall Steps per Second: 10,409.93008

Timestep Collection Time: 2.30078
Timestep Consumption Time: 2.50367
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.80445

Cumulative Model Updates: 148,240
Cumulative Timesteps: 1,237,056,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,661.37313
Policy Entropy: 1.71815
Value Function Loss: 0.04744

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.31588
Value Function Update Magnitude: 0.32333

Collected Steps per Second: 22,074.80184
Overall Steps per Second: 10,661.10899

Timestep Collection Time: 2.26548
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.69088

Cumulative Model Updates: 148,246
Cumulative Timesteps: 1,237,106,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1237106010...
Checkpoint 1237106010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,289.79668
Policy Entropy: 1.71847
Value Function Loss: 0.04969

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.31709
Value Function Update Magnitude: 0.33949

Collected Steps per Second: 21,651.83844
Overall Steps per Second: 10,384.00464

Timestep Collection Time: 2.31158
Timestep Consumption Time: 2.50833
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.81991

Cumulative Model Updates: 148,252
Cumulative Timesteps: 1,237,156,060

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,443.79991
Policy Entropy: 1.70458
Value Function Loss: 0.04670

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.31604
Value Function Update Magnitude: 0.34367

Collected Steps per Second: 22,086.60083
Overall Steps per Second: 10,531.81407

Timestep Collection Time: 2.26436
Timestep Consumption Time: 2.48430
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.74866

Cumulative Model Updates: 148,258
Cumulative Timesteps: 1,237,206,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1237206072...
Checkpoint 1237206072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,558.92863
Policy Entropy: 1.70997
Value Function Loss: 0.05387

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.32268
Value Function Update Magnitude: 0.33847

Collected Steps per Second: 21,811.13968
Overall Steps per Second: 10,478.10917

Timestep Collection Time: 2.29424
Timestep Consumption Time: 2.48143
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.77567

Cumulative Model Updates: 148,264
Cumulative Timesteps: 1,237,256,112

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,351.58569
Policy Entropy: 1.70619
Value Function Loss: 0.05534

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.32472
Value Function Update Magnitude: 0.35653

Collected Steps per Second: 21,656.79548
Overall Steps per Second: 10,419.41833

Timestep Collection Time: 2.31087
Timestep Consumption Time: 2.49228
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.80315

Cumulative Model Updates: 148,270
Cumulative Timesteps: 1,237,306,158

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1237306158...
Checkpoint 1237306158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,787.92305
Policy Entropy: 1.72238
Value Function Loss: 0.05611

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.32529
Value Function Update Magnitude: 0.37843

Collected Steps per Second: 21,137.20959
Overall Steps per Second: 10,237.85370

Timestep Collection Time: 2.36682
Timestep Consumption Time: 2.51975
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.88657

Cumulative Model Updates: 148,276
Cumulative Timesteps: 1,237,356,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,923.83998
Policy Entropy: 1.71695
Value Function Loss: 0.05338

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.32086
Value Function Update Magnitude: 0.36718

Collected Steps per Second: 21,419.50021
Overall Steps per Second: 10,467.59717

Timestep Collection Time: 2.33572
Timestep Consumption Time: 2.44379
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.77951

Cumulative Model Updates: 148,282
Cumulative Timesteps: 1,237,406,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1237406216...
Checkpoint 1237406216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,162.60791
Policy Entropy: 1.72063
Value Function Loss: 0.05189

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.32338
Value Function Update Magnitude: 0.37544

Collected Steps per Second: 21,588.70556
Overall Steps per Second: 10,384.87878

Timestep Collection Time: 2.31751
Timestep Consumption Time: 2.50027
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.81777

Cumulative Model Updates: 148,288
Cumulative Timesteps: 1,237,456,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,186.33523
Policy Entropy: 1.72132
Value Function Loss: 0.05149

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.31923
Value Function Update Magnitude: 0.35791

Collected Steps per Second: 22,353.97968
Overall Steps per Second: 10,671.11074

Timestep Collection Time: 2.23817
Timestep Consumption Time: 2.45038
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.68855

Cumulative Model Updates: 148,294
Cumulative Timesteps: 1,237,506,280

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1237506280...
Checkpoint 1237506280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,612.67381
Policy Entropy: 1.73297
Value Function Loss: 0.05074

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.31660
Value Function Update Magnitude: 0.31278

Collected Steps per Second: 21,828.02936
Overall Steps per Second: 10,573.08153

Timestep Collection Time: 2.29063
Timestep Consumption Time: 2.43836
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.72899

Cumulative Model Updates: 148,300
Cumulative Timesteps: 1,237,556,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,925.43408
Policy Entropy: 1.73310
Value Function Loss: 0.05802

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.30591
Value Function Update Magnitude: 0.32519

Collected Steps per Second: 21,980.62242
Overall Steps per Second: 10,568.25939

Timestep Collection Time: 2.27519
Timestep Consumption Time: 2.45691
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.73209

Cumulative Model Updates: 148,306
Cumulative Timesteps: 1,237,606,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1237606290...
Checkpoint 1237606290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,479.97930
Policy Entropy: 1.74379
Value Function Loss: 0.05493

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.29126
Value Function Update Magnitude: 0.37305

Collected Steps per Second: 21,864.42978
Overall Steps per Second: 10,611.00933

Timestep Collection Time: 2.28783
Timestep Consumption Time: 2.42633
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.71416

Cumulative Model Updates: 148,312
Cumulative Timesteps: 1,237,656,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,665.99438
Policy Entropy: 1.73650
Value Function Loss: 0.05282

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.29950
Value Function Update Magnitude: 0.35223

Collected Steps per Second: 21,912.75974
Overall Steps per Second: 10,463.13654

Timestep Collection Time: 2.28296
Timestep Consumption Time: 2.49820
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.78117

Cumulative Model Updates: 148,318
Cumulative Timesteps: 1,237,706,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1237706338...
Checkpoint 1237706338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,465.56901
Policy Entropy: 1.74544
Value Function Loss: 0.04904

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.30994
Value Function Update Magnitude: 0.32097

Collected Steps per Second: 21,827.31481
Overall Steps per Second: 10,578.91151

Timestep Collection Time: 2.29107
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.72714

Cumulative Model Updates: 148,324
Cumulative Timesteps: 1,237,756,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,402.69376
Policy Entropy: 1.73926
Value Function Loss: 0.05277

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.31601
Value Function Update Magnitude: 0.31315

Collected Steps per Second: 21,153.84095
Overall Steps per Second: 10,503.21288

Timestep Collection Time: 2.36458
Timestep Consumption Time: 2.39777
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.76235

Cumulative Model Updates: 148,330
Cumulative Timesteps: 1,237,806,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1237806366...
Checkpoint 1237806366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,281.32755
Policy Entropy: 1.74307
Value Function Loss: 0.05446

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.32210
Value Function Update Magnitude: 0.33843

Collected Steps per Second: 20,898.71146
Overall Steps per Second: 10,407.91753

Timestep Collection Time: 2.39297
Timestep Consumption Time: 2.41203
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.80500

Cumulative Model Updates: 148,336
Cumulative Timesteps: 1,237,856,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,528.53686
Policy Entropy: 1.73966
Value Function Loss: 0.05563

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.32843
Value Function Update Magnitude: 0.35594

Collected Steps per Second: 21,254.69860
Overall Steps per Second: 10,625.36407

Timestep Collection Time: 2.35336
Timestep Consumption Time: 2.35424
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.70760

Cumulative Model Updates: 148,342
Cumulative Timesteps: 1,237,906,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1237906396...
Checkpoint 1237906396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,070.47830
Policy Entropy: 1.73829
Value Function Loss: 0.05740

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.32837
Value Function Update Magnitude: 0.31795

Collected Steps per Second: 20,973.81218
Overall Steps per Second: 10,381.30914

Timestep Collection Time: 2.38421
Timestep Consumption Time: 2.43271
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.81693

Cumulative Model Updates: 148,348
Cumulative Timesteps: 1,237,956,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,099.62270
Policy Entropy: 1.74005
Value Function Loss: 0.06111

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.33075
Value Function Update Magnitude: 0.32615

Collected Steps per Second: 20,675.39315
Overall Steps per Second: 10,355.69035

Timestep Collection Time: 2.41949
Timestep Consumption Time: 2.41109
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.83058

Cumulative Model Updates: 148,354
Cumulative Timesteps: 1,238,006,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1238006426...
Checkpoint 1238006426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,108.90412
Policy Entropy: 1.73489
Value Function Loss: 0.06011

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.33170
Value Function Update Magnitude: 0.36594

Collected Steps per Second: 20,602.52485
Overall Steps per Second: 10,285.99188

Timestep Collection Time: 2.42931
Timestep Consumption Time: 2.43653
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.86584

Cumulative Model Updates: 148,360
Cumulative Timesteps: 1,238,056,476

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,702.24384
Policy Entropy: 1.74881
Value Function Loss: 0.05658

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.32839
Value Function Update Magnitude: 0.36215

Collected Steps per Second: 20,234.04537
Overall Steps per Second: 10,316.16334

Timestep Collection Time: 2.47148
Timestep Consumption Time: 2.37606
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.84754

Cumulative Model Updates: 148,366
Cumulative Timesteps: 1,238,106,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1238106484...
Checkpoint 1238106484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,381.64475
Policy Entropy: 1.73565
Value Function Loss: 0.05068

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.31302
Value Function Update Magnitude: 0.31267

Collected Steps per Second: 20,943.28576
Overall Steps per Second: 10,251.02683

Timestep Collection Time: 2.38931
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.88146

Cumulative Model Updates: 148,372
Cumulative Timesteps: 1,238,156,524

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,826.37092
Policy Entropy: 1.73770
Value Function Loss: 0.04956

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.30707
Value Function Update Magnitude: 0.31523

Collected Steps per Second: 21,556.52819
Overall Steps per Second: 10,447.64306

Timestep Collection Time: 2.32069
Timestep Consumption Time: 2.46757
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.78826

Cumulative Model Updates: 148,378
Cumulative Timesteps: 1,238,206,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1238206550...
Checkpoint 1238206550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,882.73391
Policy Entropy: 1.71354
Value Function Loss: 0.05238

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.31559
Value Function Update Magnitude: 0.34406

Collected Steps per Second: 21,708.13531
Overall Steps per Second: 10,603.54886

Timestep Collection Time: 2.30485
Timestep Consumption Time: 2.41376
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.71861

Cumulative Model Updates: 148,384
Cumulative Timesteps: 1,238,256,584

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,081.58872
Policy Entropy: 1.70588
Value Function Loss: 0.05403

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.32090
Value Function Update Magnitude: 0.36362

Collected Steps per Second: 21,824.02805
Overall Steps per Second: 10,507.11859

Timestep Collection Time: 2.29307
Timestep Consumption Time: 2.46980
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.76287

Cumulative Model Updates: 148,390
Cumulative Timesteps: 1,238,306,628

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1238306628...
Checkpoint 1238306628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,842.61358
Policy Entropy: 1.69452
Value Function Loss: 0.05495

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.32017
Value Function Update Magnitude: 0.35918

Collected Steps per Second: 21,829.85251
Overall Steps per Second: 10,588.20583

Timestep Collection Time: 2.29099
Timestep Consumption Time: 2.43238
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.72337

Cumulative Model Updates: 148,396
Cumulative Timesteps: 1,238,356,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,224.68650
Policy Entropy: 1.71233
Value Function Loss: 0.05203

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.31713
Value Function Update Magnitude: 0.34284

Collected Steps per Second: 21,867.29127
Overall Steps per Second: 10,503.40715

Timestep Collection Time: 2.28734
Timestep Consumption Time: 2.47473
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.76207

Cumulative Model Updates: 148,402
Cumulative Timesteps: 1,238,406,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1238406658...
Checkpoint 1238406658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,289.89698
Policy Entropy: 1.72460
Value Function Loss: 0.04919

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.31647
Value Function Update Magnitude: 0.34494

Collected Steps per Second: 21,983.53024
Overall Steps per Second: 10,613.85980

Timestep Collection Time: 2.27470
Timestep Consumption Time: 2.43668
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.71139

Cumulative Model Updates: 148,408
Cumulative Timesteps: 1,238,456,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,647.44780
Policy Entropy: 1.74009
Value Function Loss: 0.04915

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.31515
Value Function Update Magnitude: 0.34976

Collected Steps per Second: 21,817.32254
Overall Steps per Second: 10,446.40393

Timestep Collection Time: 2.29368
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.79036

Cumulative Model Updates: 148,414
Cumulative Timesteps: 1,238,506,706

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1238506706...
Checkpoint 1238506706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,899.99220
Policy Entropy: 1.73133
Value Function Loss: 0.04741

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.31188
Value Function Update Magnitude: 0.36365

Collected Steps per Second: 21,842.54772
Overall Steps per Second: 10,579.92074

Timestep Collection Time: 2.29003
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.72782

Cumulative Model Updates: 148,420
Cumulative Timesteps: 1,238,556,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,802.55379
Policy Entropy: 1.72918
Value Function Loss: 0.04977

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.36031

Collected Steps per Second: 21,886.74354
Overall Steps per Second: 10,597.77188

Timestep Collection Time: 2.28522
Timestep Consumption Time: 2.43426
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.71948

Cumulative Model Updates: 148,426
Cumulative Timesteps: 1,238,606,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1238606742...
Checkpoint 1238606742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,687.45064
Policy Entropy: 1.72461
Value Function Loss: 0.05145

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08057
Policy Update Magnitude: 0.31907
Value Function Update Magnitude: 0.36247

Collected Steps per Second: 21,665.84598
Overall Steps per Second: 10,543.69799

Timestep Collection Time: 2.30926
Timestep Consumption Time: 2.43595
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.74520

Cumulative Model Updates: 148,432
Cumulative Timesteps: 1,238,656,774

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,422.37794
Policy Entropy: 1.73320
Value Function Loss: 0.05412

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.31536
Value Function Update Magnitude: 0.36587

Collected Steps per Second: 21,586.25950
Overall Steps per Second: 10,547.16730

Timestep Collection Time: 2.31721
Timestep Consumption Time: 2.42529
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.74251

Cumulative Model Updates: 148,438
Cumulative Timesteps: 1,238,706,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1238706794...
Checkpoint 1238706794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,193.30438
Policy Entropy: 1.73899
Value Function Loss: 0.05452

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.31179
Value Function Update Magnitude: 0.36669

Collected Steps per Second: 21,246.21879
Overall Steps per Second: 10,317.01869

Timestep Collection Time: 2.35355
Timestep Consumption Time: 2.49320
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.84675

Cumulative Model Updates: 148,444
Cumulative Timesteps: 1,238,756,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,559.06653
Policy Entropy: 1.74266
Value Function Loss: 0.05430

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.31830
Value Function Update Magnitude: 0.38416

Collected Steps per Second: 21,523.63814
Overall Steps per Second: 10,341.68280

Timestep Collection Time: 2.32414
Timestep Consumption Time: 2.51298
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.83712

Cumulative Model Updates: 148,450
Cumulative Timesteps: 1,238,806,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1238806822...
Checkpoint 1238806822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,046.59143
Policy Entropy: 1.73555
Value Function Loss: 0.05217

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.31836
Value Function Update Magnitude: 0.38638

Collected Steps per Second: 21,594.98790
Overall Steps per Second: 10,527.99856

Timestep Collection Time: 2.31619
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.75095

Cumulative Model Updates: 148,456
Cumulative Timesteps: 1,238,856,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,980.71142
Policy Entropy: 1.73416
Value Function Loss: 0.05053

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.31433
Value Function Update Magnitude: 0.36964

Collected Steps per Second: 21,969.38632
Overall Steps per Second: 10,504.98823

Timestep Collection Time: 2.27653
Timestep Consumption Time: 2.48444
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.76098

Cumulative Model Updates: 148,462
Cumulative Timesteps: 1,238,906,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1238906854...
Checkpoint 1238906854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,814.20699
Policy Entropy: 1.72639
Value Function Loss: 0.04783

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.31121
Value Function Update Magnitude: 0.35549

Collected Steps per Second: 21,958.51470
Overall Steps per Second: 10,584.35311

Timestep Collection Time: 2.27912
Timestep Consumption Time: 2.44918
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.72830

Cumulative Model Updates: 148,468
Cumulative Timesteps: 1,238,956,900

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,246.15153
Policy Entropy: 1.74100
Value Function Loss: 0.04883

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.30893
Value Function Update Magnitude: 0.34665

Collected Steps per Second: 21,803.60619
Overall Steps per Second: 10,593.43232

Timestep Collection Time: 2.29439
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.72236

Cumulative Model Updates: 148,474
Cumulative Timesteps: 1,239,006,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1239006926...
Checkpoint 1239006926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,554.16530
Policy Entropy: 1.74514
Value Function Loss: 0.05196

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.30976
Value Function Update Magnitude: 0.31803

Collected Steps per Second: 21,951.76687
Overall Steps per Second: 10,631.26461

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.42558
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.70349

Cumulative Model Updates: 148,480
Cumulative Timesteps: 1,239,056,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,512.73795
Policy Entropy: 1.74832
Value Function Loss: 0.05402

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.31567
Value Function Update Magnitude: 0.30859

Collected Steps per Second: 22,418.08482
Overall Steps per Second: 10,618.70883

Timestep Collection Time: 2.23052
Timestep Consumption Time: 2.47853
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.70905

Cumulative Model Updates: 148,486
Cumulative Timesteps: 1,239,106,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1239106934...
Checkpoint 1239106934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,098.97762
Policy Entropy: 1.72287
Value Function Loss: 0.05389

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.31324
Value Function Update Magnitude: 0.34324

Collected Steps per Second: 21,875.15340
Overall Steps per Second: 10,431.15242

Timestep Collection Time: 2.28780
Timestep Consumption Time: 2.50994
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.79774

Cumulative Model Updates: 148,492
Cumulative Timesteps: 1,239,156,980

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,624.57782
Policy Entropy: 1.70958
Value Function Loss: 0.05139

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.30785
Value Function Update Magnitude: 0.35991

Collected Steps per Second: 21,486.63877
Overall Steps per Second: 10,399.31247

Timestep Collection Time: 2.32768
Timestep Consumption Time: 2.48168
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.80936

Cumulative Model Updates: 148,498
Cumulative Timesteps: 1,239,206,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1239206994...
Checkpoint 1239206994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,354.13191
Policy Entropy: 1.70828
Value Function Loss: 0.04994

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.31183
Value Function Update Magnitude: 0.34993

Collected Steps per Second: 21,422.47293
Overall Steps per Second: 10,365.79589

Timestep Collection Time: 2.33512
Timestep Consumption Time: 2.49075
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.82587

Cumulative Model Updates: 148,504
Cumulative Timesteps: 1,239,257,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,279.91591
Policy Entropy: 1.71805
Value Function Loss: 0.04827

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.31752
Value Function Update Magnitude: 0.32029

Collected Steps per Second: 21,325.66780
Overall Steps per Second: 10,314.87549

Timestep Collection Time: 2.34553
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.84931

Cumulative Model Updates: 148,510
Cumulative Timesteps: 1,239,307,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1239307038...
Checkpoint 1239307038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,221.13237
Policy Entropy: 1.72245
Value Function Loss: 0.04975

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08660
Policy Update Magnitude: 0.31595
Value Function Update Magnitude: 0.31295

Collected Steps per Second: 21,602.47263
Overall Steps per Second: 10,417.11576

Timestep Collection Time: 2.31640
Timestep Consumption Time: 2.48723
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.80363

Cumulative Model Updates: 148,516
Cumulative Timesteps: 1,239,357,078

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,014.78987
Policy Entropy: 1.70964
Value Function Loss: 0.05630

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.31754
Value Function Update Magnitude: 0.32631

Collected Steps per Second: 22,168.90846
Overall Steps per Second: 10,605.29420

Timestep Collection Time: 2.25541
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.71463

Cumulative Model Updates: 148,522
Cumulative Timesteps: 1,239,407,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1239407078...
Checkpoint 1239407078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,571.52531
Policy Entropy: 1.71900
Value Function Loss: 0.05680

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.31905
Value Function Update Magnitude: 0.35929

Collected Steps per Second: 21,074.07656
Overall Steps per Second: 10,404.13294

Timestep Collection Time: 2.37258
Timestep Consumption Time: 2.43320
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.80578

Cumulative Model Updates: 148,528
Cumulative Timesteps: 1,239,457,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,968.74038
Policy Entropy: 1.72904
Value Function Loss: 0.05553

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.32159
Value Function Update Magnitude: 0.37341

Collected Steps per Second: 21,605.61330
Overall Steps per Second: 10,698.06602

Timestep Collection Time: 2.31542
Timestep Consumption Time: 2.36076
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.67617

Cumulative Model Updates: 148,534
Cumulative Timesteps: 1,239,507,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1239507104...
Checkpoint 1239507104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,851.53433
Policy Entropy: 1.74297
Value Function Loss: 0.04965

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.31369
Value Function Update Magnitude: 0.35151

Collected Steps per Second: 21,353.45596
Overall Steps per Second: 10,651.67995

Timestep Collection Time: 2.34238
Timestep Consumption Time: 2.35340
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.69579

Cumulative Model Updates: 148,540
Cumulative Timesteps: 1,239,557,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,825.57940
Policy Entropy: 1.73836
Value Function Loss: 0.04934

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.30496
Value Function Update Magnitude: 0.34051

Collected Steps per Second: 21,599.49602
Overall Steps per Second: 10,528.26546

Timestep Collection Time: 2.31533
Timestep Consumption Time: 2.43474
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.75007

Cumulative Model Updates: 148,546
Cumulative Timesteps: 1,239,607,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1239607132...
Checkpoint 1239607132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,687.62532
Policy Entropy: 1.73756
Value Function Loss: 0.04853

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.33577

Collected Steps per Second: 21,638.12290
Overall Steps per Second: 10,584.88495

Timestep Collection Time: 2.31111
Timestep Consumption Time: 2.41337
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.72447

Cumulative Model Updates: 148,552
Cumulative Timesteps: 1,239,657,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,949.17842
Policy Entropy: 1.73670
Value Function Loss: 0.05046

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.29989
Value Function Update Magnitude: 0.33707

Collected Steps per Second: 21,701.01149
Overall Steps per Second: 10,493.15830

Timestep Collection Time: 2.30469
Timestep Consumption Time: 2.46166
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.76634

Cumulative Model Updates: 148,558
Cumulative Timesteps: 1,239,707,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1239707154...
Checkpoint 1239707154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,176.03408
Policy Entropy: 1.74713
Value Function Loss: 0.05255

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.30514
Value Function Update Magnitude: 0.35759

Collected Steps per Second: 21,374.40839
Overall Steps per Second: 10,522.93067

Timestep Collection Time: 2.34028
Timestep Consumption Time: 2.41334
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.75362

Cumulative Model Updates: 148,564
Cumulative Timesteps: 1,239,757,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,805.38572
Policy Entropy: 1.75414
Value Function Loss: 0.05692

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.30863
Value Function Update Magnitude: 0.37658

Collected Steps per Second: 21,583.78524
Overall Steps per Second: 10,592.67439

Timestep Collection Time: 2.31683
Timestep Consumption Time: 2.40398
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.72081

Cumulative Model Updates: 148,570
Cumulative Timesteps: 1,239,807,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1239807182...
Checkpoint 1239807182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,599.29903
Policy Entropy: 1.74625
Value Function Loss: 0.05635

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.32063
Value Function Update Magnitude: 0.39256

Collected Steps per Second: 21,525.20612
Overall Steps per Second: 10,562.81826

Timestep Collection Time: 2.32332
Timestep Consumption Time: 2.41121
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.73453

Cumulative Model Updates: 148,576
Cumulative Timesteps: 1,239,857,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,065.99576
Policy Entropy: 1.72563
Value Function Loss: 0.05529

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.32373
Value Function Update Magnitude: 0.39038

Collected Steps per Second: 22,147.89801
Overall Steps per Second: 10,478.45501

Timestep Collection Time: 2.25845
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.77360

Cumulative Model Updates: 148,582
Cumulative Timesteps: 1,239,907,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1239907212...
Checkpoint 1239907212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,337.15903
Policy Entropy: 1.72804
Value Function Loss: 0.04870

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.31703
Value Function Update Magnitude: 0.38512

Collected Steps per Second: 21,711.36759
Overall Steps per Second: 10,535.44319

Timestep Collection Time: 2.30313
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.74626

Cumulative Model Updates: 148,588
Cumulative Timesteps: 1,239,957,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,832.69237
Policy Entropy: 1.73949
Value Function Loss: 0.05176

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.31271
Value Function Update Magnitude: 0.35187

Collected Steps per Second: 22,127.19767
Overall Steps per Second: 10,608.49323

Timestep Collection Time: 2.26002
Timestep Consumption Time: 2.45393
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.71396

Cumulative Model Updates: 148,594
Cumulative Timesteps: 1,240,007,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1240007224...
Checkpoint 1240007224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,309.93224
Policy Entropy: 1.73557
Value Function Loss: 0.05055

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.30756
Value Function Update Magnitude: 0.34415

Collected Steps per Second: 21,687.64030
Overall Steps per Second: 10,543.81677

Timestep Collection Time: 2.30601
Timestep Consumption Time: 2.43724
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.74325

Cumulative Model Updates: 148,600
Cumulative Timesteps: 1,240,057,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,024.93166
Policy Entropy: 1.73331
Value Function Loss: 0.04915

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.30495
Value Function Update Magnitude: 0.33701

Collected Steps per Second: 21,983.60280
Overall Steps per Second: 10,478.17028

Timestep Collection Time: 2.27506
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.77316

Cumulative Model Updates: 148,606
Cumulative Timesteps: 1,240,107,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1240107250...
Checkpoint 1240107250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,961.55671
Policy Entropy: 1.72090
Value Function Loss: 0.04865

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.30681
Value Function Update Magnitude: 0.32167

Collected Steps per Second: 21,895.72020
Overall Steps per Second: 10,574.74681

Timestep Collection Time: 2.28510
Timestep Consumption Time: 2.44636
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.73146

Cumulative Model Updates: 148,612
Cumulative Timesteps: 1,240,157,284

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,064.64867
Policy Entropy: 1.72976
Value Function Loss: 0.05071

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.30911
Value Function Update Magnitude: 0.32820

Collected Steps per Second: 21,734.48525
Overall Steps per Second: 10,605.55462

Timestep Collection Time: 2.30206
Timestep Consumption Time: 2.41566
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.71772

Cumulative Model Updates: 148,618
Cumulative Timesteps: 1,240,207,318

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1240207318...
Checkpoint 1240207318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,678.61147
Policy Entropy: 1.71672
Value Function Loss: 0.05357

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.31374
Value Function Update Magnitude: 0.33264

Collected Steps per Second: 21,237.71119
Overall Steps per Second: 10,471.75151

Timestep Collection Time: 2.35553
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.77723

Cumulative Model Updates: 148,624
Cumulative Timesteps: 1,240,257,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,654.02934
Policy Entropy: 1.73287
Value Function Loss: 0.05171

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.31542
Value Function Update Magnitude: 0.32631

Collected Steps per Second: 21,852.02700
Overall Steps per Second: 10,588.76474

Timestep Collection Time: 2.28903
Timestep Consumption Time: 2.43484
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.72387

Cumulative Model Updates: 148,630
Cumulative Timesteps: 1,240,307,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1240307364...
Checkpoint 1240307364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,898.24849
Policy Entropy: 1.72727
Value Function Loss: 0.05204

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.31572
Value Function Update Magnitude: 0.30846

Collected Steps per Second: 21,696.26248
Overall Steps per Second: 10,503.27489

Timestep Collection Time: 2.30501
Timestep Consumption Time: 2.45637
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.76137

Cumulative Model Updates: 148,636
Cumulative Timesteps: 1,240,357,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,736.16371
Policy Entropy: 1.72983
Value Function Loss: 0.05271

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.31435
Value Function Update Magnitude: 0.32015

Collected Steps per Second: 22,275.37417
Overall Steps per Second: 10,529.89018

Timestep Collection Time: 2.24589
Timestep Consumption Time: 2.50516
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.75105

Cumulative Model Updates: 148,642
Cumulative Timesteps: 1,240,407,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1240407402...
Checkpoint 1240407402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,765.55977
Policy Entropy: 1.71009
Value Function Loss: 0.05135

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.31661
Value Function Update Magnitude: 0.32582

Collected Steps per Second: 21,725.82715
Overall Steps per Second: 10,540.29374

Timestep Collection Time: 2.30214
Timestep Consumption Time: 2.44307
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.74522

Cumulative Model Updates: 148,648
Cumulative Timesteps: 1,240,457,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,960.22806
Policy Entropy: 1.70099
Value Function Loss: 0.04802

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.31196
Value Function Update Magnitude: 0.31732

Collected Steps per Second: 22,205.60003
Overall Steps per Second: 10,513.71038

Timestep Collection Time: 2.25295
Timestep Consumption Time: 2.50541
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.75836

Cumulative Model Updates: 148,654
Cumulative Timesteps: 1,240,507,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1240507446...
Checkpoint 1240507446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,204.98026
Policy Entropy: 1.69038
Value Function Loss: 0.04580

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.30622
Value Function Update Magnitude: 0.30495

Collected Steps per Second: 22,012.99474
Overall Steps per Second: 10,608.98358

Timestep Collection Time: 2.27166
Timestep Consumption Time: 2.44189
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.71355

Cumulative Model Updates: 148,660
Cumulative Timesteps: 1,240,557,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,970.25926
Policy Entropy: 1.70300
Value Function Loss: 0.04531

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08017
Policy Update Magnitude: 0.30866
Value Function Update Magnitude: 0.31398

Collected Steps per Second: 22,031.26249
Overall Steps per Second: 10,511.83023

Timestep Collection Time: 2.26977
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.75712

Cumulative Model Updates: 148,666
Cumulative Timesteps: 1,240,607,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1240607458...
Checkpoint 1240607458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,812.02489
Policy Entropy: 1.70216
Value Function Loss: 0.04846

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.31250
Value Function Update Magnitude: 0.31763

Collected Steps per Second: 21,525.65755
Overall Steps per Second: 10,564.33124

Timestep Collection Time: 2.32420
Timestep Consumption Time: 2.41154
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.73575

Cumulative Model Updates: 148,672
Cumulative Timesteps: 1,240,657,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,576.85596
Policy Entropy: 1.71019
Value Function Loss: 0.04763

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.31412
Value Function Update Magnitude: 0.32104

Collected Steps per Second: 21,665.70464
Overall Steps per Second: 10,539.50531

Timestep Collection Time: 2.30798
Timestep Consumption Time: 2.43646
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.74444

Cumulative Model Updates: 148,678
Cumulative Timesteps: 1,240,707,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1240707492...
Checkpoint 1240707492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,871.77477
Policy Entropy: 1.69246
Value Function Loss: 0.05004

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.30821
Value Function Update Magnitude: 0.32547

Collected Steps per Second: 21,567.99310
Overall Steps per Second: 10,544.94838

Timestep Collection Time: 2.31825
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.74161

Cumulative Model Updates: 148,684
Cumulative Timesteps: 1,240,757,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,577.15503
Policy Entropy: 1.70037
Value Function Loss: 0.04852

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.30640
Value Function Update Magnitude: 0.31228

Collected Steps per Second: 21,793.31620
Overall Steps per Second: 10,574.50257

Timestep Collection Time: 2.29428
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.72835

Cumulative Model Updates: 148,690
Cumulative Timesteps: 1,240,807,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1240807492...
Checkpoint 1240807492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,420.25072
Policy Entropy: 1.71893
Value Function Loss: 0.05489

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.31265
Value Function Update Magnitude: 0.30181

Collected Steps per Second: 20,885.53430
Overall Steps per Second: 10,524.04479

Timestep Collection Time: 2.39515
Timestep Consumption Time: 2.35815
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.75331

Cumulative Model Updates: 148,696
Cumulative Timesteps: 1,240,857,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,486.73425
Policy Entropy: 1.74541
Value Function Loss: 0.05487

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.31414
Value Function Update Magnitude: 0.28302

Collected Steps per Second: 21,707.13048
Overall Steps per Second: 10,528.34162

Timestep Collection Time: 2.30394
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.75023

Cumulative Model Updates: 148,702
Cumulative Timesteps: 1,240,907,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1240907528...
Checkpoint 1240907528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,810.78249
Policy Entropy: 1.74327
Value Function Loss: 0.05523

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.30978
Value Function Update Magnitude: 0.27818

Collected Steps per Second: 21,084.47363
Overall Steps per Second: 10,557.42294

Timestep Collection Time: 2.37151
Timestep Consumption Time: 2.36469
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.73619

Cumulative Model Updates: 148,708
Cumulative Timesteps: 1,240,957,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,747.80868
Policy Entropy: 1.73417
Value Function Loss: 0.04871

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.30490
Value Function Update Magnitude: 0.28259

Collected Steps per Second: 21,678.14118
Overall Steps per Second: 10,548.48117

Timestep Collection Time: 2.30785
Timestep Consumption Time: 2.43501
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.74286

Cumulative Model Updates: 148,714
Cumulative Timesteps: 1,241,007,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1241007560...
Checkpoint 1241007560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,599.01895
Policy Entropy: 1.71414
Value Function Loss: 0.04820

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.30258
Value Function Update Magnitude: 0.27133

Collected Steps per Second: 21,209.27747
Overall Steps per Second: 10,350.91901

Timestep Collection Time: 2.35765
Timestep Consumption Time: 2.47323
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.83088

Cumulative Model Updates: 148,720
Cumulative Timesteps: 1,241,057,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,995.88963
Policy Entropy: 1.71325
Value Function Loss: 0.04948

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07781
Policy Update Magnitude: 0.30604
Value Function Update Magnitude: 0.28370

Collected Steps per Second: 21,899.89087
Overall Steps per Second: 10,640.88157

Timestep Collection Time: 2.28312
Timestep Consumption Time: 2.41574
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.69886

Cumulative Model Updates: 148,726
Cumulative Timesteps: 1,241,107,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1241107564...
Checkpoint 1241107564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,746.37284
Policy Entropy: 1.70746
Value Function Loss: 0.04777

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.30446
Value Function Update Magnitude: 0.30212

Collected Steps per Second: 21,857.57491
Overall Steps per Second: 10,663.23188

Timestep Collection Time: 2.28873
Timestep Consumption Time: 2.40272
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.69145

Cumulative Model Updates: 148,732
Cumulative Timesteps: 1,241,157,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,849.50885
Policy Entropy: 1.71427
Value Function Loss: 0.04559

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.30434
Value Function Update Magnitude: 0.31053

Collected Steps per Second: 21,435.01742
Overall Steps per Second: 10,533.04183

Timestep Collection Time: 2.33356
Timestep Consumption Time: 2.41530
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.74887

Cumulative Model Updates: 148,738
Cumulative Timesteps: 1,241,207,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1241207610...
Checkpoint 1241207610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,581.19324
Policy Entropy: 1.71613
Value Function Loss: 0.04432

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.30756
Value Function Update Magnitude: 0.32233

Collected Steps per Second: 21,320.05684
Overall Steps per Second: 10,303.94389

Timestep Collection Time: 2.34624
Timestep Consumption Time: 2.50840
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.85465

Cumulative Model Updates: 148,744
Cumulative Timesteps: 1,241,257,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,954.83318
Policy Entropy: 1.71496
Value Function Loss: 0.04788

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.30122
Value Function Update Magnitude: 0.34396

Collected Steps per Second: 21,709.73233
Overall Steps per Second: 10,366.20725

Timestep Collection Time: 2.30450
Timestep Consumption Time: 2.52176
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.82626

Cumulative Model Updates: 148,750
Cumulative Timesteps: 1,241,307,662

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1241307662...
Checkpoint 1241307662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,942.33432
Policy Entropy: 1.71072
Value Function Loss: 0.05147

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.29928
Value Function Update Magnitude: 0.35772

Collected Steps per Second: 21,788.23154
Overall Steps per Second: 10,567.09321

Timestep Collection Time: 2.29619
Timestep Consumption Time: 2.43832
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.73451

Cumulative Model Updates: 148,756
Cumulative Timesteps: 1,241,357,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,967.69070
Policy Entropy: 1.71541
Value Function Loss: 0.04944

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.30163
Value Function Update Magnitude: 0.34946

Collected Steps per Second: 22,040.70112
Overall Steps per Second: 10,502.94126

Timestep Collection Time: 2.26880
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.76114

Cumulative Model Updates: 148,762
Cumulative Timesteps: 1,241,407,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1241407698...
Checkpoint 1241407698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,363.87989
Policy Entropy: 1.72177
Value Function Loss: 0.05126

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.30861
Value Function Update Magnitude: 0.33154

Collected Steps per Second: 22,185.44264
Overall Steps per Second: 10,685.55816

Timestep Collection Time: 2.25445
Timestep Consumption Time: 2.42626
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.68071

Cumulative Model Updates: 148,768
Cumulative Timesteps: 1,241,457,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,427.20523
Policy Entropy: 1.73200
Value Function Loss: 0.04804

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.31087
Value Function Update Magnitude: 0.32261

Collected Steps per Second: 21,961.10933
Overall Steps per Second: 10,412.79874

Timestep Collection Time: 2.27803
Timestep Consumption Time: 2.52644
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.80447

Cumulative Model Updates: 148,774
Cumulative Timesteps: 1,241,507,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1241507742...
Checkpoint 1241507742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,506.21856
Policy Entropy: 1.72179
Value Function Loss: 0.04897

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.30799
Value Function Update Magnitude: 0.31663

Collected Steps per Second: 21,908.84480
Overall Steps per Second: 10,577.01843

Timestep Collection Time: 2.28227
Timestep Consumption Time: 2.44514
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.72742

Cumulative Model Updates: 148,780
Cumulative Timesteps: 1,241,557,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,947.16461
Policy Entropy: 1.71204
Value Function Loss: 0.05256

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.31222
Value Function Update Magnitude: 0.31964

Collected Steps per Second: 22,121.99823
Overall Steps per Second: 10,484.30764

Timestep Collection Time: 2.26074
Timestep Consumption Time: 2.50944
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.77018

Cumulative Model Updates: 148,786
Cumulative Timesteps: 1,241,607,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1241607756...
Checkpoint 1241607756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,916.16728
Policy Entropy: 1.69865
Value Function Loss: 0.04955

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.31609
Value Function Update Magnitude: 0.33983

Collected Steps per Second: 22,120.35805
Overall Steps per Second: 10,656.22921

Timestep Collection Time: 2.26072
Timestep Consumption Time: 2.43212
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.69284

Cumulative Model Updates: 148,792
Cumulative Timesteps: 1,241,657,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,917.11813
Policy Entropy: 1.71386
Value Function Loss: 0.05623

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.31140
Value Function Update Magnitude: 0.34585

Collected Steps per Second: 21,854.68331
Overall Steps per Second: 10,457.63465

Timestep Collection Time: 2.28821
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.78196

Cumulative Model Updates: 148,798
Cumulative Timesteps: 1,241,707,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1241707772...
Checkpoint 1241707772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,019.42183
Policy Entropy: 1.73066
Value Function Loss: 0.05374

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.31575
Value Function Update Magnitude: 0.35293

Collected Steps per Second: 21,518.29111
Overall Steps per Second: 10,380.27819

Timestep Collection Time: 2.32426
Timestep Consumption Time: 2.49392
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.81818

Cumulative Model Updates: 148,804
Cumulative Timesteps: 1,241,757,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,521.11521
Policy Entropy: 1.73526
Value Function Loss: 0.05477

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.31399
Value Function Update Magnitude: 0.35207

Collected Steps per Second: 21,812.40287
Overall Steps per Second: 10,456.14613

Timestep Collection Time: 2.29246
Timestep Consumption Time: 2.48980
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.78226

Cumulative Model Updates: 148,810
Cumulative Timesteps: 1,241,807,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1241807790...
Checkpoint 1241807790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,380.15645
Policy Entropy: 1.74128
Value Function Loss: 0.04957

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.29247
Value Function Update Magnitude: 0.34325

Collected Steps per Second: 21,544.34916
Overall Steps per Second: 10,442.05878

Timestep Collection Time: 2.32117
Timestep Consumption Time: 2.46793
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.78909

Cumulative Model Updates: 148,816
Cumulative Timesteps: 1,241,857,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,602.44140
Policy Entropy: 1.73330
Value Function Loss: 0.04588

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.30052
Value Function Update Magnitude: 0.34314

Collected Steps per Second: 21,958.00863
Overall Steps per Second: 10,452.87181

Timestep Collection Time: 2.27771
Timestep Consumption Time: 2.50700
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.78471

Cumulative Model Updates: 148,822
Cumulative Timesteps: 1,241,907,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1241907812...
Checkpoint 1241907812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,847.36808
Policy Entropy: 1.71626
Value Function Loss: 0.04334

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.29908
Value Function Update Magnitude: 0.33623

Collected Steps per Second: 21,951.46129
Overall Steps per Second: 10,604.59376

Timestep Collection Time: 2.27784
Timestep Consumption Time: 2.43728
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.71513

Cumulative Model Updates: 148,828
Cumulative Timesteps: 1,241,957,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,072.15312
Policy Entropy: 1.72739
Value Function Loss: 0.04613

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.30517
Value Function Update Magnitude: 0.32199

Collected Steps per Second: 22,215.42978
Overall Steps per Second: 10,496.00663

Timestep Collection Time: 2.25087
Timestep Consumption Time: 2.51323
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.76410

Cumulative Model Updates: 148,834
Cumulative Timesteps: 1,242,007,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1242007818...
Checkpoint 1242007818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,598.95617
Policy Entropy: 1.74664
Value Function Loss: 0.05098

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.31049
Value Function Update Magnitude: 0.33940

Collected Steps per Second: 21,812.08127
Overall Steps per Second: 10,649.90248

Timestep Collection Time: 2.29368
Timestep Consumption Time: 2.40401
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.69770

Cumulative Model Updates: 148,840
Cumulative Timesteps: 1,242,057,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,289.59730
Policy Entropy: 1.76381
Value Function Loss: 0.05145

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.31546
Value Function Update Magnitude: 0.33965

Collected Steps per Second: 21,735.83914
Overall Steps per Second: 10,425.52461

Timestep Collection Time: 2.30053
Timestep Consumption Time: 2.49577
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.79631

Cumulative Model Updates: 148,846
Cumulative Timesteps: 1,242,107,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1242107852...
Checkpoint 1242107852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,841.69180
Policy Entropy: 1.75944
Value Function Loss: 0.05025

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.31966
Value Function Update Magnitude: 0.35181

Collected Steps per Second: 21,265.04850
Overall Steps per Second: 10,268.76820

Timestep Collection Time: 2.35259
Timestep Consumption Time: 2.51927
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.87186

Cumulative Model Updates: 148,852
Cumulative Timesteps: 1,242,157,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,401.50658
Policy Entropy: 1.72208
Value Function Loss: 0.04879

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.31448
Value Function Update Magnitude: 0.35504

Collected Steps per Second: 21,624.34213
Overall Steps per Second: 10,413.31395

Timestep Collection Time: 2.31276
Timestep Consumption Time: 2.48993
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.80270

Cumulative Model Updates: 148,858
Cumulative Timesteps: 1,242,207,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1242207892...
Checkpoint 1242207892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,270.31575
Policy Entropy: 1.71465
Value Function Loss: 0.05000

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.31058
Value Function Update Magnitude: 0.34122

Collected Steps per Second: 21,488.38457
Overall Steps per Second: 10,375.02299

Timestep Collection Time: 2.32851
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.82274

Cumulative Model Updates: 148,864
Cumulative Timesteps: 1,242,257,928

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,767.46454
Policy Entropy: 1.71118
Value Function Loss: 0.05178

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.31659
Value Function Update Magnitude: 0.34041

Collected Steps per Second: 21,923.38172
Overall Steps per Second: 10,381.50969

Timestep Collection Time: 2.28085
Timestep Consumption Time: 2.53579
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.81664

Cumulative Model Updates: 148,870
Cumulative Timesteps: 1,242,307,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1242307932...
Checkpoint 1242307932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,007.01589
Policy Entropy: 1.71624
Value Function Loss: 0.05326

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.32344
Value Function Update Magnitude: 0.32179

Collected Steps per Second: 21,662.07049
Overall Steps per Second: 10,504.46614

Timestep Collection Time: 2.30938
Timestep Consumption Time: 2.45297
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.76236

Cumulative Model Updates: 148,876
Cumulative Timesteps: 1,242,357,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,139.30701
Policy Entropy: 1.71373
Value Function Loss: 0.05151

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.31939
Value Function Update Magnitude: 0.32682

Collected Steps per Second: 22,066.68911
Overall Steps per Second: 10,461.64240

Timestep Collection Time: 2.26686
Timestep Consumption Time: 2.51461
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.78147

Cumulative Model Updates: 148,882
Cumulative Timesteps: 1,242,407,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1242407980...
Checkpoint 1242407980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,269.38096
Policy Entropy: 1.70742
Value Function Loss: 0.04768

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.31005
Value Function Update Magnitude: 0.33251

Collected Steps per Second: 21,828.51941
Overall Steps per Second: 10,576.58386

Timestep Collection Time: 2.29186
Timestep Consumption Time: 2.43821
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.73007

Cumulative Model Updates: 148,888
Cumulative Timesteps: 1,242,458,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,568.48064
Policy Entropy: 1.72164
Value Function Loss: 0.04987

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.30955
Value Function Update Magnitude: 0.33176

Collected Steps per Second: 21,814.19039
Overall Steps per Second: 10,590.51354

Timestep Collection Time: 2.29309
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.72328

Cumulative Model Updates: 148,894
Cumulative Timesteps: 1,242,508,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1242508030...
Checkpoint 1242508030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,493.32870
Policy Entropy: 1.71945
Value Function Loss: 0.05191

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.31618
Value Function Update Magnitude: 0.33401

Collected Steps per Second: 22,238.11838
Overall Steps per Second: 10,591.61237

Timestep Collection Time: 2.24974
Timestep Consumption Time: 2.47381
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.72355

Cumulative Model Updates: 148,900
Cumulative Timesteps: 1,242,558,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,788.31967
Policy Entropy: 1.72682
Value Function Loss: 0.05270

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08502
Policy Update Magnitude: 0.32150
Value Function Update Magnitude: 0.33393

Collected Steps per Second: 22,121.75288
Overall Steps per Second: 10,496.98121

Timestep Collection Time: 2.26103
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.76499

Cumulative Model Updates: 148,906
Cumulative Timesteps: 1,242,608,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1242608078...
Checkpoint 1242608078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,384.04210
Policy Entropy: 1.72865
Value Function Loss: 0.04897

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.31643
Value Function Update Magnitude: 0.29529

Collected Steps per Second: 21,535.68603
Overall Steps per Second: 10,557.27521

Timestep Collection Time: 2.32340
Timestep Consumption Time: 2.41608
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.73948

Cumulative Model Updates: 148,912
Cumulative Timesteps: 1,242,658,114

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,108.90235
Policy Entropy: 1.74013
Value Function Loss: 0.05542

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.31678
Value Function Update Magnitude: 0.24709

Collected Steps per Second: 21,494.43245
Overall Steps per Second: 10,491.86628

Timestep Collection Time: 2.32702
Timestep Consumption Time: 2.44029
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.76731

Cumulative Model Updates: 148,918
Cumulative Timesteps: 1,242,708,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1242708132...
Checkpoint 1242708132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,975.13717
Policy Entropy: 1.73510
Value Function Loss: 0.05373

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.31891
Value Function Update Magnitude: 0.23680

Collected Steps per Second: 21,548.86658
Overall Steps per Second: 10,533.12021

Timestep Collection Time: 2.32068
Timestep Consumption Time: 2.42701
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.74769

Cumulative Model Updates: 148,924
Cumulative Timesteps: 1,242,758,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,640.92217
Policy Entropy: 1.75029
Value Function Loss: 0.05419

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.31522
Value Function Update Magnitude: 0.23421

Collected Steps per Second: 21,402.80055
Overall Steps per Second: 10,487.64468

Timestep Collection Time: 2.33885
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.77304

Cumulative Model Updates: 148,930
Cumulative Timesteps: 1,242,808,198

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


Saving checkpoint 1242808198...
Checkpoint 1242808198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,831.19716
Policy Entropy: 1.73893
Value Function Loss: 0.04950

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07478
Policy Update Magnitude: 0.31323
Value Function Update Magnitude: 0.23365

Collected Steps per Second: 21,668.15237
Overall Steps per Second: 10,391.22812

Timestep Collection Time: 2.30901
Timestep Consumption Time: 2.50582
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.81483

Cumulative Model Updates: 148,936
Cumulative Timesteps: 1,242,858,230

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,623.61415
Policy Entropy: 1.73391
Value Function Loss: 0.05059

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.31302
Value Function Update Magnitude: 0.28716

Collected Steps per Second: 22,114.74699
Overall Steps per Second: 10,411.45036

Timestep Collection Time: 2.26274
Timestep Consumption Time: 2.54350
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.80625

Cumulative Model Updates: 148,942
Cumulative Timesteps: 1,242,908,270

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1242908270...
Checkpoint 1242908270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,572.93128
Policy Entropy: 1.71665
Value Function Loss: 0.05312

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.31437
Value Function Update Magnitude: 0.29794

Collected Steps per Second: 21,907.61096
Overall Steps per Second: 10,530.83565

Timestep Collection Time: 2.28286
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.74910

Cumulative Model Updates: 148,948
Cumulative Timesteps: 1,242,958,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,476.14239
Policy Entropy: 1.73117
Value Function Loss: 0.05311

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.31275
Value Function Update Magnitude: 0.30306

Collected Steps per Second: 21,404.47497
Overall Steps per Second: 10,475.40916

Timestep Collection Time: 2.33736
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.77595

Cumulative Model Updates: 148,954
Cumulative Timesteps: 1,243,008,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1243008312...
Checkpoint 1243008312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,368.97908
Policy Entropy: 1.74275
Value Function Loss: 0.05385

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.31199
Value Function Update Magnitude: 0.33471

Collected Steps per Second: 21,372.58422
Overall Steps per Second: 10,648.05831

Timestep Collection Time: 2.34150
Timestep Consumption Time: 2.35832
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.69982

Cumulative Model Updates: 148,960
Cumulative Timesteps: 1,243,058,356

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,700.93908
Policy Entropy: 1.75437
Value Function Loss: 0.05310

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07870
Policy Update Magnitude: 0.31541
Value Function Update Magnitude: 0.33851

Collected Steps per Second: 21,178.65381
Overall Steps per Second: 10,447.07718

Timestep Collection Time: 2.36219
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.78871

Cumulative Model Updates: 148,966
Cumulative Timesteps: 1,243,108,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1243108384...
Checkpoint 1243108384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,861.37991
Policy Entropy: 1.75447
Value Function Loss: 0.05128

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.31339
Value Function Update Magnitude: 0.33364

Collected Steps per Second: 21,357.57799
Overall Steps per Second: 10,627.37784

Timestep Collection Time: 2.34146
Timestep Consumption Time: 2.36412
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.70558

Cumulative Model Updates: 148,972
Cumulative Timesteps: 1,243,158,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,760.79232
Policy Entropy: 1.74396
Value Function Loss: 0.05011

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.30896
Value Function Update Magnitude: 0.34447

Collected Steps per Second: 21,239.42125
Overall Steps per Second: 10,479.76968

Timestep Collection Time: 2.35600
Timestep Consumption Time: 2.41892
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.77491

Cumulative Model Updates: 148,978
Cumulative Timesteps: 1,243,208,432

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1243208432...
Checkpoint 1243208432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,367.20566
Policy Entropy: 1.72691
Value Function Loss: 0.04517

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.30633
Value Function Update Magnitude: 0.34723

Collected Steps per Second: 21,539.26563
Overall Steps per Second: 10,591.93035

Timestep Collection Time: 2.32236
Timestep Consumption Time: 2.40029
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.72265

Cumulative Model Updates: 148,984
Cumulative Timesteps: 1,243,258,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,548.56471
Policy Entropy: 1.71388
Value Function Loss: 0.04615

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.30320
Value Function Update Magnitude: 0.35663

Collected Steps per Second: 21,124.52093
Overall Steps per Second: 10,444.32408

Timestep Collection Time: 2.36928
Timestep Consumption Time: 2.42279
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.79208

Cumulative Model Updates: 148,990
Cumulative Timesteps: 1,243,308,504

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1243308504...
Checkpoint 1243308504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,766.33685
Policy Entropy: 1.71251
Value Function Loss: 0.04638

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.30650
Value Function Update Magnitude: 0.37100

Collected Steps per Second: 21,546.32086
Overall Steps per Second: 10,342.64621

Timestep Collection Time: 2.32179
Timestep Consumption Time: 2.51508
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.83687

Cumulative Model Updates: 148,996
Cumulative Timesteps: 1,243,358,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,463.57709
Policy Entropy: 1.71838
Value Function Loss: 0.05010

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.31579
Value Function Update Magnitude: 0.34612

Collected Steps per Second: 21,325.27437
Overall Steps per Second: 10,450.15849

Timestep Collection Time: 2.34604
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.78749

Cumulative Model Updates: 149,002
Cumulative Timesteps: 1,243,408,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1243408560...
Checkpoint 1243408560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,267.33260
Policy Entropy: 1.74288
Value Function Loss: 0.05071

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.31494
Value Function Update Magnitude: 0.33506

Collected Steps per Second: 21,423.86176
Overall Steps per Second: 10,496.82753

Timestep Collection Time: 2.33562
Timestep Consumption Time: 2.43134
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.76696

Cumulative Model Updates: 149,008
Cumulative Timesteps: 1,243,458,598

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,636.55465
Policy Entropy: 1.76196
Value Function Loss: 0.05239

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.30616
Value Function Update Magnitude: 0.32593

Collected Steps per Second: 21,996.01574
Overall Steps per Second: 10,533.69330

Timestep Collection Time: 2.27405
Timestep Consumption Time: 2.47452
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74857

Cumulative Model Updates: 149,014
Cumulative Timesteps: 1,243,508,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1243508618...
Checkpoint 1243508618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,190.27348
Policy Entropy: 1.76403
Value Function Loss: 0.04942

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.30356
Value Function Update Magnitude: 0.33169

Collected Steps per Second: 22,159.00979
Overall Steps per Second: 10,649.27395

Timestep Collection Time: 2.25687
Timestep Consumption Time: 2.43922
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.69609

Cumulative Model Updates: 149,020
Cumulative Timesteps: 1,243,558,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,254.18715
Policy Entropy: 1.74985
Value Function Loss: 0.04915

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.30647
Value Function Update Magnitude: 0.33347

Collected Steps per Second: 22,154.02131
Overall Steps per Second: 10,444.33589

Timestep Collection Time: 2.25693
Timestep Consumption Time: 2.53036
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.78728

Cumulative Model Updates: 149,026
Cumulative Timesteps: 1,243,608,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1243608628...
Checkpoint 1243608628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,861.83297
Policy Entropy: 1.74157
Value Function Loss: 0.04869

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.30996
Value Function Update Magnitude: 0.33582

Collected Steps per Second: 22,248.01289
Overall Steps per Second: 10,706.26290

Timestep Collection Time: 2.24784
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.67110

Cumulative Model Updates: 149,032
Cumulative Timesteps: 1,243,658,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,548.75377
Policy Entropy: 1.72532
Value Function Loss: 0.05184

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.31047
Value Function Update Magnitude: 0.34179

Collected Steps per Second: 22,277.09888
Overall Steps per Second: 10,497.64767

Timestep Collection Time: 2.24580
Timestep Consumption Time: 2.52003
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.76583

Cumulative Model Updates: 149,038
Cumulative Timesteps: 1,243,708,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1243708668...
Checkpoint 1243708668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,082.31240
Policy Entropy: 1.72657
Value Function Loss: 0.05183

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.35310

Collected Steps per Second: 20,843.46922
Overall Steps per Second: 10,171.32880

Timestep Collection Time: 2.39989
Timestep Consumption Time: 2.51805
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.91794

Cumulative Model Updates: 149,044
Cumulative Timesteps: 1,243,758,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,394.77525
Policy Entropy: 1.71202
Value Function Loss: 0.04969

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.31365
Value Function Update Magnitude: 0.36654

Collected Steps per Second: 21,692.51789
Overall Steps per Second: 10,364.09769

Timestep Collection Time: 2.30513
Timestep Consumption Time: 2.51961
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.82473

Cumulative Model Updates: 149,050
Cumulative Timesteps: 1,243,808,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1243808694...
Checkpoint 1243808694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,335.46107
Policy Entropy: 1.71169
Value Function Loss: 0.04947

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.31352
Value Function Update Magnitude: 0.37021

Collected Steps per Second: 21,688.32268
Overall Steps per Second: 10,571.25604

Timestep Collection Time: 2.30566
Timestep Consumption Time: 2.42471
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.73037

Cumulative Model Updates: 149,056
Cumulative Timesteps: 1,243,858,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,895.34701
Policy Entropy: 1.70499
Value Function Loss: 0.04767

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.31671
Value Function Update Magnitude: 0.35605

Collected Steps per Second: 21,782.99476
Overall Steps per Second: 10,535.49742

Timestep Collection Time: 2.29537
Timestep Consumption Time: 2.45049
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.74586

Cumulative Model Updates: 149,062
Cumulative Timesteps: 1,243,908,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1243908700...
Checkpoint 1243908700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,348.83401
Policy Entropy: 1.72031
Value Function Loss: 0.04798

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.31567
Value Function Update Magnitude: 0.34253

Collected Steps per Second: 21,571.85317
Overall Steps per Second: 10,322.12268

Timestep Collection Time: 2.31941
Timestep Consumption Time: 2.52785
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.84726

Cumulative Model Updates: 149,068
Cumulative Timesteps: 1,243,958,734

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,997.65063
Policy Entropy: 1.71511
Value Function Loss: 0.04997

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.31361
Value Function Update Magnitude: 0.33716

Collected Steps per Second: 22,293.01691
Overall Steps per Second: 10,672.22765

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.68637

Cumulative Model Updates: 149,074
Cumulative Timesteps: 1,244,008,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1244008748...
Checkpoint 1244008748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,447.18848
Policy Entropy: 1.72909
Value Function Loss: 0.05127

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.31157
Value Function Update Magnitude: 0.33672

Collected Steps per Second: 22,074.73171
Overall Steps per Second: 10,645.97940

Timestep Collection Time: 2.26567
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.69792

Cumulative Model Updates: 149,080
Cumulative Timesteps: 1,244,058,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,380.72688
Policy Entropy: 1.73093
Value Function Loss: 0.05141

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.30761
Value Function Update Magnitude: 0.34763

Collected Steps per Second: 22,138.66122
Overall Steps per Second: 10,508.45212

Timestep Collection Time: 2.26012
Timestep Consumption Time: 2.50138
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.76150

Cumulative Model Updates: 149,086
Cumulative Timesteps: 1,244,108,798

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1244108798...
Checkpoint 1244108798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,647.25268
Policy Entropy: 1.76561
Value Function Loss: 0.05461

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.30889
Value Function Update Magnitude: 0.32807

Collected Steps per Second: 21,849.83471
Overall Steps per Second: 10,590.50280

Timestep Collection Time: 2.28880
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.72216

Cumulative Model Updates: 149,092
Cumulative Timesteps: 1,244,158,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,412.49893
Policy Entropy: 1.75181
Value Function Loss: 0.05532

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.29382
Value Function Update Magnitude: 0.31330

Collected Steps per Second: 22,161.17281
Overall Steps per Second: 10,534.79731

Timestep Collection Time: 2.25755
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.74902

Cumulative Model Updates: 149,098
Cumulative Timesteps: 1,244,208,838

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1244208838...
Checkpoint 1244208838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,411.07976
Policy Entropy: 1.76625
Value Function Loss: 0.05456

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.28900
Value Function Update Magnitude: 0.34413

Collected Steps per Second: 21,816.72009
Overall Steps per Second: 10,606.10784

Timestep Collection Time: 2.29219
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.71502

Cumulative Model Updates: 149,104
Cumulative Timesteps: 1,244,258,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,063.87435
Policy Entropy: 1.76830
Value Function Loss: 0.05227

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.30346
Value Function Update Magnitude: 0.33841

Collected Steps per Second: 21,648.10525
Overall Steps per Second: 10,584.75861

Timestep Collection Time: 2.31078
Timestep Consumption Time: 2.41526
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.72604

Cumulative Model Updates: 149,110
Cumulative Timesteps: 1,244,308,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1244308870...
Checkpoint 1244308870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,126.13069
Policy Entropy: 1.75632
Value Function Loss: 0.04946

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.30772
Value Function Update Magnitude: 0.34100

Collected Steps per Second: 21,367.88937
Overall Steps per Second: 10,494.41123

Timestep Collection Time: 2.33996
Timestep Consumption Time: 2.42448
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.76444

Cumulative Model Updates: 149,116
Cumulative Timesteps: 1,244,358,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,292.28085
Policy Entropy: 1.76066
Value Function Loss: 0.04939

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.30585
Value Function Update Magnitude: 0.34285

Collected Steps per Second: 21,877.80769
Overall Steps per Second: 10,487.73064

Timestep Collection Time: 2.28624
Timestep Consumption Time: 2.48295
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.76919

Cumulative Model Updates: 149,122
Cumulative Timesteps: 1,244,408,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1244408888...
Checkpoint 1244408888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,209.49233
Policy Entropy: 1.73041
Value Function Loss: 0.04888

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.30570
Value Function Update Magnitude: 0.32450

Collected Steps per Second: 21,550.29410
Overall Steps per Second: 10,409.97043

Timestep Collection Time: 2.32090
Timestep Consumption Time: 2.48373
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.80462

Cumulative Model Updates: 149,128
Cumulative Timesteps: 1,244,458,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,591.19486
Policy Entropy: 1.73697
Value Function Loss: 0.04637

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.30578
Value Function Update Magnitude: 0.31443

Collected Steps per Second: 22,024.91387
Overall Steps per Second: 10,603.23684

Timestep Collection Time: 2.27106
Timestep Consumption Time: 2.44636
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.71743

Cumulative Model Updates: 149,134
Cumulative Timesteps: 1,244,508,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1244508924...
Checkpoint 1244508924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,393.09256
Policy Entropy: 1.72105
Value Function Loss: 0.04376

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07896
Policy Update Magnitude: 0.30225
Value Function Update Magnitude: 0.31800

Collected Steps per Second: 21,763.06876
Overall Steps per Second: 10,403.55965

Timestep Collection Time: 2.29830
Timestep Consumption Time: 2.50948
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.80778

Cumulative Model Updates: 149,140
Cumulative Timesteps: 1,244,558,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,862.25168
Policy Entropy: 1.73370
Value Function Loss: 0.04797

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.30197
Value Function Update Magnitude: 0.30837

Collected Steps per Second: 21,736.52604
Overall Steps per Second: 10,719.53565

Timestep Collection Time: 2.30046
Timestep Consumption Time: 2.36429
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.66475

Cumulative Model Updates: 149,146
Cumulative Timesteps: 1,244,608,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1244608946...
Checkpoint 1244608946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,620.58570
Policy Entropy: 1.73108
Value Function Loss: 0.04676

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.30443
Value Function Update Magnitude: 0.30784

Collected Steps per Second: 21,131.95620
Overall Steps per Second: 10,627.70801

Timestep Collection Time: 2.36656
Timestep Consumption Time: 2.33907
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.70562

Cumulative Model Updates: 149,152
Cumulative Timesteps: 1,244,658,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,011.34834
Policy Entropy: 1.72190
Value Function Loss: 0.04948

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.30582
Value Function Update Magnitude: 0.30973

Collected Steps per Second: 21,710.96352
Overall Steps per Second: 10,519.25095

Timestep Collection Time: 2.30381
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.75490

Cumulative Model Updates: 149,158
Cumulative Timesteps: 1,244,708,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1244708974...
Checkpoint 1244708974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,237.30616
Policy Entropy: 1.71825
Value Function Loss: 0.04678

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.31069
Value Function Update Magnitude: 0.30065

Collected Steps per Second: 20,840.67121
Overall Steps per Second: 10,375.51983

Timestep Collection Time: 2.40079
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.82231

Cumulative Model Updates: 149,164
Cumulative Timesteps: 1,244,759,008

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,240.94412
Policy Entropy: 1.71401
Value Function Loss: 0.04574

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.30530
Value Function Update Magnitude: 0.31862

Collected Steps per Second: 21,893.84325
Overall Steps per Second: 10,675.21537

Timestep Collection Time: 2.28585
Timestep Consumption Time: 2.40221
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.68806

Cumulative Model Updates: 149,170
Cumulative Timesteps: 1,244,809,054

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1244809054...
Checkpoint 1244809054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,395.20369
Policy Entropy: 1.70493
Value Function Loss: 0.04362

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.30449
Value Function Update Magnitude: 0.32808

Collected Steps per Second: 21,377.79678
Overall Steps per Second: 10,414.02148

Timestep Collection Time: 2.33962
Timestep Consumption Time: 2.46313
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.80276

Cumulative Model Updates: 149,176
Cumulative Timesteps: 1,244,859,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,367.57299
Policy Entropy: 1.69977
Value Function Loss: 0.04158

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.30489
Value Function Update Magnitude: 0.32553

Collected Steps per Second: 21,776.56878
Overall Steps per Second: 10,657.61341

Timestep Collection Time: 2.29641
Timestep Consumption Time: 2.39582
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.69223

Cumulative Model Updates: 149,182
Cumulative Timesteps: 1,244,909,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1244909078...
Checkpoint 1244909078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,754.47089
Policy Entropy: 1.69783
Value Function Loss: 0.04200

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.30505
Value Function Update Magnitude: 0.32317

Collected Steps per Second: 21,431.90185
Overall Steps per Second: 10,277.21538

Timestep Collection Time: 2.33325
Timestep Consumption Time: 2.53246
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.86571

Cumulative Model Updates: 149,188
Cumulative Timesteps: 1,244,959,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,871.94841
Policy Entropy: 1.70725
Value Function Loss: 0.04353

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.30163
Value Function Update Magnitude: 0.32230

Collected Steps per Second: 21,646.67728
Overall Steps per Second: 10,440.14896

Timestep Collection Time: 2.31010
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.78978

Cumulative Model Updates: 149,194
Cumulative Timesteps: 1,245,009,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1245009090...
Checkpoint 1245009090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,883.83794
Policy Entropy: 1.71762
Value Function Loss: 0.04377

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.29124
Value Function Update Magnitude: 0.32519

Collected Steps per Second: 21,506.93994
Overall Steps per Second: 10,357.81874

Timestep Collection Time: 2.32576
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.82920

Cumulative Model Updates: 149,200
Cumulative Timesteps: 1,245,059,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,396.49726
Policy Entropy: 1.71433
Value Function Loss: 0.04580

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.28703
Value Function Update Magnitude: 0.32020

Collected Steps per Second: 22,380.09039
Overall Steps per Second: 10,650.29895

Timestep Collection Time: 2.23413
Timestep Consumption Time: 2.46058
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.69470

Cumulative Model Updates: 149,206
Cumulative Timesteps: 1,245,109,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1245109110...
Checkpoint 1245109110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,287.49379
Policy Entropy: 1.70615
Value Function Loss: 0.04925

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.30572
Value Function Update Magnitude: 0.32110

Collected Steps per Second: 21,934.84985
Overall Steps per Second: 10,462.66659

Timestep Collection Time: 2.28057
Timestep Consumption Time: 2.50062
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.78119

Cumulative Model Updates: 149,212
Cumulative Timesteps: 1,245,159,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,710.47948
Policy Entropy: 1.71270
Value Function Loss: 0.05011

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.31732
Value Function Update Magnitude: 0.35627

Collected Steps per Second: 22,164.51537
Overall Steps per Second: 10,650.15780

Timestep Collection Time: 2.25604
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.69514

Cumulative Model Updates: 149,218
Cumulative Timesteps: 1,245,209,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1245209138...
Checkpoint 1245209138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,208.77823
Policy Entropy: 1.72959
Value Function Loss: 0.05171

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.32278
Value Function Update Magnitude: 0.36334

Collected Steps per Second: 21,968.95569
Overall Steps per Second: 10,645.99606

Timestep Collection Time: 2.27821
Timestep Consumption Time: 2.42308
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.70130

Cumulative Model Updates: 149,224
Cumulative Timesteps: 1,245,259,188

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,263.73721
Policy Entropy: 1.74253
Value Function Loss: 0.04982

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.31488
Value Function Update Magnitude: 0.36212

Collected Steps per Second: 22,278.03808
Overall Steps per Second: 10,505.03453

Timestep Collection Time: 2.24508
Timestep Consumption Time: 2.51606
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.76115

Cumulative Model Updates: 149,230
Cumulative Timesteps: 1,245,309,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1245309204...
Checkpoint 1245309204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,917.59297
Policy Entropy: 1.73174
Value Function Loss: 0.05175

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.31338
Value Function Update Magnitude: 0.35989

Collected Steps per Second: 21,929.19853
Overall Steps per Second: 10,603.95490

Timestep Collection Time: 2.28043
Timestep Consumption Time: 2.43555
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.71598

Cumulative Model Updates: 149,236
Cumulative Timesteps: 1,245,359,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,506.71883
Policy Entropy: 1.72174
Value Function Loss: 0.04880

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.31230
Value Function Update Magnitude: 0.36587

Collected Steps per Second: 22,066.36441
Overall Steps per Second: 10,538.97559

Timestep Collection Time: 2.26598
Timestep Consumption Time: 2.47850
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.74448

Cumulative Model Updates: 149,242
Cumulative Timesteps: 1,245,409,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1245409214...
Checkpoint 1245409214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,640.53459
Policy Entropy: 1.73201
Value Function Loss: 0.04997

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.31715
Value Function Update Magnitude: 0.35953

Collected Steps per Second: 21,505.22836
Overall Steps per Second: 10,534.23823

Timestep Collection Time: 2.32520
Timestep Consumption Time: 2.42161
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.74681

Cumulative Model Updates: 149,248
Cumulative Timesteps: 1,245,459,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,965.82089
Policy Entropy: 1.73743
Value Function Loss: 0.04674

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.35770

Collected Steps per Second: 21,490.22285
Overall Steps per Second: 10,470.83344

Timestep Collection Time: 2.32701
Timestep Consumption Time: 2.44892
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.77593

Cumulative Model Updates: 149,254
Cumulative Timesteps: 1,245,509,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1245509226...
Checkpoint 1245509226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,835.43330
Policy Entropy: 1.75308
Value Function Loss: 0.05270

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08439
Policy Update Magnitude: 0.31919
Value Function Update Magnitude: 0.37056

Collected Steps per Second: 21,283.81161
Overall Steps per Second: 10,281.62127

Timestep Collection Time: 2.35061
Timestep Consumption Time: 2.51535
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.86596

Cumulative Model Updates: 149,260
Cumulative Timesteps: 1,245,559,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,330.21493
Policy Entropy: 1.74798
Value Function Loss: 0.04913

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.31593
Value Function Update Magnitude: 0.36704

Collected Steps per Second: 21,658.87194
Overall Steps per Second: 10,429.45481

Timestep Collection Time: 2.30917
Timestep Consumption Time: 2.48629
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.79546

Cumulative Model Updates: 149,266
Cumulative Timesteps: 1,245,609,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1245609270...
Checkpoint 1245609270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,590.46594
Policy Entropy: 1.74702
Value Function Loss: 0.05059

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.30893
Value Function Update Magnitude: 0.35376

Collected Steps per Second: 21,380.66220
Overall Steps per Second: 10,319.98109

Timestep Collection Time: 2.33987
Timestep Consumption Time: 2.50781
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.84768

Cumulative Model Updates: 149,272
Cumulative Timesteps: 1,245,659,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,931.72692
Policy Entropy: 1.72627
Value Function Loss: 0.04682

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.30795
Value Function Update Magnitude: 0.34362

Collected Steps per Second: 22,073.47492
Overall Steps per Second: 10,361.74515

Timestep Collection Time: 2.26580
Timestep Consumption Time: 2.56100
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.82679

Cumulative Model Updates: 149,278
Cumulative Timesteps: 1,245,709,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1245709312...
Checkpoint 1245709312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,038.71354
Policy Entropy: 1.72779
Value Function Loss: 0.04603

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.30652
Value Function Update Magnitude: 0.34494

Collected Steps per Second: 21,853.27922
Overall Steps per Second: 10,540.49227

Timestep Collection Time: 2.28826
Timestep Consumption Time: 2.45592
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.74418

Cumulative Model Updates: 149,284
Cumulative Timesteps: 1,245,759,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,871.96186
Policy Entropy: 1.71883
Value Function Loss: 0.04587

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.30650
Value Function Update Magnitude: 0.35514

Collected Steps per Second: 22,233.37962
Overall Steps per Second: 10,547.47953

Timestep Collection Time: 2.24923
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.74123

Cumulative Model Updates: 149,290
Cumulative Timesteps: 1,245,809,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1245809326...
Checkpoint 1245809326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,332.85928
Policy Entropy: 1.71537
Value Function Loss: 0.04219

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.30050
Value Function Update Magnitude: 0.34498

Collected Steps per Second: 22,038.38342
Overall Steps per Second: 10,661.34201

Timestep Collection Time: 2.26886
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.69003

Cumulative Model Updates: 149,296
Cumulative Timesteps: 1,245,859,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,198.84729
Policy Entropy: 1.71452
Value Function Loss: 0.04507

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.29944
Value Function Update Magnitude: 0.33099

Collected Steps per Second: 22,115.71915
Overall Steps per Second: 10,469.17258

Timestep Collection Time: 2.26201
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.77841

Cumulative Model Updates: 149,302
Cumulative Timesteps: 1,245,909,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1245909354...
Checkpoint 1245909354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,935.48258
Policy Entropy: 1.71773
Value Function Loss: 0.04716

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.30767
Value Function Update Magnitude: 0.33235

Collected Steps per Second: 22,062.18125
Overall Steps per Second: 10,604.10733

Timestep Collection Time: 2.26650
Timestep Consumption Time: 2.44903
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.71553

Cumulative Model Updates: 149,308
Cumulative Timesteps: 1,245,959,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,826.97368
Policy Entropy: 1.71734
Value Function Loss: 0.04830

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.30610
Value Function Update Magnitude: 0.32959

Collected Steps per Second: 22,128.78956
Overall Steps per Second: 10,488.03050

Timestep Collection Time: 2.25950
Timestep Consumption Time: 2.50784
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.76734

Cumulative Model Updates: 149,314
Cumulative Timesteps: 1,246,009,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1246009358...
Checkpoint 1246009358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,044.60786
Policy Entropy: 1.70835
Value Function Loss: 0.05362

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.30141
Value Function Update Magnitude: 0.31559

Collected Steps per Second: 21,334.96678
Overall Steps per Second: 10,494.36107

Timestep Collection Time: 2.34563
Timestep Consumption Time: 2.42302
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.76866

Cumulative Model Updates: 149,320
Cumulative Timesteps: 1,246,059,402

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,706.58453
Policy Entropy: 1.71893
Value Function Loss: 0.05131

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.33427

Collected Steps per Second: 21,702.23567
Overall Steps per Second: 10,586.53768

Timestep Collection Time: 2.30603
Timestep Consumption Time: 2.42129
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.72732

Cumulative Model Updates: 149,326
Cumulative Timesteps: 1,246,109,448

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1246109448...
Checkpoint 1246109448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,768.93290
Policy Entropy: 1.71986
Value Function Loss: 0.04840

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.31499
Value Function Update Magnitude: 0.34544

Collected Steps per Second: 21,453.95525
Overall Steps per Second: 10,521.32452

Timestep Collection Time: 2.33225
Timestep Consumption Time: 2.42342
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.75568

Cumulative Model Updates: 149,332
Cumulative Timesteps: 1,246,159,484

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,090.85662
Policy Entropy: 1.73669
Value Function Loss: 0.04706

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.31189
Value Function Update Magnitude: 0.31010

Collected Steps per Second: 21,530.27077
Overall Steps per Second: 10,513.89471

Timestep Collection Time: 2.32371
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.75846

Cumulative Model Updates: 149,338
Cumulative Timesteps: 1,246,209,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1246209514...
Checkpoint 1246209514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,224.94032
Policy Entropy: 1.71081
Value Function Loss: 0.04621

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.30615
Value Function Update Magnitude: 0.24129

Collected Steps per Second: 20,893.60925
Overall Steps per Second: 10,414.80150

Timestep Collection Time: 2.39413
Timestep Consumption Time: 2.40884
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.80297

Cumulative Model Updates: 149,344
Cumulative Timesteps: 1,246,259,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,564.06017
Policy Entropy: 1.69531
Value Function Loss: 0.04714

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.30247
Value Function Update Magnitude: 0.27159

Collected Steps per Second: 21,759.86628
Overall Steps per Second: 10,696.23667

Timestep Collection Time: 2.29827
Timestep Consumption Time: 2.37721
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.67548

Cumulative Model Updates: 149,350
Cumulative Timesteps: 1,246,309,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1246309546...
Checkpoint 1246309546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,953.24466
Policy Entropy: 1.68610
Value Function Loss: 0.04466

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.29377
Value Function Update Magnitude: 0.29642

Collected Steps per Second: 21,516.02630
Overall Steps per Second: 10,682.06132

Timestep Collection Time: 2.32441
Timestep Consumption Time: 2.35746
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.68187

Cumulative Model Updates: 149,356
Cumulative Timesteps: 1,246,359,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,524.91472
Policy Entropy: 1.69343
Value Function Loss: 0.04395

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.27760
Value Function Update Magnitude: 0.29397

Collected Steps per Second: 21,537.53969
Overall Steps per Second: 10,417.70852

Timestep Collection Time: 2.32376
Timestep Consumption Time: 2.48037
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.80413

Cumulative Model Updates: 149,362
Cumulative Timesteps: 1,246,409,606

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1246409606...
Checkpoint 1246409606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,313.88566
Policy Entropy: 1.69757
Value Function Loss: 0.04432

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.29723
Value Function Update Magnitude: 0.28765

Collected Steps per Second: 21,947.62285
Overall Steps per Second: 10,689.86255

Timestep Collection Time: 2.27833
Timestep Consumption Time: 2.39937
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.67770

Cumulative Model Updates: 149,368
Cumulative Timesteps: 1,246,459,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,639.22634
Policy Entropy: 1.70302
Value Function Loss: 0.04533

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.30415
Value Function Update Magnitude: 0.26531

Collected Steps per Second: 22,026.23489
Overall Steps per Second: 10,523.31992

Timestep Collection Time: 2.27175
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.75496

Cumulative Model Updates: 149,374
Cumulative Timesteps: 1,246,509,648

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1246509648...
Checkpoint 1246509648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,685.76566
Policy Entropy: 1.68329
Value Function Loss: 0.04529

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.30734
Value Function Update Magnitude: 0.24810

Collected Steps per Second: 21,640.97654
Overall Steps per Second: 10,518.11487

Timestep Collection Time: 2.31052
Timestep Consumption Time: 2.44337
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.75389

Cumulative Model Updates: 149,380
Cumulative Timesteps: 1,246,559,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,257.66242
Policy Entropy: 1.69292
Value Function Loss: 0.04487

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.28437

Collected Steps per Second: 21,713.58416
Overall Steps per Second: 10,432.33916

Timestep Collection Time: 2.30298
Timestep Consumption Time: 2.49038
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.79336

Cumulative Model Updates: 149,386
Cumulative Timesteps: 1,246,609,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1246609656...
Checkpoint 1246609656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,467.70994
Policy Entropy: 1.67825
Value Function Loss: 0.04795

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.31129
Value Function Update Magnitude: 0.30312

Collected Steps per Second: 21,436.64128
Overall Steps per Second: 10,332.90996

Timestep Collection Time: 2.33488
Timestep Consumption Time: 2.50906
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.84394

Cumulative Model Updates: 149,392
Cumulative Timesteps: 1,246,659,708

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,239.70252
Policy Entropy: 1.68564
Value Function Loss: 0.05164

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.31193
Value Function Update Magnitude: 0.31777

Collected Steps per Second: 21,543.12776
Overall Steps per Second: 10,316.23165

Timestep Collection Time: 2.32130
Timestep Consumption Time: 2.52621
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.84751

Cumulative Model Updates: 149,398
Cumulative Timesteps: 1,246,709,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1246709716...
Checkpoint 1246709716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,366.82307
Policy Entropy: 1.67930
Value Function Loss: 0.04964

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.30507
Value Function Update Magnitude: 0.34254

Collected Steps per Second: 21,493.37861
Overall Steps per Second: 10,333.15917

Timestep Collection Time: 2.32732
Timestep Consumption Time: 2.51360
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.84092

Cumulative Model Updates: 149,404
Cumulative Timesteps: 1,246,759,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,879.99971
Policy Entropy: 1.69669
Value Function Loss: 0.04761

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.30370
Value Function Update Magnitude: 0.33781

Collected Steps per Second: 21,983.34202
Overall Steps per Second: 10,353.92811

Timestep Collection Time: 2.27545
Timestep Consumption Time: 2.55576
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.83121

Cumulative Model Updates: 149,410
Cumulative Timesteps: 1,246,809,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1246809760...
Checkpoint 1246809760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,038.36308
Policy Entropy: 1.70694
Value Function Loss: 0.04737

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.31181
Value Function Update Magnitude: 0.32367

Collected Steps per Second: 21,842.66382
Overall Steps per Second: 10,560.05760

Timestep Collection Time: 2.28983
Timestep Consumption Time: 2.44651
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.73634

Cumulative Model Updates: 149,416
Cumulative Timesteps: 1,246,859,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,085.92375
Policy Entropy: 1.72329
Value Function Loss: 0.04587

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.31420
Value Function Update Magnitude: 0.31409

Collected Steps per Second: 22,135.80418
Overall Steps per Second: 10,517.39883

Timestep Collection Time: 2.25969
Timestep Consumption Time: 2.49624
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.75593

Cumulative Model Updates: 149,422
Cumulative Timesteps: 1,246,909,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1246909796...
Checkpoint 1246909796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,012.99768
Policy Entropy: 1.71816
Value Function Loss: 0.04963

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.30998
Value Function Update Magnitude: 0.31341

Collected Steps per Second: 21,994.17262
Overall Steps per Second: 10,619.90940

Timestep Collection Time: 2.27406
Timestep Consumption Time: 2.43559
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.70964

Cumulative Model Updates: 149,428
Cumulative Timesteps: 1,246,959,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,550.87741
Policy Entropy: 1.71719
Value Function Loss: 0.05074

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.31128
Value Function Update Magnitude: 0.32736

Collected Steps per Second: 21,677.86183
Overall Steps per Second: 10,469.28094

Timestep Collection Time: 2.30890
Timestep Consumption Time: 2.47194
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.78084

Cumulative Model Updates: 149,434
Cumulative Timesteps: 1,247,009,864

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1247009864...
Checkpoint 1247009864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,167.28478
Policy Entropy: 1.71566
Value Function Loss: 0.05354

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.31199
Value Function Update Magnitude: 0.33710

Collected Steps per Second: 21,693.79026
Overall Steps per Second: 10,585.10809

Timestep Collection Time: 2.30619
Timestep Consumption Time: 2.42026
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.72645

Cumulative Model Updates: 149,440
Cumulative Timesteps: 1,247,059,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,043.62547
Policy Entropy: 1.72217
Value Function Loss: 0.05195

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.30200
Value Function Update Magnitude: 0.34675

Collected Steps per Second: 22,130.02656
Overall Steps per Second: 10,498.24627

Timestep Collection Time: 2.26010
Timestep Consumption Time: 2.50413
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.76422

Cumulative Model Updates: 149,446
Cumulative Timesteps: 1,247,109,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1247109910...
Checkpoint 1247109910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,521.95278
Policy Entropy: 1.73069
Value Function Loss: 0.05107

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.30830
Value Function Update Magnitude: 0.34338

Collected Steps per Second: 21,668.77832
Overall Steps per Second: 10,399.99292

Timestep Collection Time: 2.30885
Timestep Consumption Time: 2.50173
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.81058

Cumulative Model Updates: 149,452
Cumulative Timesteps: 1,247,159,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,522.68748
Policy Entropy: 1.71463
Value Function Loss: 0.05073

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.30136
Value Function Update Magnitude: 0.33578

Collected Steps per Second: 21,595.11538
Overall Steps per Second: 10,404.19012

Timestep Collection Time: 2.31599
Timestep Consumption Time: 2.49112
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.80710

Cumulative Model Updates: 149,458
Cumulative Timesteps: 1,247,209,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1247209954...
Checkpoint 1247209954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,283.67183
Policy Entropy: 1.70353
Value Function Loss: 0.04917

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.29093
Value Function Update Magnitude: 0.34194

Collected Steps per Second: 21,198.10941
Overall Steps per Second: 10,558.06082

Timestep Collection Time: 2.35927
Timestep Consumption Time: 2.37759
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.73685

Cumulative Model Updates: 149,464
Cumulative Timesteps: 1,247,259,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,769.45463
Policy Entropy: 1.69799
Value Function Loss: 0.05213

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.30207
Value Function Update Magnitude: 0.34637

Collected Steps per Second: 21,190.23155
Overall Steps per Second: 10,424.39742

Timestep Collection Time: 2.36071
Timestep Consumption Time: 2.43803
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.79874

Cumulative Model Updates: 149,470
Cumulative Timesteps: 1,247,309,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1247309990...
Checkpoint 1247309990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,888.93811
Policy Entropy: 1.71650
Value Function Loss: 0.05114

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.28934
Value Function Update Magnitude: 0.34836

Collected Steps per Second: 20,635.11367
Overall Steps per Second: 10,284.99080

Timestep Collection Time: 2.42412
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.86359

Cumulative Model Updates: 149,476
Cumulative Timesteps: 1,247,360,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,804.27057
Policy Entropy: 1.72375
Value Function Loss: 0.05684

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.30098
Value Function Update Magnitude: 0.34095

Collected Steps per Second: 21,414.44122
Overall Steps per Second: 10,433.76064

Timestep Collection Time: 2.33618
Timestep Consumption Time: 2.45864
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.79482

Cumulative Model Updates: 149,482
Cumulative Timesteps: 1,247,410,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1247410040...
Checkpoint 1247410040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,774.24053
Policy Entropy: 1.72908
Value Function Loss: 0.05292

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08763
Policy Update Magnitude: 0.31543
Value Function Update Magnitude: 0.35513

Collected Steps per Second: 21,550.86885
Overall Steps per Second: 10,553.76389

Timestep Collection Time: 2.32074
Timestep Consumption Time: 2.41823
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.73897

Cumulative Model Updates: 149,488
Cumulative Timesteps: 1,247,460,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,620.53572
Policy Entropy: 1.72617
Value Function Loss: 0.05250

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.31228
Value Function Update Magnitude: 0.34989

Collected Steps per Second: 20,989.34455
Overall Steps per Second: 10,183.90320

Timestep Collection Time: 2.38283
Timestep Consumption Time: 2.52826
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.91108

Cumulative Model Updates: 149,494
Cumulative Timesteps: 1,247,510,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1247510068...
Checkpoint 1247510068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,289.63766
Policy Entropy: 1.71847
Value Function Loss: 0.04797

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.29574
Value Function Update Magnitude: 0.32624

Collected Steps per Second: 21,928.84473
Overall Steps per Second: 10,478.11282

Timestep Collection Time: 2.28065
Timestep Consumption Time: 2.49235
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.77300

Cumulative Model Updates: 149,500
Cumulative Timesteps: 1,247,560,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,317.06225
Policy Entropy: 1.68293
Value Function Loss: 0.04853

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.28025
Value Function Update Magnitude: 0.33531

Collected Steps per Second: 21,951.57037
Overall Steps per Second: 10,516.32471

Timestep Collection Time: 2.27801
Timestep Consumption Time: 2.47707
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.75508

Cumulative Model Updates: 149,506
Cumulative Timesteps: 1,247,610,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1247610086...
Checkpoint 1247610086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,575.49869
Policy Entropy: 1.67478
Value Function Loss: 0.04523

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.29751
Value Function Update Magnitude: 0.31347

Collected Steps per Second: 22,274.05487
Overall Steps per Second: 10,580.44662

Timestep Collection Time: 2.24530
Timestep Consumption Time: 2.48153
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.72683

Cumulative Model Updates: 149,512
Cumulative Timesteps: 1,247,660,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,243.39171
Policy Entropy: 1.68304
Value Function Loss: 0.04462

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07908
Policy Update Magnitude: 0.30532
Value Function Update Magnitude: 0.29553

Collected Steps per Second: 22,093.97592
Overall Steps per Second: 10,450.26477

Timestep Collection Time: 2.26342
Timestep Consumption Time: 2.52191
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.78533

Cumulative Model Updates: 149,518
Cumulative Timesteps: 1,247,710,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1247710106...
Checkpoint 1247710106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,875.05812
Policy Entropy: 1.70295
Value Function Loss: 0.04514

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.30886
Value Function Update Magnitude: 0.29803

Collected Steps per Second: 22,026.79054
Overall Steps per Second: 10,625.69517

Timestep Collection Time: 2.27123
Timestep Consumption Time: 2.43698
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.70821

Cumulative Model Updates: 149,524
Cumulative Timesteps: 1,247,760,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,072.93205
Policy Entropy: 1.69953
Value Function Loss: 0.04876

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.31387
Value Function Update Magnitude: 0.29477

Collected Steps per Second: 21,366.77730
Overall Steps per Second: 10,450.92738

Timestep Collection Time: 2.34046
Timestep Consumption Time: 2.44457
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.78503

Cumulative Model Updates: 149,530
Cumulative Timesteps: 1,247,810,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1247810142...
Checkpoint 1247810142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,280.05643
Policy Entropy: 1.70698
Value Function Loss: 0.04888

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.31687
Value Function Update Magnitude: 0.33869

Collected Steps per Second: 21,441.22844
Overall Steps per Second: 10,329.77916

Timestep Collection Time: 2.33298
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.84250

Cumulative Model Updates: 149,536
Cumulative Timesteps: 1,247,860,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,849.88990
Policy Entropy: 1.70723
Value Function Loss: 0.05007

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.32079
Value Function Update Magnitude: 0.37921

Collected Steps per Second: 21,778.40163
Overall Steps per Second: 10,410.91269

Timestep Collection Time: 2.29585
Timestep Consumption Time: 2.50680
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.80265

Cumulative Model Updates: 149,542
Cumulative Timesteps: 1,247,910,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1247910164...
Checkpoint 1247910164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,717.15716
Policy Entropy: 1.71809
Value Function Loss: 0.05101

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.32452
Value Function Update Magnitude: 0.36288

Collected Steps per Second: 21,675.68007
Overall Steps per Second: 10,527.66485

Timestep Collection Time: 2.30793
Timestep Consumption Time: 2.44393
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.75186

Cumulative Model Updates: 149,548
Cumulative Timesteps: 1,247,960,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,569.80410
Policy Entropy: 1.72130
Value Function Loss: 0.05132

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.32226
Value Function Update Magnitude: 0.35805

Collected Steps per Second: 21,632.03607
Overall Steps per Second: 10,504.76017

Timestep Collection Time: 2.31259
Timestep Consumption Time: 2.44963
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.76222

Cumulative Model Updates: 149,554
Cumulative Timesteps: 1,248,010,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1248010216...
Checkpoint 1248010216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,400.68074
Policy Entropy: 1.71558
Value Function Loss: 0.05317

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.32263
Value Function Update Magnitude: 0.37486

Collected Steps per Second: 22,055.18858
Overall Steps per Second: 10,572.87679

Timestep Collection Time: 2.26822
Timestep Consumption Time: 2.46332
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.73154

Cumulative Model Updates: 149,560
Cumulative Timesteps: 1,248,060,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,333.46128
Policy Entropy: 1.71115
Value Function Loss: 0.05380

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.32550
Value Function Update Magnitude: 0.38101

Collected Steps per Second: 21,904.89661
Overall Steps per Second: 10,465.36588

Timestep Collection Time: 2.28360
Timestep Consumption Time: 2.49617
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.77977

Cumulative Model Updates: 149,566
Cumulative Timesteps: 1,248,110,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1248110264...
Checkpoint 1248110264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,630.08279
Policy Entropy: 1.72085
Value Function Loss: 0.05439

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.32762
Value Function Update Magnitude: 0.37641

Collected Steps per Second: 21,776.63594
Overall Steps per Second: 10,424.30175

Timestep Collection Time: 2.29769
Timestep Consumption Time: 2.50225
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.79994

Cumulative Model Updates: 149,572
Cumulative Timesteps: 1,248,160,300

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,321.00486
Policy Entropy: 1.71592
Value Function Loss: 0.05093

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.32349
Value Function Update Magnitude: 0.36981

Collected Steps per Second: 21,804.13599
Overall Steps per Second: 10,655.59654

Timestep Collection Time: 2.29415
Timestep Consumption Time: 2.40028
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.69443

Cumulative Model Updates: 149,578
Cumulative Timesteps: 1,248,210,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1248210322...
Checkpoint 1248210322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,290.68775
Policy Entropy: 1.71765
Value Function Loss: 0.05279

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.32289
Value Function Update Magnitude: 0.35786

Collected Steps per Second: 21,921.82181
Overall Steps per Second: 10,629.98261

Timestep Collection Time: 2.28266
Timestep Consumption Time: 2.42478
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.70744

Cumulative Model Updates: 149,584
Cumulative Timesteps: 1,248,260,362

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,862.99456
Policy Entropy: 1.72921
Value Function Loss: 0.05472

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.32591
Value Function Update Magnitude: 0.37513

Collected Steps per Second: 22,079.74592
Overall Steps per Second: 10,531.81497

Timestep Collection Time: 2.26552
Timestep Consumption Time: 2.48409
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.74961

Cumulative Model Updates: 149,590
Cumulative Timesteps: 1,248,310,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1248310384...
Checkpoint 1248310384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,043.20771
Policy Entropy: 1.73076
Value Function Loss: 0.05494

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.32474
Value Function Update Magnitude: 0.37615

Collected Steps per Second: 21,836.33490
Overall Steps per Second: 10,582.45932

Timestep Collection Time: 2.29022
Timestep Consumption Time: 2.43553
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.72574

Cumulative Model Updates: 149,596
Cumulative Timesteps: 1,248,360,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,255.16638
Policy Entropy: 1.72811
Value Function Loss: 0.05329

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.32415
Value Function Update Magnitude: 0.34423

Collected Steps per Second: 21,558.63164
Overall Steps per Second: 10,508.81768

Timestep Collection Time: 2.31944
Timestep Consumption Time: 2.43885
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.75829

Cumulative Model Updates: 149,602
Cumulative Timesteps: 1,248,410,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1248410398...
Checkpoint 1248410398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,140.14883
Policy Entropy: 1.71431
Value Function Loss: 0.05155

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.32281
Value Function Update Magnitude: 0.34727

Collected Steps per Second: 21,259.23699
Overall Steps per Second: 10,262.67878

Timestep Collection Time: 2.35248
Timestep Consumption Time: 2.52071
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.87319

Cumulative Model Updates: 149,608
Cumulative Timesteps: 1,248,460,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,210.78399
Policy Entropy: 1.70108
Value Function Loss: 0.04945

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.31956
Value Function Update Magnitude: 0.35919

Collected Steps per Second: 21,869.13187
Overall Steps per Second: 10,400.93001

Timestep Collection Time: 2.28752
Timestep Consumption Time: 2.52225
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.80976

Cumulative Model Updates: 149,614
Cumulative Timesteps: 1,248,510,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1248510436...
Checkpoint 1248510436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,455.53121
Policy Entropy: 1.70854
Value Function Loss: 0.04646

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.30238
Value Function Update Magnitude: 0.34873

Collected Steps per Second: 22,053.46752
Overall Steps per Second: 10,552.43892

Timestep Collection Time: 2.26930
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.74260

Cumulative Model Updates: 149,620
Cumulative Timesteps: 1,248,560,482

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,408.73497
Policy Entropy: 1.69126
Value Function Loss: 0.04641

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.27702
Value Function Update Magnitude: 0.33376

Collected Steps per Second: 22,001.05103
Overall Steps per Second: 10,602.55575

Timestep Collection Time: 2.27262
Timestep Consumption Time: 2.44323
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.71584

Cumulative Model Updates: 149,626
Cumulative Timesteps: 1,248,610,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1248610482...
Checkpoint 1248610482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,396.54683
Policy Entropy: 1.70693
Value Function Loss: 0.04597

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.29363
Value Function Update Magnitude: 0.33201

Collected Steps per Second: 21,808.00272
Overall Steps per Second: 10,551.52053

Timestep Collection Time: 2.29347
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.74017

Cumulative Model Updates: 149,632
Cumulative Timesteps: 1,248,660,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,755.56601
Policy Entropy: 1.71037
Value Function Loss: 0.04503

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.34171

Collected Steps per Second: 22,227.40919
Overall Steps per Second: 10,501.79154

Timestep Collection Time: 2.24965
Timestep Consumption Time: 2.51182
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.76147

Cumulative Model Updates: 149,638
Cumulative Timesteps: 1,248,710,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1248710502...
Checkpoint 1248710502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,220.18947
Policy Entropy: 1.71886
Value Function Loss: 0.04463

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.31062
Value Function Update Magnitude: 0.34357

Collected Steps per Second: 21,810.78719
Overall Steps per Second: 10,577.08620

Timestep Collection Time: 2.29336
Timestep Consumption Time: 2.43573
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.72909

Cumulative Model Updates: 149,644
Cumulative Timesteps: 1,248,760,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,095.45624
Policy Entropy: 1.72903
Value Function Loss: 0.04858

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.31477
Value Function Update Magnitude: 0.34875

Collected Steps per Second: 22,129.83669
Overall Steps per Second: 10,494.12568

Timestep Collection Time: 2.26120
Timestep Consumption Time: 2.50718
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.76838

Cumulative Model Updates: 149,650
Cumulative Timesteps: 1,248,810,562

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1248810562...
Checkpoint 1248810562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,019.53978
Policy Entropy: 1.71154
Value Function Loss: 0.05027

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.32041
Value Function Update Magnitude: 0.34995

Collected Steps per Second: 21,176.01064
Overall Steps per Second: 10,590.78057

Timestep Collection Time: 2.36239
Timestep Consumption Time: 2.36115
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.72354

Cumulative Model Updates: 149,656
Cumulative Timesteps: 1,248,860,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,121.89499
Policy Entropy: 1.71957
Value Function Loss: 0.05281

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.32453
Value Function Update Magnitude: 0.35489

Collected Steps per Second: 20,868.24364
Overall Steps per Second: 10,504.56248

Timestep Collection Time: 2.39608
Timestep Consumption Time: 2.36395
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.76003

Cumulative Model Updates: 149,662
Cumulative Timesteps: 1,248,910,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1248910590...
Checkpoint 1248910590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,079.33046
Policy Entropy: 1.72993
Value Function Loss: 0.05361

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.32701
Value Function Update Magnitude: 0.36170

Collected Steps per Second: 21,099.10372
Overall Steps per Second: 10,581.71722

Timestep Collection Time: 2.36986
Timestep Consumption Time: 2.35546
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.72532

Cumulative Model Updates: 149,668
Cumulative Timesteps: 1,248,960,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,498.94411
Policy Entropy: 1.71561
Value Function Loss: 0.05479

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.32637
Value Function Update Magnitude: 0.35475

Collected Steps per Second: 21,018.10819
Overall Steps per Second: 10,434.17698

Timestep Collection Time: 2.38099
Timestep Consumption Time: 2.41517
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.79616

Cumulative Model Updates: 149,674
Cumulative Timesteps: 1,249,010,636

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1249010636...
Checkpoint 1249010636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,502.48150
Policy Entropy: 1.71777
Value Function Loss: 0.05691

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.32749
Value Function Update Magnitude: 0.35779

Collected Steps per Second: 21,053.50557
Overall Steps per Second: 10,290.02645

Timestep Collection Time: 2.37747
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.86432

Cumulative Model Updates: 149,680
Cumulative Timesteps: 1,249,060,690

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,187.30413
Policy Entropy: 1.70008
Value Function Loss: 0.05340

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.32716
Value Function Update Magnitude: 0.34408

Collected Steps per Second: 21,524.24947
Overall Steps per Second: 10,433.62736

Timestep Collection Time: 2.32463
Timestep Consumption Time: 2.47101
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.79565

Cumulative Model Updates: 149,686
Cumulative Timesteps: 1,249,110,726

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1249110726...
Checkpoint 1249110726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,895.23279
Policy Entropy: 1.71949
Value Function Loss: 0.05389

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.32484
Value Function Update Magnitude: 0.32658

Collected Steps per Second: 21,792.63103
Overall Steps per Second: 10,592.84187

Timestep Collection Time: 2.29518
Timestep Consumption Time: 2.42669
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.72187

Cumulative Model Updates: 149,692
Cumulative Timesteps: 1,249,160,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,316.10857
Policy Entropy: 1.70890
Value Function Loss: 0.04896

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.31928
Value Function Update Magnitude: 0.33189

Collected Steps per Second: 22,183.09356
Overall Steps per Second: 10,483.88558

Timestep Collection Time: 2.25433
Timestep Consumption Time: 2.51566
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.76999

Cumulative Model Updates: 149,698
Cumulative Timesteps: 1,249,210,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1249210752...
Checkpoint 1249210752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,333.40350
Policy Entropy: 1.71933
Value Function Loss: 0.04971

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.30227
Value Function Update Magnitude: 0.32644

Collected Steps per Second: 21,768.61369
Overall Steps per Second: 10,587.17682

Timestep Collection Time: 2.29762
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.72421

Cumulative Model Updates: 149,704
Cumulative Timesteps: 1,249,260,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,493.05351
Policy Entropy: 1.72323
Value Function Loss: 0.05060

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.31220
Value Function Update Magnitude: 0.33871

Collected Steps per Second: 22,076.13897
Overall Steps per Second: 10,507.86229

Timestep Collection Time: 2.26498
Timestep Consumption Time: 2.49355
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.75853

Cumulative Model Updates: 149,710
Cumulative Timesteps: 1,249,310,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1249310770...
Checkpoint 1249310770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,078.47805
Policy Entropy: 1.72035
Value Function Loss: 0.05167

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.31607
Value Function Update Magnitude: 0.34772

Collected Steps per Second: 21,514.19785
Overall Steps per Second: 10,347.43750

Timestep Collection Time: 2.32423
Timestep Consumption Time: 2.50827
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.83250

Cumulative Model Updates: 149,716
Cumulative Timesteps: 1,249,360,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,559.44075
Policy Entropy: 1.71311
Value Function Loss: 0.04815

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.31504
Value Function Update Magnitude: 0.34480

Collected Steps per Second: 21,215.63907
Overall Steps per Second: 10,309.41855

Timestep Collection Time: 2.35835
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.85323

Cumulative Model Updates: 149,722
Cumulative Timesteps: 1,249,410,808

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1249410808...
Checkpoint 1249410808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,451.24291
Policy Entropy: 1.72550
Value Function Loss: 0.04900

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.33764

Collected Steps per Second: 21,039.40585
Overall Steps per Second: 10,193.26523

Timestep Collection Time: 2.37830
Timestep Consumption Time: 2.53063
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.90893

Cumulative Model Updates: 149,728
Cumulative Timesteps: 1,249,460,846

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,725.40109
Policy Entropy: 1.71835
Value Function Loss: 0.04692

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.31474
Value Function Update Magnitude: 0.29949

Collected Steps per Second: 20,451.26848
Overall Steps per Second: 9,937.76457

Timestep Collection Time: 2.44523
Timestep Consumption Time: 2.58689
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 5.03212

Cumulative Model Updates: 149,734
Cumulative Timesteps: 1,249,510,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1249510854...
Checkpoint 1249510854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,953.40402
Policy Entropy: 1.70274
Value Function Loss: 0.04827

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.31520
Value Function Update Magnitude: 0.29663

Collected Steps per Second: 21,452.47283
Overall Steps per Second: 10,324.24354

Timestep Collection Time: 2.33157
Timestep Consumption Time: 2.51314
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.84471

Cumulative Model Updates: 149,740
Cumulative Timesteps: 1,249,560,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,117.98057
Policy Entropy: 1.69918
Value Function Loss: 0.04683

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.31341
Value Function Update Magnitude: 0.33579

Collected Steps per Second: 21,819.04189
Overall Steps per Second: 10,470.59174

Timestep Collection Time: 2.29240
Timestep Consumption Time: 2.48460
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.77700

Cumulative Model Updates: 149,746
Cumulative Timesteps: 1,249,610,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1249610890...
Checkpoint 1249610890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,024.58859
Policy Entropy: 1.70479
Value Function Loss: 0.05054

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.31543
Value Function Update Magnitude: 0.33101

Collected Steps per Second: 21,726.01915
Overall Steps per Second: 10,547.58665

Timestep Collection Time: 2.30203
Timestep Consumption Time: 2.43972
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.74175

Cumulative Model Updates: 149,752
Cumulative Timesteps: 1,249,660,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,868.26309
Policy Entropy: 1.72443
Value Function Loss: 0.04707

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.31657
Value Function Update Magnitude: 0.32064

Collected Steps per Second: 21,928.47163
Overall Steps per Second: 10,600.66989

Timestep Collection Time: 2.28224
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.72102

Cumulative Model Updates: 149,758
Cumulative Timesteps: 1,249,710,950

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1249710950...
Checkpoint 1249710950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,373.52931
Policy Entropy: 1.72549
Value Function Loss: 0.04875

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.30999
Value Function Update Magnitude: 0.31321

Collected Steps per Second: 21,678.22329
Overall Steps per Second: 10,565.18145

Timestep Collection Time: 2.30775
Timestep Consumption Time: 2.42742
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.73518

Cumulative Model Updates: 149,764
Cumulative Timesteps: 1,249,760,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,006.65028
Policy Entropy: 1.73098
Value Function Loss: 0.04666

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07551
Policy Update Magnitude: 0.31301
Value Function Update Magnitude: 0.31510

Collected Steps per Second: 21,569.16029
Overall Steps per Second: 10,519.13734

Timestep Collection Time: 2.31942
Timestep Consumption Time: 2.43648
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.75590

Cumulative Model Updates: 149,770
Cumulative Timesteps: 1,249,811,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1249811006...
Checkpoint 1249811006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,233.31042
Policy Entropy: 1.72854
Value Function Loss: 0.05144

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.32135
Value Function Update Magnitude: 0.32857

Collected Steps per Second: 21,241.66230
Overall Steps per Second: 10,611.58283

Timestep Collection Time: 2.35499
Timestep Consumption Time: 2.35910
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.71409

Cumulative Model Updates: 149,776
Cumulative Timesteps: 1,249,861,030

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,182.52733
Policy Entropy: 1.72193
Value Function Loss: 0.05125

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.32505
Value Function Update Magnitude: 0.34007

Collected Steps per Second: 21,747.54507
Overall Steps per Second: 10,636.54915

Timestep Collection Time: 2.30086
Timestep Consumption Time: 2.40349
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.70435

Cumulative Model Updates: 149,782
Cumulative Timesteps: 1,249,911,068

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1249911068...
Checkpoint 1249911068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,547.69554
Policy Entropy: 1.72227
Value Function Loss: 0.04793

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.31908
Value Function Update Magnitude: 0.34279

Collected Steps per Second: 21,331.36606
Overall Steps per Second: 10,468.96096

Timestep Collection Time: 2.34612
Timestep Consumption Time: 2.43429
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.78042

Cumulative Model Updates: 149,788
Cumulative Timesteps: 1,249,961,114

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,035.79710
Policy Entropy: 1.71077
Value Function Loss: 0.04412

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.30402
Value Function Update Magnitude: 0.33840

Collected Steps per Second: 21,153.06354
Overall Steps per Second: 10,489.57750

Timestep Collection Time: 2.36486
Timestep Consumption Time: 2.40407
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.76892

Cumulative Model Updates: 149,794
Cumulative Timesteps: 1,250,011,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1250011138...
Checkpoint 1250011138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,314.56346
Policy Entropy: 1.71337
Value Function Loss: 0.04278

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.29100
Value Function Update Magnitude: 0.32186

Collected Steps per Second: 21,329.29412
Overall Steps per Second: 10,532.53321

Timestep Collection Time: 2.34607
Timestep Consumption Time: 2.40492
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.75099

Cumulative Model Updates: 149,800
Cumulative Timesteps: 1,250,061,178

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,385.61180
Policy Entropy: 1.71301
Value Function Loss: 0.04646

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.29491
Value Function Update Magnitude: 0.32020

Collected Steps per Second: 21,596.92012
Overall Steps per Second: 10,582.42448

Timestep Collection Time: 2.31635
Timestep Consumption Time: 2.41092
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.72727

Cumulative Model Updates: 149,806
Cumulative Timesteps: 1,250,111,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1250111204...
Checkpoint 1250111204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,567.15221
Policy Entropy: 1.70562
Value Function Loss: 0.04961

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.31107
Value Function Update Magnitude: 0.31780

Collected Steps per Second: 22,135.99180
Overall Steps per Second: 10,619.60683

Timestep Collection Time: 2.26012
Timestep Consumption Time: 2.45098
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.71110

Cumulative Model Updates: 149,812
Cumulative Timesteps: 1,250,161,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,735.87202
Policy Entropy: 1.70020
Value Function Loss: 0.05006

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.30937
Value Function Update Magnitude: 0.33435

Collected Steps per Second: 22,267.64375
Overall Steps per Second: 10,556.82357

Timestep Collection Time: 2.24568
Timestep Consumption Time: 2.49116
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.73684

Cumulative Model Updates: 149,818
Cumulative Timesteps: 1,250,211,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1250211240...
Checkpoint 1250211240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,881.92027
Policy Entropy: 1.71316
Value Function Loss: 0.05229

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.31669
Value Function Update Magnitude: 0.34597

Collected Steps per Second: 21,827.97656
Overall Steps per Second: 10,498.75199

Timestep Collection Time: 2.29229
Timestep Consumption Time: 2.47361
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.76590

Cumulative Model Updates: 149,824
Cumulative Timesteps: 1,250,261,276

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,968.34678
Policy Entropy: 1.73527
Value Function Loss: 0.05689

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08402
Policy Update Magnitude: 0.33012
Value Function Update Magnitude: 0.32948

Collected Steps per Second: 22,161.65905
Overall Steps per Second: 10,559.27350

Timestep Collection Time: 2.25678
Timestep Consumption Time: 2.47972
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.73650

Cumulative Model Updates: 149,830
Cumulative Timesteps: 1,250,311,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1250311290...
Checkpoint 1250311290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,754.39089
Policy Entropy: 1.75103
Value Function Loss: 0.05609

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.33066
Value Function Update Magnitude: 0.36515

Collected Steps per Second: 22,122.22727
Overall Steps per Second: 10,508.55533

Timestep Collection Time: 2.26080
Timestep Consumption Time: 2.49856
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.75936

Cumulative Model Updates: 149,836
Cumulative Timesteps: 1,250,361,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,091.14105
Policy Entropy: 1.75929
Value Function Loss: 0.05770

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.32743
Value Function Update Magnitude: 0.36416

Collected Steps per Second: 22,115.65038
Overall Steps per Second: 10,527.69320

Timestep Collection Time: 2.26166
Timestep Consumption Time: 2.48943
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.75109

Cumulative Model Updates: 149,842
Cumulative Timesteps: 1,250,411,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1250411322...
Checkpoint 1250411322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,455.40792
Policy Entropy: 1.74384
Value Function Loss: 0.05200

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.31799
Value Function Update Magnitude: 0.34979

Collected Steps per Second: 21,677.85525
Overall Steps per Second: 10,552.78630

Timestep Collection Time: 2.30752
Timestep Consumption Time: 2.43265
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.74017

Cumulative Model Updates: 149,848
Cumulative Timesteps: 1,250,461,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,481.93895
Policy Entropy: 1.74036
Value Function Loss: 0.05379

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.31751
Value Function Update Magnitude: 0.34844

Collected Steps per Second: 21,648.78384
Overall Steps per Second: 10,562.34231

Timestep Collection Time: 2.31052
Timestep Consumption Time: 2.42517
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.73569

Cumulative Model Updates: 149,854
Cumulative Timesteps: 1,250,511,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1250511364...
Checkpoint 1250511364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,484.79378
Policy Entropy: 1.73167
Value Function Loss: 0.05415

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.31236
Value Function Update Magnitude: 0.34856

Collected Steps per Second: 21,285.64006
Overall Steps per Second: 10,470.61953

Timestep Collection Time: 2.34966
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.77660

Cumulative Model Updates: 149,860
Cumulative Timesteps: 1,250,561,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,538.74382
Policy Entropy: 1.72618
Value Function Loss: 0.05258

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.29906
Value Function Update Magnitude: 0.35130

Collected Steps per Second: 21,471.43653
Overall Steps per Second: 10,485.91608

Timestep Collection Time: 2.32923
Timestep Consumption Time: 2.44021
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.76945

Cumulative Model Updates: 149,866
Cumulative Timesteps: 1,250,611,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1250611390...
Checkpoint 1250611390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,992.18454
Policy Entropy: 1.71367
Value Function Loss: 0.05022

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.30290
Value Function Update Magnitude: 0.35381

Collected Steps per Second: 21,586.37034
Overall Steps per Second: 10,379.80981

Timestep Collection Time: 2.31702
Timestep Consumption Time: 2.50157
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.81859

Cumulative Model Updates: 149,872
Cumulative Timesteps: 1,250,661,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,359.66390
Policy Entropy: 1.70091
Value Function Loss: 0.04777

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.30644
Value Function Update Magnitude: 0.35026

Collected Steps per Second: 21,971.76457
Overall Steps per Second: 10,370.79498

Timestep Collection Time: 2.27774
Timestep Consumption Time: 2.54793
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.82567

Cumulative Model Updates: 149,878
Cumulative Timesteps: 1,250,711,452

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1250711452...
Checkpoint 1250711452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,418.49737
Policy Entropy: 1.69712
Value Function Loss: 0.05017

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.31734
Value Function Update Magnitude: 0.34808

Collected Steps per Second: 21,992.57203
Overall Steps per Second: 10,531.91895

Timestep Collection Time: 2.27513
Timestep Consumption Time: 2.47576
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.75089

Cumulative Model Updates: 149,884
Cumulative Timesteps: 1,250,761,488

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,133.16820
Policy Entropy: 1.71232
Value Function Loss: 0.05118

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.31387
Value Function Update Magnitude: 0.33990

Collected Steps per Second: 22,125.27864
Overall Steps per Second: 10,499.03763

Timestep Collection Time: 2.26058
Timestep Consumption Time: 2.50328
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.76387

Cumulative Model Updates: 149,890
Cumulative Timesteps: 1,250,811,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1250811504...
Checkpoint 1250811504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,537.32708
Policy Entropy: 1.73155
Value Function Loss: 0.05416

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.31904
Value Function Update Magnitude: 0.34075

Collected Steps per Second: 21,627.94837
Overall Steps per Second: 10,549.40243

Timestep Collection Time: 2.31330
Timestep Consumption Time: 2.42934
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.74264

Cumulative Model Updates: 149,896
Cumulative Timesteps: 1,250,861,536

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,167.25234
Policy Entropy: 1.74277
Value Function Loss: 0.05466

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.32551
Value Function Update Magnitude: 0.34712

Collected Steps per Second: 22,127.54912
Overall Steps per Second: 10,527.89627

Timestep Collection Time: 2.26062
Timestep Consumption Time: 2.49076
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.75138

Cumulative Model Updates: 149,902
Cumulative Timesteps: 1,250,911,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1250911558...
Checkpoint 1250911558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,711.38637
Policy Entropy: 1.73258
Value Function Loss: 0.05642

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.32936
Value Function Update Magnitude: 0.34467

Collected Steps per Second: 21,824.54867
Overall Steps per Second: 10,581.94478

Timestep Collection Time: 2.29256
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.72824

Cumulative Model Updates: 149,908
Cumulative Timesteps: 1,250,961,592

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,905.09491
Policy Entropy: 1.73409
Value Function Loss: 0.05464

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.31322
Value Function Update Magnitude: 0.34431

Collected Steps per Second: 21,951.33500
Overall Steps per Second: 10,640.76215

Timestep Collection Time: 2.27868
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.70079

Cumulative Model Updates: 149,914
Cumulative Timesteps: 1,251,011,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1251011612...
Checkpoint 1251011612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,972.47315
Policy Entropy: 1.75208
Value Function Loss: 0.05045

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.29712
Value Function Update Magnitude: 0.32618

Collected Steps per Second: 21,611.26825
Overall Steps per Second: 10,503.26106

Timestep Collection Time: 2.31370
Timestep Consumption Time: 2.44692
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.76062

Cumulative Model Updates: 149,920
Cumulative Timesteps: 1,251,061,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,491.42982
Policy Entropy: 1.75292
Value Function Loss: 0.05156

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.29549
Value Function Update Magnitude: 0.32400

Collected Steps per Second: 21,484.45193
Overall Steps per Second: 10,470.04516

Timestep Collection Time: 2.32820
Timestep Consumption Time: 2.44924
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.77744

Cumulative Model Updates: 149,926
Cumulative Timesteps: 1,251,111,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1251111634...
Checkpoint 1251111634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,887.27083
Policy Entropy: 1.76286
Value Function Loss: 0.05314

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.31767
Value Function Update Magnitude: 0.35059

Collected Steps per Second: 21,459.77355
Overall Steps per Second: 10,371.42059

Timestep Collection Time: 2.33031
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.82171

Cumulative Model Updates: 149,932
Cumulative Timesteps: 1,251,161,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,755.21758
Policy Entropy: 1.75233
Value Function Loss: 0.05414

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.32514
Value Function Update Magnitude: 0.37749

Collected Steps per Second: 21,950.07873
Overall Steps per Second: 10,479.89356

Timestep Collection Time: 2.27872
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.77276

Cumulative Model Updates: 149,938
Cumulative Timesteps: 1,251,211,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1251211660...
Checkpoint 1251211660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,431.75041
Policy Entropy: 1.74641
Value Function Loss: 0.05064

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.32200
Value Function Update Magnitude: 0.38611

Collected Steps per Second: 22,043.66449
Overall Steps per Second: 10,438.03968

Timestep Collection Time: 2.26850
Timestep Consumption Time: 2.52225
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.79075

Cumulative Model Updates: 149,944
Cumulative Timesteps: 1,251,261,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,195.13261
Policy Entropy: 1.74606
Value Function Loss: 0.04992

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.32206
Value Function Update Magnitude: 0.37804

Collected Steps per Second: 22,025.88270
Overall Steps per Second: 10,448.41315

Timestep Collection Time: 2.27078
Timestep Consumption Time: 2.51616
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.78695

Cumulative Model Updates: 149,950
Cumulative Timesteps: 1,251,311,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1251311682...
Checkpoint 1251311682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,239.19645
Policy Entropy: 1.75167
Value Function Loss: 0.05041

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08209
Policy Update Magnitude: 0.32613
Value Function Update Magnitude: 0.36722

Collected Steps per Second: 22,102.27818
Overall Steps per Second: 10,629.20477

Timestep Collection Time: 2.26330
Timestep Consumption Time: 2.44298
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.70628

Cumulative Model Updates: 149,956
Cumulative Timesteps: 1,251,361,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,359.68487
Policy Entropy: 1.77790
Value Function Loss: 0.05318

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.32829
Value Function Update Magnitude: 0.37626

Collected Steps per Second: 21,919.56013
Overall Steps per Second: 10,502.19040

Timestep Collection Time: 2.28134
Timestep Consumption Time: 2.48014
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.76148

Cumulative Model Updates: 149,962
Cumulative Timesteps: 1,251,411,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1251411712...
Checkpoint 1251411712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,865.39372
Policy Entropy: 1.75874
Value Function Loss: 0.05379

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.32473
Value Function Update Magnitude: 0.39184

Collected Steps per Second: 21,195.95191
Overall Steps per Second: 10,278.22730

Timestep Collection Time: 2.35894
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.86465

Cumulative Model Updates: 149,968
Cumulative Timesteps: 1,251,461,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,543.87416
Policy Entropy: 1.75756
Value Function Loss: 0.05666

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.31005
Value Function Update Magnitude: 0.38192

Collected Steps per Second: 21,549.86483
Overall Steps per Second: 10,347.60744

Timestep Collection Time: 2.32057
Timestep Consumption Time: 2.51224
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.83281

Cumulative Model Updates: 149,974
Cumulative Timesteps: 1,251,511,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1251511720...
Checkpoint 1251511720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,287.92291
Policy Entropy: 1.73828
Value Function Loss: 0.05628

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.29714
Value Function Update Magnitude: 0.36679

Collected Steps per Second: 21,542.79138
Overall Steps per Second: 10,392.26771

Timestep Collection Time: 2.32291
Timestep Consumption Time: 2.49240
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.81531

Cumulative Model Updates: 149,980
Cumulative Timesteps: 1,251,561,762

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,279.31221
Policy Entropy: 1.75181
Value Function Loss: 0.05429

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.30169
Value Function Update Magnitude: 0.36360

Collected Steps per Second: 21,888.33075
Overall Steps per Second: 10,613.71500

Timestep Collection Time: 2.28569
Timestep Consumption Time: 2.42802
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.71371

Cumulative Model Updates: 149,986
Cumulative Timesteps: 1,251,611,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1251611792...
Checkpoint 1251611792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,233.42169
Policy Entropy: 1.73808
Value Function Loss: 0.04974

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.31261
Value Function Update Magnitude: 0.36653

Collected Steps per Second: 21,301.46653
Overall Steps per Second: 10,292.97051

Timestep Collection Time: 2.34754
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.85827

Cumulative Model Updates: 149,992
Cumulative Timesteps: 1,251,661,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,954.22849
Policy Entropy: 1.74201
Value Function Loss: 0.05137

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.31561
Value Function Update Magnitude: 0.36059

Collected Steps per Second: 21,977.69939
Overall Steps per Second: 10,431.45927

Timestep Collection Time: 2.27558
Timestep Consumption Time: 2.51876
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.79434

Cumulative Model Updates: 149,998
Cumulative Timesteps: 1,251,711,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1251711810...
Checkpoint 1251711810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,712.30465
Policy Entropy: 1.75160
Value Function Loss: 0.05213

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.32124
Value Function Update Magnitude: 0.34651

Collected Steps per Second: 21,810.75295
Overall Steps per Second: 10,545.74349

Timestep Collection Time: 2.29336
Timestep Consumption Time: 2.44978
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.74315

Cumulative Model Updates: 150,004
Cumulative Timesteps: 1,251,761,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,394.02884
Policy Entropy: 1.76075
Value Function Loss: 0.05116

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.32309
Value Function Update Magnitude: 0.34359

Collected Steps per Second: 22,174.53476
Overall Steps per Second: 10,573.11787

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.47473
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.73011

Cumulative Model Updates: 150,010
Cumulative Timesteps: 1,251,811,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1251811842...
Checkpoint 1251811842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,004.06469
Policy Entropy: 1.75162
Value Function Loss: 0.04941

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.31798
Value Function Update Magnitude: 0.34436

Collected Steps per Second: 21,915.59551
Overall Steps per Second: 10,608.81885

Timestep Collection Time: 2.28221
Timestep Consumption Time: 2.43236
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.71457

Cumulative Model Updates: 150,016
Cumulative Timesteps: 1,251,861,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,985.56411
Policy Entropy: 1.76014
Value Function Loss: 0.05083

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.31253
Value Function Update Magnitude: 0.33721

Collected Steps per Second: 22,055.07267
Overall Steps per Second: 10,509.93465

Timestep Collection Time: 2.26732
Timestep Consumption Time: 2.49065
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.75797

Cumulative Model Updates: 150,022
Cumulative Timesteps: 1,251,911,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1251911864...
Checkpoint 1251911864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,080.58475
Policy Entropy: 1.75547
Value Function Loss: 0.05491

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.34350

Collected Steps per Second: 21,917.52629
Overall Steps per Second: 10,642.02478

Timestep Collection Time: 2.28174
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.69929

Cumulative Model Updates: 150,028
Cumulative Timesteps: 1,251,961,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,049.69795
Policy Entropy: 1.74840
Value Function Loss: 0.05140

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.31480
Value Function Update Magnitude: 0.34468

Collected Steps per Second: 21,480.38309
Overall Steps per Second: 10,560.47703

Timestep Collection Time: 2.32966
Timestep Consumption Time: 2.40895
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.73861

Cumulative Model Updates: 150,034
Cumulative Timesteps: 1,252,011,916

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1252011916...
Checkpoint 1252011916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,134.80425
Policy Entropy: 1.75038
Value Function Loss: 0.04946

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.31134
Value Function Update Magnitude: 0.33039

Collected Steps per Second: 21,099.08049
Overall Steps per Second: 10,481.53827

Timestep Collection Time: 2.36996
Timestep Consumption Time: 2.40071
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.77067

Cumulative Model Updates: 150,040
Cumulative Timesteps: 1,252,061,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,316.02356
Policy Entropy: 1.75943
Value Function Loss: 0.04482

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.30674
Value Function Update Magnitude: 0.32822

Collected Steps per Second: 21,067.32848
Overall Steps per Second: 10,458.62601

Timestep Collection Time: 2.37429
Timestep Consumption Time: 2.40836
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.78266

Cumulative Model Updates: 150,046
Cumulative Timesteps: 1,252,111,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1252111940...
Checkpoint 1252111940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,044.28654
Policy Entropy: 1.75923
Value Function Loss: 0.04804

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.30666
Value Function Update Magnitude: 0.34308

Collected Steps per Second: 20,930.42777
Overall Steps per Second: 10,558.55401

Timestep Collection Time: 2.38973
Timestep Consumption Time: 2.34748
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.73720

Cumulative Model Updates: 150,052
Cumulative Timesteps: 1,252,161,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,274.35526
Policy Entropy: 1.73069
Value Function Loss: 0.05106

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.31676
Value Function Update Magnitude: 0.36697

Collected Steps per Second: 20,593.87642
Overall Steps per Second: 10,462.97482

Timestep Collection Time: 2.42917
Timestep Consumption Time: 2.35207
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.78124

Cumulative Model Updates: 150,058
Cumulative Timesteps: 1,252,211,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1252211984...
Checkpoint 1252211984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,713.35163
Policy Entropy: 1.72611
Value Function Loss: 0.05277

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.31899
Value Function Update Magnitude: 0.37402

Collected Steps per Second: 20,802.38161
Overall Steps per Second: 10,264.83121

Timestep Collection Time: 2.40549
Timestep Consumption Time: 2.46940
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.87490

Cumulative Model Updates: 150,064
Cumulative Timesteps: 1,252,262,024

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,321.05766
Policy Entropy: 1.73492
Value Function Loss: 0.05346

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.31150
Value Function Update Magnitude: 0.34729

Collected Steps per Second: 21,942.90818
Overall Steps per Second: 10,452.82643

Timestep Collection Time: 2.28037
Timestep Consumption Time: 2.50666
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.78703

Cumulative Model Updates: 150,070
Cumulative Timesteps: 1,252,312,062

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1252312062...
Checkpoint 1252312062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,465.31355
Policy Entropy: 1.74838
Value Function Loss: 0.05186

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.31429
Value Function Update Magnitude: 0.32804

Collected Steps per Second: 21,979.57079
Overall Steps per Second: 10,679.26080

Timestep Collection Time: 2.27611
Timestep Consumption Time: 2.40848
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.68459

Cumulative Model Updates: 150,076
Cumulative Timesteps: 1,252,362,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,334.22065
Policy Entropy: 1.75379
Value Function Loss: 0.05379

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.31724
Value Function Update Magnitude: 0.34690

Collected Steps per Second: 22,015.74677
Overall Steps per Second: 10,552.18799

Timestep Collection Time: 2.27192
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.74006

Cumulative Model Updates: 150,082
Cumulative Timesteps: 1,252,412,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1252412108...
Checkpoint 1252412108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,740.62760
Policy Entropy: 1.75774
Value Function Loss: 0.05048

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.31302
Value Function Update Magnitude: 0.34468

Collected Steps per Second: 22,127.89413
Overall Steps per Second: 10,546.39496

Timestep Collection Time: 2.25977
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.74134

Cumulative Model Updates: 150,088
Cumulative Timesteps: 1,252,462,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,177.20610
Policy Entropy: 1.76963
Value Function Loss: 0.05181

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.31127
Value Function Update Magnitude: 0.33485

Collected Steps per Second: 21,773.02177
Overall Steps per Second: 10,389.25811

Timestep Collection Time: 2.29807
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.81613

Cumulative Model Updates: 150,094
Cumulative Timesteps: 1,252,512,148

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1252512148...
Checkpoint 1252512148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,250.77960
Policy Entropy: 1.74876
Value Function Loss: 0.04899

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.31561
Value Function Update Magnitude: 0.31386

Collected Steps per Second: 21,983.10299
Overall Steps per Second: 10,668.55519

Timestep Collection Time: 2.27566
Timestep Consumption Time: 2.41345
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.68911

Cumulative Model Updates: 150,100
Cumulative Timesteps: 1,252,562,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,482.94314
Policy Entropy: 1.75369
Value Function Loss: 0.04733

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.31142
Value Function Update Magnitude: 0.32649

Collected Steps per Second: 22,033.76243
Overall Steps per Second: 10,440.84280

Timestep Collection Time: 2.27033
Timestep Consumption Time: 2.52085
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.79118

Cumulative Model Updates: 150,106
Cumulative Timesteps: 1,252,612,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1252612198...
Checkpoint 1252612198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,912.06949
Policy Entropy: 1.74473
Value Function Loss: 0.04466

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.30711
Value Function Update Magnitude: 0.35408

Collected Steps per Second: 21,707.86966
Overall Steps per Second: 10,571.96761

Timestep Collection Time: 2.30543
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.73384

Cumulative Model Updates: 150,112
Cumulative Timesteps: 1,252,662,244

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,329.42604
Policy Entropy: 1.76242
Value Function Loss: 0.04809

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.30964
Value Function Update Magnitude: 0.36167

Collected Steps per Second: 21,615.20840
Overall Steps per Second: 10,496.53506

Timestep Collection Time: 2.31346
Timestep Consumption Time: 2.45058
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.76405

Cumulative Model Updates: 150,118
Cumulative Timesteps: 1,252,712,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1252712250...
Checkpoint 1252712250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,496.22053
Policy Entropy: 1.76203
Value Function Loss: 0.04830

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.31419
Value Function Update Magnitude: 0.35873

Collected Steps per Second: 21,298.52723
Overall Steps per Second: 10,242.38419

Timestep Collection Time: 2.34871
Timestep Consumption Time: 2.53531
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.88402

Cumulative Model Updates: 150,124
Cumulative Timesteps: 1,252,762,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,792.98030
Policy Entropy: 1.75411
Value Function Loss: 0.04702

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.31526
Value Function Update Magnitude: 0.35404

Collected Steps per Second: 21,793.48003
Overall Steps per Second: 10,463.64113

Timestep Collection Time: 2.29537
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.78075

Cumulative Model Updates: 150,130
Cumulative Timesteps: 1,252,812,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1252812298...
Checkpoint 1252812298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,821.20777
Policy Entropy: 1.75213
Value Function Loss: 0.04800

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.31253
Value Function Update Magnitude: 0.33316

Collected Steps per Second: 21,898.18979
Overall Steps per Second: 10,600.17371

Timestep Collection Time: 2.28457
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.71955

Cumulative Model Updates: 150,136
Cumulative Timesteps: 1,252,862,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,655.40395
Policy Entropy: 1.75371
Value Function Loss: 0.05118

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.31720
Value Function Update Magnitude: 0.34113

Collected Steps per Second: 21,990.40184
Overall Steps per Second: 10,481.97440

Timestep Collection Time: 2.27381
Timestep Consumption Time: 2.49647
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.77028

Cumulative Model Updates: 150,142
Cumulative Timesteps: 1,252,912,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1252912328...
Checkpoint 1252912328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,534.77206
Policy Entropy: 1.75728
Value Function Loss: 0.04844

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.31955
Value Function Update Magnitude: 0.35134

Collected Steps per Second: 22,263.91008
Overall Steps per Second: 10,672.52770

Timestep Collection Time: 2.24776
Timestep Consumption Time: 2.44129
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.68905

Cumulative Model Updates: 150,148
Cumulative Timesteps: 1,252,962,372

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,922.49300
Policy Entropy: 1.75113
Value Function Loss: 0.04951

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.31702
Value Function Update Magnitude: 0.32442

Collected Steps per Second: 22,057.88510
Overall Steps per Second: 10,459.29045

Timestep Collection Time: 2.26676
Timestep Consumption Time: 2.51368
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.78044

Cumulative Model Updates: 150,154
Cumulative Timesteps: 1,253,012,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1253012372...
Checkpoint 1253012372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,756.48641
Policy Entropy: 1.74498
Value Function Loss: 0.04900

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.31503
Value Function Update Magnitude: 0.32949

Collected Steps per Second: 21,894.71959
Overall Steps per Second: 10,570.41822

Timestep Collection Time: 2.28475
Timestep Consumption Time: 2.44770
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.73245

Cumulative Model Updates: 150,160
Cumulative Timesteps: 1,253,062,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,883.14734
Policy Entropy: 1.74026
Value Function Loss: 0.04912

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.31180
Value Function Update Magnitude: 0.32189

Collected Steps per Second: 22,073.87045
Overall Steps per Second: 10,473.17237

Timestep Collection Time: 2.26576
Timestep Consumption Time: 2.50968
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.77544

Cumulative Model Updates: 150,166
Cumulative Timesteps: 1,253,112,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1253112410...
Checkpoint 1253112410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,801.08202
Policy Entropy: 1.73588
Value Function Loss: 0.04645

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.30883
Value Function Update Magnitude: 0.31320

Collected Steps per Second: 20,372.91454
Overall Steps per Second: 10,163.56217

Timestep Collection Time: 2.45434
Timestep Consumption Time: 2.46539
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.91973

Cumulative Model Updates: 150,172
Cumulative Timesteps: 1,253,162,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,562.30952
Policy Entropy: 1.75106
Value Function Loss: 0.04391

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.30354
Value Function Update Magnitude: 0.32718

Collected Steps per Second: 22,136.11912
Overall Steps per Second: 10,513.10553

Timestep Collection Time: 2.26011
Timestep Consumption Time: 2.49872
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.75882

Cumulative Model Updates: 150,178
Cumulative Timesteps: 1,253,212,442

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1253212442...
Checkpoint 1253212442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,155.37832
Policy Entropy: 1.76306
Value Function Loss: 0.04907

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.32776

Collected Steps per Second: 21,254.81627
Overall Steps per Second: 10,300.19240

Timestep Collection Time: 2.35260
Timestep Consumption Time: 2.50207
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.85467

Cumulative Model Updates: 150,184
Cumulative Timesteps: 1,253,262,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,233.40840
Policy Entropy: 1.78164
Value Function Loss: 0.05087

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.31347
Value Function Update Magnitude: 0.33674

Collected Steps per Second: 21,329.54111
Overall Steps per Second: 10,361.69927

Timestep Collection Time: 2.34445
Timestep Consumption Time: 2.48159
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.82604

Cumulative Model Updates: 150,190
Cumulative Timesteps: 1,253,312,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1253312452...
Checkpoint 1253312452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,432.80729
Policy Entropy: 1.77365
Value Function Loss: 0.04970

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.31325
Value Function Update Magnitude: 0.33226

Collected Steps per Second: 21,502.31575
Overall Steps per Second: 10,344.89624

Timestep Collection Time: 2.32719
Timestep Consumption Time: 2.50998
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.83717

Cumulative Model Updates: 150,196
Cumulative Timesteps: 1,253,362,492

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,076.13483
Policy Entropy: 1.75747
Value Function Loss: 0.04587

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.30873
Value Function Update Magnitude: 0.30150

Collected Steps per Second: 21,741.65703
Overall Steps per Second: 10,393.65701

Timestep Collection Time: 2.30074
Timestep Consumption Time: 2.51200
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.81274

Cumulative Model Updates: 150,202
Cumulative Timesteps: 1,253,412,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1253412514...
Checkpoint 1253412514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,286.27106
Policy Entropy: 1.76094
Value Function Loss: 0.04824

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.31052
Value Function Update Magnitude: 0.27070

Collected Steps per Second: 21,442.71530
Overall Steps per Second: 10,494.32456

Timestep Collection Time: 2.33291
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.76677

Cumulative Model Updates: 150,208
Cumulative Timesteps: 1,253,462,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,109.51726
Policy Entropy: 1.74120
Value Function Loss: 0.05105

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.31526
Value Function Update Magnitude: 0.24813

Collected Steps per Second: 22,004.71376
Overall Steps per Second: 10,554.27825

Timestep Collection Time: 2.27415
Timestep Consumption Time: 2.46725
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.74139

Cumulative Model Updates: 150,214
Cumulative Timesteps: 1,253,512,580

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1253512580...
Checkpoint 1253512580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,785.87767
Policy Entropy: 1.73600
Value Function Loss: 0.05063

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.31954
Value Function Update Magnitude: 0.28904

Collected Steps per Second: 21,607.88530
Overall Steps per Second: 10,311.95605

Timestep Collection Time: 2.31527
Timestep Consumption Time: 2.53619
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.85146

Cumulative Model Updates: 150,220
Cumulative Timesteps: 1,253,562,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,479.16456
Policy Entropy: 1.72532
Value Function Loss: 0.04885

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31215
Value Function Update Magnitude: 0.28274

Collected Steps per Second: 22,116.98911
Overall Steps per Second: 10,522.85521

Timestep Collection Time: 2.26215
Timestep Consumption Time: 2.49245
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.75460

Cumulative Model Updates: 150,226
Cumulative Timesteps: 1,253,612,640

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1253612640...
Checkpoint 1253612640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,796.97379
Policy Entropy: 1.73887
Value Function Loss: 0.04876

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.29133

Collected Steps per Second: 22,054.17849
Overall Steps per Second: 10,481.59722

Timestep Collection Time: 2.26760
Timestep Consumption Time: 2.50362
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.77122

Cumulative Model Updates: 150,232
Cumulative Timesteps: 1,253,662,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,961.04025
Policy Entropy: 1.74228
Value Function Loss: 0.04991

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.31634
Value Function Update Magnitude: 0.31967

Collected Steps per Second: 22,354.97897
Overall Steps per Second: 10,572.79445

Timestep Collection Time: 2.23691
Timestep Consumption Time: 2.49278
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.72969

Cumulative Model Updates: 150,238
Cumulative Timesteps: 1,253,712,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1253712656...
Checkpoint 1253712656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,652.12894
Policy Entropy: 1.74818
Value Function Loss: 0.05127

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07498
Policy Update Magnitude: 0.32292
Value Function Update Magnitude: 0.34111

Collected Steps per Second: 21,926.81263
Overall Steps per Second: 10,413.46871

Timestep Collection Time: 2.28113
Timestep Consumption Time: 2.52207
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.80320

Cumulative Model Updates: 150,244
Cumulative Timesteps: 1,253,762,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,151.33655
Policy Entropy: 1.75918
Value Function Loss: 0.05139

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.32326
Value Function Update Magnitude: 0.34629

Collected Steps per Second: 21,741.82321
Overall Steps per Second: 10,573.92212

Timestep Collection Time: 2.30165
Timestep Consumption Time: 2.43094
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.73259

Cumulative Model Updates: 150,250
Cumulative Timesteps: 1,253,812,716

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1253812716...
Checkpoint 1253812716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,845.27008
Policy Entropy: 1.77362
Value Function Loss: 0.05263

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08112
Policy Update Magnitude: 0.32003
Value Function Update Magnitude: 0.33833

Collected Steps per Second: 21,401.04241
Overall Steps per Second: 10,521.67665

Timestep Collection Time: 2.33652
Timestep Consumption Time: 2.41595
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.75247

Cumulative Model Updates: 150,256
Cumulative Timesteps: 1,253,862,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,545.62033
Policy Entropy: 1.76101
Value Function Loss: 0.05166

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.32119
Value Function Update Magnitude: 0.34832

Collected Steps per Second: 21,673.82095
Overall Steps per Second: 10,574.76664

Timestep Collection Time: 2.30841
Timestep Consumption Time: 2.42286
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.73126

Cumulative Model Updates: 150,262
Cumulative Timesteps: 1,253,912,752

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1253912752...
Checkpoint 1253912752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,292.35141
Policy Entropy: 1.74842
Value Function Loss: 0.04833

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.31488
Value Function Update Magnitude: 0.32514

Collected Steps per Second: 21,518.48926
Overall Steps per Second: 10,529.24305

Timestep Collection Time: 2.32488
Timestep Consumption Time: 2.42645
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.75134

Cumulative Model Updates: 150,268
Cumulative Timesteps: 1,253,962,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,584.44674
Policy Entropy: 1.74882
Value Function Loss: 0.05174

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.31265
Value Function Update Magnitude: 0.27597

Collected Steps per Second: 21,623.42414
Overall Steps per Second: 10,545.81177

Timestep Collection Time: 2.31268
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.74198

Cumulative Model Updates: 150,274
Cumulative Timesteps: 1,254,012,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1254012788...
Checkpoint 1254012788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,006.21440
Policy Entropy: 1.76136
Value Function Loss: 0.05241

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.31277
Value Function Update Magnitude: 0.27505

Collected Steps per Second: 20,988.34346
Overall Steps per Second: 10,546.03441

Timestep Collection Time: 2.38247
Timestep Consumption Time: 2.35903
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.74150

Cumulative Model Updates: 150,280
Cumulative Timesteps: 1,254,062,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,213.81924
Policy Entropy: 1.76493
Value Function Loss: 0.05290

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.31918
Value Function Update Magnitude: 0.32290

Collected Steps per Second: 21,646.13184
Overall Steps per Second: 10,474.22565

Timestep Collection Time: 2.31034
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.77458

Cumulative Model Updates: 150,286
Cumulative Timesteps: 1,254,112,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1254112802...
Checkpoint 1254112802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,279.53368
Policy Entropy: 1.77149
Value Function Loss: 0.05406

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.32410
Value Function Update Magnitude: 0.35385

Collected Steps per Second: 20,847.88630
Overall Steps per Second: 10,346.69454

Timestep Collection Time: 2.39871
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.83323

Cumulative Model Updates: 150,292
Cumulative Timesteps: 1,254,162,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,627.03036
Policy Entropy: 1.77477
Value Function Loss: 0.05524

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.32981
Value Function Update Magnitude: 0.36291

Collected Steps per Second: 21,653.13699
Overall Steps per Second: 10,712.22134

Timestep Collection Time: 2.30950
Timestep Consumption Time: 2.35881
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.66831

Cumulative Model Updates: 150,298
Cumulative Timesteps: 1,254,212,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1254212818...
Checkpoint 1254212818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,833.44387
Policy Entropy: 1.76729
Value Function Loss: 0.05368

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.29855
Value Function Update Magnitude: 0.35907

Collected Steps per Second: 21,206.01627
Overall Steps per Second: 10,604.22293

Timestep Collection Time: 2.35820
Timestep Consumption Time: 2.35766
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.71586

Cumulative Model Updates: 150,304
Cumulative Timesteps: 1,254,262,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,311.82749
Policy Entropy: 1.77842
Value Function Loss: 0.05203

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.28756
Value Function Update Magnitude: 0.36218

Collected Steps per Second: 21,646.33136
Overall Steps per Second: 10,484.82746

Timestep Collection Time: 2.31041
Timestep Consumption Time: 2.45953
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.76994

Cumulative Model Updates: 150,310
Cumulative Timesteps: 1,254,312,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1254312838...
Checkpoint 1254312838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,307.30314
Policy Entropy: 1.79086
Value Function Loss: 0.05311

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.30554
Value Function Update Magnitude: 0.37222

Collected Steps per Second: 21,379.53998
Overall Steps per Second: 10,408.60595

Timestep Collection Time: 2.33897
Timestep Consumption Time: 2.46533
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.80429

Cumulative Model Updates: 150,316
Cumulative Timesteps: 1,254,362,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,888.64257
Policy Entropy: 1.79277
Value Function Loss: 0.05468

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.31345
Value Function Update Magnitude: 0.38216

Collected Steps per Second: 22,155.82246
Overall Steps per Second: 10,728.08434

Timestep Collection Time: 2.25801
Timestep Consumption Time: 2.40527
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.66327

Cumulative Model Updates: 150,322
Cumulative Timesteps: 1,254,412,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1254412872...
Checkpoint 1254412872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,594.80866
Policy Entropy: 1.78940
Value Function Loss: 0.05176

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.29173
Value Function Update Magnitude: 0.39349

Collected Steps per Second: 21,218.08529
Overall Steps per Second: 10,369.11305

Timestep Collection Time: 2.35648
Timestep Consumption Time: 2.46553
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.82201

Cumulative Model Updates: 150,328
Cumulative Timesteps: 1,254,462,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,004.05437
Policy Entropy: 1.75863
Value Function Loss: 0.05110

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.30659
Value Function Update Magnitude: 0.38880

Collected Steps per Second: 22,000.08938
Overall Steps per Second: 10,645.74532

Timestep Collection Time: 2.27335
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.69803

Cumulative Model Updates: 150,334
Cumulative Timesteps: 1,254,512,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1254512886...
Checkpoint 1254512886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,534.61226
Policy Entropy: 1.76146
Value Function Loss: 0.04747

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.31682
Value Function Update Magnitude: 0.37345

Collected Steps per Second: 21,193.93579
Overall Steps per Second: 10,272.28076

Timestep Collection Time: 2.35945
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.86805

Cumulative Model Updates: 150,340
Cumulative Timesteps: 1,254,562,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,999.39228
Policy Entropy: 1.75293
Value Function Loss: 0.04728

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.31367
Value Function Update Magnitude: 0.36289

Collected Steps per Second: 21,818.73025
Overall Steps per Second: 10,446.22652

Timestep Collection Time: 2.29280
Timestep Consumption Time: 2.49611
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.78891

Cumulative Model Updates: 150,346
Cumulative Timesteps: 1,254,612,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1254612918...
Checkpoint 1254612918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,539.60713
Policy Entropy: 1.76325
Value Function Loss: 0.04276

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.30663
Value Function Update Magnitude: 0.34798

Collected Steps per Second: 21,807.61150
Overall Steps per Second: 10,577.62263

Timestep Collection Time: 2.29314
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.72772

Cumulative Model Updates: 150,352
Cumulative Timesteps: 1,254,662,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,646.11806
Policy Entropy: 1.77891
Value Function Loss: 0.04622

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.30043
Value Function Update Magnitude: 0.33444

Collected Steps per Second: 22,038.39416
Overall Steps per Second: 10,579.76132

Timestep Collection Time: 2.26958
Timestep Consumption Time: 2.45812
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.72771

Cumulative Model Updates: 150,358
Cumulative Timesteps: 1,254,712,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1254712944...
Checkpoint 1254712944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,903.94554
Policy Entropy: 1.79403
Value Function Loss: 0.04648

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.30200
Value Function Update Magnitude: 0.33569

Collected Steps per Second: 21,889.53612
Overall Steps per Second: 10,543.84297

Timestep Collection Time: 2.28538
Timestep Consumption Time: 2.45919
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.74457

Cumulative Model Updates: 150,364
Cumulative Timesteps: 1,254,762,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,722.08384
Policy Entropy: 1.78198
Value Function Loss: 0.04858

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.30444
Value Function Update Magnitude: 0.34375

Collected Steps per Second: 22,033.28187
Overall Steps per Second: 10,481.69866

Timestep Collection Time: 2.26948
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.77060

Cumulative Model Updates: 150,370
Cumulative Timesteps: 1,254,812,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1254812974...
Checkpoint 1254812974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,786.17514
Policy Entropy: 1.76712
Value Function Loss: 0.04471

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.30614
Value Function Update Magnitude: 0.34567

Collected Steps per Second: 21,850.64543
Overall Steps per Second: 10,592.06259

Timestep Collection Time: 2.28909
Timestep Consumption Time: 2.43313
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.72222

Cumulative Model Updates: 150,376
Cumulative Timesteps: 1,254,862,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,334.34654
Policy Entropy: 1.74951
Value Function Loss: 0.04829

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.30798
Value Function Update Magnitude: 0.35409

Collected Steps per Second: 22,157.13512
Overall Steps per Second: 10,492.77159

Timestep Collection Time: 2.25769
Timestep Consumption Time: 2.50978
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.76747

Cumulative Model Updates: 150,382
Cumulative Timesteps: 1,254,913,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1254913016...
Checkpoint 1254913016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,483.92960
Policy Entropy: 1.75275
Value Function Loss: 0.04852

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.31083
Value Function Update Magnitude: 0.36678

Collected Steps per Second: 21,935.33195
Overall Steps per Second: 10,621.24201

Timestep Collection Time: 2.28043
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.70962

Cumulative Model Updates: 150,388
Cumulative Timesteps: 1,254,963,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,225.17779
Policy Entropy: 1.75932
Value Function Loss: 0.05190

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08552
Policy Update Magnitude: 0.31501
Value Function Update Magnitude: 0.37200

Collected Steps per Second: 21,869.04735
Overall Steps per Second: 10,440.39238

Timestep Collection Time: 2.28643
Timestep Consumption Time: 2.50286
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.78928

Cumulative Model Updates: 150,394
Cumulative Timesteps: 1,255,013,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1255013040...
Checkpoint 1255013040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,257.73319
Policy Entropy: 1.75448
Value Function Loss: 0.04796

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.30891
Value Function Update Magnitude: 0.36406

Collected Steps per Second: 21,294.53238
Overall Steps per Second: 10,298.75021

Timestep Collection Time: 2.34952
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.85807

Cumulative Model Updates: 150,400
Cumulative Timesteps: 1,255,063,072

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,131.84813
Policy Entropy: 1.75355
Value Function Loss: 0.04667

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.30835
Value Function Update Magnitude: 0.34780

Collected Steps per Second: 21,976.72582
Overall Steps per Second: 10,463.10607

Timestep Collection Time: 2.27723
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.78309

Cumulative Model Updates: 150,406
Cumulative Timesteps: 1,255,113,118

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1255113118...
Checkpoint 1255113118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,421.73814
Policy Entropy: 1.73502
Value Function Loss: 0.04407

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.30664
Value Function Update Magnitude: 0.34422

Collected Steps per Second: 21,651.33953
Overall Steps per Second: 10,528.22242

Timestep Collection Time: 2.31117
Timestep Consumption Time: 2.44177
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.75294

Cumulative Model Updates: 150,412
Cumulative Timesteps: 1,255,163,158

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,628.80215
Policy Entropy: 1.73376
Value Function Loss: 0.04982

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.30949
Value Function Update Magnitude: 0.35984

Collected Steps per Second: 21,973.90558
Overall Steps per Second: 10,577.65731

Timestep Collection Time: 2.27661
Timestep Consumption Time: 2.45279
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.72940

Cumulative Model Updates: 150,418
Cumulative Timesteps: 1,255,213,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1255213184...
Checkpoint 1255213184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,439.37587
Policy Entropy: 1.74259
Value Function Loss: 0.04905

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.31270
Value Function Update Magnitude: 0.34757

Collected Steps per Second: 22,046.18052
Overall Steps per Second: 10,487.53558

Timestep Collection Time: 2.26869
Timestep Consumption Time: 2.50040
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.76909

Cumulative Model Updates: 150,424
Cumulative Timesteps: 1,255,263,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,279.03141
Policy Entropy: 1.76324
Value Function Loss: 0.05202

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.30777
Value Function Update Magnitude: 0.36803

Collected Steps per Second: 22,147.84791
Overall Steps per Second: 10,513.64248

Timestep Collection Time: 2.25810
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.75687

Cumulative Model Updates: 150,430
Cumulative Timesteps: 1,255,313,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1255313212...
Checkpoint 1255313212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,946.30320
Policy Entropy: 1.77817
Value Function Loss: 0.05118

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.30785
Value Function Update Magnitude: 0.35497

Collected Steps per Second: 21,911.91082
Overall Steps per Second: 10,607.78803

Timestep Collection Time: 2.28250
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.71484

Cumulative Model Updates: 150,436
Cumulative Timesteps: 1,255,363,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,333.84898
Policy Entropy: 1.75449
Value Function Loss: 0.05230

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.29846

Collected Steps per Second: 22,052.70417
Overall Steps per Second: 10,535.18305

Timestep Collection Time: 2.26884
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.74923

Cumulative Model Updates: 150,442
Cumulative Timesteps: 1,255,413,260

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1255413260...
Checkpoint 1255413260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,212.66142
Policy Entropy: 1.74592
Value Function Loss: 0.05180

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.32051
Value Function Update Magnitude: 0.31184

Collected Steps per Second: 22,095.86142
Overall Steps per Second: 10,662.12809

Timestep Collection Time: 2.26350
Timestep Consumption Time: 2.42731
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.69081

Cumulative Model Updates: 150,448
Cumulative Timesteps: 1,255,463,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,425.67396
Policy Entropy: 1.73923
Value Function Loss: 0.04842

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07997
Policy Update Magnitude: 0.32003
Value Function Update Magnitude: 0.37299

Collected Steps per Second: 21,903.78013
Overall Steps per Second: 10,502.11167

Timestep Collection Time: 2.28372
Timestep Consumption Time: 2.47933
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.76304

Cumulative Model Updates: 150,454
Cumulative Timesteps: 1,255,513,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1255513296...
Checkpoint 1255513296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,722.93277
Policy Entropy: 1.74794
Value Function Loss: 0.04708

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.31866
Value Function Update Magnitude: 0.37499

Collected Steps per Second: 21,582.23283
Overall Steps per Second: 10,535.15944

Timestep Collection Time: 2.31774
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.74810

Cumulative Model Updates: 150,460
Cumulative Timesteps: 1,255,563,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,850.99165
Policy Entropy: 1.75021
Value Function Loss: 0.04736

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.31160
Value Function Update Magnitude: 0.36782

Collected Steps per Second: 21,682.35480
Overall Steps per Second: 10,469.67086

Timestep Collection Time: 2.30695
Timestep Consumption Time: 2.47066
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.77761

Cumulative Model Updates: 150,466
Cumulative Timesteps: 1,255,613,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1255613338...
Checkpoint 1255613338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,688.84867
Policy Entropy: 1.74002
Value Function Loss: 0.04957

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.37096

Collected Steps per Second: 21,544.19717
Overall Steps per Second: 10,348.46300

Timestep Collection Time: 2.32211
Timestep Consumption Time: 2.51223
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.83434

Cumulative Model Updates: 150,472
Cumulative Timesteps: 1,255,663,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,561.42692
Policy Entropy: 1.74866
Value Function Loss: 0.05256

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.31820
Value Function Update Magnitude: 0.39142

Collected Steps per Second: 22,287.45280
Overall Steps per Second: 10,488.01981

Timestep Collection Time: 2.24431
Timestep Consumption Time: 2.52494
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.76925

Cumulative Model Updates: 150,478
Cumulative Timesteps: 1,255,713,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1255713386...
Checkpoint 1255713386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,405.21509
Policy Entropy: 1.72736
Value Function Loss: 0.05294

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.32116
Value Function Update Magnitude: 0.41490

Collected Steps per Second: 21,871.16212
Overall Steps per Second: 10,407.65911

Timestep Collection Time: 2.28740
Timestep Consumption Time: 2.51945
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.80684

Cumulative Model Updates: 150,484
Cumulative Timesteps: 1,255,763,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,770.09638
Policy Entropy: 1.72705
Value Function Loss: 0.05614

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.32449
Value Function Update Magnitude: 0.42603

Collected Steps per Second: 21,991.86199
Overall Steps per Second: 10,493.08875

Timestep Collection Time: 2.27466
Timestep Consumption Time: 2.49267
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.76733

Cumulative Model Updates: 150,490
Cumulative Timesteps: 1,255,813,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1255813438...
Checkpoint 1255813438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,192.17702
Policy Entropy: 1.71704
Value Function Loss: 0.05645

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.32443
Value Function Update Magnitude: 0.42849

Collected Steps per Second: 21,851.87499
Overall Steps per Second: 10,604.70362

Timestep Collection Time: 2.28932
Timestep Consumption Time: 2.42802
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.71734

Cumulative Model Updates: 150,496
Cumulative Timesteps: 1,255,863,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,263.96746
Policy Entropy: 1.74146
Value Function Loss: 0.05393

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.42398

Collected Steps per Second: 22,174.07675
Overall Steps per Second: 10,474.85909

Timestep Collection Time: 2.25516
Timestep Consumption Time: 2.51875
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.77391

Cumulative Model Updates: 150,502
Cumulative Timesteps: 1,255,913,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1255913470...
Checkpoint 1255913470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,290.01613
Policy Entropy: 1.76702
Value Function Loss: 0.04923

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.31237
Value Function Update Magnitude: 0.39415

Collected Steps per Second: 22,049.90328
Overall Steps per Second: 10,618.01454

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.44305
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.71218

Cumulative Model Updates: 150,508
Cumulative Timesteps: 1,255,963,504

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,974.14196
Policy Entropy: 1.77629
Value Function Loss: 0.04582

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.30759
Value Function Update Magnitude: 0.38012

Collected Steps per Second: 21,920.75368
Overall Steps per Second: 10,515.72298

Timestep Collection Time: 2.28222
Timestep Consumption Time: 2.47523
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.75745

Cumulative Model Updates: 150,514
Cumulative Timesteps: 1,256,013,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1256013532...
Checkpoint 1256013532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,045.46519
Policy Entropy: 1.77111
Value Function Loss: 0.04723

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07447
Policy Update Magnitude: 0.30949
Value Function Update Magnitude: 0.35344

Collected Steps per Second: 21,415.73701
Overall Steps per Second: 10,371.79563

Timestep Collection Time: 2.33557
Timestep Consumption Time: 2.48693
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.82250

Cumulative Model Updates: 150,520
Cumulative Timesteps: 1,256,063,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,932.59032
Policy Entropy: 1.76625
Value Function Loss: 0.04789

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.31075
Value Function Update Magnitude: 0.34196

Collected Steps per Second: 21,849.18168
Overall Steps per Second: 10,452.19043

Timestep Collection Time: 2.28961
Timestep Consumption Time: 2.49657
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.78617

Cumulative Model Updates: 150,526
Cumulative Timesteps: 1,256,113,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1256113576...
Checkpoint 1256113576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,617.92646
Policy Entropy: 1.76315
Value Function Loss: 0.04888

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07720
Policy Update Magnitude: 0.31102
Value Function Update Magnitude: 0.35412

Collected Steps per Second: 21,740.20945
Overall Steps per Second: 10,441.88962

Timestep Collection Time: 2.30081
Timestep Consumption Time: 2.48951
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.79032

Cumulative Model Updates: 150,532
Cumulative Timesteps: 1,256,163,596

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,773.59814
Policy Entropy: 1.75974
Value Function Loss: 0.04874

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.31122
Value Function Update Magnitude: 0.36937

Collected Steps per Second: 21,546.41276
Overall Steps per Second: 10,521.50004

Timestep Collection Time: 2.32057
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.75217

Cumulative Model Updates: 150,538
Cumulative Timesteps: 1,256,213,596

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1256213596...
Checkpoint 1256213596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,916.76363
Policy Entropy: 1.75740
Value Function Loss: 0.04979

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.31631
Value Function Update Magnitude: 0.38719

Collected Steps per Second: 21,696.13745
Overall Steps per Second: 10,539.23514

Timestep Collection Time: 2.30649
Timestep Consumption Time: 2.44167
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.74816

Cumulative Model Updates: 150,544
Cumulative Timesteps: 1,256,263,638

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,021.33033
Policy Entropy: 1.76119
Value Function Loss: 0.04958

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.31907
Value Function Update Magnitude: 0.39071

Collected Steps per Second: 21,961.12880
Overall Steps per Second: 10,590.10033

Timestep Collection Time: 2.27857
Timestep Consumption Time: 2.44660
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.72517

Cumulative Model Updates: 150,550
Cumulative Timesteps: 1,256,313,678

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1256313678...
Checkpoint 1256313678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,375.45368
Policy Entropy: 1.75446
Value Function Loss: 0.05245

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.32302
Value Function Update Magnitude: 0.38539

Collected Steps per Second: 21,974.08186
Overall Steps per Second: 10,580.13207

Timestep Collection Time: 2.27750
Timestep Consumption Time: 2.45269
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.73019

Cumulative Model Updates: 150,556
Cumulative Timesteps: 1,256,363,724

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,806.82167
Policy Entropy: 1.72651
Value Function Loss: 0.04964

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.32521
Value Function Update Magnitude: 0.38308

Collected Steps per Second: 21,891.82919
Overall Steps per Second: 10,464.25197

Timestep Collection Time: 2.28496
Timestep Consumption Time: 2.49531
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.78027

Cumulative Model Updates: 150,562
Cumulative Timesteps: 1,256,413,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1256413746...
Checkpoint 1256413746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,523.43403
Policy Entropy: 1.73211
Value Function Loss: 0.05343

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.32659
Value Function Update Magnitude: 0.36431

Collected Steps per Second: 21,995.23061
Overall Steps per Second: 10,603.10188

Timestep Collection Time: 2.27358
Timestep Consumption Time: 2.44277
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.71636

Cumulative Model Updates: 150,568
Cumulative Timesteps: 1,256,463,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,429.01648
Policy Entropy: 1.74339
Value Function Loss: 0.05288

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.32731
Value Function Update Magnitude: 0.36049

Collected Steps per Second: 22,065.82134
Overall Steps per Second: 10,476.92280

Timestep Collection Time: 2.26731
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.77526

Cumulative Model Updates: 150,574
Cumulative Timesteps: 1,256,513,784

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1256513784...
Checkpoint 1256513784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,942.17882
Policy Entropy: 1.77802
Value Function Loss: 0.05423

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.32301
Value Function Update Magnitude: 0.36465

Collected Steps per Second: 21,761.02346
Overall Steps per Second: 10,574.90064

Timestep Collection Time: 2.29833
Timestep Consumption Time: 2.43117
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.72950

Cumulative Model Updates: 150,580
Cumulative Timesteps: 1,256,563,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,717.16911
Policy Entropy: 1.77148
Value Function Loss: 0.05359

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.32183
Value Function Update Magnitude: 0.36015

Collected Steps per Second: 21,523.69833
Overall Steps per Second: 10,497.03186

Timestep Collection Time: 2.32414
Timestep Consumption Time: 2.44140
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.76554

Cumulative Model Updates: 150,586
Cumulative Timesteps: 1,256,613,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1256613822...
Checkpoint 1256613822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,006.77790
Policy Entropy: 1.77767
Value Function Loss: 0.05295

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.32243
Value Function Update Magnitude: 0.34756

Collected Steps per Second: 21,495.55368
Overall Steps per Second: 10,353.10715

Timestep Collection Time: 2.32839
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.83430

Cumulative Model Updates: 150,592
Cumulative Timesteps: 1,256,663,872

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,137.29490
Policy Entropy: 1.75590
Value Function Loss: 0.04765

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.31696
Value Function Update Magnitude: 0.33049

Collected Steps per Second: 21,807.42456
Overall Steps per Second: 10,392.41158

Timestep Collection Time: 2.29426
Timestep Consumption Time: 2.52002
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.81428

Cumulative Model Updates: 150,598
Cumulative Timesteps: 1,256,713,904

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1256713904...
Checkpoint 1256713904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,641.60383
Policy Entropy: 1.75561
Value Function Loss: 0.04954

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.30991
Value Function Update Magnitude: 0.31782

Collected Steps per Second: 21,646.48495
Overall Steps per Second: 10,529.80936

Timestep Collection Time: 2.31197
Timestep Consumption Time: 2.44082
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.75279

Cumulative Model Updates: 150,604
Cumulative Timesteps: 1,256,763,950

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,282.24715
Policy Entropy: 1.75523
Value Function Loss: 0.04692

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.30854
Value Function Update Magnitude: 0.30705

Collected Steps per Second: 21,837.10557
Overall Steps per Second: 10,521.06032

Timestep Collection Time: 2.28996
Timestep Consumption Time: 2.46299
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.75294

Cumulative Model Updates: 150,610
Cumulative Timesteps: 1,256,813,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1256813956...
Checkpoint 1256813956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,192.13290
Policy Entropy: 1.76771
Value Function Loss: 0.04712

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.30486
Value Function Update Magnitude: 0.30876

Collected Steps per Second: 21,776.94909
Overall Steps per Second: 10,560.92529

Timestep Collection Time: 2.29821
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.73898

Cumulative Model Updates: 150,616
Cumulative Timesteps: 1,256,864,004

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,974.69890
Policy Entropy: 1.75237
Value Function Loss: 0.04506

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.30584
Value Function Update Magnitude: 0.33174

Collected Steps per Second: 21,573.85798
Overall Steps per Second: 10,426.71728

Timestep Collection Time: 2.31799
Timestep Consumption Time: 2.47815
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.79614

Cumulative Model Updates: 150,622
Cumulative Timesteps: 1,256,914,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1256914012...
Checkpoint 1256914012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,252.29168
Policy Entropy: 1.75332
Value Function Loss: 0.04289

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.30486
Value Function Update Magnitude: 0.33098

Collected Steps per Second: 21,913.82106
Overall Steps per Second: 10,442.94816

Timestep Collection Time: 2.28185
Timestep Consumption Time: 2.50646
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.78830

Cumulative Model Updates: 150,628
Cumulative Timesteps: 1,256,964,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,647.72929
Policy Entropy: 1.75418
Value Function Loss: 0.04669

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.30448
Value Function Update Magnitude: 0.33751

Collected Steps per Second: 22,175.74935
Overall Steps per Second: 10,692.55592

Timestep Collection Time: 2.25661
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.68008

Cumulative Model Updates: 150,634
Cumulative Timesteps: 1,257,014,058

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1257014058...
Checkpoint 1257014058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,034.14460
Policy Entropy: 1.76115
Value Function Loss: 0.04386

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.29915
Value Function Update Magnitude: 0.31098

Collected Steps per Second: 22,042.81232
Overall Steps per Second: 10,639.72365

Timestep Collection Time: 2.26859
Timestep Consumption Time: 2.43135
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.69993

Cumulative Model Updates: 150,640
Cumulative Timesteps: 1,257,064,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,302.89634
Policy Entropy: 1.74439
Value Function Loss: 0.04496

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07682
Policy Update Magnitude: 0.30121
Value Function Update Magnitude: 0.31320

Collected Steps per Second: 21,517.96188
Overall Steps per Second: 10,489.14588

Timestep Collection Time: 2.32559
Timestep Consumption Time: 2.44524
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.77084

Cumulative Model Updates: 150,646
Cumulative Timesteps: 1,257,114,106

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1257114106...
Checkpoint 1257114106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,962.75575
Policy Entropy: 1.72181
Value Function Loss: 0.04427

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.30530
Value Function Update Magnitude: 0.31156

Collected Steps per Second: 21,636.79832
Overall Steps per Second: 10,391.01809

Timestep Collection Time: 2.31208
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.81435

Cumulative Model Updates: 150,652
Cumulative Timesteps: 1,257,164,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,523.47295
Policy Entropy: 1.73163
Value Function Loss: 0.04884

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.31208
Value Function Update Magnitude: 0.32874

Collected Steps per Second: 21,750.23403
Overall Steps per Second: 10,474.37336

Timestep Collection Time: 2.30066
Timestep Consumption Time: 2.47671
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.77737

Cumulative Model Updates: 150,658
Cumulative Timesteps: 1,257,214,172

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1257214172...
Checkpoint 1257214172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,378.25854
Policy Entropy: 1.74667
Value Function Loss: 0.04994

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.31614
Value Function Update Magnitude: 0.32466

Collected Steps per Second: 21,608.29288
Overall Steps per Second: 10,481.27188

Timestep Collection Time: 2.31550
Timestep Consumption Time: 2.45816
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.77366

Cumulative Model Updates: 150,664
Cumulative Timesteps: 1,257,264,206

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,392.53804
Policy Entropy: 1.76076
Value Function Loss: 0.04796

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.31302
Value Function Update Magnitude: 0.32987

Collected Steps per Second: 21,553.59655
Overall Steps per Second: 10,367.56193

Timestep Collection Time: 2.32045
Timestep Consumption Time: 2.50364
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.82408

Cumulative Model Updates: 150,670
Cumulative Timesteps: 1,257,314,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1257314220...
Checkpoint 1257314220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,102.39625
Policy Entropy: 1.76163
Value Function Loss: 0.04933

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.31222
Value Function Update Magnitude: 0.33929

Collected Steps per Second: 21,630.00324
Overall Steps per Second: 10,344.63784

Timestep Collection Time: 2.31188
Timestep Consumption Time: 2.52212
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.83400

Cumulative Model Updates: 150,676
Cumulative Timesteps: 1,257,364,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,572.48051
Policy Entropy: 1.75031
Value Function Loss: 0.04968

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.31536
Value Function Update Magnitude: 0.34731

Collected Steps per Second: 22,079.84981
Overall Steps per Second: 10,445.86789

Timestep Collection Time: 2.26523
Timestep Consumption Time: 2.52288
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.78811

Cumulative Model Updates: 150,682
Cumulative Timesteps: 1,257,414,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1257414242...
Checkpoint 1257414242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,136.37954
Policy Entropy: 1.74904
Value Function Loss: 0.05078

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.31741
Value Function Update Magnitude: 0.34445

Collected Steps per Second: 21,701.55118
Overall Steps per Second: 10,565.05071

Timestep Collection Time: 2.30527
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.73524

Cumulative Model Updates: 150,688
Cumulative Timesteps: 1,257,464,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,628.46227
Policy Entropy: 1.73313
Value Function Loss: 0.05047

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.31987
Value Function Update Magnitude: 0.35185

Collected Steps per Second: 21,735.89210
Overall Steps per Second: 10,568.73990

Timestep Collection Time: 2.30191
Timestep Consumption Time: 2.43224
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.73415

Cumulative Model Updates: 150,694
Cumulative Timesteps: 1,257,514,304

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1257514304...
Checkpoint 1257514304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,670.28140
Policy Entropy: 1.73282
Value Function Loss: 0.04546

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.31444
Value Function Update Magnitude: 0.34586

Collected Steps per Second: 21,232.38843
Overall Steps per Second: 10,453.68010

Timestep Collection Time: 2.35631
Timestep Consumption Time: 2.42957
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.78587

Cumulative Model Updates: 150,700
Cumulative Timesteps: 1,257,564,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,047.43752
Policy Entropy: 1.72828
Value Function Loss: 0.04773

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.31007
Value Function Update Magnitude: 0.32097

Collected Steps per Second: 21,590.26966
Overall Steps per Second: 10,540.99051

Timestep Collection Time: 2.31651
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.74472

Cumulative Model Updates: 150,706
Cumulative Timesteps: 1,257,614,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1257614348...
Checkpoint 1257614348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,610.04645
Policy Entropy: 1.73846
Value Function Loss: 0.04809

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.31284
Value Function Update Magnitude: 0.32876

Collected Steps per Second: 21,105.76970
Overall Steps per Second: 10,605.69414

Timestep Collection Time: 2.37035
Timestep Consumption Time: 2.34674
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.71709

Cumulative Model Updates: 150,712
Cumulative Timesteps: 1,257,664,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,823.58624
Policy Entropy: 1.73599
Value Function Loss: 0.04937

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.31585
Value Function Update Magnitude: 0.34520

Collected Steps per Second: 21,478.04552
Overall Steps per Second: 10,557.38112

Timestep Collection Time: 2.32814
Timestep Consumption Time: 2.40826
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.73640

Cumulative Model Updates: 150,718
Cumulative Timesteps: 1,257,714,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1257714380...
Checkpoint 1257714380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,981.96952
Policy Entropy: 1.72840
Value Function Loss: 0.04691

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.31367
Value Function Update Magnitude: 0.35256

Collected Steps per Second: 21,843.73495
Overall Steps per Second: 10,539.17951

Timestep Collection Time: 2.28908
Timestep Consumption Time: 2.45531
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.74439

Cumulative Model Updates: 150,724
Cumulative Timesteps: 1,257,764,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,109.62841
Policy Entropy: 1.73436
Value Function Loss: 0.04711

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.31183
Value Function Update Magnitude: 0.36251

Collected Steps per Second: 21,504.58948
Overall Steps per Second: 10,458.00417

Timestep Collection Time: 2.32583
Timestep Consumption Time: 2.45673
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.78256

Cumulative Model Updates: 150,730
Cumulative Timesteps: 1,257,814,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1257814398...
Checkpoint 1257814398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,659.41585
Policy Entropy: 1.74923
Value Function Loss: 0.04568

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.31168
Value Function Update Magnitude: 0.34992

Collected Steps per Second: 21,303.69755
Overall Steps per Second: 10,376.68882

Timestep Collection Time: 2.34851
Timestep Consumption Time: 2.47306
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.82158

Cumulative Model Updates: 150,736
Cumulative Timesteps: 1,257,864,430

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,427.30180
Policy Entropy: 1.76877
Value Function Loss: 0.04787

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.31471
Value Function Update Magnitude: 0.34735

Collected Steps per Second: 21,796.33352
Overall Steps per Second: 10,467.22045

Timestep Collection Time: 2.29506
Timestep Consumption Time: 2.48405
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.77911

Cumulative Model Updates: 150,742
Cumulative Timesteps: 1,257,914,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1257914454...
Checkpoint 1257914454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,469.76937
Policy Entropy: 1.75851
Value Function Loss: 0.04753

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.31372
Value Function Update Magnitude: 0.38298

Collected Steps per Second: 21,462.58234
Overall Steps per Second: 10,504.87425

Timestep Collection Time: 2.33150
Timestep Consumption Time: 2.43200
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.76350

Cumulative Model Updates: 150,748
Cumulative Timesteps: 1,257,964,494

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,551.47063
Policy Entropy: 1.77942
Value Function Loss: 0.04789

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.31385
Value Function Update Magnitude: 0.37860

Collected Steps per Second: 22,272.36362
Overall Steps per Second: 10,461.84211

Timestep Collection Time: 2.24538
Timestep Consumption Time: 2.53485
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.78023

Cumulative Model Updates: 150,754
Cumulative Timesteps: 1,258,014,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1258014504...
Checkpoint 1258014504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,075.72155
Policy Entropy: 1.78006
Value Function Loss: 0.04377

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.30842
Value Function Update Magnitude: 0.35439

Collected Steps per Second: 21,886.68856
Overall Steps per Second: 10,586.54810

Timestep Collection Time: 2.28541
Timestep Consumption Time: 2.43946
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.72486

Cumulative Model Updates: 150,760
Cumulative Timesteps: 1,258,064,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,968.44093
Policy Entropy: 1.78955
Value Function Loss: 0.04399

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07371
Policy Update Magnitude: 0.30163
Value Function Update Magnitude: 0.35377

Collected Steps per Second: 22,222.05631
Overall Steps per Second: 10,458.86525

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.53082
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.78102

Cumulative Model Updates: 150,766
Cumulative Timesteps: 1,258,114,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1258114528...
Checkpoint 1258114528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,830.64011
Policy Entropy: 1.77559
Value Function Loss: 0.04460

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07390
Policy Update Magnitude: 0.30207
Value Function Update Magnitude: 0.33856

Collected Steps per Second: 22,174.90209
Overall Steps per Second: 10,665.06175

Timestep Collection Time: 2.25579
Timestep Consumption Time: 2.43447
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.69027

Cumulative Model Updates: 150,772
Cumulative Timesteps: 1,258,164,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,429.94819
Policy Entropy: 1.78685
Value Function Loss: 0.04912

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.30862
Value Function Update Magnitude: 0.33846

Collected Steps per Second: 22,206.50199
Overall Steps per Second: 10,463.69246

Timestep Collection Time: 2.25159
Timestep Consumption Time: 2.52684
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.77843

Cumulative Model Updates: 150,778
Cumulative Timesteps: 1,258,214,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1258214550...
Checkpoint 1258214550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,938.29108
Policy Entropy: 1.77681
Value Function Loss: 0.04587

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.30533
Value Function Update Magnitude: 0.34284

Collected Steps per Second: 21,903.31066
Overall Steps per Second: 10,594.13327

Timestep Collection Time: 2.28422
Timestep Consumption Time: 2.43839
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.72261

Cumulative Model Updates: 150,784
Cumulative Timesteps: 1,258,264,582

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,712.36800
Policy Entropy: 1.77481
Value Function Loss: 0.04357

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.30201
Value Function Update Magnitude: 0.30055

Collected Steps per Second: 21,851.77280
Overall Steps per Second: 10,464.67466

Timestep Collection Time: 2.28860
Timestep Consumption Time: 2.49033
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.77894

Cumulative Model Updates: 150,790
Cumulative Timesteps: 1,258,314,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1258314592...
Checkpoint 1258314592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,310.85526
Policy Entropy: 1.75681
Value Function Loss: 0.04554

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07461
Policy Update Magnitude: 0.30487
Value Function Update Magnitude: 0.29230

Collected Steps per Second: 21,503.66321
Overall Steps per Second: 10,379.76428

Timestep Collection Time: 2.32612
Timestep Consumption Time: 2.49288
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.81899

Cumulative Model Updates: 150,796
Cumulative Timesteps: 1,258,364,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,017.27925
Policy Entropy: 1.75103
Value Function Loss: 0.04721

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.30899
Value Function Update Magnitude: 0.30680

Collected Steps per Second: 21,925.47014
Overall Steps per Second: 10,656.15931

Timestep Collection Time: 2.28191
Timestep Consumption Time: 2.41321
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.69513

Cumulative Model Updates: 150,802
Cumulative Timesteps: 1,258,414,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1258414644...
Checkpoint 1258414644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,582.96078
Policy Entropy: 1.75712
Value Function Loss: 0.04916

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.31107
Value Function Update Magnitude: 0.31442

Collected Steps per Second: 21,393.46590
Overall Steps per Second: 10,270.43444

Timestep Collection Time: 2.33791
Timestep Consumption Time: 2.53199
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.86990

Cumulative Model Updates: 150,808
Cumulative Timesteps: 1,258,464,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,380.43750
Policy Entropy: 1.76550
Value Function Loss: 0.04801

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08251
Policy Update Magnitude: 0.30973
Value Function Update Magnitude: 0.31862

Collected Steps per Second: 21,906.23389
Overall Steps per Second: 10,436.96970

Timestep Collection Time: 2.28328
Timestep Consumption Time: 2.50911
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.79239

Cumulative Model Updates: 150,814
Cumulative Timesteps: 1,258,514,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1258514678...
Checkpoint 1258514678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,563.92846
Policy Entropy: 1.77851
Value Function Loss: 0.04600

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.30568
Value Function Update Magnitude: 0.32043

Collected Steps per Second: 22,000.58617
Overall Steps per Second: 10,584.19514

Timestep Collection Time: 2.27376
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.72629

Cumulative Model Updates: 150,820
Cumulative Timesteps: 1,258,564,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,077.48016
Policy Entropy: 1.76928
Value Function Loss: 0.04600

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.30514
Value Function Update Magnitude: 0.32551

Collected Steps per Second: 22,161.69203
Overall Steps per Second: 10,510.13366

Timestep Collection Time: 2.25768
Timestep Consumption Time: 2.50287
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.76055

Cumulative Model Updates: 150,826
Cumulative Timesteps: 1,258,614,736

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1258614736...
Checkpoint 1258614736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,344.33662
Policy Entropy: 1.76339
Value Function Loss: 0.04678

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.30892
Value Function Update Magnitude: 0.32750

Collected Steps per Second: 21,781.89339
Overall Steps per Second: 10,607.16562

Timestep Collection Time: 2.29567
Timestep Consumption Time: 2.41850
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.71417

Cumulative Model Updates: 150,832
Cumulative Timesteps: 1,258,664,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,140.15200
Policy Entropy: 1.76162
Value Function Loss: 0.04779

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08939
Policy Update Magnitude: 0.31211
Value Function Update Magnitude: 0.33277

Collected Steps per Second: 21,759.98313
Overall Steps per Second: 10,553.76936

Timestep Collection Time: 2.29936
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.74087

Cumulative Model Updates: 150,838
Cumulative Timesteps: 1,258,714,774

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1258714774...
Checkpoint 1258714774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,514.50240
Policy Entropy: 1.75710
Value Function Loss: 0.04513

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.30719
Value Function Update Magnitude: 0.33495

Collected Steps per Second: 22,101.95271
Overall Steps per Second: 10,660.60401

Timestep Collection Time: 2.26270
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.69110

Cumulative Model Updates: 150,844
Cumulative Timesteps: 1,258,764,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,201.11628
Policy Entropy: 1.75527
Value Function Loss: 0.04500

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.30332
Value Function Update Magnitude: 0.32290

Collected Steps per Second: 20,461.93181
Overall Steps per Second: 10,139.36879

Timestep Collection Time: 2.44483
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.93384

Cumulative Model Updates: 150,850
Cumulative Timesteps: 1,258,814,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1258814810...
Checkpoint 1258814810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,716.74504
Policy Entropy: 1.75805
Value Function Loss: 0.04313

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.30412
Value Function Update Magnitude: 0.29837

Collected Steps per Second: 20,817.94154
Overall Steps per Second: 10,525.97526

Timestep Collection Time: 2.40225
Timestep Consumption Time: 2.34885
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.75110

Cumulative Model Updates: 150,856
Cumulative Timesteps: 1,258,864,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,886.82913
Policy Entropy: 1.76191
Value Function Loss: 0.04219

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.30260
Value Function Update Magnitude: 0.28161

Collected Steps per Second: 21,363.54324
Overall Steps per Second: 10,461.81528

Timestep Collection Time: 2.34240
Timestep Consumption Time: 2.44090
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.78330

Cumulative Model Updates: 150,862
Cumulative Timesteps: 1,258,914,862

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1258914862...
Checkpoint 1258914862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,814.11446
Policy Entropy: 1.76327
Value Function Loss: 0.04175

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.29950
Value Function Update Magnitude: 0.28780

Collected Steps per Second: 21,048.97362
Overall Steps per Second: 10,510.84780

Timestep Collection Time: 2.37636
Timestep Consumption Time: 2.38253
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.75889

Cumulative Model Updates: 150,868
Cumulative Timesteps: 1,258,964,882

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,001.39609
Policy Entropy: 1.75726
Value Function Loss: 0.04376

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.30309
Value Function Update Magnitude: 0.30430

Collected Steps per Second: 21,622.41065
Overall Steps per Second: 10,516.02877

Timestep Collection Time: 2.31279
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.75541

Cumulative Model Updates: 150,874
Cumulative Timesteps: 1,259,014,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1259014890...
Checkpoint 1259014890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,862.41059
Policy Entropy: 1.75173
Value Function Loss: 0.04561

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.28711
Value Function Update Magnitude: 0.31879

Collected Steps per Second: 21,190.86079
Overall Steps per Second: 10,344.58445

Timestep Collection Time: 2.36017
Timestep Consumption Time: 2.47463
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.83480

Cumulative Model Updates: 150,880
Cumulative Timesteps: 1,259,064,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,903.67976
Policy Entropy: 1.74996
Value Function Loss: 0.04572

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.28772
Value Function Update Magnitude: 0.32917

Collected Steps per Second: 22,275.81007
Overall Steps per Second: 10,720.60700

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.41981
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.66485

Cumulative Model Updates: 150,886
Cumulative Timesteps: 1,259,114,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1259114914...
Checkpoint 1259114914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,857.86008
Policy Entropy: 1.75259
Value Function Loss: 0.04642

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.29496
Value Function Update Magnitude: 0.32806

Collected Steps per Second: 21,925.50343
Overall Steps per Second: 10,640.02580

Timestep Collection Time: 2.28173
Timestep Consumption Time: 2.42014
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.70187

Cumulative Model Updates: 150,892
Cumulative Timesteps: 1,259,164,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,606.04981
Policy Entropy: 1.75399
Value Function Loss: 0.04750

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08103
Policy Update Magnitude: 0.30382
Value Function Update Magnitude: 0.33577

Collected Steps per Second: 22,106.66384
Overall Steps per Second: 10,528.55382

Timestep Collection Time: 2.26221
Timestep Consumption Time: 2.48773
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.74994

Cumulative Model Updates: 150,898
Cumulative Timesteps: 1,259,214,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1259214952...
Checkpoint 1259214952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,836.81248
Policy Entropy: 1.76799
Value Function Loss: 0.04471

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.30180
Value Function Update Magnitude: 0.33390

Collected Steps per Second: 21,465.70008
Overall Steps per Second: 10,517.66464

Timestep Collection Time: 2.32939
Timestep Consumption Time: 2.42471
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.75410

Cumulative Model Updates: 150,904
Cumulative Timesteps: 1,259,264,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,418.30841
Policy Entropy: 1.77963
Value Function Loss: 0.04358

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.29900
Value Function Update Magnitude: 0.32341

Collected Steps per Second: 21,747.91108
Overall Steps per Second: 10,524.38164

Timestep Collection Time: 2.30027
Timestep Consumption Time: 2.45308
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.75334

Cumulative Model Updates: 150,910
Cumulative Timesteps: 1,259,314,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1259314980...
Checkpoint 1259314980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,769.25580
Policy Entropy: 1.77509
Value Function Loss: 0.04374

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.29668
Value Function Update Magnitude: 0.33488

Collected Steps per Second: 21,456.34928
Overall Steps per Second: 10,320.10948

Timestep Collection Time: 2.33143
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.84724

Cumulative Model Updates: 150,916
Cumulative Timesteps: 1,259,365,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,302.35365
Policy Entropy: 1.76890
Value Function Loss: 0.04911

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.30797
Value Function Update Magnitude: 0.35139

Collected Steps per Second: 21,929.07198
Overall Steps per Second: 10,485.81071

Timestep Collection Time: 2.28163
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.77159

Cumulative Model Updates: 150,922
Cumulative Timesteps: 1,259,415,038

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1259415038...
Checkpoint 1259415038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,544.29272
Policy Entropy: 1.75990
Value Function Loss: 0.04742

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.30929
Value Function Update Magnitude: 0.35613

Collected Steps per Second: 21,311.23047
Overall Steps per Second: 10,408.41541

Timestep Collection Time: 2.34656
Timestep Consumption Time: 2.45802
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.80457

Cumulative Model Updates: 150,928
Cumulative Timesteps: 1,259,465,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,246.58503
Policy Entropy: 1.76081
Value Function Loss: 0.04654

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.30566
Value Function Update Magnitude: 0.34712

Collected Steps per Second: 20,757.55702
Overall Steps per Second: 10,103.88894

Timestep Collection Time: 2.40915
Timestep Consumption Time: 2.54023
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.94938

Cumulative Model Updates: 150,934
Cumulative Timesteps: 1,259,515,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1259515054...
Checkpoint 1259515054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,691.06256
Policy Entropy: 1.76902
Value Function Loss: 0.04751

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.31136
Value Function Update Magnitude: 0.33101

Collected Steps per Second: 20,583.38919
Overall Steps per Second: 10,161.03386

Timestep Collection Time: 2.42973
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.92194

Cumulative Model Updates: 150,940
Cumulative Timesteps: 1,259,565,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,663.85883
Policy Entropy: 1.77236
Value Function Loss: 0.05097

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07863
Policy Update Magnitude: 0.31365
Value Function Update Magnitude: 0.35826

Collected Steps per Second: 20,710.64931
Overall Steps per Second: 10,112.08112

Timestep Collection Time: 2.41644
Timestep Consumption Time: 2.53269
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.94913

Cumulative Model Updates: 150,946
Cumulative Timesteps: 1,259,615,112

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1259615112...
Checkpoint 1259615112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,422.14788
Policy Entropy: 1.77429
Value Function Loss: 0.05325

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08009
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.39372

Collected Steps per Second: 20,529.55107
Overall Steps per Second: 10,158.33959

Timestep Collection Time: 2.43571
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.92246

Cumulative Model Updates: 150,952
Cumulative Timesteps: 1,259,665,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,192.06213
Policy Entropy: 1.76256
Value Function Loss: 0.04998

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.31226
Value Function Update Magnitude: 0.38826

Collected Steps per Second: 20,932.17542
Overall Steps per Second: 10,146.90921

Timestep Collection Time: 2.38895
Timestep Consumption Time: 2.53925
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.92820

Cumulative Model Updates: 150,958
Cumulative Timesteps: 1,259,715,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1259715122...
Checkpoint 1259715122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,076.46278
Policy Entropy: 1.75679
Value Function Loss: 0.05065

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.10708
Policy Update Magnitude: 0.28202
Value Function Update Magnitude: 0.37373

Collected Steps per Second: 20,635.20109
Overall Steps per Second: 10,086.47097

Timestep Collection Time: 2.42353
Timestep Consumption Time: 2.53460
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.95813

Cumulative Model Updates: 150,964
Cumulative Timesteps: 1,259,765,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,487.34043
Policy Entropy: 1.76710
Value Function Loss: 0.04972

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.27647
Value Function Update Magnitude: 0.36398

Collected Steps per Second: 20,873.62567
Overall Steps per Second: 10,138.22350

Timestep Collection Time: 2.39613
Timestep Consumption Time: 2.53727
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.93341

Cumulative Model Updates: 150,970
Cumulative Timesteps: 1,259,815,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1259815148...
Checkpoint 1259815148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,877.97017
Policy Entropy: 1.77292
Value Function Loss: 0.05079

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.29669
Value Function Update Magnitude: 0.35211

Collected Steps per Second: 21,795.14473
Overall Steps per Second: 10,575.72932

Timestep Collection Time: 2.29464
Timestep Consumption Time: 2.43430
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.72894

Cumulative Model Updates: 150,976
Cumulative Timesteps: 1,259,865,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,868.29989
Policy Entropy: 1.77457
Value Function Loss: 0.04869

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.30840
Value Function Update Magnitude: 0.34006

Collected Steps per Second: 22,222.97460
Overall Steps per Second: 10,526.52692

Timestep Collection Time: 2.25064
Timestep Consumption Time: 2.50078
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.75142

Cumulative Model Updates: 150,982
Cumulative Timesteps: 1,259,915,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1259915176...
Checkpoint 1259915176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,433.58216
Policy Entropy: 1.76139
Value Function Loss: 0.04501

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.30815
Value Function Update Magnitude: 0.33547

Collected Steps per Second: 21,302.47599
Overall Steps per Second: 10,618.78984

Timestep Collection Time: 2.34780
Timestep Consumption Time: 2.36215
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.70995

Cumulative Model Updates: 150,988
Cumulative Timesteps: 1,259,965,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,051.73818
Policy Entropy: 1.75373
Value Function Loss: 0.04299

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.30366
Value Function Update Magnitude: 0.33339

Collected Steps per Second: 21,397.67908
Overall Steps per Second: 10,522.47937

Timestep Collection Time: 2.33736
Timestep Consumption Time: 2.41571
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.75306

Cumulative Model Updates: 150,994
Cumulative Timesteps: 1,260,015,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1260015204...
Checkpoint 1260015204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,976.85304
Policy Entropy: 1.75180
Value Function Loss: 0.04320

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.30542
Value Function Update Magnitude: 0.33975

Collected Steps per Second: 20,634.88783
Overall Steps per Second: 10,471.64605

Timestep Collection Time: 2.42444
Timestep Consumption Time: 2.35303
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.77747

Cumulative Model Updates: 151,000
Cumulative Timesteps: 1,260,065,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,203.99424
Policy Entropy: 1.76097
Value Function Loss: 0.04281

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.30321
Value Function Update Magnitude: 0.34513

Collected Steps per Second: 21,259.81103
Overall Steps per Second: 10,498.58764

Timestep Collection Time: 2.35308
Timestep Consumption Time: 2.41194
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.76502

Cumulative Model Updates: 151,006
Cumulative Timesteps: 1,260,115,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1260115258...
Checkpoint 1260115258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,647.64006
Policy Entropy: 1.78339
Value Function Loss: 0.04685

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.30224
Value Function Update Magnitude: 0.35765

Collected Steps per Second: 21,142.24021
Overall Steps per Second: 10,314.04191

Timestep Collection Time: 2.36749
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.85300

Cumulative Model Updates: 151,012
Cumulative Timesteps: 1,260,165,312

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,753.48100
Policy Entropy: 1.78711
Value Function Loss: 0.04527

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.30469
Value Function Update Magnitude: 0.35418

Collected Steps per Second: 22,133.28765
Overall Steps per Second: 10,536.11745

Timestep Collection Time: 2.25976
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.74710

Cumulative Model Updates: 151,018
Cumulative Timesteps: 1,260,215,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1260215328...
Checkpoint 1260215328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,763.60816
Policy Entropy: 1.79265
Value Function Loss: 0.04484

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.30045
Value Function Update Magnitude: 0.34295

Collected Steps per Second: 21,951.17400
Overall Steps per Second: 10,500.01954

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.76190

Cumulative Model Updates: 151,024
Cumulative Timesteps: 1,260,265,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,875.21573
Policy Entropy: 1.75602
Value Function Loss: 0.04424

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.30278
Value Function Update Magnitude: 0.30470

Collected Steps per Second: 22,170.73211
Overall Steps per Second: 10,495.10981

Timestep Collection Time: 2.25541
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.76450

Cumulative Model Updates: 151,030
Cumulative Timesteps: 1,260,315,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1260315332...
Checkpoint 1260315332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,520.30009
Policy Entropy: 1.77090
Value Function Loss: 0.04786

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.30623
Value Function Update Magnitude: 0.27295

Collected Steps per Second: 21,973.03148
Overall Steps per Second: 10,554.14539

Timestep Collection Time: 2.27597
Timestep Consumption Time: 2.46245
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.73842

Cumulative Model Updates: 151,036
Cumulative Timesteps: 1,260,365,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,086.42617
Policy Entropy: 1.75447
Value Function Loss: 0.04861

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.30766
Value Function Update Magnitude: 0.24832

Collected Steps per Second: 21,985.13408
Overall Steps per Second: 10,458.93672

Timestep Collection Time: 2.27472
Timestep Consumption Time: 2.50684
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.78156

Cumulative Model Updates: 151,042
Cumulative Timesteps: 1,260,415,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1260415352...
Checkpoint 1260415352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,862.64718
Policy Entropy: 1.76987
Value Function Loss: 0.04789

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.30902
Value Function Update Magnitude: 0.29217

Collected Steps per Second: 22,043.66177
Overall Steps per Second: 10,687.57684

Timestep Collection Time: 2.26950
Timestep Consumption Time: 2.41145
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.68095

Cumulative Model Updates: 151,048
Cumulative Timesteps: 1,260,465,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,051.32560
Policy Entropy: 1.75293
Value Function Loss: 0.04234

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.30026
Value Function Update Magnitude: 0.32480

Collected Steps per Second: 21,985.70411
Overall Steps per Second: 10,449.49563

Timestep Collection Time: 2.27530
Timestep Consumption Time: 2.51192
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.78722

Cumulative Model Updates: 151,054
Cumulative Timesteps: 1,260,515,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1260515404...
Checkpoint 1260515404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,279.68208
Policy Entropy: 1.76922
Value Function Loss: 0.04725

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.30030
Value Function Update Magnitude: 0.29760

Collected Steps per Second: 21,349.72721
Overall Steps per Second: 10,500.55163

Timestep Collection Time: 2.34279
Timestep Consumption Time: 2.42058
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.76337

Cumulative Model Updates: 151,060
Cumulative Timesteps: 1,260,565,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,619.25969
Policy Entropy: 1.75529
Value Function Loss: 0.04757

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.30522
Value Function Update Magnitude: 0.33196

Collected Steps per Second: 21,398.06296
Overall Steps per Second: 10,489.59906

Timestep Collection Time: 2.33778
Timestep Consumption Time: 2.43113
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.76891

Cumulative Model Updates: 151,066
Cumulative Timesteps: 1,260,615,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1260615446...
Checkpoint 1260615446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,689.99354
Policy Entropy: 1.76347
Value Function Loss: 0.05193

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08259
Policy Update Magnitude: 0.31307
Value Function Update Magnitude: 0.36791

Collected Steps per Second: 21,123.77664
Overall Steps per Second: 10,237.44599

Timestep Collection Time: 2.36785
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.88579

Cumulative Model Updates: 151,072
Cumulative Timesteps: 1,260,665,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,272.86646
Policy Entropy: 1.76822
Value Function Loss: 0.04450

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07881
Policy Update Magnitude: 0.30966
Value Function Update Magnitude: 0.36586

Collected Steps per Second: 21,528.30949
Overall Steps per Second: 10,513.68579

Timestep Collection Time: 2.32438
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.75951

Cumulative Model Updates: 151,078
Cumulative Timesteps: 1,260,715,504

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1260715504...
Checkpoint 1260715504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,186.43047
Policy Entropy: 1.78525
Value Function Loss: 0.04239

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07488
Policy Update Magnitude: 0.29940
Value Function Update Magnitude: 0.33888

Collected Steps per Second: 21,768.65537
Overall Steps per Second: 10,541.61022

Timestep Collection Time: 2.29725
Timestep Consumption Time: 2.44662
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74387

Cumulative Model Updates: 151,084
Cumulative Timesteps: 1,260,765,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,267.70374
Policy Entropy: 1.78115
Value Function Loss: 0.04265

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.29587
Value Function Update Magnitude: 0.30162

Collected Steps per Second: 22,087.97773
Overall Steps per Second: 10,501.09940

Timestep Collection Time: 2.26413
Timestep Consumption Time: 2.49823
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.76236

Cumulative Model Updates: 151,090
Cumulative Timesteps: 1,260,815,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1260815522...
Checkpoint 1260815522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,531.46919
Policy Entropy: 1.78599
Value Function Loss: 0.04657

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.30374
Value Function Update Magnitude: 0.28294

Collected Steps per Second: 21,899.51984
Overall Steps per Second: 10,596.31733

Timestep Collection Time: 2.28462
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.72164

Cumulative Model Updates: 151,096
Cumulative Timesteps: 1,260,865,554

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,646.56860
Policy Entropy: 1.75614
Value Function Loss: 0.04657

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.30388
Value Function Update Magnitude: 0.28461

Collected Steps per Second: 22,022.45117
Overall Steps per Second: 10,510.88663

Timestep Collection Time: 2.27096
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.75811

Cumulative Model Updates: 151,102
Cumulative Timesteps: 1,260,915,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1260915566...
Checkpoint 1260915566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,120.28422
Policy Entropy: 1.77751
Value Function Loss: 0.04603

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.30065
Value Function Update Magnitude: 0.30917

Collected Steps per Second: 22,156.74131
Overall Steps per Second: 10,680.89761

Timestep Collection Time: 2.25701
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.68200

Cumulative Model Updates: 151,108
Cumulative Timesteps: 1,260,965,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,810.78146
Policy Entropy: 1.76587
Value Function Loss: 0.04240

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.29886
Value Function Update Magnitude: 0.30671

Collected Steps per Second: 21,793.47288
Overall Steps per Second: 10,743.68264

Timestep Collection Time: 2.29491
Timestep Consumption Time: 2.36029
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.65520

Cumulative Model Updates: 151,114
Cumulative Timesteps: 1,261,015,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1261015588...
Checkpoint 1261015588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,199.25245
Policy Entropy: 1.76947
Value Function Loss: 0.04290

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.30132
Value Function Update Magnitude: 0.30427

Collected Steps per Second: 20,873.90283
Overall Steps per Second: 10,291.90108

Timestep Collection Time: 2.39764
Timestep Consumption Time: 2.46522
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.86285

Cumulative Model Updates: 151,120
Cumulative Timesteps: 1,261,065,636

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,349.55023
Policy Entropy: 1.75018
Value Function Loss: 0.04723

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07400
Policy Update Magnitude: 0.31095
Value Function Update Magnitude: 0.32258

Collected Steps per Second: 19,944.09449
Overall Steps per Second: 9,979.37726

Timestep Collection Time: 2.50791
Timestep Consumption Time: 2.50423
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 5.01214

Cumulative Model Updates: 151,126
Cumulative Timesteps: 1,261,115,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1261115654...
Checkpoint 1261115654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,764.09699
Policy Entropy: 1.74325
Value Function Loss: 0.04658

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07730
Policy Update Magnitude: 0.31623
Value Function Update Magnitude: 0.34687

Collected Steps per Second: 19,670.99277
Overall Steps per Second: 10,195.09693

Timestep Collection Time: 2.54202
Timestep Consumption Time: 2.36269
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.90471

Cumulative Model Updates: 151,132
Cumulative Timesteps: 1,261,165,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,133.62099
Policy Entropy: 1.74161
Value Function Loss: 0.04340

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.34818

Collected Steps per Second: 19,865.18656
Overall Steps per Second: 10,066.12472

Timestep Collection Time: 2.51717
Timestep Consumption Time: 2.45038
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.96755

Cumulative Model Updates: 151,138
Cumulative Timesteps: 1,261,215,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1261215662...
Checkpoint 1261215662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,248.69814
Policy Entropy: 1.75003
Value Function Loss: 0.03891

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07502
Policy Update Magnitude: 0.29723
Value Function Update Magnitude: 0.32832

Collected Steps per Second: 20,359.04366
Overall Steps per Second: 10,183.35143

Timestep Collection Time: 2.45689
Timestep Consumption Time: 2.45505
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.91194

Cumulative Model Updates: 151,144
Cumulative Timesteps: 1,261,265,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,176.67449
Policy Entropy: 1.75396
Value Function Loss: 0.04507

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07164
Policy Update Magnitude: 0.30303
Value Function Update Magnitude: 0.32494

Collected Steps per Second: 20,668.24830
Overall Steps per Second: 9,997.79507

Timestep Collection Time: 2.42091
Timestep Consumption Time: 2.58379
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 5.00470

Cumulative Model Updates: 151,150
Cumulative Timesteps: 1,261,315,718

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1261315718...
Checkpoint 1261315718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,367.73096
Policy Entropy: 1.75614
Value Function Loss: 0.04613

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.31270
Value Function Update Magnitude: 0.32082

Collected Steps per Second: 20,528.12568
Overall Steps per Second: 10,235.29207

Timestep Collection Time: 2.43792
Timestep Consumption Time: 2.45163
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.88955

Cumulative Model Updates: 151,156
Cumulative Timesteps: 1,261,365,764

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,976.47612
Policy Entropy: 1.75905
Value Function Loss: 0.04713

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.31241
Value Function Update Magnitude: 0.30504

Collected Steps per Second: 20,454.63266
Overall Steps per Second: 10,069.04369

Timestep Collection Time: 2.44453
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.96591

Cumulative Model Updates: 151,162
Cumulative Timesteps: 1,261,415,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1261415766...
Checkpoint 1261415766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,738.94776
Policy Entropy: 1.76638
Value Function Loss: 0.04821

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.31335
Value Function Update Magnitude: 0.31481

Collected Steps per Second: 20,482.39651
Overall Steps per Second: 10,186.28553

Timestep Collection Time: 2.44200
Timestep Consumption Time: 2.46833
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.91033

Cumulative Model Updates: 151,168
Cumulative Timesteps: 1,261,465,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,370.46961
Policy Entropy: 1.79313
Value Function Loss: 0.05050

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.31741
Value Function Update Magnitude: 0.34773

Collected Steps per Second: 19,251.42148
Overall Steps per Second: 9,740.15134

Timestep Collection Time: 2.59731
Timestep Consumption Time: 2.53628
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 5.13360

Cumulative Model Updates: 151,174
Cumulative Timesteps: 1,261,515,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1261515786...
Checkpoint 1261515786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,588.34498
Policy Entropy: 1.78138
Value Function Loss: 0.04893

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.31551
Value Function Update Magnitude: 0.36115

Collected Steps per Second: 20,835.46430
Overall Steps per Second: 10,235.92489

Timestep Collection Time: 2.40110
Timestep Consumption Time: 2.48639
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.88749

Cumulative Model Updates: 151,180
Cumulative Timesteps: 1,261,565,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,963.78048
Policy Entropy: 1.76919
Value Function Loss: 0.05104

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.32018
Value Function Update Magnitude: 0.36512

Collected Steps per Second: 21,972.09747
Overall Steps per Second: 10,417.57961

Timestep Collection Time: 2.27589
Timestep Consumption Time: 2.52427
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.80016

Cumulative Model Updates: 151,186
Cumulative Timesteps: 1,261,615,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1261615820...
Checkpoint 1261615820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,205.45214
Policy Entropy: 1.75551
Value Function Loss: 0.04814

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.31672
Value Function Update Magnitude: 0.38756

Collected Steps per Second: 22,019.09249
Overall Steps per Second: 10,629.23038

Timestep Collection Time: 2.27130
Timestep Consumption Time: 2.43384
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.70514

Cumulative Model Updates: 151,192
Cumulative Timesteps: 1,261,665,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,011.89666
Policy Entropy: 1.77377
Value Function Loss: 0.05023

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.31537
Value Function Update Magnitude: 0.39244

Collected Steps per Second: 21,983.25570
Overall Steps per Second: 10,443.06612

Timestep Collection Time: 2.27519
Timestep Consumption Time: 2.51421
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.78940

Cumulative Model Updates: 151,198
Cumulative Timesteps: 1,261,715,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1261715848...
Checkpoint 1261715848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,453.54307
Policy Entropy: 1.78613
Value Function Loss: 0.04834

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.31541
Value Function Update Magnitude: 0.36995

Collected Steps per Second: 21,894.94253
Overall Steps per Second: 10,655.32144

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.40973
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.69418

Cumulative Model Updates: 151,204
Cumulative Timesteps: 1,261,765,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,680.88959
Policy Entropy: 1.78787
Value Function Loss: 0.04902

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.30948
Value Function Update Magnitude: 0.35366

Collected Steps per Second: 21,515.14516
Overall Steps per Second: 10,465.32825

Timestep Collection Time: 2.32515
Timestep Consumption Time: 2.45501
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.78017

Cumulative Model Updates: 151,210
Cumulative Timesteps: 1,261,815,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1261815892...
Checkpoint 1261815892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,745.99610
Policy Entropy: 1.77244
Value Function Loss: 0.04653

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.29030
Value Function Update Magnitude: 0.34638

Collected Steps per Second: 21,740.77566
Overall Steps per Second: 10,558.92395

Timestep Collection Time: 2.30047
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.73666

Cumulative Model Updates: 151,216
Cumulative Timesteps: 1,261,865,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,049.44511
Policy Entropy: 1.78189
Value Function Loss: 0.04723

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.29417
Value Function Update Magnitude: 0.35684

Collected Steps per Second: 21,359.08675
Overall Steps per Second: 10,498.75288

Timestep Collection Time: 2.34205
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.76476

Cumulative Model Updates: 151,222
Cumulative Timesteps: 1,261,915,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1261915930...
Checkpoint 1261915930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,731.01585
Policy Entropy: 1.77301
Value Function Loss: 0.04297

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.29611
Value Function Update Magnitude: 0.33168

Collected Steps per Second: 21,659.00288
Overall Steps per Second: 10,562.81278

Timestep Collection Time: 2.30906
Timestep Consumption Time: 2.42566
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.73472

Cumulative Model Updates: 151,228
Cumulative Timesteps: 1,261,965,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,596.06373
Policy Entropy: 1.79794
Value Function Loss: 0.04803

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.29028
Value Function Update Magnitude: 0.32256

Collected Steps per Second: 21,853.02291
Overall Steps per Second: 10,488.80270

Timestep Collection Time: 2.28856
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.76813

Cumulative Model Updates: 151,234
Cumulative Timesteps: 1,262,015,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1262015954...
Checkpoint 1262015954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,851.86764
Policy Entropy: 1.76596
Value Function Loss: 0.04755

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.29283
Value Function Update Magnitude: 0.33159

Collected Steps per Second: 21,551.78915
Overall Steps per Second: 10,361.24714

Timestep Collection Time: 2.32064
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.82703

Cumulative Model Updates: 151,240
Cumulative Timesteps: 1,262,065,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,626.65384
Policy Entropy: 1.77464
Value Function Loss: 0.04961

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.30035
Value Function Update Magnitude: 0.32397

Collected Steps per Second: 22,104.78371
Overall Steps per Second: 10,520.43610

Timestep Collection Time: 2.26204
Timestep Consumption Time: 2.49080
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.75284

Cumulative Model Updates: 151,246
Cumulative Timesteps: 1,262,115,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1262115970...
Checkpoint 1262115970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,305.95937
Policy Entropy: 1.75490
Value Function Loss: 0.04550

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.30238
Value Function Update Magnitude: 0.32781

Collected Steps per Second: 22,162.60264
Overall Steps per Second: 10,513.47759

Timestep Collection Time: 2.25686
Timestep Consumption Time: 2.50065
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.75751

Cumulative Model Updates: 151,252
Cumulative Timesteps: 1,262,165,988

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,197.18998
Policy Entropy: 1.76982
Value Function Loss: 0.04384

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.30146
Value Function Update Magnitude: 0.32092

Collected Steps per Second: 21,571.70689
Overall Steps per Second: 10,384.27785

Timestep Collection Time: 2.31924
Timestep Consumption Time: 2.49862
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.81786

Cumulative Model Updates: 151,258
Cumulative Timesteps: 1,262,216,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1262216018...
Checkpoint 1262216018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,938.27057
Policy Entropy: 1.76996
Value Function Loss: 0.04456

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.30500
Value Function Update Magnitude: 0.32186

Collected Steps per Second: 21,857.13062
Overall Steps per Second: 10,592.93337

Timestep Collection Time: 2.28813
Timestep Consumption Time: 2.43313
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.72126

Cumulative Model Updates: 151,264
Cumulative Timesteps: 1,262,266,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,391.38967
Policy Entropy: 1.76104
Value Function Loss: 0.04638

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.30410
Value Function Update Magnitude: 0.32800

Collected Steps per Second: 21,745.57297
Overall Steps per Second: 10,556.37229

Timestep Collection Time: 2.29959
Timestep Consumption Time: 2.43745
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.73704

Cumulative Model Updates: 151,270
Cumulative Timesteps: 1,262,316,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1262316036...
Checkpoint 1262316036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,833.10221
Policy Entropy: 1.76609
Value Function Loss: 0.05033

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.31495
Value Function Update Magnitude: 0.29766

Collected Steps per Second: 21,417.91881
Overall Steps per Second: 10,521.71761

Timestep Collection Time: 2.33524
Timestep Consumption Time: 2.41836
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.75360

Cumulative Model Updates: 151,276
Cumulative Timesteps: 1,262,366,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,484.12766
Policy Entropy: 1.77394
Value Function Loss: 0.05092

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.31845
Value Function Update Magnitude: 0.25731

Collected Steps per Second: 21,537.09738
Overall Steps per Second: 10,517.35232

Timestep Collection Time: 2.32185
Timestep Consumption Time: 2.43276
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.75462

Cumulative Model Updates: 151,282
Cumulative Timesteps: 1,262,416,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1262416058...
Checkpoint 1262416058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,524.22113
Policy Entropy: 1.78203
Value Function Loss: 0.05427

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.31528
Value Function Update Magnitude: 0.30352

Collected Steps per Second: 21,683.40163
Overall Steps per Second: 10,561.23847

Timestep Collection Time: 2.30803
Timestep Consumption Time: 2.43062
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.73865

Cumulative Model Updates: 151,288
Cumulative Timesteps: 1,262,466,104

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,082.42096
Policy Entropy: 1.77826
Value Function Loss: 0.04927

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.35761

Collected Steps per Second: 21,692.10756
Overall Steps per Second: 10,489.34521

Timestep Collection Time: 2.30582
Timestep Consumption Time: 2.46264
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.76846

Cumulative Model Updates: 151,294
Cumulative Timesteps: 1,262,516,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1262516122...
Checkpoint 1262516122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,788.33864
Policy Entropy: 1.77023
Value Function Loss: 0.05195

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.31574
Value Function Update Magnitude: 0.36843

Collected Steps per Second: 21,608.19858
Overall Steps per Second: 10,233.40475

Timestep Collection Time: 2.31421
Timestep Consumption Time: 2.57233
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.88655

Cumulative Model Updates: 151,300
Cumulative Timesteps: 1,262,566,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,432.05109
Policy Entropy: 1.75395
Value Function Loss: 0.04900

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.31849
Value Function Update Magnitude: 0.38036

Collected Steps per Second: 22,125.35717
Overall Steps per Second: 10,462.55178

Timestep Collection Time: 2.26021
Timestep Consumption Time: 2.51950
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.77971

Cumulative Model Updates: 151,306
Cumulative Timesteps: 1,262,616,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1262616136...
Checkpoint 1262616136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,750.74588
Policy Entropy: 1.73507
Value Function Loss: 0.04749

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08102
Policy Update Magnitude: 0.31547
Value Function Update Magnitude: 0.36724

Collected Steps per Second: 22,069.50271
Overall Steps per Second: 10,628.08820

Timestep Collection Time: 2.26774
Timestep Consumption Time: 2.44129
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.70903

Cumulative Model Updates: 151,312
Cumulative Timesteps: 1,262,666,184

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,804.86194
Policy Entropy: 1.72966
Value Function Loss: 0.04790

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.31784
Value Function Update Magnitude: 0.36329

Collected Steps per Second: 21,799.63984
Overall Steps per Second: 10,394.97303

Timestep Collection Time: 2.29490
Timestep Consumption Time: 2.51781
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.81271

Cumulative Model Updates: 151,318
Cumulative Timesteps: 1,262,716,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1262716212...
Checkpoint 1262716212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,576.18978
Policy Entropy: 1.73745
Value Function Loss: 0.04906

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.31653
Value Function Update Magnitude: 0.37179

Collected Steps per Second: 21,983.51254
Overall Steps per Second: 10,632.67319

Timestep Collection Time: 2.27443
Timestep Consumption Time: 2.42805
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.70249

Cumulative Model Updates: 151,324
Cumulative Timesteps: 1,262,766,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,887.49968
Policy Entropy: 1.73784
Value Function Loss: 0.05040

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.31362
Value Function Update Magnitude: 0.37109

Collected Steps per Second: 22,201.94304
Overall Steps per Second: 10,549.06629

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.48850
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.74127

Cumulative Model Updates: 151,330
Cumulative Timesteps: 1,262,816,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1262816228...
Checkpoint 1262816228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,019.94858
Policy Entropy: 1.74245
Value Function Loss: 0.04624

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.35370

Collected Steps per Second: 21,502.42984
Overall Steps per Second: 10,542.43767

Timestep Collection Time: 2.32606
Timestep Consumption Time: 2.41819
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.74425

Cumulative Model Updates: 151,336
Cumulative Timesteps: 1,262,866,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,469.27736
Policy Entropy: 1.74263
Value Function Loss: 0.04401

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.30226
Value Function Update Magnitude: 0.31154

Collected Steps per Second: 21,526.95658
Overall Steps per Second: 10,500.02308

Timestep Collection Time: 2.32341
Timestep Consumption Time: 2.44001
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.76342

Cumulative Model Updates: 151,342
Cumulative Timesteps: 1,262,916,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1262916260...
Checkpoint 1262916260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,801.12924
Policy Entropy: 1.74392
Value Function Loss: 0.04300

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.30062
Value Function Update Magnitude: 0.29929

Collected Steps per Second: 21,078.89664
Overall Steps per Second: 10,597.17759

Timestep Collection Time: 2.37289
Timestep Consumption Time: 2.34704
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.71994

Cumulative Model Updates: 151,348
Cumulative Timesteps: 1,262,966,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,110.19403
Policy Entropy: 1.77244
Value Function Loss: 0.04802

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.30401
Value Function Update Magnitude: 0.31475

Collected Steps per Second: 21,120.02031
Overall Steps per Second: 10,604.42960

Timestep Collection Time: 2.36941
Timestep Consumption Time: 2.34956
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.71897

Cumulative Model Updates: 151,354
Cumulative Timesteps: 1,263,016,320

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1263016320...
Checkpoint 1263016320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,917.11235
Policy Entropy: 1.77266
Value Function Loss: 0.04841

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.31118
Value Function Update Magnitude: 0.32937

Collected Steps per Second: 21,159.85160
Overall Steps per Second: 10,570.75728

Timestep Collection Time: 2.36382
Timestep Consumption Time: 2.36792
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.73173

Cumulative Model Updates: 151,360
Cumulative Timesteps: 1,263,066,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,080.44219
Policy Entropy: 1.77803
Value Function Loss: 0.04751

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.30493

Collected Steps per Second: 20,831.57834
Overall Steps per Second: 10,462.05294

Timestep Collection Time: 2.40030
Timestep Consumption Time: 2.37907
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.77937

Cumulative Model Updates: 151,366
Cumulative Timesteps: 1,263,116,340

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1263116340...
Checkpoint 1263116340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,470.78388
Policy Entropy: 1.75238
Value Function Loss: 0.04818

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.30944
Value Function Update Magnitude: 0.25002

Collected Steps per Second: 20,858.75505
Overall Steps per Second: 10,305.71350

Timestep Collection Time: 2.39813
Timestep Consumption Time: 2.45568
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.85381

Cumulative Model Updates: 151,372
Cumulative Timesteps: 1,263,166,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,945.26787
Policy Entropy: 1.76205
Value Function Loss: 0.04741

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.31169
Value Function Update Magnitude: 0.21885

Collected Steps per Second: 21,378.05115
Overall Steps per Second: 10,336.77998

Timestep Collection Time: 2.33932
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.83806

Cumulative Model Updates: 151,378
Cumulative Timesteps: 1,263,216,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1263216372...
Checkpoint 1263216372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,546.62753
Policy Entropy: 1.79096
Value Function Loss: 0.05071

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.31520
Value Function Update Magnitude: 0.26530

Collected Steps per Second: 22,087.85288
Overall Steps per Second: 10,616.93294

Timestep Collection Time: 2.26586
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.71398

Cumulative Model Updates: 151,384
Cumulative Timesteps: 1,263,266,420

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,607.51817
Policy Entropy: 1.79799
Value Function Loss: 0.05020

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.31840
Value Function Update Magnitude: 0.33721

Collected Steps per Second: 21,948.22489
Overall Steps per Second: 10,466.09967

Timestep Collection Time: 2.28018
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.78172

Cumulative Model Updates: 151,390
Cumulative Timesteps: 1,263,316,466

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1263316466...
Checkpoint 1263316466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,270.85030
Policy Entropy: 1.78598
Value Function Loss: 0.04960

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.32106
Value Function Update Magnitude: 0.35807

Collected Steps per Second: 21,840.21018
Overall Steps per Second: 10,614.42136

Timestep Collection Time: 2.29027
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.71246

Cumulative Model Updates: 151,396
Cumulative Timesteps: 1,263,366,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,466.39977
Policy Entropy: 1.76871
Value Function Loss: 0.04959

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.32271
Value Function Update Magnitude: 0.35672

Collected Steps per Second: 21,985.11196
Overall Steps per Second: 10,514.28731

Timestep Collection Time: 2.27499
Timestep Consumption Time: 2.48196
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.75696

Cumulative Model Updates: 151,402
Cumulative Timesteps: 1,263,416,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1263416502...
Checkpoint 1263416502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,857.20922
Policy Entropy: 1.76909
Value Function Loss: 0.04837

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.32032
Value Function Update Magnitude: 0.35357

Collected Steps per Second: 21,954.83567
Overall Steps per Second: 10,617.71471

Timestep Collection Time: 2.27758
Timestep Consumption Time: 2.43190
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.70949

Cumulative Model Updates: 151,408
Cumulative Timesteps: 1,263,466,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,719.55398
Policy Entropy: 1.78211
Value Function Loss: 0.04715

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.31130
Value Function Update Magnitude: 0.34880

Collected Steps per Second: 21,574.74045
Overall Steps per Second: 10,519.22445

Timestep Collection Time: 2.31910
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.75643

Cumulative Model Updates: 151,414
Cumulative Timesteps: 1,263,516,540

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1263516540...
Checkpoint 1263516540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,481.58268
Policy Entropy: 1.77663
Value Function Loss: 0.04773

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.31344
Value Function Update Magnitude: 0.33843

Collected Steps per Second: 21,543.13741
Overall Steps per Second: 10,537.96736

Timestep Collection Time: 2.32315
Timestep Consumption Time: 2.42615
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.74930

Cumulative Model Updates: 151,420
Cumulative Timesteps: 1,263,566,588

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,416.65307
Policy Entropy: 1.76848
Value Function Loss: 0.05026

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.31852
Value Function Update Magnitude: 0.33287

Collected Steps per Second: 21,504.64019
Overall Steps per Second: 10,493.75724

Timestep Collection Time: 2.32536
Timestep Consumption Time: 2.43995
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.76531

Cumulative Model Updates: 151,426
Cumulative Timesteps: 1,263,616,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1263616594...
Checkpoint 1263616594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,592.79429
Policy Entropy: 1.77806
Value Function Loss: 0.05174

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.32074
Value Function Update Magnitude: 0.34840

Collected Steps per Second: 21,438.26459
Overall Steps per Second: 10,362.61488

Timestep Collection Time: 2.33368
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.82793

Cumulative Model Updates: 151,432
Cumulative Timesteps: 1,263,666,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,666.76481
Policy Entropy: 1.78598
Value Function Loss: 0.05149

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.31625
Value Function Update Magnitude: 0.35379

Collected Steps per Second: 21,773.00582
Overall Steps per Second: 10,344.75671

Timestep Collection Time: 2.29762
Timestep Consumption Time: 2.53826
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.83588

Cumulative Model Updates: 151,438
Cumulative Timesteps: 1,263,716,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1263716650...
Checkpoint 1263716650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,606.91284
Policy Entropy: 1.79895
Value Function Loss: 0.04927

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.31255
Value Function Update Magnitude: 0.33540

Collected Steps per Second: 21,897.47984
Overall Steps per Second: 10,519.95836

Timestep Collection Time: 2.28446
Timestep Consumption Time: 2.47069
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.75515

Cumulative Model Updates: 151,444
Cumulative Timesteps: 1,263,766,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,432.36439
Policy Entropy: 1.79510
Value Function Loss: 0.05031

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07592
Policy Update Magnitude: 0.31555
Value Function Update Magnitude: 0.33775

Collected Steps per Second: 21,487.95470
Overall Steps per Second: 10,454.96909

Timestep Collection Time: 2.32698
Timestep Consumption Time: 2.45563
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.78261

Cumulative Model Updates: 151,450
Cumulative Timesteps: 1,263,816,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1263816676...
Checkpoint 1263816676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,444.27991
Policy Entropy: 1.79314
Value Function Loss: 0.04647

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.31613
Value Function Update Magnitude: 0.33562

Collected Steps per Second: 21,736.56578
Overall Steps per Second: 10,428.39223

Timestep Collection Time: 2.30220
Timestep Consumption Time: 2.49643
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.79863

Cumulative Model Updates: 151,456
Cumulative Timesteps: 1,263,866,718

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,677.94201
Policy Entropy: 1.77151
Value Function Loss: 0.04497

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.32905

Collected Steps per Second: 22,263.60111
Overall Steps per Second: 10,670.28210

Timestep Collection Time: 2.24699
Timestep Consumption Time: 2.44136
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.68835

Cumulative Model Updates: 151,462
Cumulative Timesteps: 1,263,916,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1263916744...
Checkpoint 1263916744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,896.75399
Policy Entropy: 1.78125
Value Function Loss: 0.04654

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.31410
Value Function Update Magnitude: 0.32128

Collected Steps per Second: 21,759.04275
Overall Steps per Second: 10,601.14302

Timestep Collection Time: 2.29845
Timestep Consumption Time: 2.41916
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.71760

Cumulative Model Updates: 151,468
Cumulative Timesteps: 1,263,966,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,082.17357
Policy Entropy: 1.79043
Value Function Loss: 0.04776

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.31872
Value Function Update Magnitude: 0.28355

Collected Steps per Second: 22,247.15476
Overall Steps per Second: 10,547.42467

Timestep Collection Time: 2.24847
Timestep Consumption Time: 2.49411
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.74258

Cumulative Model Updates: 151,474
Cumulative Timesteps: 1,264,016,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1264016778...
Checkpoint 1264016778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,959.51289
Policy Entropy: 1.81292
Value Function Loss: 0.05046

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.31471
Value Function Update Magnitude: 0.27605

Collected Steps per Second: 21,749.49738
Overall Steps per Second: 10,575.85062

Timestep Collection Time: 2.29890
Timestep Consumption Time: 2.42885
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.72775

Cumulative Model Updates: 151,480
Cumulative Timesteps: 1,264,066,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,224.94015
Policy Entropy: 1.80914
Value Function Loss: 0.04572

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07436
Policy Update Magnitude: 0.30917
Value Function Update Magnitude: 0.28216

Collected Steps per Second: 21,844.48795
Overall Steps per Second: 10,601.87343

Timestep Collection Time: 2.29129
Timestep Consumption Time: 2.42977
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.72105

Cumulative Model Updates: 151,486
Cumulative Timesteps: 1,264,116,830

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1264116830...
Checkpoint 1264116830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,241.61975
Policy Entropy: 1.79792
Value Function Loss: 0.04755

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07425
Policy Update Magnitude: 0.30878
Value Function Update Magnitude: 0.31208

Collected Steps per Second: 21,425.77642
Overall Steps per Second: 10,499.79798

Timestep Collection Time: 2.33401
Timestep Consumption Time: 2.42875
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.76276

Cumulative Model Updates: 151,492
Cumulative Timesteps: 1,264,166,838

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,416.24542
Policy Entropy: 1.79442
Value Function Loss: 0.04786

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.34518

Collected Steps per Second: 21,733.87640
Overall Steps per Second: 10,596.69524

Timestep Collection Time: 2.30175
Timestep Consumption Time: 2.41915
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.72091

Cumulative Model Updates: 151,498
Cumulative Timesteps: 1,264,216,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1264216864...
Checkpoint 1264216864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,018.67659
Policy Entropy: 1.80171
Value Function Loss: 0.05176

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.29515
Value Function Update Magnitude: 0.35576

Collected Steps per Second: 21,447.09710
Overall Steps per Second: 10,499.80632

Timestep Collection Time: 2.33178
Timestep Consumption Time: 2.43116
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.76294

Cumulative Model Updates: 151,504
Cumulative Timesteps: 1,264,266,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,255.35334
Policy Entropy: 1.79613
Value Function Loss: 0.05200

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.28601
Value Function Update Magnitude: 0.35758

Collected Steps per Second: 22,339.16159
Overall Steps per Second: 10,509.67445

Timestep Collection Time: 2.23894
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.75904

Cumulative Model Updates: 151,510
Cumulative Timesteps: 1,264,316,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1264316890...
Checkpoint 1264316890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,286.68338
Policy Entropy: 1.79093
Value Function Loss: 0.04986

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.28775
Value Function Update Magnitude: 0.34683

Collected Steps per Second: 21,678.29492
Overall Steps per Second: 10,562.57885

Timestep Collection Time: 2.30747
Timestep Consumption Time: 2.42831
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.73578

Cumulative Model Updates: 151,516
Cumulative Timesteps: 1,264,366,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,702.63269
Policy Entropy: 1.77872
Value Function Loss: 0.04748

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.29874
Value Function Update Magnitude: 0.33066

Collected Steps per Second: 20,574.69103
Overall Steps per Second: 10,229.98872

Timestep Collection Time: 2.43231
Timestep Consumption Time: 2.45958
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.89189

Cumulative Model Updates: 151,522
Cumulative Timesteps: 1,264,416,956

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1264416956...
Checkpoint 1264416956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,272.40849
Policy Entropy: 1.79288
Value Function Loss: 0.04457

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.30789
Value Function Update Magnitude: 0.31143

Collected Steps per Second: 21,150.95100
Overall Steps per Second: 10,502.43039

Timestep Collection Time: 2.36396
Timestep Consumption Time: 2.39684
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.76080

Cumulative Model Updates: 151,528
Cumulative Timesteps: 1,264,466,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,433.70410
Policy Entropy: 1.79899
Value Function Loss: 0.04771

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.30411
Value Function Update Magnitude: 0.32280

Collected Steps per Second: 21,627.47717
Overall Steps per Second: 10,534.47623

Timestep Collection Time: 2.31335
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.74936

Cumulative Model Updates: 151,534
Cumulative Timesteps: 1,264,516,988

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1264516988...
Checkpoint 1264516988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,562.18227
Policy Entropy: 1.80699
Value Function Loss: 0.05242

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.31022
Value Function Update Magnitude: 0.35578

Collected Steps per Second: 21,336.65772
Overall Steps per Second: 10,550.02123

Timestep Collection Time: 2.34357
Timestep Consumption Time: 2.39613
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.73971

Cumulative Model Updates: 151,540
Cumulative Timesteps: 1,264,566,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,609.45190
Policy Entropy: 1.79625
Value Function Loss: 0.05246

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.30551
Value Function Update Magnitude: 0.37293

Collected Steps per Second: 21,312.32187
Overall Steps per Second: 10,542.44115

Timestep Collection Time: 2.34747
Timestep Consumption Time: 2.39811
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.74558

Cumulative Model Updates: 151,546
Cumulative Timesteps: 1,264,617,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1264617022...
Checkpoint 1264617022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,517.71378
Policy Entropy: 1.79930
Value Function Loss: 0.04891

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.29212
Value Function Update Magnitude: 0.36141

Collected Steps per Second: 21,773.82896
Overall Steps per Second: 10,587.28631

Timestep Collection Time: 2.29643
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.72283

Cumulative Model Updates: 151,552
Cumulative Timesteps: 1,264,667,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,790.46144
Policy Entropy: 1.80787
Value Function Loss: 0.04447

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.27666
Value Function Update Magnitude: 0.34221

Collected Steps per Second: 21,890.31113
Overall Steps per Second: 10,450.07622

Timestep Collection Time: 2.28476
Timestep Consumption Time: 2.50124
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.78599

Cumulative Model Updates: 151,558
Cumulative Timesteps: 1,264,717,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1264717038...
Checkpoint 1264717038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,134.13002
Policy Entropy: 1.81983
Value Function Loss: 0.04736

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.29766
Value Function Update Magnitude: 0.34215

Collected Steps per Second: 21,210.40016
Overall Steps per Second: 10,360.80811

Timestep Collection Time: 2.35762
Timestep Consumption Time: 2.46884
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.82646

Cumulative Model Updates: 151,564
Cumulative Timesteps: 1,264,767,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,013.75104
Policy Entropy: 1.81269
Value Function Loss: 0.04845

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.31242
Value Function Update Magnitude: 0.34548

Collected Steps per Second: 22,059.40581
Overall Steps per Second: 10,704.49845

Timestep Collection Time: 2.26670
Timestep Consumption Time: 2.40442
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.67112

Cumulative Model Updates: 151,570
Cumulative Timesteps: 1,264,817,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1264817046...
Checkpoint 1264817046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,554.30438
Policy Entropy: 1.80112
Value Function Loss: 0.04869

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.31064
Value Function Update Magnitude: 0.34078

Collected Steps per Second: 21,750.83572
Overall Steps per Second: 10,316.80577

Timestep Collection Time: 2.29922
Timestep Consumption Time: 2.54821
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.84743

Cumulative Model Updates: 151,576
Cumulative Timesteps: 1,264,867,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,715.35247
Policy Entropy: 1.79499
Value Function Loss: 0.04891

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.30598
Value Function Update Magnitude: 0.32421

Collected Steps per Second: 22,120.32297
Overall Steps per Second: 10,465.84456

Timestep Collection Time: 2.26082
Timestep Consumption Time: 2.51758
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.77840

Cumulative Model Updates: 151,582
Cumulative Timesteps: 1,264,917,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1264917066...
Checkpoint 1264917066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,122.58911
Policy Entropy: 1.79595
Value Function Loss: 0.04899

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.30902
Value Function Update Magnitude: 0.30441

Collected Steps per Second: 20,856.42123
Overall Steps per Second: 10,165.75392

Timestep Collection Time: 2.39917
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.92221

Cumulative Model Updates: 151,588
Cumulative Timesteps: 1,264,967,104

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,186.12516
Policy Entropy: 1.78062
Value Function Loss: 0.04844

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.30494
Value Function Update Magnitude: 0.30350

Collected Steps per Second: 22,258.55542
Overall Steps per Second: 10,546.92134

Timestep Collection Time: 2.24723
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.74262

Cumulative Model Updates: 151,594
Cumulative Timesteps: 1,265,017,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1265017124...
Checkpoint 1265017124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,076.35209
Policy Entropy: 1.78624
Value Function Loss: 0.04571

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.30790
Value Function Update Magnitude: 0.31073

Collected Steps per Second: 21,847.43077
Overall Steps per Second: 10,490.65063

Timestep Collection Time: 2.28896
Timestep Consumption Time: 2.47795
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.76691

Cumulative Model Updates: 151,600
Cumulative Timesteps: 1,265,067,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,556.17786
Policy Entropy: 1.77101
Value Function Loss: 0.04198

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.30798
Value Function Update Magnitude: 0.32893

Collected Steps per Second: 22,306.95258
Overall Steps per Second: 10,536.31906

Timestep Collection Time: 2.24325
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.74929

Cumulative Model Updates: 151,606
Cumulative Timesteps: 1,265,117,172

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1265117172...
Checkpoint 1265117172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,100.96821
Policy Entropy: 1.79691
Value Function Loss: 0.04570

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.33725

Collected Steps per Second: 21,704.14037
Overall Steps per Second: 10,531.88548

Timestep Collection Time: 2.30463
Timestep Consumption Time: 2.44476
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.74939

Cumulative Model Updates: 151,612
Cumulative Timesteps: 1,265,167,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,655.76535
Policy Entropy: 1.78965
Value Function Loss: 0.04587

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.31189
Value Function Update Magnitude: 0.34604

Collected Steps per Second: 21,647.45630
Overall Steps per Second: 10,567.59481

Timestep Collection Time: 2.31150
Timestep Consumption Time: 2.42355
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.73504

Cumulative Model Updates: 151,618
Cumulative Timesteps: 1,265,217,230

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1265217230...
Checkpoint 1265217230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,173.52761
Policy Entropy: 1.79916
Value Function Loss: 0.04581

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.30332
Value Function Update Magnitude: 0.33186

Collected Steps per Second: 21,715.46721
Overall Steps per Second: 10,590.73431

Timestep Collection Time: 2.30343
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.72300

Cumulative Model Updates: 151,624
Cumulative Timesteps: 1,265,267,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,073.86410
Policy Entropy: 1.78199
Value Function Loss: 0.04811

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.30571
Value Function Update Magnitude: 0.31601

Collected Steps per Second: 21,284.09561
Overall Steps per Second: 10,393.02312

Timestep Collection Time: 2.35011
Timestep Consumption Time: 2.46273
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.81284

Cumulative Model Updates: 151,630
Cumulative Timesteps: 1,265,317,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1265317270...
Checkpoint 1265317270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,205.83536
Policy Entropy: 1.79836
Value Function Loss: 0.05384

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.31381
Value Function Update Magnitude: 0.31496

Collected Steps per Second: 21,339.59795
Overall Steps per Second: 10,363.00140

Timestep Collection Time: 2.34494
Timestep Consumption Time: 2.48378
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.82872

Cumulative Model Updates: 151,636
Cumulative Timesteps: 1,265,367,310

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,576.39026
Policy Entropy: 1.80709
Value Function Loss: 0.05243

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.31133
Value Function Update Magnitude: 0.34477

Collected Steps per Second: 22,365.43769
Overall Steps per Second: 10,676.67784

Timestep Collection Time: 2.23640
Timestep Consumption Time: 2.44839
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.68479

Cumulative Model Updates: 151,642
Cumulative Timesteps: 1,265,417,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1265417328...
Checkpoint 1265417328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,176.14038
Policy Entropy: 1.82053
Value Function Loss: 0.05047

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.30928
Value Function Update Magnitude: 0.36057

Collected Steps per Second: 21,844.77681
Overall Steps per Second: 10,460.75733

Timestep Collection Time: 2.28943
Timestep Consumption Time: 2.49149
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.78092

Cumulative Model Updates: 151,648
Cumulative Timesteps: 1,265,467,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,330.43753
Policy Entropy: 1.79530
Value Function Loss: 0.04483

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.33673

Collected Steps per Second: 22,043.38555
Overall Steps per Second: 10,626.73467

Timestep Collection Time: 2.27061
Timestep Consumption Time: 2.43939
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.71001

Cumulative Model Updates: 151,654
Cumulative Timesteps: 1,265,517,392

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1265517392...
Checkpoint 1265517392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,349.32386
Policy Entropy: 1.78421
Value Function Loss: 0.04447

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.30808
Value Function Update Magnitude: 0.31059

Collected Steps per Second: 21,822.91367
Overall Steps per Second: 10,446.95678

Timestep Collection Time: 2.29163
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.78704

Cumulative Model Updates: 151,660
Cumulative Timesteps: 1,265,567,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,029.55278
Policy Entropy: 1.77836
Value Function Loss: 0.04250

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.30450
Value Function Update Magnitude: 0.32220

Collected Steps per Second: 22,027.59820
Overall Steps per Second: 10,664.37537

Timestep Collection Time: 2.27160
Timestep Consumption Time: 2.42047
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.69207

Cumulative Model Updates: 151,666
Cumulative Timesteps: 1,265,617,440

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1265617440...
Checkpoint 1265617440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,052.83030
Policy Entropy: 1.77966
Value Function Loss: 0.04509

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.30614
Value Function Update Magnitude: 0.33335

Collected Steps per Second: 21,616.00798
Overall Steps per Second: 10,411.16416

Timestep Collection Time: 2.31329
Timestep Consumption Time: 2.48964
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.80292

Cumulative Model Updates: 151,672
Cumulative Timesteps: 1,265,667,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,653.16830
Policy Entropy: 1.79241
Value Function Loss: 0.05011

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.30891
Value Function Update Magnitude: 0.35159

Collected Steps per Second: 21,841.32616
Overall Steps per Second: 10,439.30605

Timestep Collection Time: 2.28979
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.79074

Cumulative Model Updates: 151,678
Cumulative Timesteps: 1,265,717,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1265717456...
Checkpoint 1265717456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,513.77937
Policy Entropy: 1.79621
Value Function Loss: 0.04981

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.31441
Value Function Update Magnitude: 0.37398

Collected Steps per Second: 21,710.57218
Overall Steps per Second: 10,421.55594

Timestep Collection Time: 2.30505
Timestep Consumption Time: 2.49692
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.80197

Cumulative Model Updates: 151,684
Cumulative Timesteps: 1,265,767,500

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,068.36265
Policy Entropy: 1.79517
Value Function Loss: 0.04753

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.31232
Value Function Update Magnitude: 0.34584

Collected Steps per Second: 21,655.61853
Overall Steps per Second: 10,519.67661

Timestep Collection Time: 2.31016
Timestep Consumption Time: 2.44550
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.75566

Cumulative Model Updates: 151,690
Cumulative Timesteps: 1,265,817,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1265817528...
Checkpoint 1265817528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,091.91603
Policy Entropy: 1.79304
Value Function Loss: 0.04266

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.30523
Value Function Update Magnitude: 0.32169

Collected Steps per Second: 21,024.49199
Overall Steps per Second: 10,579.47194

Timestep Collection Time: 2.37837
Timestep Consumption Time: 2.34814
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.72651

Cumulative Model Updates: 151,696
Cumulative Timesteps: 1,265,867,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,397.23081
Policy Entropy: 1.78820
Value Function Loss: 0.04078

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.29801
Value Function Update Magnitude: 0.31352

Collected Steps per Second: 21,184.44960
Overall Steps per Second: 10,566.96923

Timestep Collection Time: 2.36117
Timestep Consumption Time: 2.37245
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.73362

Cumulative Model Updates: 151,702
Cumulative Timesteps: 1,265,917,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1265917552...
Checkpoint 1265917552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,338.66317
Policy Entropy: 1.80248
Value Function Loss: 0.04407

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07576
Policy Update Magnitude: 0.30004
Value Function Update Magnitude: 0.31244

Collected Steps per Second: 21,448.34597
Overall Steps per Second: 10,582.55562

Timestep Collection Time: 2.33258
Timestep Consumption Time: 2.39501
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.72759

Cumulative Model Updates: 151,708
Cumulative Timesteps: 1,265,967,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,128.32439
Policy Entropy: 1.80368
Value Function Loss: 0.04717

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.30532
Value Function Update Magnitude: 0.32643

Collected Steps per Second: 20,999.89529
Overall Steps per Second: 10,464.04935

Timestep Collection Time: 2.38182
Timestep Consumption Time: 2.39816
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.77999

Cumulative Model Updates: 151,714
Cumulative Timesteps: 1,266,017,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1266017600...
Checkpoint 1266017600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,792.04469
Policy Entropy: 1.79056
Value Function Loss: 0.04986

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.30911
Value Function Update Magnitude: 0.34291

Collected Steps per Second: 21,355.89173
Overall Steps per Second: 10,536.64015

Timestep Collection Time: 2.34333
Timestep Consumption Time: 2.40619
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.74952

Cumulative Model Updates: 151,720
Cumulative Timesteps: 1,266,067,644

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,464.75662
Policy Entropy: 1.78693
Value Function Loss: 0.04803

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.31108
Value Function Update Magnitude: 0.35602

Collected Steps per Second: 22,022.90514
Overall Steps per Second: 10,543.35051

Timestep Collection Time: 2.27036
Timestep Consumption Time: 2.47196
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.74233

Cumulative Model Updates: 151,726
Cumulative Timesteps: 1,266,117,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1266117644...
Checkpoint 1266117644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,117.72934
Policy Entropy: 1.78218
Value Function Loss: 0.04554

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.31069
Value Function Update Magnitude: 0.35659

Collected Steps per Second: 21,859.28468
Overall Steps per Second: 10,640.87737

Timestep Collection Time: 2.28827
Timestep Consumption Time: 2.41247
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.70074

Cumulative Model Updates: 151,732
Cumulative Timesteps: 1,266,167,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,739.53816
Policy Entropy: 1.77607
Value Function Loss: 0.04283

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.30439
Value Function Update Magnitude: 0.34361

Collected Steps per Second: 21,486.87509
Overall Steps per Second: 10,465.60914

Timestep Collection Time: 2.32812
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.77985

Cumulative Model Updates: 151,738
Cumulative Timesteps: 1,266,217,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1266217688...
Checkpoint 1266217688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,085.20914
Policy Entropy: 1.76992
Value Function Loss: 0.04560

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.30878
Value Function Update Magnitude: 0.34618

Collected Steps per Second: 21,490.27826
Overall Steps per Second: 10,542.52849

Timestep Collection Time: 2.32701
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.74345

Cumulative Model Updates: 151,744
Cumulative Timesteps: 1,266,267,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,696.86844
Policy Entropy: 1.76177
Value Function Loss: 0.04628

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.31517
Value Function Update Magnitude: 0.36045

Collected Steps per Second: 21,058.71968
Overall Steps per Second: 10,249.21335

Timestep Collection Time: 2.37564
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.88116

Cumulative Model Updates: 151,750
Cumulative Timesteps: 1,266,317,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1266317724...
Checkpoint 1266317724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,676.26257
Policy Entropy: 1.77341
Value Function Loss: 0.04631

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.36521

Collected Steps per Second: 21,817.43090
Overall Steps per Second: 10,481.07255

Timestep Collection Time: 2.29248
Timestep Consumption Time: 2.47955
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.77203

Cumulative Model Updates: 151,756
Cumulative Timesteps: 1,266,367,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,793.21615
Policy Entropy: 1.78102
Value Function Loss: 0.04448

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.30128
Value Function Update Magnitude: 0.35820

Collected Steps per Second: 21,668.89772
Overall Steps per Second: 10,425.81922

Timestep Collection Time: 2.30773
Timestep Consumption Time: 2.48863
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.79636

Cumulative Model Updates: 151,762
Cumulative Timesteps: 1,266,417,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1266417746...
Checkpoint 1266417746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,883.66018
Policy Entropy: 1.78411
Value Function Loss: 0.04712

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.29850
Value Function Update Magnitude: 0.33334

Collected Steps per Second: 21,546.91775
Overall Steps per Second: 10,361.67761

Timestep Collection Time: 2.32135
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.82721

Cumulative Model Updates: 151,768
Cumulative Timesteps: 1,266,467,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,692.10730
Policy Entropy: 1.80580
Value Function Loss: 0.05031

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.29962
Value Function Update Magnitude: 0.34137

Collected Steps per Second: 21,960.00317
Overall Steps per Second: 10,384.05257

Timestep Collection Time: 2.27760
Timestep Consumption Time: 2.53902
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.81662

Cumulative Model Updates: 151,774
Cumulative Timesteps: 1,266,517,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1266517780...
Checkpoint 1266517780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,572.00517
Policy Entropy: 1.80098
Value Function Loss: 0.04817

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.30588
Value Function Update Magnitude: 0.34665

Collected Steps per Second: 22,229.45485
Overall Steps per Second: 10,537.71839

Timestep Collection Time: 2.24999
Timestep Consumption Time: 2.49639
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.74638

Cumulative Model Updates: 151,780
Cumulative Timesteps: 1,266,567,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,129.58511
Policy Entropy: 1.79441
Value Function Loss: 0.04590

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.30398
Value Function Update Magnitude: 0.33780

Collected Steps per Second: 21,960.33999
Overall Steps per Second: 10,470.49798

Timestep Collection Time: 2.27711
Timestep Consumption Time: 2.49879
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.77590

Cumulative Model Updates: 151,786
Cumulative Timesteps: 1,266,617,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1266617802...
Checkpoint 1266617802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,763.72514
Policy Entropy: 1.77750
Value Function Loss: 0.04395

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.28023
Value Function Update Magnitude: 0.32608

Collected Steps per Second: 22,087.32849
Overall Steps per Second: 10,638.94342

Timestep Collection Time: 2.26465
Timestep Consumption Time: 2.43695
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.70159

Cumulative Model Updates: 151,792
Cumulative Timesteps: 1,266,667,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,599.45220
Policy Entropy: 1.77665
Value Function Loss: 0.04297

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.27116
Value Function Update Magnitude: 0.30775

Collected Steps per Second: 22,174.29875
Overall Steps per Second: 10,477.87305

Timestep Collection Time: 2.25549
Timestep Consumption Time: 2.51780
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.77330

Cumulative Model Updates: 151,798
Cumulative Timesteps: 1,266,717,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1266717836...
Checkpoint 1266717836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,128.46790
Policy Entropy: 1.77738
Value Function Loss: 0.04194

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.28086
Value Function Update Magnitude: 0.29377

Collected Steps per Second: 21,972.16019
Overall Steps per Second: 10,606.91426

Timestep Collection Time: 2.27624
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.71523

Cumulative Model Updates: 151,804
Cumulative Timesteps: 1,266,767,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,731.91106
Policy Entropy: 1.77297
Value Function Loss: 0.04344

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.29901
Value Function Update Magnitude: 0.31170

Collected Steps per Second: 22,044.75818
Overall Steps per Second: 10,472.31817

Timestep Collection Time: 2.26929
Timestep Consumption Time: 2.50768
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.77697

Cumulative Model Updates: 151,810
Cumulative Timesteps: 1,266,817,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1266817876...
Checkpoint 1266817876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,723.61599
Policy Entropy: 1.76148
Value Function Loss: 0.04429

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.31213
Value Function Update Magnitude: 0.34004

Collected Steps per Second: 21,278.44448
Overall Steps per Second: 10,322.46569

Timestep Collection Time: 2.35008
Timestep Consumption Time: 2.49431
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.84439

Cumulative Model Updates: 151,816
Cumulative Timesteps: 1,266,867,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,536.81788
Policy Entropy: 1.76706
Value Function Loss: 0.04668

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.31399
Value Function Update Magnitude: 0.35971

Collected Steps per Second: 21,590.88458
Overall Steps per Second: 10,393.39274

Timestep Collection Time: 2.31783
Timestep Consumption Time: 2.49715
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.81498

Cumulative Model Updates: 151,822
Cumulative Timesteps: 1,266,917,926

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1266917926...
Checkpoint 1266917926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,215.78285
Policy Entropy: 1.77307
Value Function Loss: 0.04722

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.31026
Value Function Update Magnitude: 0.35090

Collected Steps per Second: 21,422.72808
Overall Steps per Second: 10,497.52857

Timestep Collection Time: 2.33416
Timestep Consumption Time: 2.42925
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.76341

Cumulative Model Updates: 151,828
Cumulative Timesteps: 1,266,967,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,466.65912
Policy Entropy: 1.79011
Value Function Loss: 0.04814

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.34089

Collected Steps per Second: 21,658.67920
Overall Steps per Second: 10,543.07967

Timestep Collection Time: 2.30974
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.74491

Cumulative Model Updates: 151,834
Cumulative Timesteps: 1,267,017,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1267017956...
Checkpoint 1267017956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,484.36846
Policy Entropy: 1.79838
Value Function Loss: 0.04970

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.31458
Value Function Update Magnitude: 0.33220

Collected Steps per Second: 21,463.40576
Overall Steps per Second: 10,380.21519

Timestep Collection Time: 2.32964
Timestep Consumption Time: 2.48741
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.81705

Cumulative Model Updates: 151,840
Cumulative Timesteps: 1,267,067,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,073.30060
Policy Entropy: 1.81867
Value Function Loss: 0.04977

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.31000
Value Function Update Magnitude: 0.31758

Collected Steps per Second: 21,477.66157
Overall Steps per Second: 10,626.59485

Timestep Collection Time: 2.32949
Timestep Consumption Time: 2.37870
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.70819

Cumulative Model Updates: 151,846
Cumulative Timesteps: 1,267,117,990

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1267117990...
Checkpoint 1267117990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,223.74958
Policy Entropy: 1.80735
Value Function Loss: 0.04663

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.30271
Value Function Update Magnitude: 0.31940

Collected Steps per Second: 21,323.11528
Overall Steps per Second: 10,596.59642

Timestep Collection Time: 2.34722
Timestep Consumption Time: 2.37600
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.72321

Cumulative Model Updates: 151,852
Cumulative Timesteps: 1,267,168,040

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,189.91443
Policy Entropy: 1.80220
Value Function Loss: 0.04830

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07323
Policy Update Magnitude: 0.30371
Value Function Update Magnitude: 0.32858

Collected Steps per Second: 21,439.49367
Overall Steps per Second: 10,552.15295

Timestep Collection Time: 2.33233
Timestep Consumption Time: 2.40642
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.73875

Cumulative Model Updates: 151,858
Cumulative Timesteps: 1,267,218,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1267218044...
Checkpoint 1267218044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,818.96528
Policy Entropy: 1.79084
Value Function Loss: 0.04352

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07312
Policy Update Magnitude: 0.30125
Value Function Update Magnitude: 0.32701

Collected Steps per Second: 21,292.56245
Overall Steps per Second: 10,628.33934

Timestep Collection Time: 2.34824
Timestep Consumption Time: 2.35617
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.70440

Cumulative Model Updates: 151,864
Cumulative Timesteps: 1,267,268,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,115.11339
Policy Entropy: 1.79574
Value Function Loss: 0.04272

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07092
Policy Update Magnitude: 0.30191
Value Function Update Magnitude: 0.31416

Collected Steps per Second: 21,464.93733
Overall Steps per Second: 10,444.37341

Timestep Collection Time: 2.32938
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.78727

Cumulative Model Updates: 151,870
Cumulative Timesteps: 1,267,318,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1267318044...
Checkpoint 1267318044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,356.08108
Policy Entropy: 1.79421
Value Function Loss: 0.04238

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07145
Policy Update Magnitude: 0.30122
Value Function Update Magnitude: 0.30052

Collected Steps per Second: 21,694.25412
Overall Steps per Second: 10,593.08172

Timestep Collection Time: 2.30605
Timestep Consumption Time: 2.41666
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.72271

Cumulative Model Updates: 151,876
Cumulative Timesteps: 1,267,368,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,315.56127
Policy Entropy: 1.79034
Value Function Loss: 0.04644

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.30405
Value Function Update Magnitude: 0.30229

Collected Steps per Second: 21,853.64091
Overall Steps per Second: 10,543.37485

Timestep Collection Time: 2.28859
Timestep Consumption Time: 2.45505
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.74364

Cumulative Model Updates: 151,882
Cumulative Timesteps: 1,267,418,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1267418086...
Checkpoint 1267418086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,458.45186
Policy Entropy: 1.80014
Value Function Loss: 0.04772

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.30372
Value Function Update Magnitude: 0.31315

Collected Steps per Second: 21,597.09340
Overall Steps per Second: 10,590.74843

Timestep Collection Time: 2.31605
Timestep Consumption Time: 2.40694
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.72299

Cumulative Model Updates: 151,888
Cumulative Timesteps: 1,267,468,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,575.19434
Policy Entropy: 1.80519
Value Function Loss: 0.05437

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.29144

Collected Steps per Second: 21,675.48510
Overall Steps per Second: 10,466.27517

Timestep Collection Time: 2.30814
Timestep Consumption Time: 2.47198
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.78012

Cumulative Model Updates: 151,894
Cumulative Timesteps: 1,267,518,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1267518136...
Checkpoint 1267518136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,719.91335
Policy Entropy: 1.79415
Value Function Loss: 0.05228

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.31551
Value Function Update Magnitude: 0.31008

Collected Steps per Second: 21,711.03178
Overall Steps per Second: 10,378.55323

Timestep Collection Time: 2.30353
Timestep Consumption Time: 2.51525
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.81878

Cumulative Model Updates: 151,900
Cumulative Timesteps: 1,267,568,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,647.64769
Policy Entropy: 1.79667
Value Function Loss: 0.05400

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.31424
Value Function Update Magnitude: 0.34730

Collected Steps per Second: 22,364.73894
Overall Steps per Second: 10,665.43350

Timestep Collection Time: 2.23656
Timestep Consumption Time: 2.45336
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.68992

Cumulative Model Updates: 151,906
Cumulative Timesteps: 1,267,618,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1267618168...
Checkpoint 1267618168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,104.96322
Policy Entropy: 1.77915
Value Function Loss: 0.04879

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.31650
Value Function Update Magnitude: 0.38196

Collected Steps per Second: 21,644.54145
Overall Steps per Second: 10,613.53866

Timestep Collection Time: 2.31236
Timestep Consumption Time: 2.40331
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.71568

Cumulative Model Updates: 151,912
Cumulative Timesteps: 1,267,668,218

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,357.90954
Policy Entropy: 1.77168
Value Function Loss: 0.04846

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.31175
Value Function Update Magnitude: 0.37687

Collected Steps per Second: 22,072.69615
Overall Steps per Second: 10,512.83804

Timestep Collection Time: 2.26642
Timestep Consumption Time: 2.49214
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.75856

Cumulative Model Updates: 151,918
Cumulative Timesteps: 1,267,718,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1267718244...
Checkpoint 1267718244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,691.12900
Policy Entropy: 1.77521
Value Function Loss: 0.04627

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.30817
Value Function Update Magnitude: 0.34074

Collected Steps per Second: 22,132.53989
Overall Steps per Second: 10,658.67365

Timestep Collection Time: 2.26047
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.69383

Cumulative Model Updates: 151,924
Cumulative Timesteps: 1,267,768,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,436.96947
Policy Entropy: 1.78737
Value Function Loss: 0.04637

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.31118
Value Function Update Magnitude: 0.32213

Collected Steps per Second: 22,012.32992
Overall Steps per Second: 10,452.38126

Timestep Collection Time: 2.27218
Timestep Consumption Time: 2.51295
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.78513

Cumulative Model Updates: 151,930
Cumulative Timesteps: 1,267,818,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1267818290...
Checkpoint 1267818290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,246.24863
Policy Entropy: 1.79099
Value Function Loss: 0.04695

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07879
Policy Update Magnitude: 0.31171
Value Function Update Magnitude: 0.34150

Collected Steps per Second: 21,960.92616
Overall Steps per Second: 10,609.91981

Timestep Collection Time: 2.27805
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.71521

Cumulative Model Updates: 151,936
Cumulative Timesteps: 1,267,868,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,830.46093
Policy Entropy: 1.78278
Value Function Loss: 0.04797

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.31083
Value Function Update Magnitude: 0.33746

Collected Steps per Second: 21,267.89874
Overall Steps per Second: 10,432.13180

Timestep Collection Time: 2.35200
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.79499

Cumulative Model Updates: 151,942
Cumulative Timesteps: 1,267,918,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1267918340...
Checkpoint 1267918340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,191.28556
Policy Entropy: 1.77817
Value Function Loss: 0.04617

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.30403
Value Function Update Magnitude: 0.32926

Collected Steps per Second: 21,527.06070
Overall Steps per Second: 10,355.86283

Timestep Collection Time: 2.32396
Timestep Consumption Time: 2.50693
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.83089

Cumulative Model Updates: 151,948
Cumulative Timesteps: 1,267,968,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,244.26882
Policy Entropy: 1.79584
Value Function Loss: 0.04642

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.29889
Value Function Update Magnitude: 0.32693

Collected Steps per Second: 21,448.21424
Overall Steps per Second: 10,356.50285

Timestep Collection Time: 2.33157
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.82866

Cumulative Model Updates: 151,954
Cumulative Timesteps: 1,268,018,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1268018376...
Checkpoint 1268018376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,086.86077
Policy Entropy: 1.78870
Value Function Loss: 0.04687

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.29803
Value Function Update Magnitude: 0.32767

Collected Steps per Second: 21,558.68881
Overall Steps per Second: 10,362.21528

Timestep Collection Time: 2.32083
Timestep Consumption Time: 2.50768
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.82850

Cumulative Model Updates: 151,960
Cumulative Timesteps: 1,268,068,410

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,338.39318
Policy Entropy: 1.78383
Value Function Loss: 0.04907

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.30419
Value Function Update Magnitude: 0.32270

Collected Steps per Second: 21,959.06568
Overall Steps per Second: 10,382.97438

Timestep Collection Time: 2.27742
Timestep Consumption Time: 2.53912
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.81654

Cumulative Model Updates: 151,966
Cumulative Timesteps: 1,268,118,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1268118420...
Checkpoint 1268118420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,534.29845
Policy Entropy: 1.77221
Value Function Loss: 0.04807

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.31178
Value Function Update Magnitude: 0.33325

Collected Steps per Second: 21,715.44457
Overall Steps per Second: 10,477.92254

Timestep Collection Time: 2.30297
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.77289

Cumulative Model Updates: 151,972
Cumulative Timesteps: 1,268,168,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,923.40449
Policy Entropy: 1.77685
Value Function Loss: 0.04608

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.31506
Value Function Update Magnitude: 0.34230

Collected Steps per Second: 21,764.33524
Overall Steps per Second: 10,604.60409

Timestep Collection Time: 2.29761
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.71550

Cumulative Model Updates: 151,978
Cumulative Timesteps: 1,268,218,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1268218436...
Checkpoint 1268218436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,868.58780
Policy Entropy: 1.76723
Value Function Loss: 0.04690

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.31431
Value Function Update Magnitude: 0.34782

Collected Steps per Second: 21,517.90945
Overall Steps per Second: 10,502.73074

Timestep Collection Time: 2.32485
Timestep Consumption Time: 2.43829
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.76314

Cumulative Model Updates: 151,984
Cumulative Timesteps: 1,268,268,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,742.29085
Policy Entropy: 1.76760
Value Function Loss: 0.04514

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.30663
Value Function Update Magnitude: 0.34409

Collected Steps per Second: 22,054.31522
Overall Steps per Second: 10,481.58241

Timestep Collection Time: 2.26722
Timestep Consumption Time: 2.50324
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.77046

Cumulative Model Updates: 151,990
Cumulative Timesteps: 1,268,318,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1268318464...
Checkpoint 1268318464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,233.96665
Policy Entropy: 1.76366
Value Function Loss: 0.04353

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07671
Policy Update Magnitude: 0.30279
Value Function Update Magnitude: 0.33188

Collected Steps per Second: 21,181.31793
Overall Steps per Second: 10,234.32052

Timestep Collection Time: 2.36152
Timestep Consumption Time: 2.52596
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.88748

Cumulative Model Updates: 151,996
Cumulative Timesteps: 1,268,368,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,458.11462
Policy Entropy: 1.76365
Value Function Loss: 0.04190

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07690
Policy Update Magnitude: 0.30415
Value Function Update Magnitude: 0.32898

Collected Steps per Second: 21,531.17112
Overall Steps per Second: 10,504.10682

Timestep Collection Time: 2.32305
Timestep Consumption Time: 2.43871
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.76176

Cumulative Model Updates: 152,002
Cumulative Timesteps: 1,268,418,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1268418502...
Checkpoint 1268418502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,218.17761
Policy Entropy: 1.76697
Value Function Loss: 0.04661

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.31053
Value Function Update Magnitude: 0.32890

Collected Steps per Second: 21,395.51573
Overall Steps per Second: 10,510.99651

Timestep Collection Time: 2.33815
Timestep Consumption Time: 2.42124
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.75940

Cumulative Model Updates: 152,008
Cumulative Timesteps: 1,268,468,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,915.05941
Policy Entropy: 1.77177
Value Function Loss: 0.05054

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.31494
Value Function Update Magnitude: 0.33501

Collected Steps per Second: 21,611.03592
Overall Steps per Second: 10,478.77847

Timestep Collection Time: 2.31419
Timestep Consumption Time: 2.45851
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.77269

Cumulative Model Updates: 152,014
Cumulative Timesteps: 1,268,518,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1268518540...
Checkpoint 1268518540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,150.36774
Policy Entropy: 1.78651
Value Function Loss: 0.04938

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.29803
Value Function Update Magnitude: 0.34313

Collected Steps per Second: 21,921.22275
Overall Steps per Second: 10,382.86681

Timestep Collection Time: 2.28099
Timestep Consumption Time: 2.53483
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.81582

Cumulative Model Updates: 152,020
Cumulative Timesteps: 1,268,568,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,181.70348
Policy Entropy: 1.78328
Value Function Loss: 0.04673

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.28255
Value Function Update Magnitude: 0.33275

Collected Steps per Second: 22,303.98755
Overall Steps per Second: 10,715.11560

Timestep Collection Time: 2.24238
Timestep Consumption Time: 2.42523
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.66761

Cumulative Model Updates: 152,026
Cumulative Timesteps: 1,268,618,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1268618556...
Checkpoint 1268618556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,589.11872
Policy Entropy: 1.79503
Value Function Loss: 0.04481

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.29340
Value Function Update Magnitude: 0.32052

Collected Steps per Second: 21,588.24456
Overall Steps per Second: 10,390.68238

Timestep Collection Time: 2.31608
Timestep Consumption Time: 2.49593
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.81200

Cumulative Model Updates: 152,032
Cumulative Timesteps: 1,268,668,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,301.64971
Policy Entropy: 1.80598
Value Function Loss: 0.04443

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08840
Policy Update Magnitude: 0.29692
Value Function Update Magnitude: 0.32017

Collected Steps per Second: 22,317.74308
Overall Steps per Second: 10,695.74534

Timestep Collection Time: 2.24153
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.67719

Cumulative Model Updates: 152,038
Cumulative Timesteps: 1,268,718,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1268718582...
Checkpoint 1268718582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,423.13538
Policy Entropy: 1.81099
Value Function Loss: 0.04256

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.30069
Value Function Update Magnitude: 0.31735

Collected Steps per Second: 21,972.37475
Overall Steps per Second: 10,638.88320

Timestep Collection Time: 2.27750
Timestep Consumption Time: 2.42619
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.70369

Cumulative Model Updates: 152,044
Cumulative Timesteps: 1,268,768,624

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,298.74757
Policy Entropy: 1.79164
Value Function Loss: 0.04419

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.33055

Collected Steps per Second: 21,611.31638
Overall Steps per Second: 10,530.60585

Timestep Collection Time: 2.31444
Timestep Consumption Time: 2.43534
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.74977

Cumulative Model Updates: 152,050
Cumulative Timesteps: 1,268,818,642

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1268818642...
Checkpoint 1268818642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,514.66367
Policy Entropy: 1.77615
Value Function Loss: 0.04309

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.30725
Value Function Update Magnitude: 0.34692

Collected Steps per Second: 21,106.24445
Overall Steps per Second: 10,584.96778

Timestep Collection Time: 2.37048
Timestep Consumption Time: 2.35622
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72670

Cumulative Model Updates: 152,056
Cumulative Timesteps: 1,268,868,674

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,639.74131
Policy Entropy: 1.76877
Value Function Loss: 0.04217

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.30247
Value Function Update Magnitude: 0.32802

Collected Steps per Second: 21,063.23291
Overall Steps per Second: 10,574.43677

Timestep Collection Time: 2.37428
Timestep Consumption Time: 2.35505
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.72933

Cumulative Model Updates: 152,062
Cumulative Timesteps: 1,268,918,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1268918684...
Checkpoint 1268918684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,244.75605
Policy Entropy: 1.77309
Value Function Loss: 0.04159

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.29884
Value Function Update Magnitude: 0.31498

Collected Steps per Second: 20,992.10062
Overall Steps per Second: 10,571.86329

Timestep Collection Time: 2.38309
Timestep Consumption Time: 2.34891
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.73199

Cumulative Model Updates: 152,068
Cumulative Timesteps: 1,268,968,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,906.62801
Policy Entropy: 1.76783
Value Function Loss: 0.04145

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.29739
Value Function Update Magnitude: 0.31695

Collected Steps per Second: 21,365.85744
Overall Steps per Second: 10,553.60158

Timestep Collection Time: 2.34102
Timestep Consumption Time: 2.39840
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.73942

Cumulative Model Updates: 152,074
Cumulative Timesteps: 1,269,018,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1269018728...
Checkpoint 1269018728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,443.28043
Policy Entropy: 1.75726
Value Function Loss: 0.04298

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.30148
Value Function Update Magnitude: 0.31988

Collected Steps per Second: 21,699.54608
Overall Steps per Second: 10,524.88430

Timestep Collection Time: 2.30438
Timestep Consumption Time: 2.44665
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.75103

Cumulative Model Updates: 152,080
Cumulative Timesteps: 1,269,068,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,702.76993
Policy Entropy: 1.75096
Value Function Loss: 0.04279

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.29932
Value Function Update Magnitude: 0.31195

Collected Steps per Second: 22,088.74717
Overall Steps per Second: 10,438.96512

Timestep Collection Time: 2.26378
Timestep Consumption Time: 2.52635
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.79013

Cumulative Model Updates: 152,086
Cumulative Timesteps: 1,269,118,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1269118736...
Checkpoint 1269118736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,610.12615
Policy Entropy: 1.75920
Value Function Loss: 0.04429

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07918
Policy Update Magnitude: 0.29900
Value Function Update Magnitude: 0.29726

Collected Steps per Second: 21,722.63453
Overall Steps per Second: 10,583.49979

Timestep Collection Time: 2.30294
Timestep Consumption Time: 2.42385
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.72679

Cumulative Model Updates: 152,092
Cumulative Timesteps: 1,269,168,762

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,750.05771
Policy Entropy: 1.74877
Value Function Loss: 0.04349

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.30032
Value Function Update Magnitude: 0.30788

Collected Steps per Second: 22,060.45613
Overall Steps per Second: 10,515.67211

Timestep Collection Time: 2.26677
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.75538

Cumulative Model Updates: 152,098
Cumulative Timesteps: 1,269,218,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1269218768...
Checkpoint 1269218768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,791.34070
Policy Entropy: 1.76857
Value Function Loss: 0.04312

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.30062
Value Function Update Magnitude: 0.31727

Collected Steps per Second: 21,539.41752
Overall Steps per Second: 10,371.98232

Timestep Collection Time: 2.32318
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.82454

Cumulative Model Updates: 152,104
Cumulative Timesteps: 1,269,268,808

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,271.90199
Policy Entropy: 1.77609
Value Function Loss: 0.04238

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.29963
Value Function Update Magnitude: 0.31820

Collected Steps per Second: 22,330.47958
Overall Steps per Second: 10,684.15030

Timestep Collection Time: 2.23954
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.68077

Cumulative Model Updates: 152,110
Cumulative Timesteps: 1,269,318,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1269318818...
Checkpoint 1269318818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,202.18747
Policy Entropy: 1.79023
Value Function Loss: 0.03904

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.29596
Value Function Update Magnitude: 0.31856

Collected Steps per Second: 21,703.87295
Overall Steps per Second: 10,406.66818

Timestep Collection Time: 2.30392
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.80500

Cumulative Model Updates: 152,116
Cumulative Timesteps: 1,269,368,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,703.26042
Policy Entropy: 1.78349
Value Function Loss: 0.03861

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.29380
Value Function Update Magnitude: 0.29399

Collected Steps per Second: 22,167.68451
Overall Steps per Second: 10,666.06205

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.68927

Cumulative Model Updates: 152,122
Cumulative Timesteps: 1,269,418,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1269418838...
Checkpoint 1269418838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,126.38945
Policy Entropy: 1.79720
Value Function Loss: 0.04123

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.29665
Value Function Update Magnitude: 0.26773

Collected Steps per Second: 21,124.46955
Overall Steps per Second: 10,267.70307

Timestep Collection Time: 2.36749
Timestep Consumption Time: 2.50332
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.87081

Cumulative Model Updates: 152,128
Cumulative Timesteps: 1,269,468,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,613.73708
Policy Entropy: 1.81068
Value Function Loss: 0.04524

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.30000
Value Function Update Magnitude: 0.26318

Collected Steps per Second: 21,798.47249
Overall Steps per Second: 10,471.48921

Timestep Collection Time: 2.29429
Timestep Consumption Time: 2.48173
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.77602

Cumulative Model Updates: 152,134
Cumulative Timesteps: 1,269,518,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1269518862...
Checkpoint 1269518862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,118.74308
Policy Entropy: 1.81062
Value Function Loss: 0.04549

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.30197
Value Function Update Magnitude: 0.29625

Collected Steps per Second: 21,318.52008
Overall Steps per Second: 10,359.38028

Timestep Collection Time: 2.34622
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.82828

Cumulative Model Updates: 152,140
Cumulative Timesteps: 1,269,568,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,246.75837
Policy Entropy: 1.80991
Value Function Loss: 0.04740

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.30383
Value Function Update Magnitude: 0.31770

Collected Steps per Second: 21,778.54078
Overall Steps per Second: 10,500.54068

Timestep Collection Time: 2.29685
Timestep Consumption Time: 2.46691
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.76375

Cumulative Model Updates: 152,146
Cumulative Timesteps: 1,269,618,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1269618902...
Checkpoint 1269618902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,706.39517
Policy Entropy: 1.81275
Value Function Loss: 0.04600

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.30142
Value Function Update Magnitude: 0.32980

Collected Steps per Second: 21,022.47637
Overall Steps per Second: 10,420.94458

Timestep Collection Time: 2.37955
Timestep Consumption Time: 2.42078
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.80033

Cumulative Model Updates: 152,152
Cumulative Timesteps: 1,269,668,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,156.86580
Policy Entropy: 1.80375
Value Function Loss: 0.04480

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.29897
Value Function Update Magnitude: 0.33258

Collected Steps per Second: 21,475.00967
Overall Steps per Second: 10,454.58512

Timestep Collection Time: 2.32959
Timestep Consumption Time: 2.45568
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.78527

Cumulative Model Updates: 152,158
Cumulative Timesteps: 1,269,718,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1269718954...
Checkpoint 1269718954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,862.57813
Policy Entropy: 1.80713
Value Function Loss: 0.04009

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07245
Policy Update Magnitude: 0.29417
Value Function Update Magnitude: 0.31118

Collected Steps per Second: 21,253.42832
Overall Steps per Second: 10,572.34743

Timestep Collection Time: 2.35520
Timestep Consumption Time: 2.37942
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.73462

Cumulative Model Updates: 152,164
Cumulative Timesteps: 1,269,769,010

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,296.97952
Policy Entropy: 1.79925
Value Function Loss: 0.03696

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.28637
Value Function Update Magnitude: 0.30606

Collected Steps per Second: 21,958.25192
Overall Steps per Second: 10,532.77453

Timestep Collection Time: 2.27750
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.74804

Cumulative Model Updates: 152,170
Cumulative Timesteps: 1,269,819,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1269819020...
Checkpoint 1269819020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,995.62877
Policy Entropy: 1.79224
Value Function Loss: 0.03661

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07760
Policy Update Magnitude: 0.27778
Value Function Update Magnitude: 0.29033

Collected Steps per Second: 21,839.79102
Overall Steps per Second: 10,652.74181

Timestep Collection Time: 2.28977
Timestep Consumption Time: 2.40461
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.69438

Cumulative Model Updates: 152,176
Cumulative Timesteps: 1,269,869,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,591.96695
Policy Entropy: 1.78836
Value Function Loss: 0.04132

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.27964
Value Function Update Magnitude: 0.28996

Collected Steps per Second: 22,160.91961
Overall Steps per Second: 10,574.86633

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.47286
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.72989

Cumulative Model Updates: 152,182
Cumulative Timesteps: 1,269,919,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1269919046...
Checkpoint 1269919046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,001.70140
Policy Entropy: 1.78078
Value Function Loss: 0.04488

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.28401
Value Function Update Magnitude: 0.30382

Collected Steps per Second: 22,086.54333
Overall Steps per Second: 10,479.89041

Timestep Collection Time: 2.26609
Timestep Consumption Time: 2.50973
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.77581

Cumulative Model Updates: 152,188
Cumulative Timesteps: 1,269,969,096

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,449.81375
Policy Entropy: 1.81248
Value Function Loss: 0.04779

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.29495
Value Function Update Magnitude: 0.31624

Collected Steps per Second: 22,040.89797
Overall Steps per Second: 10,451.46641

Timestep Collection Time: 2.26960
Timestep Consumption Time: 2.51671
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.78631

Cumulative Model Updates: 152,194
Cumulative Timesteps: 1,270,019,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1270019120...
Checkpoint 1270019120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,128.98684
Policy Entropy: 1.80181
Value Function Loss: 0.04715

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.30415
Value Function Update Magnitude: 0.31184

Collected Steps per Second: 20,216.48595
Overall Steps per Second: 10,178.88383

Timestep Collection Time: 2.47481
Timestep Consumption Time: 2.44046
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.91527

Cumulative Model Updates: 152,200
Cumulative Timesteps: 1,270,069,152

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,866.35914
Policy Entropy: 1.82098
Value Function Loss: 0.04948

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.30851
Value Function Update Magnitude: 0.30241

Collected Steps per Second: 21,437.70500
Overall Steps per Second: 10,478.53682

Timestep Collection Time: 2.33253
Timestep Consumption Time: 2.43951
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.77204

Cumulative Model Updates: 152,206
Cumulative Timesteps: 1,270,119,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1270119156...
Checkpoint 1270119156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,842.82997
Policy Entropy: 1.77997
Value Function Loss: 0.04595

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.31036
Value Function Update Magnitude: 0.31232

Collected Steps per Second: 21,645.70464
Overall Steps per Second: 10,557.73681

Timestep Collection Time: 2.31030
Timestep Consumption Time: 2.42632
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.73662

Cumulative Model Updates: 152,212
Cumulative Timesteps: 1,270,169,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,591.10701
Policy Entropy: 1.79602
Value Function Loss: 0.04688

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.30700
Value Function Update Magnitude: 0.33004

Collected Steps per Second: 21,587.45603
Overall Steps per Second: 10,509.95566

Timestep Collection Time: 2.31616
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.75739

Cumulative Model Updates: 152,218
Cumulative Timesteps: 1,270,219,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1270219164...
Checkpoint 1270219164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,635.62466
Policy Entropy: 1.77448
Value Function Loss: 0.04526

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.30907
Value Function Update Magnitude: 0.35777

Collected Steps per Second: 21,717.00694
Overall Steps per Second: 10,400.32194

Timestep Collection Time: 2.30308
Timestep Consumption Time: 2.50600
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.80908

Cumulative Model Updates: 152,224
Cumulative Timesteps: 1,270,269,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,121.55655
Policy Entropy: 1.80164
Value Function Loss: 0.04500

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.30575
Value Function Update Magnitude: 0.37487

Collected Steps per Second: 22,277.76403
Overall Steps per Second: 10,659.22408

Timestep Collection Time: 2.24628
Timestep Consumption Time: 2.44844
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.69471

Cumulative Model Updates: 152,230
Cumulative Timesteps: 1,270,319,222

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1270319222...
Checkpoint 1270319222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,272.35379
Policy Entropy: 1.78133
Value Function Loss: 0.04226

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.30079
Value Function Update Magnitude: 0.36009

Collected Steps per Second: 21,857.02873
Overall Steps per Second: 10,431.98119

Timestep Collection Time: 2.28897
Timestep Consumption Time: 2.50686
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.79583

Cumulative Model Updates: 152,236
Cumulative Timesteps: 1,270,369,252

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,978.82602
Policy Entropy: 1.79130
Value Function Loss: 0.04075

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.29820
Value Function Update Magnitude: 0.34815

Collected Steps per Second: 21,819.25260
Overall Steps per Second: 10,463.76054

Timestep Collection Time: 2.29229
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.77993

Cumulative Model Updates: 152,242
Cumulative Timesteps: 1,270,419,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1270419268...
Checkpoint 1270419268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,067.42737
Policy Entropy: 1.77473
Value Function Loss: 0.04038

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.29926
Value Function Update Magnitude: 0.35329

Collected Steps per Second: 22,124.97626
Overall Steps per Second: 10,499.72136

Timestep Collection Time: 2.26052
Timestep Consumption Time: 2.50284
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.76336

Cumulative Model Updates: 152,248
Cumulative Timesteps: 1,270,469,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,084.29158
Policy Entropy: 1.76852
Value Function Loss: 0.04196

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.30562
Value Function Update Magnitude: 0.34480

Collected Steps per Second: 21,850.77965
Overall Steps per Second: 10,389.35976

Timestep Collection Time: 2.28834
Timestep Consumption Time: 2.52447
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.81281

Cumulative Model Updates: 152,254
Cumulative Timesteps: 1,270,519,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1270519284...
Checkpoint 1270519284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,395.35508
Policy Entropy: 1.76725
Value Function Loss: 0.04312

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.30675
Value Function Update Magnitude: 0.34432

Collected Steps per Second: 22,041.08621
Overall Steps per Second: 10,622.18343

Timestep Collection Time: 2.26885
Timestep Consumption Time: 2.43903
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.70788

Cumulative Model Updates: 152,260
Cumulative Timesteps: 1,270,569,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,432.70587
Policy Entropy: 1.77728
Value Function Loss: 0.04446

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.29316
Value Function Update Magnitude: 0.34066

Collected Steps per Second: 21,951.30394
Overall Steps per Second: 10,500.41264

Timestep Collection Time: 2.27932
Timestep Consumption Time: 2.48564
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.76496

Cumulative Model Updates: 152,266
Cumulative Timesteps: 1,270,619,326

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1270619326...
Checkpoint 1270619326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,190.15917
Policy Entropy: 1.77589
Value Function Loss: 0.04439

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.28999
Value Function Update Magnitude: 0.31869

Collected Steps per Second: 21,359.08027
Overall Steps per Second: 10,368.25914

Timestep Collection Time: 2.34177
Timestep Consumption Time: 2.48238
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.82415

Cumulative Model Updates: 152,272
Cumulative Timesteps: 1,270,669,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,768.28907
Policy Entropy: 1.76238
Value Function Loss: 0.04240

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07368
Policy Update Magnitude: 0.29986
Value Function Update Magnitude: 0.31758

Collected Steps per Second: 21,692.78882
Overall Steps per Second: 10,416.96045

Timestep Collection Time: 2.30537
Timestep Consumption Time: 2.49545
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.80082

Cumulative Model Updates: 152,278
Cumulative Timesteps: 1,270,719,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1270719354...
Checkpoint 1270719354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,823.52834
Policy Entropy: 1.74866
Value Function Loss: 0.04192

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07693
Policy Update Magnitude: 0.30202
Value Function Update Magnitude: 0.31020

Collected Steps per Second: 21,791.28207
Overall Steps per Second: 10,472.85705

Timestep Collection Time: 2.29569
Timestep Consumption Time: 2.48104
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.77673

Cumulative Model Updates: 152,284
Cumulative Timesteps: 1,270,769,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,138.16146
Policy Entropy: 1.74647
Value Function Loss: 0.03957

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.30103
Value Function Update Magnitude: 0.31109

Collected Steps per Second: 21,520.52639
Overall Steps per Second: 10,551.14609

Timestep Collection Time: 2.32513
Timestep Consumption Time: 2.41729
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.74242

Cumulative Model Updates: 152,290
Cumulative Timesteps: 1,270,819,418

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1270819418...
Checkpoint 1270819418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,969.41268
Policy Entropy: 1.76172
Value Function Loss: 0.03923

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.29364
Value Function Update Magnitude: 0.31451

Collected Steps per Second: 21,056.03765
Overall Steps per Second: 10,551.34356

Timestep Collection Time: 2.37595
Timestep Consumption Time: 2.36544
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.74139

Cumulative Model Updates: 152,296
Cumulative Timesteps: 1,270,869,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,228.57902
Policy Entropy: 1.78598
Value Function Loss: 0.04545

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.30001
Value Function Update Magnitude: 0.30190

Collected Steps per Second: 21,032.06810
Overall Steps per Second: 10,511.98079

Timestep Collection Time: 2.37846
Timestep Consumption Time: 2.38030
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.75876

Cumulative Model Updates: 152,302
Cumulative Timesteps: 1,270,919,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1270919470...
Checkpoint 1270919470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,173.13477
Policy Entropy: 1.81124
Value Function Loss: 0.04398

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07425
Policy Update Magnitude: 0.31026
Value Function Update Magnitude: 0.30174

Collected Steps per Second: 21,158.90953
Overall Steps per Second: 10,563.19168

Timestep Collection Time: 2.36373
Timestep Consumption Time: 2.37101
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.73474

Cumulative Model Updates: 152,308
Cumulative Timesteps: 1,270,969,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,125.81371
Policy Entropy: 1.80566
Value Function Loss: 0.04513

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07684
Policy Update Magnitude: 0.31007
Value Function Update Magnitude: 0.32437

Collected Steps per Second: 21,382.49772
Overall Steps per Second: 10,468.92490

Timestep Collection Time: 2.33902
Timestep Consumption Time: 2.43836
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.77738

Cumulative Model Updates: 152,314
Cumulative Timesteps: 1,271,019,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1271019498...
Checkpoint 1271019498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,114.89746
Policy Entropy: 1.79662
Value Function Loss: 0.04279

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.30932
Value Function Update Magnitude: 0.32441

Collected Steps per Second: 21,519.98597
Overall Steps per Second: 10,715.12820

Timestep Collection Time: 2.32370
Timestep Consumption Time: 2.34316
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.66686

Cumulative Model Updates: 152,320
Cumulative Timesteps: 1,271,069,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,651.05482
Policy Entropy: 1.78322
Value Function Loss: 0.04512

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.30833
Value Function Update Magnitude: 0.33350

Collected Steps per Second: 21,425.10387
Overall Steps per Second: 10,380.91484

Timestep Collection Time: 2.33511
Timestep Consumption Time: 2.48431
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.81942

Cumulative Model Updates: 152,326
Cumulative Timesteps: 1,271,119,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1271119534...
Checkpoint 1271119534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,200.65485
Policy Entropy: 1.79192
Value Function Loss: 0.04785

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.31120
Value Function Update Magnitude: 0.35598

Collected Steps per Second: 21,698.65102
Overall Steps per Second: 10,601.25040

Timestep Collection Time: 2.30530
Timestep Consumption Time: 2.41320
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.71850

Cumulative Model Updates: 152,332
Cumulative Timesteps: 1,271,169,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,543.70640
Policy Entropy: 1.80569
Value Function Loss: 0.04461

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.07645
Policy Update Magnitude: 0.30923
Value Function Update Magnitude: 0.36583

Collected Steps per Second: 22,022.43095
Overall Steps per Second: 10,523.45733

Timestep Collection Time: 2.27159
Timestep Consumption Time: 2.48217
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.75376

Cumulative Model Updates: 152,338
Cumulative Timesteps: 1,271,219,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1271219582...
Checkpoint 1271219582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,632.03451
Policy Entropy: 1.79130
Value Function Loss: 0.04717

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.30912
Value Function Update Magnitude: 0.35532

Collected Steps per Second: 21,602.24958
Overall Steps per Second: 10,608.63644

Timestep Collection Time: 2.31652
Timestep Consumption Time: 2.40058
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.71710

Cumulative Model Updates: 152,344
Cumulative Timesteps: 1,271,269,624

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,630.41106
Policy Entropy: 1.79183
Value Function Loss: 0.04611

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.30850
Value Function Update Magnitude: 0.34865

Collected Steps per Second: 21,528.53271
Overall Steps per Second: 10,474.82341

Timestep Collection Time: 2.32371
Timestep Consumption Time: 2.45213
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.77583

Cumulative Model Updates: 152,350
Cumulative Timesteps: 1,271,319,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1271319650...
Checkpoint 1271319650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,894.40002
Policy Entropy: 1.78209
Value Function Loss: 0.04670

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.30813
Value Function Update Magnitude: 0.35060

Collected Steps per Second: 21,705.70499
Overall Steps per Second: 10,555.88846

Timestep Collection Time: 2.30474
Timestep Consumption Time: 2.43442
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.73916

Cumulative Model Updates: 152,356
Cumulative Timesteps: 1,271,369,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,985.84180
Policy Entropy: 1.80225
Value Function Loss: 0.04424

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07657
Policy Update Magnitude: 0.30843
Value Function Update Magnitude: 0.35232

Collected Steps per Second: 21,681.86045
Overall Steps per Second: 10,536.28743

Timestep Collection Time: 2.30764
Timestep Consumption Time: 2.44109
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.74873

Cumulative Model Updates: 152,362
Cumulative Timesteps: 1,271,419,710

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1271419710...
Checkpoint 1271419710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,479.23353
Policy Entropy: 1.80829
Value Function Loss: 0.04458

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.31006
Value Function Update Magnitude: 0.35968

Collected Steps per Second: 21,554.55111
Overall Steps per Second: 10,355.77190

Timestep Collection Time: 2.32062
Timestep Consumption Time: 2.50953
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.83016

Cumulative Model Updates: 152,368
Cumulative Timesteps: 1,271,469,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,732.97637
Policy Entropy: 1.80934
Value Function Loss: 0.04683

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.31434
Value Function Update Magnitude: 0.35869

Collected Steps per Second: 22,122.12754
Overall Steps per Second: 10,441.32750

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.52929
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.79020

Cumulative Model Updates: 152,374
Cumulative Timesteps: 1,271,519,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1271519746...
Checkpoint 1271519746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,061.34304
Policy Entropy: 1.79994
Value Function Loss: 0.05120

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.31887
Value Function Update Magnitude: 0.36302

Collected Steps per Second: 22,236.70259
Overall Steps per Second: 10,484.70126

Timestep Collection Time: 2.24871
Timestep Consumption Time: 2.52052
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.76923

Cumulative Model Updates: 152,380
Cumulative Timesteps: 1,271,569,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,942.63751
Policy Entropy: 1.77797
Value Function Loss: 0.05021

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.31954
Value Function Update Magnitude: 0.37102

Collected Steps per Second: 22,031.58704
Overall Steps per Second: 10,485.33657

Timestep Collection Time: 2.27001
Timestep Consumption Time: 2.49970
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.76971

Cumulative Model Updates: 152,386
Cumulative Timesteps: 1,271,619,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1271619762...
Checkpoint 1271619762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,461.46268
Policy Entropy: 1.76586
Value Function Loss: 0.04773

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.32201
Value Function Update Magnitude: 0.36889

Collected Steps per Second: 21,954.28324
Overall Steps per Second: 10,664.82528

Timestep Collection Time: 2.27819
Timestep Consumption Time: 2.41162
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.68981

Cumulative Model Updates: 152,392
Cumulative Timesteps: 1,271,669,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,779.11907
Policy Entropy: 1.76618
Value Function Loss: 0.04307

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.31294
Value Function Update Magnitude: 0.35821

Collected Steps per Second: 22,063.56297
Overall Steps per Second: 10,494.70427

Timestep Collection Time: 2.26836
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.76888

Cumulative Model Updates: 152,398
Cumulative Timesteps: 1,271,719,826

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1271719826...
Checkpoint 1271719826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,667.87864
Policy Entropy: 1.77614
Value Function Loss: 0.04187

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.30491
Value Function Update Magnitude: 0.33977

Collected Steps per Second: 22,015.71597
Overall Steps per Second: 10,537.87058

Timestep Collection Time: 2.27238
Timestep Consumption Time: 2.47507
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.74745

Cumulative Model Updates: 152,404
Cumulative Timesteps: 1,271,769,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,608.08353
Policy Entropy: 1.77208
Value Function Loss: 0.04044

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.30071
Value Function Update Magnitude: 0.32039

Collected Steps per Second: 21,930.13511
Overall Steps per Second: 10,473.98181

Timestep Collection Time: 2.28088
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.77564

Cumulative Model Updates: 152,410
Cumulative Timesteps: 1,271,819,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1271819874...
Checkpoint 1271819874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,179.04296
Policy Entropy: 1.77760
Value Function Loss: 0.04252

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.29898
Value Function Update Magnitude: 0.31610

Collected Steps per Second: 21,652.76447
Overall Steps per Second: 10,567.87348

Timestep Collection Time: 2.30964
Timestep Consumption Time: 2.42263
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.73227

Cumulative Model Updates: 152,416
Cumulative Timesteps: 1,271,869,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,354.99499
Policy Entropy: 1.76758
Value Function Loss: 0.04043

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.30406
Value Function Update Magnitude: 0.31432

Collected Steps per Second: 21,454.47147
Overall Steps per Second: 10,474.37631

Timestep Collection Time: 2.33182
Timestep Consumption Time: 2.44441
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.77623

Cumulative Model Updates: 152,422
Cumulative Timesteps: 1,271,919,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1271919912...
Checkpoint 1271919912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,892.64829
Policy Entropy: 1.75941
Value Function Loss: 0.03943

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.30068
Value Function Update Magnitude: 0.32037

Collected Steps per Second: 21,148.59742
Overall Steps per Second: 10,259.85065

Timestep Collection Time: 2.36507
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.87512

Cumulative Model Updates: 152,428
Cumulative Timesteps: 1,271,969,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,111.31311
Policy Entropy: 1.76649
Value Function Loss: 0.04410

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.30041
Value Function Update Magnitude: 0.31642

Collected Steps per Second: 22,159.93473
Overall Steps per Second: 10,471.36490

Timestep Collection Time: 2.25678
Timestep Consumption Time: 2.51911
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.77588

Cumulative Model Updates: 152,434
Cumulative Timesteps: 1,272,019,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1272019940...
Checkpoint 1272019940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,276.03156
Policy Entropy: 1.77359
Value Function Loss: 0.04347

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.29996
Value Function Update Magnitude: 0.32725

Collected Steps per Second: 21,886.10303
Overall Steps per Second: 10,580.71317

Timestep Collection Time: 2.28620
Timestep Consumption Time: 2.44278
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.72898

Cumulative Model Updates: 152,440
Cumulative Timesteps: 1,272,069,976

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,558.10613
Policy Entropy: 1.78579
Value Function Loss: 0.04486

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.28889
Value Function Update Magnitude: 0.33269

Collected Steps per Second: 21,976.09287
Overall Steps per Second: 10,495.70028

Timestep Collection Time: 2.27629
Timestep Consumption Time: 2.48985
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.76614

Cumulative Model Updates: 152,446
Cumulative Timesteps: 1,272,120,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1272120000...
Checkpoint 1272120000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,403.60825
Policy Entropy: 1.77643
Value Function Loss: 0.04416

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.28690
Value Function Update Magnitude: 0.31258

Collected Steps per Second: 22,070.86976
Overall Steps per Second: 10,640.71584

Timestep Collection Time: 2.26688
Timestep Consumption Time: 2.43506
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.70194

Cumulative Model Updates: 152,452
Cumulative Timesteps: 1,272,170,032

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,843.46659
Policy Entropy: 1.78205
Value Function Loss: 0.04757

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.30157
Value Function Update Magnitude: 0.31069

Collected Steps per Second: 22,130.23904
Overall Steps per Second: 10,487.58352

Timestep Collection Time: 2.26008
Timestep Consumption Time: 2.50899
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.76907

Cumulative Model Updates: 152,458
Cumulative Timesteps: 1,272,220,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1272220048...
Checkpoint 1272220048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,119.22892
Policy Entropy: 1.78396
Value Function Loss: 0.04847

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.30910
Value Function Update Magnitude: 0.33852

Collected Steps per Second: 21,775.40347
Overall Steps per Second: 10,592.33563

Timestep Collection Time: 2.29773
Timestep Consumption Time: 2.42587
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.72360

Cumulative Model Updates: 152,464
Cumulative Timesteps: 1,272,270,082

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,659.55647
Policy Entropy: 1.76609
Value Function Loss: 0.04588

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.31036
Value Function Update Magnitude: 0.34485

Collected Steps per Second: 21,384.87021
Overall Steps per Second: 10,538.90413

Timestep Collection Time: 2.33913
Timestep Consumption Time: 2.40728
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.74641

Cumulative Model Updates: 152,470
Cumulative Timesteps: 1,272,320,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1272320104...
Checkpoint 1272320104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,645.12535
Policy Entropy: 1.75544
Value Function Loss: 0.04503

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.31455
Value Function Update Magnitude: 0.32231

Collected Steps per Second: 20,808.96862
Overall Steps per Second: 10,532.23954

Timestep Collection Time: 2.40435
Timestep Consumption Time: 2.34602
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.75037

Cumulative Model Updates: 152,476
Cumulative Timesteps: 1,272,370,136

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,585.40202
Policy Entropy: 1.75324
Value Function Loss: 0.04213

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.30840
Value Function Update Magnitude: 0.31120

Collected Steps per Second: 21,116.86665
Overall Steps per Second: 10,601.99933

Timestep Collection Time: 2.36929
Timestep Consumption Time: 2.34982
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.71911

Cumulative Model Updates: 152,482
Cumulative Timesteps: 1,272,420,168

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1272420168...
Checkpoint 1272420168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,702.52905
Policy Entropy: 1.74525
Value Function Loss: 0.04141

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.30277
Value Function Update Magnitude: 0.30770

Collected Steps per Second: 20,913.17928
Overall Steps per Second: 10,284.12740

Timestep Collection Time: 2.39122
Timestep Consumption Time: 2.47142
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.86264

Cumulative Model Updates: 152,488
Cumulative Timesteps: 1,272,470,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,722.09826
Policy Entropy: 1.72740
Value Function Loss: 0.03826

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08103
Policy Update Magnitude: 0.30047
Value Function Update Magnitude: 0.29586

Collected Steps per Second: 21,833.29206
Overall Steps per Second: 10,654.39026

Timestep Collection Time: 2.29109
Timestep Consumption Time: 2.40388
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.69497

Cumulative Model Updates: 152,494
Cumulative Timesteps: 1,272,520,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1272520198...
Checkpoint 1272520198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,401.67072
Policy Entropy: 1.72124
Value Function Loss: 0.03959

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.30121
Value Function Update Magnitude: 0.27345

Collected Steps per Second: 21,126.39282
Overall Steps per Second: 10,250.89267

Timestep Collection Time: 2.36690
Timestep Consumption Time: 2.51112
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.87801

Cumulative Model Updates: 152,500
Cumulative Timesteps: 1,272,570,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,686.12832
Policy Entropy: 1.71474
Value Function Loss: 0.04167

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.28830
Value Function Update Magnitude: 0.27096

Collected Steps per Second: 22,016.22789
Overall Steps per Second: 10,495.19211

Timestep Collection Time: 2.27132
Timestep Consumption Time: 2.49333
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.76466

Cumulative Model Updates: 152,506
Cumulative Timesteps: 1,272,620,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1272620208...
Checkpoint 1272620208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,853.67028
Policy Entropy: 1.73916
Value Function Loss: 0.04687

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.28475
Value Function Update Magnitude: 0.29381

Collected Steps per Second: 21,716.21284
Overall Steps per Second: 10,538.04195

Timestep Collection Time: 2.30372
Timestep Consumption Time: 2.44365
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.74737

Cumulative Model Updates: 152,512
Cumulative Timesteps: 1,272,670,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,362.76474
Policy Entropy: 1.73813
Value Function Loss: 0.04625

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.30476
Value Function Update Magnitude: 0.32468

Collected Steps per Second: 21,975.78519
Overall Steps per Second: 10,616.52367

Timestep Collection Time: 2.27760
Timestep Consumption Time: 2.43694
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.71454

Cumulative Model Updates: 152,518
Cumulative Timesteps: 1,272,720,288

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1272720288...
Checkpoint 1272720288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,965.31591
Policy Entropy: 1.75380
Value Function Loss: 0.04162

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.30663
Value Function Update Magnitude: 0.32099

Collected Steps per Second: 21,914.49098
Overall Steps per Second: 10,602.72794

Timestep Collection Time: 2.28214
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.71690

Cumulative Model Updates: 152,524
Cumulative Timesteps: 1,272,770,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,962.34187
Policy Entropy: 1.75097
Value Function Loss: 0.03897

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.30313
Value Function Update Magnitude: 0.29714

Collected Steps per Second: 22,205.19250
Overall Steps per Second: 10,503.47171

Timestep Collection Time: 2.25371
Timestep Consumption Time: 2.51081
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.76452

Cumulative Model Updates: 152,530
Cumulative Timesteps: 1,272,820,344

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1272820344...
Checkpoint 1272820344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,381.27744
Policy Entropy: 1.75402
Value Function Loss: 0.04016

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07486
Policy Update Magnitude: 0.30504
Value Function Update Magnitude: 0.29603

Collected Steps per Second: 21,821.47647
Overall Steps per Second: 10,582.61054

Timestep Collection Time: 2.29242
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.72700

Cumulative Model Updates: 152,536
Cumulative Timesteps: 1,272,870,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,692.49920
Policy Entropy: 1.75904
Value Function Loss: 0.03994

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.30751
Value Function Update Magnitude: 0.29746

Collected Steps per Second: 21,664.48264
Overall Steps per Second: 10,408.33753

Timestep Collection Time: 2.30820
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.80442

Cumulative Model Updates: 152,542
Cumulative Timesteps: 1,272,920,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1272920374...
Checkpoint 1272920374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,527.59719
Policy Entropy: 1.75151
Value Function Loss: 0.04088

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.30407
Value Function Update Magnitude: 0.28813

Collected Steps per Second: 21,209.58124
Overall Steps per Second: 10,346.44329

Timestep Collection Time: 2.35865
Timestep Consumption Time: 2.47644
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.83509

Cumulative Model Updates: 152,548
Cumulative Timesteps: 1,272,970,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,420.28932
Policy Entropy: 1.74672
Value Function Loss: 0.04143

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.30793
Value Function Update Magnitude: 0.29756

Collected Steps per Second: 21,729.42627
Overall Steps per Second: 10,410.42283

Timestep Collection Time: 2.30112
Timestep Consumption Time: 2.50195
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.80307

Cumulative Model Updates: 152,554
Cumulative Timesteps: 1,273,020,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1273020402...
Checkpoint 1273020402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,507.14353
Policy Entropy: 1.75078
Value Function Loss: 0.04459

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.31010
Value Function Update Magnitude: 0.32410

Collected Steps per Second: 21,525.62768
Overall Steps per Second: 10,509.04281

Timestep Collection Time: 2.32476
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.76180

Cumulative Model Updates: 152,560
Cumulative Timesteps: 1,273,070,444

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,771.62772
Policy Entropy: 1.75044
Value Function Loss: 0.04506

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.31371
Value Function Update Magnitude: 0.32057

Collected Steps per Second: 21,867.44595
Overall Steps per Second: 10,537.22771

Timestep Collection Time: 2.28669
Timestep Consumption Time: 2.45877
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.74546

Cumulative Model Updates: 152,566
Cumulative Timesteps: 1,273,120,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1273120448...
Checkpoint 1273120448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,779.37658
Policy Entropy: 1.75785
Value Function Loss: 0.04560

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.30245
Value Function Update Magnitude: 0.31579

Collected Steps per Second: 21,743.17826
Overall Steps per Second: 10,529.20375

Timestep Collection Time: 2.30022
Timestep Consumption Time: 2.44981
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.75003

Cumulative Model Updates: 152,572
Cumulative Timesteps: 1,273,170,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,196.85175
Policy Entropy: 1.73839
Value Function Loss: 0.04626

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.30381
Value Function Update Magnitude: 0.31391

Collected Steps per Second: 22,240.10150
Overall Steps per Second: 10,510.02670

Timestep Collection Time: 2.24891
Timestep Consumption Time: 2.50997
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.75888

Cumulative Model Updates: 152,578
Cumulative Timesteps: 1,273,220,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1273220478...
Checkpoint 1273220478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,857.51727
Policy Entropy: 1.76234
Value Function Loss: 0.04683

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.30700
Value Function Update Magnitude: 0.31214

Collected Steps per Second: 21,946.65120
Overall Steps per Second: 10,596.29110

Timestep Collection Time: 2.27853
Timestep Consumption Time: 2.44067
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.71920

Cumulative Model Updates: 152,584
Cumulative Timesteps: 1,273,270,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,855.28573
Policy Entropy: 1.77638
Value Function Loss: 0.04815

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.31481
Value Function Update Magnitude: 0.31959

Collected Steps per Second: 22,252.09141
Overall Steps per Second: 10,498.20875

Timestep Collection Time: 2.24743
Timestep Consumption Time: 2.51624
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.76367

Cumulative Model Updates: 152,590
Cumulative Timesteps: 1,273,320,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1273320494...
Checkpoint 1273320494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,532.65421
Policy Entropy: 1.78346
Value Function Loss: 0.04413

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.31098
Value Function Update Magnitude: 0.32067

Collected Steps per Second: 21,877.64480
Overall Steps per Second: 10,576.50520

Timestep Collection Time: 2.28562
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.72784

Cumulative Model Updates: 152,596
Cumulative Timesteps: 1,273,370,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,759.70306
Policy Entropy: 1.76846
Value Function Loss: 0.04652

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.30928
Value Function Update Magnitude: 0.32103

Collected Steps per Second: 22,072.09780
Overall Steps per Second: 10,520.56131

Timestep Collection Time: 2.26693
Timestep Consumption Time: 2.48909
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.75602

Cumulative Model Updates: 152,602
Cumulative Timesteps: 1,273,420,534

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1273420534...
Checkpoint 1273420534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,413.66440
Policy Entropy: 1.74929
Value Function Loss: 0.04587

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.30808
Value Function Update Magnitude: 0.33880

Collected Steps per Second: 21,117.74669
Overall Steps per Second: 10,246.82623

Timestep Collection Time: 2.36967
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.88366

Cumulative Model Updates: 152,608
Cumulative Timesteps: 1,273,470,576

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,205.58428
Policy Entropy: 1.74693
Value Function Loss: 0.04829

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.31097
Value Function Update Magnitude: 0.36445

Collected Steps per Second: 21,475.18660
Overall Steps per Second: 10,374.40680

Timestep Collection Time: 2.32864
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.82032

Cumulative Model Updates: 152,614
Cumulative Timesteps: 1,273,520,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1273520584...
Checkpoint 1273520584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,410.67381
Policy Entropy: 1.75454
Value Function Loss: 0.04779

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.31943
Value Function Update Magnitude: 0.37468

Collected Steps per Second: 21,451.20359
Overall Steps per Second: 10,303.16770

Timestep Collection Time: 2.33236
Timestep Consumption Time: 2.52362
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.85598

Cumulative Model Updates: 152,620
Cumulative Timesteps: 1,273,570,616

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,999.32363
Policy Entropy: 1.76908
Value Function Loss: 0.04626

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.31736
Value Function Update Magnitude: 0.36529

Collected Steps per Second: 22,167.67201
Overall Steps per Second: 10,406.07133

Timestep Collection Time: 2.25554
Timestep Consumption Time: 2.54935
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.80489

Cumulative Model Updates: 152,626
Cumulative Timesteps: 1,273,620,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1273620616...
Checkpoint 1273620616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,776.47354
Policy Entropy: 1.77000
Value Function Loss: 0.04361

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.31108
Value Function Update Magnitude: 0.33579

Collected Steps per Second: 21,852.30323
Overall Steps per Second: 10,557.12623

Timestep Collection Time: 2.28836
Timestep Consumption Time: 2.44834
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73671

Cumulative Model Updates: 152,632
Cumulative Timesteps: 1,273,670,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,989.25613
Policy Entropy: 1.77407
Value Function Loss: 0.04248

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.30473
Value Function Update Magnitude: 0.32217

Collected Steps per Second: 22,364.02210
Overall Steps per Second: 10,525.33112

Timestep Collection Time: 2.23636
Timestep Consumption Time: 2.51541
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.75177

Cumulative Model Updates: 152,638
Cumulative Timesteps: 1,273,720,636

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1273720636...
Checkpoint 1273720636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,046.87205
Policy Entropy: 1.76687
Value Function Loss: 0.04071

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.30126
Value Function Update Magnitude: 0.30082

Collected Steps per Second: 21,790.07339
Overall Steps per Second: 10,559.31165

Timestep Collection Time: 2.29545
Timestep Consumption Time: 2.44141
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.73686

Cumulative Model Updates: 152,644
Cumulative Timesteps: 1,273,770,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,370.53133
Policy Entropy: 1.77210
Value Function Loss: 0.04134

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.29841
Value Function Update Magnitude: 0.25540

Collected Steps per Second: 21,784.02741
Overall Steps per Second: 10,501.46942

Timestep Collection Time: 2.29535
Timestep Consumption Time: 2.46608
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.76143

Cumulative Model Updates: 152,650
Cumulative Timesteps: 1,273,820,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1273820656...
Checkpoint 1273820656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,713.80618
Policy Entropy: 1.77598
Value Function Loss: 0.04380

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.29796
Value Function Update Magnitude: 0.25917

Collected Steps per Second: 21,916.93422
Overall Steps per Second: 10,612.48483

Timestep Collection Time: 2.28207
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.71294

Cumulative Model Updates: 152,656
Cumulative Timesteps: 1,273,870,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,468.31648
Policy Entropy: 1.78449
Value Function Loss: 0.04138

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.29729
Value Function Update Magnitude: 0.29171

Collected Steps per Second: 22,366.39280
Overall Steps per Second: 10,564.57469

Timestep Collection Time: 2.23630
Timestep Consumption Time: 2.49820
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.73450

Cumulative Model Updates: 152,662
Cumulative Timesteps: 1,273,920,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1273920690...
Checkpoint 1273920690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,919.01700
Policy Entropy: 1.77744
Value Function Loss: 0.04141

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.29708
Value Function Update Magnitude: 0.28472

Collected Steps per Second: 21,202.00494
Overall Steps per Second: 10,475.78421

Timestep Collection Time: 2.35846
Timestep Consumption Time: 2.41484
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.77329

Cumulative Model Updates: 152,668
Cumulative Timesteps: 1,273,970,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,706.55874
Policy Entropy: 1.75933
Value Function Loss: 0.04030

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.30105
Value Function Update Magnitude: 0.29882

Collected Steps per Second: 21,116.07902
Overall Steps per Second: 10,511.04911

Timestep Collection Time: 2.36824
Timestep Consumption Time: 2.38942
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.75766

Cumulative Model Updates: 152,674
Cumulative Timesteps: 1,274,020,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1274020702...
Checkpoint 1274020702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,304.85232
Policy Entropy: 1.75815
Value Function Loss: 0.04255

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.30168
Value Function Update Magnitude: 0.32755

Collected Steps per Second: 20,655.37304
Overall Steps per Second: 10,340.38083

Timestep Collection Time: 2.42155
Timestep Consumption Time: 2.41560
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.83715

Cumulative Model Updates: 152,680
Cumulative Timesteps: 1,274,070,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,891.12107
Policy Entropy: 1.75241
Value Function Loss: 0.04325

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.33403

Collected Steps per Second: 20,987.56503
Overall Steps per Second: 10,378.71824

Timestep Collection Time: 2.38370
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.82025

Cumulative Model Updates: 152,686
Cumulative Timesteps: 1,274,120,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1274120748...
Checkpoint 1274120748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,093.47937
Policy Entropy: 1.74458
Value Function Loss: 0.04331

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.30705
Value Function Update Magnitude: 0.33980

Collected Steps per Second: 20,899.09054
Overall Steps per Second: 10,515.34860

Timestep Collection Time: 2.39264
Timestep Consumption Time: 2.36269
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.75533

Cumulative Model Updates: 152,692
Cumulative Timesteps: 1,274,170,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,200.69212
Policy Entropy: 1.74704
Value Function Loss: 0.04075

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.30298
Value Function Update Magnitude: 0.32676

Collected Steps per Second: 21,638.72778
Overall Steps per Second: 10,521.20880

Timestep Collection Time: 2.31243
Timestep Consumption Time: 2.44349
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.75592

Cumulative Model Updates: 152,698
Cumulative Timesteps: 1,274,220,790

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1274220790...
Checkpoint 1274220790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,222.97367
Policy Entropy: 1.74640
Value Function Loss: 0.04085

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.30165
Value Function Update Magnitude: 0.31805

Collected Steps per Second: 21,648.52529
Overall Steps per Second: 10,579.30954

Timestep Collection Time: 2.30990
Timestep Consumption Time: 2.41687
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.72677

Cumulative Model Updates: 152,704
Cumulative Timesteps: 1,274,270,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,874.40739
Policy Entropy: 1.75537
Value Function Loss: 0.04374

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.30763
Value Function Update Magnitude: 0.31055

Collected Steps per Second: 21,957.38176
Overall Steps per Second: 10,489.57012

Timestep Collection Time: 2.27732
Timestep Consumption Time: 2.48970
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.76702

Cumulative Model Updates: 152,710
Cumulative Timesteps: 1,274,320,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1274320800...
Checkpoint 1274320800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,071.00496
Policy Entropy: 1.76086
Value Function Loss: 0.04602

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.31035
Value Function Update Magnitude: 0.32954

Collected Steps per Second: 21,993.22096
Overall Steps per Second: 10,595.90011

Timestep Collection Time: 2.27416
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.72032

Cumulative Model Updates: 152,716
Cumulative Timesteps: 1,274,370,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,704.65767
Policy Entropy: 1.77513
Value Function Loss: 0.04737

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.31370
Value Function Update Magnitude: 0.34632

Collected Steps per Second: 22,179.04606
Overall Steps per Second: 10,529.94885

Timestep Collection Time: 2.25582
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.75140

Cumulative Model Updates: 152,722
Cumulative Timesteps: 1,274,420,848

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1274420848...
Checkpoint 1274420848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,831.21339
Policy Entropy: 1.79145
Value Function Loss: 0.04452

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.30777
Value Function Update Magnitude: 0.34414

Collected Steps per Second: 21,844.06719
Overall Steps per Second: 10,599.66021

Timestep Collection Time: 2.28923
Timestep Consumption Time: 2.42847
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.71770

Cumulative Model Updates: 152,728
Cumulative Timesteps: 1,274,470,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,072.49159
Policy Entropy: 1.79228
Value Function Loss: 0.05152

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.31152
Value Function Update Magnitude: 0.31448

Collected Steps per Second: 22,103.92931
Overall Steps per Second: 10,545.19075

Timestep Collection Time: 2.26231
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.74207

Cumulative Model Updates: 152,734
Cumulative Timesteps: 1,274,520,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1274520860...
Checkpoint 1274520860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,168.08886
Policy Entropy: 1.79101
Value Function Loss: 0.05103

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.31460
Value Function Update Magnitude: 0.26258

Collected Steps per Second: 21,735.27461
Overall Steps per Second: 10,544.94598

Timestep Collection Time: 2.30087
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.74256

Cumulative Model Updates: 152,740
Cumulative Timesteps: 1,274,570,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,556.99662
Policy Entropy: 1.78051
Value Function Loss: 0.04988

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.31411
Value Function Update Magnitude: 0.30158

Collected Steps per Second: 21,706.73972
Overall Steps per Second: 10,459.94277

Timestep Collection Time: 2.30380
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.78091

Cumulative Model Updates: 152,746
Cumulative Timesteps: 1,274,620,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1274620878...
Checkpoint 1274620878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,357.15455
Policy Entropy: 1.76319
Value Function Loss: 0.04148

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.30757
Value Function Update Magnitude: 0.32758

Collected Steps per Second: 21,640.06149
Overall Steps per Second: 10,559.09056

Timestep Collection Time: 2.31062
Timestep Consumption Time: 2.42482
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.73545

Cumulative Model Updates: 152,752
Cumulative Timesteps: 1,274,670,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,946.74236
Policy Entropy: 1.76445
Value Function Loss: 0.03991

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.29221
Value Function Update Magnitude: 0.33933

Collected Steps per Second: 21,553.51424
Overall Steps per Second: 10,484.10596

Timestep Collection Time: 2.31999
Timestep Consumption Time: 2.44951
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.76951

Cumulative Model Updates: 152,758
Cumulative Timesteps: 1,274,720,884

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1274720884...
Checkpoint 1274720884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,800.22599
Policy Entropy: 1.75577
Value Function Loss: 0.03967

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.27113
Value Function Update Magnitude: 0.33039

Collected Steps per Second: 21,777.68652
Overall Steps per Second: 10,331.35263

Timestep Collection Time: 2.29620
Timestep Consumption Time: 2.54401
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.84022

Cumulative Model Updates: 152,764
Cumulative Timesteps: 1,274,770,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,812.58249
Policy Entropy: 1.75287
Value Function Loss: 0.04039

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.27961
Value Function Update Magnitude: 0.31602

Collected Steps per Second: 21,864.42404
Overall Steps per Second: 10,357.02273

Timestep Collection Time: 2.28682
Timestep Consumption Time: 2.54082
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.82764

Cumulative Model Updates: 152,770
Cumulative Timesteps: 1,274,820,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1274820890...
Checkpoint 1274820890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,972.76019
Policy Entropy: 1.74198
Value Function Loss: 0.04098

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.28047
Value Function Update Magnitude: 0.29525

Collected Steps per Second: 21,949.27536
Overall Steps per Second: 10,600.13485

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.44031
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.71956

Cumulative Model Updates: 152,776
Cumulative Timesteps: 1,274,870,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,467.98310
Policy Entropy: 1.73935
Value Function Loss: 0.03972

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.28821
Value Function Update Magnitude: 0.27110

Collected Steps per Second: 22,035.53569
Overall Steps per Second: 10,481.29409

Timestep Collection Time: 2.27015
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.77269

Cumulative Model Updates: 152,782
Cumulative Timesteps: 1,274,920,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1274920942...
Checkpoint 1274920942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,357.98728
Policy Entropy: 1.74465
Value Function Loss: 0.04159

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.29700
Value Function Update Magnitude: 0.30305

Collected Steps per Second: 21,971.48162
Overall Steps per Second: 10,604.31289

Timestep Collection Time: 2.27631
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.71638

Cumulative Model Updates: 152,788
Cumulative Timesteps: 1,274,970,956

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,601.11270
Policy Entropy: 1.73633
Value Function Loss: 0.03902

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.30158
Value Function Update Magnitude: 0.33135

Collected Steps per Second: 21,951.00967
Overall Steps per Second: 10,476.58774

Timestep Collection Time: 2.27816
Timestep Consumption Time: 2.49515
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.77331

Cumulative Model Updates: 152,794
Cumulative Timesteps: 1,275,020,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1275020964...
Checkpoint 1275020964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,319.59125
Policy Entropy: 1.75618
Value Function Loss: 0.04497

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.30824
Value Function Update Magnitude: 0.32708

Collected Steps per Second: 21,739.36191
Overall Steps per Second: 10,586.95815

Timestep Collection Time: 2.30090
Timestep Consumption Time: 2.42379
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.72468

Cumulative Model Updates: 152,800
Cumulative Timesteps: 1,275,070,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,131.65505
Policy Entropy: 1.75070
Value Function Loss: 0.04660

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.31419
Value Function Update Magnitude: 0.32463

Collected Steps per Second: 21,561.28901
Overall Steps per Second: 10,506.95590

Timestep Collection Time: 2.32036
Timestep Consumption Time: 2.44125
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.76161

Cumulative Model Updates: 152,806
Cumulative Timesteps: 1,275,121,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1275121014...
Checkpoint 1275121014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,477.73081
Policy Entropy: 1.75724
Value Function Loss: 0.04537

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.30662
Value Function Update Magnitude: 0.34022

Collected Steps per Second: 20,872.49238
Overall Steps per Second: 10,385.30119

Timestep Collection Time: 2.39626
Timestep Consumption Time: 2.41977
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.81604

Cumulative Model Updates: 152,812
Cumulative Timesteps: 1,275,171,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,619.24668
Policy Entropy: 1.73745
Value Function Loss: 0.04269

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.30158
Value Function Update Magnitude: 0.33832

Collected Steps per Second: 20,991.99338
Overall Steps per Second: 10,445.81849

Timestep Collection Time: 2.38300
Timestep Consumption Time: 2.40590
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.78890

Cumulative Model Updates: 152,818
Cumulative Timesteps: 1,275,221,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1275221054...
Checkpoint 1275221054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,589.86797
Policy Entropy: 1.74242
Value Function Loss: 0.04269

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07831
Policy Update Magnitude: 0.31137
Value Function Update Magnitude: 0.32876

Collected Steps per Second: 21,145.46921
Overall Steps per Second: 10,505.13934

Timestep Collection Time: 2.36533
Timestep Consumption Time: 2.39577
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.76110

Cumulative Model Updates: 152,824
Cumulative Timesteps: 1,275,271,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,736.79360
Policy Entropy: 1.73443
Value Function Loss: 0.04576

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.31376
Value Function Update Magnitude: 0.35173

Collected Steps per Second: 21,565.82811
Overall Steps per Second: 10,430.37364

Timestep Collection Time: 2.31960
Timestep Consumption Time: 2.47640
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.79599

Cumulative Model Updates: 152,830
Cumulative Timesteps: 1,275,321,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1275321094...
Checkpoint 1275321094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,147.29788
Policy Entropy: 1.73653
Value Function Loss: 0.04857

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.32309
Value Function Update Magnitude: 0.36775

Collected Steps per Second: 21,520.19153
Overall Steps per Second: 10,549.96000

Timestep Collection Time: 2.32470
Timestep Consumption Time: 2.41731
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.74201

Cumulative Model Updates: 152,836
Cumulative Timesteps: 1,275,371,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,406.48166
Policy Entropy: 1.73529
Value Function Loss: 0.04526

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.31878
Value Function Update Magnitude: 0.36658

Collected Steps per Second: 21,648.24600
Overall Steps per Second: 10,598.98599

Timestep Collection Time: 2.30993
Timestep Consumption Time: 2.40807
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.71800

Cumulative Model Updates: 152,842
Cumulative Timesteps: 1,275,421,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1275421128...
Checkpoint 1275421128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,130.70171
Policy Entropy: 1.72993
Value Function Loss: 0.04536

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.31056
Value Function Update Magnitude: 0.34054

Collected Steps per Second: 21,973.26334
Overall Steps per Second: 10,581.66189

Timestep Collection Time: 2.27695
Timestep Consumption Time: 2.45123
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.72818

Cumulative Model Updates: 152,848
Cumulative Timesteps: 1,275,471,160

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,335.16839
Policy Entropy: 1.73907
Value Function Loss: 0.04327

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.31101
Value Function Update Magnitude: 0.33190

Collected Steps per Second: 22,042.69957
Overall Steps per Second: 10,447.89323

Timestep Collection Time: 2.26969
Timestep Consumption Time: 2.51884
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.78853

Cumulative Model Updates: 152,854
Cumulative Timesteps: 1,275,521,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1275521190...
Checkpoint 1275521190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,039.89963
Policy Entropy: 1.73764
Value Function Loss: 0.04301

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.30970
Value Function Update Magnitude: 0.34367

Collected Steps per Second: 22,046.41369
Overall Steps per Second: 10,634.20788

Timestep Collection Time: 2.26812
Timestep Consumption Time: 2.43406
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.70218

Cumulative Model Updates: 152,860
Cumulative Timesteps: 1,275,571,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,277.90762
Policy Entropy: 1.77204
Value Function Loss: 0.04250

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.30912
Value Function Update Magnitude: 0.31860

Collected Steps per Second: 21,721.50695
Overall Steps per Second: 10,462.32673

Timestep Collection Time: 2.30251
Timestep Consumption Time: 2.47788
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.78039

Cumulative Model Updates: 152,866
Cumulative Timesteps: 1,275,621,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1275621208...
Checkpoint 1275621208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,398.76716
Policy Entropy: 1.78618
Value Function Loss: 0.04542

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.30490
Value Function Update Magnitude: 0.30373

Collected Steps per Second: 21,446.16131
Overall Steps per Second: 10,370.89024

Timestep Collection Time: 2.33263
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.82369

Cumulative Model Updates: 152,872
Cumulative Timesteps: 1,275,671,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,644.23177
Policy Entropy: 1.78867
Value Function Loss: 0.04536

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.30129
Value Function Update Magnitude: 0.28337

Collected Steps per Second: 20,902.15238
Overall Steps per Second: 10,362.23477

Timestep Collection Time: 2.39239
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.82579

Cumulative Model Updates: 152,878
Cumulative Timesteps: 1,275,721,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1275721240...
Checkpoint 1275721240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,480.72599
Policy Entropy: 1.77304
Value Function Loss: 0.04797

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.31041
Value Function Update Magnitude: 0.26867

Collected Steps per Second: 21,675.80405
Overall Steps per Second: 10,528.57704

Timestep Collection Time: 2.30792
Timestep Consumption Time: 2.44353
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.75145

Cumulative Model Updates: 152,884
Cumulative Timesteps: 1,275,771,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,735.31435
Policy Entropy: 1.78053
Value Function Loss: 0.04580

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.31324
Value Function Update Magnitude: 0.31806

Collected Steps per Second: 21,718.72012
Overall Steps per Second: 10,546.97761

Timestep Collection Time: 2.30244
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.74126

Cumulative Model Updates: 152,890
Cumulative Timesteps: 1,275,821,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1275821272...
Checkpoint 1275821272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,052.13331
Policy Entropy: 1.79363
Value Function Loss: 0.04685

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08462
Policy Update Magnitude: 0.31267
Value Function Update Magnitude: 0.35873

Collected Steps per Second: 21,709.57357
Overall Steps per Second: 10,533.26325

Timestep Collection Time: 2.30359
Timestep Consumption Time: 2.44422
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.74782

Cumulative Model Updates: 152,896
Cumulative Timesteps: 1,275,871,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,079.55534
Policy Entropy: 1.79604
Value Function Loss: 0.04383

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.30634
Value Function Update Magnitude: 0.36421

Collected Steps per Second: 22,062.90354
Overall Steps per Second: 10,483.60854

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.50330
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.76973

Cumulative Model Updates: 152,902
Cumulative Timesteps: 1,275,921,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1275921286...
Checkpoint 1275921286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,876.28128
Policy Entropy: 1.76982
Value Function Loss: 0.04130

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.29864
Value Function Update Magnitude: 0.34586

Collected Steps per Second: 21,729.82512
Overall Steps per Second: 10,537.04438

Timestep Collection Time: 2.30163
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.74649

Cumulative Model Updates: 152,908
Cumulative Timesteps: 1,275,971,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,100.31883
Policy Entropy: 1.77255
Value Function Loss: 0.04057

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.29697
Value Function Update Magnitude: 0.33048

Collected Steps per Second: 21,912.65032
Overall Steps per Second: 10,633.14317

Timestep Collection Time: 2.28233
Timestep Consumption Time: 2.42107
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.70341

Cumulative Model Updates: 152,914
Cumulative Timesteps: 1,276,021,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1276021312...
Checkpoint 1276021312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,119.05680
Policy Entropy: 1.77850
Value Function Loss: 0.03858

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.29682
Value Function Update Magnitude: 0.31742

Collected Steps per Second: 21,865.82516
Overall Steps per Second: 10,620.27909

Timestep Collection Time: 2.28713
Timestep Consumption Time: 2.42179
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.70892

Cumulative Model Updates: 152,920
Cumulative Timesteps: 1,276,071,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,703.31142
Policy Entropy: 1.79419
Value Function Loss: 0.04216

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.30011
Value Function Update Magnitude: 0.32408

Collected Steps per Second: 22,358.54011
Overall Steps per Second: 10,577.38187

Timestep Collection Time: 2.23879
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.73236

Cumulative Model Updates: 152,926
Cumulative Timesteps: 1,276,121,378

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1276121378...
Checkpoint 1276121378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,008.16072
Policy Entropy: 1.79355
Value Function Loss: 0.04710

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.31151
Value Function Update Magnitude: 0.32177

Collected Steps per Second: 22,247.89123
Overall Steps per Second: 10,546.90777

Timestep Collection Time: 2.24767
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.74129

Cumulative Model Updates: 152,932
Cumulative Timesteps: 1,276,171,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,999.82521
Policy Entropy: 1.78548
Value Function Loss: 0.04748

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.31662
Value Function Update Magnitude: 0.34947

Collected Steps per Second: 21,315.46336
Overall Steps per Second: 10,371.25928

Timestep Collection Time: 2.34703
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.82372

Cumulative Model Updates: 152,938
Cumulative Timesteps: 1,276,221,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1276221412...
Checkpoint 1276221412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,883.03371
Policy Entropy: 1.77072
Value Function Loss: 0.04508

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.31072
Value Function Update Magnitude: 0.36381

Collected Steps per Second: 20,682.73714
Overall Steps per Second: 10,311.25009

Timestep Collection Time: 2.41767
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.84946

Cumulative Model Updates: 152,944
Cumulative Timesteps: 1,276,271,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,563.52339
Policy Entropy: 1.76685
Value Function Loss: 0.04449

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.31057
Value Function Update Magnitude: 0.34026

Collected Steps per Second: 21,092.56376
Overall Steps per Second: 10,413.54967

Timestep Collection Time: 2.37060
Timestep Consumption Time: 2.43103
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.80163

Cumulative Model Updates: 152,950
Cumulative Timesteps: 1,276,321,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1276321418...
Checkpoint 1276321418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,398.15727
Policy Entropy: 1.76483
Value Function Loss: 0.04824

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.31603
Value Function Update Magnitude: 0.34780

Collected Steps per Second: 21,139.90898
Overall Steps per Second: 10,585.14703

Timestep Collection Time: 2.36680
Timestep Consumption Time: 2.36001
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.72681

Cumulative Model Updates: 152,956
Cumulative Timesteps: 1,276,371,452

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,498.86457
Policy Entropy: 1.78241
Value Function Loss: 0.05257

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.32268
Value Function Update Magnitude: 0.36111

Collected Steps per Second: 21,387.65749
Overall Steps per Second: 10,452.91827

Timestep Collection Time: 2.33836
Timestep Consumption Time: 2.44614
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.78450

Cumulative Model Updates: 152,962
Cumulative Timesteps: 1,276,421,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1276421464...
Checkpoint 1276421464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,050.33975
Policy Entropy: 1.78671
Value Function Loss: 0.04863

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.31832
Value Function Update Magnitude: 0.34895

Collected Steps per Second: 21,407.02590
Overall Steps per Second: 10,538.83102

Timestep Collection Time: 2.33718
Timestep Consumption Time: 2.41022
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.74740

Cumulative Model Updates: 152,968
Cumulative Timesteps: 1,276,471,496

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,452.13035
Policy Entropy: 1.78717
Value Function Loss: 0.04588

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.30741
Value Function Update Magnitude: 0.32742

Collected Steps per Second: 21,932.42858
Overall Steps per Second: 10,523.37850

Timestep Collection Time: 2.28055
Timestep Consumption Time: 2.47249
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.75304

Cumulative Model Updates: 152,974
Cumulative Timesteps: 1,276,521,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1276521514...
Checkpoint 1276521514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,755.75299
Policy Entropy: 1.76752
Value Function Loss: 0.04363

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.30253
Value Function Update Magnitude: 0.31130

Collected Steps per Second: 21,813.55068
Overall Steps per Second: 10,618.83874

Timestep Collection Time: 2.29215
Timestep Consumption Time: 2.41646
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.70861

Cumulative Model Updates: 152,980
Cumulative Timesteps: 1,276,571,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,575.41506
Policy Entropy: 1.76596
Value Function Loss: 0.04290

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.30689
Value Function Update Magnitude: 0.31805

Collected Steps per Second: 22,017.47582
Overall Steps per Second: 10,541.20758

Timestep Collection Time: 2.27129
Timestep Consumption Time: 2.47276
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.74405

Cumulative Model Updates: 152,986
Cumulative Timesteps: 1,276,621,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1276621522...
Checkpoint 1276621522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,765.26637
Policy Entropy: 1.75541
Value Function Loss: 0.04274

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.30737
Value Function Update Magnitude: 0.30195

Collected Steps per Second: 22,122.71976
Overall Steps per Second: 10,596.73429

Timestep Collection Time: 2.26130
Timestep Consumption Time: 2.45959
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.72089

Cumulative Model Updates: 152,992
Cumulative Timesteps: 1,276,671,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,328.90152
Policy Entropy: 1.75541
Value Function Loss: 0.04068

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.30497
Value Function Update Magnitude: 0.27518

Collected Steps per Second: 22,013.04793
Overall Steps per Second: 10,456.82756

Timestep Collection Time: 2.27147
Timestep Consumption Time: 2.51029
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.78176

Cumulative Model Updates: 152,998
Cumulative Timesteps: 1,276,721,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1276721550...
Checkpoint 1276721550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,142.81046
Policy Entropy: 1.73548
Value Function Loss: 0.04184

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.30567
Value Function Update Magnitude: 0.28083

Collected Steps per Second: 21,624.19035
Overall Steps per Second: 10,527.06660

Timestep Collection Time: 2.31306
Timestep Consumption Time: 2.43831
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.75137

Cumulative Model Updates: 153,004
Cumulative Timesteps: 1,276,771,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,326.84699
Policy Entropy: 1.72496
Value Function Loss: 0.04062

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.28984
Value Function Update Magnitude: 0.27052

Collected Steps per Second: 21,732.52178
Overall Steps per Second: 10,572.67650

Timestep Collection Time: 2.30199
Timestep Consumption Time: 2.42983
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.73182

Cumulative Model Updates: 153,010
Cumulative Timesteps: 1,276,821,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1276821596...
Checkpoint 1276821596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,079.76475
Policy Entropy: 1.72637
Value Function Loss: 0.04337

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.25355
Value Function Update Magnitude: 0.29559

Collected Steps per Second: 21,270.68478
Overall Steps per Second: 10,299.20696

Timestep Collection Time: 2.35084
Timestep Consumption Time: 2.50429
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.85513

Cumulative Model Updates: 153,016
Cumulative Timesteps: 1,276,871,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,792.44121
Policy Entropy: 1.73525
Value Function Loss: 0.04478

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.26614
Value Function Update Magnitude: 0.31592

Collected Steps per Second: 22,141.15631
Overall Steps per Second: 10,511.07745

Timestep Collection Time: 2.25923
Timestep Consumption Time: 2.49975
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.75898

Cumulative Model Updates: 153,022
Cumulative Timesteps: 1,276,921,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1276921622...
Checkpoint 1276921622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,088.47223
Policy Entropy: 1.74595
Value Function Loss: 0.04613

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.28856
Value Function Update Magnitude: 0.33536

Collected Steps per Second: 21,997.56775
Overall Steps per Second: 10,399.78388

Timestep Collection Time: 2.27362
Timestep Consumption Time: 2.53552
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.80914

Cumulative Model Updates: 153,028
Cumulative Timesteps: 1,276,971,636

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,417.44684
Policy Entropy: 1.75594
Value Function Loss: 0.04886

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.31043
Value Function Update Magnitude: 0.36123

Collected Steps per Second: 21,811.63186
Overall Steps per Second: 10,521.19460

Timestep Collection Time: 2.29309
Timestep Consumption Time: 2.46074
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.75383

Cumulative Model Updates: 153,034
Cumulative Timesteps: 1,277,021,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1277021652...
Checkpoint 1277021652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,033.36401
Policy Entropy: 1.77438
Value Function Loss: 0.04834

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.31628
Value Function Update Magnitude: 0.35277

Collected Steps per Second: 21,993.14891
Overall Steps per Second: 10,651.83555

Timestep Collection Time: 2.27380
Timestep Consumption Time: 2.42098
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.69478

Cumulative Model Updates: 153,040
Cumulative Timesteps: 1,277,071,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,412.78443
Policy Entropy: 1.76694
Value Function Loss: 0.04713

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.35602

Collected Steps per Second: 22,274.46283
Overall Steps per Second: 10,528.69470

Timestep Collection Time: 2.24589
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.75140

Cumulative Model Updates: 153,046
Cumulative Timesteps: 1,277,121,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1277121686...
Checkpoint 1277121686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,703.90249
Policy Entropy: 1.75680
Value Function Loss: 0.04660

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.30963
Value Function Update Magnitude: 0.35441

Collected Steps per Second: 22,266.01746
Overall Steps per Second: 10,501.90160

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.51567
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.76142

Cumulative Model Updates: 153,052
Cumulative Timesteps: 1,277,171,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,015.43781
Policy Entropy: 1.74333
Value Function Loss: 0.04336

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.32886

Collected Steps per Second: 22,048.44927
Overall Steps per Second: 10,488.67638

Timestep Collection Time: 2.26791
Timestep Consumption Time: 2.49951
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.76743

Cumulative Model Updates: 153,058
Cumulative Timesteps: 1,277,221,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1277221694...
Checkpoint 1277221694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,273.84821
Policy Entropy: 1.73765
Value Function Loss: 0.04579

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.31589
Value Function Update Magnitude: 0.28093

Collected Steps per Second: 21,448.73551
Overall Steps per Second: 10,344.14869

Timestep Collection Time: 2.33226
Timestep Consumption Time: 2.50371
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.83597

Cumulative Model Updates: 153,064
Cumulative Timesteps: 1,277,271,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,556.02660
Policy Entropy: 1.72541
Value Function Loss: 0.04314

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.32060
Value Function Update Magnitude: 0.31121

Collected Steps per Second: 21,784.55944
Overall Steps per Second: 10,454.95746

Timestep Collection Time: 2.29594
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.78395

Cumulative Model Updates: 153,070
Cumulative Timesteps: 1,277,321,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1277321734...
Checkpoint 1277321734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,511.79912
Policy Entropy: 1.72339
Value Function Loss: 0.04271

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.31727
Value Function Update Magnitude: 0.33771

Collected Steps per Second: 21,200.37680
Overall Steps per Second: 10,420.12842

Timestep Collection Time: 2.35883
Timestep Consumption Time: 2.44035
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.79917

Cumulative Model Updates: 153,076
Cumulative Timesteps: 1,277,371,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,384.39527
Policy Entropy: 1.74389
Value Function Loss: 0.04026

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.30510
Value Function Update Magnitude: 0.34741

Collected Steps per Second: 21,641.80387
Overall Steps per Second: 10,500.45836

Timestep Collection Time: 2.31062
Timestep Consumption Time: 2.45165
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.76227

Cumulative Model Updates: 153,082
Cumulative Timesteps: 1,277,421,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1277421748...
Checkpoint 1277421748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,425.94354
Policy Entropy: 1.73949
Value Function Loss: 0.04294

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08341
Policy Update Magnitude: 0.30219
Value Function Update Magnitude: 0.34303

Collected Steps per Second: 21,396.28790
Overall Steps per Second: 10,329.09865

Timestep Collection Time: 2.33741
Timestep Consumption Time: 2.50444
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.84186

Cumulative Model Updates: 153,088
Cumulative Timesteps: 1,277,471,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,343.47579
Policy Entropy: 1.74021
Value Function Loss: 0.04380

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.30917
Value Function Update Magnitude: 0.29772

Collected Steps per Second: 22,148.51682
Overall Steps per Second: 10,432.92684

Timestep Collection Time: 2.25866
Timestep Consumption Time: 2.53635
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.79501

Cumulative Model Updates: 153,094
Cumulative Timesteps: 1,277,521,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1277521786...
Checkpoint 1277521786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,504.76459
Policy Entropy: 1.73411
Value Function Loss: 0.04853

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.31100
Value Function Update Magnitude: 0.27810

Collected Steps per Second: 21,995.90325
Overall Steps per Second: 10,462.97503

Timestep Collection Time: 2.27361
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.77971

Cumulative Model Updates: 153,100
Cumulative Timesteps: 1,277,571,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,799.03596
Policy Entropy: 1.76462
Value Function Loss: 0.04847

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.31253
Value Function Update Magnitude: 0.31296

Collected Steps per Second: 21,785.13333
Overall Steps per Second: 10,591.02202

Timestep Collection Time: 2.29560
Timestep Consumption Time: 2.42632
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.72192

Cumulative Model Updates: 153,106
Cumulative Timesteps: 1,277,621,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1277621806...
Checkpoint 1277621806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,939.40137
Policy Entropy: 1.76273
Value Function Loss: 0.04692

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.31123
Value Function Update Magnitude: 0.33664

Collected Steps per Second: 22,111.03238
Overall Steps per Second: 10,538.83381

Timestep Collection Time: 2.26186
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.74550

Cumulative Model Updates: 153,112
Cumulative Timesteps: 1,277,671,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,736.13655
Policy Entropy: 1.74645
Value Function Loss: 0.04416

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.31071
Value Function Update Magnitude: 0.33512

Collected Steps per Second: 22,240.02068
Overall Steps per Second: 10,506.87291

Timestep Collection Time: 2.24901
Timestep Consumption Time: 2.51149
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.76050

Cumulative Model Updates: 153,118
Cumulative Timesteps: 1,277,721,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1277721836...
Checkpoint 1277721836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,373.31149
Policy Entropy: 1.73593
Value Function Loss: 0.04661

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.31176
Value Function Update Magnitude: 0.33328

Collected Steps per Second: 21,990.86993
Overall Steps per Second: 10,640.93627

Timestep Collection Time: 2.27376
Timestep Consumption Time: 2.42526
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.69902

Cumulative Model Updates: 153,124
Cumulative Timesteps: 1,277,771,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,544.71069
Policy Entropy: 1.74340
Value Function Loss: 0.04409

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.31381
Value Function Update Magnitude: 0.34258

Collected Steps per Second: 21,934.47320
Overall Steps per Second: 10,462.76898

Timestep Collection Time: 2.28043
Timestep Consumption Time: 2.50033
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.78076

Cumulative Model Updates: 153,130
Cumulative Timesteps: 1,277,821,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1277821858...
Checkpoint 1277821858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,502.44765
Policy Entropy: 1.75101
Value Function Loss: 0.04333

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.31189
Value Function Update Magnitude: 0.34846

Collected Steps per Second: 21,052.41710
Overall Steps per Second: 10,265.35895

Timestep Collection Time: 2.37540
Timestep Consumption Time: 2.49613
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.87153

Cumulative Model Updates: 153,136
Cumulative Timesteps: 1,277,871,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,953.44138
Policy Entropy: 1.75965
Value Function Loss: 0.04581

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07751
Policy Update Magnitude: 0.31340
Value Function Update Magnitude: 0.36046

Collected Steps per Second: 21,592.09619
Overall Steps per Second: 10,347.27362

Timestep Collection Time: 2.31687
Timestep Consumption Time: 2.51784
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.83470

Cumulative Model Updates: 153,142
Cumulative Timesteps: 1,277,921,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1277921892...
Checkpoint 1277921892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,944.46414
Policy Entropy: 1.76331
Value Function Loss: 0.04848

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.31975
Value Function Update Magnitude: 0.36874

Collected Steps per Second: 21,606.11442
Overall Steps per Second: 10,553.80190

Timestep Collection Time: 2.31425
Timestep Consumption Time: 2.42357
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.73782

Cumulative Model Updates: 153,148
Cumulative Timesteps: 1,277,971,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,767.34919
Policy Entropy: 1.75033
Value Function Loss: 0.04590

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.31635
Value Function Update Magnitude: 0.35344

Collected Steps per Second: 21,146.91855
Overall Steps per Second: 10,531.62654

Timestep Collection Time: 2.36592
Timestep Consumption Time: 2.38472
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.75064

Cumulative Model Updates: 153,154
Cumulative Timesteps: 1,278,021,926

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1278021926...
Checkpoint 1278021926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,032.66193
Policy Entropy: 1.72852
Value Function Loss: 0.04475

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.31092
Value Function Update Magnitude: 0.33468

Collected Steps per Second: 20,753.41111
Overall Steps per Second: 10,381.71482

Timestep Collection Time: 2.41146
Timestep Consumption Time: 2.40913
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.82059

Cumulative Model Updates: 153,160
Cumulative Timesteps: 1,278,071,972

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,266.54610
Policy Entropy: 1.73083
Value Function Loss: 0.04662

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.31409
Value Function Update Magnitude: 0.33569

Collected Steps per Second: 21,290.87861
Overall Steps per Second: 10,385.61901

Timestep Collection Time: 2.34889
Timestep Consumption Time: 2.46642
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.81531

Cumulative Model Updates: 153,166
Cumulative Timesteps: 1,278,121,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1278121982...
Checkpoint 1278121982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,232.20532
Policy Entropy: 1.76544
Value Function Loss: 0.05141

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.32312
Value Function Update Magnitude: 0.37491

Collected Steps per Second: 21,352.22839
Overall Steps per Second: 10,500.89606

Timestep Collection Time: 2.34243
Timestep Consumption Time: 2.42060
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.76302

Cumulative Model Updates: 153,172
Cumulative Timesteps: 1,278,171,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,745.89935
Policy Entropy: 1.78911
Value Function Loss: 0.05287

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.32861
Value Function Update Magnitude: 0.39510

Collected Steps per Second: 21,643.14516
Overall Steps per Second: 10,514.20361

Timestep Collection Time: 2.31159
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.75833

Cumulative Model Updates: 153,178
Cumulative Timesteps: 1,278,222,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1278222028...
Checkpoint 1278222028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,064.48601
Policy Entropy: 1.79075
Value Function Loss: 0.05042

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.32514
Value Function Update Magnitude: 0.38639

Collected Steps per Second: 21,312.17622
Overall Steps per Second: 10,524.72136

Timestep Collection Time: 2.34739
Timestep Consumption Time: 2.40599
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.75338

Cumulative Model Updates: 153,184
Cumulative Timesteps: 1,278,272,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,912.36286
Policy Entropy: 1.76718
Value Function Loss: 0.04809

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.32138
Value Function Update Magnitude: 0.38461

Collected Steps per Second: 22,067.90480
Overall Steps per Second: 10,515.12791

Timestep Collection Time: 2.26573
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.75505

Cumulative Model Updates: 153,190
Cumulative Timesteps: 1,278,322,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1278322056...
Checkpoint 1278322056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,183.96238
Policy Entropy: 1.74172
Value Function Loss: 0.04449

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.31394
Value Function Update Magnitude: 0.37696

Collected Steps per Second: 21,740.10929
Overall Steps per Second: 10,608.08122

Timestep Collection Time: 2.30082
Timestep Consumption Time: 2.41446
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.71527

Cumulative Model Updates: 153,196
Cumulative Timesteps: 1,278,372,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,385.70799
Policy Entropy: 1.73865
Value Function Loss: 0.04498

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.31594
Value Function Update Magnitude: 0.37551

Collected Steps per Second: 22,115.85992
Overall Steps per Second: 10,515.08359

Timestep Collection Time: 2.26254
Timestep Consumption Time: 2.49615
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.75869

Cumulative Model Updates: 153,202
Cumulative Timesteps: 1,278,422,114

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1278422114...
Checkpoint 1278422114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,820.31951
Policy Entropy: 1.74612
Value Function Loss: 0.04539

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.36760

Collected Steps per Second: 21,357.15460
Overall Steps per Second: 10,541.74361

Timestep Collection Time: 2.34292
Timestep Consumption Time: 2.40374
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.74665

Cumulative Model Updates: 153,208
Cumulative Timesteps: 1,278,472,152

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,781.89441
Policy Entropy: 1.76098
Value Function Loss: 0.04764

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.37411

Collected Steps per Second: 21,650.07579
Overall Steps per Second: 10,526.68617

Timestep Collection Time: 2.31048
Timestep Consumption Time: 2.44145
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.75192

Cumulative Model Updates: 153,214
Cumulative Timesteps: 1,278,522,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1278522174...
Checkpoint 1278522174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,178.53876
Policy Entropy: 1.77817
Value Function Loss: 0.04763

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.31197
Value Function Update Magnitude: 0.37046

Collected Steps per Second: 21,483.46657
Overall Steps per Second: 10,576.43853

Timestep Collection Time: 2.32802
Timestep Consumption Time: 2.40079
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.72881

Cumulative Model Updates: 153,220
Cumulative Timesteps: 1,278,572,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,422.28821
Policy Entropy: 1.78104
Value Function Loss: 0.04732

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.31473
Value Function Update Magnitude: 0.37122

Collected Steps per Second: 21,675.20621
Overall Steps per Second: 10,556.94580

Timestep Collection Time: 2.30752
Timestep Consumption Time: 2.43021
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.73773

Cumulative Model Updates: 153,226
Cumulative Timesteps: 1,278,622,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1278622204...
Checkpoint 1278622204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,741.08866
Policy Entropy: 1.78652
Value Function Loss: 0.04773

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.31353
Value Function Update Magnitude: 0.38013

Collected Steps per Second: 21,726.95973
Overall Steps per Second: 10,540.85497

Timestep Collection Time: 2.30239
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.74573

Cumulative Model Updates: 153,232
Cumulative Timesteps: 1,278,672,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,514.37266
Policy Entropy: 1.79007
Value Function Loss: 0.04584

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.30693
Value Function Update Magnitude: 0.37100

Collected Steps per Second: 22,224.58292
Overall Steps per Second: 10,501.66872

Timestep Collection Time: 2.25075
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.76324

Cumulative Model Updates: 153,238
Cumulative Timesteps: 1,278,722,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1278722250...
Checkpoint 1278722250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,784.73192
Policy Entropy: 1.77329
Value Function Loss: 0.04701

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.30929
Value Function Update Magnitude: 0.36639

Collected Steps per Second: 21,900.68896
Overall Steps per Second: 10,580.33743

Timestep Collection Time: 2.28303
Timestep Consumption Time: 2.44271
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.72575

Cumulative Model Updates: 153,244
Cumulative Timesteps: 1,278,772,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,997.80136
Policy Entropy: 1.75560
Value Function Loss: 0.04463

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.31491
Value Function Update Magnitude: 0.35464

Collected Steps per Second: 22,324.56309
Overall Steps per Second: 10,527.37388

Timestep Collection Time: 2.24103
Timestep Consumption Time: 2.51134
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.75237

Cumulative Model Updates: 153,250
Cumulative Timesteps: 1,278,822,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1278822280...
Checkpoint 1278822280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,447.23083
Policy Entropy: 1.73527
Value Function Loss: 0.04353

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.30974
Value Function Update Magnitude: 0.34243

Collected Steps per Second: 21,966.99530
Overall Steps per Second: 10,627.36653

Timestep Collection Time: 2.27660
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.70578

Cumulative Model Updates: 153,256
Cumulative Timesteps: 1,278,872,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,902.86862
Policy Entropy: 1.74935
Value Function Loss: 0.04282

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.30748
Value Function Update Magnitude: 0.32132

Collected Steps per Second: 22,190.26484
Overall Steps per Second: 10,486.70235

Timestep Collection Time: 2.25432
Timestep Consumption Time: 2.51591
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.77023

Cumulative Model Updates: 153,262
Cumulative Timesteps: 1,278,922,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1278922314...
Checkpoint 1278922314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,844.73071
Policy Entropy: 1.74991
Value Function Loss: 0.04513

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.31140
Value Function Update Magnitude: 0.31705

Collected Steps per Second: 21,618.84848
Overall Steps per Second: 10,546.71192

Timestep Collection Time: 2.31409
Timestep Consumption Time: 2.42938
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.74347

Cumulative Model Updates: 153,268
Cumulative Timesteps: 1,278,972,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,183.11011
Policy Entropy: 1.74795
Value Function Loss: 0.04653

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.31625
Value Function Update Magnitude: 0.33131

Collected Steps per Second: 21,794.67029
Overall Steps per Second: 10,615.24311

Timestep Collection Time: 2.29616
Timestep Consumption Time: 2.41820
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.71435

Cumulative Model Updates: 153,274
Cumulative Timesteps: 1,279,022,386

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1279022386...
Checkpoint 1279022386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,009.58322
Policy Entropy: 1.74901
Value Function Loss: 0.04730

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08087
Policy Update Magnitude: 0.31575
Value Function Update Magnitude: 0.34460

Collected Steps per Second: 21,413.34500
Overall Steps per Second: 10,504.42631

Timestep Collection Time: 2.33527
Timestep Consumption Time: 2.42520
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.76047

Cumulative Model Updates: 153,280
Cumulative Timesteps: 1,279,072,392

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,641.80579
Policy Entropy: 1.74705
Value Function Loss: 0.04320

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.31619
Value Function Update Magnitude: 0.34241

Collected Steps per Second: 21,821.94475
Overall Steps per Second: 10,475.50120

Timestep Collection Time: 2.29164
Timestep Consumption Time: 2.48217
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.77381

Cumulative Model Updates: 153,286
Cumulative Timesteps: 1,279,122,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1279122400...
Checkpoint 1279122400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,024.40318
Policy Entropy: 1.73953
Value Function Loss: 0.04764

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.31548
Value Function Update Magnitude: 0.33746

Collected Steps per Second: 21,545.31924
Overall Steps per Second: 10,361.50134

Timestep Collection Time: 2.32143
Timestep Consumption Time: 2.50567
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.82710

Cumulative Model Updates: 153,292
Cumulative Timesteps: 1,279,172,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,904.67233
Policy Entropy: 1.75235
Value Function Loss: 0.04446

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.31290
Value Function Update Magnitude: 0.33115

Collected Steps per Second: 22,019.96981
Overall Steps per Second: 10,436.66999

Timestep Collection Time: 2.27085
Timestep Consumption Time: 2.52034
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.79118

Cumulative Model Updates: 153,298
Cumulative Timesteps: 1,279,222,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1279222420...
Checkpoint 1279222420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,937.87137
Policy Entropy: 1.74965
Value Function Loss: 0.04668

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.31062
Value Function Update Magnitude: 0.31629

Collected Steps per Second: 21,808.89427
Overall Steps per Second: 10,464.24560

Timestep Collection Time: 2.29429
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.78162

Cumulative Model Updates: 153,304
Cumulative Timesteps: 1,279,272,456

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,498.20188
Policy Entropy: 1.75507
Value Function Loss: 0.04344

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.30653
Value Function Update Magnitude: 0.33084

Collected Steps per Second: 22,185.65679
Overall Steps per Second: 10,486.36610

Timestep Collection Time: 2.25380
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.76829

Cumulative Model Updates: 153,310
Cumulative Timesteps: 1,279,322,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1279322458...
Checkpoint 1279322458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,164.03075
Policy Entropy: 1.75197
Value Function Loss: 0.04507

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.29894
Value Function Update Magnitude: 0.35025

Collected Steps per Second: 21,912.18954
Overall Steps per Second: 10,584.56815

Timestep Collection Time: 2.28202
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.72424

Cumulative Model Updates: 153,316
Cumulative Timesteps: 1,279,372,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,131.24981
Policy Entropy: 1.77162
Value Function Loss: 0.04833

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.31816
Value Function Update Magnitude: 0.36757

Collected Steps per Second: 22,063.26461
Overall Steps per Second: 10,512.02025

Timestep Collection Time: 2.26694
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.75798

Cumulative Model Updates: 153,322
Cumulative Timesteps: 1,279,422,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1279422478...
Checkpoint 1279422478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,794.57306
Policy Entropy: 1.77635
Value Function Loss: 0.04901

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.32332
Value Function Update Magnitude: 0.37883

Collected Steps per Second: 21,322.20341
Overall Steps per Second: 10,209.05831

Timestep Collection Time: 2.34572
Timestep Consumption Time: 2.55345
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.89918

Cumulative Model Updates: 153,328
Cumulative Timesteps: 1,279,472,494

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,865.10725
Policy Entropy: 1.75126
Value Function Loss: 0.04567

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.32405
Value Function Update Magnitude: 0.36423

Collected Steps per Second: 22,288.44755
Overall Steps per Second: 10,569.85203

Timestep Collection Time: 2.24439
Timestep Consumption Time: 2.48831
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.73271

Cumulative Model Updates: 153,334
Cumulative Timesteps: 1,279,522,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1279522518...
Checkpoint 1279522518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,475.45801
Policy Entropy: 1.74440
Value Function Loss: 0.04521

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.32211
Value Function Update Magnitude: 0.34752

Collected Steps per Second: 21,031.17854
Overall Steps per Second: 10,489.79144

Timestep Collection Time: 2.37866
Timestep Consumption Time: 2.39036
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.76902

Cumulative Model Updates: 153,340
Cumulative Timesteps: 1,279,572,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,787.15444
Policy Entropy: 1.74929
Value Function Loss: 0.04866

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.32747

Collected Steps per Second: 21,106.99259
Overall Steps per Second: 10,465.74576

Timestep Collection Time: 2.37078
Timestep Consumption Time: 2.41053
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.78131

Cumulative Model Updates: 153,346
Cumulative Timesteps: 1,279,622,584

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1279622584...
Checkpoint 1279622584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,652.83423
Policy Entropy: 1.75776
Value Function Loss: 0.05077

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.30573
Value Function Update Magnitude: 0.27642

Collected Steps per Second: 20,980.07472
Overall Steps per Second: 10,573.53624

Timestep Collection Time: 2.38445
Timestep Consumption Time: 2.34679
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.73125

Cumulative Model Updates: 153,352
Cumulative Timesteps: 1,279,672,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,377.81658
Policy Entropy: 1.74631
Value Function Loss: 0.05027

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.30166
Value Function Update Magnitude: 0.31219

Collected Steps per Second: 21,178.67353
Overall Steps per Second: 10,476.91689

Timestep Collection Time: 2.36219
Timestep Consumption Time: 2.41288
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.77507

Cumulative Model Updates: 153,358
Cumulative Timesteps: 1,279,722,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1279722638...
Checkpoint 1279722638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,044.74979
Policy Entropy: 1.72129
Value Function Loss: 0.04666

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.31413
Value Function Update Magnitude: 0.33729

Collected Steps per Second: 21,440.66582
Overall Steps per Second: 10,397.70278

Timestep Collection Time: 2.33314
Timestep Consumption Time: 2.47793
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.81106

Cumulative Model Updates: 153,364
Cumulative Timesteps: 1,279,772,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,558.08897
Policy Entropy: 1.72951
Value Function Loss: 0.04469

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.31446
Value Function Update Magnitude: 0.31680

Collected Steps per Second: 22,422.94126
Overall Steps per Second: 10,736.53405

Timestep Collection Time: 2.23013
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.65756

Cumulative Model Updates: 153,370
Cumulative Timesteps: 1,279,822,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1279822668...
Checkpoint 1279822668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,487.90078
Policy Entropy: 1.75702
Value Function Loss: 0.04439

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.31076
Value Function Update Magnitude: 0.31723

Collected Steps per Second: 22,060.56432
Overall Steps per Second: 10,671.73107

Timestep Collection Time: 2.26739
Timestep Consumption Time: 2.41976
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.68715

Cumulative Model Updates: 153,376
Cumulative Timesteps: 1,279,872,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,303.14840
Policy Entropy: 1.78090
Value Function Loss: 0.04751

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.31010
Value Function Update Magnitude: 0.33695

Collected Steps per Second: 22,071.64617
Overall Steps per Second: 10,436.28632

Timestep Collection Time: 2.26707
Timestep Consumption Time: 2.52755
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.79462

Cumulative Model Updates: 153,382
Cumulative Timesteps: 1,279,922,726

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1279922726...
Checkpoint 1279922726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,585.81540
Policy Entropy: 1.79326
Value Function Loss: 0.05051

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.32002
Value Function Update Magnitude: 0.34849

Collected Steps per Second: 22,084.36228
Overall Steps per Second: 10,611.38786

Timestep Collection Time: 2.26441
Timestep Consumption Time: 2.44827
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.71267

Cumulative Model Updates: 153,388
Cumulative Timesteps: 1,279,972,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,187.33658
Policy Entropy: 1.78387
Value Function Loss: 0.04892

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.31800
Value Function Update Magnitude: 0.34681

Collected Steps per Second: 22,010.28179
Overall Steps per Second: 10,465.61414

Timestep Collection Time: 2.27194
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.77812

Cumulative Model Updates: 153,394
Cumulative Timesteps: 1,280,022,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1280022740...
Checkpoint 1280022740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,526.61422
Policy Entropy: 1.78145
Value Function Loss: 0.04907

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.31624
Value Function Update Magnitude: 0.33001

Collected Steps per Second: 21,874.40405
Overall Steps per Second: 10,602.44760

Timestep Collection Time: 2.28678
Timestep Consumption Time: 2.43118
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.71797

Cumulative Model Updates: 153,400
Cumulative Timesteps: 1,280,072,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,842.32999
Policy Entropy: 1.75500
Value Function Loss: 0.04637

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.31488
Value Function Update Magnitude: 0.32858

Collected Steps per Second: 21,712.96389
Overall Steps per Second: 10,483.10429

Timestep Collection Time: 2.30314
Timestep Consumption Time: 2.46720
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.77034

Cumulative Model Updates: 153,406
Cumulative Timesteps: 1,280,122,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1280122770...
Checkpoint 1280122770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,910.14919
Policy Entropy: 1.75547
Value Function Loss: 0.04513

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.31428
Value Function Update Magnitude: 0.33358

Collected Steps per Second: 21,476.37496
Overall Steps per Second: 10,358.46584

Timestep Collection Time: 2.32870
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.82813

Cumulative Model Updates: 153,412
Cumulative Timesteps: 1,280,172,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,479.48171
Policy Entropy: 1.75003
Value Function Loss: 0.04316

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.30303
Value Function Update Magnitude: 0.33739

Collected Steps per Second: 21,802.62420
Overall Steps per Second: 10,451.72853

Timestep Collection Time: 2.29495
Timestep Consumption Time: 2.49239
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.78734

Cumulative Model Updates: 153,418
Cumulative Timesteps: 1,280,222,818

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1280222818...
Checkpoint 1280222818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,217.01136
Policy Entropy: 1.76150
Value Function Loss: 0.04459

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.28502
Value Function Update Magnitude: 0.33102

Collected Steps per Second: 21,861.41254
Overall Steps per Second: 10,488.31437

Timestep Collection Time: 2.28851
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.77007

Cumulative Model Updates: 153,424
Cumulative Timesteps: 1,280,272,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,483.39773
Policy Entropy: 1.76831
Value Function Loss: 0.04746

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.29072
Value Function Update Magnitude: 0.32406

Collected Steps per Second: 21,887.12231
Overall Steps per Second: 10,424.22761

Timestep Collection Time: 2.28664
Timestep Consumption Time: 2.51448
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.80112

Cumulative Model Updates: 153,430
Cumulative Timesteps: 1,280,322,896

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1280322896...
Checkpoint 1280322896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,702.45134
Policy Entropy: 1.77240
Value Function Loss: 0.05116

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.28720
Value Function Update Magnitude: 0.34601

Collected Steps per Second: 21,697.55196
Overall Steps per Second: 10,547.61738

Timestep Collection Time: 2.30570
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.74306

Cumulative Model Updates: 153,436
Cumulative Timesteps: 1,280,372,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,851.28478
Policy Entropy: 1.78718
Value Function Loss: 0.05360

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.30877
Value Function Update Magnitude: 0.38085

Collected Steps per Second: 21,980.57106
Overall Steps per Second: 10,623.69444

Timestep Collection Time: 2.27619
Timestep Consumption Time: 2.43328
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.70947

Cumulative Model Updates: 153,442
Cumulative Timesteps: 1,280,422,956

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1280422956...
Checkpoint 1280422956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,514.09478
Policy Entropy: 1.78533
Value Function Loss: 0.04816

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.31682
Value Function Update Magnitude: 0.37415

Collected Steps per Second: 21,778.94230
Overall Steps per Second: 10,649.93119

Timestep Collection Time: 2.29607
Timestep Consumption Time: 2.39936
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.69543

Cumulative Model Updates: 153,448
Cumulative Timesteps: 1,280,472,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,814.73140
Policy Entropy: 1.77885
Value Function Loss: 0.04577

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.29023
Value Function Update Magnitude: 0.36329

Collected Steps per Second: 21,970.61132
Overall Steps per Second: 10,429.02502

Timestep Collection Time: 2.27650
Timestep Consumption Time: 2.51935
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.79585

Cumulative Model Updates: 153,454
Cumulative Timesteps: 1,280,522,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1280522978...
Checkpoint 1280522978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,687.32295
Policy Entropy: 1.75829
Value Function Loss: 0.04053

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.29108
Value Function Update Magnitude: 0.35643

Collected Steps per Second: 21,755.66304
Overall Steps per Second: 10,535.50527

Timestep Collection Time: 2.29862
Timestep Consumption Time: 2.44800
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.74662

Cumulative Model Updates: 153,460
Cumulative Timesteps: 1,280,572,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,222.10368
Policy Entropy: 1.75883
Value Function Loss: 0.04330

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.30040
Value Function Update Magnitude: 0.34468

Collected Steps per Second: 21,880.07270
Overall Steps per Second: 10,486.62050

Timestep Collection Time: 2.28564
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.76893

Cumulative Model Updates: 153,466
Cumulative Timesteps: 1,280,622,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1280622996...
Checkpoint 1280622996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,305.17210
Policy Entropy: 1.77606
Value Function Loss: 0.04773

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.31145
Value Function Update Magnitude: 0.32788

Collected Steps per Second: 21,555.91785
Overall Steps per Second: 10,371.50478

Timestep Collection Time: 2.32131
Timestep Consumption Time: 2.50325
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.82457

Cumulative Model Updates: 153,472
Cumulative Timesteps: 1,280,673,034

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,808.43350
Policy Entropy: 1.78379
Value Function Loss: 0.04943

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.31431
Value Function Update Magnitude: 0.34618

Collected Steps per Second: 21,586.73089
Overall Steps per Second: 10,326.13031

Timestep Collection Time: 2.31698
Timestep Consumption Time: 2.52666
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.84363

Cumulative Model Updates: 153,478
Cumulative Timesteps: 1,280,723,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1280723050...
Checkpoint 1280723050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,409.87434
Policy Entropy: 1.77968
Value Function Loss: 0.05141

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.31716
Value Function Update Magnitude: 0.36010

Collected Steps per Second: 21,611.61226
Overall Steps per Second: 10,365.73543

Timestep Collection Time: 2.31394
Timestep Consumption Time: 2.51042
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.82436

Cumulative Model Updates: 153,484
Cumulative Timesteps: 1,280,773,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,697.76962
Policy Entropy: 1.76864
Value Function Loss: 0.04544

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.31430
Value Function Update Magnitude: 0.36825

Collected Steps per Second: 22,144.73454
Overall Steps per Second: 10,454.66200

Timestep Collection Time: 2.25860
Timestep Consumption Time: 2.52549
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.78409

Cumulative Model Updates: 153,490
Cumulative Timesteps: 1,280,823,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1280823074...
Checkpoint 1280823074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,266.92841
Policy Entropy: 1.76785
Value Function Loss: 0.04925

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.30243
Value Function Update Magnitude: 0.35722

Collected Steps per Second: 21,346.80973
Overall Steps per Second: 10,379.33959

Timestep Collection Time: 2.34302
Timestep Consumption Time: 2.47578
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.81880

Cumulative Model Updates: 153,496
Cumulative Timesteps: 1,280,873,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,126.86021
Policy Entropy: 1.76377
Value Function Loss: 0.04577

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.28627
Value Function Update Magnitude: 0.35982

Collected Steps per Second: 21,007.83263
Overall Steps per Second: 10,110.08376

Timestep Collection Time: 2.38159
Timestep Consumption Time: 2.56713
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.94872

Cumulative Model Updates: 153,502
Cumulative Timesteps: 1,280,923,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1280923122...
Checkpoint 1280923122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,686.30772
Policy Entropy: 1.77399
Value Function Loss: 0.05115

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.31121
Value Function Update Magnitude: 0.34078

Collected Steps per Second: 20,415.71172
Overall Steps per Second: 10,129.14447

Timestep Collection Time: 2.45056
Timestep Consumption Time: 2.48865
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.93921

Cumulative Model Updates: 153,508
Cumulative Timesteps: 1,280,973,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,089.38696
Policy Entropy: 1.76742
Value Function Loss: 0.04584

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.31630
Value Function Update Magnitude: 0.28379

Collected Steps per Second: 20,570.16629
Overall Steps per Second: 10,189.86579

Timestep Collection Time: 2.43207
Timestep Consumption Time: 2.47752
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.90958

Cumulative Model Updates: 153,514
Cumulative Timesteps: 1,281,023,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1281023180...
Checkpoint 1281023180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,583.29814
Policy Entropy: 1.76658
Value Function Loss: 0.04306

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.30843
Value Function Update Magnitude: 0.25798

Collected Steps per Second: 22,075.91069
Overall Steps per Second: 10,562.63977

Timestep Collection Time: 2.26555
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.73499

Cumulative Model Updates: 153,520
Cumulative Timesteps: 1,281,073,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,578.13585
Policy Entropy: 1.77762
Value Function Loss: 0.04154

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.30567
Value Function Update Magnitude: 0.30135

Collected Steps per Second: 21,767.86449
Overall Steps per Second: 10,451.41355

Timestep Collection Time: 2.29761
Timestep Consumption Time: 2.48777
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.78538

Cumulative Model Updates: 153,526
Cumulative Timesteps: 1,281,123,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1281123208...
Checkpoint 1281123208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,426.10400
Policy Entropy: 1.78551
Value Function Loss: 0.04524

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.31237
Value Function Update Magnitude: 0.33172

Collected Steps per Second: 21,868.09340
Overall Steps per Second: 10,613.90821

Timestep Collection Time: 2.28726
Timestep Consumption Time: 2.42524
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.71250

Cumulative Model Updates: 153,532
Cumulative Timesteps: 1,281,173,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,485.31776
Policy Entropy: 1.78167
Value Function Loss: 0.04482

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07720
Policy Update Magnitude: 0.31521
Value Function Update Magnitude: 0.33319

Collected Steps per Second: 21,320.90256
Overall Steps per Second: 10,444.70600

Timestep Collection Time: 2.34549
Timestep Consumption Time: 2.44239
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.78788

Cumulative Model Updates: 153,538
Cumulative Timesteps: 1,281,223,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1281223234...
Checkpoint 1281223234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,720.65999
Policy Entropy: 1.76937
Value Function Loss: 0.04506

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.31810
Value Function Update Magnitude: 0.34212

Collected Steps per Second: 21,572.29635
Overall Steps per Second: 10,376.03629

Timestep Collection Time: 2.31816
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.81957

Cumulative Model Updates: 153,544
Cumulative Timesteps: 1,281,273,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,137.45316
Policy Entropy: 1.76980
Value Function Loss: 0.04439

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.31466
Value Function Update Magnitude: 0.33679

Collected Steps per Second: 21,671.68519
Overall Steps per Second: 10,371.82127

Timestep Collection Time: 2.30928
Timestep Consumption Time: 2.51591
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.82519

Cumulative Model Updates: 153,550
Cumulative Timesteps: 1,281,323,288

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1281323288...
Checkpoint 1281323288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,329.40209
Policy Entropy: 1.77220
Value Function Loss: 0.04172

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.31267
Value Function Update Magnitude: 0.34947

Collected Steps per Second: 21,149.15990
Overall Steps per Second: 10,275.48454

Timestep Collection Time: 2.36444
Timestep Consumption Time: 2.50209
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.86653

Cumulative Model Updates: 153,556
Cumulative Timesteps: 1,281,373,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,837.05243
Policy Entropy: 1.78340
Value Function Loss: 0.04350

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.31069
Value Function Update Magnitude: 0.33827

Collected Steps per Second: 21,557.01814
Overall Steps per Second: 10,369.95437

Timestep Collection Time: 2.32045
Timestep Consumption Time: 2.50329
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.82374

Cumulative Model Updates: 153,562
Cumulative Timesteps: 1,281,423,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1281423316...
Checkpoint 1281423316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,372.99542
Policy Entropy: 1.77045
Value Function Loss: 0.04289

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.31437
Value Function Update Magnitude: 0.32541

Collected Steps per Second: 21,549.81878
Overall Steps per Second: 10,557.81698

Timestep Collection Time: 2.32104
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.73753

Cumulative Model Updates: 153,568
Cumulative Timesteps: 1,281,473,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,601.47999
Policy Entropy: 1.78191
Value Function Loss: 0.04534

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07808
Policy Update Magnitude: 0.31742
Value Function Update Magnitude: 0.32310

Collected Steps per Second: 21,481.04736
Overall Steps per Second: 10,475.85558

Timestep Collection Time: 2.32856
Timestep Consumption Time: 2.44622
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.77479

Cumulative Model Updates: 153,574
Cumulative Timesteps: 1,281,523,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1281523354...
Checkpoint 1281523354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,264.63053
Policy Entropy: 1.77165
Value Function Loss: 0.04714

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.31859
Value Function Update Magnitude: 0.35787

Collected Steps per Second: 21,895.05302
Overall Steps per Second: 10,369.49709

Timestep Collection Time: 2.28572
Timestep Consumption Time: 2.54055
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.82627

Cumulative Model Updates: 153,580
Cumulative Timesteps: 1,281,573,400

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,481.40054
Policy Entropy: 1.76748
Value Function Loss: 0.04688

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.31990
Value Function Update Magnitude: 0.34795

Collected Steps per Second: 21,709.98603
Overall Steps per Second: 10,727.11869

Timestep Collection Time: 2.30419
Timestep Consumption Time: 2.35913
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.66332

Cumulative Model Updates: 153,586
Cumulative Timesteps: 1,281,623,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1281623424...
Checkpoint 1281623424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,160.03405
Policy Entropy: 1.75397
Value Function Loss: 0.04530

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.31539
Value Function Update Magnitude: 0.32666

Collected Steps per Second: 21,072.09698
Overall Steps per Second: 10,424.66597

Timestep Collection Time: 2.37290
Timestep Consumption Time: 2.42361
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.79651

Cumulative Model Updates: 153,592
Cumulative Timesteps: 1,281,673,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,839.61578
Policy Entropy: 1.76096
Value Function Loss: 0.04514

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.31332
Value Function Update Magnitude: 0.32974

Collected Steps per Second: 21,495.77643
Overall Steps per Second: 10,662.09913

Timestep Collection Time: 2.32641
Timestep Consumption Time: 2.36385
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.69026

Cumulative Model Updates: 153,598
Cumulative Timesteps: 1,281,723,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1281723434...
Checkpoint 1281723434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,976.37941
Policy Entropy: 1.77216
Value Function Loss: 0.04328

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.30662
Value Function Update Magnitude: 0.32512

Collected Steps per Second: 21,147.08472
Overall Steps per Second: 10,602.43197

Timestep Collection Time: 2.36477
Timestep Consumption Time: 2.35188
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.71665

Cumulative Model Updates: 153,604
Cumulative Timesteps: 1,281,773,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,961.89676
Policy Entropy: 1.77956
Value Function Loss: 0.04593

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.30451
Value Function Update Magnitude: 0.32400

Collected Steps per Second: 21,446.17252
Overall Steps per Second: 10,565.45936

Timestep Collection Time: 2.33151
Timestep Consumption Time: 2.40108
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.73259

Cumulative Model Updates: 153,610
Cumulative Timesteps: 1,281,823,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1281823444...
Checkpoint 1281823444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,485.25147
Policy Entropy: 1.78243
Value Function Loss: 0.04482

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.31088
Value Function Update Magnitude: 0.32875

Collected Steps per Second: 21,466.06108
Overall Steps per Second: 10,565.87211

Timestep Collection Time: 2.33038
Timestep Consumption Time: 2.40411
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.73449

Cumulative Model Updates: 153,616
Cumulative Timesteps: 1,281,873,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,946.35572
Policy Entropy: 1.77651
Value Function Loss: 0.04569

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.31305
Value Function Update Magnitude: 0.33786

Collected Steps per Second: 21,527.70779
Overall Steps per Second: 10,573.42799

Timestep Collection Time: 2.32268
Timestep Consumption Time: 2.40634
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.72902

Cumulative Model Updates: 153,622
Cumulative Timesteps: 1,281,923,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1281923470...
Checkpoint 1281923470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,865.20632
Policy Entropy: 1.77218
Value Function Loss: 0.04899

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.32068
Value Function Update Magnitude: 0.35503

Collected Steps per Second: 21,327.91570
Overall Steps per Second: 10,571.22178

Timestep Collection Time: 2.34631
Timestep Consumption Time: 2.38748
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.73380

Cumulative Model Updates: 153,628
Cumulative Timesteps: 1,281,973,512

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,820.47553
Policy Entropy: 1.76678
Value Function Loss: 0.04631

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.32279
Value Function Update Magnitude: 0.36030

Collected Steps per Second: 21,863.92591
Overall Steps per Second: 10,479.00246

Timestep Collection Time: 2.28760
Timestep Consumption Time: 2.48537
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.77297

Cumulative Model Updates: 153,634
Cumulative Timesteps: 1,282,023,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1282023528...
Checkpoint 1282023528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,706.45325
Policy Entropy: 1.76940
Value Function Loss: 0.04840

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.31494
Value Function Update Magnitude: 0.34779

Collected Steps per Second: 21,758.11597
Overall Steps per Second: 10,574.33308

Timestep Collection Time: 2.29900
Timestep Consumption Time: 2.43151
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.73051

Cumulative Model Updates: 153,640
Cumulative Timesteps: 1,282,073,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,849.90470
Policy Entropy: 1.78812
Value Function Loss: 0.04597

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.30999
Value Function Update Magnitude: 0.33994

Collected Steps per Second: 22,218.13834
Overall Steps per Second: 10,507.23620

Timestep Collection Time: 2.25221
Timestep Consumption Time: 2.51022
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.76243

Cumulative Model Updates: 153,646
Cumulative Timesteps: 1,282,123,590

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1282123590...
Checkpoint 1282123590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,499.72630
Policy Entropy: 1.79796
Value Function Loss: 0.04831

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.31437
Value Function Update Magnitude: 0.36072

Collected Steps per Second: 21,694.98289
Overall Steps per Second: 10,562.97011

Timestep Collection Time: 2.30551
Timestep Consumption Time: 2.42971
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.73522

Cumulative Model Updates: 153,652
Cumulative Timesteps: 1,282,173,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,570.27770
Policy Entropy: 1.79339
Value Function Loss: 0.04607

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.31459
Value Function Update Magnitude: 0.38138

Collected Steps per Second: 21,935.70784
Overall Steps per Second: 10,608.61545

Timestep Collection Time: 2.28085
Timestep Consumption Time: 2.43532
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.71617

Cumulative Model Updates: 153,658
Cumulative Timesteps: 1,282,223,640

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1282223640...
Checkpoint 1282223640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,734.73889
Policy Entropy: 1.79555
Value Function Loss: 0.04414

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.30913
Value Function Update Magnitude: 0.35515

Collected Steps per Second: 21,997.94787
Overall Steps per Second: 10,578.57067

Timestep Collection Time: 2.27403
Timestep Consumption Time: 2.45477
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.72881

Cumulative Model Updates: 153,664
Cumulative Timesteps: 1,282,273,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,558.92861
Policy Entropy: 1.77807
Value Function Loss: 0.04469

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.33424

Collected Steps per Second: 22,336.50887
Overall Steps per Second: 10,526.46333

Timestep Collection Time: 2.23920
Timestep Consumption Time: 2.51225
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.75145

Cumulative Model Updates: 153,670
Cumulative Timesteps: 1,282,323,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1282323680...
Checkpoint 1282323680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,061.48147
Policy Entropy: 1.76282
Value Function Loss: 0.04122

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.30264
Value Function Update Magnitude: 0.31166

Collected Steps per Second: 21,716.63003
Overall Steps per Second: 10,537.17487

Timestep Collection Time: 2.30257
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.74548

Cumulative Model Updates: 153,676
Cumulative Timesteps: 1,282,373,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,754.63075
Policy Entropy: 1.75576
Value Function Loss: 0.04231

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.29881
Value Function Update Magnitude: 0.29763

Collected Steps per Second: 22,068.48569
Overall Steps per Second: 10,441.92048

Timestep Collection Time: 2.26749
Timestep Consumption Time: 2.52474
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.79222

Cumulative Model Updates: 153,682
Cumulative Timesteps: 1,282,423,724

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1282423724...
Checkpoint 1282423724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,460.18427
Policy Entropy: 1.76416
Value Function Loss: 0.04144

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.29993
Value Function Update Magnitude: 0.28772

Collected Steps per Second: 21,185.71924
Overall Steps per Second: 10,271.31660

Timestep Collection Time: 2.36112
Timestep Consumption Time: 2.50895
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.87007

Cumulative Model Updates: 153,688
Cumulative Timesteps: 1,282,473,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,675.57951
Policy Entropy: 1.77902
Value Function Loss: 0.04451

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.30147
Value Function Update Magnitude: 0.27908

Collected Steps per Second: 21,792.99539
Overall Steps per Second: 10,419.03735

Timestep Collection Time: 2.29523
Timestep Consumption Time: 2.50559
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.80083

Cumulative Model Updates: 153,694
Cumulative Timesteps: 1,282,523,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1282523766...
Checkpoint 1282523766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,235.02150
Policy Entropy: 1.77772
Value Function Loss: 0.04611

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.30746
Value Function Update Magnitude: 0.29271

Collected Steps per Second: 21,267.29924
Overall Steps per Second: 10,313.37085

Timestep Collection Time: 2.35206
Timestep Consumption Time: 2.49815
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.85021

Cumulative Model Updates: 153,700
Cumulative Timesteps: 1,282,573,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,700.76108
Policy Entropy: 1.76287
Value Function Loss: 0.04452

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.32491

Collected Steps per Second: 21,821.06379
Overall Steps per Second: 10,426.56821

Timestep Collection Time: 2.29136
Timestep Consumption Time: 2.50408
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.79544

Cumulative Model Updates: 153,706
Cumulative Timesteps: 1,282,623,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1282623788...
Checkpoint 1282623788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,440.17510
Policy Entropy: 1.77874
Value Function Loss: 0.04373

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.30532
Value Function Update Magnitude: 0.34031

Collected Steps per Second: 20,998.23028
Overall Steps per Second: 10,583.80706

Timestep Collection Time: 2.38230
Timestep Consumption Time: 2.34417
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.72647

Cumulative Model Updates: 153,712
Cumulative Timesteps: 1,282,673,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,932.67371
Policy Entropy: 1.78594
Value Function Loss: 0.04012

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.30046
Value Function Update Magnitude: 0.33453

Collected Steps per Second: 21,674.34558
Overall Steps per Second: 10,497.79943

Timestep Collection Time: 2.30881
Timestep Consumption Time: 2.45809
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.76690

Cumulative Model Updates: 153,718
Cumulative Timesteps: 1,282,723,854

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1282723854...
Checkpoint 1282723854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,321.69459
Policy Entropy: 1.79077
Value Function Loss: 0.03915

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.29651
Value Function Update Magnitude: 0.32030

Collected Steps per Second: 21,066.68860
Overall Steps per Second: 10,516.35470

Timestep Collection Time: 2.37484
Timestep Consumption Time: 2.38251
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.75735

Cumulative Model Updates: 153,724
Cumulative Timesteps: 1,282,773,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,681.92242
Policy Entropy: 1.79075
Value Function Loss: 0.03781

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.29317
Value Function Update Magnitude: 0.30558

Collected Steps per Second: 21,454.16857
Overall Steps per Second: 10,483.82125

Timestep Collection Time: 2.33176
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.77173

Cumulative Model Updates: 153,730
Cumulative Timesteps: 1,282,823,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1282823910...
Checkpoint 1282823910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,886.75244
Policy Entropy: 1.78050
Value Function Loss: 0.03859

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.29622
Value Function Update Magnitude: 0.30784

Collected Steps per Second: 21,371.32848
Overall Steps per Second: 10,686.80597

Timestep Collection Time: 2.34099
Timestep Consumption Time: 2.34049
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.68147

Cumulative Model Updates: 153,736
Cumulative Timesteps: 1,282,873,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,900.24261
Policy Entropy: 1.77888
Value Function Loss: 0.04126

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.30726
Value Function Update Magnitude: 0.33575

Collected Steps per Second: 21,830.86995
Overall Steps per Second: 10,453.99977

Timestep Collection Time: 2.29070
Timestep Consumption Time: 2.49292
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.78362

Cumulative Model Updates: 153,742
Cumulative Timesteps: 1,282,923,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1282923948...
Checkpoint 1282923948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,441.39471
Policy Entropy: 1.75896
Value Function Loss: 0.04031

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.30734
Value Function Update Magnitude: 0.35337

Collected Steps per Second: 21,694.33794
Overall Steps per Second: 10,599.28123

Timestep Collection Time: 2.30595
Timestep Consumption Time: 2.41381
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.71975

Cumulative Model Updates: 153,748
Cumulative Timesteps: 1,282,973,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,459.87754
Policy Entropy: 1.74338
Value Function Loss: 0.03928

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.30416
Value Function Update Magnitude: 0.32014

Collected Steps per Second: 22,191.59782
Overall Steps per Second: 10,572.88791

Timestep Collection Time: 2.25310
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.72908

Cumulative Model Updates: 153,754
Cumulative Timesteps: 1,283,023,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1283023974...
Checkpoint 1283023974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,868.00321
Policy Entropy: 1.75145
Value Function Loss: 0.04201

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.30638
Value Function Update Magnitude: 0.28800

Collected Steps per Second: 21,546.87265
Overall Steps per Second: 10,595.69801

Timestep Collection Time: 2.32154
Timestep Consumption Time: 2.39943
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.72097

Cumulative Model Updates: 153,760
Cumulative Timesteps: 1,283,073,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,139.66368
Policy Entropy: 1.76373
Value Function Loss: 0.04407

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.30657
Value Function Update Magnitude: 0.31730

Collected Steps per Second: 21,730.87067
Overall Steps per Second: 10,383.01002

Timestep Collection Time: 2.30189
Timestep Consumption Time: 2.51579
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.81768

Cumulative Model Updates: 153,766
Cumulative Timesteps: 1,283,124,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1283124018...
Checkpoint 1283124018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,430.63117
Policy Entropy: 1.75950
Value Function Loss: 0.04753

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.30897
Value Function Update Magnitude: 0.34253

Collected Steps per Second: 21,632.10435
Overall Steps per Second: 10,545.28277

Timestep Collection Time: 2.31258
Timestep Consumption Time: 2.43134
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.74392

Cumulative Model Updates: 153,772
Cumulative Timesteps: 1,283,174,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,782.81849
Policy Entropy: 1.76403
Value Function Loss: 0.04826

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.31329
Value Function Update Magnitude: 0.33740

Collected Steps per Second: 21,590.06500
Overall Steps per Second: 10,489.19903

Timestep Collection Time: 2.31690
Timestep Consumption Time: 2.45201
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.76891

Cumulative Model Updates: 153,778
Cumulative Timesteps: 1,283,224,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1283224066...
Checkpoint 1283224066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,397.03578
Policy Entropy: 1.76154
Value Function Loss: 0.05067

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.31310
Value Function Update Magnitude: 0.31995

Collected Steps per Second: 21,409.98425
Overall Steps per Second: 10,336.72996

Timestep Collection Time: 2.33713
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.84080

Cumulative Model Updates: 153,784
Cumulative Timesteps: 1,283,274,104

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,659.79188
Policy Entropy: 1.76984
Value Function Loss: 0.04781

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.31168
Value Function Update Magnitude: 0.34306

Collected Steps per Second: 22,242.33918
Overall Steps per Second: 10,448.23099

Timestep Collection Time: 2.24797
Timestep Consumption Time: 2.53753
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.78550

Cumulative Model Updates: 153,790
Cumulative Timesteps: 1,283,324,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1283324104...
Checkpoint 1283324104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,661.44012
Policy Entropy: 1.75770
Value Function Loss: 0.04346

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.30718
Value Function Update Magnitude: 0.31797

Collected Steps per Second: 22,125.03439
Overall Steps per Second: 10,453.14247

Timestep Collection Time: 2.26169
Timestep Consumption Time: 2.52539
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.78708

Cumulative Model Updates: 153,796
Cumulative Timesteps: 1,283,374,144

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,673.10365
Policy Entropy: 1.74460
Value Function Loss: 0.04042

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.30243
Value Function Update Magnitude: 0.32747

Collected Steps per Second: 22,100.96351
Overall Steps per Second: 10,566.54424

Timestep Collection Time: 2.26244
Timestep Consumption Time: 2.46967
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.73211

Cumulative Model Updates: 153,802
Cumulative Timesteps: 1,283,424,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1283424146...
Checkpoint 1283424146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,677.13541
Policy Entropy: 1.74654
Value Function Loss: 0.03817

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.29535
Value Function Update Magnitude: 0.33986

Collected Steps per Second: 21,920.39821
Overall Steps per Second: 10,605.63900

Timestep Collection Time: 2.28107
Timestep Consumption Time: 2.43359
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.71466

Cumulative Model Updates: 153,808
Cumulative Timesteps: 1,283,474,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,210.70236
Policy Entropy: 1.74075
Value Function Loss: 0.03757

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.29097
Value Function Update Magnitude: 0.31227

Collected Steps per Second: 22,282.40266
Overall Steps per Second: 10,495.17511

Timestep Collection Time: 2.24473
Timestep Consumption Time: 2.52108
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.76581

Cumulative Model Updates: 153,814
Cumulative Timesteps: 1,283,524,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1283524166...
Checkpoint 1283524166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,911.07479
Policy Entropy: 1.74689
Value Function Loss: 0.03659

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.29379
Value Function Update Magnitude: 0.30784

Collected Steps per Second: 21,587.17296
Overall Steps per Second: 10,537.82183

Timestep Collection Time: 2.31702
Timestep Consumption Time: 2.42950
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.74652

Cumulative Model Updates: 153,820
Cumulative Timesteps: 1,283,574,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,572.37588
Policy Entropy: 1.76159
Value Function Loss: 0.03644

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.29487
Value Function Update Magnitude: 0.32028

Collected Steps per Second: 21,735.58257
Overall Steps per Second: 10,578.19939

Timestep Collection Time: 2.30084
Timestep Consumption Time: 2.42681
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.72765

Cumulative Model Updates: 153,826
Cumulative Timesteps: 1,283,624,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1283624194...
Checkpoint 1283624194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,615.83759
Policy Entropy: 1.75674
Value Function Loss: 0.04001

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.29891
Value Function Update Magnitude: 0.31815

Collected Steps per Second: 21,339.15257
Overall Steps per Second: 10,516.13264

Timestep Collection Time: 2.34367
Timestep Consumption Time: 2.41207
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.75574

Cumulative Model Updates: 153,832
Cumulative Timesteps: 1,283,674,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,331.23090
Policy Entropy: 1.75853
Value Function Loss: 0.04004

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.30401
Value Function Update Magnitude: 0.33821

Collected Steps per Second: 21,566.13281
Overall Steps per Second: 10,494.37284

Timestep Collection Time: 2.31901
Timestep Consumption Time: 2.44660
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.76560

Cumulative Model Updates: 153,838
Cumulative Timesteps: 1,283,724,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1283724218...
Checkpoint 1283724218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,536.72732
Policy Entropy: 1.74035
Value Function Loss: 0.03815

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.30066
Value Function Update Magnitude: 0.34262

Collected Steps per Second: 21,349.39039
Overall Steps per Second: 10,317.04176

Timestep Collection Time: 2.34311
Timestep Consumption Time: 2.50557
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.84868

Cumulative Model Updates: 153,844
Cumulative Timesteps: 1,283,774,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,495.31855
Policy Entropy: 1.74763
Value Function Loss: 0.03945

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.29880
Value Function Update Magnitude: 0.31482

Collected Steps per Second: 21,837.19533
Overall Steps per Second: 10,426.62286

Timestep Collection Time: 2.28985
Timestep Consumption Time: 2.50595
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.79580

Cumulative Model Updates: 153,850
Cumulative Timesteps: 1,283,824,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1283824246...
Checkpoint 1283824246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,730.40695
Policy Entropy: 1.75305
Value Function Loss: 0.04161

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.30511
Value Function Update Magnitude: 0.32694

Collected Steps per Second: 21,803.06566
Overall Steps per Second: 10,567.42580

Timestep Collection Time: 2.29390
Timestep Consumption Time: 2.43895
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.73285

Cumulative Model Updates: 153,856
Cumulative Timesteps: 1,283,874,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,783.14364
Policy Entropy: 1.76812
Value Function Loss: 0.04497

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.29421
Value Function Update Magnitude: 0.33428

Collected Steps per Second: 22,217.22999
Overall Steps per Second: 10,452.30489

Timestep Collection Time: 2.25150
Timestep Consumption Time: 2.53424
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.78574

Cumulative Model Updates: 153,862
Cumulative Timesteps: 1,283,924,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1283924282...
Checkpoint 1283924282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,489.90503
Policy Entropy: 1.75931
Value Function Loss: 0.04507

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.34371

Collected Steps per Second: 21,994.73471
Overall Steps per Second: 10,672.13993

Timestep Collection Time: 2.27345
Timestep Consumption Time: 2.41202
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.68547

Cumulative Model Updates: 153,868
Cumulative Timesteps: 1,283,974,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,140.89876
Policy Entropy: 1.74328
Value Function Loss: 0.04369

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.30227
Value Function Update Magnitude: 0.34669

Collected Steps per Second: 22,090.80608
Overall Steps per Second: 10,456.94155

Timestep Collection Time: 2.26456
Timestep Consumption Time: 2.51944
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.78400

Cumulative Model Updates: 153,874
Cumulative Timesteps: 1,284,024,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1284024312...
Checkpoint 1284024312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,706.50953
Policy Entropy: 1.73449
Value Function Loss: 0.04489

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.30335
Value Function Update Magnitude: 0.34565

Collected Steps per Second: 21,710.08641
Overall Steps per Second: 10,546.66782

Timestep Collection Time: 2.30400
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.74273

Cumulative Model Updates: 153,880
Cumulative Timesteps: 1,284,074,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,836.24896
Policy Entropy: 1.72923
Value Function Loss: 0.03963

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.30019
Value Function Update Magnitude: 0.33385

Collected Steps per Second: 22,183.29876
Overall Steps per Second: 10,512.00573

Timestep Collection Time: 2.25548
Timestep Consumption Time: 2.50422
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.75970

Cumulative Model Updates: 153,886
Cumulative Timesteps: 1,284,124,366

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1284124366...
Checkpoint 1284124366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,060.57184
Policy Entropy: 1.72664
Value Function Loss: 0.04032

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.29963
Value Function Update Magnitude: 0.33543

Collected Steps per Second: 21,953.44099
Overall Steps per Second: 10,584.11256

Timestep Collection Time: 2.27809
Timestep Consumption Time: 2.44710
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.72520

Cumulative Model Updates: 153,892
Cumulative Timesteps: 1,284,174,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,100.01528
Policy Entropy: 1.71224
Value Function Loss: 0.03711

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.29990
Value Function Update Magnitude: 0.33423

Collected Steps per Second: 22,038.23045
Overall Steps per Second: 10,494.63623

Timestep Collection Time: 2.26897
Timestep Consumption Time: 2.49575
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.76472

Cumulative Model Updates: 153,898
Cumulative Timesteps: 1,284,224,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1284224382...
Checkpoint 1284224382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,260.10705
Policy Entropy: 1.71168
Value Function Loss: 0.04002

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.30278
Value Function Update Magnitude: 0.32630

Collected Steps per Second: 21,497.92420
Overall Steps per Second: 10,370.02078

Timestep Collection Time: 2.32711
Timestep Consumption Time: 2.49718
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.82429

Cumulative Model Updates: 153,904
Cumulative Timesteps: 1,284,274,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,038.84096
Policy Entropy: 1.71172
Value Function Loss: 0.03803

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.29941
Value Function Update Magnitude: 0.31588

Collected Steps per Second: 21,604.38827
Overall Steps per Second: 10,369.34203

Timestep Collection Time: 2.31481
Timestep Consumption Time: 2.50806
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.82287

Cumulative Model Updates: 153,910
Cumulative Timesteps: 1,284,324,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1284324420...
Checkpoint 1284324420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,971.36220
Policy Entropy: 1.71199
Value Function Loss: 0.03989

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.30022
Value Function Update Magnitude: 0.31307

Collected Steps per Second: 21,590.02033
Overall Steps per Second: 10,513.03784

Timestep Collection Time: 2.31718
Timestep Consumption Time: 2.44148
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.75866

Cumulative Model Updates: 153,916
Cumulative Timesteps: 1,284,374,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,658.84461
Policy Entropy: 1.73920
Value Function Loss: 0.04000

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 0.30360
Value Function Update Magnitude: 0.30891

Collected Steps per Second: 21,586.07603
Overall Steps per Second: 10,514.42868

Timestep Collection Time: 2.31742
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.75765

Cumulative Model Updates: 153,922
Cumulative Timesteps: 1,284,424,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1284424472...
Checkpoint 1284424472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,344.90146
Policy Entropy: 1.74196
Value Function Loss: 0.03902

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.29980
Value Function Update Magnitude: 0.31561

Collected Steps per Second: 21,780.73862
Overall Steps per Second: 10,577.58148

Timestep Collection Time: 2.29726
Timestep Consumption Time: 2.43312
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73038

Cumulative Model Updates: 153,928
Cumulative Timesteps: 1,284,474,508

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,562.34134
Policy Entropy: 1.74126
Value Function Loss: 0.03533

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.29473
Value Function Update Magnitude: 0.31180

Collected Steps per Second: 22,383.50589
Overall Steps per Second: 10,489.42343

Timestep Collection Time: 2.23415
Timestep Consumption Time: 2.53332
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.76747

Cumulative Model Updates: 153,934
Cumulative Timesteps: 1,284,524,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1284524516...
Checkpoint 1284524516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,081.94996
Policy Entropy: 1.72968
Value Function Loss: 0.03369

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.28741
Value Function Update Magnitude: 0.29581

Collected Steps per Second: 21,959.64477
Overall Steps per Second: 10,584.74752

Timestep Collection Time: 2.27791
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.72586

Cumulative Model Updates: 153,940
Cumulative Timesteps: 1,284,574,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,098.17300
Policy Entropy: 1.74074
Value Function Loss: 0.03496

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07262
Policy Update Magnitude: 0.28452
Value Function Update Magnitude: 0.28741

Collected Steps per Second: 21,977.10169
Overall Steps per Second: 10,548.66759

Timestep Collection Time: 2.27591
Timestep Consumption Time: 2.46573
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.74164

Cumulative Model Updates: 153,946
Cumulative Timesteps: 1,284,624,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1284624556...
Checkpoint 1284624556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,822.10709
Policy Entropy: 1.73867
Value Function Loss: 0.03637

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06885
Policy Update Magnitude: 0.28937
Value Function Update Magnitude: 0.28302

Collected Steps per Second: 21,891.17958
Overall Steps per Second: 10,594.63793

Timestep Collection Time: 2.28457
Timestep Consumption Time: 2.43593
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.72050

Cumulative Model Updates: 153,952
Cumulative Timesteps: 1,284,674,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,532.67271
Policy Entropy: 1.73958
Value Function Loss: 0.03731

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.29293
Value Function Update Magnitude: 0.29641

Collected Steps per Second: 21,975.12721
Overall Steps per Second: 10,488.93057

Timestep Collection Time: 2.27694
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.77036

Cumulative Model Updates: 153,958
Cumulative Timesteps: 1,284,724,604

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1284724604...
Checkpoint 1284724604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,050.77254
Policy Entropy: 1.72281
Value Function Loss: 0.04275

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.30249
Value Function Update Magnitude: 0.31835

Collected Steps per Second: 21,982.65413
Overall Steps per Second: 10,609.83603

Timestep Collection Time: 2.27507
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.71374

Cumulative Model Updates: 153,964
Cumulative Timesteps: 1,284,774,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,734.38928
Policy Entropy: 1.73146
Value Function Loss: 0.04507

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.31107
Value Function Update Magnitude: 0.34832

Collected Steps per Second: 21,389.98471
Overall Steps per Second: 10,463.92596

Timestep Collection Time: 2.33876
Timestep Consumption Time: 2.44205
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.78081

Cumulative Model Updates: 153,970
Cumulative Timesteps: 1,284,824,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1284824642...
Checkpoint 1284824642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,214.15498
Policy Entropy: 1.74217
Value Function Loss: 0.04571

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.31628
Value Function Update Magnitude: 0.34902

Collected Steps per Second: 21,372.79768
Overall Steps per Second: 10,361.44991

Timestep Collection Time: 2.34073
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.82828

Cumulative Model Updates: 153,976
Cumulative Timesteps: 1,284,874,670

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,211.72993
Policy Entropy: 1.75501
Value Function Loss: 0.04163

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.31161
Value Function Update Magnitude: 0.34351

Collected Steps per Second: 21,787.21990
Overall Steps per Second: 10,412.45945

Timestep Collection Time: 2.29685
Timestep Consumption Time: 2.50912
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.80597

Cumulative Model Updates: 153,982
Cumulative Timesteps: 1,284,924,712

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1284924712...
Checkpoint 1284924712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,252.68811
Policy Entropy: 1.75818
Value Function Loss: 0.03957

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07590
Policy Update Magnitude: 0.30479
Value Function Update Magnitude: 0.34732

Collected Steps per Second: 21,724.83785
Overall Steps per Second: 10,557.75824

Timestep Collection Time: 2.30326
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.73945

Cumulative Model Updates: 153,988
Cumulative Timesteps: 1,284,974,750

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,712.81959
Policy Entropy: 1.75368
Value Function Loss: 0.03987

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.30223
Value Function Update Magnitude: 0.34910

Collected Steps per Second: 21,254.76646
Overall Steps per Second: 10,462.38810

Timestep Collection Time: 2.35298
Timestep Consumption Time: 2.42719
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.78017

Cumulative Model Updates: 153,994
Cumulative Timesteps: 1,285,024,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1285024762...
Checkpoint 1285024762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,374.95819
Policy Entropy: 1.75430
Value Function Loss: 0.04067

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.30179
Value Function Update Magnitude: 0.35829

Collected Steps per Second: 21,453.59171
Overall Steps per Second: 10,684.24039

Timestep Collection Time: 2.33145
Timestep Consumption Time: 2.35002
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.68147

Cumulative Model Updates: 154,000
Cumulative Timesteps: 1,285,074,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,146.85627
Policy Entropy: 1.76045
Value Function Loss: 0.04023

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.29868
Value Function Update Magnitude: 0.34998

Collected Steps per Second: 20,361.60431
Overall Steps per Second: 10,332.29575

Timestep Collection Time: 2.45649
Timestep Consumption Time: 2.38445
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.84094

Cumulative Model Updates: 154,006
Cumulative Timesteps: 1,285,124,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1285124798...
Checkpoint 1285124798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,929.76921
Policy Entropy: 1.75383
Value Function Loss: 0.03796

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.29710
Value Function Update Magnitude: 0.32654

Collected Steps per Second: 21,237.86073
Overall Steps per Second: 10,310.89814

Timestep Collection Time: 2.35457
Timestep Consumption Time: 2.49525
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.84982

Cumulative Model Updates: 154,012
Cumulative Timesteps: 1,285,174,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,089.25592
Policy Entropy: 1.75036
Value Function Loss: 0.03828

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.29378
Value Function Update Magnitude: 0.32178

Collected Steps per Second: 21,951.47999
Overall Steps per Second: 10,547.53135

Timestep Collection Time: 2.27912
Timestep Consumption Time: 2.46417
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.74329

Cumulative Model Updates: 154,018
Cumulative Timesteps: 1,285,224,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1285224834...
Checkpoint 1285224834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,672.44694
Policy Entropy: 1.73538
Value Function Loss: 0.03851

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.30049
Value Function Update Magnitude: 0.30705

Collected Steps per Second: 22,169.37737
Overall Steps per Second: 10,567.41030

Timestep Collection Time: 2.25726
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.73550

Cumulative Model Updates: 154,024
Cumulative Timesteps: 1,285,274,876

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,179.16688
Policy Entropy: 1.73745
Value Function Loss: 0.03841

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.29771
Value Function Update Magnitude: 0.30043

Collected Steps per Second: 21,928.62056
Overall Steps per Second: 10,523.65706

Timestep Collection Time: 2.28040
Timestep Consumption Time: 2.47137
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.75177

Cumulative Model Updates: 154,030
Cumulative Timesteps: 1,285,324,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1285324882...
Checkpoint 1285324882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,196.37342
Policy Entropy: 1.77474
Value Function Loss: 0.04271

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.29530
Value Function Update Magnitude: 0.29928

Collected Steps per Second: 21,802.65183
Overall Steps per Second: 10,479.42138

Timestep Collection Time: 2.29440
Timestep Consumption Time: 2.47915
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.77355

Cumulative Model Updates: 154,036
Cumulative Timesteps: 1,285,374,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,468.40279
Policy Entropy: 1.76677
Value Function Loss: 0.04517

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.29963
Value Function Update Magnitude: 0.29635

Collected Steps per Second: 21,613.30322
Overall Steps per Second: 10,551.41581

Timestep Collection Time: 2.31385
Timestep Consumption Time: 2.42580
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.73965

Cumulative Model Updates: 154,042
Cumulative Timesteps: 1,285,424,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1285424916...
Checkpoint 1285424916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,276.74327
Policy Entropy: 1.77189
Value Function Loss: 0.04510

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.30636
Value Function Update Magnitude: 0.33009

Collected Steps per Second: 21,375.90751
Overall Steps per Second: 10,493.35111

Timestep Collection Time: 2.34030
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.76740

Cumulative Model Updates: 154,048
Cumulative Timesteps: 1,285,474,942

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,164.84280
Policy Entropy: 1.73582
Value Function Loss: 0.04490

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.31107
Value Function Update Magnitude: 0.34050

Collected Steps per Second: 21,753.13669
Overall Steps per Second: 10,487.08660

Timestep Collection Time: 2.29944
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.76968

Cumulative Model Updates: 154,054
Cumulative Timesteps: 1,285,524,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1285524962...
Checkpoint 1285524962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,515.47009
Policy Entropy: 1.73549
Value Function Loss: 0.04176

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.30909
Value Function Update Magnitude: 0.32945

Collected Steps per Second: 21,734.71799
Overall Steps per Second: 10,370.78791

Timestep Collection Time: 2.30130
Timestep Consumption Time: 2.52167
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.82297

Cumulative Model Updates: 154,060
Cumulative Timesteps: 1,285,574,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,499.52145
Policy Entropy: 1.73240
Value Function Loss: 0.04265

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.30547
Value Function Update Magnitude: 0.32176

Collected Steps per Second: 22,369.88746
Overall Steps per Second: 10,527.42385

Timestep Collection Time: 2.23533
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.74988

Cumulative Model Updates: 154,066
Cumulative Timesteps: 1,285,624,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1285624984...
Checkpoint 1285624984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,441.92803
Policy Entropy: 1.72398
Value Function Loss: 0.04077

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.30173
Value Function Update Magnitude: 0.30497

Collected Steps per Second: 22,050.61070
Overall Steps per Second: 10,465.53908

Timestep Collection Time: 2.26860
Timestep Consumption Time: 2.51128
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.77988

Cumulative Model Updates: 154,072
Cumulative Timesteps: 1,285,675,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,107.64931
Policy Entropy: 1.72456
Value Function Loss: 0.04200

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.30463
Value Function Update Magnitude: 0.33101

Collected Steps per Second: 22,247.93953
Overall Steps per Second: 10,501.94691

Timestep Collection Time: 2.24812
Timestep Consumption Time: 2.51443
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.76255

Cumulative Model Updates: 154,078
Cumulative Timesteps: 1,285,725,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1285725024...
Checkpoint 1285725024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,385.77372
Policy Entropy: 1.72257
Value Function Loss: 0.04292

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.31167
Value Function Update Magnitude: 0.35179

Collected Steps per Second: 22,056.87674
Overall Steps per Second: 10,511.10274

Timestep Collection Time: 2.26768
Timestep Consumption Time: 2.49090
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.75859

Cumulative Model Updates: 154,084
Cumulative Timesteps: 1,285,775,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,945.42500
Policy Entropy: 1.73778
Value Function Loss: 0.04388

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.30780
Value Function Update Magnitude: 0.34442

Collected Steps per Second: 21,944.86943
Overall Steps per Second: 10,529.26108

Timestep Collection Time: 2.28017
Timestep Consumption Time: 2.47211
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.75228

Cumulative Model Updates: 154,090
Cumulative Timesteps: 1,285,825,080

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1285825080...
Checkpoint 1285825080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,521.48369
Policy Entropy: 1.74998
Value Function Loss: 0.04175

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.30177
Value Function Update Magnitude: 0.33632

Collected Steps per Second: 22,066.47467
Overall Steps per Second: 10,689.49371

Timestep Collection Time: 2.26706
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.67992

Cumulative Model Updates: 154,096
Cumulative Timesteps: 1,285,875,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,550.31047
Policy Entropy: 1.73895
Value Function Loss: 0.04251

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.30341
Value Function Update Magnitude: 0.33443

Collected Steps per Second: 22,060.86537
Overall Steps per Second: 10,512.49075

Timestep Collection Time: 2.26727
Timestep Consumption Time: 2.49069
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.75796

Cumulative Model Updates: 154,102
Cumulative Timesteps: 1,285,925,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1285925124...
Checkpoint 1285925124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,382.72383
Policy Entropy: 1.73296
Value Function Loss: 0.03975

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.30405
Value Function Update Magnitude: 0.33766

Collected Steps per Second: 21,782.01005
Overall Steps per Second: 10,504.57409

Timestep Collection Time: 2.29611
Timestep Consumption Time: 2.46505
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.76116

Cumulative Model Updates: 154,108
Cumulative Timesteps: 1,285,975,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,874.02516
Policy Entropy: 1.72447
Value Function Loss: 0.03860

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.29658
Value Function Update Magnitude: 0.32509

Collected Steps per Second: 21,602.24157
Overall Steps per Second: 10,428.12193

Timestep Collection Time: 2.31467
Timestep Consumption Time: 2.48025
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.79492

Cumulative Model Updates: 154,114
Cumulative Timesteps: 1,286,025,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1286025140...
Checkpoint 1286025140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,547.33040
Policy Entropy: 1.73509
Value Function Loss: 0.03797

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.29299
Value Function Update Magnitude: 0.31615

Collected Steps per Second: 21,415.73386
Overall Steps per Second: 10,404.72327

Timestep Collection Time: 2.33595
Timestep Consumption Time: 2.47206
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.80801

Cumulative Model Updates: 154,120
Cumulative Timesteps: 1,286,075,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,729.84216
Policy Entropy: 1.73703
Value Function Loss: 0.04022

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.29358
Value Function Update Magnitude: 0.31687

Collected Steps per Second: 21,703.55131
Overall Steps per Second: 10,409.70681

Timestep Collection Time: 2.30460
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.80494

Cumulative Model Updates: 154,126
Cumulative Timesteps: 1,286,125,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1286125184...
Checkpoint 1286125184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,770.40976
Policy Entropy: 1.73608
Value Function Loss: 0.04441

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.30273
Value Function Update Magnitude: 0.32700

Collected Steps per Second: 21,584.56852
Overall Steps per Second: 10,522.53935

Timestep Collection Time: 2.31860
Timestep Consumption Time: 2.43748
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.75608

Cumulative Model Updates: 154,132
Cumulative Timesteps: 1,286,175,230

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,580.08032
Policy Entropy: 1.74036
Value Function Loss: 0.04801

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.31326
Value Function Update Magnitude: 0.34743

Collected Steps per Second: 22,244.99092
Overall Steps per Second: 10,468.14925

Timestep Collection Time: 2.24851
Timestep Consumption Time: 2.52961
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.77811

Cumulative Model Updates: 154,138
Cumulative Timesteps: 1,286,225,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1286225248...
Checkpoint 1286225248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,268.25346
Policy Entropy: 1.75355
Value Function Loss: 0.04722

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.31300
Value Function Update Magnitude: 0.32104

Collected Steps per Second: 21,697.72374
Overall Steps per Second: 10,530.52906

Timestep Collection Time: 2.30623
Timestep Consumption Time: 2.44567
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.75190

Cumulative Model Updates: 154,144
Cumulative Timesteps: 1,286,275,288

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,472.65245
Policy Entropy: 1.75886
Value Function Loss: 0.04378

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.30549
Value Function Update Magnitude: 0.30401

Collected Steps per Second: 21,958.40806
Overall Steps per Second: 10,494.80712

Timestep Collection Time: 2.27849
Timestep Consumption Time: 2.48882
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.76731

Cumulative Model Updates: 154,150
Cumulative Timesteps: 1,286,325,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1286325320...
Checkpoint 1286325320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,027.78709
Policy Entropy: 1.73117
Value Function Loss: 0.03931

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.30172
Value Function Update Magnitude: 0.32923

Collected Steps per Second: 21,627.36281
Overall Steps per Second: 10,553.26642

Timestep Collection Time: 2.31198
Timestep Consumption Time: 2.42608
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.73806

Cumulative Model Updates: 154,156
Cumulative Timesteps: 1,286,375,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,420.99632
Policy Entropy: 1.73030
Value Function Loss: 0.03767

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.29977
Value Function Update Magnitude: 0.33924

Collected Steps per Second: 22,217.79398
Overall Steps per Second: 10,569.98096

Timestep Collection Time: 2.25171
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.73303

Cumulative Model Updates: 154,162
Cumulative Timesteps: 1,286,425,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1286425350...
Checkpoint 1286425350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,250.00926
Policy Entropy: 1.70730
Value Function Loss: 0.03694

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.29812
Value Function Update Magnitude: 0.32037

Collected Steps per Second: 22,006.43531
Overall Steps per Second: 10,644.58867

Timestep Collection Time: 2.27343
Timestep Consumption Time: 2.42661
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.70004

Cumulative Model Updates: 154,168
Cumulative Timesteps: 1,286,475,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,803.23251
Policy Entropy: 1.71434
Value Function Loss: 0.03750

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.29922
Value Function Update Magnitude: 0.31387

Collected Steps per Second: 21,974.17720
Overall Steps per Second: 10,433.39461

Timestep Collection Time: 2.27567
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.79288

Cumulative Model Updates: 154,174
Cumulative Timesteps: 1,286,525,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1286525386...
Checkpoint 1286525386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,236.48788
Policy Entropy: 1.71478
Value Function Loss: 0.03788

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.30230
Value Function Update Magnitude: 0.29822

Collected Steps per Second: 21,478.04100
Overall Steps per Second: 10,400.09898

Timestep Collection Time: 2.32870
Timestep Consumption Time: 2.48048
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.80918

Cumulative Model Updates: 154,180
Cumulative Timesteps: 1,286,575,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,679.62945
Policy Entropy: 1.73165
Value Function Loss: 0.03907

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.29971
Value Function Update Magnitude: 0.27313

Collected Steps per Second: 21,512.45186
Overall Steps per Second: 10,702.82108

Timestep Collection Time: 2.32424
Timestep Consumption Time: 2.34743
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.67167

Cumulative Model Updates: 154,186
Cumulative Timesteps: 1,286,625,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1286625402...
Checkpoint 1286625402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,032.15631
Policy Entropy: 1.75120
Value Function Loss: 0.04036

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07494
Policy Update Magnitude: 0.29685
Value Function Update Magnitude: 0.26991

Collected Steps per Second: 20,591.10093
Overall Steps per Second: 10,313.70580

Timestep Collection Time: 2.42940
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.85024

Cumulative Model Updates: 154,192
Cumulative Timesteps: 1,286,675,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,396.98121
Policy Entropy: 1.75907
Value Function Loss: 0.04001

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.29772
Value Function Update Magnitude: 0.27563

Collected Steps per Second: 21,354.79917
Overall Steps per Second: 10,505.65725

Timestep Collection Time: 2.34280
Timestep Consumption Time: 2.41940
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.76220

Cumulative Model Updates: 154,198
Cumulative Timesteps: 1,286,725,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1286725456...
Checkpoint 1286725456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,504.22591
Policy Entropy: 1.76232
Value Function Loss: 0.04520

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.30497
Value Function Update Magnitude: 0.31768

Collected Steps per Second: 21,132.63722
Overall Steps per Second: 10,429.12522

Timestep Collection Time: 2.36781
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.79791

Cumulative Model Updates: 154,204
Cumulative Timesteps: 1,286,775,494

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,455.81466
Policy Entropy: 1.75439
Value Function Loss: 0.04765

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.31383
Value Function Update Magnitude: 0.35629

Collected Steps per Second: 20,453.56429
Overall Steps per Second: 10,157.56576

Timestep Collection Time: 2.44515
Timestep Consumption Time: 2.47847
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.92362

Cumulative Model Updates: 154,210
Cumulative Timesteps: 1,286,825,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1286825506...
Checkpoint 1286825506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,020.80916
Policy Entropy: 1.73690
Value Function Loss: 0.04549

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.31319
Value Function Update Magnitude: 0.36160

Collected Steps per Second: 20,327.35629
Overall Steps per Second: 10,201.59659

Timestep Collection Time: 2.46013
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.90198

Cumulative Model Updates: 154,216
Cumulative Timesteps: 1,286,875,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,475.40438
Policy Entropy: 1.72096
Value Function Loss: 0.04439

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.34760

Collected Steps per Second: 21,984.97433
Overall Steps per Second: 10,530.95473

Timestep Collection Time: 2.27483
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.74905

Cumulative Model Updates: 154,222
Cumulative Timesteps: 1,286,925,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1286925526...
Checkpoint 1286925526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,144.44948
Policy Entropy: 1.72626
Value Function Loss: 0.04364

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.31307
Value Function Update Magnitude: 0.34925

Collected Steps per Second: 22,025.18246
Overall Steps per Second: 10,519.89742

Timestep Collection Time: 2.27095
Timestep Consumption Time: 2.48366
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.75461

Cumulative Model Updates: 154,228
Cumulative Timesteps: 1,286,975,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,430.46209
Policy Entropy: 1.74091
Value Function Loss: 0.04308

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.30742
Value Function Update Magnitude: 0.34469

Collected Steps per Second: 21,893.70722
Overall Steps per Second: 10,497.43301

Timestep Collection Time: 2.28531
Timestep Consumption Time: 2.48099
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.76631

Cumulative Model Updates: 154,234
Cumulative Timesteps: 1,287,025,578

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1287025578...
Checkpoint 1287025578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,583.28804
Policy Entropy: 1.75997
Value Function Loss: 0.04274

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.30274
Value Function Update Magnitude: 0.34305

Collected Steps per Second: 21,627.97225
Overall Steps per Second: 10,551.52070

Timestep Collection Time: 2.31312
Timestep Consumption Time: 2.42819
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.74131

Cumulative Model Updates: 154,240
Cumulative Timesteps: 1,287,075,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,489.17612
Policy Entropy: 1.75205
Value Function Loss: 0.04204

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.30481
Value Function Update Magnitude: 0.33925

Collected Steps per Second: 21,501.59897
Overall Steps per Second: 10,532.33346

Timestep Collection Time: 2.32625
Timestep Consumption Time: 2.42275
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.74900

Cumulative Model Updates: 154,246
Cumulative Timesteps: 1,287,125,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1287125624...
Checkpoint 1287125624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,183.45705
Policy Entropy: 1.73510
Value Function Loss: 0.04334

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08881
Policy Update Magnitude: 0.30639
Value Function Update Magnitude: 0.34583

Collected Steps per Second: 21,707.05115
Overall Steps per Second: 10,542.20822

Timestep Collection Time: 2.30441
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.74493

Cumulative Model Updates: 154,252
Cumulative Timesteps: 1,287,175,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,101.52783
Policy Entropy: 1.72921
Value Function Loss: 0.04602

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.31569
Value Function Update Magnitude: 0.32735

Collected Steps per Second: 21,749.79223
Overall Steps per Second: 10,480.12516

Timestep Collection Time: 2.29915
Timestep Consumption Time: 2.47236
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.77151

Cumulative Model Updates: 154,258
Cumulative Timesteps: 1,287,225,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1287225652...
Checkpoint 1287225652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,226.82881
Policy Entropy: 1.73919
Value Function Loss: 0.04659

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.31781
Value Function Update Magnitude: 0.33383

Collected Steps per Second: 21,365.86617
Overall Steps per Second: 10,352.86852

Timestep Collection Time: 2.34046
Timestep Consumption Time: 2.48970
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.83016

Cumulative Model Updates: 154,264
Cumulative Timesteps: 1,287,275,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,723.27324
Policy Entropy: 1.75178
Value Function Loss: 0.04643

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.31515
Value Function Update Magnitude: 0.35501

Collected Steps per Second: 22,307.47226
Overall Steps per Second: 10,482.40330

Timestep Collection Time: 2.24185
Timestep Consumption Time: 2.52900
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.77085

Cumulative Model Updates: 154,270
Cumulative Timesteps: 1,287,325,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1287325668...
Checkpoint 1287325668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,642.36570
Policy Entropy: 1.72985
Value Function Loss: 0.04241

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.31290
Value Function Update Magnitude: 0.36192

Collected Steps per Second: 21,991.32924
Overall Steps per Second: 10,380.22520

Timestep Collection Time: 2.27390
Timestep Consumption Time: 2.54353
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.81743

Cumulative Model Updates: 154,276
Cumulative Timesteps: 1,287,375,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,881.11721
Policy Entropy: 1.71022
Value Function Loss: 0.04107

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.30666
Value Function Update Magnitude: 0.35609

Collected Steps per Second: 22,015.34721
Overall Steps per Second: 10,493.04432

Timestep Collection Time: 2.27269
Timestep Consumption Time: 2.49561
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.76830

Cumulative Model Updates: 154,282
Cumulative Timesteps: 1,287,425,708

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1287425708...
Checkpoint 1287425708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,717.39490
Policy Entropy: 1.70904
Value Function Loss: 0.04337

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.31006
Value Function Update Magnitude: 0.35038

Collected Steps per Second: 21,517.45481
Overall Steps per Second: 10,364.62137

Timestep Collection Time: 2.32369
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.82410

Cumulative Model Updates: 154,288
Cumulative Timesteps: 1,287,475,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,860.72361
Policy Entropy: 1.72097
Value Function Loss: 0.04571

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.31505
Value Function Update Magnitude: 0.34960

Collected Steps per Second: 22,106.90347
Overall Steps per Second: 10,652.78100

Timestep Collection Time: 2.26183
Timestep Consumption Time: 2.43197
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.69380

Cumulative Model Updates: 154,294
Cumulative Timesteps: 1,287,525,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1287525710...
Checkpoint 1287525710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,770.42378
Policy Entropy: 1.73018
Value Function Loss: 0.04458

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.29929
Value Function Update Magnitude: 0.35738

Collected Steps per Second: 21,766.54557
Overall Steps per Second: 10,428.69716

Timestep Collection Time: 2.29729
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.79485

Cumulative Model Updates: 154,300
Cumulative Timesteps: 1,287,575,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,979.52054
Policy Entropy: 1.73736
Value Function Loss: 0.04253

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.30312
Value Function Update Magnitude: 0.36115

Collected Steps per Second: 22,452.21208
Overall Steps per Second: 10,731.69989

Timestep Collection Time: 2.22802
Timestep Consumption Time: 2.43331
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.66133

Cumulative Model Updates: 154,306
Cumulative Timesteps: 1,287,625,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1287625738...
Checkpoint 1287625738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,057.81631
Policy Entropy: 1.74270
Value Function Loss: 0.04196

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.30904
Value Function Update Magnitude: 0.34080

Collected Steps per Second: 21,462.21292
Overall Steps per Second: 10,353.36108

Timestep Collection Time: 2.33033
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.83070

Cumulative Model Updates: 154,312
Cumulative Timesteps: 1,287,675,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,980.63642
Policy Entropy: 1.74992
Value Function Loss: 0.04654

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.31164
Value Function Update Magnitude: 0.34566

Collected Steps per Second: 21,640.97873
Overall Steps per Second: 10,347.99912

Timestep Collection Time: 2.31071
Timestep Consumption Time: 2.52172
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.83243

Cumulative Model Updates: 154,318
Cumulative Timesteps: 1,287,725,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1287725758...
Checkpoint 1287725758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,563.31342
Policy Entropy: 1.74273
Value Function Loss: 0.04340

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.29439
Value Function Update Magnitude: 0.33965

Collected Steps per Second: 21,518.95021
Overall Steps per Second: 10,379.74863

Timestep Collection Time: 2.32483
Timestep Consumption Time: 2.49494
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.81977

Cumulative Model Updates: 154,324
Cumulative Timesteps: 1,287,775,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,050.60317
Policy Entropy: 1.75794
Value Function Loss: 0.04285

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.29471
Value Function Update Magnitude: 0.33490

Collected Steps per Second: 21,803.61152
Overall Steps per Second: 10,414.95157

Timestep Collection Time: 2.29393
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.80233

Cumulative Model Updates: 154,330
Cumulative Timesteps: 1,287,825,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1287825802...
Checkpoint 1287825802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,015.05311
Policy Entropy: 1.77220
Value Function Loss: 0.03967

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.29899
Value Function Update Magnitude: 0.32964

Collected Steps per Second: 21,979.07244
Overall Steps per Second: 10,580.20381

Timestep Collection Time: 2.27635
Timestep Consumption Time: 2.45248
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.72883

Cumulative Model Updates: 154,336
Cumulative Timesteps: 1,287,875,834

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,058.21146
Policy Entropy: 1.78914
Value Function Loss: 0.04265

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.30050
Value Function Update Magnitude: 0.32273

Collected Steps per Second: 22,235.77476
Overall Steps per Second: 10,538.09020

Timestep Collection Time: 2.25034
Timestep Consumption Time: 2.49796
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.74830

Cumulative Model Updates: 154,342
Cumulative Timesteps: 1,287,925,872

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1287925872...
Checkpoint 1287925872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,872.45268
Policy Entropy: 1.77145
Value Function Loss: 0.03884

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.29718
Value Function Update Magnitude: 0.31267

Collected Steps per Second: 21,986.99982
Overall Steps per Second: 10,449.98561

Timestep Collection Time: 2.27471
Timestep Consumption Time: 2.51133
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.78604

Cumulative Model Updates: 154,348
Cumulative Timesteps: 1,287,975,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,107.54896
Policy Entropy: 1.75657
Value Function Loss: 0.04080

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.29569
Value Function Update Magnitude: 0.30900

Collected Steps per Second: 22,158.26105
Overall Steps per Second: 10,466.23150

Timestep Collection Time: 2.25731
Timestep Consumption Time: 2.52168
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.77899

Cumulative Model Updates: 154,354
Cumulative Timesteps: 1,288,025,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1288025904...
Checkpoint 1288025904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,949.38603
Policy Entropy: 1.73788
Value Function Loss: 0.03932

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.28988
Value Function Update Magnitude: 0.28732

Collected Steps per Second: 21,917.79430
Overall Steps per Second: 10,609.47137

Timestep Collection Time: 2.28335
Timestep Consumption Time: 2.43376
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.71711

Cumulative Model Updates: 154,360
Cumulative Timesteps: 1,288,075,950

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,784.09151
Policy Entropy: 1.73590
Value Function Loss: 0.04141

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.28196
Value Function Update Magnitude: 0.31482

Collected Steps per Second: 22,185.64000
Overall Steps per Second: 10,480.64937

Timestep Collection Time: 2.25416
Timestep Consumption Time: 2.51749
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.77165

Cumulative Model Updates: 154,366
Cumulative Timesteps: 1,288,125,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1288125960...
Checkpoint 1288125960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,135.86486
Policy Entropy: 1.72475
Value Function Loss: 0.03966

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.30255
Value Function Update Magnitude: 0.33145

Collected Steps per Second: 21,854.82615
Overall Steps per Second: 10,597.56570

Timestep Collection Time: 2.28929
Timestep Consumption Time: 2.43180
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.72108

Cumulative Model Updates: 154,372
Cumulative Timesteps: 1,288,175,992

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,230.35920
Policy Entropy: 1.72483
Value Function Loss: 0.03965

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.29673
Value Function Update Magnitude: 0.31061

Collected Steps per Second: 21,758.40554
Overall Steps per Second: 10,594.11830

Timestep Collection Time: 2.30044
Timestep Consumption Time: 2.42425
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.72470

Cumulative Model Updates: 154,378
Cumulative Timesteps: 1,288,226,046

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1288226046...
Checkpoint 1288226046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,660.46318
Policy Entropy: 1.72892
Value Function Loss: 0.04562

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.28671
Value Function Update Magnitude: 0.27976

Collected Steps per Second: 21,397.89550
Overall Steps per Second: 10,498.47578

Timestep Collection Time: 2.33864
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.76660

Cumulative Model Updates: 154,384
Cumulative Timesteps: 1,288,276,088

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,572.00540
Policy Entropy: 1.73194
Value Function Loss: 0.04424

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.29687
Value Function Update Magnitude: 0.27996

Collected Steps per Second: 21,454.41220
Overall Steps per Second: 10,498.81238

Timestep Collection Time: 2.33164
Timestep Consumption Time: 2.43309
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.76473

Cumulative Model Updates: 154,390
Cumulative Timesteps: 1,288,326,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1288326112...
Checkpoint 1288326112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,442.39893
Policy Entropy: 1.72840
Value Function Loss: 0.04780

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.31175
Value Function Update Magnitude: 0.29898

Collected Steps per Second: 21,558.88403
Overall Steps per Second: 10,562.02940

Timestep Collection Time: 2.32016
Timestep Consumption Time: 2.41568
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.73583

Cumulative Model Updates: 154,396
Cumulative Timesteps: 1,288,376,132

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,803.25329
Policy Entropy: 1.70542
Value Function Loss: 0.04158

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.31194
Value Function Update Magnitude: 0.29396

Collected Steps per Second: 21,833.16352
Overall Steps per Second: 10,597.76877

Timestep Collection Time: 2.29138
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.72062

Cumulative Model Updates: 154,402
Cumulative Timesteps: 1,288,426,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1288426160...
Checkpoint 1288426160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,852.96196
Policy Entropy: 1.71332
Value Function Loss: 0.04264

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.30935
Value Function Update Magnitude: 0.28340

Collected Steps per Second: 21,217.96713
Overall Steps per Second: 10,546.90463

Timestep Collection Time: 2.35772
Timestep Consumption Time: 2.38547
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.74319

Cumulative Model Updates: 154,408
Cumulative Timesteps: 1,288,476,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,493.12459
Policy Entropy: 1.72044
Value Function Loss: 0.04651

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.31431
Value Function Update Magnitude: 0.23270

Collected Steps per Second: 21,422.86789
Overall Steps per Second: 10,467.98652

Timestep Collection Time: 2.33451
Timestep Consumption Time: 2.44310
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.77761

Cumulative Model Updates: 154,414
Cumulative Timesteps: 1,288,526,198

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1288526198...
Checkpoint 1288526198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,803.43705
Policy Entropy: 1.72815
Value Function Loss: 0.04869

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.31560
Value Function Update Magnitude: 0.22272

Collected Steps per Second: 21,340.66268
Overall Steps per Second: 10,641.78031

Timestep Collection Time: 2.34426
Timestep Consumption Time: 2.35684
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.70109

Cumulative Model Updates: 154,420
Cumulative Timesteps: 1,288,576,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,066.62346
Policy Entropy: 1.73108
Value Function Loss: 0.05114

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.31794
Value Function Update Magnitude: 0.23282

Collected Steps per Second: 21,465.45061
Overall Steps per Second: 10,481.86320

Timestep Collection Time: 2.32932
Timestep Consumption Time: 2.44082
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.77014

Cumulative Model Updates: 154,426
Cumulative Timesteps: 1,288,626,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1288626226...
Checkpoint 1288626226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,857.03943
Policy Entropy: 1.75910
Value Function Loss: 0.04933

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.31290
Value Function Update Magnitude: 0.28481

Collected Steps per Second: 21,451.25849
Overall Steps per Second: 10,563.02333

Timestep Collection Time: 2.33254
Timestep Consumption Time: 2.40436
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.73690

Cumulative Model Updates: 154,432
Cumulative Timesteps: 1,288,676,262

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,582.23380
Policy Entropy: 1.76459
Value Function Loss: 0.04580

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.30585
Value Function Update Magnitude: 0.32761

Collected Steps per Second: 21,949.22702
Overall Steps per Second: 10,517.57680

Timestep Collection Time: 2.27917
Timestep Consumption Time: 2.47725
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.75642

Cumulative Model Updates: 154,438
Cumulative Timesteps: 1,288,726,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1288726288...
Checkpoint 1288726288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,589.20401
Policy Entropy: 1.76490
Value Function Loss: 0.04847

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08209
Policy Update Magnitude: 0.30601
Value Function Update Magnitude: 0.32828

Collected Steps per Second: 21,614.69031
Overall Steps per Second: 10,598.05573

Timestep Collection Time: 2.31398
Timestep Consumption Time: 2.40537
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.71936

Cumulative Model Updates: 154,444
Cumulative Timesteps: 1,288,776,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,005.29755
Policy Entropy: 1.73545
Value Function Loss: 0.04583

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.31083
Value Function Update Magnitude: 0.32508

Collected Steps per Second: 21,829.77907
Overall Steps per Second: 10,493.85487

Timestep Collection Time: 2.29045
Timestep Consumption Time: 2.47424
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.76469

Cumulative Model Updates: 154,450
Cumulative Timesteps: 1,288,826,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1288826304...
Checkpoint 1288826304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,257.82297
Policy Entropy: 1.72476
Value Function Loss: 0.04423

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.30617
Value Function Update Magnitude: 0.33063

Collected Steps per Second: 20,959.84916
Overall Steps per Second: 10,285.14545

Timestep Collection Time: 2.38714
Timestep Consumption Time: 2.47755
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.86469

Cumulative Model Updates: 154,456
Cumulative Timesteps: 1,288,876,338

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,291.38043
Policy Entropy: 1.70904
Value Function Loss: 0.04157

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.30476
Value Function Update Magnitude: 0.32168

Collected Steps per Second: 21,509.93907
Overall Steps per Second: 10,379.31131

Timestep Collection Time: 2.32553
Timestep Consumption Time: 2.49387
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.81939

Cumulative Model Updates: 154,462
Cumulative Timesteps: 1,288,926,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1288926360...
Checkpoint 1288926360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,834.72901
Policy Entropy: 1.71508
Value Function Loss: 0.04142

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.30658
Value Function Update Magnitude: 0.32290

Collected Steps per Second: 21,769.57484
Overall Steps per Second: 10,602.27784

Timestep Collection Time: 2.29770
Timestep Consumption Time: 2.42015
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.71785

Cumulative Model Updates: 154,468
Cumulative Timesteps: 1,288,976,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,359.54223
Policy Entropy: 1.71991
Value Function Loss: 0.04445

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.31129
Value Function Update Magnitude: 0.32772

Collected Steps per Second: 22,137.83968
Overall Steps per Second: 10,486.57375

Timestep Collection Time: 2.25921
Timestep Consumption Time: 2.51013
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.76934

Cumulative Model Updates: 154,474
Cumulative Timesteps: 1,289,026,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1289026394...
Checkpoint 1289026394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,457.16557
Policy Entropy: 1.73360
Value Function Loss: 0.04560

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.30874
Value Function Update Magnitude: 0.32071

Collected Steps per Second: 21,796.53632
Overall Steps per Second: 10,619.10359

Timestep Collection Time: 2.29449
Timestep Consumption Time: 2.41513
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.70963

Cumulative Model Updates: 154,480
Cumulative Timesteps: 1,289,076,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,873.74789
Policy Entropy: 1.73472
Value Function Loss: 0.04398

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.30934
Value Function Update Magnitude: 0.31773

Collected Steps per Second: 22,025.84123
Overall Steps per Second: 10,453.73746

Timestep Collection Time: 2.27170
Timestep Consumption Time: 2.51473
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.78642

Cumulative Model Updates: 154,486
Cumulative Timesteps: 1,289,126,442

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1289126442...
Checkpoint 1289126442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,726.30717
Policy Entropy: 1.73077
Value Function Loss: 0.04261

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.30593
Value Function Update Magnitude: 0.30767

Collected Steps per Second: 22,162.46278
Overall Steps per Second: 10,649.38963

Timestep Collection Time: 2.25679
Timestep Consumption Time: 2.43982
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.69661

Cumulative Model Updates: 154,492
Cumulative Timesteps: 1,289,176,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,182.72653
Policy Entropy: 1.72515
Value Function Loss: 0.04212

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.30855
Value Function Update Magnitude: 0.31952

Collected Steps per Second: 22,048.88949
Overall Steps per Second: 10,508.12446

Timestep Collection Time: 2.27005
Timestep Consumption Time: 2.49313
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.76317

Cumulative Model Updates: 154,498
Cumulative Timesteps: 1,289,226,510

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1289226510...
Checkpoint 1289226510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,320.47058
Policy Entropy: 1.73528
Value Function Loss: 0.04472

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.29821
Value Function Update Magnitude: 0.33502

Collected Steps per Second: 21,745.84951
Overall Steps per Second: 10,565.69001

Timestep Collection Time: 2.30039
Timestep Consumption Time: 2.43418
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.73457

Cumulative Model Updates: 154,504
Cumulative Timesteps: 1,289,276,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,254.85761
Policy Entropy: 1.73494
Value Function Loss: 0.04322

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.28759
Value Function Update Magnitude: 0.33771

Collected Steps per Second: 22,017.97996
Overall Steps per Second: 10,477.75408

Timestep Collection Time: 2.27151
Timestep Consumption Time: 2.50184
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.77335

Cumulative Model Updates: 154,510
Cumulative Timesteps: 1,289,326,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1289326548...
Checkpoint 1289326548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,851.00420
Policy Entropy: 1.74053
Value Function Loss: 0.04030

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.29554
Value Function Update Magnitude: 0.32664

Collected Steps per Second: 21,542.21839
Overall Steps per Second: 10,389.45914

Timestep Collection Time: 2.32232
Timestep Consumption Time: 2.49294
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.81527

Cumulative Model Updates: 154,516
Cumulative Timesteps: 1,289,376,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,324.76403
Policy Entropy: 1.72687
Value Function Loss: 0.03603

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.29253
Value Function Update Magnitude: 0.31040

Collected Steps per Second: 21,894.42272
Overall Steps per Second: 10,655.86590

Timestep Collection Time: 2.28405
Timestep Consumption Time: 2.40895
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.69300

Cumulative Model Updates: 154,522
Cumulative Timesteps: 1,289,426,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1289426584...
Checkpoint 1289426584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,549.10353
Policy Entropy: 1.71852
Value Function Loss: 0.03949

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.29664
Value Function Update Magnitude: 0.27775

Collected Steps per Second: 21,072.45384
Overall Steps per Second: 10,263.30745

Timestep Collection Time: 2.37362
Timestep Consumption Time: 2.49986
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.87348

Cumulative Model Updates: 154,528
Cumulative Timesteps: 1,289,476,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,130.26522
Policy Entropy: 1.73084
Value Function Loss: 0.04241

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.30211
Value Function Update Magnitude: 0.29855

Collected Steps per Second: 21,458.64544
Overall Steps per Second: 10,480.91099

Timestep Collection Time: 2.33016
Timestep Consumption Time: 2.44061
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.77077

Cumulative Model Updates: 154,534
Cumulative Timesteps: 1,289,526,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1289526604...
Checkpoint 1289526604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,168.08760
Policy Entropy: 1.72548
Value Function Loss: 0.04278

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.29716
Value Function Update Magnitude: 0.32402

Collected Steps per Second: 21,321.44524
Overall Steps per Second: 10,299.67490

Timestep Collection Time: 2.34534
Timestep Consumption Time: 2.50977
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.85510

Cumulative Model Updates: 154,540
Cumulative Timesteps: 1,289,576,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,924.61133
Policy Entropy: 1.73947
Value Function Loss: 0.04241

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.29804
Value Function Update Magnitude: 0.31814

Collected Steps per Second: 22,010.52072
Overall Steps per Second: 10,413.14562

Timestep Collection Time: 2.27228
Timestep Consumption Time: 2.53069
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.80297

Cumulative Model Updates: 154,546
Cumulative Timesteps: 1,289,626,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1289626624...
Checkpoint 1289626624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,899.45215
Policy Entropy: 1.72051
Value Function Loss: 0.04081

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.30606
Value Function Update Magnitude: 0.31516

Collected Steps per Second: 22,129.84817
Overall Steps per Second: 10,524.97593

Timestep Collection Time: 2.26093
Timestep Consumption Time: 2.49291
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.75384

Cumulative Model Updates: 154,552
Cumulative Timesteps: 1,289,676,658

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,409.75144
Policy Entropy: 1.73018
Value Function Loss: 0.04009

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.30463
Value Function Update Magnitude: 0.31208

Collected Steps per Second: 21,851.69056
Overall Steps per Second: 10,446.09232

Timestep Collection Time: 2.28962
Timestep Consumption Time: 2.49993
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.78954

Cumulative Model Updates: 154,558
Cumulative Timesteps: 1,289,726,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1289726690...
Checkpoint 1289726690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,969.27973
Policy Entropy: 1.73452
Value Function Loss: 0.04296

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08286
Policy Update Magnitude: 0.30449
Value Function Update Magnitude: 0.32934

Collected Steps per Second: 21,781.88798
Overall Steps per Second: 10,558.39493

Timestep Collection Time: 2.29723
Timestep Consumption Time: 2.44194
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.73917

Cumulative Model Updates: 154,564
Cumulative Timesteps: 1,289,776,728

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,540.14468
Policy Entropy: 1.74958
Value Function Loss: 0.04289

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.30623
Value Function Update Magnitude: 0.34323

Collected Steps per Second: 21,799.39862
Overall Steps per Second: 10,561.32195

Timestep Collection Time: 2.29373
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.73445

Cumulative Model Updates: 154,570
Cumulative Timesteps: 1,289,826,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1289826730...
Checkpoint 1289826730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,721.27772
Policy Entropy: 1.76772
Value Function Loss: 0.04602

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.31035
Value Function Update Magnitude: 0.33217

Collected Steps per Second: 22,222.40391
Overall Steps per Second: 10,667.47072

Timestep Collection Time: 2.25052
Timestep Consumption Time: 2.43775
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.68827

Cumulative Model Updates: 154,576
Cumulative Timesteps: 1,289,876,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,472.26490
Policy Entropy: 1.77139
Value Function Loss: 0.04446

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.30926
Value Function Update Magnitude: 0.31731

Collected Steps per Second: 21,908.36730
Overall Steps per Second: 10,422.85096

Timestep Collection Time: 2.28269
Timestep Consumption Time: 2.51542
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.79811

Cumulative Model Updates: 154,582
Cumulative Timesteps: 1,289,926,752

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1289926752...
Checkpoint 1289926752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,667.48418
Policy Entropy: 1.77408
Value Function Loss: 0.04495

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.30719
Value Function Update Magnitude: 0.32956

Collected Steps per Second: 21,772.78976
Overall Steps per Second: 10,579.03634

Timestep Collection Time: 2.29764
Timestep Consumption Time: 2.43115
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.72879

Cumulative Model Updates: 154,588
Cumulative Timesteps: 1,289,976,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,610.85282
Policy Entropy: 1.76367
Value Function Loss: 0.04330

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.30740
Value Function Update Magnitude: 0.35339

Collected Steps per Second: 21,467.93554
Overall Steps per Second: 10,510.97281

Timestep Collection Time: 2.32999
Timestep Consumption Time: 2.42885
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.75884

Cumulative Model Updates: 154,594
Cumulative Timesteps: 1,290,026,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1290026798...
Checkpoint 1290026798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,825.47678
Policy Entropy: 1.74524
Value Function Loss: 0.04199

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.30657
Value Function Update Magnitude: 0.37224

Collected Steps per Second: 20,968.69043
Overall Steps per Second: 10,567.85157

Timestep Collection Time: 2.38460
Timestep Consumption Time: 2.34692
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.73152

Cumulative Model Updates: 154,600
Cumulative Timesteps: 1,290,076,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,589.85879
Policy Entropy: 1.72221
Value Function Loss: 0.04177

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.30681
Value Function Update Magnitude: 0.35736

Collected Steps per Second: 20,715.91179
Overall Steps per Second: 10,454.97058

Timestep Collection Time: 2.41418
Timestep Consumption Time: 2.36938
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.78356

Cumulative Model Updates: 154,606
Cumulative Timesteps: 1,290,126,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1290126812...
Checkpoint 1290126812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,210.70037
Policy Entropy: 1.70758
Value Function Loss: 0.04053

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.30215
Value Function Update Magnitude: 0.33668

Collected Steps per Second: 21,203.33055
Overall Steps per Second: 10,442.55569

Timestep Collection Time: 2.35925
Timestep Consumption Time: 2.43115
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.79040

Cumulative Model Updates: 154,612
Cumulative Timesteps: 1,290,176,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,081.56291
Policy Entropy: 1.72162
Value Function Loss: 0.04031

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.30114
Value Function Update Magnitude: 0.32319

Collected Steps per Second: 21,488.90442
Overall Steps per Second: 10,378.20748

Timestep Collection Time: 2.32706
Timestep Consumption Time: 2.49130
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.81837

Cumulative Model Updates: 154,618
Cumulative Timesteps: 1,290,226,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1290226842...
Checkpoint 1290226842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,806.61294
Policy Entropy: 1.73557
Value Function Loss: 0.03735

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.29289
Value Function Update Magnitude: 0.30294

Collected Steps per Second: 22,098.60570
Overall Steps per Second: 10,528.00820

Timestep Collection Time: 2.26295
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.75000

Cumulative Model Updates: 154,624
Cumulative Timesteps: 1,290,276,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,947.72435
Policy Entropy: 1.74025
Value Function Loss: 0.03669

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.28823
Value Function Update Magnitude: 0.28848

Collected Steps per Second: 21,792.12089
Overall Steps per Second: 10,441.25819

Timestep Collection Time: 2.29496
Timestep Consumption Time: 2.49489
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.78984

Cumulative Model Updates: 154,630
Cumulative Timesteps: 1,290,326,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1290326862...
Checkpoint 1290326862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,565.03942
Policy Entropy: 1.70978
Value Function Loss: 0.03554

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.28850
Value Function Update Magnitude: 0.28248

Collected Steps per Second: 21,612.78691
Overall Steps per Second: 10,591.18290

Timestep Collection Time: 2.31372
Timestep Consumption Time: 2.40775
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.72147

Cumulative Model Updates: 154,636
Cumulative Timesteps: 1,290,376,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,178.76495
Policy Entropy: 1.69232
Value Function Loss: 0.04027

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.29915
Value Function Update Magnitude: 0.30528

Collected Steps per Second: 22,175.41494
Overall Steps per Second: 10,521.08719

Timestep Collection Time: 2.25601
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.75502

Cumulative Model Updates: 154,642
Cumulative Timesteps: 1,290,426,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1290426896...
Checkpoint 1290426896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,854.29673
Policy Entropy: 1.70943
Value Function Loss: 0.04195

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07693
Policy Update Magnitude: 0.31073
Value Function Update Magnitude: 0.33299

Collected Steps per Second: 22,116.90783
Overall Steps per Second: 10,683.61986

Timestep Collection Time: 2.26117
Timestep Consumption Time: 2.41983
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.68100

Cumulative Model Updates: 154,648
Cumulative Timesteps: 1,290,476,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,314.52387
Policy Entropy: 1.72525
Value Function Loss: 0.04174

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.30943
Value Function Update Magnitude: 0.34562

Collected Steps per Second: 21,873.39611
Overall Steps per Second: 10,414.30384

Timestep Collection Time: 2.28643
Timestep Consumption Time: 2.51581
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.80224

Cumulative Model Updates: 154,654
Cumulative Timesteps: 1,290,526,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1290526918...
Checkpoint 1290526918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,167.80487
Policy Entropy: 1.73107
Value Function Loss: 0.03811

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.30483
Value Function Update Magnitude: 0.32319

Collected Steps per Second: 21,417.00022
Overall Steps per Second: 10,317.54976

Timestep Collection Time: 2.33684
Timestep Consumption Time: 2.51393
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.85076

Cumulative Model Updates: 154,660
Cumulative Timesteps: 1,290,576,966

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,050.13703
Policy Entropy: 1.71287
Value Function Loss: 0.03549

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.29977
Value Function Update Magnitude: 0.30544

Collected Steps per Second: 21,691.52264
Overall Steps per Second: 10,387.52277

Timestep Collection Time: 2.30698
Timestep Consumption Time: 2.51053
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.81751

Cumulative Model Updates: 154,666
Cumulative Timesteps: 1,290,627,008

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1290627008...
Checkpoint 1290627008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,335.01088
Policy Entropy: 1.72717
Value Function Loss: 0.03891

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.30036
Value Function Update Magnitude: 0.28514

Collected Steps per Second: 21,266.99853
Overall Steps per Second: 10,292.94714

Timestep Collection Time: 2.35219
Timestep Consumption Time: 2.50784
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.86003

Cumulative Model Updates: 154,672
Cumulative Timesteps: 1,290,677,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,104.67387
Policy Entropy: 1.72759
Value Function Loss: 0.03969

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.30385
Value Function Update Magnitude: 0.28551

Collected Steps per Second: 21,815.16374
Overall Steps per Second: 10,402.40857

Timestep Collection Time: 2.29382
Timestep Consumption Time: 2.51661
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.81042

Cumulative Model Updates: 154,678
Cumulative Timesteps: 1,290,727,072

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1290727072...
Checkpoint 1290727072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,733.73395
Policy Entropy: 1.72619
Value Function Loss: 0.04224

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.30598
Value Function Update Magnitude: 0.31269

Collected Steps per Second: 21,153.14057
Overall Steps per Second: 10,284.87318

Timestep Collection Time: 2.36409
Timestep Consumption Time: 2.49819
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.86229

Cumulative Model Updates: 154,684
Cumulative Timesteps: 1,290,777,080

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,784.47406
Policy Entropy: 1.71802
Value Function Loss: 0.04004

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.30284
Value Function Update Magnitude: 0.31491

Collected Steps per Second: 21,801.79792
Overall Steps per Second: 10,409.80648

Timestep Collection Time: 2.29458
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.80566

Cumulative Model Updates: 154,690
Cumulative Timesteps: 1,290,827,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1290827106...
Checkpoint 1290827106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,060.83912
Policy Entropy: 1.72820
Value Function Loss: 0.03945

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.29643
Value Function Update Magnitude: 0.31362

Collected Steps per Second: 21,612.09555
Overall Steps per Second: 10,535.62201

Timestep Collection Time: 2.31444
Timestep Consumption Time: 2.43326
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.74770

Cumulative Model Updates: 154,696
Cumulative Timesteps: 1,290,877,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,986.20023
Policy Entropy: 1.71455
Value Function Loss: 0.03815

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.29700
Value Function Update Magnitude: 0.32553

Collected Steps per Second: 21,850.34710
Overall Steps per Second: 10,449.35945

Timestep Collection Time: 2.28838
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.78517

Cumulative Model Updates: 154,702
Cumulative Timesteps: 1,290,927,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1290927128...
Checkpoint 1290927128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,179.06557
Policy Entropy: 1.70430
Value Function Loss: 0.03699

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.29917
Value Function Update Magnitude: 0.32212

Collected Steps per Second: 21,763.00912
Overall Steps per Second: 10,322.53835

Timestep Collection Time: 2.29812
Timestep Consumption Time: 2.54701
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.84513

Cumulative Model Updates: 154,708
Cumulative Timesteps: 1,290,977,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,766.96034
Policy Entropy: 1.69418
Value Function Loss: 0.03973

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.30387
Value Function Update Magnitude: 0.32361

Collected Steps per Second: 22,342.05542
Overall Steps per Second: 10,699.72875

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.43528
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.67339

Cumulative Model Updates: 154,714
Cumulative Timesteps: 1,291,027,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1291027146...
Checkpoint 1291027146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,739.27738
Policy Entropy: 1.70666
Value Function Loss: 0.03844

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.30379
Value Function Update Magnitude: 0.32208

Collected Steps per Second: 21,306.70413
Overall Steps per Second: 10,636.55757

Timestep Collection Time: 2.34762
Timestep Consumption Time: 2.35503
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.70265

Cumulative Model Updates: 154,720
Cumulative Timesteps: 1,291,077,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,282.42493
Policy Entropy: 1.71727
Value Function Loss: 0.03743

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.30124
Value Function Update Magnitude: 0.30704

Collected Steps per Second: 21,558.20986
Overall Steps per Second: 10,489.74027

Timestep Collection Time: 2.32042
Timestep Consumption Time: 2.44843
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.76885

Cumulative Model Updates: 154,726
Cumulative Timesteps: 1,291,127,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1291127190...
Checkpoint 1291127190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,751.32151
Policy Entropy: 1.71697
Value Function Loss: 0.03609

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.29361
Value Function Update Magnitude: 0.29967

Collected Steps per Second: 21,224.36704
Overall Steps per Second: 10,602.49569

Timestep Collection Time: 2.35682
Timestep Consumption Time: 2.36113
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.71795

Cumulative Model Updates: 154,732
Cumulative Timesteps: 1,291,177,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,164.04490
Policy Entropy: 1.70211
Value Function Loss: 0.04434

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.29741
Value Function Update Magnitude: 0.31211

Collected Steps per Second: 21,650.69371
Overall Steps per Second: 10,563.21976

Timestep Collection Time: 2.30949
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.73359

Cumulative Model Updates: 154,738
Cumulative Timesteps: 1,291,227,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1291227214...
Checkpoint 1291227214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,554.19945
Policy Entropy: 1.69101
Value Function Loss: 0.04179

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.30387
Value Function Update Magnitude: 0.32618

Collected Steps per Second: 21,195.68040
Overall Steps per Second: 10,508.70425

Timestep Collection Time: 2.36039
Timestep Consumption Time: 2.40043
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.76082

Cumulative Model Updates: 154,744
Cumulative Timesteps: 1,291,277,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,155.93538
Policy Entropy: 1.68469
Value Function Loss: 0.04314

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.30803
Value Function Update Magnitude: 0.33563

Collected Steps per Second: 21,681.05252
Overall Steps per Second: 10,621.48804

Timestep Collection Time: 2.30754
Timestep Consumption Time: 2.40272
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.71026

Cumulative Model Updates: 154,750
Cumulative Timesteps: 1,291,327,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1291327274...
Checkpoint 1291327274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,464.55634
Policy Entropy: 1.69289
Value Function Loss: 0.04010

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.30547
Value Function Update Magnitude: 0.32535

Collected Steps per Second: 21,266.28510
Overall Steps per Second: 10,521.31998

Timestep Collection Time: 2.35142
Timestep Consumption Time: 2.40140
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.75283

Cumulative Model Updates: 154,756
Cumulative Timesteps: 1,291,377,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,707.19215
Policy Entropy: 1.71140
Value Function Loss: 0.04392

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.30394
Value Function Update Magnitude: 0.31177

Collected Steps per Second: 21,705.96401
Overall Steps per Second: 10,526.14085

Timestep Collection Time: 2.30517
Timestep Consumption Time: 2.44833
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.75350

Cumulative Model Updates: 154,762
Cumulative Timesteps: 1,291,427,316

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1291427316...
Checkpoint 1291427316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,899.42525
Policy Entropy: 1.70893
Value Function Loss: 0.04259

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.30210
Value Function Update Magnitude: 0.31708

Collected Steps per Second: 21,287.15871
Overall Steps per Second: 10,312.37977

Timestep Collection Time: 2.35024
Timestep Consumption Time: 2.50121
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.85145

Cumulative Model Updates: 154,768
Cumulative Timesteps: 1,291,477,346

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,423.36223
Policy Entropy: 1.71309
Value Function Loss: 0.03956

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.30083
Value Function Update Magnitude: 0.31749

Collected Steps per Second: 22,311.42550
Overall Steps per Second: 10,652.19136

Timestep Collection Time: 2.24172
Timestep Consumption Time: 2.45365
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.69537

Cumulative Model Updates: 154,774
Cumulative Timesteps: 1,291,527,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1291527362...
Checkpoint 1291527362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,193.37644
Policy Entropy: 1.70869
Value Function Loss: 0.04035

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.30240
Value Function Update Magnitude: 0.29161

Collected Steps per Second: 21,921.37187
Overall Steps per Second: 10,425.65042

Timestep Collection Time: 2.28179
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.79778

Cumulative Model Updates: 154,780
Cumulative Timesteps: 1,291,577,382

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,202.84801
Policy Entropy: 1.73312
Value Function Loss: 0.04309

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.30584
Value Function Update Magnitude: 0.30660

Collected Steps per Second: 22,288.30058
Overall Steps per Second: 10,668.20347

Timestep Collection Time: 2.24414
Timestep Consumption Time: 2.44437
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.68851

Cumulative Model Updates: 154,786
Cumulative Timesteps: 1,291,627,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1291627400...
Checkpoint 1291627400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,994.39131
Policy Entropy: 1.73796
Value Function Loss: 0.04714

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.31094
Value Function Update Magnitude: 0.32865

Collected Steps per Second: 21,710.39457
Overall Steps per Second: 10,414.89881

Timestep Collection Time: 2.30314
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.80101

Cumulative Model Updates: 154,792
Cumulative Timesteps: 1,291,677,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,383.30972
Policy Entropy: 1.73492
Value Function Loss: 0.04572

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.31092
Value Function Update Magnitude: 0.29189

Collected Steps per Second: 22,144.17143
Overall Steps per Second: 10,522.55582

Timestep Collection Time: 2.25847
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.75284

Cumulative Model Updates: 154,798
Cumulative Timesteps: 1,291,727,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1291727414...
Checkpoint 1291727414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,908.07265
Policy Entropy: 1.73301
Value Function Loss: 0.04627

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.30916
Value Function Update Magnitude: 0.28081

Collected Steps per Second: 21,693.83827
Overall Steps per Second: 10,413.13039

Timestep Collection Time: 2.30499
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.80201

Cumulative Model Updates: 154,804
Cumulative Timesteps: 1,291,777,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,820.95709
Policy Entropy: 1.73033
Value Function Loss: 0.04406

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.29930
Value Function Update Magnitude: 0.30211

Collected Steps per Second: 22,288.78421
Overall Steps per Second: 10,499.46552

Timestep Collection Time: 2.24436
Timestep Consumption Time: 2.52008
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.76443

Cumulative Model Updates: 154,810
Cumulative Timesteps: 1,291,827,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1291827442...
Checkpoint 1291827442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,741.92332
Policy Entropy: 1.72449
Value Function Loss: 0.04183

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.29642
Value Function Update Magnitude: 0.32657

Collected Steps per Second: 21,757.44611
Overall Steps per Second: 10,575.32890

Timestep Collection Time: 2.29834
Timestep Consumption Time: 2.43021
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.72855

Cumulative Model Updates: 154,816
Cumulative Timesteps: 1,291,877,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,186.00149
Policy Entropy: 1.71733
Value Function Loss: 0.04291

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.30550
Value Function Update Magnitude: 0.30817

Collected Steps per Second: 21,613.98325
Overall Steps per Second: 10,495.56309

Timestep Collection Time: 2.31378
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.76487

Cumulative Model Updates: 154,822
Cumulative Timesteps: 1,291,927,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1291927458...
Checkpoint 1291927458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,916.04323
Policy Entropy: 1.72277
Value Function Loss: 0.04311

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.30664
Value Function Update Magnitude: 0.33527

Collected Steps per Second: 21,352.22083
Overall Steps per Second: 10,335.22922

Timestep Collection Time: 2.34336
Timestep Consumption Time: 2.49794
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.84131

Cumulative Model Updates: 154,828
Cumulative Timesteps: 1,291,977,494

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,489.06528
Policy Entropy: 1.72618
Value Function Loss: 0.04511

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.30606
Value Function Update Magnitude: 0.31998

Collected Steps per Second: 22,021.76853
Overall Steps per Second: 10,528.85214

Timestep Collection Time: 2.27057
Timestep Consumption Time: 2.47847
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.74905

Cumulative Model Updates: 154,834
Cumulative Timesteps: 1,292,027,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1292027496...
Checkpoint 1292027496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,254.99890
Policy Entropy: 1.73755
Value Function Loss: 0.04839

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.30853
Value Function Update Magnitude: 0.28269

Collected Steps per Second: 21,495.05761
Overall Steps per Second: 10,531.62496

Timestep Collection Time: 2.32733
Timestep Consumption Time: 2.42275
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.75007

Cumulative Model Updates: 154,840
Cumulative Timesteps: 1,292,077,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,445.31845
Policy Entropy: 1.74559
Value Function Loss: 0.04993

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.31495
Value Function Update Magnitude: 0.28632

Collected Steps per Second: 22,147.72873
Overall Steps per Second: 10,441.01741

Timestep Collection Time: 2.25974
Timestep Consumption Time: 2.53367
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.79340

Cumulative Model Updates: 154,846
Cumulative Timesteps: 1,292,127,570

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1292127570...
Checkpoint 1292127570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,091.43556
Policy Entropy: 1.74906
Value Function Loss: 0.04827

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.31440
Value Function Update Magnitude: 0.33238

Collected Steps per Second: 21,939.17261
Overall Steps per Second: 10,587.40895

Timestep Collection Time: 2.27930
Timestep Consumption Time: 2.44386
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.72316

Cumulative Model Updates: 154,852
Cumulative Timesteps: 1,292,177,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,160.00167
Policy Entropy: 1.73097
Value Function Loss: 0.04588

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31615
Value Function Update Magnitude: 0.31555

Collected Steps per Second: 22,234.78575
Overall Steps per Second: 10,563.53902

Timestep Collection Time: 2.24990
Timestep Consumption Time: 2.48583
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.73572

Cumulative Model Updates: 154,858
Cumulative Timesteps: 1,292,227,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1292227602...
Checkpoint 1292227602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,672.66084
Policy Entropy: 1.72011
Value Function Loss: 0.04403

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.31850
Value Function Update Magnitude: 0.32892

Collected Steps per Second: 21,974.26278
Overall Steps per Second: 10,506.13197

Timestep Collection Time: 2.27603
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.76046

Cumulative Model Updates: 154,864
Cumulative Timesteps: 1,292,277,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,690.88973
Policy Entropy: 1.70277
Value Function Loss: 0.04349

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.31314
Value Function Update Magnitude: 0.34079

Collected Steps per Second: 21,324.93865
Overall Steps per Second: 10,448.43309

Timestep Collection Time: 2.34561
Timestep Consumption Time: 2.44171
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.78732

Cumulative Model Updates: 154,870
Cumulative Timesteps: 1,292,327,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1292327636...
Checkpoint 1292327636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,000.53662
Policy Entropy: 1.69594
Value Function Loss: 0.04077

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31093
Value Function Update Magnitude: 0.33483

Collected Steps per Second: 20,963.49964
Overall Steps per Second: 10,522.72332

Timestep Collection Time: 2.38634
Timestep Consumption Time: 2.36775
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.75409

Cumulative Model Updates: 154,876
Cumulative Timesteps: 1,292,377,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,982.60807
Policy Entropy: 1.68317
Value Function Loss: 0.03888

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.31090
Value Function Update Magnitude: 0.32709

Collected Steps per Second: 21,321.92437
Overall Steps per Second: 10,550.26550

Timestep Collection Time: 2.34688
Timestep Consumption Time: 2.39613
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.74301

Cumulative Model Updates: 154,882
Cumulative Timesteps: 1,292,427,702

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1292427702...
Checkpoint 1292427702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,186.46202
Policy Entropy: 1.68682
Value Function Loss: 0.03811

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.30905
Value Function Update Magnitude: 0.33994

Collected Steps per Second: 21,130.36154
Overall Steps per Second: 10,614.72195

Timestep Collection Time: 2.36693
Timestep Consumption Time: 2.34483
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.71176

Cumulative Model Updates: 154,888
Cumulative Timesteps: 1,292,477,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,626.52092
Policy Entropy: 1.70838
Value Function Loss: 0.03906

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08287
Policy Update Magnitude: 0.30641
Value Function Update Magnitude: 0.33426

Collected Steps per Second: 21,084.79104
Overall Steps per Second: 10,429.76897

Timestep Collection Time: 2.37147
Timestep Consumption Time: 2.42269
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.79416

Cumulative Model Updates: 154,894
Cumulative Timesteps: 1,292,527,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1292527718...
Checkpoint 1292527718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,696.19693
Policy Entropy: 1.71917
Value Function Loss: 0.03841

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.30558
Value Function Update Magnitude: 0.33857

Collected Steps per Second: 21,204.92808
Overall Steps per Second: 10,321.83160

Timestep Collection Time: 2.35823
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.84468

Cumulative Model Updates: 154,900
Cumulative Timesteps: 1,292,577,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,992.18276
Policy Entropy: 1.72676
Value Function Loss: 0.03820

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.29971
Value Function Update Magnitude: 0.34028

Collected Steps per Second: 21,585.64690
Overall Steps per Second: 10,373.40203

Timestep Collection Time: 2.31700
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.82137

Cumulative Model Updates: 154,906
Cumulative Timesteps: 1,292,627,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1292627738...
Checkpoint 1292627738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,411.25586
Policy Entropy: 1.71950
Value Function Loss: 0.03738

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.30154
Value Function Update Magnitude: 0.32608

Collected Steps per Second: 21,443.83674
Overall Steps per Second: 10,361.00422

Timestep Collection Time: 2.33419
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.83100

Cumulative Model Updates: 154,912
Cumulative Timesteps: 1,292,677,792

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,848.67845
Policy Entropy: 1.69658
Value Function Loss: 0.04034

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.30006
Value Function Update Magnitude: 0.31662

Collected Steps per Second: 21,922.76137
Overall Steps per Second: 10,415.35324

Timestep Collection Time: 2.28110
Timestep Consumption Time: 2.52027
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.80137

Cumulative Model Updates: 154,918
Cumulative Timesteps: 1,292,727,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1292727800...
Checkpoint 1292727800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,558.27259
Policy Entropy: 1.70601
Value Function Loss: 0.04534

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.31257
Value Function Update Magnitude: 0.31018

Collected Steps per Second: 21,944.83343
Overall Steps per Second: 10,509.04208

Timestep Collection Time: 2.27862
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.75819

Cumulative Model Updates: 154,924
Cumulative Timesteps: 1,292,777,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,887.34110
Policy Entropy: 1.69868
Value Function Loss: 0.04498

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.31881
Value Function Update Magnitude: 0.33475

Collected Steps per Second: 22,261.28731
Overall Steps per Second: 10,496.50935

Timestep Collection Time: 2.24776
Timestep Consumption Time: 2.51935
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.76711

Cumulative Model Updates: 154,930
Cumulative Timesteps: 1,292,827,842

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1292827842...
Checkpoint 1292827842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,697.99670
Policy Entropy: 1.71772
Value Function Loss: 0.04587

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.31790
Value Function Update Magnitude: 0.35567

Collected Steps per Second: 22,141.35469
Overall Steps per Second: 10,675.79348

Timestep Collection Time: 2.25840
Timestep Consumption Time: 2.42547
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.68387

Cumulative Model Updates: 154,936
Cumulative Timesteps: 1,292,877,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,535.76461
Policy Entropy: 1.72472
Value Function Loss: 0.04428

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.31696
Value Function Update Magnitude: 0.34861

Collected Steps per Second: 21,998.68835
Overall Steps per Second: 10,410.54828

Timestep Collection Time: 2.27423
Timestep Consumption Time: 2.53148
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.80570

Cumulative Model Updates: 154,942
Cumulative Timesteps: 1,292,927,876

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1292927876...
Checkpoint 1292927876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,524.27666
Policy Entropy: 1.74442
Value Function Loss: 0.04595

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.31383
Value Function Update Magnitude: 0.33968

Collected Steps per Second: 21,813.41473
Overall Steps per Second: 10,616.20279

Timestep Collection Time: 2.29345
Timestep Consumption Time: 2.41897
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.71242

Cumulative Model Updates: 154,948
Cumulative Timesteps: 1,292,977,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,649.54924
Policy Entropy: 1.73961
Value Function Loss: 0.04416

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.31063
Value Function Update Magnitude: 0.34276

Collected Steps per Second: 21,527.46993
Overall Steps per Second: 10,493.25362

Timestep Collection Time: 2.32345
Timestep Consumption Time: 2.44323
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.76668

Cumulative Model Updates: 154,954
Cumulative Timesteps: 1,293,027,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1293027922...
Checkpoint 1293027922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,613.51320
Policy Entropy: 1.71041
Value Function Loss: 0.04392

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.31475
Value Function Update Magnitude: 0.35273

Collected Steps per Second: 21,567.35454
Overall Steps per Second: 10,536.81997

Timestep Collection Time: 2.31906
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.74678

Cumulative Model Updates: 154,960
Cumulative Timesteps: 1,293,077,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,992.98489
Policy Entropy: 1.69887
Value Function Loss: 0.04105

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.31177
Value Function Update Magnitude: 0.34586

Collected Steps per Second: 21,563.59977
Overall Steps per Second: 10,503.76611

Timestep Collection Time: 2.32002
Timestep Consumption Time: 2.44284
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.76286

Cumulative Model Updates: 154,966
Cumulative Timesteps: 1,293,127,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1293127966...
Checkpoint 1293127966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,044.79863
Policy Entropy: 1.70347
Value Function Loss: 0.04131

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.30393
Value Function Update Magnitude: 0.34175

Collected Steps per Second: 21,551.19568
Overall Steps per Second: 10,311.39208

Timestep Collection Time: 2.32052
Timestep Consumption Time: 2.52945
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.84998

Cumulative Model Updates: 154,972
Cumulative Timesteps: 1,293,177,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,725.68822
Policy Entropy: 1.71196
Value Function Loss: 0.04146

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.30111
Value Function Update Magnitude: 0.33633

Collected Steps per Second: 22,269.03379
Overall Steps per Second: 10,464.81061

Timestep Collection Time: 2.24617
Timestep Consumption Time: 2.53366
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.77983

Cumulative Model Updates: 154,978
Cumulative Timesteps: 1,293,227,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1293227996...
Checkpoint 1293227996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,418.78162
Policy Entropy: 1.70463
Value Function Loss: 0.03990

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.30705
Value Function Update Magnitude: 0.33972

Collected Steps per Second: 21,870.76539
Overall Steps per Second: 10,600.46178

Timestep Collection Time: 2.28725
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.71904

Cumulative Model Updates: 154,984
Cumulative Timesteps: 1,293,278,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,145.10889
Policy Entropy: 1.69117
Value Function Loss: 0.04112

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.34176

Collected Steps per Second: 22,104.45027
Overall Steps per Second: 10,468.53376

Timestep Collection Time: 2.26262
Timestep Consumption Time: 2.51493
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.77756

Cumulative Model Updates: 154,990
Cumulative Timesteps: 1,293,328,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1293328034...
Checkpoint 1293328034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,281.70889
Policy Entropy: 1.69434
Value Function Loss: 0.03881

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.30975
Value Function Update Magnitude: 0.34280

Collected Steps per Second: 22,045.57934
Overall Steps per Second: 10,598.88352

Timestep Collection Time: 2.26975
Timestep Consumption Time: 2.45131
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.72106

Cumulative Model Updates: 154,996
Cumulative Timesteps: 1,293,378,072

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,414.00040
Policy Entropy: 1.69370
Value Function Loss: 0.04074

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.30824
Value Function Update Magnitude: 0.34067

Collected Steps per Second: 22,041.96196
Overall Steps per Second: 10,484.61274

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.50129
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.77042

Cumulative Model Updates: 155,002
Cumulative Timesteps: 1,293,428,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1293428088...
Checkpoint 1293428088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,341.90748
Policy Entropy: 1.70501
Value Function Loss: 0.04056

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.34949

Collected Steps per Second: 21,855.72980
Overall Steps per Second: 10,607.08303

Timestep Collection Time: 2.28773
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.71383

Cumulative Model Updates: 155,008
Cumulative Timesteps: 1,293,478,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,990.77705
Policy Entropy: 1.68881
Value Function Loss: 0.03940

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07861
Policy Update Magnitude: 0.30968
Value Function Update Magnitude: 0.34831

Collected Steps per Second: 21,356.68827
Overall Steps per Second: 10,475.88471

Timestep Collection Time: 2.34325
Timestep Consumption Time: 2.43382
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.77707

Cumulative Model Updates: 155,014
Cumulative Timesteps: 1,293,528,132

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1293528132...
Checkpoint 1293528132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,461.09269
Policy Entropy: 1.68863
Value Function Loss: 0.04342

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.30830
Value Function Update Magnitude: 0.34046

Collected Steps per Second: 20,903.45187
Overall Steps per Second: 10,535.36852

Timestep Collection Time: 2.39386
Timestep Consumption Time: 2.35585
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74972

Cumulative Model Updates: 155,020
Cumulative Timesteps: 1,293,578,172

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,423.15380
Policy Entropy: 1.68599
Value Function Loss: 0.04430

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.30882
Value Function Update Magnitude: 0.33793

Collected Steps per Second: 20,731.65196
Overall Steps per Second: 10,482.49976

Timestep Collection Time: 2.41225
Timestep Consumption Time: 2.35856
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.77081

Cumulative Model Updates: 155,026
Cumulative Timesteps: 1,293,628,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1293628182...
Checkpoint 1293628182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,460.96204
Policy Entropy: 1.69728
Value Function Loss: 0.04600

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.31528
Value Function Update Magnitude: 0.31394

Collected Steps per Second: 20,910.85322
Overall Steps per Second: 10,415.95869

Timestep Collection Time: 2.39215
Timestep Consumption Time: 2.41028
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.80244

Cumulative Model Updates: 155,032
Cumulative Timesteps: 1,293,678,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,672.78669
Policy Entropy: 1.70168
Value Function Loss: 0.04168

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.31431
Value Function Update Magnitude: 0.31335

Collected Steps per Second: 21,464.78722
Overall Steps per Second: 10,431.98216

Timestep Collection Time: 2.33051
Timestep Consumption Time: 2.46474
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.79525

Cumulative Model Updates: 155,038
Cumulative Timesteps: 1,293,728,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1293728228...
Checkpoint 1293728228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,677.85446
Policy Entropy: 1.70705
Value Function Loss: 0.04407

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.31653
Value Function Update Magnitude: 0.32812

Collected Steps per Second: 21,414.30960
Overall Steps per Second: 10,532.72506

Timestep Collection Time: 2.33535
Timestep Consumption Time: 2.41270
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.74806

Cumulative Model Updates: 155,044
Cumulative Timesteps: 1,293,778,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,624.91565
Policy Entropy: 1.69681
Value Function Loss: 0.04256

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.31503
Value Function Update Magnitude: 0.35056

Collected Steps per Second: 21,966.68931
Overall Steps per Second: 10,499.81495

Timestep Collection Time: 2.27699
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.76370

Cumulative Model Updates: 155,050
Cumulative Timesteps: 1,293,828,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1293828256...
Checkpoint 1293828256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,550.77695
Policy Entropy: 1.70293
Value Function Loss: 0.04191

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.31140
Value Function Update Magnitude: 0.35207

Collected Steps per Second: 21,919.04687
Overall Steps per Second: 10,488.04888

Timestep Collection Time: 2.28176
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.76867

Cumulative Model Updates: 155,056
Cumulative Timesteps: 1,293,878,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,535.68137
Policy Entropy: 1.69525
Value Function Loss: 0.04096

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07626
Policy Update Magnitude: 0.31090
Value Function Update Magnitude: 0.32618

Collected Steps per Second: 22,068.76857
Overall Steps per Second: 10,451.74619

Timestep Collection Time: 2.26628
Timestep Consumption Time: 2.51895
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.78523

Cumulative Model Updates: 155,062
Cumulative Timesteps: 1,293,928,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1293928284...
Checkpoint 1293928284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,946.57132
Policy Entropy: 1.70778
Value Function Loss: 0.04015

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.30821
Value Function Update Magnitude: 0.31190

Collected Steps per Second: 21,669.15180
Overall Steps per Second: 10,565.07817

Timestep Collection Time: 2.30900
Timestep Consumption Time: 2.42679
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.73579

Cumulative Model Updates: 155,068
Cumulative Timesteps: 1,293,978,318

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,116.81824
Policy Entropy: 1.68729
Value Function Loss: 0.04220

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07631
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.30549

Collected Steps per Second: 21,817.28607
Overall Steps per Second: 10,603.33673

Timestep Collection Time: 2.29286
Timestep Consumption Time: 2.42490
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.71776

Cumulative Model Updates: 155,074
Cumulative Timesteps: 1,294,028,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1294028342...
Checkpoint 1294028342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,291.69761
Policy Entropy: 1.68954
Value Function Loss: 0.03765

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.30666
Value Function Update Magnitude: 0.27839

Collected Steps per Second: 21,819.11472
Overall Steps per Second: 10,565.75671

Timestep Collection Time: 2.29276
Timestep Consumption Time: 2.44197
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.73473

Cumulative Model Updates: 155,080
Cumulative Timesteps: 1,294,078,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,643.05552
Policy Entropy: 1.70020
Value Function Loss: 0.03816

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07366
Policy Update Magnitude: 0.30262
Value Function Update Magnitude: 0.29393

Collected Steps per Second: 21,764.72956
Overall Steps per Second: 10,467.23534

Timestep Collection Time: 2.29840
Timestep Consumption Time: 2.48071
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.77910

Cumulative Model Updates: 155,086
Cumulative Timesteps: 1,294,128,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1294128392...
Checkpoint 1294128392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,158.17425
Policy Entropy: 1.71189
Value Function Loss: 0.03713

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07280
Policy Update Magnitude: 0.30062
Value Function Update Magnitude: 0.28505

Collected Steps per Second: 21,586.23201
Overall Steps per Second: 10,395.24069

Timestep Collection Time: 2.31713
Timestep Consumption Time: 2.49450
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.81162

Cumulative Model Updates: 155,092
Cumulative Timesteps: 1,294,178,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,240.91444
Policy Entropy: 1.70865
Value Function Loss: 0.03983

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.30480
Value Function Update Magnitude: 0.26744

Collected Steps per Second: 21,763.35908
Overall Steps per Second: 10,460.29652

Timestep Collection Time: 2.29983
Timestep Consumption Time: 2.48512
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.78495

Cumulative Model Updates: 155,098
Cumulative Timesteps: 1,294,228,462

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1294228462...
Checkpoint 1294228462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,461.58543
Policy Entropy: 1.69350
Value Function Loss: 0.04131

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.30852
Value Function Update Magnitude: 0.26644

Collected Steps per Second: 21,805.75450
Overall Steps per Second: 10,454.91352

Timestep Collection Time: 2.29389
Timestep Consumption Time: 2.49046
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.78435

Cumulative Model Updates: 155,104
Cumulative Timesteps: 1,294,278,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,990.12748
Policy Entropy: 1.69008
Value Function Loss: 0.04247

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07347
Policy Update Magnitude: 0.31227
Value Function Update Magnitude: 0.27260

Collected Steps per Second: 21,463.53031
Overall Steps per Second: 10,421.65712

Timestep Collection Time: 2.32953
Timestep Consumption Time: 2.46817
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.79770

Cumulative Model Updates: 155,110
Cumulative Timesteps: 1,294,328,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1294328482...
Checkpoint 1294328482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,743.72873
Policy Entropy: 1.67710
Value Function Loss: 0.04231

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.31493
Value Function Update Magnitude: 0.29156

Collected Steps per Second: 21,174.64421
Overall Steps per Second: 10,557.72488

Timestep Collection Time: 2.36264
Timestep Consumption Time: 2.37588
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.73852

Cumulative Model Updates: 155,116
Cumulative Timesteps: 1,294,378,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,870.41463
Policy Entropy: 1.69239
Value Function Loss: 0.04192

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.31367
Value Function Update Magnitude: 0.31367

Collected Steps per Second: 21,374.16921
Overall Steps per Second: 10,539.17859

Timestep Collection Time: 2.34058
Timestep Consumption Time: 2.40628
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.74686

Cumulative Model Updates: 155,122
Cumulative Timesteps: 1,294,428,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1294428538...
Checkpoint 1294428538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,784.84887
Policy Entropy: 1.69844
Value Function Loss: 0.04312

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.31482
Value Function Update Magnitude: 0.31544

Collected Steps per Second: 21,319.46793
Overall Steps per Second: 10,640.71163

Timestep Collection Time: 2.34537
Timestep Consumption Time: 2.35375
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.69912

Cumulative Model Updates: 155,128
Cumulative Timesteps: 1,294,478,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,395.29354
Policy Entropy: 1.71399
Value Function Loss: 0.04025

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.31080
Value Function Update Magnitude: 0.31750

Collected Steps per Second: 20,324.75141
Overall Steps per Second: 10,220.20923

Timestep Collection Time: 2.46055
Timestep Consumption Time: 2.43270
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.89325

Cumulative Model Updates: 155,134
Cumulative Timesteps: 1,294,528,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1294528550...
Checkpoint 1294528550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,979.19165
Policy Entropy: 1.69988
Value Function Loss: 0.03887

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.30651
Value Function Update Magnitude: 0.30934

Collected Steps per Second: 21,382.94996
Overall Steps per Second: 10,533.29797

Timestep Collection Time: 2.33859
Timestep Consumption Time: 2.40883
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.74742

Cumulative Model Updates: 155,140
Cumulative Timesteps: 1,294,578,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,944.96506
Policy Entropy: 1.70200
Value Function Loss: 0.03782

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07918
Policy Update Magnitude: 0.30615
Value Function Update Magnitude: 0.29730

Collected Steps per Second: 21,716.29321
Overall Steps per Second: 10,454.57544

Timestep Collection Time: 2.30297
Timestep Consumption Time: 2.48077
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.78374

Cumulative Model Updates: 155,146
Cumulative Timesteps: 1,294,628,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1294628568...
Checkpoint 1294628568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,713.04611
Policy Entropy: 1.69626
Value Function Loss: 0.04472

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.30908
Value Function Update Magnitude: 0.28448

Collected Steps per Second: 21,577.65915
Overall Steps per Second: 10,009.53986

Timestep Collection Time: 2.31805
Timestep Consumption Time: 2.67899
PPO Batch Consumption Time: 0.31975
Total Iteration Time: 4.99703

Cumulative Model Updates: 155,152
Cumulative Timesteps: 1,294,678,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,552.88585
Policy Entropy: 1.69138
Value Function Loss: 0.04451

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.31547
Value Function Update Magnitude: 0.29827

Collected Steps per Second: 10,621.22424
Overall Steps per Second: 6,686.42520

Timestep Collection Time: 4.71132
Timestep Consumption Time: 2.77250
PPO Batch Consumption Time: 0.31374
Total Iteration Time: 7.48382

Cumulative Model Updates: 155,158
Cumulative Timesteps: 1,294,728,626

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1294728626...
Checkpoint 1294728626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,487.92179
Policy Entropy: 1.68609
Value Function Loss: 0.04461

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.31957
Value Function Update Magnitude: 0.30736

Collected Steps per Second: 19,979.44679
Overall Steps per Second: 9,373.12951

Timestep Collection Time: 2.50277
Timestep Consumption Time: 2.83205
PPO Batch Consumption Time: 0.33559
Total Iteration Time: 5.33482

Cumulative Model Updates: 155,164
Cumulative Timesteps: 1,294,778,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,157.95059
Policy Entropy: 1.68242
Value Function Loss: 0.04042

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.30982
Value Function Update Magnitude: 0.31880

Collected Steps per Second: 19,000.09783
Overall Steps per Second: 9,577.89732

Timestep Collection Time: 2.63325
Timestep Consumption Time: 2.59044
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 5.22369

Cumulative Model Updates: 155,170
Cumulative Timesteps: 1,294,828,662

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1294828662...
Checkpoint 1294828662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,761.49485
Policy Entropy: 1.68065
Value Function Loss: 0.04075

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.29051
Value Function Update Magnitude: 0.31745

Collected Steps per Second: 19,354.89838
Overall Steps per Second: 9,959.73530

Timestep Collection Time: 2.58405
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 5.02162

Cumulative Model Updates: 155,176
Cumulative Timesteps: 1,294,878,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1294878676...
Checkpoint 1294878676 saved!
