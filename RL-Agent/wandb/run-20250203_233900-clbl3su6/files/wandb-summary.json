{"x_vel":25.173079143227156,"_step":125384,"z_vel":4.7584952486414,"_timestamp":1.7386440638399084e+09,"_runtime":315785.6468164,"Timestep Collection Time":2.6291816000000097,"Policy Update Magnitude":0.31638026237487793,"Policy Entropy":3.0807480414708457,"Value Function Loss":0.009497541623810926,"Collected Steps per Second":19021.888788511154,"Total Iteration Time":5.426570400000003,"Policy Reward":18817.688685348163,"PPO Batch Consumption Time":0.32575281461079914,"Value Function Update Magnitude":0.346201628446579,"Cumulative Timesteps":3135891066,"Timestep Consumption Time":2.797388799999993,"_wandb":{"runtime":315785},"SB3 Clip Fraction":0.06680333179732163,"Cumulative Model Updates":375966,"Mean KL Divergence":0.007115525969614585,"y_vel":17.97942035686662,"Overall Steps per Second":9216.134006111848,"Timesteps Collected":50012}